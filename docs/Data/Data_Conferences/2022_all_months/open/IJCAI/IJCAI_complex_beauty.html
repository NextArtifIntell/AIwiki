<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJCAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijcai---862">IJCAI - 862</h2>
<ul>
<li><details>
<summary>
(2022). Text/speech-driven full-body animation. <em>IJCAI</em>,
5956–5959. (<a href="https://doi.org/10.24963/ijcai.2022/863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the increasing demand in films and games, synthesizing 3D avatar animation has attracted much attention recently. In this work, we present a production-ready text/speech-driven full-body animation synthesis system. Given the text and corresponding speech, our system synthesizes face and body animations simultaneously, which are then skinned and rendered to obtain a video stream output. We adopt a learning-based approach for synthesizing facial animation and a graph-based approach to animate the body, which generates high-quality avatar animation efficiently and robustly. Our results demonstrate the generated avatar animations are realistic, diverse and highly text/speech-correlated. Keywords: Humans and AI: Cognitive Systems Agent-based and Multi-agent Systems: Human-Agent Interaction Humans and AI: Applications Humans and AI: Cognitive Modeling Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Wenlin Zhuang and Jinwei Qi and Peng Zhang and Bang Zhang and Ping Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/863},
  pages     = {5956-5959},
  title     = {Text/Speech-driven full-body animation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AutoVideo: An automated video action recognition system.
<em>IJCAI</em>, 5952–5955. (<a
href="https://doi.org/10.24963/ijcai.2022/862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Action recognition is an important task for video understanding with broad applications. However, developing an effective action recognition solution often requires extensive engineering efforts in building and testing different combinations of the modules and their hyperparameters. In this demo, we present AutoVideo, a Python system for automated video action recognition. AutoVideo is featured for 1) highly modular and extendable infrastructure following the standard pipeline language, 2) an exhaustive list of primitives for pipeline construction, 3) data-driven tuners to save the efforts of pipeline tuning, and 4) easy-to-use Graphical User Interface (GUI). AutoVideo is released under MIT license at https://github.com/datamllab/autovideo Keywords: Machine Learning: Automated Machine Learning Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Daochen Zha and Zaid Pervaiz Bhat and Yi-Wei Chen and Yicheng Wang and Sirui Ding and Jiaben Chen and Kwei-Herng Lai and Mohammad Qazim Bhat and Anmoll Kumar Jain and Alfredo Costilla Reyes and Na Zou and Xia Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/862},
  pages     = {5952-5955},
  title     = {AutoVideo: An automated video action recognition system},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-tuning deep neural networks by interactively refining
the 2D latent space of ambiguous images. <em>IJCAI</em>, 5948–5951. (<a
href="https://doi.org/10.24963/ijcai.2022/861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks (DNNs) have achieved excellent results currently in classification, while they may still suffer from ambiguous images which are similar across classes. By contrast, humans have a relatively good ability to distinguish these categories of images. Therefore, we propose a human-in-the-loop solution to assist the network to better classify the images by leveraging human knowledge. To achieve this, we project the high-dimensional latent space trained by the network onto a two-dimensional workspace. The users can interactively modify the projected coordinates of inputs on the workspace using our designed tools, then the modified information will be fed back to the network to fine-tune it, which in turn affects the network&#39;s classification results, thereby improving the accuracy of network classification. Keywords: Humans and AI: Human-Computer Interaction Humans and AI: Human-AI Collaboration},
  archive   = {C_IJCAI},
  author    = {Jiafu Wei and Haoran Xie and Chia-Ming Chang and Xi Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/861},
  pages     = {5948-5951},
  title     = {Fine-tuning deep neural networks by interactively refining the 2D latent space of ambiguous images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VMAgent: A practical virtual machine scheduling platform.
<em>IJCAI</em>, 5944–5947. (<a
href="https://doi.org/10.24963/ijcai.2022/860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Virtual machine (VM) scheduling is one of the critical tasks in cloud computing. Many works have attempted to incorporate machine learning, especially reinforcement learning, to empower VM scheduling procedures. Although improved results are shown in several demo simulators, the performances in real-world scenarios are still underexploited. In this paper, we design a practical VM scheduling platform, i.e., VMAgent, to assist researchers in developing their methods on the VM scheduling problem. VMAgent consists of three components: simulator, scheduler, and visualizer. The simulator abstracts three general realistic scheduling scenarios (fading, recovering, and expansion) based on Huawei Cloud’s scheduling data, which is the core of our platform. Flexible configurations are further provided to make the simulator compatible with practical cloud computing architecture (i.e., Multi Non-Uniform Memory Access) and scenarios. Researchers then need to instantiate the scheduler to interact with the simulator, which is also pre-built in various types (e.g., heuristic, machine learning, and operations research) of scheduling algorithms to speed up the algorithm design. The visualizer, as an auxiliary component of the simulator and scheduler, facilitates researchers to conduct an in-depth analysis of the scheduling procedure and comprehensively compare different scheduling algorithms. We believe that VMAgent would shed light on the AI for the VM scheduling community, and the demo video is presented in https://bit.ly/vmagent-demo-video. Keywords: Planning and Scheduling: Learning in Planning and Scheduling Machine Learning: Deep Reinforcement Learning Planning and Scheduling: Scheduling Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Junjie Sheng and Shengliang Cai and Haochuan Cui and Wenhao Li and Yun Hua and Bo Jin and Wenli Zhou and Yiqiu Hu and Lei Zhu and Qian Peng and Hongyuan Zha and Xiangfeng Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/860},
  pages     = {5944-5947},
  title     = {VMAgent: A practical virtual machine scheduling platform},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ACTA 2.0: A modular architecture for multi-layer
argumentative analysis of clinical trials. <em>IJCAI</em>, 5940–5943.
(<a href="https://doi.org/10.24963/ijcai.2022/859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evidence-based medicine aims at making decisions about the care of individual patients based on the explicit use of the best available evidence in the patient clinical history and the medical literature results. Argumentation represents a natural way of addressing this task by (i) identifying evidence and claims in text, and (ii) reasoning upon the extracted arguments and their relations to make a decision. ACTA 2.0 is an automated tool which relies on Argument Mining methods to analyse the abstracts of clinical trials to extract argument components and relations to support evidence-based clinical decision making. ACTA 2.0 allows also for the identification of PICO (Patient, Intervention, Comparison, Outcome) elements, and the analysis of the effects of an intervention on the outcomes of the study. A REST API is also provided to exploit the tool’s functionalities. Keywords: Natural Language Processing: Information Extraction Knowledge Representation and Reasoning: Argumentation Natural Language Processing: Applications Natural Language Processing: Tools},
  archive   = {C_IJCAI},
  author    = {Benjamin Molinet and Santiago Marro and Elena Cabrio and Serena Villata and Tobias Mayer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/859},
  pages     = {5940-5943},
  title     = {ACTA 2.0: A modular architecture for multi-layer argumentative analysis of clinical trials},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The good, the bad, and the explainer: A tool for contrastive
explanations of text classifiers. <em>IJCAI</em>, 5936–5939. (<a
href="https://doi.org/10.24963/ijcai.2022/858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the last few years, we have been witnessing the increasing deployment of machine learning-based systems, which act as black boxes whose behaviour is hidden to end-users. As a side-effect, this contributes to increasing the need for explainable methods and tools to support the coordination between humans and ML models towards collaborative decision-making. In this paper, we demonstrate ContrXT, a novel tool that computes the differences in the classification logic of two distinct trained models, reasoning on their symbolic representation through Binary Decision Diagrams. ContrXT is available as a pip package and API. Keywords: Natural Language Processing: Interpretability and Analysis of Models for NLP AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Lorenzo Malandri and Fabio Mercorio and Mario Mezzanzanica and Navid Nobani and Andrea Seveso},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/858},
  pages     = {5936-5939},
  title     = {The good, the bad, and the explainer: A tool for contrastive explanations of text classifiers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AMICA: An argumentative search engine for COVID-19
literature. <em>IJCAI</em>, 5932–5935. (<a
href="https://doi.org/10.24963/ijcai.2022/857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AMICA is an argument mining-based search engine, specifically designed for the analysis of scientific literature related to Covid-19. AMICA retrieves scientific papers based on matching keywords and ranks the results based on the papers&#39; argumentative content. An experimental evaluation conducted on a case study in collaboration with the Italian National Institute of Health shows that the AMICA ranking agrees with expert opinion, as well as, importantly, with the impartial quality criteria indicated by Cochrane Systematic Reviews. Keywords: Natural Language Processing: Applications Multidisciplinary Topics and Applications: Health and Medicine Natural Language Processing: Information Retrieval and Text Mining},
  archive   = {C_IJCAI},
  author    = {Marco Lippi and Francesco Antici and Gianfranco Brambilla and Evaristo Cisbani and Andrea Galassi and Daniele Giansanti and Fabio Magurano and Antonella Rosi and Federico Ruggeri and Paolo Torroni},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/857},
  pages     = {5932-5935},
  title     = {AMICA: An argumentative search engine for COVID-19 literature},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time portrait stylization on the edge. <em>IJCAI</em>,
5928–5931. (<a href="https://doi.org/10.24963/ijcai.2022/856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we demonstrate real-time portrait stylization, specifically, translating self-portrait into cartoon or anime style on mobile devices. We propose a latency-driven differentiable architecture search method, maintaining realistic generative quality. With our framework, we obtain 10× computation reduction on the generative model and achieve real-time video stylization on off-the-shelf smartphone using mobile GPUs. Keywords: Computer Vision: Neural generative models, auto encoders, GANs Constraint Satisfaction and Optimization: Applications Machine Learning: Automated Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yanyu Li and Xuan Shen and Geng Yuan and Jiexiong Guan and Wei Niu and Hao Tang and Bin Ren and Yanzhi Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/856},
  pages     = {5928-5931},
  title     = {Real-time portrait stylization on the edge},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sign-to-speech model for sign language understanding: A case
study of nigerian sign language. <em>IJCAI</em>, 5924–5927. (<a
href="https://doi.org/10.24963/ijcai.2022/855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Through this paper, we seek to reduce the communication barrier between the hearing-impaired community and the larger society who are usually not familiar with sign language in the sub-Saharan region of Africa with the largest occurrences of hearing disability cases, while using Nigeria as a case study. The dataset is a pioneer dataset for the Nigerian Sign Language and was created in collaboration with relevant stakeholders. We pre-processed the data in readiness for two different object detection models and a classification model and employed diverse evaluation metrics to gauge model performance on sign-language to text conversion tasks. Finally, we convert the predicted sign texts to speech and deploy the best performing model in a lightweight application that works in real-time and achieves impressive results converting sign words/phrases to text and subsequently, into speech. Keywords: AI Ethics, Trust, Fairness: Societal Impact of AI AI Ethics, Trust, Fairness: Fairness &amp; Diversity Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Steven Kolawole and Opeyemi Osakuade and Nayan Saxena and Babatunde Kazeem Olorisade},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/855},
  pages     = {5924-5927},
  title     = {Sign-to-speech model for sign language understanding: A case study of nigerian sign language},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PillGood: Automated and interactive pill dispenser using
facial recognition for safe and personalized medication. <em>IJCAI</em>,
5920–5923. (<a href="https://doi.org/10.24963/ijcai.2022/854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safety of taking medicine prescribed differently to each patient in hospital relies on the discernment of medical professionals who deals with measuring pill quantity, packaging, and distributing. It is difficult and time consuming to keep track of medication record of each patient. Also, medication safety is prone to be in risk due to the human error. To help patients get accurate medication following their prescription plan with minimizing human labors and mistakes, we developed PillGood, an automated smart pill dispenser system using facial recognition technique. PillGood provides real-time and personalized guidance to take the correct medicine by alarming patients and distributing exact quantity of pills at specific time following each patient&#39;s prescription table. The system notify patients through mobile app and speaker when they need to take the medicine, and detect who the patient is through the machine learning based face recognition. Then, based on each patient&#39;s prescribing information, the controller distributes pills to each patient. Results show that PillGood enable highly accurate personalized pill dispensation followed by precise face recognition, benefiting both patients and medical professionals. Videos for demonstrating the system can be found on https://youtu.be/Wx7bXxRGjXA Keywords: Multidisciplinary Topics and Applications: AI Hardware Computer Vision: Applications Computer Vision: Recognition (object detection, categorization) Humans and AI: Applications Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Jonghyeok Kim and Hosung Kwon and Jonghyeon Kim and Jinsoo Park and Soong-Un Choi and Sookyung Kim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/854},
  pages     = {5920-5923},
  title     = {PillGood: Automated and interactive pill dispenser using facial recognition for safe and personalized medication},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ExplainIt!: A tool for computing robust attributions of
DNNs. <em>IJCAI</em>, 5916–5919. (<a
href="https://doi.org/10.24963/ijcai.2022/853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Responsible integration of deep neural networks into the design of trustworthy systems requires the ability to explain decisions made by these models. Explainability and transparency are critical for system analysis, certification, and human-machine teaming. We have recently demonstrated that neural stochastic differential equations (SDEs) present an explanation-friendly DNN architecture. In this paper, we present ExplainIt, an online tool for explaining AI decisions that uses neural SDEs to create visually sharper and more robust attributions than traditional residual neural networks. Our tool shows that the injection of noise in every layer of a residual network often leads to less noisy and less fragile integrated gradient attributions. The discrete neural stochastic differential equation model is trained on the ImageNet data set with a million images, and the demonstration produces robust attributions on images in the ImageNet validation library and on a variety of images in the wild. Our online tool is hosted publicly for educational purposes. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Sumit Jha and Alvaro Velasquez and Rickard Ewetz and Laura Pullum and Susmit Jha},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/853},
  pages     = {5916-5919},
  title     = {ExplainIt!: A tool for computing robust attributions of DNNs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A speech-driven sign language avatar animation system for
hearing impaired applications. <em>IJCAI</em>, 5912–5915. (<a
href="https://doi.org/10.24963/ijcai.2022/852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sign language is the communication language used in hearing impaired community. Recently, the research of sign language production has made great progress but still need to cope with some critical challenges. In this paper, we propose a system-level scheme and push forward the implementation of sign language production for practical usage. We build a system capable of translating speech into sign language avatar. Different from previous approach only focusing on single technology, we systematically combine algorithms of language translation, body gesture animation and facial avatar generation. We also develop two applications: Sign Language Interpretation APP and Virtual Sign Language Anchor, to facilitate easy and clear communication for hearing impaired people. Keywords: Humans and AI: Cognitive Systems Humans and AI: Applications Humans and AI: Human-Computer Interaction Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Li Hu and Jiahui Li and Jiashuo Zhang and Qi Wang and Bang Zhang and Ping Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/852},
  pages     = {5912-5915},
  title     = {A speech-driven sign language avatar animation system for hearing impaired applications},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CARBEN: Composite adversarial robustness benchmark.
<em>IJCAI</em>, 5908–5911. (<a
href="https://doi.org/10.24963/ijcai.2022/851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prior literature on adversarial attack methods has mainly focused on attacking with and defending against a single threat model, e.g., perturbations bounded in Lp ball. However, multiple threat models can be combined into composite perturbations. One such approach, composite adversarial attack (CAA), not only expands the perturbable space of the image, but also may be overlooked by current modes of robustness evaluation. This paper demonstrates how CAA&#39;s attack order affects the resulting image, and provides real-time inferences of different models, which will facilitate users&#39; configuration of the parameters of the attack level and their rapid evaluation of model prediction. A leaderboard to benchmark adversarial robustness against CAA is also introduced. Keywords: Humans and AI: Computer-Aided Education AI Ethics, Trust, Fairness: Explainability and Interpretability Humans and AI: Human-Computer Interaction Machine Learning: Robustness Multidisciplinary Topics and Applications: Web and Social Networks},
  archive   = {C_IJCAI},
  author    = {Lei Hsiung and Yun-Yun Tsai and Pin-Yu Chen and Tsung-Yi Ho},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/851},
  pages     = {5908-5911},
  title     = {CARBEN: Composite adversarial robustness benchmark},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Knowledge-based news event analysis and forecasting toolkit.
<em>IJCAI</em>, 5904–5907. (<a
href="https://doi.org/10.24963/ijcai.2022/850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a toolkit for knowledge-based news event analysis and forecasting. The toolkit is powered by a Knowledge Graph (KG) of events curated from structured and unstructured sources of event-related knowledge. The toolkit provides functions for 1) mapping ongoing news headlines to concepts in the KG, 2) retrieval, reasoning, and visualization for causal analysis and forecasting, and 3) extraction of causal knowledge from text documents to augment the KG with additional domain knowledge. Each function has a number of implementations using a wide range of state-of-the-art neuro-symbolic techniques. We show how the toolkit enables building a human-in-the-loop explainable solution for event analysis and forecasting. Keywords: Natural Language Processing: Applications Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Semantic Web Natural Language Processing: Knowledge Extraction Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {Oktie Hassanzadeh and Parul Awasthy and Ken Barker and Onkar Bhardwaj and Debarun Bhattacharjya and Mark Feblowitz and Lee Martie and Jian Ni and Kavitha Srinivas and Lucy Yip},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/850},
  pages     = {5904-5907},
  title     = {Knowledge-based news event analysis and forecasting toolkit},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactive reinforcement learning for symbolic regression
from multi-format human-preference feedbacks. <em>IJCAI</em>, 5900–5903.
(<a href="https://doi.org/10.24963/ijcai.2022/849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we propose an interactive platform to perform grammar-guided symbolic regression using a reinforcement learning approach from human-preference feedback. To do so, a reinforcement learning algorithm iteratively generates symbolic expressions, modeled as trajectories constrained by grammatical rules, from which a user shall elicit preferences. The interface gives the user three distinct ways of stating its preferences between multiple sampled symbolic expressions: categorizing samples, comparing pairs, and suggesting improvements to a sampled symbolic expression. Learning from preferences enables users to guide the exploration in the symbolic space toward regions that are more relevant to them. We provide a web-based interface testable on symbolic regression benchmark functions and power system data. Keywords: Machine Learning: Reinforcement Learning Humans and AI: Human-Computer Interaction},
  archive   = {C_IJCAI},
  author    = {Laure Crochepierre and Lydia Boudjeloud-Assala and Vincent Barbesant},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/849},
  pages     = {5900-5903},
  title     = {Interactive reinforcement learning for symbolic regression from multi-format human-preference feedbacks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Itero: An online iterative voting application.
<em>IJCAI</em>, 5896–5899. (<a
href="https://doi.org/10.24963/ijcai.2022/848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Iterative voting allows a group of agents to take a collective decision in a dynamic fashion: a series of plurality elections are staged, making the relative scores of the candidates public after each round. Voters can thus adjust their ballots at each step until the process converges (or a maximal number of steps is reached). Research in computational social choice has shown that this method has the potential of reaching good-quality decisions while at the same time being easy to explain to voters. This paper presents our implementation of iterative voting on a voting platform accessible on the web. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Applications Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Joseph Boudou and Rachael Colley and Umberto Grandi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/848},
  pages     = {5896-5899},
  title     = {Itero: An online iterative voting application},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Displaying justifications for collective decisions.
<em>IJCAI</em>, 5892–5895. (<a
href="https://doi.org/10.24963/ijcai.2022/847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an online demonstration tool illustrating a general approach to computing justifications for accepting a given decision when confronted with the preferences of several agents. Such a justification consists of a set of axioms providing a normative basis for the decision, together with a step-by-step explanation of how those axioms determine the decision. Our open-source implementation may also prove useful for realising other kinds of projects in computational social choice, particularly those requiring access to a SAT solver. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Knowledge Representation and Reasoning: Automated Reasoning and Theorem Proving},
  archive   = {C_IJCAI},
  author    = {Arthur Boixel and Ulle Endriss and Oliviero Nardi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/847},
  pages     = {5892-5895},
  title     = {Displaying justifications for collective decisions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Together about dementia. <em>IJCAI</em>, 5888–5891. (<a
href="https://doi.org/10.24963/ijcai.2022/846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present ``Together about Dementia&#39;&#39;, a mobile health app that aims to help persons with dementia when they get lost through the help of caregivers, relatives, and volunteering citizens. When the app detects that a person with dementia is disoriented, wandering, and getting lost, it triggers an alarm that activates a relative and possibly a volunteer in the proximity. A backend system based on a microservice and serverless architecture performs the detection of wandering and the subsequent coordination of users that are put on a mission to the rescue of the person with dementia. The backend system implements an AI technique for spatio-temporal anomaly detection based on location data recorded by the frontend system installed on the portable device of the person with dementia. Keywords: Data Mining: Applications Data Mining: Anomaly/Outlier Detection Data Mining: Frequent Pattern Mining Data Mining: Parallel, Distributed and Cloud-based High Performance Mining Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Nicklas Sindlev Andersen and Marco Chiarandini},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/846},
  pages     = {5888-5891},
  title     = {Together about dementia},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diffusion incentives in cooperative games. <em>IJCAI</em>,
5885–5886. (<a href="https://doi.org/10.24963/ijcai.2022/845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a cooperative game setting where we want to gather more players through their social connections. Social connections can be modeled as a graph, and initially, only a subset of the players are in the game. We want to introduce diffusion incentives in such a cooperative game, i.e., incentivize the players to use their connections to invite more players to join the game. Our goal cannot be achieved by existing classical solutions, such as the Shapley value. Hence, to combat this problem, we have already proposed a solution called weighted permission Shapley value. Under this solution, for each player, inviting all of her neighbors is a dominant strategy in all monotone games. As one special application of the diffusion cooperative game, we also considered the diffusion incentives in query networks and the weighted permission Shapley value successfully characterizes the solution to the query network. Furthermore, we also characterize a Sybil-proof solution to the query network called the double geometric mechanism. Keywords: Game Theory and Economic Paradigms (GTEP): General},
  archive   = {C_IJCAI},
  author    = {Yao Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/845},
  pages     = {5885-5886},
  title     = {Diffusion incentives in cooperative games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly explanation. <em>IJCAI</em>, 5883–5884. (<a
href="https://doi.org/10.24963/ijcai.2022/844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the surge of deep learning and laws aiming at regulating the use of artificial intelligence, providing explanations to algorithms outputs has been a hot topic in the recent years. Most works are devoted to the explanation of classifiers outputs. The explanation of unsupervised machine learning algorithms, like anomaly detection, has received less attention from the XAI community. But this little interest is not imputable to the irrelevance of the topic. In this paper, we demonstrate the importance of anomaly explanation, the areas still needing investigation based upon our previous contributions to the field, and the future directions that will be explored. Keywords: Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Véronne Yepmo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/844},
  pages     = {5883-5884},
  title     = {Anomaly explanation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic multimodal emotion recognition using facial
expression, voice, and text. <em>IJCAI</em>, 5881–5882. (<a
href="https://doi.org/10.24963/ijcai.2022/843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It has been a long-time dream for humans to interact with a machine as we would with a person, in a way that it understands us, advises us, and looks after us with no human supervision. Despite being efficient on logical reasoning, current advanced systems lack empathy and user understanding. Estimating the user&#39;s emotion could greatly help the machine to identify the user&#39;s needs and adapt its behaviour accordingly. This research project aims to develop an automatic emotion recognition system based on facial expression, voice, and words. We expect to address the challenges related to multimodality, data complexity, and emotion representation. Keywords: Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Hélène Tran},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/843},
  pages     = {5881-5882},
  title     = {Automatic multimodal emotion recognition using facial expression, voice, and text},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information injection to deep learning solutions in
knowledge transfer. <em>IJCAI</em>, 5879–5880. (<a
href="https://doi.org/10.24963/ijcai.2022/842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nowadays, with the thrive of AutoML techniques, it is expected that Machine Learning algorithms will work well without any human intervention. This is why the biggest focus is on introducing new neural network architectures, especially those capable of learning to learn. Recently, the Data-Centric AI Challenge was proposed by Andrew Ng whose goal was to change the paradigm and instead of having a fixed dataset and modifying the model, now the model is fixed and the data is preprocessed so that the model results in the best performance. In my thesis, I would like to focus on another approach, where I would not modify the given data nor introduce new architectures, instead, I would like to propose new ways of injecting additional information into knowledge transfer models to increase their performance. Keywords: Machine Learning (ML): General Computer Vision (CV): General},
  archive   = {C_IJCAI},
  author    = {Paulina Tomaszewska},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/842},
  pages     = {5879-5880},
  title     = {Information injection to deep learning solutions in knowledge transfer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive artificial intelligence scheduling methods for
large-scale, stochastic, industrial applications. <em>IJCAI</em>,
5877–5878. (<a href="https://doi.org/10.24963/ijcai.2022/841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional scheduling techniques suffer from a lack of flexibility. The problem&#39;s instances need to be deterministic, and results on datasets with small benchmark instances do usually not transfer to large-scale instances. We propose to develop adaptive algorithms that can leverage the similarities between instances of industrial scheduling problems. In particular, we focus on applications of modern machine learning techniques to combinatorial optimization problems, an emerging and promising research area. Traditional scheduling techniques such as constraint, mixed-integer, or answer set programming are highly generic, domain-independent, and, therefore, do not explicitly exploit the specificities of a problem domain. However, in a production facility, the settings between two consecutive schedules are often very similar. The machines, workers, production capacity, etc., usually stay the same or do not change significantly. Traditional scheduling techniques do not take advantage of such similarities, while machine learning, especially deep learning, can discover and exploit relationships in the data. Therefore, our research aims to incorporate machine learning into combinatorial optimization. Keywords: Machine Learning (ML): General Planning, Routing, and Scheduling (PRS): General Constraint Satisfaction and Optimization (CSO): General},
  archive   = {C_IJCAI},
  author    = {Pierre Tassel},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/841},
  pages     = {5877-5878},
  title     = {Adaptive artificial intelligence scheduling methods for large-scale, stochastic, industrial applications},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A model-oriented approach for lifting symmetry-breaking
constraints in answer set programming. <em>IJCAI</em>, 5875–5876. (<a
href="https://doi.org/10.24963/ijcai.2022/840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Writing correct models for combinatorial problems is relatively straightforward; however, they must be efficient to be usable with instances producing many solution candidates. In this work, we aim to automatically generalise the discarding of symmetric solutions of Answer Set Programming instances, improving the efficiency of the programs with first-order constraints derived from propositional symmetry-breaking constraints. Keywords: Search and Optimization (SO): General Knowledge Representation and Reasoning (KRR): General Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Alice Tarzariol},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/840},
  pages     = {5875-5876},
  title     = {A model-oriented approach for lifting symmetry-breaking constraints in answer set programming},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-efficient algorithms and neural natural language
processing: Applications in the healthcare domain. <em>IJCAI</em>,
5873–5874. (<a href="https://doi.org/10.24963/ijcai.2022/839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently proposed pre-trained language models can be easily fine-tuned to a wide range of downstream tasks. However, fine-tuning requires a large training set. This PhD project introduces novel natural language processing (NLP) use cases in the healthcare domain where obtaining a large training dataset is difficult and expensive. To this end, we propose data-efficient algorithms to fine-tune NLP models in low-resource settings and validate their effectiveness. We expect the outcomes of this PhD project could contribute to the NLP research and low-resource application domains. Keywords: Speech &amp; Natural Language Processing (SNLP): General Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Heereen Shim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/839},
  pages     = {5873-5874},
  title     = {Data-efficient algorithms and neural natural language processing: Applications in the healthcare domain},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards contextually sensitive analysis of memes: Meme
genealogy and knowledge base. <em>IJCAI</em>, 5871–5872. (<a
href="https://doi.org/10.24963/ijcai.2022/838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As online communication grows, memes have continued to evolve and circulate as succinct multimodal forms of communication. However, computational approaches applied to meme-related tasks lack the same depth and contextual sensitivity of non-computational approaches and struggle to interpret intra-modal dynamics and referentiality. This research proposes to a ‘meme genealogy’ of key features and relationships between memes to inform a knowledge base constructed from meme-specific online sources and embed connotative meaning or contextual information in memes. The proposed methods provide a basis to train contextually sensitive computational models for analysing memes and applications in semi-automated meme annotation. Keywords: Computer Vision (CV): General Speech &amp; Natural Language Processing (SNLP): General Knowledge Representation and Reasoning (KRR): General},
  archive   = {C_IJCAI},
  author    = {Victoria Sherratt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/838},
  pages     = {5871-5872},
  title     = {Towards contextually sensitive analysis of memes: Meme genealogy and knowledge base},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transferability and stability of learning with limited
labelled data in multilingual text document classification.
<em>IJCAI</em>, 5869–5870. (<a
href="https://doi.org/10.24963/ijcai.2022/837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We focus on learning with limited labelled data (especially meta-learning) in conjunction with so-far under-researched multilingual textual document classification. The core principle in such learning is to achieve transferability of learned knowledge to new datasets and tasks. Currently, factors influencing the success of transfer remain mostly unclear. Their identification from experiments is challenging due to small amounts of labels making results considerably unstable. When instability of the investigated models is not explicitly taken into consideration (as is common in existing benchmarking studies), it may result in randomness possibly even invalidating the findings. We want to remedy this by in-depth exploration of factors that influence the stability and the transferability of learning with limited labelled data in multilingual textual documents classification, such as misinformation detection. Keywords: Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Branislav Pecher},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/837},
  pages     = {5869-5870},
  title     = {Transferability and stability of learning with limited labelled data in multilingual text document classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anchors selection for cross-lingual embedding alignment
through time. <em>IJCAI</em>, 5867–5868. (<a
href="https://doi.org/10.24963/ijcai.2022/836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, vector representations of words have proven to be extremely useful across a wide range of NLP applications. Because of the broad interest in the topic, it became essential to answer the following question: is it possible to align different embeddings, in order to compare terms belonging to different vector spaces and their relations? While embedding alignment received considerable attention in the literature, how to find the best anchors for this process is still an open problem; in this paper, we propose an unsupervised, automatic method to select words belonging to different corpora that are close from a semantic point of view, and can be used as anchors for aligning their respective embedding spaces. Keywords: Speech &amp; Natural Language Processing (SNLP): General},
  archive   = {C_IJCAI},
  author    = {Filippo Pallucchini},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/836},
  pages     = {5867-5868},
  title     = {Anchors selection for cross-lingual embedding alignment through time},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multivariate times series classification using multichannel
CNN. <em>IJCAI</em>, 5865–5866. (<a
href="https://doi.org/10.24963/ijcai.2022/835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series classification is an important and demanding task in sequence data mining. We focus on the multichannel representation of the time series and its corresponding convolutional neural network (CNN) classifier. The proposed method transforms multivariate time series into multichannel analogous image and it is fed into a pretrained multichannel CNN with transfer learning. To verify the efficacy of the proposed method, we compared it with recent deep learning-based time series classification models on five datasets with small amounts of training data. The results indicate that the proposed method provides improved performance on average compared with the other methods when incorporated with transfer learning. Keywords: Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {YongKyung Oh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/835},
  pages     = {5865-5866},
  title     = {Multivariate times series classification using multichannel CNN},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Application of neurosymbolic AI to sequential decision
making. <em>IJCAI</em>, 5863–5864. (<a
href="https://doi.org/10.24963/ijcai.2022/834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the history of AI, two main paradigms have been proposed to solve Sequential Decision Making (SDM) problems: Automated Planning (AP) and Reinforcement Learning (RL). Among the many proposals to unify both fields, the one known as neurosymbolic AI has recently attracted great attention. It combines the Deep Neural Networks used in modern RL with the symbolic representations typical of AP. The main goal of this PhD is to progress the state of the art in neurosymbolic AI for SDM, developing methods for both solving these problems and learning aspects of their structure. Keywords: Planning, Routing, and Scheduling (PRS): General Knowledge Representation and Reasoning (KRR): General Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Carlos Núñez-Molina},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/834},
  pages     = {5863-5864},
  title     = {Application of neurosymbolic AI to sequential decision making},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Engineering socially-oriented autonomous agents and
multiagent systems. <em>IJCAI</em>, 5861–5862. (<a
href="https://doi.org/10.24963/ijcai.2022/833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The emergent field of social AI is concerned with the development of autonomous agents that are able to act as part of larger community. Within this context, my research seeks to engineer meaningful social interactions among a group of agents from two different approaches. First, the societal level leverages constructs that apply to a society as a whole, like norms and social values. Second, the individual level endows agents with the ability to reason about others, by making use of Theory of Mind capabilities. Keywords: Multiagent Systems (MAS): General Game Theory and Economic Paradigms (GTEP): General Knowledge Representation and Reasoning (KRR): General},
  archive   = {C_IJCAI},
  author    = {Nieves Montes},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/833},
  pages     = {5861-5862},
  title     = {Engineering socially-oriented autonomous agents and multiagent systems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Equilibria in strategic nominee selection. <em>IJCAI</em>,
5859–5860. (<a href="https://doi.org/10.24963/ijcai.2022/832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In my PhD project I explore the game-theoretic problems related to the strategic selection of party nominees. I aim at establishing the complexity of computational problems in this setting. I further study aspects of opinion diffusion protocols related to this problem. Keywords: Game Theory and Economic Paradigms (GTEP): General Multiagent Systems (MAS): General},
  archive   = {C_IJCAI},
  author    = {Grzegorz Lisowski},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/832},
  pages     = {5859-5860},
  title     = {Equilibria in strategic nominee selection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable ML methods to optimize KPIs in real-world
manufacturing processes. <em>IJCAI</em>, 5857–5858. (<a
href="https://doi.org/10.24963/ijcai.2022/831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The goal of this work is to develop novel methods to solve the semiconductor fab scheduling problem. The problem can be modeled as a flexible job-shop with large instances and specific constraints related to special machine and job characteristics. To investigate the problem, we develop a tool to simulate small to large-scale instances of the problem. Using the simulator, we aim to develop new dispatching strategies using genetic programming and reinforcement learning. Keywords: Machine Learning (ML): General Planning, Routing, and Scheduling (PRS): General},
  archive   = {C_IJCAI},
  author    = {Benjamin Kovács},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/831},
  pages     = {5857-5858},
  title     = {Scalable ML methods to optimize KPIs in real-world manufacturing processes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Early diagnosis of lyme disease by recognizing erythema
migrans skin lesion from images utilizing deep learning techniques.
<em>IJCAI</em>, 5855–5856. (<a
href="https://doi.org/10.24963/ijcai.2022/830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lyme disease is one of the most common infectious vector-borne diseases in the world. We extensively studied the effectiveness of convolutional neural networks for identifying Lyme dis-ease from images. Our research contribution includes dealing with lack of data, multimodal learning incorporating expert opinion elicitation, and automation of skin hair mask generation. Keywords: Machine Learning (ML): General Computer Vision (CV): General},
  archive   = {C_IJCAI},
  author    = {Sk Imran Hossain},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/830},
  pages     = {5855-5856},
  title     = {Early diagnosis of lyme disease by recognizing erythema migrans skin lesion from images utilizing deep learning techniques},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for intrinsic evaluation of
word-embedding algorithms. <em>IJCAI</em>, 5853–5854. (<a
href="https://doi.org/10.24963/ijcai.2022/829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Word embeddings are widely used in copious Natural Language Processing tasks, including semantic analysis, information retrieval, dependency parsing, question answering, and machine translation. This extensive use implies that the evaluation of the performance of such representations is crucial for choosing the best model to perform those tasks. Though there are well-established procedures and benchmarks for intrinsic evaluation, as far as we know, a unified method of evaluation that can merge the results of those tasks to provide a comprehensive evaluation is missing. The main goal of this work is to create a pipeline to blend all major intrinsic evaluation tasks to compute such overall evaluation - the PCE - of word embeddings. Keywords: Speech &amp; Natural Language Processing (SNLP): General},
  archive   = {C_IJCAI},
  author    = {Anna Giabelli},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/829},
  pages     = {5853-5854},
  title     = {A unified framework for intrinsic evaluation of word-embedding algorithms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized autonomous organizations and multi-agent
systems for artificial intelligence applications and data analysis.
<em>IJCAI</em>, 5851–5852. (<a
href="https://doi.org/10.24963/ijcai.2022/828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Ph.D research project aims to explore the potential of the Decentralized Autonomous Organization paradigm in conjunction with classic software architectures for Artificial Intelligence applications. The intended goal is to investigate and formalize a possible integration path between Multi-agent System architectures and Decentralized Autonomous Organizations. Starting from the Foundation for Intelligent Physical Agents standards, we will extend basic primitives to integrate Multi-agent Systems on Distributed Ledger Technology networks. Possible deployment of services and applications in the Internet-of-Things, Artificial Intelligence and Distributed Machine Learning areas will be tested. Application of Data Analysis techniques on datasets built on such a framework will be also addressed. Keywords: Multiagent Systems (MAS): General},
  archive   = {C_IJCAI},
  author    = {Sante Dino Facchini},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/828},
  pages     = {5851-5852},
  title     = {Decentralized autonomous organizations and multi-agent systems for artificial intelligence applications and data analysis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decomposition methods for solving scheduling problem using
answer set programming. <em>IJCAI</em>, 5849–5850. (<a
href="https://doi.org/10.24963/ijcai.2022/827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This study proposes solving scheduling problems in industrial applications using the decomposition approach. The proposed model has been built using Multi-shot Answer Set Programming with Difference Logic. We tested our model with some benchmark instances and the results showed that our model is comparable to Constraint Programming to other heuristics in the literature. Keywords: Knowledge Representation and Reasoning (KRR): General},
  archive   = {C_IJCAI},
  author    = {Mohammed M. S. El-Kholany},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/827},
  pages     = {5849-5850},
  title     = {Decomposition methods for solving scheduling problem using answer set programming},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Building a visual semantics aware object hierarchy.
<em>IJCAI</em>, 5847–5848. (<a
href="https://doi.org/10.24963/ijcai.2022/826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The semantic gap is defined as the difference between the linguistic representations of the same concept, which usually leads to misunderstanding between individuals with different knowledge backgrounds. Since linguistically annotated images are extensively used for training machine learning models, semantic gap problem (SGP) also results in inevitable bias on image annotations and further leads to poor performance on current computer vision tasks. To address this problem, we propose a novel unsupervised method to build visual semantics aware object hierarchy, aiming to get a classification model by learning from pure-visual information and to dissipate the bias of linguistic representations caused by SGP. Our intuition in this paper comes from real-world knowledge representation where concepts are hierarchically organized, and each concept can be described by a set of features rather than a linguistic annotation, namely visual semantic. The evaluation consists of two parts, firstly we apply the constructed hierarchy on the object recognition task and then we compare our visual hierarchy and existing lexical hierarchies to show the validity of our method. The preliminary results reveal the efficiency and potential of our proposed method. Keywords: Computer Vision (CV): General},
  archive   = {C_IJCAI},
  author    = {Xiaolei Diao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/826},
  pages     = {5847-5848},
  title     = {Building a visual semantics aware object hierarchy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KRAKEN: A novel semantic-based approach for keyphrases
extraction. <em>IJCAI</em>, 5845–5846. (<a
href="https://doi.org/10.24963/ijcai.2022/825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose KRAKEN, a novel approach for the extraction of keyphrases from texts. To this aim, KRAKEN makes use of distributional semantics to identify, as completely as possible, representative portions of documents, i.e. keyphrases. In addition, we define novel metrics to assess a weighted significance to the keyphrases extracted from a document, identifying the most important ones by assessing their semantic similarity with the text of the document they belong to. Keywords: Speech &amp; Natural Language Processing (SNLP): General},
  archive   = {C_IJCAI},
  author    = {Simone D&#39;Amico},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/825},
  pages     = {5845-5846},
  title     = {KRAKEN: A novel semantic-based approach for keyphrases extraction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hybrid learning system for large-scale medical image
analysis. <em>IJCAI</em>, 5843–5844. (<a
href="https://doi.org/10.24963/ijcai.2022/824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adequate annotated data cannot always be satisfied in medical imaging applications. To address such a challenge, we would explore ways to reduce the quality and quantity of annotations requirements of the deep learning model by developing a hybrid learning system. We combined self-supervised learning, semi-supervised learning and weak-supervised learning to improve annotation utilization. Our primary research work on 2D medical image detection under poor annotation conditions has found that better regularization and adversarial loss can improve the robustness and performance with poor annotation conditions. Keywords: Computer Vision (CV): General},
  archive   = {C_IJCAI},
  author    = {Zehua Cheng and Lianlong Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/824},
  pages     = {5843-5844},
  title     = {Hybrid learning system for large-scale medical image analysis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic bandits with temporal structure. <em>IJCAI</em>,
5841–5842. (<a href="https://doi.org/10.24963/ijcai.2022/823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we study a dynamic multi-armed bandit (MAB) problem, where the expected reward of each arm evolves over time following an auto-regressive model. We present an algorithm whose per-round regret upper bound almost matches the regret lower bound, and numerically demonstrate its efficacy in adapting to the changing environment. Keywords: Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Qinyi Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/823},
  pages     = {5841-5842},
  title     = {Dynamic bandits with temporal structure},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Extending decision tree to handle multiple fairness
criteria. <em>IJCAI</em>, 5839–5840. (<a
href="https://doi.org/10.24963/ijcai.2022/822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The demand for machine learning systems that can provide both transparency and fairness is constantly growing. Since the concept of fairness depends on the context, studies in the literature have proposed various formalisation and mitigation strategies. In this work, we propose a novel, flexible, discrimination-aware classifier that allows the user to: (i) select and mitigate the desired fairness criterion from a set of available options; (ii) implement more than one fairness criterion; (iii) handle more than one sensitive attribute; and (iv) specify the desired level of fairness to meet specific business needs or regulatory requirements. Our approach is based on an optimised extension to the decision-tree classifier, and aims to provide transparent and fair rules to the final users. Keywords: Philosophy and Ethics of AI (PEAI): General Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Alessandro Castelnovo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/822},
  pages     = {5839-5840},
  title     = {Extending decision tree to handle multiple fairness criteria},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards new optimized artificial immune recognition systems
under the belief function theory. <em>IJCAI</em>, 5837–5838. (<a
href="https://doi.org/10.24963/ijcai.2022/821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artificial Immune Recognition Systems (AIRS) are powerful machine learning techniques, which aim to solve real world problems. A number of AIRS versions have produced successful prediction results. Nevertheless, these methods are unable to handle the uncertainty that could spread out at any stage of the AIRS approach. This issue is considered as a huge obstacle for having accurate and effective classification outputs. Therefore, our main objective is to handle this uncertainty using the belief function theory. We opt also in this article for an optimization over the classical AIRS approaches in order to enhance the classification performance. Keywords: Reasoning Under Uncertainty (RU): General Machine Learning (ML): General},
  archive   = {C_IJCAI},
  author    = {Rihab Abdelkhalek},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/821},
  pages     = {5837-5838},
  title     = {Towards new optimized artificial immune recognition systems under the belief function theory},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mechanism design powered by social interactions: A call to
arms. <em>IJCAI</em>, 5831–5835. (<a
href="https://doi.org/10.24963/ijcai.2022/820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mechanism design has traditionally assumed that the participants are fixed and independent. However, in reality, the participants are well-connected (e.g., via their social networks) and we can utilize their connections to power the design. One interesting trend is to incentivize the existing participants to use their connections to invite new participants. This helps to form larger games in auctions, coalitional games, matching etc., which is not achievable with the traditional solutions. The challenge is that the participants are competitors and they would not invite each other by default. Solving this is well-coupled with the existing challenges. For example, in auctions, solving it may require revenue monotonicity and false-name-proofness, which were proved impossible to achieve under certain sensible conditions. In matching, this cannot get along with standard optimality and stability. Hence, we believe there is an important theoretical value to discover and the study will stimulate many interesting applications, especially under decentralized systems with blockchain. Keywords: EC: Mechanism Design EC: Game Theory And Economic Paradigms EC: Multi-agent Systems},
  archive   = {C_IJCAI},
  author    = {Dengji Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/820},
  pages     = {5831-5835},
  title     = {Mechanism design powered by social interactions: A call to arms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards theoretically grounded evolutionary learning.
<em>IJCAI</em>, 5826–5830. (<a
href="https://doi.org/10.24963/ijcai.2022/819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning tasks are often formulated as complex optimization problems, where the objective function can be non-differentiable, non-continuous, non-unique, inaccurate, dynamic, and have many local optima, making conventional optimization algorithms fail. Evolutionary Algorithms (EAs), inspired by Darwin&#39;s theory of evolution, are general-purpose randomized heuristic optimization algorithms, mimicking variational reproduction and natural selection. EAs have yielded encouraging outcomes for solving complex optimization problems (e.g., neural architecture search) in machine learning. However, due to the heuristic nature of EAs, most outcomes to date have been empirical and lack theoretical support, encumbering their acceptance to the general machine learning community. In this paper, I will review the progress towards theoretically grounded evolutionary learning, from the aspects of analysis methodology, theoretical perspectives and learning algorithms. Due to space limit, I will include a few representative examples and highlight our contributions. I will also discuss some future challenges. Keywords: EC: Evolutionary Computation EC: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Chao Qian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/819},
  pages     = {5826-5830},
  title     = {Towards theoretically grounded evolutionary learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Controllable text generation for open-domain creativity and
fairness. <em>IJCAI</em>, 5821–5825. (<a
href="https://doi.org/10.24963/ijcai.2022/818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in large pre-trained language models have demonstrated strong results in generating natural languages and significantly improved performances for many natural language generation (NLG) applications such as machine translation and text summarization. However, when the generation tasks are more open-ended and the content is under-specified, existing techniques struggle to generate long-term coherent and creative content. Moreover, the models exhibit and even amplify social biases that are learned from the training corpora. This happens because the generation models are trained to capture the surface patterns (i.e. sequences of words), instead of capturing underlying semantics and discourse structures, as well as background knowledge including social norms. In this paper, I introduce our recent works on controllable text generation to enhance the creativity and fairness of language generation models. We explore hierarchical generation and constrained decoding, with applications to creative language generation including story, poetry, and figurative languages, and bias mitigation for generation models. Keywords: EC: Natural Language Generation},
  archive   = {C_IJCAI},
  author    = {Nanyun (Violet) Peng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/818},
  pages     = {5821-5825},
  title     = {Controllable text generation for open-domain creativity and fairness},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counting, sampling, and synthesis: The quest for
scalability. <em>IJCAI</em>, 5816–5820. (<a
href="https://doi.org/10.24963/ijcai.2022/817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The current generation of symbolic reasoning techniques excel at the qualitative tasks (i.e., when the answer is Yes or No); such techniques sufficed for traditional systems whose design sought to achieve deterministic behavior. In contrast, modern computing systems crucially rely on the statistical methods to account for the uncertainty in the environment, and to reason about behavior of these systems, there is need to look beyond qualitative symbolic reasoning techniques. We will discuss our work focused on the development of the next generation of automated reasoning techniques that can perform higher-order tasks such as quantitative measurement, sampling of representative behavior, and automated synthesis of systems. From a core technical perspective, our work builds on the SAT revolution, which refers to algorithmic advances in combinatorial solving techniques for the fundamental problem of satisfiability (SAT), i.e., whether it is possible to satisfy a given set of constraints. The SAT revolution offers the opportunity to develop scalable techniques for problems that lie beyond SAT from complexity perspective and, therefore, stand to benefit from the availability of powerful SAT engines. Our work seeks to enable a Beyond SAT revolution via design of scalable techniques for three fundamental problems that lie beyond SAT: constrained counting, constrained sampling, and automated synthesis. Keywords: EC: Knowledge Representation And Reasoning EC: Constraint Satisfaction And Optimization},
  archive   = {C_IJCAI},
  author    = {Kuldeep S. Meel},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/817},
  pages     = {5816-5820},
  title     = {Counting, sampling, and synthesis: The quest for scalability},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interaction and expressivity in collective decision-making.
<em>IJCAI</em>, 5813–5815. (<a
href="https://doi.org/10.24963/ijcai.2022/816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collective decisions among human and artificial agents can be enhanced by allowing for more interaction among decision-makers and by letting them express more information about their preferences. In this paper I present ongoing research on two settings: iterative voting, which repeatedly applies a voting rule until decision-makers converge to an outcome, and delegative voting on multiple issues. Keywords: EC: Agent-based And Multi-agent Systems EC: Knowledge Representation And Reasoning EC: Game Theory And Economic Paradigms},
  archive   = {C_IJCAI},
  author    = {Umberto Grandi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/816},
  pages     = {5813-5815},
  title     = {Interaction and expressivity in collective decision-making},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Integrating machine learning and optimization to boost
decision making. <em>IJCAI</em>, 5808–5812. (<a
href="https://doi.org/10.24963/ijcai.2022/815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a conceptual review of our recent advancements in the integration of machine learning and optimization. It focuses on describing new hybrid machine learning and optimization methods to predict fast, approximate, solutions to combinatorial problems and to enable structural logical inference. Keywords: EC: Machine Learning EC: Combinatorial Optimization},
  archive   = {C_IJCAI},
  author    = {Ferdinando Fioretto},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/815},
  pages     = {5808-5812},
  title     = {Integrating machine learning and optimization to boost decision making},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Analyzing and designing strategic environments in social
domains. <em>IJCAI</em>, 5803–5807. (<a
href="https://doi.org/10.24963/ijcai.2022/814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The cross-fertilization of AI and economic concepts has led to the advanced development of novel computational ideas. These ideas include models and approaches for analyzing multi-agent interaction (via game-theoretic models and solution concepts) in strategic environments and designing strategic environments (via mechanism design) to address principal decision-making problems involving multi-agent within various social contexts. In what follows, we will discuss our works on these two main topics. For analyzing multi-agent interaction, we will discuss several computational game-theoretic models to capture various agent characteristics and social (e.g., self-organization) domains. For designing strategic environments, we will discuss principal decision-making mechanism design settings in various social (e.g., facility location) contexts where the principal has to design mechanisms that elicit agent preferences over social outcomes and implement the principal&#39;s desirable social outcomes. Keywords: EC: Game Theory, EC: Mechanism Design EC: Strategic Agents EC: Multi-agent Systems},
  archive   = {C_IJCAI},
  author    = {Hau Chan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/814},
  pages     = {5803-5807},
  title     = {Analyzing and designing strategic environments in social domains},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Irrational, but adaptive and goal oriented: Humans
interacting with autonomous agents. <em>IJCAI</em>, 5798–5802. (<a
href="https://doi.org/10.24963/ijcai.2022/813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autonomous agents that interact with humans are becoming more and more prominent. Currently, such agents usually take one of the following approaches for considering human behavior. Some methods assume either a fully cooperative or a zero-sum setting; these assumptions entail that the human&#39;s goals are either identical to that of the agent, or their opposite. In both cases, the agent is not required to explicitly model the human’s goals and account for humans&#39; adaptation nature. Other methods first compose a model of human behavior based on observing human actions, and then optimize the agent’s actions based on this model. Such methods do not account for how the human will react to the agent&#39;s actions and thus, suffer an overestimation bias. Finally, other methods, such as model free reinforcement learning, merely learn which actions the agent should take at which states. While such methods can, theoretically, account for human adaptation nature, since they require extensive interaction with humans, they usually run in simulation. By not considering the human’s goals, autonomous agents act selfishly, lack generalization, require vast amounts of data, and cannot account for human’s strategic behavior. Therefore, we call for pursuing solution concepts for autonomous agents interacting with humans that consider the human’s goals and adaptive nature. Keywords: EC: Human-Agent Interaction.},
  archive   = {C_IJCAI},
  author    = {Amos Azaria},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/813},
  pages     = {5798-5802},
  title     = {Irrational, but adaptive and goal oriented: Humans interacting with autonomous agents},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving the effectiveness and efficiency of stochastic
neighbour embedding with isolation kernel (extended abstract).
<em>IJCAI</em>, 5792–5796. (<a
href="https://doi.org/10.24963/ijcai.2022/812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a new insight into improving the performance of Stochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of Gaussian kernel. We show that Isolation kernel addresses two deficiencies of t-SNE that employs Gaussian kernel, and the use of Isolation kernel enables t-SNE to deal with large-scale datasets in less runtime without trading off accuracy, unlike existing methods used in speeding up t-SNE. Keywords: Data Mining: Data Visualisation Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Ye Zhu and Kai Ming Ting},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/812},
  pages     = {5792-5796},
  title     = {Improving the effectiveness and efficiency of stochastic neighbour embedding with isolation kernel (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ethics and governance of artificial intelligence: A survey
of machine learning researchers (extended abstract). <em>IJCAI</em>,
5787–5791. (<a href="https://doi.org/10.24963/ijcai.2022/811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning (ML) and artificial intelligence (AI) researchers play an important role in the ethics and governance of AI, including through their work, advocacy, and choice of employment. Nevertheless, this influential group&#39;s attitudes are not well understood, undermining our ability to discern consensuses or disagreements between AI/ML researchers. To examine these researchers&#39; views, we conducted a survey of those who published in two top AI/ML conferences (N = 524). We compare these results with those from a 2016 survey of AI/ML researchers and a 2018 survey of the US public. We find that AI/ML researchers place high levels of trust in international organizations and scientific organizations to shape the development and use of AI in the public interest; moderate trust in most Western tech companies; and low trust in national militaries, Chinese tech companies, and Facebook. While the respondents were overwhelmingly opposed to AI/ML researchers working on lethal autonomous weapons, they are less opposed to researchers working on other military applications of AI, particularly logistics algorithms. A strong majority of respondents think that AI safety research should be prioritized more and a majority that ML institutions should conduct pre-publication review to assess potential harms. Being closer to the technology itself, AI/ML researchers are well placed to highlight new risks and develop technical solutions, so this novel data has broad relevance. The findings should help to improve how researchers, private sector executives, and policymakers think about regulations, governance frameworks, guiding principles, and national and international governance strategies for AI. Keywords: AI Ethics, Trust, Fairness: AI and Law, Governance, Regulation AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Baobao Zhang and Markus Anderljung and Lauren Kahn and Noemi Dreksler and Michael C. Horowitz and Allan Dafoe},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/811},
  pages     = {5787-5791},
  title     = {Ethics and governance of artificial intelligence: A survey of machine learning researchers (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Why bad coffee? Explaining BDI agent behaviour with valuings
(extended abstract). <em>IJCAI</em>, 5782–5786. (<a
href="https://doi.org/10.24963/ijcai.2022/810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important issue in deploying an autonomous system is how to enable human users and stakeholders to develop an appropriate level of trust in the system. It has been argued that a crucial mechanism to enable appropriate trust is the ability of a system to explain its behaviour. Obviously, such explanations need to be comprehensible to humans. Due to the perceived similarity in functioning between humans and autonomous systems, we argue that it makes sense to build on the results of extensive research in social sciences that explores how humans explain their behaviour. Using similar concepts for explanation is argued to help with comprehensibility, since the concepts are familiar. Following work in the social sciences, we propose the use of a folk-psychological model that utilises beliefs, desires, and ``valuings&#39;&#39;. We propose a formal framework for constructing explanations of the behaviour of an autonomous system, present an (implemented) algorithm for giving explanations, and present evaluation results. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability Agent-based and Multi-agent Systems: Agent Theories and Models AI Ethics, Trust, Fairness: Trustworthy AI AI Ethics, Trust, Fairness: Values AI Ethics, Trust, Fairness: General},
  archive   = {C_IJCAI},
  author    = {Michael Winikoff and Galina Sidorenko and Virginia Dignum and Frank Dignum},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/810},
  pages     = {5782-5786},
  title     = {Why bad coffee? explaining BDI agent behaviour with valuings (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring the occupational impact of AI: Tasks, cognitive
abilities and AI benchmarks (extended abstract)*. <em>IJCAI</em>,
5777–5781. (<a href="https://doi.org/10.24963/ijcai.2022/809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a framework for analysing the impact of AI on occupations. This framework maps 59 generic tasks from different occupational datasets to 14 cognitive abilities and these to a comprehensive list of 328 AI benchmarks used to evaluate research intensity in AI. The use of cognitive abilities as an intermediate layer allows for an identification of potential AI exposure for tasks for which AI applications have not been explicitly programmed. We provide insights into the abilities through which AI is most likely to affect jobs, and we show how some of the abilities where AI research is currently very intense are linked to tasks with comparatively limited labour input in the labour markets of advanced economies. Keywords: AI Ethics, Trust, Fairness: Societal Impact of AI AI Ethics, Trust, Fairness: Ethical, Legal and Societal Issues Machine Learning: Evaluation Multidisciplinary Topics and Applications: Economics},
  archive   = {C_IJCAI},
  author    = {Songül Tolan and Annarosa Pesole and Fernando Martínez-Plumed and Enrique Fernández-Macías and José Hernández-Orallo and Emilia Gómez},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/809},
  pages     = {5777-5781},
  title     = {Measuring the occupational impact of AI: Tasks, cognitive abilities and AI benchmarks (Extended abstract)*},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A theoretical perspective on hyperdimensional computing
(extended abstract). <em>IJCAI</em>, 5772–5776. (<a
href="https://doi.org/10.24963/ijcai.2022/808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hyperdimensional (HD) computing is a set of neurally inspired methods for computing on high-dimensional, low-precision, distributed representations of data. These representations can be combined with simple, neurally plausible algorithms to effect a variety of information processing tasks. HD computing has recently garnered significant interest from the computer hardware community as an energy-efficient, low-latency, and noise-robust tool for solving learning problems. We present a novel mathematical framework that unifies analysis of HD computing architectures, and provides general, non-asymptotic, sufficient conditions under which HD information processing techniques will succeed. Keywords: Machine Learning: Symbolic methods Knowledge Representation and Reasoning: Knowledge Representation Languages Knowledge Representation and Reasoning: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Anthony Thomas and Sanjoy Dasgupta and Tajana Rosing},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/808},
  pages     = {5772-5776},
  title     = {A theoretical perspective on hyperdimensional computing (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abstraction for non-ground answer set programs (extended
abstract). <em>IJCAI</em>, 5767–5771. (<a
href="https://doi.org/10.24963/ijcai.2022/807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstraction is a powerful technique that has not been considered much for nonmonotonic reasoning formalisms including Answer Set Programming (ASP), apart from related simplification methods. We introduce a notion for abstracting from the domain of an ASP program that shrinks the domain size and over-approximates the set of answer sets, as well as an abstraction-&amp;-refinement methodology that, starting from an initial abstraction, automatically yields an abstraction with an associated answer set matching an answer set of the original program if one exists. Experiments reveal the potential of the approach, by its ability to focus on the program parts that cause unsatisfiability and by achieving concrete abstract answer sets that merely reflect relevant details. Keywords: Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Zeynep G. Saribatur and Thomas Eiter and Peter Schüller},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/807},
  pages     = {5767-5771},
  title     = {Abstraction for non-ground answer set programs (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning realistic patterns from visually unrealistic
stimuli: Generalization and data anonymization (extended abstract).
<em>IJCAI</em>, 5762–5766. (<a
href="https://doi.org/10.24963/ijcai.2022/806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Good training data is a prerequisite to develop useful Machine Learning applications. However, in many domains existing data sets cannot be shared due to privacy regulations (e.g., from medical studies). This work investigates a simple yet unconventional approach for anonymized data synthesis to enable third parties to benefit from such anonymized data. We explore the feasibility of learning implicitly from visually unrealistic, task-relevant stimuli, which are synthesized by exciting the neurons of a trained deep neural network. As such, neuronal excitation can be used to generate synthetic stimuli. The stimuli data is used to train new classification models. Furthermore, we extend this framework to inhibit representations that are associated with specific individuals. Extensive comparative empirical investigation shows that different algorithms trained on the stimuli are able to generalize successfully on the same task as the original model. Keywords: Computer Vision: Representation Learning Computer Vision: Neural generative models, auto encoders, GANs Natural Language Processing: Knowledge Extraction Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {Konstantinos Nikolaidis and Stein Kristiansen and Thomas Plagemann and Vera Goebel and Knut Liestøl and Mohan Kankanhalli and Gunn-Marit Traaen and Britt Øverland and Harriet Akre and Lars Aakeroy and Sigurd Steinshamn},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/806},
  pages     = {5762-5766},
  title     = {Learning realistic patterns from visually unrealistic stimuli: Generalization and data anonymization (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intelligence in strategic games (extended abstract).
<em>IJCAI</em>, 5757–5761. (<a
href="https://doi.org/10.24963/ijcai.2022/805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {If an agent, or a coalition of agents, has a strategy, knows that she has a strategy, and knows what the strategy is, then she has a know-how strategy. Several modal logics of coalition power for know-how strategies have been studied before. The contribution of the article is three-fold. First, it proposes a new class of know-how strategies that depend on the intelligence information about the opponents&#39; actions. Second, it shows that the coalition power modality for the proposed new class of strategies cannot be expressed through the standard know-how modality. Third, it gives a sound and complete logical system that describes the interplay between the coalition power modality with intelligence and the distributed knowledge modality in games with imperfect information. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Pavel Naumov and Yuan Yuan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/805},
  pages     = {5757-5761},
  title     = {Intelligence in strategic games (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sunny-as2: Enhancing SUNNY for algorithm selection (extended
abstract). <em>IJCAI</em>, 5752–5756. (<a
href="https://doi.org/10.24963/ijcai.2022/804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {SUNNY is a k-nearest neighbors based Algorithm Selection (AS) approach that schedules and runs a number of solvers for a given unforeseen problem. In this work we present sunny-as2, an enhancement of SUNNY for generic AS scenarios that advances the original approach with wrapper-based feature selection, neighborhood-size configuration and a greedy approach to speed-up the training phase. Empirical evidence shows that sunny-as2 is competitive w.r.t. state-of-the-art AS approaches. Keywords: Machine Learning: Optimisation Constraint Satisfaction and Optimization: Constraints and Machine Learning Machine Learning: Applications Machine Learning: Classification Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Tong Liu and Roberto Amadini and Maurizio Gabbrielli and Jacopo Mauro},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/804},
  pages     = {5752-5756},
  title     = {Sunny-as2: Enhancing SUNNY for algorithm selection (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local and global explanations of agent behavior: Integrating
strategy summaries with saliency maps (extended abstract).
<em>IJCAI</em>, 5747–5751. (<a
href="https://doi.org/10.24963/ijcai.2022/803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With advances in reinforcement learning (RL), agents are now being developed in high-stakes application domains such as healthcare and transportation. Explaining the behavior of these agents is challenging, as they act in large state spaces, and their decision-making can be affected by delayed rewards. In this paper, we explore a combination of explanations that attempt to convey the global behavior of the agent and local explanations which provide information regarding the agent&#39;s decision-making in a particular state. Specifically, we augment strategy summaries that demonstrate the agent&#39;s actions in a range of states with saliency maps highlighting the information it attends to. Our user study shows that intelligently choosing what states to include in the summary (global information) results in an improved analysis of the agents. We find mixed results with respect to augmenting summaries with saliency maps (local information). Keywords: Machine Learning: Explainable/Interpretable Machine Learning AI Ethics, Trust, Fairness: Explainability and Interpretability Machine Learning: Deep Reinforcement Learning AI Ethics, Trust, Fairness: Trustworthy AI Computer Vision: Interpretability and Transparency},
  archive   = {C_IJCAI},
  author    = {Tobias Huber and Katharina Weitz and Elisabeth André and Ofra Amir},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/803},
  pages     = {5747-5751},
  title     = {Local and global explanations of agent behavior: Integrating strategy summaries with saliency maps (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dimensional inconsistency measures and postulates in
spatio-temporal databases (extended abstract). <em>IJCAI</em>,
5742–5746. (<a href="https://doi.org/10.24963/ijcai.2022/802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We define and investigate new inconsistency measures that are particularly suitable for dealing with inconsistent spatio-temporal information, as they explicitly take into account the spatial and temporal dimensions, as well as the dimension concerning the identifiers of the monitored objects. Specifically, we first define natural measures that look at individual dimensions (time, space, and objects), and then propose measures based on the notion of a repair. We then analyze their behavior w.r.t. common postulates defined for classical propositional knowledge bases, and find that the latter are not suitable for spatio-temporal databases, in that the proposed inconsistency measures do not often satisfy them. In light of this, we argue that also postulates should explicitly take into account the spatial, temporal, and object dimensions, and thus define ``dimension-aware&#39;&#39; counterparts of common postulates, which are indeed often satisfied by the new inconsistency measures. Finally, we study the complexity of the proposed inconsistency measures. Keywords: Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning},
  archive   = {C_IJCAI},
  author    = {John Grant and Maria Vanina Martinez and Cristian Molinaro and Francesco Parisi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/802},
  pages     = {5742-5746},
  title     = {Dimensional inconsistency measures and postulates in spatio-temporal databases (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Experimental comparison and survey of twelve time series
anomaly detection algorithms (extended abstract). <em>IJCAI</em>,
5737–5741. (<a href="https://doi.org/10.24963/ijcai.2022/801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existence of an anomaly detection method that is optimal for all domains is a myth. Thus, there exists a plethora of anomaly detection methods which increases every year for a wide variety of domains. But a strength can also be a weakness; given this massive library of methods, how can one select the best method for their application? Current literature is focused on creating new anomaly detection methods or large frameworks for experimenting with multiple methods at the same time. However, and especially as the literature continues to expand, an extensive evaluation of every anomaly detection method is simply not feasible. To reduce this evaluation burden, we present guidelines to intelligently choose the optimal anomaly detection methods based on the characteristics the time series displays such as seasonality, trend, level change concept drift, and missing time steps. We provide a comprehensive experimental validation and survey of twelve anomaly detection methods over different time series characteristics to form guidelines based on several metrics: the AUC (Area Under the Curve), windowed F-score, and Numenta Anomaly Benchmark (NAB) scoring model. Applying our methodologies can save time and effort by surfacing the most promising anomaly detection methods instead of experimenting extensively with a rapidly expanding library of anomaly detection methods, especially in an online setting. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Applications Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Cynthia Freeman and Jonathan Merriman and Ian Beaver and Abdullah Mueen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/801},
  pages     = {5737-5741},
  title     = {Experimental comparison and survey of twelve time series anomaly detection algorithms (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abstraction in data-sparse task transfer (extended
abstract). <em>IJCAI</em>, 5732–5736. (<a
href="https://doi.org/10.24963/ijcai.2022/800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When a robot adapts a learned task for a novel environment, any changes to objects in the novel environment have an unknown effect on its task execution. For example, replacing an object in a pick-and-place task affects where the robot should target its actions, but does not necessarily affect the underlying action model. In contrast, replacing a tool that the robot will use to complete a task will effectively alter its end-effector pose with respect to the robot&#39;s base coordinate system, and thus the robot&#39;s motion must be replanned accordingly. These examples highlight the relationship among (i) differences between the source and target environments, (ii) the level of abstraction at which a robot&#39;s task model should be represented to enable transfer to the target environment, and (iii) the information needed to ground the abstracted task representation in the target environment. In this abstract, summarizing our full article [Fitzgerald et al., 2021], we present our taxonomy of transfer problems based on this relationship. We also describe a knowledge representation called the Tiered Task Abstraction (TTA) and demonstrate its applicability to a variety of transfer problems in the taxonomy. Our experimental results indicate a trade-off between the generality and data requirements of a task representation, and reinforce the need for multiple transfer methods that operate at different levels of abstraction. Keywords: Robotics: Cognitive Robotics Robotics: Learning in Robotics Knowledge Representation and Reasoning: General},
  archive   = {C_IJCAI},
  author    = {Tesca Fitzgerald and Ashok Goel and Andrea Thomaz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/800},
  pages     = {5732-5736},
  title     = {Abstraction in data-sparse task transfer (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Making sense of raw input (extended abstract).
<em>IJCAI</em>, 5727–5731. (<a
href="https://doi.org/10.24963/ijcai.2022/799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How should a machine intelligence perform unsupervised structure discovery over streams of sensory input? One approach to this problem is to cast it as an apperception task. Here, the task is to construct an explicit interpretable theory that both explains the sensory sequence and also satisfies a set of unity conditions, designed to ensure that the constituents of the theory are connected in a relational structure. However, the original formulation of the apperception task had one fundamental limitation: it assumed the raw sensory input had already been parsed using a set of discrete categories, so that all the system had to do was receive this already-digested symbolic input, and make sense of it. But what if we don&#39;t have access to pre-parsed input? What if our sensory sequence is raw unprocessed information? The central contribution of this paper is a neuro-symbolic framework for distilling interpretable theories out of streams of raw, unprocessed sensory experience. First, we extend the definition of the apperception task to include ambiguous (but still symbolic) input: sequences of sets of disjunctions. Next, we use a neural network to map raw sensory input to disjunctive input. Our binary neural network is encoded as a logic program, so the weights of the network and the rules of the theory can be solved jointly as a single SAT problem. This way, we are able to jointly learn how to perceive (mapping raw sensory information to concepts) and apperceive (combining concepts into declarative rules). Keywords: Machine Learning: Explainable/Interpretable Machine Learning Knowledge Representation and Reasoning: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Richard Evans and Matko Bošnjak and Lars Buesing and Kevin Ellis and David Pfau and Pushmeet Kohli and Marek Sergot},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/799},
  pages     = {5727-5731},
  title     = {Making sense of raw input (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Situation calculus for controller synthesis in manufacturing
systems with first-order state representation (extended abstract).
<em>IJCAI</em>, 5722–5726. (<a
href="https://doi.org/10.24963/ijcai.2022/798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Manufacturing is transitioning from a mass production model to a service model in which facilities `bid&#39; for previously unseen products. To decide whether to bid for a previously unseen product, a facility must be able to synthesize, on the fly, a process plan controller that delegates abstract manufacturing tasks in a supplied process recipe to the available manufacturing resources. First-order representations of the state are commonly considered in reasoning about action in AI. Here we show that we can leverage the wide literature on the Situation Calculus automatically synthesize such controllers. We identify two important decidable cases---finite domains and bounded action theories---for which we provide practical synthesis techniques. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Automated Reasoning and Theorem Proving},
  archive   = {C_IJCAI},
  author    = {Giuseppe De Giacomo and Paolo Felli and Brian Logan and Fabio Patrizi and Sebastian Sardiña},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/798},
  pages     = {5722-5726},
  title     = {Situation calculus for controller synthesis in manufacturing systems with first-order state representation (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On quantifying literals in boolean logic and its
applications to explainable AI (extended abstract). <em>IJCAI</em>,
5718–5721. (<a href="https://doi.org/10.24963/ijcai.2022/797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantified Boolean logic results from adding operators to Boolean logic for existentially and universally quantifying variables. This extends the reach of Boolean logic by enabling a variety of applications that have been explored over the decades. The existential quantification of literals (variable states) and its applications have also been studied in the literature. We complement this by studying universal literal quantification and its applications, particularly to explainable AI. We also provide a novel semantics for quantification and discuss the interplay between variable/literal and existential/universal quantification. We further identify classes of Boolean formulas and circuits that allow efficient quantification. Literal quantification is more fine-grained than variable quantification, which leads to a refinement of quantified Boolean logic with literal quantification as its primitive. Keywords: Knowledge Representation and Reasoning: Automated Reasoning and Theorem Proving AI Ethics, Trust, Fairness: Explainability and Interpretability Knowledge Representation and Reasoning: Knowledge Compilation and Tractable Languages},
  archive   = {C_IJCAI},
  author    = {Adnan Darwiche and Pierre Marquis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/797},
  pages     = {5718-5721},
  title     = {On quantifying literals in boolean logic and its applications to explainable AI (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Overlapping communities and roles in networks with node
attributes: Probabilistic graphical modeling, bayesian formulation and
variational inference (extended abstract). <em>IJCAI</em>, 5713–5717.
(<a href="https://doi.org/10.24963/ijcai.2022/796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the seamless integration of community discovery and behavioral role analysis, in the domain of networks with node attributes. In particular, we focus on unifying the two tasks, by explicitly harnessing node attributes and behavioral role patterns in a principled manner. To this end, we propose two Bayesian probabilistic generative models of networks, whose novelty consists in the interrelationship of overlapping communities, roles, their behavioral patterns and node attributes. The devised models allow for a variety of exploratory, descriptive and predictive tasks. These are carried out through mean-field variational inference, which is in turn mathematically derived and implemented into a coordinate-ascent algorithm. A wide spectrum of experiments is designed, to validate the devised models against three classes of state-of-the-art competitors using various real-world benchmark data sets from different social networking services. Keywords: Machine Learning: Probabilistic Machine Learning Data Mining: Mining Graphs Data Mining: General Machine Learning: General},
  archive   = {C_IJCAI},
  author    = {Gianni Costa and Riccardo Ortale},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/796},
  pages     = {5713-5717},
  title     = {Overlapping communities and roles in networks with node attributes: Probabilistic graphical modeling, bayesian formulation and variational inference (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bayesian auctions with efficient queries (extended
abstract). <em>IJCAI</em>, 5708–5712. (<a
href="https://doi.org/10.24963/ijcai.2022/795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Designing dominant-strategy incentive compatible (DSIC) mechanisms for a seller to generate (approximately) optimal revenue by selling items to players is a fundamental problem in Bayesian mechanism design. However, most existing studies assume that the seller knows the entire distribution from which the players’ values are drawn. Unfortunately, this assumption may not hold in reality: for example, when the distributions have exponentially large supports or do not have succinct representations. In this work we consider, for the first time, the query complexityof Bayesian mechanisms. The seller only has limited oracle accesses to the players’ distributions, via quantile queriesand value queries. For single-item auctions, we design mechanisms with logarithmicnumber of value or quantile queries which achieve almost optimal revenue. We then prove logarithmic lower-bounds, i.e., logarithmic number of queries are necessary for any constant approximation DSIC mechanisms, even when randomized and adaptive queries are allowed. Thus our mechanisms are almost optimal regarding query complexity. Our lower-bounds can be extended to multi-item auctions with monotone subadditive valuations, and we complement this part with constant approximation mechanisms for unit-demand or additive valuation functions. Our results are robust even if the answers to the queries contain noises. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Jing Chen and Bo Li and Yingkai Li and Pinyan Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/795},
  pages     = {5708-5712},
  title     = {Bayesian auctions with efficient queries (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the first-order rewritability of ontology-mediated
queries in linear temporal logic (extended abstract). <em>IJCAI</em>,
5703–5707. (<a href="https://doi.org/10.24963/ijcai.2022/794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We argue that linear temporal logic LTL in tandem with monadic first-order logic can be used as a ba- sic language for ontology-based access to tempo- ral data and obtain a classification of the resulting ontology-mediated queries according to the type of standard first-order queries they can be rewritten to. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies Knowledge Representation and Reasoning: Automated Reasoning and Theorem Proving Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Knowledge Representation Languages},
  archive   = {C_IJCAI},
  author    = {Alessandro Artale and Roman Kontchakov and Alisa Kovtunova and Vladislav Ryzhikov and Frank Wolter and Michael Zakharyaschev},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/794},
  pages     = {5703-5707},
  title     = {On the first-order rewritability of ontology-mediated queries in linear temporal logic (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on neural open information extraction: Current
status and future directions. <em>IJCAI</em>, 5694–5701. (<a
href="https://doi.org/10.24963/ijcai.2022/793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this survey, we provide an extensive overview of the state-of-the-art neural OpenIE models, their key design decisions, strengths and weakness. Then, we discuss limitations of current solutions and the open issues in OpenIE problem itself. Finally we list recent trends that could help expand its scope and applicability, setting up promising directions for future research in OpenIE. To our best knowledge, this paper is the first review on neural OpenIE. Keywords: Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Shaowen Zhou and Bowen Yu and Aixin Sun and Cheng Long and Jingyang Li and Jian Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/793},
  pages     = {5694-5701},
  title     = {A survey on neural open information extraction: Current status and future directions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards verifiable federated learning. <em>IJCAI</em>,
5686–5693. (<a href="https://doi.org/10.24963/ijcai.2022/792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is an emerging paradigm of collaborative machine learning that preserves user privacy while building powerful models. Nevertheless, due to the nature of open participation by self-interested entities, it needs to guard against potential misbehaviours by legitimate FL participants. FL verification techniques are promising solutions for this problem. They have been shown to effectively enhance the reliability of FL networks and build trust among participants. Verifiable FL has become an emerging topic of research that has attracted significant interest from the academia and the industry alike. Currently, there is no comprehensive survey on the field of verifiable federated learning, which is interdisciplinary in nature and can be challenging for researchers to enter into. In this paper, we bridge this gap by reviewing works focusing on verifiable FL. We propose a novel taxonomy for verifiable FL covering both centralised and decentralised settings, summarise the commonly adopted performance evaluation approaches, and discuss promising directions towards a versatile verifiable FL framework. Keywords: Survey Track: Machine Learning Survey Track: AI Ethics, Trust, Fairness Survey Track: Multidisciplinary Topics and Applications Survey Track: Humans and AI},
  archive   = {C_IJCAI},
  author    = {Yanci Zhang and Han Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/792},
  pages     = {5686-5693},
  title     = {Towards verifiable federated learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on gradient inversion: Attacks, defenses and future
directions. <em>IJCAI</em>, 5678–5685. (<a
href="https://doi.org/10.24963/ijcai.2022/791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have shown that the training samples can be recovered from gradients, which are called Gradient Inversion (GradInv) attacks. However, there remains a lack of extensive surveys covering recent advances and thorough analysis of this issue. In this paper, we present a comprehensive survey on GradInv, aiming to summarize the cutting-edge research and broaden the horizons for different domains. Firstly, we propose a taxonomy of GradInv attacks by characterizing existing attacks into two paradigms: iteration- and recursion-based attacks. In particular, we dig out some critical ingredients from the iteration-based attacks, including data initialization, model training and gradient matching. Second, we summarize emerging defense strategies against GradInv attacks. We find these approaches focus on three perspectives covering data obscuration, model improvement and gradient protection. Finally, we discuss some promising directions and open problems for further research. Keywords: Survey Track: AI Ethics, Trust, Fairness Survey Track: Uncertainty in AI Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Rui Zhang and Song Guo and Junxiao Wang and Xin Xie and Dacheng Tao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/791},
  pages     = {5678-5685},
  title     = {A survey on gradient inversion: Attacks, defenses and future directions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances and new frontiers in spiking neural
networks. <em>IJCAI</em>, 5670–5677. (<a
href="https://doi.org/10.24963/ijcai.2022/790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, spiking neural networks (SNNs) have received extensive attention in brain-inspired intelligence due to their rich spatially-temporal dynamics, various encoding methods, and event-driven characteristics that naturally fit the neuromorphic hardware. With the development of SNNs, brain-inspired intelligence, an emerging research field inspired by brain science achievements and aiming at artificial general intelligence, is becoming hot. This paper reviews recent advances and discusses new frontiers in SNNs from five major research topics, including essential elements (i.e., spiking neuron models, encoding methods, and topology structures), neuromorphic datasets, optimization algorithms, software, and hardware frameworks. We hope our survey can help researchers understand SNNs better and inspire new works to advance this field. Keywords: Survey Track: -},
  archive   = {C_IJCAI},
  author    = {Duzhen Zhang and Shuncheng Jia and Qingyu Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/790},
  pages     = {5670-5677},
  title     = {Recent advances and new frontiers in spiking neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Few-shot learning on graphs. <em>IJCAI</em>, 5662–5669. (<a
href="https://doi.org/10.24963/ijcai.2022/789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph representation learning has attracted tremendous attention due to its remarkable performance in many real-world applications. However, prevailing supervised graph representation learning models for specific tasks often suffer from label sparsity issue as data labeling is always time and resource consuming. In light of this, few-shot learning on graphs (FSLG), which combines the strengths of graph representation learning and few-shot learning together, has been proposed to tackle the performance degradation in face of limited annotated data challenge. There have been many studies working on FSLG recently. In this paper, we comprehensively survey these work in the form of a series of methods and applications. Specifically, we first introduce FSLG challenges and bases, then categorize and summarize existing work of FSLG in terms of three major graph mining tasks at different granularity levels, i.e., node, edge, and graph. Finally, we share our thoughts on some future research directions of FSLG. The authors of this survey have contributed significantly to the AI literature on FSLG over the last few years. Keywords: Survey Track: Machine Learning Survey Track: Data Mining},
  archive   = {C_IJCAI},
  author    = {Chuxu Zhang and Kaize Ding and Jundong Li and Xiangliang Zhang and Yanfang Ye and Nitesh V. Chawla and Huan Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/789},
  pages     = {5662-5669},
  title     = {Few-shot learning on graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recent advances in concept drift adaptation methods for deep
learning. <em>IJCAI</em>, 5654–5661. (<a
href="https://doi.org/10.24963/ijcai.2022/788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the ``Big Data&#39;&#39; age, the amount and distribution of data have increased wildly and changed over time in various time-series-based tasks, e.g weather prediction, network intrusion detection. However, deep learning models may become outdated facing variable input data distribution, which is called concept drift. To address this problem, large number of samples are usually required to update deep learning models, which is impractical in many realistic applications. This challenge drives researchers to explore the effective ways to adapt deep learning models to concept drift. In this paper, we first mathematically describe the categories of concept drift including abrupt drift, gradual drift, recurrent drift, incremental drift. We then divide existing studies into two categories (i.e., model parameter updating and model structure updating), and analyze the pros and cons of representative methods in each category. Finally, we evaluate the performance of these methods, and point out the future directions of concept drift adaptation for deep learning. Keywords: Survey Track: Machine Learning Survey Track: Data Mining Survey Track: -},
  archive   = {C_IJCAI},
  author    = {Liheng Yuan and Heng Li and Beihao Xia and Cuiying Gao and Mingyue Liu and Wei Yuan and Xinge You},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/788},
  pages     = {5654-5661},
  title     = {Recent advances in concept drift adaptation methods for deep learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the opportunity of causal learning in recommendation
systems: Foundation, estimation, prediction and challenges.
<em>IJCAI</em>, 5646–5653. (<a
href="https://doi.org/10.24963/ijcai.2022/787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, recommender system (RS) based on causal inference has gained much attention in the industrial community, as well as the states of the art performance in many prediction and debiasing tasks. Nevertheless, a unified causal analysis framework has not been established yet. Many causal-based prediction and debiasing studies rarely discuss the causal interpretation of various biases and the rationality of the corresponding causal assumptions. In this paper, we first provide a formal causal analysis framework to survey and unify the existing causal-inspired recommendation methods, which can accommodate different scenarios in RS. Then we propose a new taxonomy and give formal causal definitions of various biases in RS from the perspective of violating the assumptions adopted in causal analysis. Finally, we formalize many debiasing and prediction tasks in RS, and summarize the statistical and machine learning-based causal estimation methods, expecting to provide new research opportunities and perspectives to the causal RS community. Keywords: Survey Track: Data Mining Survey Track: Machine Learning Survey Track: Multidisciplinary Topics and Applications Survey Track: Constraint Satisfaction and Optimization},
  archive   = {C_IJCAI},
  author    = {Peng Wu and Haoxuan Li and Yuhao Deng and Wenjie Hu and Quanyu Dai and Zhenhua Dong and Jie Sun and Rui Zhang and Xiao-Hua Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/787},
  pages     = {5646-5653},
  title     = {On the opportunity of causal learning in recommendation systems: Foundation, estimation, prediction and challenges},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Recent advances on neural network pruning at
initialization. <em>IJCAI</em>, 5638–5645. (<a
href="https://doi.org/10.24963/ijcai.2022/786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network pruning typically removes connections or neurons from a pretrained converged model; while a new pruning paradigm, pruning at initialization (PaI), attempts to prune a randomly initialized network. This paper offers the first survey concentrated on this emerging pruning fashion. We first introduce a generic formulation of neural network pruning, followed by the major classic pruning topics. Then, as the main body of this paper, a thorough and structured literature review of PaI methods is presented, consisting of two major tracks (sparse training and sparse selection). Finally, we summarize the surge of PaI compared to PaT and discuss the open problems. Apart from the dedicated literature review, this paper also offers a code base for easy sanity-checking and benchmarking of different PaI methods. Keywords: Survey Track: Computer Vision Survey Track: Machine Learning Survey Track: Multidisciplinary Topics and Applications},
  archive   = {C_IJCAI},
  author    = {Huan Wang and Can Qin and Yue Bai and Yulun Zhang and Yun Fu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/786},
  pages     = {5638-5645},
  title     = {Recent advances on neural network pruning at initialization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vision-based intention and trajectory prediction in
autonomous vehicles: A survey. <em>IJCAI</em>, 5630–5637. (<a
href="https://doi.org/10.24963/ijcai.2022/785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This survey targets intention and trajectory prediction in Autonomous Vehicles (AV), as AV companies compete to create dedicated prediction pipelines to avoid collisions. The survey starts with a formal definition of the prediction problem and highlights its challenges, to then critically compare the models proposed in the last 2-3 years in terms of how they overcome these challenges. Further, it lists the latest methodological and technical trends in the field and comments on the efficacy of different machine learning blocks in modelling various aspects of the prediction problem. It also summarises the popular datasets and metrics used to evaluate prediction models, before concluding with the possible research gaps and future directions. Keywords: Survey Track: - Survey Track: Machine Learning Survey Track: Robotics},
  archive   = {C_IJCAI},
  author    = {Izzeddin Teeti and Salman Khan and Ajmal Shahbaz and Andrew Bradley and Fabio Cuzzolin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/785},
  pages     = {5630-5637},
  title     = {Vision-based intention and trajectory prediction in autonomous vehicles: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of risk-aware multi-armed bandits. <em>IJCAI</em>,
5623–5629. (<a href="https://doi.org/10.24963/ijcai.2022/784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In several applications such as clinical trials and financial portfolio optimization, the expected value (or the average reward) does not satisfactorily capture the merits of a drug or a portfolio. In such applications, risk plays a crucial role, and a risk-aware performance measure is preferable, so as to capture losses in the case of adverse events. This survey aims to consolidate and summarise the existing research on risk measures, specifically in the context of multi-armed bandits. We review various risk measures of interest, and comment on their properties. Next, we review existing concentration inequalities for various risk measures. Then, we proceed to defining risk-aware bandit problems, We consider algorithms for the regret minimization setting, where the exploration-exploitation tradeoff manifests, as well as the best arm identification setting, which is a pure exploration problem—both in the context of risk-sensitive measures. We conclude by commenting on persisting challenges and fertile areas for future research. Keywords: Survey Track: - Survey Track: Machine Learning Survey Track: Constraint Satisfaction and Optimization Survey Track: Uncertainty in AI},
  archive   = {C_IJCAI},
  author    = {Vincent Y. F. Tan and Prashanth L.A. and Krishna Jagannathan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/784},
  pages     = {5623-5629},
  title     = {A survey of risk-aware multi-armed bandits},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Problem compilation for multi-agent path finding: A survey.
<em>IJCAI</em>, 5615–5622. (<a
href="https://doi.org/10.24963/ijcai.2022/783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-agent path finding (MAPF) attracts considerable attention in artificial intelligence community. The task in the standard MAPF is to find discrete paths through which agents can navigate from their starting positions to individual goal positions. The combination of two additional requirements makes the problem computationally challenging: agents must not collide with each other and the paths must be optimal with respect to some objective. Two major approaches to optimal MAPF solving include dedicated search-based methods, and compilation-based methods that reduce a MAPF instance to an instance in a different formalism, for which an efficient solver exists. In this survey, we summarize major compilation-based solvers for MAPF using CSP, SAT, and MILP formalisms. We explain the core ideas of the solvers in a simplified and unified way while preserving the merit making them more accessible for a wider audience. Keywords: Survey Track: Search Survey Track: Planning and Scheduling Survey Track: Robotics Survey Track: Agent-based and Multi-agent Systems},
  archive   = {C_IJCAI},
  author    = {Pavel Surynek},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/783},
  pages     = {5615-5622},
  title     = {Problem compilation for multi-agent path finding: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data valuation in machine learning: &amp;Quot; ingredients"
, strategies, and open challenges. <em>IJCAI</em>, 5607–5614. (<a
href="https://doi.org/10.24963/ijcai.2022/782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data valuation in machine learning (ML) is an emerging research area that studies the worth of data in ML. Data valuation is used in collaborative ML to determine a fair compensation for every data owner and in interpretable ML to identify the most responsible, noisy, or misleading training examples. This paper presents a comprehensive technical survey that provides a new formal study of data valuation in ML through its “ingredients” and the corresponding properties, grounds the discussion of common desiderata satisfied by existing data valuation strategies on our proposed ingredients, and identifies open research challenges for designing new ingredients, data valuation strategies, and cost reduction techniques. Keywords: Survey Track: Machine Learning Survey Track: AI Ethics, Trust, Fairness Survey Track: Multidisciplinary Topics and Applications},
  archive   = {C_IJCAI},
  author    = {Rachael Hwee Ling Sim and Xinyi Xu and Bryan Kian Hsiang Low},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/782},
  pages     = {5607-5614},
  title     = {Data valuation in machine learning: &amp;quot; ingredients&amp;quot; , strategies, and open challenges},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting and understanding harmful memes: A survey.
<em>IJCAI</em>, 5597–5606. (<a
href="https://doi.org/10.24963/ijcai.2022/781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often combines multiple modalities, as in the case of memes. With this in mind, here we offer a comprehensive survey with a focus on harmful memes. Based on a systematic analysis of recent literature, we first propose a new typology of harmful memes, and then we highlight and summarize the relevant state of the art. One interesting finding is that many types of harmful memes are not really studied, e.g., such featuring self-harm and extremism, partly due to the lack of suitable datasets. We further find that existing datasets mostly capture multi-class scenarios, which are not inclusive of the affective spectrum that memes can represent. Another observation is that memes can propagate globally through repackaging in different languages and that they can also be multilingual, blending different cultures. We conclude by highlighting several challenges related to multimodal semiotics, technological constraints, and non-trivial social engagement, and we present several open-ended aspects such as delineating online harm and empirically examining related frameworks and assistive interventions, which we believe will motivate and drive future research. Keywords: Survey Track: - Survey Track: Natural Language Processing Survey Track: Multidisciplinary Topics and Applications Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Shivam Sharma and Firoj Alam and Md. Shad Akhtar and Dimitar Dimitrov and Giovanni Da San Martino and Hamed Firooz and Alon Halevy and Fabrizio Silvestri and Preslav Nakov and Tanmoy Chakraborty},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/781},
  pages     = {5597-5606},
  title     = {Detecting and understanding harmful memes: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abstraction for deep reinforcement learning. <em>IJCAI</em>,
5588–5596. (<a href="https://doi.org/10.24963/ijcai.2022/780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We characterise the problem of abstraction in the context of deep reinforcement learning. Various well established approaches to analogical reasoning and associative memory might be brought to bear on this issue, but they present difficulties because of the need for end-to-end differentiability. We review developments in AI and machine learning that could facilitate their adoption. Keywords: Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Murray Shanahan and Melanie Mitchell},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/780},
  pages     = {5588-5596},
  title     = {Abstraction for deep reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of machine narrative reading comprehension
assessments. <em>IJCAI</em>, 5580–5587. (<a
href="https://doi.org/10.24963/ijcai.2022/779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the body of research on machine narrative comprehension grows, there is a critical need for consideration of performance assessment strategies as well as the depth and scope of different benchmark tasks. Based on narrative theories, reading comprehension theories, as well as existing machine narrative reading comprehension tasks and datasets, we propose a typology that captures the main similarities and differences among assessment tasks; and discuss the implications of our typology for new task design and the challenges of narrative reading comprehension. Keywords: Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Yisi Sang and Xiangyang Mou and Jing Li and Jeffrey Stanton and Mo Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/779},
  pages     = {5580-5587},
  title     = {A survey of machine narrative reading comprehension assessments},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The shapley value in machine learning. <em>IJCAI</em>,
5572–5579. (<a href="https://doi.org/10.24963/ijcai.2022/778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the last few years, the Shapley value, a solution concept from cooperative game theory, has found numerous applications in machine learning. In this paper, we first discuss fundamental concepts of cooperative game theory and axiomatic properties of the Shapley value. Then we give an overview of the most important applications of the Shapley value in machine learning: feature selection, explainability, multi-agent reinforcement learning, ensemble pruning, and data valuation. We examine the most crucial limitations of the Shapley value and point out directions for future research. Keywords: Survey Track: - Survey Track: Data Mining Survey Track: Machine Learning Survey Track: Constraint Satisfaction and Optimization},
  archive   = {C_IJCAI},
  author    = {Benedek Rozemberczki and Lauren Watson and Péter Bayer and Hao-Tsung Yang and Olivér Kiss and Sebastian Nilsson and Rik Sarkar},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/778},
  pages     = {5572-5579},
  title     = {The shapley value in machine learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified view of relational deep learning for drug pair
scoring. <em>IJCAI</em>, 5564–5571. (<a
href="https://doi.org/10.24963/ijcai.2022/777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, numerous machine learning models which attempt to solve polypharmacy side effect identification, drug-drug interaction prediction, and combination therapy design tasks have been proposed. Here, we present a unified theoretical view of relational machine learning models which can address these tasks. We provide fundamental definitions, compare existing model architectures and discuss performance metrics, datasets, and evaluation protocols. In addition, we emphasize possible high-impact applications and important future research directions in this domain. Keywords: Survey Track: - Survey Track: Machine Learning Survey Track: Data Mining Survey Track: Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Benedek Rozemberczki and Stephen Bonner and Andriy Nikolov and Michaël Ughetto and Sebastian Nilsson and Eliseo Papa},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/777},
  pages     = {5564-5571},
  title     = {A unified view of relational deep learning for drug pair scoring},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evaluation methods for representation learning: A survey.
<em>IJCAI</em>, 5556–5563. (<a
href="https://doi.org/10.24963/ijcai.2022/776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation learning enables us to automatically extract generic feature representations from a dataset to solve another machine learning task. Recently, extracted feature representations by a representation learning algorithm and a simple predictor have exhibited state-of-the-art performance on several machine learning tasks. Despite its remarkable progress, there exist various ways to evaluate representation learning algorithms depending on the application because of the flexibility of representation learning. To understand the current applications of representation learning, we review evaluation methods of representation learning algorithms. On the basis of our evaluation survey, we also discuss the future direction of representation learning. The extended version, https://arxiv.org/abs/2204.08226, gives more detailed discussions and a survey on theoretical analyses. Keywords: Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Kento Nozawa and Issei Sato},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/776},
  pages     = {5556-5563},
  title     = {Evaluation methods for representation learning: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning meets software engineering: A survey on
pre-trained models of source code. <em>IJCAI</em>, 5546–5555. (<a
href="https://doi.org/10.24963/ijcai.2022/775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions. Keywords: Survey Track: Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Changan Niu and Chuanyi Li and Bin Luo and Vincent Ng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/775},
  pages     = {5546-5555},
  title     = {Deep learning meets software engineering: A survey on pre-trained models of source code},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Predictive coding: Towards a future of deep learning beyond
backpropagation? <em>IJCAI</em>, 5538–5545. (<a
href="https://doi.org/10.24963/ijcai.2022/774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The backpropagation of error algorithm (BP) used to train deep neural networks has been fundamental to the successes of deep learning. However, it requires sequential backwards updates and non-local computations which make it challenging to parallelize at scale and is unlike how learning works in the brain. Neuroscience-inspired learning algorithms, however, such as \emph{predictive coding} which utilize local learning have the potential to overcome these limitations and advance beyond deep learning technologies in the future. While predictive coding originated in theoretical neuroscience as a model of information processing in the cortex, recent work has developed the idea into a general-purpose algorithm able to train neural networks using only local computations. In this survey, we review works that have contributed to this perspective and demonstrate the close connection between predictive coding and backpropagation in terms of generalization quality, as well as works that highlight the multiple advantages of using predictive coding models over backprop-trained neural networks. Specifically, we show the substantially greater flexibility of predictive coding networks against equivalent deep neural networks, which can function as classifiers, generators, and associative memories simultaneously, and can be defined on arbitrary graph topologies. Finally, we review direct benchmarks of predictive coding networks on machine learning classification tasks, as well as its close connections to control theory and applications in robotics. Keywords: Survey Track: Machine Learning Survey Track: Multidisciplinary Topics and Applications},
  archive   = {C_IJCAI},
  author    = {Beren Millidge and Tommaso Salvatori and Yuhang Song and Rafal Bogacz and Thomas Lukasiewicz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/774},
  pages     = {5538-5545},
  title     = {Predictive coding: Towards a future of deep learning beyond backpropagation?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vision-and-language pretrained models: A survey.
<em>IJCAI</em>, 5530–5537. (<a
href="https://doi.org/10.24963/ijcai.2022/773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pretrained models have produced great success in both Computer Vision (CV) and Natural Language Processing (NLP). This progress leads to learning joint representations of vision and language pretraining by feeding visual and linguistic contents into a multi-layer transformer, Visual-Language Pretrained Models (VLPMs). In this paper, we present an overview of the major advances achieved in VLPMs for producing joint representations of vision and language. As the preliminaries, we briefly describe the general task definition and genetic architecture of VLPMs. We first discuss the language and vision data encoding methods and then present the mainstream VLPM structure as the core content. We further summarise several essential pretraining and fine-tuning strategies. Finally, we highlight three future directions for both CV and NLP researchers to provide insightful guidance. Keywords: Survey Track: Multidisciplinary Topics and Applications Survey Track: Computer Vision Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Siqu Long and Feiqi Cao and Soyeon Caren Han and Haiqin Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/773},
  pages     = {5530-5537},
  title     = {Vision-and-language pretrained models: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Survey on graph neural network acceleration: An algorithmic
perspective. <em>IJCAI</em>, 5521–5529. (<a
href="https://doi.org/10.24963/ijcai.2022/772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have been a hot spot of recent research and are widely utilized in diverse applications. However, with the use of huger data and deeper models, an urgent demand is unsurprisingly made to accelerate GNNs for more efficient execution. In this paper, we provide a comprehensive survey on acceleration methods for GNNs from an algorithmic perspective. We first present a new taxonomy to classify existing acceleration methods into five categories. Based on the classification, we systematically discuss these methods and highlight their correlations. Next, we provide comparisons from aspects of the efficiency and characteristics of these methods. Finally, we suggest some promising prospects for future research. Keywords: Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Xin Liu and Mingyu Yan and Lei Deng and Guoqi Li and Xiaochun Ye and Dongrui Fan and Shirui Pan and Yuan Xie},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/772},
  pages     = {5521-5529},
  title     = {Survey on graph neural network acceleration: An algorithmic perspective},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural re-ranking in multi-stage recommender systems: A
review. <em>IJCAI</em>, 5512–5520. (<a
href="https://doi.org/10.24963/ijcai.2022/771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As the final stage of the multi-stage recommender system (MRS), re-ranking directly affects users’ experience and satisfaction by rearranging the input ranking lists, and thereby plays a critical role in MRS. With the advances in deep learning, neural re-ranking has become a trending topic and been widely adopted in industrial applications. This review aims at integrating re-ranking algorithms into a broader picture, and paving ways for more comprehensive solutions for future research. For this purpose, we first present a taxonomy of current methods on neural re-ranking. Then we give a description of these methods along with the historic development according to their objectives. The network structure, personalization, and complexity are also discussed and compared. Next, we provide a benchmark for the major neural re-ranking models and quantitatively analyze their re-ranking performance. Finally, the review concludes with a discussion on future prospects of this field. A list of papers discussed in this review, the benchmark datasets, our re-ranking library LibRerank, and detailed parameter settings are publicly available at https://github.com/LibRerank-Community/LibRerank. Keywords: Survey Track: -},
  archive   = {C_IJCAI},
  author    = {Weiwen Liu and Yunjia Xi and Jiarui Qin and Fei Sun and Bo Chen and Weinan Zhang and Rui Zhang and Ruiming Tang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/771},
  pages     = {5512-5520},
  title     = {Neural re-ranking in multi-stage recommender systems: A review},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal-conditioned reinforcement learning: Problems and
solutions. <em>IJCAI</em>, 5502–5511. (<a
href="https://doi.org/10.24963/ijcai.2022/770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Goal-conditioned reinforcement learning (GCRL), related to a set of complex RL problems, trains an agent to achieve different goals under particular scenarios. Compared to the standard RL solutions that learn a policy solely depending on the states or observations, GCRL additionally requires the agent to make decisions according to different goals. In this survey, we provide a comprehensive overview of the challenges and algorithms for GCRL. Firstly, we answer what the basic problems are studied in this field. Then, we explain how goals are represented and present how existing solutions are designed from different points of view. Finally, we make the conclusion and discuss potential future prospects that recent researches focus on. Keywords: Survey Track: Robotics Survey Track: Machine Learning Survey Track: Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Minghuan Liu and Menghui Zhu and Weinan Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/770},
  pages     = {5502-5511},
  title     = {Goal-conditioned reinforcement learning: Problems and solutions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Survey on efficient training of large neural networks.
<em>IJCAI</em>, 5494–5501. (<a
href="https://doi.org/10.24963/ijcai.2022/769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern Deep Neural Networks (DNNs) require significant memory to store weight, activations, and other intermediate tensors during training. Hence, many models don’t fit one GPU device or can be trained using only a small per-GPU batch size. This survey provides a systematic overview of the approaches that enable more efficient DNNs training. We analyze techniques that save memory and make good use of computation and communication resources on architectures with a single or several GPUs. We summarize the main categories of strategies and compare strategies within and across categories. Along with approaches proposed in the literature, we discuss available implementations. Keywords: Survey Track: - Survey Track: Machine Learning Survey Track: Natural Language Processing Survey Track: Computer Vision},
  archive   = {C_IJCAI},
  author    = {Julia Gusak and Daria Cherniuk and Alena Shilova and Alexandr Katrutsa and Daniel Bershatsky and Xunyi Zhao and Lionel Eyraud-Dubois and Oleh Shliazhko and Denis Dimitrov and Ivan Oseledets and Olivier Beaumont},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/769},
  pages     = {5494-5501},
  title     = {Survey on efficient training of large neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Who says what to whom: A survey of multi-party
conversations. <em>IJCAI</em>, 5486–5493. (<a
href="https://doi.org/10.24963/ijcai.2022/768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-party conversations (MPCs) are a more practical and challenging scenario involving more than two interlocutors. This research topic has drawn significant attention from both academia and industry, and it is nowadays counted as one of the most promising research areas in the field of dialogue systems. In general, MPC algorithms aim at addressing the issues of Who says What to Whom, specifically, who speaks, say what, and address whom. The complicated interactions between interlocutors, between utterances, and between interlocutors and utterances develop many variant tasks of MPCs worth investigation. In this paper, we present a comprehensive survey of recent advances in text-based MPCs. In particular, we first summarize recent advances on the research of MPC context modeling including dialogue discourse parsing, dialogue flow modeling and self-supervised training for MPCs. Then we review the state-of-the-art models categorized by Who says What to Whom in MPCs. Finally, we highlight the challenges which are not yet well addressed in MPCs and present future research directions. Keywords: Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Jia-Chen Gu and Chongyang Tao and Zhen-Hua Ling},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/768},
  pages     = {5486-5493},
  title     = {Who says what to whom: A survey of multi-party conversations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep learning with logical constraints. <em>IJCAI</em>,
5478–5485. (<a href="https://doi.org/10.24963/ijcai.2022/767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, there has been an increasing interest in exploiting logically specified background knowledge in order to obtain neural models (i) with a better performance, (ii) able to learn from less data, and/or (iii) guaranteed to be compliant with the background knowledge itself, e.g., for safety-critical applications. In this survey, we retrace such works and categorize them based on (i) the logical language that they use to express the background knowledge and (ii) the goals that they achieve. Keywords: Survey Track: - Survey Track: Machine Learning Survey Track: Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Eleonora Giunchiglia and Mihaela Catalina Stoian and Thomas Lukasiewicz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/767},
  pages     = {5478-5485},
  title     = {Deep learning with logical constraints},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Differential privacy and fairness in decisions and learning
tasks: A survey. <em>IJCAI</em>, 5470–5477. (<a
href="https://doi.org/10.24963/ijcai.2022/766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper surveys the recent work in the intersection of differential privacy (DP) and fairness. It focuses on surveying the work observing that DP systems may exacerbate bias and disparate impacts for different groups of individuals. The survey reviews the conditions under which privacy and fairness may be aligned or contrasting goals, analyzes how and why DP exacerbates bias and unfairness in decision problems and learning tasks, and reviews the available solutions to mitigate the fairness issues arising in DP systems. The survey provides a unified understanding of the main challenges and potential risks arising when deploying privacy-preserving machine learning or decisions making tasks under a fairness lens. Keywords: Survey Track: AI Ethics, Trust, Fairness Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Ferdinando Fioretto and Cuong Tran and Pascal Van Hentenryck and Keyu Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/766},
  pages     = {5470-5477},
  title     = {Differential privacy and fairness in decisions and learning tasks: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Legal judgment prediction: A survey of the state of the art.
<em>IJCAI</em>, 5461–5469. (<a
href="https://doi.org/10.24963/ijcai.2022/765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic legal judgment prediction (LJP) has recently received increasing attention in the natural language processing community in part because of its practical values as well as the associated research challenges. We present an overview of the major milestones made in LJP research covering multiple jurisdictions and multiple languages, and conclude with promising future research directions. Keywords: Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Yi Feng and Chuanyi Li and Vincent Ng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/765},
  pages     = {5461-5469},
  title     = {Legal judgment prediction: A survey of the state of the art},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on dialogue summarization: Recent advances and new
frontiers. <em>IJCAI</em>, 5453–5460. (<a
href="https://doi.org/10.24963/ijcai.2022/764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dialogue summarization aims to condense the original dialogue into a shorter version covering salient information, which is a crucial way to reduce dialogue data overload. Recently, the promising achievements in both dialogue systems and natural language generation techniques drastically lead this task to a new landscape, which results in significant research attentions. However, there still remains a lack of a comprehensive survey for this task. To this end, we take the first step and present a thorough review of this research field carefully and widely. In detail, we systematically organize the current works according to the characteristics of each domain, covering meeting, chat, email thread, customer service and medical dialogue. Additionally, we provide an overview of publicly available research datasets as well as organize two leaderboards under unified metrics. Furthermore, we discuss some future directions, including faithfulness, multi-modal, multi-domain and multi-lingual dialogue summarization, and give our thoughts respectively. We hope that this first survey of dialogue summarization can provide the community with a quick access and a general picture to this task and motivate future researches. Keywords: Survey Track: - Survey Track: Natural Language Processing},
  archive   = {C_IJCAI},
  author    = {Xiachong Feng and Xiaocheng Feng and Bing Qin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/764},
  pages     = {5453-5460},
  title     = {A survey on dialogue summarization: Recent advances and new frontiers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on machine learning approaches for modelling
intuitive physics. <em>IJCAI</em>, 5444–5452. (<a
href="https://doi.org/10.24963/ijcai.2022/763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Research in cognitive science has provided extensive evidence of human cognitive ability in performing physical reasoning of objects from noisy perceptual inputs. Such a cognitive ability is commonly known as intuitive physics. With advancements in deep learning, there is an increasing interest in building intelligent systems that are capable of performing physical reasoning from a given scene for the purpose of building better AI systems. As a result, many contemporary approaches in modelling intuitive physics for machine cognition have been inspired by literature from cognitive science. Despite the wide range of work in physical reasoning for machine cognition, there is a scarcity of reviews that organize and group these deep learning approaches. Especially at the intersection of intuitive physics and artificial intelligence, there is a need to make sense of the diverse range of ideas and approaches. Therefore, this paper presents a comprehensive survey of recent advances and techniques in intuitive physics-inspired deep learning approaches for physical reasoning. The survey will first categorize existing deep learning approaches into three facets of physical reasoning before organizing them into three general technical approaches and propose six categorical tasks of the field. Finally, we highlight the challenges of the current field and present some future research directions. Keywords: Survey Track: Knowledge Representation and Reasoning Survey Track: Machine Learning Survey Track: Computer Vision},
  archive   = {C_IJCAI},
  author    = {Jiafei Duan and Arijit Dasgupta and Jason Fischer and Cheston Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/763},
  pages     = {5444-5452},
  title     = {A survey on machine learning approaches for modelling intuitive physics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey of vision-language pre-trained models.
<em>IJCAI</em>, 5436–5443. (<a
href="https://doi.org/10.24963/ijcai.2022/762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As transformer evolves, pre-trained models have advanced at a breakneck pace in recent years. They have dominated the mainstream techniques in natural language processing (NLP) and computer vision (CV). How to adapt pre-training to the field of Vision-and-Language (V-L) learning and improve downstream task performance becomes a focus of multimodal learning. In this paper, we review the recent progress in Vision-Language Pre-Trained Models (VL-PTMs). As the core content, we first briefly introduce several ways to encode raw images and texts to single-modal embeddings before pre-training. Then, we dive into the mainstream architectures of VL-PTMs in modeling the interaction between text and image representations. We further present widely-used pre-training tasks, and then we introduce some common downstream tasks. We finally conclude this paper and present some promising research directions. Our survey aims to provide researchers with synthesis and pointer to related research. Keywords: Survey Track: Natural Language Processing Survey Track: Computer Vision},
  archive   = {C_IJCAI},
  author    = {Yifan Du and Zikang Liu and Junyi Li and Wayne Xin Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/762},
  pages     = {5436-5443},
  title     = {A survey of vision-language pre-trained models},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Table pre-training: A survey on model architectures,
pre-training objectives, and downstream tasks. <em>IJCAI</em>,
5426–5435. (<a href="https://doi.org/10.24963/ijcai.2022/761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Following the success of pre-training techniques in the natural language domain, a flurry of table pre-training frameworks have been proposed and have achieved new state-of-the-arts on various downstream tasks such as table question answering, table type recognition, column relation classification, table search, and formula prediction. Various model architectures have been explored to best capture the characteristics of (semi-)structured tables, especially specially-designed attention mechanisms. Moreover, to fully leverage the supervision signals in unlabeled tables, diverse pre-training objectives have been designed and evaluated, for example, denoising cell values, predicting numerical relationships, and learning a neural SQL executor. This survey aims to provide a comprehensive review of model designs, pre-training objectives, and downstream tasks for table pre-training, and we further share our thoughts on existing challenges and future opportunities. Keywords: Survey Track: Knowledge Representation and Reasoning Survey Track: Natural Language Processing Survey Track: Data Mining},
  archive   = {C_IJCAI},
  author    = {Haoyu Dong and Zhoujun Cheng and Xinyi He and Mengyu Zhou and Anda Zhou and Fan Zhou and Ao Liu and Shi Han and Dongmei Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/761},
  pages     = {5426-5435},
  title     = {Table pre-training: A survey on model architectures, pre-training objectives, and downstream tasks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evidential reasoning and learning: A survey. <em>IJCAI</em>,
5418–5425. (<a href="https://doi.org/10.24963/ijcai.2022/760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When collaborating with an artificial intelligence (AI) system, we need to assess when to trust its recommendations. Suppose we mistakenly trust it in regions where it is likely to err. In that case, catastrophic failures may occur, hence the need for Bayesian approaches for reasoning and learning to determine the confidence (or epistemic uncertainty) in the probabilities of the queried outcome. Pure Bayesian methods, however, suffer from high computational costs. To overcome them, we revert to efficient and effective approximations. In this paper, we focus on techniques that take the name of evidential reasoning and learning from the process of Bayesian update of given hypotheses based on additional evidence. This paper provides the reader with a gentle introduction to the area of investigation, the up-to-date research outcomes, and the open questions still left unanswered. Keywords: Survey Track: - Survey Track: Uncertainty in AI Survey Track: Knowledge Representation and Reasoning Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Federico Cerutti and Lance M. Kaplan and Murat Şensoy},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/760},
  pages     = {5418-5425},
  title     = {Evidential reasoning and learning: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Image-text retrieval: A survey on recent research and
development. <em>IJCAI</em>, 5410–5417. (<a
href="https://doi.org/10.24963/ijcai.2022/759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the past few years, cross-modal image-text retrieval (ITR) has experienced increased interest in the research community due to its excellent research value and broad real-world application. It is designed for the scenarios where the queries are from one modality and the retrieval galleries from another modality. This paper presents a comprehensive and up-to-date survey on the ITR approaches from four perspectives. By dissecting an ITR system into two processes: feature extraction and feature alignment, we summarize the recent advance of the ITR approaches from these two perspectives. On top of this, the efficiency-focused study on the ITR system is introduced as the third perspective. To keep pace with the times, we also provide a pioneering overview of the cross-modal pre-training ITR approaches as the fourth perspective. Finally, we outline the common benchmark datasets and evaluation metric for ITR, and conduct the accuracy comparison among the representative ITR approaches. Some critical yet less studied issues are discussed at the end of the paper. Keywords: Survey Track: -},
  archive   = {C_IJCAI},
  author    = {Min Cao and Shiping Li and Juntao Li and Liqiang Nie and Min Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/759},
  pages     = {5410-5417},
  title     = {Image-text retrieval: A survey on recent research and development},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A survey on word meta-embedding learning. <em>IJCAI</em>,
5402–5409. (<a href="https://doi.org/10.24963/ijcai.2022/758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Meta-embedding (ME) learning is an emerging approach that attempts to learn more accurate word embeddings given existing (source) word embeddings as the sole input. Due to their ability to incorporate semantics from multiple source embeddings in a compact manner with superior performance, ME learning has gained popularity among practitioners in NLP. To the best of our knowledge, there exist no prior systematic survey on ME learning and this paper attempts to fill this need. We classify ME learning methods according to multiple factors such as whether they (a) operate on static or contextualised embeddings, (b) trained in an unsupervised manner or (c) fine-tuned for a particular task/domain. Moreover, we discuss the limitations of existing ME learning methods and highlight potential future research directions. Keywords: Survey Track: - Survey Track: Natural Language Processing Survey Track: Machine Learning},
  archive   = {C_IJCAI},
  author    = {Danushka Bollegala and James O&#39; Neill},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/758},
  pages     = {5402-5409},
  title     = {A survey on word meta-embedding learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Text transformations in contrastive self-supervised
learning: A review. <em>IJCAI</em>, 5394–5401. (<a
href="https://doi.org/10.24963/ijcai.2022/757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Contrastive self-supervised learning has become a prominent technique in representation learning. The main step in these methods is to contrast semantically similar and dissimilar pairs of samples. However, in the domain of Natural Language Processing (NLP), the augmentation methods used in creating similar pairs with regard to contrastive learning (CL) assumptions are challenging. This is because, even simply modifying a word in the input might change the semantic meaning of the sentence, and hence, would violate the distributional hypothesis. In this review paper, we formalize the contrastive learning framework, emphasize the considerations that need to be addressed in the data transformation step, and review the state-of-the-art methods and evaluations for contrastive representation learning in NLP. Finally, we describe some challenges and potential directions for learning better text representations using contrastive methods. Keywords: Survey Track: - Survey Track: Natural Language Processing Survey Track: Machine Learning Survey Track: Data Mining},
  archive   = {C_IJCAI},
  author    = {Amrita Bhattacharjee and Mansooreh Karami and Huan Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/757},
  pages     = {5394-5401},
  title     = {Text transformations in contrastive self-supervised learning: A review},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fair division of indivisible goods: A survey.
<em>IJCAI</em>, 5385–5393. (<a
href="https://doi.org/10.24963/ijcai.2022/756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Allocating resources to individuals in a fair manner has been a topic of interest since the ancient times, with most of the early rigorous mathematical work on the problem focusing on infinitely divisible resources. Recently, there has been a surge of papers studying computational questions regarding various different notions of fairness for the indivisible case, like maximin share fairness (MMS) and envy-freeness up to any good (EFX). We survey the most important results in the discrete fair division literature, focusing on the case of additive valuation functions and paying particular attention to the progress made in the last 10 years. Keywords: Survey Track: -},
  archive   = {C_IJCAI},
  author    = {Georgios Amanatidis and Georgios Birmpas and Aris Filos-Ratsikas and Alexandros A. Voudouris},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/756},
  pages     = {5385-5393},
  title     = {Fair division of indivisible goods: A survey},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rx-refill graph neural network to reduce drug
overprescribing risks (extended abstract). <em>IJCAI</em>, 5379–5383.
(<a href="https://doi.org/10.24963/ijcai.2022/755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Prescription (aka Rx) drugs can be easily overprescribed and lead to drug abuse or opioid overdose. Accordingly, a state-run prescription drug monitoring program (PDMP) in the United States has been developed to reduce overprescribing. However, PDMP has limited capability in detecting patients&#39; potential overprescribing behaviors, impairing its effectiveness in preventing drug abuse and overdose in patients. In this paper, we propose a novel model RxNet, which builds 1) a dynamic heterogeneous graph to model Rx refills that are essentially prescribing and dispensing (P&amp;D) relationships among various patients, 2) an RxLSTM network to explore the dynamic Rx-refill behavior and medical condition variation of patients, and 3) a dosing-adaptive network to extract and recalibrate dosing patterns and obtain the refined patient representations which are finally utilized for overprescribing detection. The extensive experimental results on a one-year state-wide PDMP data demonstrate that RxNet consistently outperforms state-of-the-art methods in predicting patients at high risk of opioid overdose and drug abuse. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Jianfei Zhang and Ai-Te Kuo and Jianan Zhao and Qianlong Wen and Erin Winstanley and Chuxu Zhang and Yanfang Ye},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/755},
  pages     = {5379-5383},
  title     = {Rx-refill graph neural network to reduce drug overprescribing risks (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning discrete representations via constrained clustering
for effective and efficient dense retrieval (extended abstract).
<em>IJCAI</em>, 5374–5378. (<a
href="https://doi.org/10.24963/ijcai.2022/754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dense Retrieval (DR) has achieved state-of-the-art first-stage ranking effectiveness. However, the efficiency of most existing DR models is limited by the large memory cost of storing dense vectors and the time-consuming nearest neighbor search (NNS) in vector space. Therefore, we present RepCONC, a novel retrieval model that learns discrete Representations via CONstrained Clustering. RepCONC jointly trains dual-encoders and the Product Quantization (PQ) method to learn discrete document representations and enables fast approximate NNS with compact indexes. It models quantization as a constrained clustering process, which requires the document embeddings to be uniformly clustered around the quantization centroids. We theoretically demonstrate the importance of the uniform clustering constraint and derive an efficient approximate solution for constrained clustering by reducing it to an instance of the optimal transport problem. Extensive experiments on two popular ad-hoc retrieval benchmarks show that RepCONC substantially outperforms a wide range of existing retrieval models in terms of retrieval effectiveness, memory efficiency, and time efficiency. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Jingtao Zhan and Jiaxin Mao and Yiqun Liu and Jiafeng Guo and Min Zhang and Shaoping Ma},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/754},
  pages     = {5374-5378},
  title     = {Learning discrete representations via constrained clustering for effective and efficient dense retrieval (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Including signed languages in natural language processing
(extended abstract). <em>IJCAI</em>, 5369–5373. (<a
href="https://doi.org/10.24963/ijcai.2022/753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Signed languages are the primary means of communication for many deaf and hard of hearing individuals. Since signed languages exhibit all the fundamental linguistic properties of natural language, we believe that tools and theories of Natural Language Processing (NLP) are crucial towards its modeling. However, existing research in Sign Language Processing (SLP) seldom attempt to explore and leverage the linguistic organization of signed languages. This position paper calls on the NLP community to include signed languages as a research area with high social and scientific impact. We first discuss the linguistic properties of signed languages to consider during their modeling. Then, we review the limitations of current SLP models and identify the open challenges to extend NLP to signed languages. Finally, we urge (1) the adoption of an efficient tokenization method; (2) the development of linguistically-informed models; (3) the collection of real-world signed language data; (4) the inclusion of local signed language communities as an active and leading voice in research. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Kayo Yin and Malihe Alikhani},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/753},
  pages     = {5369-5373},
  title     = {Including signed languages in natural language processing (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Statistically-guided deep network transformation to harness
heterogeneity in space (extended abstract). <em>IJCAI</em>, 5364–5368.
(<a href="https://doi.org/10.24963/ijcai.2022/752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial data are ubiquitous and have transformed decision-making in many critical domains, including public health, agriculture, transportation, etc. While recent advances in machine learning offer promising ways to harness massive spatial datasets (e.g., satellite imagery), spatial heterogeneity -- a fundamental property of spatial data -- poses a major challenge as data distributions or generative processes often vary over space. Recent studies targeting this difficult problem either require a known space-partitioning as the input, or can only support limited special cases (e.g., binary classification). Moreover, heterogeneity-pattern learned by these methods are locked to the locations of the training samples, and cannot be applied to new locations. We propose a statistically-guided framework to adaptively partition data in space during training using distribution-driven optimization and transform a deep learning model (of user&#39;s choice) into a heterogeneity-aware architecture. We also propose a spatial moderator to generalize learned patterns to new test regions. Experiment results on real-world datasets show that the framework can effectively capture footprints of heterogeneity and substantially improve prediction performances. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Yiqun Xie and Erhu He and Xiaowei Jia and Han Bao and Xun Zhou and Rahul Ghosh and Praveen Ravirathinam},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/752},
  pages     = {5364-5368},
  title     = {Statistically-guided deep network transformation to harness heterogeneity in space (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The min-max complexity of distributed stochastic convex
optimization with intermittent communication (extended abstract).
<em>IJCAI</em>, 5359–5363. (<a
href="https://doi.org/10.24963/ijcai.2022/751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We resolve the min-max complexity of distributed stochastic convex optimization (up to a log factor) in the intermittent communication setting, where M machines work in parallel over the course of R rounds of communication to optimize the objective, and during each round of communication, each machine may sequentially compute K stochastic gradient estimates. We present a novel lower bound with a matching upper bound that establishes an optimal algorithm. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Blake Woodworth and Brian Bullins and Ohad Shamir and Nathan Srebro},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/751},
  pages     = {5359-5363},
  title     = {The min-max complexity of distributed stochastic convex optimization with intermittent communication (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unbiased gradient estimation in unrolled computation graphs
with persistent evolution strategies (extended abstract).
<em>IJCAI</em>, 5354–5358. (<a
href="https://doi.org/10.24963/ijcai.2022/750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current approaches for optimizing parameters in unrolled computation graphs suffer from high variance gradients, bias, slow updates, or large memory usage. We introduce a method called Persistent Evolution Strategies (PES), which divides the computation graph into a series of truncated unrolls, and performs an evolution strategies-based update step after each unroll. PES eliminates bias from these truncations by accumulating correction terms over the entire sequence of unrolls. PES allows for rapid parameter updates, has low memory usage, is unbiased, and has reasonable variance. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Paul Vicol and Luke Metz and Jascha Sohl-Dickstein},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/750},
  pages     = {5354-5358},
  title     = {Unbiased gradient estimation in unrolled computation graphs with persistent evolution strategies (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Black-box audit of YouTube’s video recommendation:
Investigation of misinformation filter bubble dynamics (extended
abstract). <em>IJCAI</em>, 5349–5353. (<a
href="https://doi.org/10.24963/ijcai.2022/749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we describe a black-box sockpuppeting audit which we carried out to investigate the creation and bursting dynamics of misinformation filter bubbles on YouTube. Pre-programmed agents acting as YouTube users stimulated YouTube&#39;s recommender systems: they first watched a series of misinformation promoting videos (bubble creation) and then a series of misinformation debunking videos (bubble bursting). Meanwhile, agents logged videos recommended to them by YouTube. After manually annotating these recommendations, we were able to quantify the portion of misinformative videos among them. The results confirm the creation of filter bubbles (albeit not in all situations) and show that these bubbles can be bursted by watching credible content. Drawing a direct comparison with a previous study, we do not see improvements in overall quantities of misinformation recommended. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Matus Tomlein and Branislav Pecher and Jakub Simko and Ivan Srba and Robert Moro and Elena Stefancova and Michal Kompan and Andrea Hrckova and Juraj Podrouzek and Maria Bielikova},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/749},
  pages     = {5349-5353},
  title     = {Black-box audit of YouTube&#39;s video recommendation: Investigation of misinformation filter bubble dynamics (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ProtoAI: Model-informed prototyping for AI-powered
interfaces (extended abstract). <em>IJCAI</em>, 5344–5348. (<a
href="https://doi.org/10.24963/ijcai.2022/748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When prototyping AI experiences (AIX), interface designers seek effective ways to support end-user tasks through AI capabilities. However, AI poses challenges to design due to its dynamic behavior in response to training data, end-user data, and feedback. Designers must consider AI&#39;s uncertainties and offer adaptations such as explainability, error recovery, and automation vs. human task control. Unfortunately, current prototyping tools assume a black-box view of AI, forcing designers to work with separate tools to explore machine learning models, understand model performance, and align interface choices with model behavior. This introduces friction to rapid and iterative prototyping. We propose Model-Informed Prototyping (MIP), a workflow for AIX design that combines model exploration with UI prototyping tasks. Our system, ProtoAI, allows designers to directly incorporate model outputs into interface designs, evaluate design choices across different inputs, and iteratively revise designs by analyzing model breakdowns. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Hariharan Subramonyam and Colleen Seifert and Eytan Adar},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/748},
  pages     = {5344-5348},
  title     = {ProtoAI: Model-informed prototyping for AI-powered interfaces (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards facilitating empathic conversations in online mental
health support: A reinforcement learning approach (extended abstract).
<em>IJCAI</em>, 5339–5343. (<a
href="https://doi.org/10.24963/ijcai.2022/747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online peer-to-peer support platforms enable conversations between millions of people who seek and provide mental health support. If successful, web-based mental health conversations could improve access to treatment and reduce the global disease burden. Psychologists have repeatedly demonstrated that empathy, the ability to understand and feel the emotions and experiences of others, is a key component leading to positive outcomes in supportive conversations. However, recent studies have shown that highly empathic conversations are rare in online mental health platforms. In this paper, we work towards improving empathy in online mental health support conversations. We introduce a new task of empathic rewriting which aims to transform low-empathy conversational posts to higher empathy. Learning such transformations is challenging and requires a deep understanding of empathy while maintaining conversation quality through text fluency and specificity to the conversational context. Here we propose Partner, a deep reinforcement learning (RL) agent that learns to make sentence-level edits to posts in order to increase the expressed level of empathy while maintaining conversation quality. Our RL agent leverages a policy network, based on a transformer language model adapted from GPT-2, which performs the dual task of generating candidate empathic sentences and adding those sentences at appropriate positions. Through a combination of automatic and human evaluation, we demonstrate that Partner successfully generates more empathic, specific, and diverse responses and outperforms NLP methods from related tasks such as style transfer and empathic dialogue generation. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Ashish Sharma and Inna W. Lin and Adam S. Miner and Dave C. Atkins and Tim Althoff},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/747},
  pages     = {5339-5343},
  title     = {Towards facilitating empathic conversations in online mental health support: A reinforcement learning approach (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing programs for generalized planning as heuristic
search (extended abstract). <em>IJCAI</em>, 5334–5338. (<a
href="https://doi.org/10.24963/ijcai.2022/746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although heuristic search is one of the most successful approaches to classical planning, this planning paradigm does not apply straightforwardly to Generalized Planning (GP). This paper adapts the planning as heuristic search paradigm to the particularities of GP, and presents the first native heuristic search approach to GP. First, the paper defines a program-based solution space for GP that is independent of the number of planning instances in a GP problem, and the size of these instances. Second, the paper defines the BFGP algorithm for GP, that implements a best-first search in our program-based solution space, and that is guided by different evaluation and heuristic functions. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Javier Segovia-Aguas and Sergio Jiménez Celorrio and Anders Jonsson},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/746},
  pages     = {5334-5338},
  title     = {Computing programs for generalized planning as heuristic search (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Asymmetric hybrids: Dialogues for computational concept
combination (extended abstract). <em>IJCAI</em>, 5329–5333. (<a
href="https://doi.org/10.24963/ijcai.2022/745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When considering two concepts in terms of extensional logic, their combination will often be trivial, returning an empty extension. Consider e.g. “a Fish Vehicle”, i.e., “a Vehicle which is also a Fish”. Still, people use sophisticated strategies to produce new, non-empty concepts. All these strategies involve the human ability to mend the conflicting attributes of the input concepts and to create new properties of the combination. We focus in particular on the case where a Head concept has superior ‘asymmetric’ control over steering the resulting combination (or hybridisation) with a Modifier concept. Specifically, we propose a dialogical model of the cognitive and logical mechanics of this asymmetric form of hybridisation. Its implementation is then evaluated using a combination of example ontologies. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Guendalina Righetti and Daniele Porello and Nicolas Troquard and Oliver Kutz and Maria Hedblom and Pietro Galliani},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/745},
  pages     = {5329-5333},
  title     = {Asymmetric hybrids: Dialogues for computational concept combination (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logic rules meet deep learning: A novel approach for ship
type classification (extended abstract). <em>IJCAI</em>, 5324–5328. (<a
href="https://doi.org/10.24963/ijcai.2022/744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The shipping industry is an important component of the global trade and economy. In order to ensure law compliance and safety, it needs to be monitored. In this paper, we present a novel ship type classification model that combines vessel transmitted data from the Automatic Identification System, with vessel imagery. The main components of our approach are the Faster R-CNN Deep Neural Network and a Neuro-Fuzzy system with IF-THEN rules. We evaluate our model using real world data and showcase the advantages of this combination while also compare it with other methods. Results show that our model can increase prediction scores by up to 15.4\% when compared with the next best model we considered, while also maintaining a level of explainability as opposed to common black box approaches. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Manolis Pitsikalis and Thanh-Toan Do and Alexei Lisitsa and Shan Luo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/744},
  pages     = {5324-5328},
  title     = {Logic rules meet deep learning: A novel approach for ship type classification (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computationally efficient optimization of plackett-luce
ranking models for relevance and fairness (extended abstract).
<em>IJCAI</em>, 5319–5323. (<a
href="https://doi.org/10.24963/ijcai.2022/743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Computing the gradient of stochastic Plackett-Luce (PL) ranking models for relevance and fairness metrics can be infeasible because it requires iterating over all possible permutations of items. In this paper, we introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL ranking model through sampling. Unlike existing approaches, PL-Rank makes use of the specific structure of PL models and ranking metrics. Our experimental analysis shows that PL-Rank has a greater sample-efficiency and is computationally less costly than existing policy gradients, resulting in faster convergence at higher performance. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Harrie Oosterhuis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/743},
  pages     = {5319-5323},
  title     = {Computationally efficient optimization of plackett-luce ranking models for relevance and fairness (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detect, understand, act: A neuro-symbolic hierarchical
reinforcement learning framework (extended abstract). <em>IJCAI</em>,
5314–5318. (<a href="https://doi.org/10.24963/ijcai.2022/742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce Detect, Understand, Act (DUA), a neuro-symbolic reinforcement learning framework. The Detect component is composed of a traditional computer vision object detector and tracker. The Act component houses a set of options, high-level actions enacted by pre-trained deep reinforcement learning (DRL) policies. The Understand component provides a novel answer set programming (ASP) paradigm for effectively learning symbolic meta-policies over options using inductive logic programming (ILP). We evaluate our framework on the Animal-AI (AAI) competition testbed, a set of physical cognitive reasoning problems. Given a set of pre-trained DRL policies, DUA requires only a few examples to learn a meta-policy that allows it to improve the state-of-the-art on multiple of the most challenging categories from the testbed. DUA constitutes the first holistic hybrid integration of computer vision, ILP and DRL applied to an AAI-like environment and sets the foundations for further use of ILP in complex DRL challenges. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Ludovico Mitchener and David Tuckey and Matthew Crosby and Alessandra Russo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/742},
  pages     = {5314-5318},
  title     = {Detect, understand, act: A neuro-symbolic hierarchical reinforcement learning framework (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Complex query answering with neural link predictors
(extended abstract)*. <em>IJCAI</em>, 5309–5313. (<a
href="https://doi.org/10.24963/ijcai.2022/741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural link predictors are useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries containing logical conjunctions (∧), disjunctions (∨), and existential quantifiers (∃). We propose a framework for efficiently answering complex queries on in- complete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods — black-box models trained on millions of generated queries — without the need for training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8\% up to 40\% in Hits@3 across multiple knowledge graphs. We find that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms. All our source code and datasets are available online (https://github.com/uclnlp/cqd). Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Pasquale Minervini and Erik Arakelyan and Daniel Daza and Michael Cochez},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/741},
  pages     = {5309-5313},
  title     = {Complex query answering with neural link predictors (Extended abstract)*},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Open data science to fight COVID-19: Winning the 500k XPRIZE
pandemic response challenge (extended abstract). <em>IJCAI</em>,
5304–5308. (<a href="https://doi.org/10.24963/ijcai.2022/740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We describe the deep learning-based COVID-19 cases predictor and the Pareto-optimal Non-Pharmaceutical Intervention (NPI) prescriptor developed by the winning team of the 500k XPRIZE Pandemic Response Challenge. The competition aimed at developing data-driven AI models to predict COVID-19 infection rates and to prescribe NPI Plans that governments, business leaders and organizations could implement to minimize harm when reopening their economies. In addition to the validation performed by XPRIZE with real data, our models were validated in a real-world scenario thanks to an ongoing collaboration with the Valencian Government in Spain. Our experience contributes to a necessary transition to more evidence-driven policy-making during a pandemic. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Miguel Angel Lozano and Òscar Garibo-i-Orts and Eloy Piñol and Miguel Rebollo and Kristina Polotskaya and Miguel Ángel García-March and J. Alberto Conejero and Francisco Escolano and Nuria Oliver},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/740},
  pages     = {5304-5308},
  title     = {Open data science to fight COVID-19: Winning the 500k XPRIZE pandemic response challenge (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining clause learning and branch and bound for MaxSAT
(extended abstract). <em>IJCAI</em>, 5299–5303. (<a
href="https://doi.org/10.24963/ijcai.2022/739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Branch and Bound (BnB) has been successfully used to solve many combinatorial optimization problems. However, BnB MaxSAT solvers perform poorly when solving real-world and academic optimization problems. They are only competitive for random and some crafted instances. Thus, it is a prevailing opinion in the community that BnB is not really useful for practical MaxSAT solving. We refute this opinion by presenting a new BnB MaxSAT solver, called MaxCDCL, which combines clause learning and an efficient bounding procedure. MaxCDCL is among the top 5 out of a total of 15 exact solvers that participated in the 2020 MaxSAT Evaluation, solving several instances that other solvers cannot solve. Furthermore, MaxCDCL solves the highest number of instances from different MaxSAT Evaluations when combined with the best existing solvers. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Chu-Min Li and Zhenxing Xu and Jordi Coll and Felip Manyà and Djamal Habet and Kun He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/739},
  pages     = {5299-5303},
  title     = {Combining clause learning and branch and bound for MaxSAT (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Homeomorphic-invariance of EM: Non-asymptotic convergence in
KL divergence for exponential families via mirror descent (extended
abstract). <em>IJCAI</em>, 5294–5298. (<a
href="https://doi.org/10.24963/ijcai.2022/738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Expectation maximization (EM) is the default algorithm for fitting probabilistic models with missing or latent variables, yet we lack a full understanding of its non-asymptotic convergence properties. Previous works show results along the lines of “EM converges at least as fast as gradient descent” by assuming the conditions for the convergence of gradient descent apply. This approach is not only loose, in that it does not capture that EM can make more progress than a gradient step, but the assumptions fail to hold for textbook examples of EM like Gaussian mixtures. In this work, we show that for the common setting of exponential family distributions, viewing EM as a mirror descent algorithm leads to convergence rates in Kullback-Leibler (KL) divergence and how the KL divergence is related to first-order stationarity via Bregman divergences. In contrast to previous works, the analysis is invariant to the choice of parametrization and holds with minimal assumptions. We also show applications of these ideas to local linear (and superlinear) convergence rates, generalized EM, and non-exponential family distributions. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Frederik Kunstner and Raunak Kumar and Mark Schmidt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/738},
  pages     = {5294-5298},
  title     = {Homeomorphic-invariance of EM: Non-asymptotic convergence in KL divergence for exponential families via mirror descent (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Allocating opportunities in a dynamic model of
intergenerational mobility (extended abstract). <em>IJCAI</em>,
5289–5293. (<a href="https://doi.org/10.24963/ijcai.2022/737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Opportunities such as higher education can promote intergenerational mobility, leading individuals to achieve levels of socioeconomic status above that of their parents. In this work, which is an extended abstract of a longer paper in the proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, we develop a dynamic model for allocating such opportunities in a society that exhibits bottlenecks in mobility; the problem of optimal allocation reflects a trade-off between the benefits conferred by the opportunities in the current generation and the potential to elevate the socioeconomic status of recipients, shaping the composition of future generations in ways that can benefit further from the opportunities. We show how optimal allocations in our model arise as solutions to continuous optimization problems over multiple generations, and we find in general that these optimal solutions can favor recipients of low socioeconomic status over slightly higher-performing individuals of high socioeconomic status --- a form of socioeconomic affirmative action that the society in our model discovers in the pursuit of purely payoff-maximizing goals. We characterize how the structure of the model can lead to either temporary or persistent affirmative action, and we consider extensions of the model with more complex processes modulating the movement between different levels of socioeconomic status. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Hoda Heidari and Jon Kleinberg},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/737},
  pages     = {5289-5293},
  title     = {Allocating opportunities in a dynamic model of intergenerational mobility (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Measuring data leakage in machine-learning models with
fisher information (extended abstract). <em>IJCAI</em>, 5284–5288. (<a
href="https://doi.org/10.24963/ijcai.2022/736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine-learning models contain information about the data they were trained on. This information leaks either through the model itself or through predictions made by the model. Consequently, when the training data contains sensitive attributes, assessing the amount of information leakage is paramount. We propose a method to quantify this leakage using the Fisher information of the model about the data. Unlike the worst-case a priori guarantees of differential privacy, Fisher information loss measures leakage with respect to specific examples, attributes, or sub-populations within the dataset. We motivate Fisher information loss through the Cramer-Rao bound and delineate the implied threat model. We provide efficient methods to compute Fisher information loss for output-perturbed generalized linear models. Finally, we empirically validate Fisher information loss as a useful measure of information leakage. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Awni Hannun and Chuan Guo and Laurens van der Maaten},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/736},
  pages     = {5284-5288},
  title     = {Measuring data leakage in machine-learning models with fisher information (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable anytime planning for multi-agent MDPs (extended
abstract). <em>IJCAI</em>, 5279–5283. (<a
href="https://doi.org/10.24963/ijcai.2022/735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a scalable planning algorithm for multi-agent sequential decision problems that require dynamic collaboration. Teams of agents need to coordinate decisions in many domains, but naive approaches fail due to the exponential growth of the joint action space with the number of agents. We circumvent this complexity through an anytime approach that allows us to trade computation for approximation quality and also dynamically coordinate actions. Our algorithm comprises three elements: online planning with Monte Carlo Tree Search (MCTS), factorizing local agent interactions with coordination graphs, and selecting optimal joint actions with the Max-Plus method. On the benchmark SysAdmin domain with static coordination graphs, our approach achieves comparable performance with much lower computation cost than the MCTS baselines. We also introduce a multi-drone delivery domain with dynamic, i.e., state-dependent coordination graphs, and demonstrate how our approach scales to large problems on this domain that are intractable for other MCTS methods. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Shushman Choudhury and Jayesh K. Gupta and Mykel J. Kochenderfer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/735},
  pages     = {5279-5283},
  title     = {Scalable anytime planning for multi-agent MDPs (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep cooperation of CDCL and local search for SAT (extended
abstract). <em>IJCAI</em>, 5274–5278. (<a
href="https://doi.org/10.24963/ijcai.2022/734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern SAT solvers are based on a paradigm named conflict driven clause learning (CDCL), while local search is an important alternative. Although there have been attempts combining these two methods, this work proposes deeper cooperation techniques. First, we relax the CDCL framework by extending promising branches to complete assignments and calling a local search solver to search for a model nearby. More importantly, the local search assignments and the conflict frequency of variables in local search are exploited in the phase selection and branching heuristics of CDCL. We use our techniques to improve three typical CDCL solvers (glucose, MapleLCMDistChronoBT and Kissat). Experiments on benchmarks from the Main tracks of SAT Competitions 2017-2020 and a real world benchmark of spectrum allocation show that the techniques bring significant improvements, particularly on satisfiable instances. A resulting solver won the Main Track SAT category in SAT Competition 2020 and also performs very well on the spectrum allocation benchmark. As far as we know, this is the first work that meets the standard of the challenge ``Demonstrate the successful combination of stochastic search and systematic search techniques, by the creation of a new algorithm that outperforms the best previous examples of both approaches.&#39;&#39; (AAAI 1997) on standard application benchmarks. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Shaowei Cai and Xindi Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/734},
  pages     = {5274-5278},
  title     = {Deep cooperation of CDCL and local search for SAT (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Capturing homomorphism-closed decidable queries with
existential rules (extended abstract). <em>IJCAI</em>, 5269–5273. (<a
href="https://doi.org/10.24963/ijcai.2022/733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existential rules are a very popular ontology-mediated query language for which the chase represents a generic computational approach for query answering. It is straightforward that existential rule queries exhibiting chase termination are decidable and can only recognize properties that are preserved under homomorphisms. This paper is an extended abstract of our eponymous publication at KR 2021 where we show the converse: every decidable query that is closed under homomorphism can be expressed by an existential rule set for which the standard chase universally terminates. Membership in this fragment is not decidable, but we show via a diagonalisation argument that this is unavoidable. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Camille Bourgaux and David Carral and Markus Krötzsch and Sebastian Rudolph and Michaël Thomazo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/733},
  pages     = {5269-5273},
  title     = {Capturing homomorphism-closed decidable queries with existential rules (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Utilizing treewidth for quantitative reasoning on epistemic
logic programs (extended abstract). <em>IJCAI</em>, 5264–5268. (<a
href="https://doi.org/10.24963/ijcai.2022/732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extending the popular Answer Set Programming (ASP) paradigm by introspective reasoning capacities has received increasing interest within the last years. Particular attention is given to the formalism of epistemic logic programs (ELPs) where standard rules are equipped with modal operators which allow to express conditions on literals for being known or possible, i.e., contained in all or some answer sets, respectively. ELPs thus deliver multiple collections of answer sets, known as world views. Employing ELPs for reasoning problems so far has mainly been restricted to standard deci- sion problems (complexity analysis) and enumeration (development of systems) of world views. In this paper, we first establish quantitative reasoning for ELPs, where the acceptance of a certain set of literals depends on the number (proportion) of world views that are compatible with the set. Second, we present a novel system capable of efficiently solving the underlying counting problems required for quantitative reasoning. Our system exploits the graph-based measure treewidth by iteratively finding (graph) abstractions of ELPs. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Viktor Besin and Markus Hecher and Stefan Woltran},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/732},
  pages     = {5264-5268},
  title     = {Utilizing treewidth for quantitative reasoning on epistemic logic programs (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving inductive link prediction using hyper-relational
facts (extended abstract). <em>IJCAI</em>, 5259–5263. (<a
href="https://doi.org/10.24963/ijcai.2022/731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For many years, link prediction on knowledge. graphs has been a purely transductive task, not allowing for reasoning on unseen entities. Recently, increasing efforts are put into exploring semi- and fully inductive scenarios, enabling inference over unseen and emerging entities. Still, all these approaches only consider triple-based KGs, whereas their richer counterparts, hyper-relational KGs (e.g., Wikidata), have not yet been properly studied. In this work, we classify different inductive settings and study the benefits of employing hyper-relational KGs on a wide range of semi- and fully inductive link prediction tasks powered by recent advancements in graph neural networks. Our experiments on a novel set of benchmarks show that qualifiers over typed edges can lead to performance improvements of 6\% of absolute gains (for the Hits@10 metric) compared to triple-only baselines. Our code is available at https://github.com/mali-git/hyper_relational_ilp. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {Mehdi Ali and Max Berrendorf and Mikhail Galkin and Veronika Thost and Tengfei Ma and Volker Tresp and Jens Lehmann},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/731},
  pages     = {5259-5263},
  title     = {Improving inductive link prediction using hyper-relational facts (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the expressivity of markov reward (extended abstract).
<em>IJCAI</em>, 5254–5258. (<a
href="https://doi.org/10.24963/ijcai.2022/730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reward is the driving force for reinforcement-learning agents. We here set out to understand the expressivity of Markov reward as a way to capture tasks that we would want an agent to perform. We frame this study around three new abstract notions of &quot;task&quot;: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering over trajectories. Our main results prove that while reward can express many of these tasks, there exist instances of each task type that no Markov reward function can capture. We then provide a set of polynomial-time algorithms that construct a Markov reward function that allows an agent to perform each task type, and correctly determine when no such reward function exists. Keywords: Artificial Intelligence: General},
  archive   = {C_IJCAI},
  author    = {David Abel and Will Dabney and Anna Harutyunyan and Mark K. Ho and Michael L. Littman and Doina Precup and Satinder Singh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/730},
  pages     = {5254-5258},
  title     = {On the expressivity of markov reward (Extended abstract)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Climate bot: A machine reading comprehension system for
climate change question answering. <em>IJCAI</em>, 5249–5252. (<a
href="https://doi.org/10.24963/ijcai.2022/729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Climate change has a severe impact on the overall ecosystem of the whole world, including humankind. This demo paper presents Climate Bot - a machine reading comprehension system for question answering over documents about climate change. The proposed Climate Bot provides an interface for users to ask questions in natural language and get answers from reliable data sources. The purpose of the climate bot is to spread awareness about climate change and help individuals and communities to learn about the impact and challenges of climate change. Additionally, we open-sourced an annotated climate change dataset CCMRC to promote further research on the topic. This paper describes the dataset collection, annotation, system design, and evaluation. Keywords: Natural Language Processing: Question Answering Natural Language Processing: Applications Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Md Rashad Al Hasan Rony and Ying Zuo and Liubov Kovriguina and Roman Teucher and Jens Lehmann},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/729},
  pages     = {5249-5252},
  title     = {Climate bot: A machine reading comprehension system for climate change question answering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Argo: Towards small vessel detection for humanitarian
purposes. <em>IJCAI</em>, 5245–5248. (<a
href="https://doi.org/10.24963/ijcai.2022/728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Refugees trying to get to Europe via the Mediterranean often face human rights violations. The present situation is not in line with the UN&#39;s SDG&#39;s 10 and 16. We present Argo: a semi-automatically created vessel classification dataset focused on small boats, with the aim to enable NGOs and the public to detect refugee boats in satellite imagery. We achieve a classification recall of 91\% on small ships. With a tool developed on top of the results presented here, NGOs could collect information and hold institutions participating in illegal activities accountable. Keywords: Multidisciplinary Topics and Applications: Sustainable Development Goals AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Elisabeth Moser and Selina Meyer and Maximilian Schmidhuber and Daniel Ketterer and Matthias Eberhardt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/728},
  pages     = {5245-5248},
  title     = {Argo: Towards small vessel detection for humanitarian purposes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactive concept-map based summaries for SEND children.
<em>IJCAI</em>, 5236–5243. (<a
href="https://doi.org/10.24963/ijcai.2022/727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Equitable and inclusive quality education is a human right. It is crucial to provide for the learning needs of every child, especially those with learning disabilities. Traditional approaches to learning propose education paths performed with speech therapists. One of the most efficient strategies to help children with reading comprehension difficulties is the creation of a ``concept map&#39;&#39;, a structured summary of the written text in a graph structure. Online tools that offer students the possibility to manually create or automatically extract concept maps from text have been created over the years. However, there is still a shortage of software that are specifically designed for children at risk and which produce a concept map that is tailored to the clinical profiles of individuals. In this Project Collaboration, we want to tackle this gap by implementing a multi-modal, online and open-access Artificial-Intelligence powered tool that could help these children to make sense of written text by enabling them to interactively create concept maps. The expected output is threefold. We will implement a new model for concept-map-based document summarization and a clinically appropriate web interface. We will evaluate them in real-world settings through user studies performed by speech therapists. Keywords: AI for Good Project Proposal: AI for Good Project Proposal},
  archive   = {C_IJCAI},
  author    = {Martina Galletti and Michael Anslow and Francesca Bianchi and Manuela Calanca and Donatella Tomaiuoli and Remi Van Trijp and Diletta Vedovelli and Eleonora Pasqua},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/727},
  pages     = {5236-5243},
  title     = {Interactive concept-map based summaries for SEND children},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A norm optimisation approach to SDGs: Tackling poverty by
acting on discrimination. <em>IJCAI</em>, 5228–5235. (<a
href="https://doi.org/10.24963/ijcai.2022/726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Policies that seek to mitigate poverty by acting on equal opportunity have been found to aggravate discrimination against the poor (aporophobia), since individuals are made responsible for not progressing in the social hierarchy. Only a minority of the poor benefit from meritocracy in this era of growing inequality, generating resentment among those who seek to escape their needy situations by trying to climb up the ladder. Through the formulation and development of an agent-based social simulation, this study aims to analyse the role of norms implementing equal opportunity and social solidarity principles as enhancers or mitigators of aporophobia, as well as the threshold of aporophobia that would facilitate the success of poverty-reduction policies. The ultimate goal of the social simulation is to extract insights that could help inform and guide a new generation of policy making for poverty reduction by acting on the discrimination against the poor, in line with the UN “Leave No One Behind” principle. An “aporophobia-meter” will be developed and guidelines will be drafted based on both the simulation results and a review of poverty reduction policies at regional levels. Keywords: AI for Good Project Proposal: AI for Good Project Proposal},
  archive   = {C_IJCAI},
  author    = {Georgina Curto and Nieves Montes and Carles Sierra and Nardine Osman and Flavio Comim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/726},
  pages     = {5228-5235},
  title     = {A norm optimisation approach to SDGs: Tackling poverty by acting on discrimination},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Psychiatric scale guided risky post screening for early
detection of depression. <em>IJCAI</em>, 5220–5226. (<a
href="https://doi.org/10.24963/ijcai.2022/725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Depression is a prominent health challenge to the world, and early risk detection (ERD) of depression from online posts can be a promising technique for combating the threat. Early depression detection faces the challenge of efficiently tackling streaming data, balancing the tradeoff between timeliness, accuracy and explainability. To tackle these challenges, we propose a psychiatric scale guided risky post screening method that can capture risky posts related to the dimensions defined in clinical depression scales, and providing interpretable diagnostic basis. A Hierarchical Attentional Network equipped with BERT (HAN-BERT) is proposed to further advance explainable predictions. For ERD, we propose an online algorithm based on an evolving queue of risky posts that can significantly reduce the number of model inferences to boost efficiency. Experiments show that our method outperforms the competitive feature-based and neural models under conventional depression detection settings, and achieves simultaneous improvement in both efficacy and efficiency for ERD. Keywords: Natural Language Processing: Text Classification Machine Learning: Time-series; Data Streams AI Ethics, Trust, Fairness: Explainability and Interpretability Humans and AI: Computational Sustainability and Human Well-Being Machine Learning: Attention Models Machine Learning: Classification Machine Learning: Sequence and Graph Learning AI Ethics, Trust, Fairness: Ethical, Legal and Societal Issues Multidisciplinary Topics and Applications: Health and Medicine Multidisciplinary Topics and Applications: Sustainable Development Goals Multidisciplinary Topics and Applications: Web and Social Networks Multidisciplinary Topics and Applications: General Natural Language Processing: General},
  archive   = {C_IJCAI},
  author    = {Zhiling Zhang and Siyuan Chen and Mengyue Wu and Kenny Q. Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/725},
  pages     = {5220-5226},
  title     = {Psychiatric scale guided risky post screening for early detection of depression},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conversational inequality through the lens of political
interruption. <em>IJCAI</em>, 5213–5219. (<a
href="https://doi.org/10.24963/ijcai.2022/724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel dataset of dialogues containing interruption with an aim to conduct a large-scale analysis of interruption patterns of people from diverse backgrounds in terms of gender, race/ethnicity, occupation, and political orientation. Our dataset includes 625, 409 dialogues containing interruptions found in 275, 420 transcripts from CNN, Fox News, and MSNBC spanning between January 2000 and July 2021. From this large, unlabeled pool of interruptions, we release an annotated dataset consisting of 2, 000 dialogues with fine-grained interruption labels. We use this dataset to train an interruption classifier and predict the interruption type of a given dialogue. Our results reveal that male speakers (in our collected samples) tend to talk more than female speakers, while female speakers interrupt more. Moreover, people tend to use less intrusive interruptions when talking to others sharing the same political belief. This pattern becomes more pronounced among news media with stronger political bias. Keywords: Multidisciplinary Topics and Applications: Social Sciences Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Clay H. Yoo and Jiachen Wang and Yuxi Luo and Kunal Khadilkar and Ashiqur R. KhudaBukhsh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/724},
  pages     = {5213-5219},
  title     = {Conversational inequality through the lens of political interruption},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ranked prioritization of groups in combinatorial bandit
allocation. <em>IJCAI</em>, 5206–5212. (<a
href="https://doi.org/10.24963/ijcai.2022/723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Preventing poaching through ranger patrols protects endangered wildlife, directly contributing to the UN Sustainable Development Goal 15 of life on land. Combinatorial bandits have been used to allocate limited patrol resources, but existing approaches overlook the fact that each location is home to multiple species in varying proportions, so a patrol benefits each species to differing degrees. When some species are more vulnerable, we ought to offer more protection to these animals; unfortunately, existing combinatorial bandit approaches do not offer a way to prioritize important species. To bridge this gap, (1) We propose a novel combinatorial bandit objective that trades off between reward maximization and also accounts for prioritization over species, which we call ranked prioritization. We show this objective can be expressed as a weighted linear sum of Lipschitz-continuous reward functions. (2) We provide RankedCUCB, an algorithm to select combinatorial actions that optimize our prioritization-based objective, and prove that it achieves asymptotic no-regret. (3) We demonstrate empirically that RankedCUCB leads to up to 38\% improvement in outcomes for endangered species using real-world wildlife conservation data. Along with adapting to other challenges such as preventing illegal logging and overfishing, our no-regret algorithm addresses the general combinatorial bandit problem with a weighted linear objective. Keywords: Machine Learning: Online Learning Multidisciplinary Topics and Applications: Computational Sustainability Planning and Scheduling: Planning under Uncertainty Machine Learning: Reinforcement Learning Multidisciplinary Topics and Applications: Sustainable Development Goals Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Lily Xu and Arpita Biswas and Fei Fang and Milind Tambe},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/723},
  pages     = {5206-5212},
  title     = {Ranked prioritization of groups in combinatorial bandit allocation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sequential vaccine allocation with delayed feedback.
<em>IJCAI</em>, 5199–5205. (<a
href="https://doi.org/10.24963/ijcai.2022/722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we consider the problem of how to best allocate a limited supply of vaccines in the aftermath of an infectious disease outbreak by viewing the problem as a sequential game between a learner and an environment (specifically, a bandit problem). The difficulty of this problem lies in the fact that the payoff of vaccination cannot be directly observed, making it difficult to compare the relative effectiveness of vaccination on different population groups. Currently used vaccination policies make recommendations based on mathematical modelling and ethical considerations. These policies are static, and do not adapt as conditions change. Our aim is to design and evaluate an algorithm which can make use of routine surveillance data to dynamically adjust its recommendation. We evaluate the performance of our approach by applying it to a simulated epidemic of a disease based on real-world COVID-19 data, and show that our vaccination policy was able to perform better than existing vaccine allocation policies. In particular, we show that with our allocation method, we can reduce the number of required vaccination by at least 50\% in order to keep the peak number of hospitalised patients below a certain threshold. Also, when the same batch sizes are used, our method can reduce the peak number of hospitalisation by up to 20\%. We also demonstrate that our vaccine allocation does not vary the number of batches per group much, making it socially more acceptable (as it reduces uncertainty, hence results in better and more interpretable communication). Keywords: Uncertainty in AI: Sequential Decision Making AI Ethics, Trust, Fairness: Societal Impact of AI Machine Learning: Online Learning Machine Learning: Reinforcement Learning Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Yichen Xiao and Han-Ching Ou and Haipeng Chen and Van Thieu Nguyen and Long Tran-Thanh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/722},
  pages     = {5199-5205},
  title     = {Sequential vaccine allocation with delayed feedback},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quantifying health inequalities induced by data and AI
models. <em>IJCAI</em>, 5192–5198. (<a
href="https://doi.org/10.24963/ijcai.2022/721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI technologies are being increasingly tested and applied in critical environments including healthcare. Without an effective way to detect and mitigate AI induced inequalities, AI might do more harm than good, potentially leading to the widening of underlying inequalities. This paper proposes a generic allocation-deterioration framework for detecting and quantifying AI induced inequality. Specifically, AI induced inequalities are quantified as the area between two allocation-deterioration curves. To assess the framework’s performance, experiments were conducted on ten synthetic datasets (N&gt;33, 000) generated from HiRID - a real-world Intensive Care Unit (ICU) dataset, showing its ability to accurately detect and quantify inequality proportionally to controlled inequalities. Extensive analyses were carried out to quantify health inequalities (a) embedded in two real-world ICU datasets; (b) induced by AI models trained for two resource allocation scenarios. Results showed that compared to men, women had up to 33\% poorer deterioration in markers of prognosis when admitted to HiRID ICUs. All four AI models assessed were shown to induce significant inequalities (2.45\% to 43.2\%) for non-White compared to White patients. The models exacerbated data embedded inequalities significantly in 3 out of 8 assessments, one of which was &gt;9 times worse. Keywords: AI Ethics, Trust, Fairness: Bias AI Ethics, Trust, Fairness: Fairness &amp; Diversity Multidisciplinary Topics and Applications: Health and Medicine AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Honghan Wu and Aneeta Sylolypavan and Minhong Wang and Sarah Wild},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/721},
  pages     = {5192-5198},
  title     = {Quantifying health inequalities induced by data and AI models},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic structure learning through graph neural network for
forecasting soil moisture in precision agriculture. <em>IJCAI</em>,
5185–5191. (<a href="https://doi.org/10.24963/ijcai.2022/720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Soil moisture is an important component of precision agriculture as it directly impacts the growth and quality of vegetation. Forecasting soil moisture is essential to schedule the irrigation and optimize the use of water. Physics based soil moisture models need rich features and heavy computation which is not scalable. In recent literature, conventional machine learning models have been applied for this problem. These models are fast and simple, but they often fail to capture the spatio-temporal correlation that soil moisture exhibits over a region. In this work, we propose a novel graph neural network based solution that learns temporal graph structures and forecast soil moisture in an end-to-end framework. Our solution is able to handle the problem of missing ground truth soil moisture which is common in practice. We show the merit of our algorithm on real-world soil moisture data. Keywords: Multidisciplinary Topics and Applications: Computational Sustainability Data Mining: Mining Graphs Data Mining: Mining Spatial and/or Temporal Data Multidisciplinary Topics and Applications: Sustainable Development Goals},
  archive   = {C_IJCAI},
  author    = {Anoushka Vyas and Sambaran Bandyopadhyay},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/720},
  pages     = {5185-5191},
  title     = {Dynamic structure learning through graph neural network for forecasting soil moisture in precision agriculture},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting the number of tenants at-risk of formal
eviction: A machine learning approach to inform public policy.
<em>IJCAI</em>, 5178–5184. (<a
href="https://doi.org/10.24963/ijcai.2022/719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Eviction of tenants has reached a crisis level in the U.S. and its consequences pose significant challenges to society. To tackle this eviction crisis, policymakers have been allocating financial resources but a more efficient resource allocation would need an accurate forecast of the number of tenants at-risk of evictions ahead of time. To help enhance the existing eviction prevention/diversion programs, in this work, we propose a multi-view deep neural network model, named as MARTIAN, that forecasts the number of tenants at-risk of getting formally evicted (at the census tract level) n months into the future. Then, we evaluate MARTIAN’s predictive performance under various conditions using real-world eviction cases filed across Dallas County, TX. The results of empirical evaluation show that MARTIAN outperforms an extensive set of baseline models in terms of predictive performance. Additionally, MARTIAN’s superior predictive performance is generalizable to unseen census tracts, for which no labeled data is available in the training set. This research has been done in collaboration with Child Poverty Action Lab (CPAL), which is a pioneering non-governmental organization (NGO) working for tackling poverty-related issues across Dallas County, TX. The usability of MARTIAN is under review by subject matter experts. We release our codebase at https://github.com/maryam-tabar/MARTIAN. Keywords: Multidisciplinary Topics and Applications: Sustainable Development Goals Multidisciplinary Topics and Applications: Computational Sustainability},
  archive   = {C_IJCAI},
  author    = {Maryam Tabar and Wooyong Jung and Amulya Yadav and Owen Wilson Chavez and Ashley Flores and Dongwon Lee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/719},
  pages     = {5178-5184},
  title     = {Forecasting the number of tenants at-risk of formal eviction: A machine learning approach to inform public policy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revealing the excitation causality between climate and
political violence via a neural forward-intensity poisson process.
<em>IJCAI</em>, 5171–5177. (<a
href="https://doi.org/10.24963/ijcai.2022/718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The causal mechanism between climate and political violence is fraught with complex mechanisms. Current quantitative causal models rely on one or more assumptions: (1) the climate drivers persistently generate conflict, (2) the causal mechanisms have a linear relationship with the conflict generation parameter, and/or (3) there is sufficient data to inform the prior distribution. Yet, we know conflict drivers often excite a social transformation process which leads to violence (e.g., drought forces agricultural producers to join urban militia), but further climate effects do not necessarily contribute to further violence. Therefore, not only is this bifurcation relationship highly non-linear, there is also often a lack of data to support prior assumptions for high resolution modeling. Here, we aim to overcome the aforementioned causal modeling challenges by proposing a neural forward-intensity Poisson process (NFIPP) model. The NFIPP is designed to capture the potential non-linear causal mechanism in climate induced political violence, whilst being robust to sparse and timing-uncertain data. Our results span 20 recent years and reveal an excitation-based causal link between extreme climate events and political violence across diverse countries. Our climate-induced conflict model results are cross-validated against qualitative climate vulnerability indices. Furthermore, we label historical events that either improve or reduce our predictability gain, demonstrating the importance of domain expertise in informing interpretation. Keywords: Machine Learning: Applications Machine Learning: Probabilistic Machine Learning Uncertainty in AI: Applications Multidisciplinary Topics and Applications: Social Sciences},
  archive   = {C_IJCAI},
  author    = {Schyler C. Sun and Bailu Jin and Zhuangkun Wei and Weisi Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/718},
  pages     = {5171-5177},
  title     = {Revealing the excitation causality between climate and political violence via a neural forward-intensity poisson process},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scalable and memory-efficient algorithms for controlling
networked epidemic processes using multiplicative weights update method.
<em>IJCAI</em>, 5164–5170. (<a
href="https://doi.org/10.24963/ijcai.2022/717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of designing scalable algorithms to find effective intervention strategies for controlling stochastic epidemic processes on networks. This is a common problem arising in agent based models for epidemic spread. Previous approaches to this problem focus on either heuristics with no guarantees or approximation algorithms that scale only to networks corresponding to county-sized populations, typically, with less than a million nodes. In particular, the mathematical-programming based approaches need to solve the Linear Program (LP) relaxation of the problem using an LP solver, which restricts the scalability of this approach. In this work, we overcome this restriction by designing an algorithm that adapts the multiplicative weights update (MWU) framework, along with the sample average approximation (SAA) technique, to approximately solve the linear program (LP) relaxation for the problem. To scale this approach further, we provide a memory-efficient algorithm that enables scaling to large networks, corresponding to country-size populations, with over 300 million nodes and 30 billion edges. Furthermore, we show that this approach provides near-optimal solutions to the LP in practice. Keywords: Agent-based and Multi-agent Systems: Resource Allocation AI Ethics, Trust, Fairness: Fairness &amp; Diversity Data Mining: Networks Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Prathyush Sambaturu and Marco Minutoli and Mahantesh Halappanavar and Ananth Kalyanaraman and Anil Vullikanti},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/717},
  pages     = {5164-5170},
  title     = {Scalable and memory-efficient algorithms for controlling networked epidemic processes using multiplicative weights update method},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CounterGeDi: A controllable approach to generate polite,
detoxified and emotional counterspeech. <em>IJCAI</em>, 5157–5163. (<a
href="https://doi.org/10.24963/ijcai.2022/716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance. In this paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT model toward more polite, detoxified, and emotionally laden counterspeech. We generate counterspeech using three datasets and observe significant improvement across different attribute scores. The politeness and detoxification scores increased by around 15\% and 6\% respectively, while the emotion in the counterspeech increased by at least 10\% across all the datasets. We also experiment with triple-attribute control and observe significant improvement over single attribute results when combining complementing attributes, e.g., politeness, joyfulness and detoxification. In all these experiments, the relevancy of the generated text does not deteriorate due to the application of these controls. Keywords: Natural Language Processing: Language Generation Multidisciplinary Topics and Applications: Social Sciences Natural Language Processing: Dialogue and Interactive Systems},
  archive   = {C_IJCAI},
  author    = {Punyajoy Saha and Kanishk Singh and Adarsh Kumar and Binny Mathew and Animesh Mukherjee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/716},
  pages     = {5157-5163},
  title     = {CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AgriBERT: Knowledge-infused agricultural language models for
matching food and nutrition. <em>IJCAI</em>, 5150–5156. (<a
href="https://doi.org/10.24963/ijcai.2022/715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Pretraining domain-specific language models remains an important challenge which limits their applicability in various areas such as agriculture. This paper investigates the effectiveness of leveraging food related text corpora (e.g., food and agricultural literature) in pretraining transformer-based language models. We evaluate our trained language model, called AgriBERT, on the task of semantic matching, i.e., establishing mapping between food descriptions and nutrition data, which is a long-standing challenge in the agricultural domain. In particular, we formulate the task as an answer selection problem, fine-tune the trained language model with the help of an external source of knowledge (e.g., FoodOn ontology), and establish a baseline for this task. The experimental results reveal that our language model substantially outperforms other language models and baselines in the task of matching food description and nutrition. Keywords: Natural Language Processing: Language Models Multidisciplinary Topics and Applications: Health and Medicine Natural Language Processing: Applications Natural Language Processing: Named Entities},
  archive   = {C_IJCAI},
  author    = {Saed Rezayi and Zhengliang Liu and Zihao Wu and Chandra Dhakal and Bao Ge and Chen Zhen and Tianming Liu and Sheng Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/715},
  pages     = {5150-5156},
  title     = {AgriBERT: Knowledge-infused agricultural language models for matching food and nutrition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DiRe committee: Diversity and representation constraints in
multiwinner elections. <em>IJCAI</em>, 5143–5149. (<a
href="https://doi.org/10.24963/ijcai.2022/714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The study of fairness in multiwinner elections focuses on settings where candidates have attributes. However, voters may also be divided into predefined populations under one or more attributes. The models that focus on candidate attributes alone may systematically under-represent smaller voter populations. Hence, we develop a model, DiRe Committee Winner Determination (DRCWD), which delineates candidate and voter attributes to select a committee by specifying diversity and representation constraints and a voting rule. We analyze its computational complexity and develop a heuristic algorithm, which finds the winning DiRe committee in under two minutes on 63\% of the instances of synthetic datasets and on 100\% of instances of real-world datasets. We also present an empirical analysis of feasibility and utility traded-off. Moreover, even when the attributes of candidates and voters coincide, it is important to treat them separately as diversity does not imply representation and vice versa. This is to say that having a female candidate on the committee, for example, is different from having a candidate on the committee who is preferred by the female voters, and who themselves may or may not be female. Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: General},
  archive   = {C_IJCAI},
  author    = {Kunal Relia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/714},
  pages     = {5143-5149},
  title     = {DiRe committee: Diversity and representation constraints in multiwinner elections},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ownership concentration and wealth inequality in russia.
<em>IJCAI</em>, 5136–5142. (<a
href="https://doi.org/10.24963/ijcai.2022/713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge of beneficial owners of companies is key to monitoring and managing wealth inequality in any country. Here we propose a robust and scalable network-based algorithm to reveal hidden ultimate owners in public ownership data. Our approach is based on the idea of Katz centrality in complex networks and circumvents the problem of cyclic ownership used to obscure effective control through closed chains of intermediaries. When applied to a country-scale directed ownership network with 6 million nodes, the algorithm identifies ultimate holders of every organisation in 2021’s Russia. The distribution of asset ownership in the country follows a power law, indicating strong wealth inequality with Gini index of 0.93. 51.7\% of net assets of non-financial companies are ultimately held by the state and state-owned enterprises, 25.0\% — by individuals (incl. 3.4\% held by Forbes–200-listed individuals), and 11.3\% are owned by foreign entities (incl. 5.7\% in tax havens). Keywords: Data Mining: Networks Multidisciplinary Topics and Applications: Computational Sustainability Multidisciplinary Topics and Applications: Databases Multidisciplinary Topics and Applications: Economics},
  archive   = {C_IJCAI},
  author    = {Kirill Polovnikov and Nikita Pospelov and Dmitriy Skougarevskiy},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/713},
  pages     = {5136-5142},
  title     = {Ownership concentration and wealth inequality in russia},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ADVISER: AI-driven vaccination intervention optimiser for
increasing vaccine uptake in nigeria. <em>IJCAI</em>, 5129–5135. (<a
href="https://doi.org/10.24963/ijcai.2022/712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {More than 5 million children under five years die from largely preventable or treatable medical conditions every year, with an overwhelmingly large proportion of deaths occurring in under-developed countries with low vaccination uptake. One of the United Nations&#39; sustainable development goals (SDG 3) aims to end preventable deaths of newborns and children under five years of age. We focus on Nigeria, where the rate of infant mortality is appalling. We collaborate with HelpMum, a large non-profit organization in Nigeria, to design and optimize the allocation of heterogeneous health interventions under uncertainty to increase vaccination uptake, the first such collaboration in Nigeria. Our framework, ADVISER: AI-Driven Vaccination Intervention Optimiser, is based on an integer linear program that seeks to maximize the cumulative probability of successful vaccination. Our optimization formulation is intractable in practice. We present a heuristic approach that enables us to solve the problem for real-world use-cases. We also present theoretical bounds for the heuristic method. Finally, we show that the proposed approach outperforms baseline methods in terms of vaccination uptake through experimental evaluation. HelpMum is currently planning a pilot program based on our approach to be deployed in the largest city of Nigeria, which would be the first deployment of an AI-driven vaccination uptake program in the country and hopefully, pave the way for other data-driven programs to improve health outcomes in Nigeria. Keywords: Search: Combinatorial Search and Optimisation AI Ethics, Trust, Fairness: Societal Impact of AI Constraint Satisfaction and Optimization: Constraint Optimization Multidisciplinary Topics and Applications: Sustainable Development Goals Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Vineet Nair and Kritika Prakash and Michael Wilbur and Aparna Taneja and Corrine Namblard and Oyindamola Adeyemo and Abhishek Dubey and Abiodun Adereni and Milind Tambe and Ayan Mukhopadhyay},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/712},
  pages     = {5129-5135},
  title     = {ADVISER: AI-driven vaccination intervention optimiser for increasing vaccine uptake in nigeria},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gigs with guarantees: Achieving fair wage for food delivery
workers. <em>IJCAI</em>, 5122–5128. (<a
href="https://doi.org/10.24963/ijcai.2022/711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the increasing popularity of food delivery platforms, it has become pertinent to look into the working conditions of the `gig&#39; workers in these platforms, especially providing them fair wages, reasonable working hours, and transparency on work availability. However, any solution to these problems must not degrade customer experience and be cost-effective to ensure that platforms are willing to adopt them. We propose Work4Food, which provides income guarantees to delivery agents, while minimizing platform costs and ensuring customer satisfaction. Work4Food ensures that the income guarantees are met in such a way that it does not lead to increased working hours or degrade environmental impact. To incorporate these objectives, Work4Food balances supply and demand by controlling the number of agents in the system and providing dynamic payment guarantees to agents based on factors such as agent location, ratings, etc. We evaluate Work4Food on a real-world dataset from a leading food delivery platform and establish its advantages over the state of the art in terms of the multi-dimensional objectives at hand. Keywords: AI Ethics, Trust, Fairness: AI and Law, Governance, Regulation AI Ethics, Trust, Fairness: Ethical, Legal and Societal Issues AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Ashish Nair and Rahul Yadav and Anjali Gupta and Abhijnan Chakraborty and Sayan Ranu and Amitabha Bagchi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/711},
  pages     = {5122-5128},
  title     = {Gigs with guarantees: Achieving fair wage for food delivery workers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reliability-aware distributed framework to schedule
residential charging of electric vehicles. <em>IJCAI</em>, 5115–5121.
(<a href="https://doi.org/10.24963/ijcai.2022/710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Residential consumers have become active participants in the power distribution network after being equipped with residential EV charging provisions. This creates a challenge for the network operator tasked with dispatching electric power to the residential consumers through the existing distribution network infrastructure in a reliable manner. In this paper, we address the problem of scheduling residential EV charging for multiple consumers while maintaining network reliability. An additional challenge is the restricted exchange of information: where the consumers do not have access to network information and the network operator does not have access to consumer load parameters. We propose a distributed framework which generates an optimal EV charging schedule for individual residential consumers based on their preferences and iteratively updates it until the network reliability constraints set by the operator are satisfied. We validate the proposed approach for different EV adoption levels in a synthetically created digital twin of an actual power distribution network. The results demonstrate that the new approach can achieve a higher level of network reliability compared to the case where residential consumers charge EVs based solely on their individual preferences, thus providing a solution for the existing grid to keep up with increased adoption rates without significant investments in increasing grid capacity. Keywords: Planning and Scheduling: Distributed; Multi-agent Planning Agent-based and Multi-agent Systems: Coordination and Cooperation AI Ethics, Trust, Fairness: Societal Impact of AI Constraint Satisfaction and Optimization: Constraint Optimization Planning and Scheduling: Scheduling},
  archive   = {C_IJCAI},
  author    = {Rounak Meyur and Swapna Thorve and Madhav Marathe and Anil Vullikanti and Samarth Swarup and Henning Mortveit},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/710},
  pages     = {5115-5121},
  title     = {A reliability-aware distributed framework to schedule residential charging of electric vehicles},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Creating dynamic checklists via bayesian case-based
reasoning: Towards decent working conditions for all. <em>IJCAI</em>,
5108–5114. (<a href="https://doi.org/10.24963/ijcai.2022/709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Every year there are 1.9 million deaths world-wide attributed to occupational health and safety risk factors. To address poor working conditions and fulfill UN&#39;s SDG 8, &quot;protect labour rights and promote safe working environments for all workers&quot;, governmental agencies conduct labour inspections, using checklists to survey individual organisations for working environment violations. Recent research highlights the benefits of using machine learning for creating checklists. However, the current methods only create static checklists and do not adapt them to new information that surfaces during use. In contrast, we propose a new method called Context-aware Bayesian Case-Based Reasoning (CBCBR) that creates dynamic checklists. These checklists are continuously adapted as the inspections progress, based on how they are answered. Our evaluations show that CBCBR&#39;s dynamic checklists outperform static checklists created via the current state-of-the-art methods, increasing the expected number of working environment violations found in the labour inspections. Keywords: Knowledge Representation and Reasoning: Case-based Reasoning Machine Learning: Recommender Systems Multidisciplinary Topics and Applications: Sustainable Development Goals Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Eirik Lund Flogard and Ole Jakob Mengshoel and Kerstin Bach},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/709},
  pages     = {5108-5114},
  title     = {Creating dynamic checklists via bayesian case-based reasoning: Towards decent working conditions for all},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). S2SNet: A pretrained neural network for superconductivity
discovery. <em>IJCAI</em>, 5101–5107. (<a
href="https://doi.org/10.24963/ijcai.2022/708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Superconductivity allows electrical current to flow without any energy loss, and thus making solids superconducting is a grand goal of physics, material science, and electrical engineering. More than 16 Nobel Laureates have been awarded for their contribution in superconductivity research. Superconductors are valuable for sustainable development goals (SDGs), such as climate change mitigation, affordable and clean energy, industry, innovation and infrastructure, and so on. However, a unified physics theory explaining all superconductivity mechanism is still unknown. It is believed that superconductivity is microscopically due to not only molecular compositions but also the geometric crystal structure. Hence a new dataset, S2S, containing both crystal structures and superconducting critical temperature, is built upon SuperCon and Material Project. Based on this new dataset, we propose a novel model, S2SNet, which utilizes the attention mechanism for superconductivity prediction. To overcome the shortage of data, S2SNet is pre-trained on the whole Material Project dataset with Masked-Language Modeling (MLM). S2SNet makes a new state-of-the-art, with out-of-sample accuracy of 92\% and Area Under Curve (AUC) of 0.92. To the best of our knowledge, S2SNet is the first work to predict superconductivity with only information of crystal structures. This work is beneficial to superconductivity discovery and further SDGs. The code and datasets are available at https://github.com/supercond/S2SNet Keywords: Multidisciplinary Topics and Applications: Physical Science},
  archive   = {C_IJCAI},
  author    = {Ke Liu and Kaifan Yang and Jiahong Zhang and Renjun Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/708},
  pages     = {5101-5107},
  title     = {S2SNet: A pretrained neural network for superconductivity discovery},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards the quantitative interpretability analysis of
citizens happiness prediction. <em>IJCAI</em>, 5094–5100. (<a
href="https://doi.org/10.24963/ijcai.2022/707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluating the high-effect factors of citizens&#39; happiness is beneficial to a wide range of policy-making for economics and politics in most countries. Benefiting from the high-efficiency of regression models, previous efforts by sociology scholars have analyzed the effect of happiness factors with high interpretability. However, restricted to their research concerns, they are specifically interested in some subset of factors modeled as linear functions. Recently, deep learning shows promising prediction accuracy while addressing challenges in interpretability. To this end, we introduce Shapley value that is inherent in solid theory for factor contribution interpretability to work with deep learning models by taking into account interactions between multiple factors. The proposed solution computes the Shapley value of a factor, i.e., its average contribution to the prediction in different coalitions based on coalitional game theory. Aiming to evaluate the interpretability quality of our solution, experiments are conducted on a Chinese General Social Survey (CGSS) questionnaire dataset. Through systematic reviews, the experimental results of Shapley value are highly consistent with academic studies in social science, which implies our solution for citizens&#39; happiness prediction has 2-fold implications, theoretically and practically. Keywords: Humans and AI: Computational Sustainability and Human Well-Being AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Societal Impact of AI Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Lin Li and Xiaohua Wu and Miao Kong and Dong Zhou and Xiaohui Tao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/707},
  pages     = {5094-5100},
  title     = {Towards the quantitative interpretability analysis of citizens happiness prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Crowd, expert &amp; AI: A human-AI interactive approach
towards natural language explanation based COVID-19 misinformation
detection. <em>IJCAI</em>, 5087–5093. (<a
href="https://doi.org/10.24963/ijcai.2022/706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study an explainable COVID-19 misinformation detection problem where the goal is to accurately identify COVID-19 misleading posts on social media and explain the posts with natural language explanations (NLEs). Our problem is motivated by the limitations of current explainable misinformation detection approaches that cannot provide NLEs for COVID-19 posts due to the lack of sufficient professional COVID-19 knowledge for supervision. To address such a limitation, we develop CEA-COVID, a crowd-expert-AI framework that jointly exploits the common logical reasoning ability of online crowd workers and the professional knowledge of COVID-19 experts to effectively generate NLEs for detecting and explaining COVID-19 misinformation. We evaluate CEA-COVID using two public COVID-19 misinformation datasets on social media. Results demonstrate that CEA-COVID outperforms existing explainable misinformation detection models in terms of both explainability and detection accuracy. Keywords: Humans and AI: Human-AI Collaboration Humans and AI: Applications},
  archive   = {C_IJCAI},
  author    = {Ziyi Kou and Lanyu Shang and Yang Zhang and Zhenrui Yue and Huimin Zeng and Dong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/706},
  pages     = {5087-5093},
  title     = {Crowd, expert &amp;amp; AI: A human-AI interactive approach towards natural language explanation based COVID-19 misinformation detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AI facilitated isolations? The impact of
recommendation-based influence diffusion in human society.
<em>IJCAI</em>, 5080–5086. (<a
href="https://doi.org/10.24963/ijcai.2022/705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {AI recommendation techniques provide users with personalized services, feeding them the information they may be interested in. The increasing personalization raises the hypotheses of the &quot;filter bubble&quot; and &quot;echo chamber&quot; effects. To investigate these hypotheses, in this paper, we inspect the impact of recommendation algorithms on forming two types of ideological isolation, i.e., the individual isolation and the topological isolation, in terms of the filter bubble and echo chamber effects, respectively. Simulation results show that AI recommendation strategies severely facilitate the evolution of the filter bubble effect, leading users to become ideologically isolated at an individual level. Whereas, at a topological level, recommendation algorithms show eligibility in connecting individuals with dissimilar users or recommending diverse topics to receive more diverse viewpoints. This research sheds light on the ability of AI recommendation strategies to temper ideological isolation at a topological level. Keywords: Humans and AI: General Humans and AI: Personalization and User Modeling AI Ethics, Trust, Fairness: Societal Impact of AI Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence},
  archive   = {C_IJCAI},
  author    = {Yuxuan Hu and Shiqing Wu and Chenting Jiang and Weihua Li and Quan Bai and Erin Roehrer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/705},
  pages     = {5080-5086},
  title     = {AI facilitated isolations? the impact of recommendation-based influence diffusion in human society},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Am i no good? Towards detecting perceived burdensomeness and
thwarted belongingness from suicide notes. <em>IJCAI</em>, 5073–5079.
(<a href="https://doi.org/10.24963/ijcai.2022/704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The World Health Organization (WHO) has emphasized the importance of significantly accelerating suicide prevention efforts to fulfill the United Nations&#39; Sustainable Development Goal (SDG) objective of 2030. In this paper, we present an end-to-end multitask system to address a novel task of detection of two interpersonal risk factors of suicide, Perceived Burdensomeness (PB) and Thwarted Belongingness (TB) from suicide notes. We also introduce a manually translated code-mixed suicide notes corpus, CoMCEASE-v2.0, based on the benchmark CEASE-v2.0 dataset, annotated with temporal orientation, PB and TB labels. We exploit the temporal orientation and emotion information in the suicide notes to boost overall performance. For comprehensive evaluation of our proposed method, we compare it to several state-of-the-art approaches on the existing CEASE-v2.0 dataset and the newly announced CoMCEASE-v2.0 dataset. Empirical evaluation suggests that temporal and emotional information can substantially improve the detection of PB and TB. Keywords: Humans and AI: Computational Sustainability and Human Well-Being Machine Learning: Attention Models Machine Learning: Multi-task and Transfer Learning Natural Language Processing: Resources and Evaluation Natural Language Processing: Sentiment Analysis and Text Mining},
  archive   = {C_IJCAI},
  author    = {Soumitra Ghosh and Asif Ekbal and Pushpak Bhattacharyya},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/704},
  pages     = {5073-5079},
  title     = {Am i no good? towards detecting perceived burdensomeness and thwarted belongingness from suicide notes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monitoring vegetation from space at extremely fine
resolutions via coarsely-supervised smooth u-net. <em>IJCAI</em>,
5066–5072. (<a href="https://doi.org/10.24963/ijcai.2022/703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monitoring vegetation productivity at extremely fine resolutions is valuable for real-world agricultural applications, such as detecting crop stress and providing early warning of food insecurity. Solar-Induced Chlorophyll Fluorescence (SIF) provides a promising way to directly measure plant productivity from space. However, satellite SIF observations are only available at a coarse spatial resolution, making it impossible to monitor how individual crop types or farms are doing. This poses a challenging coarsely-supervised regression (or downscaling) task; at training time, we only have SIF labels at a coarse resolution (3km), but we want to predict SIF at much finer spatial resolutions (e.g. 30m, a 100x increase). We also have additional fine-resolution input features, but the relationship between these features and SIF is unknown. To address this, we propose Coarsely-Supervised Smooth U-Net (CS-SUNet), a novel method for this coarse supervision setting. CS-SUNet combines the expressive power of deep convolutional networks with novel regularization methods based on prior knowledge (such as a smoothness loss) that are crucial for preventing overfitting. Experiments show that CS-SUNet resolves fine-grained variations in SIF more accurately than existing methods. Keywords: Multidisciplinary Topics and Applications: Computational Sustainability Machine Learning: Weakly Supervised Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Machine Learning: Multi-instance Computer Vision: Applications Multidisciplinary Topics and Applications: Sustainable Development Goals},
  archive   = {C_IJCAI},
  author    = {Joshua Fan and Di Chen and Jiaming Wen and Ying Sun and Carla Gomes},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/703},
  pages     = {5066-5072},
  title     = {Monitoring vegetation from space at extremely fine resolutions via coarsely-supervised smooth U-net},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A murder and protests, the capitol riot, and the chauvin
trial: Estimating disparate news media stance. <em>IJCAI</em>,
5059–5065. (<a href="https://doi.org/10.24963/ijcai.2022/702">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we analyze the responses of three major US cable news networks to three seminal policing events in the US spanning a thirteen month period--the murder of George Floyd by police officer Derek Chauvin, the Capitol riot, Chauvin&#39;s conviction, and his sentencing. We cast the problem of aggregate stance mining as a natural language inference task and construct an active learning pipeline for robust textual entailment prediction. Via a substantial corpus of 34, 710 news transcripts, our analyses reveal that the partisan divide in viewership of these three outlets reflects on the network&#39;s news coverage of these momentous events. In addition, we release a sentence-level, domain-specific text entailment data set on policing consisting of 2, 276 annotated instances. Keywords: Multidisciplinary Topics and Applications: Social Sciences Machine Learning: Active Learning Multidisciplinary Topics and Applications: News and Media},
  archive   = {C_IJCAI},
  author    = {Sujan Dutta and Beibei Li and Daniel S. Nagin and Ashiqur R. KhudaBukhsh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/702},
  pages     = {5059-5065},
  title     = {A murder and protests, the capitol riot, and the chauvin trial: Estimating disparate news media stance},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forecasting patient outcomes in kidney exchange.
<em>IJCAI</em>, 5052–5058. (<a
href="https://doi.org/10.24963/ijcai.2022/701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Kidney exchanges allow patients with end-stage renal disease to find a lifesaving living donor by way of an organized market. However, not all patients are equally easy to match, nor are all donor organs of equal quality---some patients are matched within weeks, while others may wait for years with no match offers at all. We propose the first decision-support tool for kidney exchange that takes as input the biological features of a patient-donor pair, and returns (i) the probability of being matched prior to expiry, and (conditioned on a match outcome), (ii) the waiting time for and (iii) the organ quality of the matched transplant. This information may be used to inform medical and insurance decisions. We predict all quantities (i, ii, iii) exclusively from match records that are readily available in any kidney exchange using a quantile random forest approach. To evaluate our approach, we developed two state-of-the-art realistic simulators based on data from the United Network for Organ Sharing that sample from the training and test distribution for these learning tasks---in our application these distributions are distinct. We analyze distributional shift through a theoretical lens, and show that the two distributions converge as the kidney exchange nears steady-state. We then show that our approach produces clinically-promising estimates using simulated data. Finally, we show how our approach, in conjunction with tools from the model explainability literature, can be used to calibrate and detect bias in matching policies. Keywords: Multidisciplinary Topics and Applications: Health and Medicine Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Naveen Durvasula and Aravind Srinivasan and John Dickerson},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/701},
  pages     = {5052-5058},
  title     = {Forecasting patient outcomes in kidney exchange},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AggPose: Deep aggregation vision transformer for infant pose
estimation. <em>IJCAI</em>, 5045–5051. (<a
href="https://doi.org/10.24963/ijcai.2022/700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Movement and pose assessment of newborns lets experienced pediatricians predict neurodevelopmental disorders, allowing early intervention for related diseases. However, most of the newest AI approaches for human pose estimation methods focus on adults, lacking publicly benchmark for infant pose estimation. In this paper, we fill this gap by proposing infant pose dataset and Deep Aggregation Vision Transformer for human pose estimation, which introduces a fast trained full transformer framework without using convolution operations to extract features in the early stages. It generalizes Transformer + MLP to high-resolution deep layer aggregation within feature maps, thus enabling information fusion between different vision levels. We pre-train AggPose on COCO pose dataset and apply it on our newly released large-scale infant pose estimation dataset. The results show that AggPose could effectively learn the multi-scale features among different resolutions and significantly improve the performance of infant pose estimation. We show that AggPose outperforms hybrid model HRFormer and TokenPose in the infant pose estimation dataset. Moreover, our AggPose outperforms HRFormer by 0.8 AP on COCO val pose estimation on average. Our code is available at github.com/SZAR-LAB/AggPose. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Multidisciplinary Topics and Applications: Health and Medicine Computer Vision: Biomedical Image Analysis Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Xu Cao and Xiaoye Li and Liya Ma and Yi Huang and Xuan Feng and Zening Chen and Hongwu Zeng and Jianguo Cao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/700},
  pages     = {5045-5051},
  title     = {AggPose: Deep aggregation vision transformer for infant pose estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Chronic disease management with personalized lab test
response prediction. <em>IJCAI</em>, 5038–5044. (<a
href="https://doi.org/10.24963/ijcai.2022/699">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Chronic disease management involves frequent administration of invasive lab procedures in order for clinicians to determine the best course of treatment regimes for these patients. However, patients are often put off by these invasive lab procedures and do not follow the appointment schedules. This has resulted in poor management of their chronic conditions leading to unnecessary disease complications. An AI system that is able to personalize the prediction of individual patient lab test responses will enable clinicians to titrate the medications to achieve the desired therapeutic outcome. Accurate prediction of lab test response is a challenge because these patients typically have co-morbidities and their treatments might influence the target lab test response. To address this, we model the complex interactions among different medications, diseases, lab test response, and fine-grained dosage information to learn a strong patient representation. Together with information from similar patients and external knowledge such as drug-lab interactions and diagnosis-lab interaction, we design a system called KALP to perform personalized prediction of patients’ response for a target lab result and identify the top influencing factors for the prediction. Experiment results on real-world datasets demonstrate the effectiveness of KALP in reducing prediction errors by a significant margin. Case studies show that the identified factors are consistent with clinicians’ understanding. Keywords: Humans and AI: Personalization and User Modeling Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Suman Bhoi and Mong Li Lee and Wynne Hsu and Hao Sen Andrew Fang and Ngiap Chuan Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/699},
  pages     = {5038-5044},
  title     = {Chronic disease management with personalized lab test response prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deciphering environmental air pollution with large scale
city data. <em>IJCAI</em>, 5031–5037. (<a
href="https://doi.org/10.24963/ijcai.2022/698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Air pollution poses a serious threat to sustainable environmental conditions in the 21st century. Its importance in determining the health and living standards in urban settings is only expected to increase with time. Various factors ranging from artificial emissions to natural phenomena are known to be primary causal agents or influencers behind rising air pollution levels. However, the lack of large scale data involving the major artificial and natural factors has hindered the research on the causes and relations governing the variability of the different air pollutants. Through this work, we introduce a large scale city-wise dataset for exploring the relationships among these agents over a long period of time. We also introduce a transformer based model - cosSquareFormer, for the problem of pollutant level estimation and forecasting. Our model outperforms most of the benchmark models for this task. We also analyze and explore the dataset through our model and other methodologies to bring out important inferences which enable us to understand the dynamics of the casual agents at a deeper level. Through our paper, we seek to provide a great set of foundations for further research into this domain that will demand critical attention of ours in the near future. Keywords: Multidisciplinary Topics and Applications: Sustainable Development Goals Machine Learning: Recurrent Networks Machine Learning: Attention Models Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Time-series; Data Streams Data Mining: Exploratory Data Mining Data Mining: Mining Data Streams Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Mayukh Bhattacharyya and Sayan Nag and Udita Ghosh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/698},
  pages     = {5031-5037},
  title     = {Deciphering environmental air pollution with large scale city data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning pollution maps from mobile phone images.
<em>IJCAI</em>, 5024–5030. (<a
href="https://doi.org/10.24963/ijcai.2022/697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Air pollution monitoring and management is one of the key challenges for urban sectors, especially in developing countries. Measuring pollution levels requires significant investment in reliable and durable instrumentation and subsequent maintenance. On the other hand, there have been many attempts by researchers to develop image-based pollution measurement models which have shown significant results and established the feasibility of the idea. But, taking image-level models to a city-level system presents new challenges, which include scarcity of high-quality annotated data and a high amount of label noise. In this paper, we present a low-cost, end-to-end system for learning pollution maps using images captured through a mobile phone. We demonstrate our system for parts of New Delhi and Ghaziabad. We use transfer learning to overcome the problem of data scarcity. We investigate the effects of label noise in detail and introduce the metric of in-interval accuracy to evaluate our models in presence of noise. We use distributed averaging to learn pollution maps and mitigate the effects of noise to some extent. We also develop haze-based interpretable models which have comparable performance to mainstream models. With only 382 images from Delhi and Ghaziabad and single-scene dataset from Beijing and Shanghai, we are able to achieve a mean absolute error of 44 ug/m^3 in PM2.5 concentration on a test set of 267 images and an in-interval accuracy of 67\% on predictions. Going further, we learn pollution maps with a mean absolute error as low as 35 ug/m^3 and in-interval accuracy as high as 74\% significantly mitigating the image models&#39; error. We also show that the noise in pollution labels emerging from unreliable sensing instrumentation forms a significant barrier to the realization of an ideal air pollution monitoring system. Our codebase can be found at https://github.com/ankitbha/pollution_with_images. Keywords: Humans and AI: Computational Sustainability and Human Well-Being Computer Vision: Applications Computer Vision: Interpretability and Transparency Machine Learning: Applications Machine Learning: Ensemble Methods Machine Learning: Explainable/Interpretable Machine Learning Multidisciplinary Topics and Applications: Computational Sustainability Multidisciplinary Topics and Applications: Sustainable Development Goals},
  archive   = {C_IJCAI},
  author    = {Ankit Bhardwaj and Shiva Iyer and Yash Jalan and Lakshminarayanan Subramanian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/697},
  pages     = {5024-5030},
  title     = {Learning pollution maps from mobile phone images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to generate poetic chinese landscape painting with
calligraphy. <em>IJCAI</em>, 5019–5022. (<a
href="https://doi.org/10.24963/ijcai.2022/696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a novel system (denoted as Polaca) to generate poetic Chinese landscape painting with calligraphy. Unlike previous single image-to-image painting generation, Polaca takes the classic poetry as input and outputs the artistic landscape painting image with the corresponding calligraphy. It is equipped with three different modules to complete the whole piece of landscape painting artwork: the first one is a text-to-image module to generate landscape painting image, the second one is an image-to-image module to generate stylistic calligraphy image, and the third one is an image fusion module to fuse the two images into a whole piece of aesthetic artwork. Keywords: Application domains: Images and visual arts Application domains: Other domains of art or creativity Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Theory and philosophy of arts and creativity in AI systems: Support of human creativity},
  archive   = {C_IJCAI},
  author    = {Shaozu Yuan and Aijun Dai and Zhiling Yan and Ruixue Liu and Meng Chen and Baoyang Chen and Zhijie Qiu and Xiaodong He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/696},
  pages     = {5019-5022},
  title     = {Learning to generate poetic chinese landscape painting with calligraphy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-resolution and arbitrary-sized chinese landscape
painting creation based on generative adversarial networks.
<em>IJCAI</em>, 5015–5018. (<a
href="https://doi.org/10.24963/ijcai.2022/695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper outlines an automated creation system for Chinese landscape paintings based on generative adversarial networks. The system consists of three cascaded modules: generation, resizing, and super-resolution. The generation module first generates a square-shaped painting, then the resizing module predicts an appropriate aspect ratio for it and performs resizing, and finally the super-resolution module is used to increase the resolution and improve the quality. After training each module with the images we collected from the web, our system can create high-resolution landscape paintings in arbitrary sizes. Keywords: Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Application domains: Images and visual arts},
  archive   = {C_IJCAI},
  author    = {Peixiang Luo and Jinchao Zhang and Jie Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/695},
  pages     = {5015-5018},
  title     = {High-resolution and arbitrary-sized chinese landscape painting creation based on generative adversarial networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Captioning bosch: A twitter bot. <em>IJCAI</em>, 5011–5014.
(<a href="https://doi.org/10.24963/ijcai.2022/694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The artworks by Dutch painter Hieronymus Bosch are well known for their incredible wealth of details. The popular BoschBot regularly posts small segments of the digitized paintings on Twitter, thus relieving their density and making them more accessible. CaptioningBoschBot, the Twitter bot presented in this demo, reverses the creative process of the artist: It uses the out-of-context painting segments as input for an encoder-decoder model to generate captions that interpret the painted objects. As the model was only trained on realistic, photographic images, curious interpretations of the otherworldly details can be observed. The generated captions are again posted on Twitter to encourage discussions about Bosch&#39;s masterpieces and the AI technology in general. Keywords: Application domains: Text, literature and creative language Application domains: Images and visual arts Methods and resources: Applications and software frameworks Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Cornelia Ferner},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/694},
  pages     = {5011-5014},
  title     = {Captioning bosch: A twitter bot},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Style fader generative adversarial networks for style degree
controllable artistic style transfer. <em>IJCAI</em>, 5002–5009. (<a
href="https://doi.org/10.24963/ijcai.2022/693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Artistic style transfer is the task of synthesizing content images with learned artistic styles. Recent studies have shown the potential of Generative Adversarial Networks (GANs) for producing artistically rich stylizations. Despite the promising results, they usually fail to control the generated images&#39; style degree, which is inflexible and limits their applicability for practical use. To address the issue, in this paper, we propose a novel method that for the first time allows adjusting the style degree for existing GAN-based artistic style transfer frameworks in real time after training. Our method introduces two novel modules into existing GAN-based artistic style transfer frameworks: a Style Scaling Injection (SSI) module and a Style Degree Interpretation (SDI) module. The SSI module accepts the value of Style Degree Factor (SDF) as the input and outputs parameters that scale the feature activations in existing models, offering control signals to alter the style degrees of the stylizations. And the SDI module interprets the output probabilities of a multi-scale content-style binary classifier as the style degrees, providing a mechanism to parameterize the style degree of the stylizations. Moreover, we show that after training our method can enable existing GAN-based frameworks to produce over-stylizations. The proposed method can facilitate many existing GAN-based artistic style transfer frameworks with marginal extra training overheads and modifications. Extensive qualitative evaluations on two typical GAN-based style transfer models demonstrate the effectiveness of the proposed method for gaining style degree control for them. Keywords: Application domains: Images and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Zhiwen Zuo and Lei Zhao and Shuobin Lian and Haibo Chen and Zhizhong Wang and Ailin Li and Wei Xing and Dongming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/693},
  pages     = {5002-5009},
  title     = {Style fader generative adversarial networks for style degree controllable artistic style transfer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Composition-aware graphic layout GAN for visual-textual
presentation designs. <em>IJCAI</em>, 4995–5001. (<a
href="https://doi.org/10.24963/ijcai.2022/692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study the graphic layout generation problem of producing high-quality visual-textual presentation designs for given images. We note that image compositions, which contain not only global semantics but also spatial information, would largely affect layout results. Hence, we propose a deep generative model, dubbed as composition-aware graphic layout GAN (CGL-GAN), to synthesize layouts based on the global and spatial visual contents of input images. To obtain training images from images that already contain manually designed graphic layout data, previous work suggests masking design elements (e.g., texts and embellishments) as model inputs, which inevitably leaves hint of the ground truth. We study the misalignment between the training inputs (with hint masks) and test inputs (without masks), and design a novel domain alignment module (DAM) to narrow this gap. For training, we built a large-scale layout dataset which consists of 60, 548 advertising posters with annotated layout information. To evaluate the generated layouts, we propose three novel metrics according to aesthetic intuitions. Through both quantitative and qualitative evaluations, we demonstrate that the proposed model can synthesize high-quality graphic layouts according to image compositions. The data and code will be available at https://github.com/minzhouGithub/CGL-GAN. Keywords: Application domains: Images and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Min Zhou and Chenchen Xu and Ye Ma and Tiezheng Ge and Yuning Jiang and Weiwei Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/692},
  pages     = {4995-5001},
  title     = {Composition-aware graphic layout GAN for visual-textual presentation designs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Music-to-dance generation with optimal transport.
<em>IJCAI</em>, 4988–4994. (<a
href="https://doi.org/10.24963/ijcai.2022/691">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dance choreography for a piece of music is a challenging task, having to be creative in presenting distinctive stylistic dance elements while taking into account the musical theme and rhythm. It has been tackled by different approaches such as similarity retrieval, sequence-to-sequence modeling and generative adversarial networks, but their generated dance sequences are often short of motion realism, diversity and music consistency. In this paper, we propose a Music-to-Dance with Optimal Transport Network (MDOT-Net) for learning to generate 3D dance choreographies from music. We introduce an optimal transport distance for evaluating the authenticity of the generated dance distribution and a Gromov-Wasserstein distance to measure the correspondence between the dance distribution and the input music. This gives a well defined and non-divergent training objective that mitigates the limitation of standard GAN training which is frequently plagued with instability and divergent generator loss issues. Extensive experiments demonstrate that our MDOT-Net can synthesize realistic and diverse dances which achieve an organic unity with the input music, reflecting the shared intentionality and matching the rhythmic articulation. Sample results are found at https://www.youtube.com/watch?v=dErfBkrlUO8. Keywords: Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Application domains: Performances, dance Application domains: Music},
  archive   = {C_IJCAI},
  author    = {Shuang Wu and Shijian Lu and Li Cheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/691},
  pages     = {4988-4994},
  title     = {Music-to-dance generation with optimal transport},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DivSwapper: Towards diversified patch-based arbitrary style
transfer. <em>IJCAI</em>, 4980–4987. (<a
href="https://doi.org/10.24963/ijcai.2022/690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gram-based and patch-based approaches are two important research lines of style transfer. Recent diversified Gram-based methods have been able to produce multiple and diverse stylized outputs for the same content and style images. However, as another widespread research interest, the diversity of patch-based methods remains challenging due to the stereotyped style swapping process based on nearest patch matching. To resolve this dilemma, in this paper, we dive into the crux of existing patch-based methods and propose a universal and efficient module, termed DivSwapper, for diversified patch-based arbitrary style transfer. The key insight is to use an essential intuition that neural patches with higher activation values could contribute more to diversity. Our DivSwapper is plug-and-play and can be easily integrated into existing patch-based and Gram-based methods to generate diverse results for arbitrary styles. We conduct theoretical analyses and extensive experiments to demonstrate the effectiveness of our method, and compared with state-of-the-art algorithms, it shows superiority in diversity, quality, and efficiency. Keywords: Application domains: Images and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI},
  archive   = {C_IJCAI},
  author    = {Zhizhong Wang and Lei Zhao and Haibo Chen and Zhiwen Zuo and Ailin Li and Wei Xing and Dongming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/690},
  pages     = {4980-4987},
  title     = {DivSwapper: Towards diversified patch-based arbitrary style transfer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dataset augmentation in papyrology with generative models: A
study of synthetic ancient greek character images. <em>IJCAI</em>,
4973–4979. (<a href="https://doi.org/10.24963/ijcai.2022/689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Character recognition models rely substantially on image datasets that maintain a balance of class samples. However, achieving a balance of classes is particularly challenging for ancient manuscript contexts as character instances may be significantly limited. In this paper, we present findings from a study that assess the efficacy of using synthetically generated character instances to augment an existing dataset of ancient Greek character images for use in machine learning models. We complement our model exploration by engaging professional papyrologists to better understand the practical opportunities afforded by synthetic instances. Our results suggest that synthetic instances improve model performance for limited character classes, and may have unexplored effects on character classes more generally. We also find that trained papyrologists are unable to distinguish between synthetic and non-synthetic images and regard synthetic instances as valuable assets for professional and educational contexts. We conclude by discussing the practical implications of our research. Keywords: Application domains: Text, literature and creative language Application domains: Other domains of art or creativity Methods and resources: Datasets, knowledge bases and ontologies Theory and philosophy of arts and creativity in AI systems: Support of human creativity},
  archive   = {C_IJCAI},
  author    = {Matthew I. Swindall and Timothy Player and Ben Keener and Alex C. Williams and James H. Brusuelas and Federica Nicolardi and Marzia D&#39;Angelo and Claudio Vergara and Michael McOsker and John F. Wallin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/689},
  pages     = {4973-4979},
  title     = {Dataset augmentation in papyrology with generative models: A study of synthetic ancient greek character images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). StyleCLIPDraw: Coupling content and style in text-to-drawing
translation. <em>IJCAI</em>, 4966–4972. (<a
href="https://doi.org/10.24963/ijcai.2022/688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating images that fit a given text description using machine learning has improved greatly with the release of technologies such as the CLIP image-text encoder model; however, current methods lack artistic control of the style of image to be generated. We present an approach for generating styled drawings for a given text description where a user can specify a desired drawing style using a sample image. Inspired by a theory in art that style and content are generally inseparable during the creative process, we propose a coupled approach, known here as StyleCLIPDraw, whereby the drawing is generated by optimizing for style and content simultaneously throughout the process as opposed to applying style transfer after creating content in a sequence. Based on human evaluation, the styles of images generated by StyleCLIPDraw are strongly preferred to those by the sequential approach. Although the quality of content generation degrades for certain styles, overall considering both content and style, StyleCLIPDraw is found far more preferred, indicating the importance of style, look, and feel of machine generated images to people as well as indicating that style is coupled in the drawing process itself. Our code, a demonstration, and style evaluation data are publicly available. Keywords: Application domains: Images and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Theory and philosophy of arts and creativity in AI systems: Evaluation of artistic or creative outputs, or of systems},
  archive   = {C_IJCAI},
  author    = {Peter Schaldenbrand and Zhixuan Liu and Jean Oh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/688},
  pages     = {4966-4972},
  title     = {StyleCLIPDraw: Coupling content and style in text-to-drawing translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Universal video style transfer via crystallization,
separation, and blending. <em>IJCAI</em>, 4957–4965. (<a
href="https://doi.org/10.24963/ijcai.2022/687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Universal video style transfer aims to migrate arbitrary styles to input videos. However, how to maintain the temporal consistency of videos while achieving high-quality arbitrary style transfer is still a hard nut to crack. To resolve this dilemma, in this paper, we propose the CSBNet which involves three key modules: 1) the Crystallization (Cr) Module that generates several orthogonal crystal nuclei, representing hierarchical stability-aware content and style components, from raw VGG features; 2) the Separation (Sp) Module that separates these crystal nuclei to generate the stability-enhanced content and style features; 3) the Blending (Bd) Module to cross-blend these stability-enhanced content and style features, producing more stable and higher-quality stylized videos. Moreover, we also introduce a new pair of component enhancement losses to improve network performance. Extensive qualitative and quantitative experiments are conducted to demonstrate the effectiveness and superiority of our CSBNet. Compared with the state-of-the-art models, it not only produces temporally more consistent and stable results for arbitrary videos but also achieves higher-quality stylizations for arbitrary images. Keywords: Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Haofei Lu and Zhizhong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/687},
  pages     = {4957-4965},
  title     = {Universal video style transfer via crystallization, separation, and blending},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated sifting of stories from simulated storyworlds.
<em>IJCAI</em>, 4950–4956. (<a
href="https://doi.org/10.24963/ijcai.2022/686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Story sifting (or story recognition) allows for the exploration of events, stories, and patterns that emerge from simulated storyworlds. The goal of this work is to reduce the authoring burden for creating sifting queries. In this paper, we use the event traces of simulated storyworlds to create Dynamic Character Networks that track the changing relationship scores between characters in a simulation. These networks allow for the fortunes between any two characters to be plotted against time as a story arc. Similarity scores between story arcs from the simulation and a user’s query arc can be calculated using the Dynamic Time Warping algorithm. Events corresponding to the story arc that best matches the query arc can then be returned to the user, thus providing an intuitive means for users to sift a variety of stories without coding a search query. These components are implemented in our experimental prototype ARC SIFT. The results of a user study support our expectation that ARC SIFT is an intuitive and accurate tool that allows human users to sift stories out from a larger chronicle of events emerging from a simulated story world. Keywords: Application domains: Text, literature and creative language Application domains: User interfaces Theory and philosophy of arts and creativity in AI systems: Support of human creativity Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Application domains: Ideation Application domains: Games Theory and philosophy of arts and creativity in AI systems: Evaluation of artistic or creative outputs, or of systems Methods and resources: Other methods or resources},
  archive   = {C_IJCAI},
  author    = {Wilkins Leong and Julie Porteous and John Thangarajah},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/686},
  pages     = {4950-4956},
  title     = {Automated sifting of stories from simulated storyworlds},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Threshold designer adaptation: Improved adaptation for
designers in co-creative systems. <em>IJCAI</em>, 4943–4949. (<a
href="https://doi.org/10.24963/ijcai.2022/685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To best assist human designers with different styles, Machine Learning (ML) systems need to be able to adapt to them. However, there has been relatively little prior work on how and when to best adapt an ML system to a co-designer. In this paper we present threshold designer adaptation: a novel method for adapting a creative ML model to an individual designer. We evaluate our approach with a human subject study using a co-creative rhythm game design tool. We find that designers prefer our proposed method and produce higher quality content in comparison to an existing baseline. Keywords: Application domains: Games Theory and philosophy of arts and creativity in AI systems: Support of human creativity Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Emily Halina and Matthew Guzdial},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/685},
  pages     = {4943-4949},
  title     = {Threshold designer adaptation: Improved adaptation for designers in co-creative systems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Art creation with multi-conditional StyleGANs.
<em>IJCAI</em>, 4936–4942. (<a
href="https://doi.org/10.24963/ijcai.2022/684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Creating art is often viewed as a uniquely human endeavor. In this paper, we introduce a multi-conditional Generative Adversarial Network (GAN) approach trained on large amounts of human paintings to synthesize realistic-looking paintings that emulate human art. Our approach is based on the StyleGAN neural network architecture, but incorporates a custom multi-conditional control mechanism that provides fine-granular control over characteristics of the generated paintings, e.g., with regard to the perceived emotion evoked in a spectator. We also investigate several evaluation techniques tailored to multi-conditional generation. Keywords: Application domains: Images and visual arts Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Konstantin Dobler and Florian Hübscher and Jan Westphal and Alejandro Sierra-Múnera and Gerard de Melo and Ralf Krestel},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/684},
  pages     = {4936-4942},
  title     = {Art creation with multi-conditional StyleGANs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards creativity characterization of generative models via
group-based subset scanning. <em>IJCAI</em>, 4929–4935. (<a
href="https://doi.org/10.24963/ijcai.2022/683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep generative models, such as Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), have been employed widely in computational creativity research. However, such models discourage out-of-distribution generation to avoid spurious sample generation, thereby limiting their creativity. Thus, incorporating research on human creativity into generative deep learning techniques presents an opportunity to make their outputs more compelling and human-like. As we see the emergence of generative models directed toward creativity research, a need for machine learning-based surrogate metrics to characterize creative output from these models is imperative. We propose group-based subset scanning to identify, quantify, and characterize creative processes by detecting a subset of anomalous node-activations in the hidden layers of the generative models. Our experiments on the standard image benchmarks and their ``creatively generated&#39;&#39; variants reveal that the proposed subset scores distribution is more useful for detecting novelty in creative processes in the activation space rather than the pixel space. Further, we found that creative samples generate larger subsets of anomalies than normal or non-creative samples across datasets. The node activations highlighted during the creative decoding process are different from those responsible for the normal sample generation. Lastly, we assess if the images from the subsets selected by our method were also found creative by human evaluators, presenting a link between creativity perception in humans and node activations within deep neural nets. Keywords: Theory and philosophy of arts and creativity in AI systems: Evaluation of artistic or creative outputs, or of systems Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Theory and philosophy of arts and creativity in AI systems: Autonomous creative or artistic AI Theory and philosophy of arts and creativity in AI systems: Support of human creativity},
  archive   = {C_IJCAI},
  author    = {Celia Cintas and Payel Das and Brian Quanz and Girmaw Abebe Tadesse and Skyler Speakman and Pin-Yu Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/683},
  pages     = {4929-4935},
  title     = {Towards creativity characterization of generative models via group-based subset scanning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sound2Synth: Interpreting sound via FM synthesizer
parameters estimation. <em>IJCAI</em>, 4921–4928. (<a
href="https://doi.org/10.24963/ijcai.2022/682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthesizer is a type of electronic musical instrument that is now widely used in modern music production and sound design. Each parameters configuration of a synthesizer produces a unique timbre and can be viewed as a unique instrument. The problem of estimating a set of parameters configuration that best restore a sound timbre is an important yet complicated problem, i.e.: the synthesizer parameters estimation problem. We proposed a multi-modal deep-learning-based pipeline Sound2Synth, together with a network structure Prime-Dilated Convolution (PDC) specially designed to solve this problem. Our method achieved not only SOTA but also the first real-world applicable results on Dexed synthesizer, a popular FM synthesizer. Keywords: Application domains: Music Methods and resources: Machine learning, deep learning, neural models, reinforcement learning},
  archive   = {C_IJCAI},
  author    = {Zui Chen and Yansen Jing and Shengcheng Yuan and Yifei Xu and Jian Wu and Hang Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/682},
  pages     = {4921-4928},
  title     = {Sound2Synth: Interpreting sound via FM synthesizer parameters estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tradformer: A transformer model of traditional music
transcriptions. <em>IJCAI</em>, 4915–4920. (<a
href="https://doi.org/10.24963/ijcai.2022/681">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We explore the transformer neural network architecture for modeling music, specifically Irish and Swedish traditional dance music. Given the repetitive structures of these kinds of music, the transformer should be as successful with fewer parameters and complexity as the hitherto most successful model, a vanilla long short-term memory network. We find that achieving good performance with the transformer is not straightforward, and careful consideration is needed for the sampling strategy, evaluating intermediate outputs in relation to engineering choices, and finally analyzing what the model learns. We discuss these points with several illustrations, providing reusable insights for engineering other music generation systems. We also report the high performance of our final transformer model in a competition of music generation systems focused on a type of Swedish dance. Keywords: Methods and resources: Machine learning, deep learning, neural models, reinforcement learning Application domains: Music Theory and philosophy of arts and creativity in AI systems: Evaluation of artistic or creative outputs, or of systems},
  archive   = {C_IJCAI},
  author    = {Luca Casini and Bob L. T. Sturm},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/681},
  pages     = {4915-4920},
  title     = {Tradformer: A transformer model of traditional music transcriptions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep interactive surface creation from 3D sketch strokes.
<em>IJCAI</em>, 4908–4914. (<a
href="https://doi.org/10.24963/ijcai.2022/680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a deep neural framework that allows users to create surfaces from a stream of sparse 3D sketch strokes. Our network consists of a global surface estimation module followed by a local surface refinement. This facilitates in the incremental prediction of surfaces. Thus, our proposed method works with 3D sketch strokes and estimate a surface interactively in real time. We compare the proposed method with various state-of-the-art methods and show its efficacy for surface fitting. Further, we integrate our method into an existing Blender based 3D content creation pipeline to show its usefulness in 3D modelling. Keywords: Theory and philosophy of arts and creativity in AI systems: Computational paradigms, architectures and models for creativity Application domains: Other domains of art or creativity Theory and philosophy of arts and creativity in AI systems: Support of human creativity},
  archive   = {C_IJCAI},
  author    = {Sukanya Bhattacharjee and Parag Chaudhuri},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/680},
  pages     = {4908-4914},
  title     = {Deep interactive surface creation from 3D sketch strokes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DPVI: A dynamic-weight particle-based variational inference
framework. <em>IJCAI</em>, 4900–4906. (<a
href="https://doi.org/10.24963/ijcai.2022/679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recently developed Particle-based Variational Inference (ParVI) methods drive the empirical distribution of a set of fixed-weight particles towards a given target distribution by iteratively updating particles&#39; positions. However, the fixed weight restriction greatly confines the empirical distribution&#39;s approximation ability, especially when the particle number is limited. In this paper, we propose to dynamically adjust particles&#39; weights according to a Fisher-Rao reaction flow. We develop a general Dynamic-weight Particle-based Variational Inference (DPVI) framework according to a novel continuous composite flow, which evolves the positions and weights of particles simultaneously. We show that the mean-field limit of our composite flow is actually a Wasserstein-Fisher-Rao gradient flow of the associated dissimilarity functional. By using different finite-particle approximations in our general framework, we derive several efficient DPVI algorithms. The empirical results demonstrate the superiority of our derived DPVI algorithms over their fixed-weight counterparts. Keywords: Uncertainty in AI: Inference Machine Learning: Bayesian Learning},
  archive   = {C_IJCAI},
  author    = {Chao Zhang and Zhijian Li and Xin Du and Hui Qian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/679},
  pages     = {4900-4906},
  title     = {DPVI: A dynamic-weight particle-based variational inference framework},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On attacking out-domain uncertainty estimation in deep
neural networks. <em>IJCAI</em>, 4893–4899. (<a
href="https://doi.org/10.24963/ijcai.2022/678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many applications with real-world consequences, it is crucial to develop reliable uncertainty estimation for the predictions made by the AI decision systems. Targeting at the goal of estimating uncertainty, various deep neural network (DNN) based uncertainty estimation algorithms have been proposed. However, the robustness of the uncertainty returned by these algorithms has not been systematically explored. In this work, to raise the awareness of the research community on robust uncertainty estimation, we show that state-of-the-art uncertainty estimation algorithms could fail catastrophically under our proposed adversarial attack despite their impressive performance on uncertainty estimation. In particular, we aim at attacking out-domain uncertainty estimation: under our attack, the uncertainty model would be fooled to make high-confident predictions for the out-domain data, which they originally would have rejected. Extensive experimental results on various benchmark image datasets show that the uncertainty estimated by state-of-the-art methods could be easily corrupted by our attack. Keywords: Uncertainty in AI: Uncertainty Representations Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Huimin Zeng and Zhenrui Yue and Yang Zhang and Ziyi Kou and Lanyu Shang and Dong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/678},
  pages     = {4893-4899},
  title     = {On attacking out-domain uncertainty estimation in deep neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robustness guarantees for credal bayesian networks via
constraint relaxation over probabilistic circuits. <em>IJCAI</em>,
4885–4892. (<a href="https://doi.org/10.24963/ijcai.2022/677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In many domains, worst-case guarantees on the performance (e.g. prediction accuracy) of a decision function subject to distributional shifts and uncertainty about the environment are crucial. In this work we develop a method to quantify the robustness of decision functions with respect to credal Bayesian networks, formal parametric models of the environment where uncertainty is expressed through credal sets on the parameters. In particular, we address the maximum marginal probability (MARmax) problem, that is, determining the greatest probability of an event (such as misclassification) obtainable for parameters in the credal set. We develop a method to faithfully transfer the problem into a constrained optimization problem on a probabilistic circuit. By performing a simple constraint relaxation, we show how to obtain a guaranteed upper bound on MARmax in linear time in the size of the circuit. We further theoretically characterize this constraint relaxation in terms of the original Bayesian network structure, which yields insight into the tightness of the bound. We implement the method and provide experimental evidence that the upper bound is often near tight and demonstrates improved scalability compared to other methods. Keywords: Uncertainty in AI: Bayesian Networks Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis AI Ethics, Trust, Fairness: Safety &amp; Robustness Constraint Satisfaction and Optimization: Constraint Satisfaction Uncertainty in AI: Tractable Probabilistic Models},
  archive   = {C_IJCAI},
  author    = {Hjalmar Wijk and Benjie Wang and Marta Kwiatkowska},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/677},
  pages     = {4885-4892},
  title     = {Robustness guarantees for credal bayesian networks via constraint relaxation over probabilistic circuits},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear combinatorial semi-bandit with causally related
rewards. <em>IJCAI</em>, 4878–4884. (<a
href="https://doi.org/10.24963/ijcai.2022/676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In a sequential decision-making problem, having a structural dependency amongst the reward distributions associated with the arms makes it challenging to identify a subset of alternatives that guarantees the optimal collective outcome. Thus, besides individual actions&#39; reward, learning the causal relations is essential to improve the decision-making strategy. To solve the two-fold learning problem described above, we develop the &#39;combinatorial semi-bandit framework with causally related rewards&#39;, where we model the causal relations by a directed graph in a stationary structural equation model. The nodal observation in the graph signal comprises the corresponding base arm&#39;s instantaneous reward and an additional term resulting from the causal influences of other base arms&#39; rewards. The objective is to maximize the long-term average payoff, which is a linear function of the base arms&#39; rewards and depends strongly on the network topology. To achieve this objective, we propose a policy that determines the causal relations by learning the network&#39;s topology and simultaneously exploits this knowledge to optimize the decision-making process. We establish a sublinear regret bound for the proposed algorithm. Numerical experiments using synthetic and real-world datasets demonstrate the superior performance of our proposed method compared to several benchmarks. Keywords: Uncertainty in AI: Sequential Decision Making Machine Learning: Online Learning Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Behzad Nourani-Koliji and Saeed Ghoorchian and Setareh Maghsudi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/676},
  pages     = {4878-4884},
  title     = {Linear combinatorial semi-bandit with causally related rewards},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning cluster causal diagrams: An information-theoretic
approach. <em>IJCAI</em>, 4871–4877. (<a
href="https://doi.org/10.24963/ijcai.2022/675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world phenomena arise from causal relationships among a set of variables. As a powerful tool, Bayesian Network (BN) has been successful in describing high-dimensional distributions. However, the faithfulness condition, enforced in most BN learning algorithms, is violated in the settings where multiple variables synergistically affect the outcome (i.e., with polyadic dependencies). Building upon recent development in cluster causal diagrams (C-DAGs), we initiate the formal study of learning C-DAGs from observational data to relax the faithfulness condition. We propose a new scoring function, the Clustering Information Criterion (CIC), based on information-theoretic measures that represent various complex interactions among variables. The CIC score also contains a penalization of the model complexity under the minimum description length principle. We further provide a searching strategy to learn structures of high scores. Experiments on both synthetic and real data support the effectiveness of the proposed method. Keywords: Uncertainty in AI: Causality, Structural Causal Models and Causal Inference Uncertainty in AI: Bayesian Networks Uncertainty in AI: Graphical Models Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Xueyan Niu and Xiaoyun Li and Ping Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/675},
  pages     = {4871-4877},
  title     = {Learning cluster causal diagrams: An information-theoretic approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exchangeability-aware sum-product networks. <em>IJCAI</em>,
4864–4870. (<a href="https://doi.org/10.24963/ijcai.2022/674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sum-Product Networks (SPNs) are expressive probabilistic models that provide exact, tractable inference. They achieve this efficiency by making use of local independence. On the other hand, mixtures of exchangeable variable models (MEVMs) are a class of tractable probabilistic models that make use of exchangeability of discrete random variables to render inference tractable. Exchangeability, which arises naturally in relational domains, has not been considered for efficient representation and inference in SPNs yet. The contribution of this paper is a novel probabilistic model which we call Exchangeability-Aware Sum-Product Networks (XSPNs). It contains both SPNs and MEVMs as special cases, and combines the ability of SPNs to efficiently learn deep probabilistic models with the ability of MEVMs to efficiently handle exchangeable random variables. We introduce a structure learning algorithm for XSPNs and empirically show that they can be more accurate than conventional SPNs when the data contains repeated, interchangeable parts. Keywords: Uncertainty in AI: Tractable Probabilistic Models Uncertainty in AI: Graphical Models Uncertainty in AI: Inference},
  archive   = {C_IJCAI},
  author    = {Stefan Lüdtke and Christian Bartelt and Heiner Stuckenschmidt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/674},
  pages     = {4864-4870},
  title     = {Exchangeability-aware sum-product networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hidden 1-counter markov models and how to learn them.
<em>IJCAI</em>, 4857–4863. (<a
href="https://doi.org/10.24963/ijcai.2022/673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce hidden 1-counter Markov models (H1MMs) as an attractive sweet spot between standard hidden Markov models (HMMs) and probabilistic context-free grammars (PCFGs). Both HMMs and PCFGs have a variety of applications, e.g., speech recognition, anomaly detection, and bioinformatics. PCFGs are more expressive than HMMs, e.g., they are more suited for studying protein folding or natural language processing. However, they suffer from slow parameter fitting, which is cubic in the observation sequence length. The same process for HMMs is just linear using the well-known forward-backward algorithm. We argue that by adding to each state of an HMM an integer counter, e.g., representing the number of clients waiting in a queue, brings its expressivity closer to PCFGs. At the same time, we show that parameter fitting for such a model is computationally inexpensive: it is bi-linear in the length of the observation sequence and the maximal counter value, which grows slower than the observation length. The resulting model of H1MMs allows us to combine the best of both worlds: more expressivity with faster parameter fitting. Keywords: Uncertainty in AI: Bayesian Networks Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Machine Learning: Bayesian Learning Machine Learning: Time-series; Data Streams Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Mehmet Kurucan and Mete Özbaltan and Sven Schewe and Dominik Wojtczak},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/673},
  pages     = {4857-4863},
  title     = {Hidden 1-counter markov models and how to learn them},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Empirical bayesian approaches for robust constraint-based
causal discovery under insufficient data. <em>IJCAI</em>, 4850–4856. (<a
href="https://doi.org/10.24963/ijcai.2022/672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Causal discovery is to learn cause-effect relationships among variables given observational data and is important for many applications. Existing causal discovery methods assume data sufficiency, which may not be the case in many real world datasets. As a result, many existing causal discovery methods can fail under limited data. In this work, we propose Bayesian-augmented frequentist independence tests to improve the performance of constraint-based causal discovery methods under insufficient data: 1) We firstly introduce a Bayesian method to estimate mutual information (MI), based on which we propose a robust MI based independence test; 2) Secondly, we consider the Bayesian estimation of hypothesis likelihood and incorporate it into a well-defined statistical test, resulting in a robust statistical testing based independence test. We apply proposed independence tests to constraint-based causal discovery methods and evaluate the performance on benchmark datasets with insufficient samples. Experiments show significant performance improvement in terms of both accuracy and efficiency over SOTA methods. Keywords: Uncertainty in AI: Graphical Models Uncertainty in AI: Causality, Structural Causal Models and Causal Inference},
  archive   = {C_IJCAI},
  author    = {Zijun Cui and Naiyu Yin and Yuru Wang and Qiang Ji},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/672},
  pages     = {4850-4856},
  title     = {Empirical bayesian approaches for robust constraint-based causal discovery under insufficient data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ancestral instrument method for causal inference without
complete knowledge. <em>IJCAI</em>, 4843–4849. (<a
href="https://doi.org/10.24963/ijcai.2022/671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unobserved confounding is the main obstacle to causal effect estimation from observational data. Instrumental variables (IVs) are widely used for causal effect estimation when there exist latent confounders. With the standard IV method, when a given IV is valid, unbiased estimation can be obtained, but the validity requirement on a standard IV is strict and untestable. Conditional IVs have been proposed to relax the requirement of standard IVs by conditioning on a set of observed variables (known as a conditioning set for a conditional IV). However, the criterion for finding a conditioning set for a conditional IV needs a directed acyclic graph (DAG) representing the causal relationships of both observed and unobserved variables. This makes it challenging to discover a conditioning set directly from data. In this paper, by leveraging maximal ancestral graphs (MAGs) for causal inference with latent variables, we study the graphical properties of ancestral IVs, a type of conditional IVs using MAGs, and develop the theory to support data-driven discovery of the conditioning set for a given ancestral IV in data under the pretreatment variable assumption. Based on the theory, we develop an algorithm for unbiased causal effect estimation with a given ancestral IV and observational data. Extensive experiments on synthetic and real-world datasets demonstrate the performance of the algorithm in comparison with existing IV methods. Keywords: Uncertainty in AI: Causality, Structural Causal Models and Causal Inference Knowledge Representation and Reasoning: Causality},
  archive   = {C_IJCAI},
  author    = {Debo Cheng and Jiuyong Li and Lin Liu and Jiji Zhang and Thuc Duy Le and Jixue Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/671},
  pages     = {4843-4849},
  title     = {Ancestral instrument method for causal inference without complete knowledge},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Summary markov models for event sequences. <em>IJCAI</em>,
4836–4842. (<a href="https://doi.org/10.24963/ijcai.2022/670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Datasets involving sequences of different types of events without meaningful time stamps are prevalent in many applications, for instance when extracted from textual corpora. We propose a family of models for such event sequences -- summary Markov models -- where the probability of observing an event type depends only on a summary of historical occurrences of its influencing set of event types. This Markov model family is motivated by Granger causal models for time series, with the important distinction that only one event can occur in a position in an event sequence. We show that a unique minimal influencing set exists for any set of event types of interest and choice of summary function, formulate two novel models from the general family that represent specific sequence dynamics, and propose a greedy search algorithm for learning them from event sequence data. We conduct an experimental investigation comparing the proposed models with relevant baselines, and illustrate their knowledge acquisition and discovery capabilities through case studies involving sequences from text. Keywords: Uncertainty in AI: Tractable Probabilistic Models Data Mining: Mining Spatial and/or Temporal Data Knowledge Representation and Reasoning: Causality Machine Learning: Time-series; Data Streams Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Debarun Bhattacharjya and Saurabh Sihag and Oktie Hassanzadeh and Liza Bialik},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/670},
  pages     = {4836-4842},
  title     = {Summary markov models for event sequences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A weighting-based tabu search algorithm for the p-next
center problem. <em>IJCAI</em>, 4828–4834. (<a
href="https://doi.org/10.24963/ijcai.2022/669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The p-next center problem (pNCP) is an extension of the classical p-center problem. It consists of locating p centers from a set of candidate centers and allocating both a reference and a backup center to each client, to minimize the maximum cost, which is the length of the path from a client to its reference center and then to its backup center. Among them, the reference center is the closest center to a client and serves it under normal circumstances, while the backup center is the closest center to the reference center and serves the client when the reference center is out of service. In this paper, we propose a weighting-based tabu search algorithm called WTS for solving pNCP. WTS optimizes the pNCP by solving its decision subproblems with given assignment costs with an efficient swap-based neighborhood structure and a hierarchical penalty strategy for neighborhood evaluation. Extensive experimental studies on 413 benchmark instances demonstrate that WTS outperforms the state-of-the-art methods in the literature. Specifically, WTS improves 12 previous best known results and matches the optimal results for all remaining 401 ones in a much shorter time than other algorithms. More importantly, WTS reaches the lower bounds for 10 instances for the first time. Keywords: Search: Combinatorial Search and Optimisation Search: Heuristic Search Search: Local search Search: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Qingyun Zhang and Zhouxing Su and Zhipeng Lü and Lingxiao Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/669},
  pages     = {4828-4834},
  title     = {A weighting-based tabu search algorithm for the p-next center problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HEA-d: A hybrid evolutionary algorithm for diversified top-k
weight clique search problem. <em>IJCAI</em>, 4821–4827. (<a
href="https://doi.org/10.24963/ijcai.2022/668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The diversified top-k weight clique (DTKWC) search problem is an important generalization of the diversified top-k clique (DTKC) search problem with extensive applications, which extends the DTKC search problem by taking into account the weight of vertices. In this paper, we formulate DTKWC search problem using mixed integer linear program constraints and propose an efficient hybrid evolutionary algorithm (HEA-D) that combines a clique-based crossover operator and an effective simulated annealing-based local optimization procedure to find high-quality local optima. The experimental results show that HEA-D performs much better than the existing methods on two representative real-world benchmarks. Keywords: Search: Heuristic Search Search: Combinatorial Search and Optimisation Search: Evolutionary Computation Search: Local search},
  archive   = {C_IJCAI},
  author    = {Jun Wu and Chu-Min Li and Yupeng Zhou and Minghao Yin and Xin Xu and Dangdang Niu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/668},
  pages     = {4821-4827},
  title     = {HEA-D: A hybrid evolutionary algorithm for diversified top-k weight clique search problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural network pruning by cooperative coevolution.
<em>IJCAI</em>, 4814–4820. (<a
href="https://doi.org/10.24963/ijcai.2022/667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural network pruning is a popular model compression method which can significantly reduce the computing cost with negligible loss of accuracy. Recently, filters are often pruned directly by designing proper criteria or using auxiliary modules to measure their importance, which, however, requires expertise and trial-and-error. Due to the advantage of automation, pruning by evolutionary algorithms (EAs) has attracted much attention, but the performance is limited for deep neural networks as the search space can be quite large. In this paper, we propose a new filter pruning algorithm CCEP by cooperative coevolution, which prunes the filters in each layer by EAs separately. That is, CCEP reduces the pruning space by a divide-and-conquer strategy. The experiments show that CCEP can achieve a competitive performance with the state-of-the-art pruning methods, e.g., prune ResNet56 for 63.42\% FLOPs on CIFAR10 with -0.24\% accuracy drop, and ResNet50 for 44.56\% FLOPs on ImageNet with 0.07\% accuracy drop. Keywords: Search: Evolutionary Computation Machine Learning: Evolutionary Learning Search: Heuristic Search Search: Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Haopu Shang and Jia-Liang Wu and Wenjing Hong and Chao Qian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/667},
  pages     = {4814-4820},
  title     = {Neural network pruning by cooperative coevolution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient algorithms for monotone non-submodular
maximization with partition matroid constraint. <em>IJCAI</em>,
4807–4813. (<a href="https://doi.org/10.24963/ijcai.2022/666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we study the problem of monotone non-submodular maximization with partition matroid constraint. Although a generalization of this problem has been studied in literature, our work focuses on leveraging properties of partition matroid constraint to (1) propose algorithms with theoretical bound and efficient query complexity; and (2) provide better analysis on theoretical performance guarantee of some existing techniques. We further investigate those algorithms&#39; performance in two applications: Boosting Influence Spread and Video Summarization. Experiments show our algorithms return comparative results to the state-of-the-art algorithms while taking much fewer queries. Keywords: Search: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Lan N. Nguyen and My T. Thai},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/666},
  pages     = {4807-4813},
  title     = {Efficient algorithms for monotone non-submodular maximization with partition matroid constraint},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Runtime analysis of single- and multi-objective evolutionary
algorithms for chance constrained optimization problems with normally
distributed random variables. <em>IJCAI</em>, 4800–4806. (<a
href="https://doi.org/10.24963/ijcai.2022/665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Chance constrained optimization problems allow to model problems where constraints involving stochastic components should only be violated with a small probability. Evolutionary algorithms have been applied to this scenario and shown to achieve high quality results. With this paper, we contribute to the theoretical understanding of evolutionary algorithms for chance constrained optimization. We study the scenario of stochastic components that are independent and Normally distributed. Considering the simple single-objective (1+1)~EA, we show that imposing an additional uniform constraint already leads to local optima for very restricted scenarios and an exponential optimization time. We therefore introduce a multi-objective formulation of the problem which trades off the expected cost and its variance. We show that multi-objective evolutionary algorithms are highly effective when using this formulation and obtain a set of solutions that contains an optimal solution for any possible confidence level imposed on the constraint. Furthermore, we prove that this approach can also be used to compute a set of optimal solutions for the chance constrained minimum spanning tree problem. Experimental investigations on instances of the NP-hard stochastic minimum weight dominating set problem confirm the benefit of the multi-objective approach in practice. Keywords: Search: Evolutionary Computation},
  archive   = {C_IJCAI},
  author    = {Frank Neumann and Carsten Witt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/665},
  pages     = {4800-4806},
  title     = {Runtime analysis of single- and multi-objective evolutionary algorithms for chance constrained optimization problems with normally distributed random variables},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning for cross-domain hyper-heuristics.
<em>IJCAI</em>, 4793–4799. (<a
href="https://doi.org/10.24963/ijcai.2022/664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose a new hyper-heuristic approach that uses reinforcement learning to automatically learn the selection of low-level heuristics across a wide range of problem domains. We provide a detailed analysis and evaluation of the algorithm components, including different ways to represent the hyper-heuristic state space and reset strategies to avoid unpromising areas of the solution space. Our methods have been evaluated using HyFlex, a well-known benchmarking framework for cross-domain hyper-heuristics, and compared with state-of-the-art approaches. The experimental evaluation shows that our reinforcement-learning based approach produces results that are competitive with the state-of-the-art, including the top participants of the Cross Domain Hyper-heuristic Search Competition 2011. Keywords: Search: Meta-Reasoning and Meta-Heuristics Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Florian Mischek and Nysret Musliu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/664},
  pages     = {4793-4799},
  title     = {Reinforcement learning for cross-domain hyper-heuristics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time heuristic search with LTLf goals. <em>IJCAI</em>,
4785–4792. (<a href="https://doi.org/10.24963/ijcai.2022/663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Real-Time Heuristic Search (RTHS) we are given a search graph G, a heuristic, and the objective is to find a path from a given start node to a given goal node in G. As such, one does not impose any trajectory constraints on the path, besides reaching the goal. In this paper we consider a version of RTHS in which temporally extended goals can be defined on the form of the path. Such goals are specified in Linear Temporal Logic over Finite Traces (LTLf), an expressive language that has been considered in many other frameworks, such as Automated Planning, Synthesis, and Reinforcement Learning, but has not yet been studied in the context of RTHS. We propose a general automata-theoretic approach for RTHS, whereby LTLf goals are supported as the result of searching over the cross product of the search graph and the automaton for the LTLf goal; specifically, we describe LTL-LRTA*, a version of LSS-LRTA*. Second, we propose an approach to produce heuristics for LTLf goals, based on existing goal-dependent heuristics. Finally, we propose a greedy strategy for RTHS with LTLf goals, which focuses search to make progress over the structure of the automaton; this yields LTL-LRTA*+A. In our experimental evaluation over standard benchmarks we show LTL-LRTA*+A may outperform LTL-LRTA* substantially for a variety of LTLf goals. Keywords: Search: Heuristic Search Knowledge Representation and Reasoning: Knowledge Representation Languages Search: Combinatorial Search and Optimisation Search: Local search Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Jaime Middleton and Rodrigo Toro Icarte and Jorge Baier},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/663},
  pages     = {4785-4792},
  title     = {Real-time heuristic search with LTLf goals},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient neural neighborhood search for pickup and delivery
problems. <em>IJCAI</em>, 4776–4784. (<a
href="https://doi.org/10.24963/ijcai.2022/662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an efficient Neural Neighborhood Search (N2S) approach for pickup and delivery problems (PDPs). In specific, we design a powerful Synthesis Attention that allows the vanilla self-attention to synthesize various types of features regarding a route solution. We also exploit two customized decoders that automatically learn to perform removal and reinsertion of a pickup-delivery node pair to tackle the precedence constraint. Additionally, a diversity enhancement scheme is leveraged to further ameliorate the performance. Our N2S is generic, and extensive experiments on two canonical PDP variants show that it can produce state-of-the-art results among existing neural methods. Moreover, it even outstrips the well-known LKH3 solver on the more constrained PDP variant. Our implementation for N2S is available online. Keywords: Search: Search and Machine Learning Machine Learning: Deep Reinforcement Learning Search: Local search Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Yining Ma and Jingwen Li and Zhiguang Cao and Wen Song and Hongliang Guo and Yuejiao Gong and Yeow Meng Chee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/662},
  pages     = {4776-4784},
  title     = {Efficient neural neighborhood search for pickup and delivery problems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generalisation of alpha-beta search for AND-OR graphs with
partially ordered values. <em>IJCAI</em>, 4769–4775. (<a
href="https://doi.org/10.24963/ijcai.2022/661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We define a new setting related to the evaluation of AND-OR directed acyclic graphs with partially ordered values. Such graphs arise naturally when solving games with incomplete information (e.g. most card games such as Bridge) or games with multiple criteria. In particular, this setting generalises standard AND-OR graph evaluation and computation of optimal strategies in games with complete information. Under this setting, we propose a new algorithm which uses both alpha-beta pruning and cached values. In this paper, we present our algorithm, prove its correctness, and give experimental results on a card game with incomplete information. Keywords: Search: Game Playing Multidisciplinary Topics and Applications: Computer Games},
  archive   = {C_IJCAI},
  author    = {Junkang Li and Bruno Zanuttini and Tristan Cazenave and Véronique Ventos},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/661},
  pages     = {4769-4775},
  title     = {Generalisation of alpha-beta search for AND-OR graphs with partially ordered values},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient budgeted graph search. <em>IJCAI</em>, 4761–4768.
(<a href="https://doi.org/10.24963/ijcai.2022/660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Iterative Budgeted Exponential Search (IBEX) is a general search algorithm that can limit the number of re-expansions performed in common problems like iterative-deepening tree search and search with inconsistent heuristics. IBEX has been adapted into a specific tree algorithm, Budgeted Tree Search (BTS), which behaves like IDA* when the problem instance is well-behaved but keeps the worst-case guarantees when problems are not well-behaved. The analogous algorithms on graphs, Budgeted Graph Search (BGS), do not have these same properties. This paper reformulates BGS into Efficient Budgeted Graph Search (BGSe), showing how to implement the algorithm so that it behaves identically to A* when problems are well-behaved, and retains the best-case performance otherwise. Experimental results validate the performance of BGSe on a range of theoretical and practical problem instances. Keywords: Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Jasmeet Kaur and Nathan R. Sturtevant},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/660},
  pages     = {4761-4768},
  title     = {Efficient budgeted graph search},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large neighborhood search with decision diagrams.
<em>IJCAI</em>, 4754–4760. (<a
href="https://doi.org/10.24963/ijcai.2022/659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Local search is a popular technique to solve combinatorial optimization problems efficiently. To escape local minima one generally uses metaheuristics or try to design large neighborhoods around the current best solution. A somewhat more black box approach consists in using an optimization solver to explore a large neighborhood. This is the large-neighborhood search (LNS) idea that we reuse in this work. We introduce a generic neighborhood exploration algorithm based on restricted decision diagrams (DD) constructed from the current best solution. We experiment DD-LNS on two sequencing problems: the traveling salesman problem with time windows (TSPTW) and a production planning problem (DLSP). Despite its simplicity, DD-LNS is competitive with the state-of-the-art MIP approach on DLSP. It is able to improve the best known solutions of some standard instances for TSPTW and even to prove the optimality of quite a few other instances. Keywords: Search: Combinatorial Search and Optimisation Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Solvers and Tools Search: Meta-Reasoning and Meta-Heuristics},
  archive   = {C_IJCAI},
  author    = {Xavier Gillard and Pierre Schaus},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/659},
  pages     = {4754-4760},
  title     = {Large neighborhood search with decision diagrams},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Completeness and diversity in depth-first proof-number
search with applications to retrosynthesis. <em>IJCAI</em>, 4747–4753.
(<a href="https://doi.org/10.24963/ijcai.2022/658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We revisit Depth-First Proof-Number Search (DFPN), a well-known algorithm for solving two-player games. First, we consider the completeness property of the algorithm and its variants, i.e., whether they always find a winning strategy when there exists one. While it is known that the standard version is not complete, we show that the combination with the simple Threshold Controlling Algorithm is complete, solving an open problem from the area. Second, we modify DFPN to compute a diverse set of solutions rather than just a single one. Finally, we apply this new variant in Chemistry to the synthesis planning of new target molecules (Retrosynthesis). In this domain a diverse set of many solutions is desirable. We apply additional modifications from the literature to the algorithm and show that it outperforms Monte-Carlo Tree-Search, another well-known algorithm for the same problem, according to a natural diversity measure. Keywords: Search: Search and Machine Learning Agent-based and Multi-agent Systems: Algorithmic Game Theory Multidisciplinary Topics and Applications: Life Science Planning and Scheduling: Planning Algorithms},
  archive   = {C_IJCAI},
  author    = {Christopher Franz and Georg Mogk and Thomas Mrziglod and Kevin Schewior},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/658},
  pages     = {4747-4753},
  title     = {Completeness and diversity in depth-first proof-number search with applications to retrosynthesis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning and exploiting progress states in greedy best-first
search. <em>IJCAI</em>, 4740–4746. (<a
href="https://doi.org/10.24963/ijcai.2022/657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous work introduced the concept of progress states. After expanding a progress state, a greedy best-first search (GBFS) will only expand states with lower heuristic values. Current methods can identify progress states only for a single task and only after a solution for the task has been found. We introduce a novel approach that learns a description logic formula characterizing all progress states in a classical planning domain. Using the learned formulas in a GBFS to break ties in favor of progress states often significantly reduces the search effort. Keywords: Search: Heuristic Search Planning and Scheduling: Learning in Planning and Scheduling Planning and Scheduling: Search in Planning and Scheduling Search: Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Patrick Ferber and Liat Cohen and Jendrik Seipp and Thomas Keller},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/657},
  pages     = {4740-4746},
  title     = {Learning and exploiting progress states in greedy best-first search},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Budgeted sequence submodular maximization. <em>IJCAI</em>,
4733–4739. (<a href="https://doi.org/10.24963/ijcai.2022/656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of selecting a sequence of items that maximizes a given submodular function appears in many real-world applications. Existing study on the problem only considers uniform costs over items, but non-uniform costs on items are more general. Taking this cue, we study the problem of budgeted sequence submodular maximization (BSSM), which introduces non-uniform costs of items into the sequence selection. This problem can be found in a number of applications such as movie recommendation, course sequence design and so on. Non-uniform costs on items significantly increase the solution complexity and we prove that BSSM is NP-hard. To solve the problem, we first propose a greedy algorithm GBM with an error bound. We also design an anytime algorithm POBM based on Pareto optimization to improve the quality of solutions. Moreover, we prove that POBM can obtain approximate solutions in expected polynomial running time, and converges faster than a state-of-the-art algorithm POSEQSEL for sequence submodular maximization with cardinality constraints. We further introduce optimizations to speed up POBM. Experimental results on both synthetic and real-world datasets demonstrate the performance of our new algorithms. Keywords: Search: Combinatorial Search and Optimisation Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Xuefeng Chen and Liang Feng and Xin Cao and Yifeng Zeng and Yaqing Hou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/656},
  pages     = {4733-4739},
  title     = {Budgeted sequence submodular maximization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust subset selection by greedy and evolutionary pareto
optimization. <em>IJCAI</em>, 4726–4732. (<a
href="https://doi.org/10.24963/ijcai.2022/655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Subset selection, which aims to select a subset from a ground set to maximize some objective function, arises in various applications such as influence maximization and sensor placement. In real-world scenarios, however, one often needs to find a subset which is robust against (i.e., is good over) a number of possible objective functions due to uncertainty, resulting in the problem of robust subset selection. This paper considers robust subset selection with monotone objective functions, relaxing the submodular property required by previous studies. We first show that the greedy algorithm can obtain an approximation ratio with respect to the correlation and submodularity ratios of the objective functions; and then propose EPORSS, an evolutionary Pareto optimization algorithm that can utilize more time to find better subsets. We prove that EPORSS can also be theoretically grounded, achieving a similar approximation guarantee to the greedy algorithm. In addition, we derive the lower bound of the correlation ratio for the application of robust influence maximization, and further conduct experiments to validate the performance of the greedy algorithm and EPORSS. Keywords: Search: Evolutionary Computation Machine Learning: Evolutionary Learning Search: Combinatorial Search and Optimisation Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Chao Bian and Yawen Zhou and Chao Qian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/655},
  pages     = {4726-4732},
  title     = {Robust subset selection by greedy and evolutionary pareto optimization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). A closed-loop perception, decision-making and reasoning
mechanism for human-like navigation. <em>IJCAI</em>, 4717–4724. (<a
href="https://doi.org/10.24963/ijcai.2022/654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reliable navigation systems have a wide range of applications in robotics and autonomous driving. Current approaches employ an open-loop process that converts sensor inputs directly into actions. However, these open-loop schemes are challenging to handle complex and dynamic real-world scenarios due to their poor generalization. Imitating human navigation, we add a reasoning process to convert actions back to internal latent states, forming a two-stage closed loop of perception, decision-making, and reasoning. Firstly, VAE-Enhanced Demonstration Learning endows the model with the understanding of basic navigation rules. Then, two dual processes in RL-Enhanced Interaction Learning generate reward feedback for each other and collectively enhance obstacle avoidance capability. The reasoning model can substantially promote generalization and robustness, and facilitate the deployment of the algorithm to real-world robots without elaborate transfers. Experiments show our method is more adaptable to novel scenarios compared with state-of-the-art approaches. Keywords: Robotics: Applications Machine Learning: Deep Reinforcement Learning Robotics: Learning in Robotics Robotics: Motion and Path Planning},
  archive   = {C_IJCAI},
  author    = {Wenqi Zhang and Kai Zhao and Peng Li and Xiao Zhu and Yongliang Shen and Yanna Ma and Yingfeng Chen and Weiming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/654},
  pages     = {4717-4724},
  title     = {A closed-loop perception, decision-making and reasoning mechanism for human-like navigation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-robot task allocation in the environment with
functional tasks. <em>IJCAI</em>, 4710–4716. (<a
href="https://doi.org/10.24963/ijcai.2022/653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-robot task allocation (MRTA) problem has long been a key issue in multi-robot systems. Previous studies usually assumed that the robots must complete all tasks with minimum time cost. However, in many real situations, some tasks can be selectively performed by robots and will not limit the achievement of the goal. Instead, completing these tasks will cause some functional effects, such as decreasing the time cost of completing other tasks. This kind of task can be called “functional task”. This paper studies the multi-robot task allocation in the environment with functional tasks. In the problem, neither allocating all functional tasks nor allocating no functional task is always optimal. Previous algorithms usually allocate all tasks and cannot suitably select the functional tasks. Because of the interaction and sequential influence, the total effects of the functional tasks are too complex to exactly calculate. We fully analyze this problem and then design a heuristic algorithm. The heuristic algorithm scores the functional tasks referring to linear threshold model (used to analyze the sequential influence of a functional task). The simulated experiments demonstrate that the heuristic algorithm can outperform the benchmark algorithms. Keywords: Robotics: Multi-Robot Systems Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Fuhan Yan and Kai Di},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/653},
  pages     = {4710-4716},
  title     = {Multi-robot task allocation in the environment with functional tasks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic car dispatching and pricing: Revenue and fairness
for ridesharing platforms. <em>IJCAI</em>, 4701–4708. (<a
href="https://doi.org/10.24963/ijcai.2022/652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A major challenge for ridesharing platforms is to guarantee profit and fairness simultaneously, especially in the presence of misaligned incentives of drivers and riders. We focus on the dispatching-pricing problem to maximize the total revenue while keeping both drivers and riders satisfied. We study the computational complexity of the problem, provide a novel two-phased pricing solution with revenue and fairness guarantees, extend it to stochastic settings and develop a dynamic (a.k.a., learning-while-doing) algorithm that actively collects data to learn the demand distribution during the scheduling process. We also conduct extensive experiments to demonstrate the effectiveness of our algorithms. Keywords: Planning and Scheduling: Planning Algorithms Agent-based and Multi-agent Systems: Mechanism Design AI Ethics, Trust, Fairness: Fairness &amp; Diversity Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Planning with Incomplete Information},
  archive   = {C_IJCAI},
  author    = {Zishuo Zhao and Xi Chen and Xuefeng Zhang and Yuan Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/652},
  pages     = {4701-4708},
  title     = {Dynamic car dispatching and pricing: Revenue and fairness for ridesharing platforms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A native qualitative numeric planning solver based on AND/OR
graph search. <em>IJCAI</em>, 4693–4700. (<a
href="https://doi.org/10.24963/ijcai.2022/651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Qualitative numeric planning (QNP) is classical planning extended with non-negative real variables that can be increased or decreased by some arbitrary amount. Existing approaches for solving QNP problems are exclusively based on compilation to fully observable nondeterministic planning (FOND) problems or FOND+ problems, i.e., FOND problems with explicit fairness assumptions. However, the FOND-compilation approaches suffer from some limitations, such as difficulties to generate all strong cyclic solutions for FOND problems or introducing a great many extra variables and actions. In this paper, we propose a simpler characterization of QNP solutions and a new approach to solve QNP problems based on directly searching for a solution, which is a closed and terminating subgraph that contains a goal node, in the AND/OR graphs induced by QNP problems. Moreover, we introduce a pruning strategy based on termination tests on subgraphs. We implemented a native solver DSET based on the proposed approach and compared the performance of it with that of the two compilation-based approaches. Experimental results show that DSET is faster than the FOND-compilation approach by one order of magnitude, and comparable with the FOND+-compilation approach. Keywords: Planning and Scheduling: Planning Algorithms Planning and Scheduling: Planning under Uncertainty},
  archive   = {C_IJCAI},
  author    = {Hemeng Zeng and Yikun Liang and Yongmei Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/651},
  pages     = {4693-4700},
  title     = {A native qualitative numeric planning solver based on AND/OR graph search},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PG3: Policy-guided planning for generalized policy
generation. <em>IJCAI</em>, 4686–4692. (<a
href="https://doi.org/10.24963/ijcai.2022/650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A longstanding objective in classical planning is to synthesize policies that generalize across multiple problems from the same domain. In this work, we study generalized policy search-based methods with a focus on the score function used to guide the search over policies. We demonstrate limitations of two score functions --- policy evaluation and plan comparison --- and propose a new approach that overcomes these limitations. The main idea behind our approach, Policy-Guided Planning for Generalized Policy Generalization (PG3), is that a candidate policy should be used to guide planning on training problems as a mechanism for evaluating that candidate. Theoretical results in a simplified setting give conditions under which PG3 is optimal or admissible. We then study a specific instantiation of policy search where planning problems are PDDL-based and policies are lifted decision lists. Empirical results in six domains confirm that PG3 learns generalized policies more efficiently and effectively than several baselines. Keywords: Planning and Scheduling: Learning in Planning and Scheduling Machine Learning: Relational Learning Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Ryan Yang and Tom Silver and Aidan Curtis and Tomas Lozano-Perez and Leslie Kaelbling},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/650},
  pages     = {4686-4692},
  title     = {PG3: Policy-guided planning for generalized policy generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An online learning approach towards far-sighted emergency
relief planning under intentional attacks in conflict areas.
<em>IJCAI</em>, 4679–4685. (<a
href="https://doi.org/10.24963/ijcai.2022/649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A large number of emergency humanitarian rescue demands in conflict areas around the world are accompanied by intentional, persistent and unpredictable attacks on rescuers and supplies. Unfortunately, existing work on humanitarian relief planning mostly ignores this challenge in reality resulting a parlous and short-sighted relief distribution plan to a large extent. To address this, we first propose an offline multi-stage optimization problem of emergency relief planning under intentional attacks, in which all parameters in the game between the rescuer and attacker are supposed to be known or predictable. Then, an online version of this problem is introduced to meet the need of online and irrevocable decision making when those parameters are revealed in an online fashion. To achieve a far-sighted emergency relief planning under attacks, we design an online learning approach which is proven to obtain a near-optimal solution of the offline problem when those online reveled parameters are i.i.d. sampled from an unknown distribution. Finally, extensive experiments on a real anti-Ebola relief planning case based on the data of Ebola outbreak and armed attacks in DRC Congo show the scalability and effectiveness of our approach. Keywords: Planning and Scheduling: Planning under Uncertainty Agent-based and Multi-agent Systems: Noncooperative Games Planning and Scheduling: Mixed Discrete/Continuous Planning Planning and Scheduling: Real-time Planning Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Haoyu Yang and Kaiming Xiao and Lihua Liu and Hongbin Huang and Weiming Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/649},
  pages     = {4679-4685},
  title     = {An online learning approach towards far-sighted emergency relief planning under intentional attacks in conflict areas},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Competitive analysis for multi-commodity ski-rental problem.
<em>IJCAI</em>, 4672–4678. (<a
href="https://doi.org/10.24963/ijcai.2022/648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate an extended version of the classical ski-rental problem with multiple commodities. A customer uses a set of commodities altogether, and he/she needs to choose payment options to cover the usage of each commodity without the knowledge of the future. The payment options of each commodity include (1) renting: to pay for an on-demand usage and (2) buying: to pay for the lifetime usage. It is a novel extension of the classical ski-rental problem which deals with only one commodity. To address this problem, we propose a new online algorithm called the Multi-Object Break-Even (MOBE) algorithm and conduct competitive analysis. We show that the tight lower and upper bounds of MOBE algorithm&#39;s competitive ratio are e/e-1 and 2 respectively against adaptive adversary under arbitrary renting and buying prices. We further prove that MOBE algorithm is an optimal online algorithm if commodities have the same rent-to-buy ratio. Numerical results verify our theoretical conclusion and demonstrate the advantages of MOBE in a real-world scenario. Keywords: Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Applications Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Binghan Wu and Wei Bao and Dong Yuan and Bing Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/648},
  pages     = {4672-4678},
  title     = {Competitive analysis for multi-commodity ski-rental problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Landmark heuristics for lifted classical planning.
<em>IJCAI</em>, 4665–4671. (<a
href="https://doi.org/10.24963/ijcai.2022/647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While state-of-the-art planning systems need a grounded (propositional) task representation, the input model is provided &quot;lifted&quot;, specifying predicates and action schemas with variables over a finite object universe. The size of the grounded model is exponential in predicate/action-schema arity, limiting applicability to cases where it is small enough. Recent work has taken up this challenge, devising an effective lifted forward search planner as basis for lifted heuristic search, as well as a variety of lifted heuristic functions based on the delete relaxation. Here we add a novel family of lifted heuristic functions, based on landmarks. We design two methods for landmark extraction in the lifted setting. The resulting heuristics exhibit performance advantages over previous heuristics in several benchmark domains. Especially the combination with lifted delete relaxation heuristics to a LAMA-style planner yields good results, beating the previous state of the art in lifted planning. Keywords: Planning and Scheduling: Search in Planning and Scheduling Planning and Scheduling: Planning Algorithms},
  archive   = {C_IJCAI},
  author    = {Julia Wichlacz and Daniel Höller and Jörg Hoffmann},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/647},
  pages     = {4665-4671},
  title     = {Landmark heuristics for lifted classical planning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the computational complexity of model reconciliations.
<em>IJCAI</em>, 4657–4664. (<a
href="https://doi.org/10.24963/ijcai.2022/646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model-reconciliation explanation is a popular framework for generating explanations for planning problems. While the framework has been extended to multiple settings since its introduction for classical planning problems, there is little agreement on the computational complexity of generating minimal model reconciliation explanations in the basic setting. In this paper, we address this lacuna by introducing a decision-version of the model-reconciliation explanation generation problem and we show that it is Sigma-2-P Complete. Keywords: Planning and Scheduling: Theoretical Foundations of Planning AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Sarath Sreedharan and Pascal Bercher and Subbarao Kambhampati},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/646},
  pages     = {4657-4664},
  title     = {On the computational complexity of model reconciliations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Offline time-independent multi-agent path planning.
<em>IJCAI</em>, 4649–4656. (<a
href="https://doi.org/10.24963/ijcai.2022/645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies a novel planning problem for multiple agents that cannot share holding resources, named OTIMAPP (Offline Time-Independent Multi-Agent Path Planning). Given a graph and a set of start-goal pairs, the problem consists in assigning a path to each agent such that every agent eventually reaches their goal without blocking each other, regardless of how the agents are being scheduled at runtime. The motivation stems from the nature of distributed environments that agents take actions fully asynchronous and have no knowledge about those exact timings of other actors. We present solution conditions, computational complexity, solvers, and robotic applications. Keywords: Planning and Scheduling: Distributed; Multi-agent Planning Agent-based and Multi-agent Systems: Multi-agent Planning Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Robot Planning Robotics: Motion and Path Planning},
  archive   = {C_IJCAI},
  author    = {Keisuke Okumura and François Bonnet and Yasumasa Tamura and Xavier Défago},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/645},
  pages     = {4649-4656},
  title     = {Offline time-independent multi-agent path planning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General optimization framework for recurrent reachability
objectives. <em>IJCAI</em>, 4642–4648. (<a
href="https://doi.org/10.24963/ijcai.2022/644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the mobile robot path planning problem for a class of recurrent reachability objectives. These objectives are parameterized by the expected time needed to visit one position from another, the expected square of this time, and also the frequency of moves between two neighboring locations. We design an efficient strategy synthesis algorithm for recurrent reachability objectives and demonstrate its functionality on non-trivial instances. Keywords: Planning and Scheduling: Robot Planning Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Mechanism Design Planning and Scheduling: Planning Algorithms Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {David Klaska and Antonin Kucera and Vit Musil and Vojtech Rehak},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/644},
  pages     = {4642-4648},
  title     = {General optimization framework for recurrent reachability objectives},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An efficient approach to data transfer scheduling for long
range space exploration. <em>IJCAI</em>, 4635–4641. (<a
href="https://doi.org/10.24963/ijcai.2022/643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Long range space missions, such as Rosetta, require robust plans of data-acquisition activities and of the resulting data transfers. In this paper we revisit the problem of assigning priorities to data transfers in order to maximize safety margin of onboard memory. We propose a fast sweep algorithm to verify the feasibility of a given priority assignment and we introduce an efficient exact algorithm to assign priorities on a single downlink window. We prove that the problem is NP-hard for several windows, and we propose several randomized heuristics to tackle the general case. Our experimental results show that the proposed approaches are able to improve the plans computed for the real mission by the previously existing method, while the sweep algorithm yields drastic accelerations. Keywords: Planning and Scheduling: Applications Planning and Scheduling: Scheduling Planning and Scheduling: Search in Planning and Scheduling Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Emmanuel Hebrard and Christian Artigues and Pierre Lopez and Arnaud Lusson and Steve Chien and Adrien Maillard and Gregg Rabideau},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/643},
  pages     = {4635-4641},
  title     = {An efficient approach to data transfer scheduling for long range space exploration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online planning in POMDPs with self-improving simulators.
<em>IJCAI</em>, 4628–4634. (<a
href="https://doi.org/10.24963/ijcai.2022/642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How can we plan efficiently in a large and complex environment when the time budget is limited? Given the original simulator of the environment, which may be computationally very demanding, we propose to learn online an approximate but much faster simulator that improves over time. To plan reliably and efficiently while the approximate simulator is learning, we develop a method that adaptively decides which simulator to use for every simulation, based on a statistic that measures the accuracy of the approximate simulator. This allows us to use the approximate simulator to replace the original simulator for faster simulations when it is accurate enough under the current context, thus trading off simulation speed and accuracy. Experimental results in two large domains show that when integrated with POMCP, our approach allows to plan with improving efficiency over time. Keywords: Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Planning Algorithms Planning and Scheduling: POMDPs Planning and Scheduling: Real-time Planning},
  archive   = {C_IJCAI},
  author    = {Jinke He and Miguel Suau and Hendrik Baier and Michael Kaisers and Frans A. Oliehoek},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/642},
  pages     = {4628-4634},
  title     = {Online planning in POMDPs with self-improving simulators},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explaining soft-goal conflicts through constraint
relaxations. <em>IJCAI</em>, 4621–4627. (<a
href="https://doi.org/10.24963/ijcai.2022/641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work suggests to explain trade-offs between soft-goals in terms of their conflicts, i.e., minimal unsolvable soft-goal subsets. But this does not explain the conflicts themselves: Why can a given set of soft-goals not be jointly achieved? Here we approach that question in terms of the underlying constraints on plans in the task at hand, namely resource availability and time windows. In this context, a natural form of explanation for a soft-goal conflict is a minimal constraint relaxation under which the conflict disappears (``if the deadline was 1 hour later, it would work&#39;&#39;). We explore algorithms for computing such explanations. A baseline is to simply loop over all relaxed tasks and compute the conflicts for each separately. We improve over this by two algorithms that leverage information -- conflicts, reachable states -- across relaxed tasks. We show that these algorithms can exponentially outperform the baseline in theory, and we run experiments confirming that advantage in practice. Keywords: Planning and Scheduling: Planning Algorithms},
  archive   = {C_IJCAI},
  author    = {Rebecca Eifler and Jeremy Frank and Jörg Hoffmann},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/641},
  pages     = {4621-4627},
  title     = {Explaining soft-goal conflicts through constraint relaxations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shared autonomy systems with stochastic operator models.
<em>IJCAI</em>, 4614–4620. (<a
href="https://doi.org/10.24963/ijcai.2022/640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider shared autonomy systems where multiple operators (AI and human), can interact with the environment, e.g. by controlling a robot. The decision problem for the shared autonomy system is to select which operator takes control at each timestep, such that a reward specifying the intended system behaviour is maximised. The performance of the human operator is influenced by unobserved factors, such as fatigue or skill level. Therefore, the system must reason over stochastic models of operator performance. We present a framework for stochastic operators in shared autonomy systems (SO-SAS), where we represent operators using rich, partially observable models. We formalise SO-SAS as a mixed-observability Markov decision process, where environment states are fully observable and internal operator states are hidden. We test SO-SAS on a simulated domain and a computer game, empirically showing it results in better performance compared to traditional formulations of shared autonomy systems. Keywords: Planning and Scheduling: Planning under Uncertainty Agent-based and Multi-agent Systems: Human-Agent Interaction Humans and AI: Human-AI Collaboration Planning and Scheduling: Markov Decisions Processes Robotics: Human Robot Interaction},
  archive   = {C_IJCAI},
  author    = {Clarissa Costen and Marc Rigter and Bruno Lacerda and Nick Hawes},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/640},
  pages     = {4614-4620},
  title     = {Shared autonomy systems with stochastic operator models},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Planning with qualitative action-trajectory constraints in
PDDL. <em>IJCAI</em>, 4606–4613. (<a
href="https://doi.org/10.24963/ijcai.2022/639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In automated planning the ability of expressing constraints on the structure of the desired plans is important to deal with solution quality, as well as to express control knowledge. In PDDL3, this is supported through state-trajectory constraints corresponding to a class of LTLf formulae. In this paper, first we introduce a formalism to express trajectory constraints over actions in the plan, rather than over traversed states; Then we investigate compilation-based methods to deal with such constraints in propositional planning, and propose a new simple effective method. Finally, we experimentally study the usefulness of our action-trajectory constraints as a tool to express control knowledge. The experimental results show that the performance of a classical planner can be significantly improved by exploiting knowledge expressed by action constraints and handled by our compilation method, while the same knowledge turns out to be less beneficial when specified as state constraints and handled by two state-of-the-art systems supporting state constraints. Keywords: Planning and Scheduling: Planning Algorithms Knowledge Representation and Reasoning: Knowledge Representation Languages Planning and Scheduling: Search in Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Luigi Bonassi and Alfonso Emilio Gerevini and Enrico Scala},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/639},
  pages     = {4606-4613},
  title     = {Planning with qualitative action-trajectory constraints in PDDL},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tight bounds for hybrid planning. <em>IJCAI</em>, 4597–4605.
(<a href="https://doi.org/10.24963/ijcai.2022/638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Several hierarchical planning systems feature a rich level of language features making them capable of expressing real-world problems. One such feature that&#39;s used by several current planning systems is causal links, which are used to track search progress. The formalism combining Hierarchical Task Network (HTN) planning with these links known from Partial Order Causal Link (POCL) planning is often referred to as hybrid planning. In this paper we study the computational complexity of such hybrid planning problems. More specifically, we provide missing membership results to existing hardness proofs and thereby provide tight complexity bounds for all known subclasses of hierarchical planning problems. We also re-visit and correct a result from the literature for plan verification showing that it remains NP-complete even in the absence of a task hierarchy. Keywords: Planning and Scheduling: Hierarchical Planning Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Pascal Bercher and Songtuan Lin and Ron Alford},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/638},
  pages     = {4597-4605},
  title     = {Tight bounds for hybrid planning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive information belief space planning. <em>IJCAI</em>,
4588–4596. (<a href="https://doi.org/10.24963/ijcai.2022/637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reasoning about uncertainty is vital in many real-life autonomous systems. However, current state-of-the-art planning algorithms either cannot reason about uncertainty explicitly, or do so with high computational burden. Here, we focus on making informed decisions efficiently, using reward functions that explicitly deal with uncertainty. We formulate an approximation, namely an abstract observation model, that uses an aggregation scheme to alleviate computational costs. We derive bounds on the expected information-theoretic reward function and, as a consequence, on the value function. We then propose a method to refine aggregation to achieve identical action selection in a fraction of the computational time. Keywords: Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Planning Algorithms Planning and Scheduling: Planning with Incomplete Information Planning and Scheduling: POMDPs Planning and Scheduling: Robot Planning},
  archive   = {C_IJCAI},
  author    = {Moran Barenboim and Vadim Indelman},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/637},
  pages     = {4588-4596},
  title     = {Adaptive information belief space planning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Scheduling with untrusted predictions. <em>IJCAI</em>,
4581–4587. (<a href="https://doi.org/10.24963/ijcai.2022/636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Using machine-learned predictions to create algorithms with better approximation guarantees is a very fresh and active field. In this work, we study classic scheduling problems under the learning augmented setting. More specifically, we consider the problem of scheduling jobs with arbitrary release dates on a single machine and the problem of scheduling jobs with a common release date on multiple machines. Our objective is to minimize the sum of completion times. For both problems, we propose algorithms which use predictions for taking their decisions. Our algorithms are consistent -- i.e. when the predictions are accurate, the performances of our algorithms are close to those of an optimal offline algorithm--, and robust -- i.e. when the predictions are wrong, the performance of our algorithms are close to those of an online algorithm without predictions. In addition, we confirm the above theoretical bounds by conducting experimental evaluation comparing the proposed algorithms to the offline optimal ones for both the single and multiple machines settings. Keywords: Planning and Scheduling: Scheduling Planning and Scheduling: Learning in Planning and Scheduling Uncertainty in AI: Nonprobabilistic Models},
  archive   = {C_IJCAI},
  author    = {Evripidis Bampis and Konstantinos Dogeas and Alexander Kononov and Giorgio Lucarelli and Fanny Pascual},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/636},
  pages     = {4581-4587},
  title     = {Scheduling with untrusted predictions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online bin packing with predictions. <em>IJCAI</em>,
4574–4580. (<a href="https://doi.org/10.24963/ijcai.2022/635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bin packing is a classic optimization problem with a wide range of applications from load balancing to supply chain management. In this work, we study the online variant of the problem, in which a sequence of items of various sizes must be placed into a minimum number of bins of uniform capacity. The online algorithm is enhanced with a (potentially erroneous) prediction concerning the frequency of item sizes in the sequence. We design and analyze online algorithms with efficient tradeoffs between the consistency (i.e., the competitive ratio assuming no prediction error) and the robustness (i.e., the competitive ratio under adversarial error), and whose performance degrades near-optimally as a function of the prediction error. This is the first theoretical and experimental study of online bin packing in the realistic setting of learnable predictions. Previous work addressed only extreme cases with respect to the prediction error, and relied on overly powerful and error-free oracles. Keywords: Planning and Scheduling: Learning in Planning and Scheduling Machine Learning: Optimisation Planning and Scheduling: Planning under Uncertainty Planning and Scheduling: Scheduling},
  archive   = {C_IJCAI},
  author    = {Spyros Angelopoulos and Shahin Kamali and Kimia Shadkami},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/635},
  pages     = {4574-4580},
  title     = {Online bin packing with predictions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explaining the behaviour of hybrid systems with PDDL+
planning. <em>IJCAI</em>, 4567–4573. (<a
href="https://doi.org/10.24963/ijcai.2022/634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The aim of this work is to explain the observed behaviour of a hybrid system (HS). The explanation problem is cast as finding a trajectory of the HS that matches some observations. By using the formalism of hybrid automata (HA), we characterize the explanations as the language of a network of HA that comprises one automaton for the HS and another one for the observations, thus restricting the behaviour of the HS exclusively to trajectories that explain the observations. We observe that this problem corresponds to a reachability problem in model-checking, but that state-of-the-art model checkers struggle to find concrete trajectories. To overcome this issue we provide a formal mapping from HA to PDDL+ and show how to use an off-the-shelf automated planner. An experimental analysis over domains with piece-wise constant, linear and nonlinear dynamics reveals that the proposed PDDL+ approach is much more efficient than solving directly the explanation problem with model-checking solvers. Keywords: Planning and Scheduling: Mixed Discrete/Continuous Planning Planning and Scheduling: Activity and Plan Recognition},
  archive   = {C_IJCAI},
  author    = {Diego Aineto and Eva Onaindia and Miquel Ramirez and Enrico Scala and Ivan Serina},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/634},
  pages     = {4567-4573},
  title     = {Explaining the behaviour of hybrid systems with PDDL+ planning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive graph transformer network for personality
detection. <em>IJCAI</em>, 4559–4565. (<a
href="https://doi.org/10.24963/ijcai.2022/633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Personality detection is to identify the personality traits underlying social media posts. Most of the existing work is mainly devoted to learning the representations of posts based on labeled data. Yet the ground-truth personality traits are collected through time-consuming questionnaires. Thus, one of the biggest limitations lies in the lack of training data for this data-hungry task. In addition, the correlations among traits should be considered since they are important psychological cues that could help collectively identify the traits. In this paper, we construct a fully-connected post graph for each user and develop a novel Contrastive Graph Transformer Network model (CGTN) which distills potential labels of the graphs based on both labeled and unlabeled data. Specifically, our model first explores a self-supervised Graph Neural Network (GNN) to learn the post embeddings. We design two types of post graph augmentations to incorporate different priors based on psycholinguistic knowledge of Linguistic Inquiry and Word Count (LIWC) and post semantics. Then, upon the post embeddings of the graph, a Transformer-based decoder equipped with post-to-trait attention is exploited to generate traits sequentially. Experiments on two standard datasets demonstrate that our CGTN outperforms the state-of-the-art methods for personality detection. Keywords: Natural Language Processing: Psycholinguistics Natural Language Processing: Applications Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Yangfu Zhu and Linmei Hu and Xinkai Ge and Wanrong Peng and Bin Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/633},
  pages     = {4559-4565},
  title     = {Contrastive graph transformer network for personality detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient document-level event extraction via
pseudo-trigger-aware pruned complete graph. <em>IJCAI</em>, 4552–4558.
(<a href="https://doi.org/10.24963/ijcai.2022/632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most previous studies of document-level event extraction mainly focus on building argument chains in an autoregressive way, which achieves a certain success but is inefficient in both training and inference. In contrast to the previous studies, we propose a fast and lightweight model named as PTPCG. In our model, we design a novel strategy for event argument combination together with a non-autoregressive decoding algorithm via pruned complete graphs, which are constructed under the guidance of the automatically selected pseudo triggers. Compared to the previous systems, our system achieves competitive results with 19.8\% of parameters and much lower resource consumption, taking only 3.8\% GPU hours for training and up to 8.5 times faster for inference. Besides, our model shows superior compatibility for the datasets with (or without) triggers and the pseudo triggers can be the supplements for annotated triggers to make further improvements. Codes are available at https://github.com/Spico197/DocEE . Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Tong Zhu and Xiaoye Qu and Wenliang Chen and Zhefeng Wang and Baoxing Huai and Nicholas Yuan and Min Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/632},
  pages     = {4552-4558},
  title     = {Efficient document-level event extraction via pseudo-trigger-aware pruned complete graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Grape: Grammar-preserving rule embedding. <em>IJCAI</em>,
4545–4551. (<a href="https://doi.org/10.24963/ijcai.2022/631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Word embedding has been widely used in various areas to boost the performance of the neural models. However, when processing context-free languages, embedding grammar rules with word embedding loses two types of information. One is the structural relationship between the grammar rules, and the other one is the content information of the rule definition. In this paper, we make the first attempt to learn a grammar-preserving rule embedding. We first introduce a novel graph structure to represent the context-free grammar. Then, we apply a Graph Neural Network (GNN) to extract the structural information and use a gating layer to integrate content information. We conducted experiments on six widely-used benchmarks containing four context-free languages. The results show that our approach improves the accuracy of the base model by 0.8 to 6.4 percentage points. Furthermore, Grape also achieves 1.6 F1 score improvement on the method naming task which shows the generality of our approach. Keywords: Natural Language Processing: Applications Natural Language Processing: Language Generation Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Qihao Zhu and Zeyu Sun and Wenjie Zhang and Yingfei Xiong and Lu Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/631},
  pages     = {4545-4551},
  title     = {Grape: Grammar-preserving rule embedding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). None class ranking loss for document-level relation
extraction. <em>IJCAI</em>, 4538–4544. (<a
href="https://doi.org/10.24963/ijcai.2022/630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level relation extraction (RE) aims at extracting relations among entities expressed across multiple sentences, which can be viewed as a multi-label classification problem. In a typical document, most entity pairs do not express any pre-defined relation and are labeled as &quot;none&quot; or &quot;no relation&quot;. For good document-level RE performance, it is crucial to distinguish such none class instances (entity pairs) from those of pre-defined classes (relations). However, most existing methods only estimate the probability of pre-defined relations independently without considering the probability of &quot;no relation&quot;. This ignores the context of entity pairs and the label correlations between the none class and pre-defined classes, leading to sub-optimal predictions. To address this problem, we propose a new multi-label loss that encourages large margins of label confidence scores between each pre-defined class and the none class, which enables captured label correlations and context-dependent thresholding for label prediction. To gain further robustness against positive-negative imbalance and mislabeled data that could appear in real-world RE datasets, we propose a margin regularization and a margin shifting technique. Experimental results demonstrate that our method significantly outperforms existing multi-label losses for document-level RE and works well in other multi-label tasks such as emotion classification when none class instances are available for training. Keywords: Natural Language Processing: Information Extraction Machine Learning: Multi-label},
  archive   = {C_IJCAI},
  author    = {Yang Zhou and Wee Sun Lee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/630},
  pages     = {4538-4544},
  title     = {None class ranking loss for document-level relation extraction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reasoning over hybrid chain for table-and-text open domain
question answering. <em>IJCAI</em>, 4531–4537. (<a
href="https://doi.org/10.24963/ijcai.2022/629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tabular and textual question answering requires systems to perform reasoning over heterogeneous information, considering table structure, and the connections among table and text. In this paper, we propose a ChAin-centric Reasoning and Pre-training framework (CARP). CARP utilizes hybrid chain to model the explicit intermediate reasoning process across table and text for question answering. We also propose a novel chain-centric pre-training method, to enhance the pre-trained model in identifying the cross-modality reasoning process and alleviating the data sparsity problem. This method constructs the large-scale reasoning corpus by synthesizing pseudo heterogeneous reasoning paths from Wikipedia and generating corresponding questions. We evaluate our system on OTT-QA, a large-scale table-and-text open-domain question answering benchmark, and our system achieves the state-of-the-art performance. Further analyses illustrate that the explicit hybrid chain offers substantial performance improvement and interpretablity of the intermediate reasoning process, and the chain-centric pre-training boosts the performance on the chain extraction. Keywords: Natural Language Processing: Question Answering Natural Language Processing: Natural Language Semantics Natural Language Processing: Information Retrieval and Text Mining Natural Language Processing: Interpretability and Analysis of Models for NLP},
  archive   = {C_IJCAI},
  author    = {Wanjun Zhong and Junjie Huang and Qian Liu and Ming Zhou and Jiahai Wang and Jian Yin and Nan Duan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/629},
  pages     = {4531-4537},
  title     = {Reasoning over hybrid chain for table-and-text open domain question answering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CauAIN: Causal aware interaction network for emotion
recognition in conversations. <em>IJCAI</em>, 4524–4530. (<a
href="https://doi.org/10.24963/ijcai.2022/628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emotion Recognition in Conversations has attained increasing interest in the natural language processing community. Many neural-network based approaches endeavor to solve the challenge of emotional dynamics in conversations and gain appealing results. However, these works are limited in capturing deep emotional clues in conversational context because they ignore the emotion cause that could be viewed as stimulus to the target emotion. In this work, we propose Causal Aware Interaction Network (CauAIN) to thoroughly understand the conversational context with the help of emotion cause detection. Specifically, we retrieve causal clues provided by commonsense knowledge to guide the process of causal utterance traceback. Both retrieve and traceback steps are performed from the perspective of intra- and inter-speaker interaction simultaneously. Experimental results on three benchmark datasets show that our model achieves better performance over most baseline models. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Weixiang Zhao and Yanyan Zhao and Xin Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/628},
  pages     = {4524-4530},
  title     = {CauAIN: Causal aware interaction network for emotion recognition in conversations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Charge prediction by constitutive elements matching of
crimes. <em>IJCAI</em>, 4517–4523. (<a
href="https://doi.org/10.24963/ijcai.2022/627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Charge prediction is to automatically predict the judgemental charges for legal cases. To convict a person/unit of a charge, the case description must contain matching instances of the constitutive elements (CEs) of that charge. This knowledge of CEs is a valuable guide for the judge in making final decisions. However, it is far from fully exploited for charge prediction in the literature. In this paper we propose a novel method named Constitutive Elements-guided Charge Prediction (CECP). CECP mimics human&#39;s charge identification process to extract potential instances of CEs and generate predictions accordingly. It avoids laborious labeling of matching instances of CEs by a novel reinforcement learning module which progressively selects potentially matching sentences for CEs and evaluates their relevance. The final prediction is generated based on the selected sentences and their relevant CEs. Experiments on two real-world datasets show the superiority of CECP over competitive baselines. Keywords: Natural Language Processing: Applications Machine Learning: Deep Reinforcement Learning Natural Language Processing: Information Retrieval and Text Mining Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Jie Zhao and Ziyu Guan and Cai Xu and Wei Zhao and Enze Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/627},
  pages     = {4517-4523},
  title     = {Charge prediction by constitutive elements matching of crimes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). “Think before you speak”: Improving multi-action dialog
policy by planning single-action dialogs. <em>IJCAI</em>, 4510–4516. (<a
href="https://doi.org/10.24963/ijcai.2022/626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-action dialog policy (MADP), which generates multiple atomic dialog actions per turn, has been widely applied in task-oriented dialog systems to provide expressive and efficient system responses. Existing MADP models usually imitate action combinations from the labeled multi-action dialog samples. Due to data limitations, they generalize poorly toward unseen dialog flows. While interactive learning and reinforcement learning algorithms can be applied to incorporate external data sources of real users and user simulators, they take significant manual effort to build and suffer from instability. To address these issues, we propose Planning Enhanced Dialog Policy (PEDP), a novel multi-task learning framework that learns single-action dialog dynamics to enhance multi-action prediction. Our PEDP method employs model-based planning for conceiving what to express before deciding the current response through simulating single-action dialogs. Experimental results on the MultiWOZ dataset demonstrate that our fully supervised learning-based method achieves a solid task success rate of 90.6\%, improving 3\% compared to the state-of-the-art methods. The source code and the appendix of this paper can be obtained from https://github.com/ShuoZhangXJTU/PEDP. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Shuo Zhang and Junzhou Zhao and Pinghui Wang and Yu Li and Yi Huang and Junlan Feng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/626},
  pages     = {4510-4516},
  title     = {“Think before you speak”: Improving multi-action dialog policy by planning single-action dialogs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). EditSinger: Zero-shot text-based singing voice editing
system with diverse prosody modeling. <em>IJCAI</em>, 4503–4509. (<a
href="https://doi.org/10.24963/ijcai.2022/625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot text-based singing editing enables singing voice modification based on the given edited lyrics without any additional data from the target singer. However, due to the different demands, challenges occur when applying existing speech editing methods to singing voice editing task, mainly including the lack of systematic consideration concerning prosody in insertion and deletion, as well as the trade-off between the naturalness of pronunciation and the preservation of prosody in replacement. In this paper we propose EditSinger, which is a novel singing voice editing model with specially designed diverse prosody modules to overcome the challenges above. Specifically, 1) a general masked variance adaptor is introduced for the comprehensive prosody modeling of the inserted lyrics and the transition of deletion boundary; and 2) we further design a fusion pitch predictor for replacement. By disentangling the reference pitch and fusing the predicted pronunciation, the edited pitch can be reconstructed, which could ensure a natural pronunciation while preserving the prosody of the original audio. In addition, to the best of our knowledge, it is the first zero-shot text-based singing voice editing system. Our experiments conducted on the OpenSinger prove that EditSinger can synthesize high-quality edited singing voices with natural prosody according to the corresponding operations. Keywords: Natural Language Processing: Speech Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Lichao Zhang and Zhou Zhao and Yi Ren and Liqun Deng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/625},
  pages     = {4503-4509},
  title     = {EditSinger: Zero-shot text-based singing voice editing system with diverse prosody modeling},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Position-aware joint entity and relation extraction with
attention mechanism. <em>IJCAI</em>, 4496–4502. (<a
href="https://doi.org/10.24963/ijcai.2022/624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named entity recognition and relation extraction are two important core subtasks of information extraction, which aim to identify named entities and extract relations between them. In recent years, span representation methods have received a lot of attention and are widely used to extract entities and corresponding relations from plain texts. Most recent works focus on how to obtain better span representations from pre-trained encoders, but ignore the negative impact of a large number of span candidates on slowing down the model performance. In our work, we propose a joint entity and relation extraction model with an attention mechanism and position-attentive markers. The attention score of each candidate span is calculated, and most of the candidate spans with low attention scores are pruned before being fed into the span classifier, thus achieving the goal of removing the most irrelevant spans. At the same time, in order to explore whether the position information can improve the performance of the model, we add position-attentive markers to the model. The experimental results show that our model is effective. With the same pre-trained encoder, our model achieves the new state-of-the-art on standard benchmarks (ACE05, CoNLL04 and SciERC), obtaining a 4.7\%-17.8\% absolute improvement in relation F1. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Knowledge Extraction Data Mining: Knowledge Graphs and Knowledge Base Completion Natural Language Processing: Language Models Natural Language Processing: Named Entities},
  archive   = {C_IJCAI},
  author    = {Chenglong Zhang and Shuyong Gao and Haofen Wang and Wenqiang Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/624},
  pages     = {4496-4502},
  title     = {Position-aware joint entity and relation extraction with attention mechanism},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stage-wise stylistic headline generation: Style generation
and summarized content insertion. <em>IJCAI</em>, 4489–4495. (<a
href="https://doi.org/10.24963/ijcai.2022/623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A quality headline with a high click-rate should not only summarize the content of an article, but also reflect a style that attracts users. Such demand has drawn rising attention to the task of stylistic headline generation (SHG). An intuitive method is to first generate plain headlines leveraged by document-headline parallel data then transfer them to a target style. However, this inevitably suffers from error propagation. Therefore, to unify the two sub-tasks and explicitly decompose style-relevant attributes and summarize content, we propose an end-to-end stage-wise SHG model containing the style generation component and the content insertion component, where the former generates stylistic-relevant intermediate outputs and the latter receives these outputs then inserts the summarized content. The intermediate outputs are observable, making the style generation easy to control. Our system is comprehensively evaluated by both quantitative and qualitative metrics, and it achieves state-of-the-art results in SHG over three different stylistic datasets. Keywords: Natural Language Processing: Language Generation Natural Language Processing: Applications Natural Language Processing: Summarization},
  archive   = {C_IJCAI},
  author    = {Jiaao Zhan and Yang Gao and Yu Bai and Qianhui Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/623},
  pages     = {4489-4495},
  title     = {Stage-wise stylistic headline generation: Style generation and summarized content insertion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Targeted multimodal sentiment classification based on
coarse-to-fine grained image-target matching. <em>IJCAI</em>, 4482–4488.
(<a href="https://doi.org/10.24963/ijcai.2022/622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Targeted Multimodal Sentiment Classification (TMSC) aims to identify the sentiment polarities over each target mentioned in a pair of sentence and image. Existing methods to TMSC failed to explicitly capture both coarse-grained and fine-grained image-target matching, including 1) the relevance between the image and the target and 2) the alignment between visual objects and the target. To tackle this issue, we propose a new multi-task learning architecture named coarse-to-fine grained Image-Target Matching network (ITM), which jointly performs image-target relevance classification, object-target alignment, and targeted sentiment classification. We further construct an Image-Target Matching dataset by manually annotating the image-target relevance and the visual object aligned with the input target. Experiments on two benchmark TMSC datasets show that our model consistently outperforms the baselines, achieves state-of-the-art results, and presents interpretable visualizations. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining},
  archive   = {C_IJCAI},
  author    = {Jianfei Yu and Jieming Wang and Rui Xia and Junjie Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/622},
  pages     = {4482-4488},
  title     = {Targeted multimodal sentiment classification based on coarse-to-fine grained image-target matching},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Clickbait detection via contrastive variational modelling of
text and label. <em>IJCAI</em>, 4475–4481. (<a
href="https://doi.org/10.24963/ijcai.2022/621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Clickbait refers to deliberately created sensational or deceptive text for tricking readers into clicking, which severely hurts the web ecosystem. With a growing number of clickbaits on social media, developing automatic detection methods becomes essential. Nonetheless, the performance of existing neural classifiers is limited due to the underutilization of small labelled datasets. Inspired by related pedagogy theories that learning to write can promote comprehension ability, we propose a novel Contrastive Variational Modelling (CVM) framework to exploit the labelled data better. CVM models the conditional distributions of text and clickbait labels by predicting labels from text and generating text from labels simultaneously with Variational AutoEncoder and further differentiates the learned spaces under each label by a mixed contrastive learning loss. In this way, CVM can capture more underlying textual properties and hence utilize label information to its full potential, boosting detection performance. We theoretically demonstrate CVM as learning a joint distribution of text, clickbait label, and latent variable. Experiments on three clickbait detection datasets show our method&#39;s robustness to inadequate and biased labels, outperforming several recent strong baselines. Keywords: Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Xiaoyuan Yi and Jiarui Zhang and Wenhao Li and Xiting Wang and Xing Xie},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/621},
  pages     = {4475-4481},
  title     = {Clickbait detection via contrastive variational modelling of text and label},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SyntaSpeech: Syntax-aware generative adversarial
text-to-speech. <em>IJCAI</em>, 4468–4474. (<a
href="https://doi.org/10.24963/ijcai.2022/620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent progress in non-autoregressive text-to-speech (NAR-TTS) has made fast and high-quality speech synthesis possible. However, current NAR-TTS models usually use phoneme sequence as input and thus cannot understand the tree-structured syntactic information of the input sequence, which hurts the prosody modeling. To this end, we propose SyntaSpeech, a syntax-aware and light-weight NAR-TTS model, which integrates tree-structured syntactic information into the prosody modeling modules in PortaSpeech. Specifically, 1) We build a syntactic graph based on the dependency tree of the input sentence, then process the text encoding with a syntactic graph encoder to extract the syntactic information. 2) We incorporate the extracted syntactic encoding with PortaSpeech to improve the prosody prediction. 3) We introduce a multi-length discriminator to replace the flow-based post-net in PortaSpeech, which simplifies the training pipeline and improves the inference speed, while keeping the naturalness of the generated audio. Experiments on three datasets not only show that the tree-structured syntactic information grants SyntaSpeech the ability to synthesize better audio with expressive prosody, but also demonstrate the generalization ability of SyntaSpeech to adapt to multiple languages and multi-speaker text-to-speech. Ablation studies demonstrate the necessity of each component in SyntaSpeech. Source code and audio samples are available at https://syntaspeech.github.io. Keywords: Natural Language Processing: Speech},
  archive   = {C_IJCAI},
  author    = {Zhenhui Ye and Zhou Zhao and Yi Ren and Fei Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/620},
  pages     = {4468-4474},
  title     = {SyntaSpeech: Syntax-aware generative adversarial text-to-speech},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). High-resource language-specific training for multilingual
neural machine translation. <em>IJCAI</em>, 4461–4467. (<a
href="https://doi.org/10.24963/ijcai.2022/619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multilingual neural machine translation (MNMT) trained in multiple language pairs has attracted considerable attention due to fewer model parameters and lower training costs by sharing knowledge among multiple languages. Nonetheless, multilingual training is plagued by language interference degeneration in shared parameters because of the negative interference among different translation directions, especially on high-resource languages. In this paper, we propose the multilingual translation model with the high-resource language-specific training (HLT-MT) to alleviate the negative interference, which adopts the two-stage training with the language-specific selection mechanism. Specifically, we first train the multilingual model only with the high-resource pairs and select the language-specific modules at the top of the decoder to enhance the translation quality of high-resource directions. Next, the model is further trained on all available corpora to transfer knowledge from high-resource languages (HRLs) to low-resource languages (LRLs). Experimental results show that HLT-MT outperforms various strong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic experiments validate the effectiveness of our method in mitigating the negative interference in multilingual training. Keywords: Natural Language Processing: Machine Translation and Multilinguality Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Jian Yang and Yuwei Yin and Shuming Ma and Dongdong Zhang and Zhoujun Li and Furu Wei},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/619},
  pages     = {4461-4467},
  title     = {High-resource language-specific training for multilingual neural machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). UM4: Unified multilingual multiple teacher-student model for
zero-resource neural machine translation. <em>IJCAI</em>, 4454–4460. (<a
href="https://doi.org/10.24963/ijcai.2022/618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most translation tasks among languages belong to the zero-resource translation problem where parallel corpora are unavailable. Multilingual neural machine translation (MNMT) enables one-pass translation using shared semantic space for all languages compared to the two-pass pivot translation but often underperforms the pivot-based method. In this paper, we propose a novel method, named as Unified Multilingual Multiple teacher-student Model for NMT (UM4). Our method unifies source-teacher, target-teacher, and pivot-teacher models to guide the student model for the zero-resource translation. The source teacher and target teacher force the student to learn the direct source-target translation by the distilled knowledge on both source and target sides. The monolingual corpus is further leveraged by the pivot-teacher model to enhance the student model. Experimental results demonstrate that our model of 72 directions significantly outperforms previous methods on the WMT benchmark. Keywords: Natural Language Processing: Machine Translation and Multilinguality Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Jian Yang and Yuwei Yin and Shuming Ma and Dongdong Zhang and Shuangzhi Wu and Hongcheng Guo and Zhoujun Li and Furu Wei},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/618},
  pages     = {4454-4460},
  title     = {UM4: Unified multilingual multiple teacher-student model for zero-resource neural machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Diversity features enhanced prototypical network for
few-shot intent detection. <em>IJCAI</em>, 4447–4453. (<a
href="https://doi.org/10.24963/ijcai.2022/617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot Intent Detection (FSID) is a challenging task in dialogue systems due to the scarcity of available annotated utterances. Although existing few-shot learning approaches have made remarkable progress, they fall short in adapting to the Generalized Few-shot Intent Detection (GFSID) task where both seen and unseen classes are present. A core problem of the simultaneous existence of these two tasks is that limited training samples fail to cover the diversity of user expressions. In this paper, we propose an effective Diversity Features Enhanced Prototypical Network (DFEPN) to enhance diversity features for novel intents by fully exploiting the diversity of known intent samples. Specially, DFEPN generates diversity features of samples in the hidden space via a diversity feature generator module and then fuses these features with original support vectors to get a more suitable prototype vector of each class. To evaluate the effectiveness of our model on both FSID and GFSID tasks, we carry out sufficient experiments on two benchmark intent detection datasets. Results demonstrate that our proposed model outperforms existing state-of-the-art methods and keeps stable performance on both two tasks. Keywords: Natural Language Processing: Dialogue and Interactive Systems Machine Learning: Few-shot learning Machine Learning: Meta-Learning Natural Language Processing: Applications Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Fengyi Yang and Xi Zhou and Yi Wang and Abibulla Atawulla and Ran Bi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/617},
  pages     = {4447-4453},
  title     = {Diversity features enhanced prototypical network for few-shot intent detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust interpretable text classification against spurious
correlations using AND-rules with negation. <em>IJCAI</em>, 4439–4446.
(<a href="https://doi.org/10.24963/ijcai.2022/616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The state-of-the-art natural language processing models have raised the bar for excellent performance on a variety of tasks in recent years. However, concerns are rising over their primitive sensitivity to distribution biases that reside in the training and testing data. This issue hugely impacts the performance of the models when exposed to out-of-distribution and counterfactual data. The root cause seems to be that many machine learning models are prone to learn the shortcuts, modelling simple correlations rather than more fundamental and general relationships. As a result, such text classifiers tend to perform poorly when a human makes minor modifications to the data, which raises questions regarding their robustness. In this paper, we employ a rule-based architecture called Tsetlin Machine (TM) that learns both simple and complex correlations by ANDing features and their negations. As such, it generates explainable AND-rules using negated and non-negated reasoning. Here, we explore how non-negated reasoning can be more prone to distribution biases than negated reasoning. We further leverage this finding by adapting the TM architecture to mainly perform negated reasoning using the specificity parameter s. As a result, the AND-rules becomes robust to spurious correlations and can also correctly predict counterfactual data. Our empirical investigation of the model&#39;s robustness uses the specificity s to control the degree of negated reasoning. Experiments on publicly available Counterfactually-Augmented Data demonstrate that the negated clauses are robust to spurious correlations and outperform Naive Bayes, SVM, and Bi-LSTM by up to 20\%, and ELMo by almost 6\% on counterfactual test data. Keywords: Natural Language Processing: Text Classification Machine Learning: Robustness Natural Language Processing: Applications Natural Language Processing: Interpretability and Analysis of Models for NLP},
  archive   = {C_IJCAI},
  author    = {Rohan Kumar Yadav and Lei Jiao and Ole-Christoffer Granmo and Morten Goodwin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/616},
  pages     = {4439-4446},
  title     = {Robust interpretable text classification against spurious correlations using AND-rules with negation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TaxoPrompt: A prompt-based generation method with taxonomic
context for self-supervised taxonomy expansion. <em>IJCAI</em>,
4432–4438. (<a href="https://doi.org/10.24963/ijcai.2022/615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Taxonomies are hierarchical classifications widely exploited to facilitate downstream natural language processing tasks. The taxonomy expansion task aims to incorporate emergent concepts into the existing taxonomies. Prior works focus on modeling the local substructure of taxonomies but neglect the global structure. In this paper, we propose TaxoPrompt, a framework that learns the global structure by prompt tuning with taxonomic context. Prompt tuning leverages a template to formulate downstream tasks into masked language model form for better distributed semantic knowledge use. To further infuse global structure knowledge into language models, we enhance the prompt template by exploiting the taxonomic context constructed by a variant of the random walk algorithm. Experiments on seven public benchmarks show that our proposed TaxoPrompt is effective and efficient in automatically expanding taxonomies and achieves state-of-the-art performance. Keywords: Natural Language Processing: Natural Language Semantics Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Hongyuan Xu and Yunong Chen and Zichen Liu and Yanlong Wen and Xiaojie Yuan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/615},
  pages     = {4432-4438},
  title     = {TaxoPrompt: A prompt-based generation method with taxonomic context for self-supervised taxonomy expansion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural subgraph explorer: Reducing noisy information via
target-oriented syntax graph pruning. <em>IJCAI</em>, 4425–4431. (<a
href="https://doi.org/10.24963/ijcai.2022/614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed the emerging success of leveraging syntax graphs for the target sentiment classification task. However, we discover that existing syntax-based models suffer from two issues: noisy information aggregation and loss of distant correlations. In this paper, we propose a novel model termed Neural Subgraph Explorer, which (1) reduces the noisy information via pruning target-irrelevant nodes on the syntax graph; (2) introduces beneficial first-order connections between the target and its related words into the obtained graph. Specifically, we design a multi-hop actions score estimator to evaluate the value of each word regarding the specific target. The discrete action sequence is sampled through Gumble-Softmax and then used for both of the syntax graph and the self-attention graph. To introduce the first-order connections between the target and its relevant words, the two pruned graphs are merged. Finally, graph convolution is conducted on the obtained unified graph to update the hidden states. And this process is stacked with multiple layers. To our knowledge, this is the first attempt of target-oriented syntax graph pruning in this task. Experimental results demonstrate the superiority of our model, which achieves new state-of-the-art performance. Keywords: Natural Language Processing: Text Classification Machine Learning: Sequence and Graph Learning Natural Language Processing: Sentiment Analysis and Text Mining},
  archive   = {C_IJCAI},
  author    = {Bowen Xing and Ivor Tsang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/614},
  pages     = {4425-4431},
  title     = {Neural subgraph explorer: Reducing noisy information via target-oriented syntax graph pruning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Propose-and-refine: A two-stage set prediction network for
nested named entity recognition. <em>IJCAI</em>, 4418–4424. (<a
href="https://doi.org/10.24963/ijcai.2022/613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Nested named entity recognition (nested NER) is a fundamental task in natural language processing. Various span-based methods have been proposed to detect nested entities with span representations. However, span-based methods do not consider the relationship between a span and other entities or phrases, which is helpful in the NER task. Besides, span-based methods have trouble predicting long entities due to limited span enumeration length. To mitigate these issues, we present the Propose-and-Refine Network (PnRNet), a two-stage set prediction network for nested NER. In the propose stage, we use a span-based predictor to generate some coarse entity predictions as entity proposals. In the refine stage, proposals interact with each other, and richer contextual information is incorporated into the proposal representations. The refined proposal representations are used to re-predict entity boundaries and classes. In this way, errors in coarse proposals can be eliminated, and the boundary prediction is no longer constrained by the span enumeration length limitation. Additionally, we build multi-scale sentence representations, which better model the hierarchical structure of sentences and provide richer contextual information than token-level representations. Experiments show that PnRNet achieves state-of-the-art performance on four nested NER datasets and one flat NER dataset. Keywords: Natural Language Processing: Named Entities Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Shuhui Wu and Yongliang Shen and Zeqi Tan and Weiming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/613},
  pages     = {4418-4424},
  title     = {Propose-and-refine: A two-stage set prediction network for nested named entity recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised context aware sentence representation
pretraining for multi-lingual dense retrieval. <em>IJCAI</em>,
4411–4417. (<a href="https://doi.org/10.24963/ijcai.2022/612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research demonstrates the effectiveness of using pretrained language models (PLM) to improve dense retrieval and multilingual dense retrieval. In this work, we present a simple but effective monolingual pretraining task called contrastive context prediction (CCP) to learn sentence representation by modeling sentence level contextual relation. By pushing the embedding of sentences in a local context closer and pushing random negative samples away, different languages could form isomorphic structure, then sentence pairs in two different languages will be automatically aligned. Our experiments show that model collapse and information leakage are very easy to happen during contrastive training of language model, but language-specific memory bank and asymmetric batch normalization operation play an essential role in preventing collapsing and information leakage, respectively. Besides, a post-processing for sentence embedding is also very effective to achieve better retrieval performance. On the multilingual sentence retrieval task Tatoeba, our model achieves new SOTA results among methods without using bilingual data. Our model also shows larger gain on Tatoeba when transferring between non-English pairs. On two multi-lingual query-passage retrieval tasks, XOR Retrieve and Mr.TYDI, our model even achieves two SOTA results in both zero-shot and supervised setting among all pretraining models using bilingual data. Keywords: Natural Language Processing: Information Retrieval and Text Mining Natural Language Processing: Embeddings Natural Language Processing: Machine Translation and Multilinguality},
  archive   = {C_IJCAI},
  author    = {Ning Wu and Yaobo Liang and Houxing Ren and Linjun Shou and Nan Duan and Ming Gong and Daxin Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/612},
  pages     = {4411-4417},
  title     = {Unsupervised context aware sentence representation pretraining for multi-lingual dense retrieval},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MGAD: Learning descriptional representation distilled from
distributional semantics for unseen entities. <em>IJCAI</em>, 4404–4410.
(<a href="https://doi.org/10.24963/ijcai.2022/611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Entity representation plays a central role in building effective entity retrieval models. Recent works propose to learn entity representations based on entity-centric contexts, which achieve SOTA performances on many tasks. However, these methods lead to poor representations for unseen entities since they rely on a multitude of occurrences for each entity to enable accurate representations. To address this issue, we propose to learn enhanced descriptional representations for unseen entities by distilling knowledge from distributional semantics into descriptional embeddings. Specifically, we infer enhanced embeddings for unseen entities based on descriptions by aligning the descriptional embedding space to the distributional embedding space with different granularities, i.e., element-level, batch-level and space-level alignment. Experimental results on four benchmark datasets show that our approach improves the performance over all baseline methods. In particular, our approach can achieve the effectiveness of the teacher model on almost all entities, and maintain such high performance on unseen entities. Keywords: Natural Language Processing: Named Entities Natural Language Processing: Information Retrieval and Text Mining Natural Language Processing: Coreference Resolution Natural Language Processing: Embeddings Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Yuanzheng Wang and Xueqi Cheng and Yixing Fan and Xiaofei Zhu and Huasheng Liang and Qiang Yan and Jiafeng Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/611},
  pages     = {4404-4410},
  title     = {MGAD: Learning descriptional representation distilled from distributional semantics for unseen entities},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust fine-tuning via perturbation and interpolation from
in-batch instances. <em>IJCAI</em>, 4397–4403. (<a
href="https://doi.org/10.24963/ijcai.2022/610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-tuning pretrained language models (PLMs) on downstream tasks has become common practice in natural language processing. However, most of the PLMs are vulnerable, e.g., they are brittle under adversarial attacks or imbalanced data, which hinders the application of the PLMs on some downstream tasks, especially in safe-critical scenarios. In this paper, we propose a simple yet effective fine-tuning method called Match-Tuning to force the PLMs to be more robust. For each instance in a batch, we involve other instances in the same batch to interact with it. To be specific, regarding the instances with other labels as a perturbation, Match-Tuning makes the model more robust to noise at the beginning of training. While nearing the end, Match-Tuning focuses more on performing an interpolation among the instances with the same label for better generalization. Extensive experiments on various tasks in GLUE benchmark show that Match-Tuning consistently outperforms the vanilla fine-tuning by 1.64 scores. Moreover, Match-Tuning exhibits remarkable robustness to adversarial attacks and data imbalance. Keywords: Natural Language Processing: Text Classification Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Shoujie Tong and Qingxiu Dong and Damai Dai and Yifan Song and Tianyu Liu and Baobao Chang and Zhifang Sui},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/610},
  pages     = {4397-4403},
  title     = {Robust fine-tuning via perturbation and interpolation from in-batch instances},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning by interpreting. <em>IJCAI</em>, 4390–4396. (<a
href="https://doi.org/10.24963/ijcai.2022/609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper introduces a novel way of enhancing NLP prediction accuracy by incorporating model interpretation insights. Conventional efforts often focus on balancing the trade-offs between accuracy and interpretability, for instance, sacrificing model performance to increase the explainability. Here, we take a unique approach and show that model interpretation can ultimately help improve NLP quality. Specifically, we employ our learned interpretability results using attention mechanisms, LIME, and SHAP to train our model. We demonstrate a significant increase in accuracy of up to +3.4 BLEU points on NMT and up to +4.8 points on GLUE tasks, verifying our hypothesis that it is possible to achieve better model learning by incorporating model interpretation knowledge. Keywords: Natural Language Processing: Interpretability and Analysis of Models for NLP Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Attention Models AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Xuting Tang and Abdul Rafae Khan and Shusen Wang and Jia Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/609},
  pages     = {4390-4396},
  title     = {Learning by interpreting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards discourse-aware document-level neural machine
translation. <em>IJCAI</em>, 4383–4389. (<a
href="https://doi.org/10.24963/ijcai.2022/608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current document-level neural machine translation (NMT) systems have achieved remarkable progress with document context. Nevertheless, discourse information that has been proven effective in many NLP tasks is ignored in most previous work. In this work, we aim at incorporating the coherence information hidden within the RST-style discourse structure into machine translation. To achieve it, we propose a document-level NMT system enhanced with the discourse-aware document context, which is named Disco2NMT. Specifically, Disco2NMT models document context based on the discourse dependency structures through a hierarchical architecture. We first convert the RST tree of an article into a dependency structure and then build the graph convolutional network (GCN) upon the segmented EDUs under the guidance of RST dependencies to capture the discourse-aware context for NMT incorporation. We conduct experiments on the document-level English-German and English-Chinese translation tasks with three domains (TED, News, and Europarl). Experimental results show that our Disco2NMT model significantly surpasses both context-agnostic and context-aware baseline systems on multiple evaluation indicators. Keywords: Natural Language Processing: Machine Translation and Multilinguality Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Xin Tan and Longyin Zhang and Fang Kong and Guodong Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/608},
  pages     = {4383-4389},
  title     = {Towards discourse-aware document-level neural machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On tracking dialogue state by inheriting slot values in
mentioned slot pools. <em>IJCAI</em>, 4375–4382. (<a
href="https://doi.org/10.24963/ijcai.2022/607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dialogue state tracking (DST) is a component of the task oriented dialogue system. It is responsible for extracting and managing slots, where each slot represents a part of the information to accomplish a task, and slot value is updated recurrently in each dialogue turn. However, many DST models cannot update slot values appropriately. These models may repeatedly inherit wrong slot values extracted in previous turns, resulting in the fail of the entire DST task. They cannot update indirectly mentioned slots well, either. This study designed a model with a mentioned slot pool (MSP) to tackle the update problem. The MSP is a slot specific memory that records all mentioned slot values that may be inherited, and our model updates slot values according to the MSP and the dialogue context. Our model rejects inheriting the previous slot value when it predicates the value is wrong. Then, it extracts the slot value from the current dialogue context. As the contextual information accumulates, the new value is more likely to be correct. It also can track the indirectly mentioned slot by picking a value from the MSP. Experimental results showed our model reached state of the art DST performance on MultiWOZ datasets. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Zhoujian Sun and Zhengxing Huang and Nai Ding},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/607},
  pages     = {4375-4382},
  title     = {On tracking dialogue state by inheriting slot values in mentioned slot pools},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified strategy for multilingual grammatical error
correction with pre-trained cross-lingual language model.
<em>IJCAI</em>, 4367–4374. (<a
href="https://doi.org/10.24963/ijcai.2022/606">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthetic data construction of Grammatical Error Correction (GEC) for non-English languages relies heavily on human-designed and language-specific rules, which produce limited error-corrected patterns. In this paper, we propose a generic and language-independent strategy for multilingual GEC, which can train a GEC system effectively for a new non-English language with only two easy-to-access resources: 1) a pre-trained cross-lingual language model (PXLM) and 2) parallel translation data between English and the language. Our approach creates diverse parallel GEC data without any language-specific operations by taking the non-autoregressive translation generated by PXLM and the gold translation as error-corrected sentence pairs. Then, we reuse PXLM to initialize the GEC model and pre-train it with the synthetic data generated by itself, which yields further improvement. We evaluate our approach on three public benchmarks of GEC in different languages. It achieves the state-of-the-art results on the NLPCC 2018 Task 2 dataset (Chinese) and obtains competitive performance on Falko-Merlin (German) and RULEC-GEC (Russian). Further analysis demonstrates that our data construction method is complementary to rule-based approaches. Keywords: Natural Language Processing: Applications Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Xin Sun and Tao Ge and Shuming Ma and Jingjing Li and Furu Wei and Houfeng Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/606},
  pages     = {4367-4374},
  title     = {A unified strategy for multilingual grammatical error correction with pre-trained cross-lingual language model},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relational triple extraction: One step is enough.
<em>IJCAI</em>, 4360–4366. (<a
href="https://doi.org/10.24963/ijcai.2022/605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Extracting relational triples from unstructured text is an essential task in natural language processing and knowledge graph construction. Existing approaches usually contain two fundamental steps: (1) finding the boundary positions of head and tail entities; (2) concatenating specific tokens to form triples. However, nearly all previous methods suffer from the problem of error accumulation, i.e., the boundary recognition error of each entity in step (1) will be accumulated into the final combined triples. To solve the problem, in this paper, we introduce a fresh perspective to revisit the triple extraction task and propose a simple but effective model, named DirectRel. Specifically, the proposed model first generates candidate entities through enumerating token sequences in a sentence, and then transforms the triple extraction task into a linking problem on a ``head -&gt; tail&quot; bipartite graph. By doing so, all triples can be directly extracted in only one step. Extensive experimental results on two widely used datasets demonstrate that the proposed model performs better than the state-of-the-art baselines. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Yu-Ming Shang and Heyan Huang and Xin Sun and Wei Wei and Xian-Ling Mao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/605},
  pages     = {4360-4366},
  title     = {Relational triple extraction: One step is enough},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Training naturalized semantic parsers with very little data.
<em>IJCAI</em>, 4353–4359. (<a
href="https://doi.org/10.24963/ijcai.2022/604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic parsing is an important NLP problem, particularly for voice assistants such as Alexa and Google Assistant. State-of-the-art (SOTA) semantic parsers are seq2seq architectures based on large language models that have been pretrained on vast amounts of text. To better leverage that pretraining, recent work has explored a reformulation of semantic parsing whereby the output sequences are themselves natural language sentences, but in a controlled fragment of natural language. This approach delivers strong results, particularly for few-shot semantic parsing, which is of key importance in practice and the focus of our paper. We push this line of work forward by introducing an automated methodology that delivers very significant additional improvements by utilizing modest amounts of unannotated data, which is typically easy to obtain. Our method is based on a novel synthesis of four techniques: joint training with auxiliary unsupervised tasks; constrained decoding; self-training; and paraphrasing. We show that this method delivers new SOTA few-shot performance on the Overnight dataset, particularly in very low-resource settings, and very compelling few-shot results on a new semantic parsing dataset. Keywords: Natural Language Processing: Dialogue and Interactive Systems Machine Learning: Few-shot learning Natural Language Processing: Tagging, Chunking, and Parsing Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Subendhu Rongali and Konstantine Arkoudas and Melanie Rubino and Wael Hamza},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/604},
  pages     = {4353-4359},
  title     = {Training naturalized semantic parsers with very little data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BiFSMN: Binary neural network for keyword spotting.
<em>IJCAI</em>, 4346–4352. (<a
href="https://doi.org/10.24963/ijcai.2022/603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The deep neural networks, such as the Deep-FSMN, have been widely studied for keyword spotting (KWS) applications. However, computational resources for these networks are significantly constrained since they usually run on-call on edge devices. In this paper, we present BiFSMN, an accurate and extreme-efficient binary neural network for KWS. We first construct a High-frequency Enhancement Distillation scheme for the binarization-aware training, which emphasizes the high-frequency information from the full-precision network&#39;s representation that is more crucial for the optimization of the binarized network. Then, to allow the instant and adaptive accuracy-efficiency trade-offs at runtime, we also propose a Thinnable Binarization Architecture to further liberate the acceleration potential of the binarized network from the topology perspective. Moreover, we implement a Fast Bitwise Computation Kernel for BiFSMN on ARMv8 devices which fully utilizes registers and increases instruction throughput to push the limit of deployment efficiency. Extensive experiments show that BiFSMN outperforms existing binarization methods by convincing margins on various datasets and is even comparable with the full-precision counterpart (e.g., less than 3\% drop on Speech Commands V1-12). We highlight that benefiting from the thinnable architecture and the optimized 1-bit implementation, BiFSMN can achieve an impressive 22.3x speedup and 15.5x storage-saving on real-world edge hardware. Keywords: Natural Language Processing: Speech Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Haotong Qin and Xudong Ma and Yifu Ding and Xiaoyang Li and Yang Zhang and Yao Tian and Zejun Ma and Jie Luo and Xianglong Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/603},
  pages     = {4346-4352},
  title     = {BiFSMN: Binary neural network for keyword spotting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Document-level event factuality identification via
reinforced multi-granularity hierarchical attention networks.
<em>IJCAI</em>, 4338–4345. (<a
href="https://doi.org/10.24963/ijcai.2022/602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level Event Factuality Identification (DEFI) predicts the event factuality according to the current document, and mainly depends on event-related tokens and sentences. However, previous studies relied on annotated information and did not filter irrelevant and noisy texts. Therefore, this paper proposes a novel end-to-end model, i.e., Reinforced Multi-Granularity Hierarchical Attention Network (RMHAN), which can learn information at different levels of granularity from tokens and sentences hierarchically. Moreover, with hierarchical reinforcement learning, RMHAN first selects relevant and meaningful tokens, and then selects useful sentences for document-level encoding. Experimental results on DLEF-v2 corpus show that RMHAN model outperforms several state-of-the-art baselines and achieves the best performance. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Text Classification Natural Language Processing: Information Retrieval and Text Mining Natural Language Processing: Natural Language Semantics},
  archive   = {C_IJCAI},
  author    = {Zhong Qian and Peifeng Li and Qiaoming Zhu and Guodong Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/602},
  pages     = {4338-4345},
  title     = {Document-level event factuality identification via reinforced multi-granularity hierarchical attention networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Document-level relation extraction via subgraph reasoning.
<em>IJCAI</em>, 4331–4337. (<a
href="https://doi.org/10.24963/ijcai.2022/601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level relation extraction aims to extract relations between entities in a document. In contrast to sentence-level relation extraction, it deals with longer texts and more complex entity interactions, which requires reasoning over multiple sentences with rich reasoning skills. Most current researches construct a document-level graph first, and then focus on the overall graph structure or the paths between the target entity pair in the graph. In this paper, we propose a novel subgraph reasoning (SGR) framework for document-level relation extraction. SGR combines the advantages of both graph-based models and path-based models, integrating various paths between the target entity pair into a much simpler subgraph structure to perform relational reasoning. Moreover, the paths generated by our designed heuristic strategy explicitly model the requisite reasoning skills and roughly cover the supporting sentences for each relation instance. Experimental results on DocRED show that SGR outperforms existing models, and further analyses demonstrate that our method is both effective and explainable. Our code is available at https://github.com/Crysta1ovo/SGR. Keywords: Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Xingyu Peng and Chong Zhang and Ke Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/601},
  pages     = {4331-4337},
  title     = {Document-level relation extraction via subgraph reasoning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Control globally, understand locally: A global-to-local
hierarchical graph network for emotional support conversation.
<em>IJCAI</em>, 4324–4330. (<a
href="https://doi.org/10.24963/ijcai.2022/600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Emotional support conversation aims at reducing the emotional distress of the help-seeker, which is a new and challenging task. It requires the system to explore the cause of help-seeker&#39;s emotional distress and understand their psychological intention to provide supportive responses. However, existing methods mainly focus on the sequential contextual information, ignoring the hierarchical relationships with the global cause and local psychological intention behind conversations, thus leads to a weak ability of emotional support. In this paper, we propose a Global-to-Local Hierarchical Graph Network to capture the multi-source information (global cause, local intentions and dialog history) and model hierarchical relationships between them, which consists of a multi-source encoder, a hierarchical graph reasoner, and a global-guide decoder. Furthermore, a novel training objective is designed to monitor semantic information of the global cause. Experimental results on the emotional support conversation dataset, ESConv, confirm that the proposed GLHG has achieved the state-of-the-art performance on the automatic and human evaluations. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Wei Peng and Yue Hu and Luxi Xing and Yuqiang Xie and Yajing Sun and Yunpeng Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/600},
  pages     = {4324-4330},
  title     = {Control globally, understand locally: A global-to-local hierarchical graph network for emotional support conversation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic noisy label correction for fine-grained entity
typing. <em>IJCAI</em>, 4317–4323. (<a
href="https://doi.org/10.24963/ijcai.2022/599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fine-grained entity typing (FET) aims to assign proper semantic types to entity mentions according to their context, which is a fundamental task in various entity-leveraging applications. Current FET systems usually establish on large-scale weaklysupervised/distantly annotation data, which may contain abundant noise and thus severely hinder the performance of the FET task. Although previous studies have made great success in automatically identifying the noisy labels in FET, they usually rely on some auxiliary resources which may be unavailable in real-world applications (e.g., pre-defined hierarchical type structures, humanannotated subsets). In this paper, we propose a novel approach to automatically correct noisy labels for FET without external resources. Specifically, it first identifies the potentially noisy labels by estimating the posterior probability of a label being positive or negative according to the logits output by the model, and then relabel candidate noisy labels by training a robust model over the remaining clean labels. Experiments on two popular benchmarks prove the effectiveness of our method. Our source code can be obtained from https://github.com/CCIIPLab/DenoiseFET. Keywords: Natural Language Processing: Named Entities Natural Language Processing: Applications Natural Language Processing: Information Retrieval and Text Mining},
  archive   = {C_IJCAI},
  author    = {Weiran Pan and Wei Wei and Feida Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/599},
  pages     = {4317-4323},
  title     = {Automatic noisy label correction for fine-grained entity typing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing text generation via multi-level knowledge aware
reasoning. <em>IJCAI</em>, 4310–4316. (<a
href="https://doi.org/10.24963/ijcai.2022/598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How to generate high-quality textual content is a non-trivial task. Existing methods generally generate text by grounding on word-level knowledge. However, word-level knowledge cannot express multi-word text units, hence existing methods may generate low-quality and unreasonable text. In this paper, we leverage event-level knowledge to enhance text generation. However, event knowledge is very sparse. To solve this problem, we split a coarse-grained event into fine-grained word components to obtain the word-level knowledge among event components. The word-level knowledge models the interaction among event components, which makes it possible to reduce the sparsity of events. Based on the event-level and the word-level knowledge, we devise a multi-level knowledge aware reasoning framework. Specifically, we first utilize event knowledge to make event-based content planning, i.e., select reasonable event sketches conditioned by the input text. Then, we combine the selected event sketches with the word-level knowledge for text generation. We validate our method on two widely used datasets, experimental results demonstrate the effectiveness of our framework to text generation. Keywords: Natural Language Processing: Applications Knowledge Representation and Reasoning: Common-Sense Reasoning Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Feiteng Mu and Wenjie Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/598},
  pages     = {4310-4316},
  title     = {Enhancing text generation via multi-level knowledge aware reasoning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Variational learning for unsupervised knowledge grounded
dialogs. <em>IJCAI</em>, 4303–4309. (<a
href="https://doi.org/10.24963/ijcai.2022/597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent methods for knowledge grounded dialogs generate responses by incorporating information from an external textual document. These methods do not require the exact document to be known during training and rely on the use of a retrieval system to fetch relevant documents from a large index. The documents used to generate the responses are modeled as latent variables whose prior probabilities need to be estimated. Models such as RAG, marginalize the document probabilities over the documents retrieved from the index to define the log-likelihood loss function which is optimized end-to-end. In this paper, we develop a variational approach to the above technique wherein, we instead maximize the Evidence Lower bound (ELBO). Using a collection of three publicly available open-conversation datasets, we demonstrate how the posterior distribution, which has information from the ground-truth response, allows for a better approximation of the objective function during training. To overcome the challenges associated with sampling over a large knowledge collection, we develop an efficient approach to approximate the ELBO. To the best of our knowledge, we are the first to apply variational training for open-scale unsupervised knowledge grounded dialog systems. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Language Grounding},
  archive   = {C_IJCAI},
  author    = {Mayank Mishra and Dhiraj Madan and Gaurav Pandey and Danish Contractor},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/597},
  pages     = {4303-4309},
  title     = {Variational learning for unsupervised knowledge grounded dialogs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Prompting to distill: Boosting data-free knowledge
distillation via reinforced prompt. <em>IJCAI</em>, 4296–4302. (<a
href="https://doi.org/10.24963/ijcai.2022/596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data-free knowledge distillation (DFKD) conducts knowledge distillation via eliminating the dependence of original training data, and has recently achieved impressive results in accelerating pre-trained language models. At the heart of DFKD is to reconstruct a synthetic dataset by inverting the parameters of the uncompressed model. Prior DFKD approaches, however, have largely relied on hand-crafted priors of the target data distribution for the reconstruction, which can be inevitably biased and often incompetent to capture the intrinsic distributions. To address this problem, we propose a prompt-based method, termed as PromptDFD, that allows us to take advantage of learned language priors, which effectively harmonizes the synthetic sentences to be semantically and grammatically correct. Specifically, PromptDFD leverages a pre-trained generative model to provide language priors and introduces a reinforced topic prompter to control data synthesis, making the generated samples thematically relevant and semantically plausible, and thus friendly to downstream tasks. As shown in our experiments, the proposed method substantially improves the synthesis quality and achieves considerable improvements on distillation performance. In some cases, PromptDFD even gives rise to results on par with those from the data-driven knowledge distillation with access to the original training data. Keywords: Natural Language Processing: Other Machine Learning: Multi-task and Transfer Learning Natural Language Processing: Language Models Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Xinyin Ma and Xinchao Wang and Gongfan Fang and Yongliang Shen and Weiming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/596},
  pages     = {4296-4302},
  title     = {Prompting to distill: Boosting data-free knowledge distillation via reinforced prompt},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Searching for optimal subword tokenization in cross-domain
NER. <em>IJCAI</em>, 4289–4295. (<a
href="https://doi.org/10.24963/ijcai.2022/595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Input distribution shift is one of the vital problems in unsupervised domain adaptation (UDA). The most popular UDA approaches focus on domain-invariant representation learning, trying to align the features from different domains into a similar feature distribution. However, these approaches ignore the direct alignment of input word distributions between domains, which is a vital factor in word-level classification tasks such as cross-domain NER. In this work, we shed new light on cross-domain NER by introducing a subword-level solution, X-Piece, for input word-level distribution shift in NER. Specifically, we re-tokenize the input words of the source domain to approach the target subword distribution, which is formulated and solved as an optimal transport problem. As this approach focuses on the input level, it can also be combined with previous DIRL methods for further improvement. Experimental results show the effectiveness of the proposed method based on BERT-tagger on four benchmark NER datasets. Also, the proposed method is proved to benefit DIRL methods such as DANN. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Tagging, Chunking, and Parsing},
  archive   = {C_IJCAI},
  author    = {Ruotian Ma and Yiding Tan and Xin Zhou and Xuanting Chen and Di Liang and Sirui Wang and Wei Wu and Tao Gui},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/595},
  pages     = {4289-4295},
  title     = {Searching for optimal subword tokenization in cross-domain NER},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph-based dynamic word embeddings. <em>IJCAI</em>,
4280–4288. (<a href="https://doi.org/10.24963/ijcai.2022/594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As time goes by, language evolves with word semantics changing. Unfortunately, traditional word embedding methods neglect the evolution of language and assume that word representations are static. Although contextualized word embedding models can capture the diverse representations of polysemous words, they ignore temporal information as well. To tackle the aforementioned challenges, we propose a graph-based dynamic word embedding (GDWE) model, which focuses on capturing the semantic drift of words continually. We introduce word-level knowledge graphs (WKGs) to store short-term and long-term knowledge. WKGs can provide rich structural information as supplement of lexical information, which help enhance the word embedding quality and capture semantic drift quickly. Theoretical analysis and extensive experiments validate the effectiveness of our GDWE on dynamic word embedding learning. Keywords: Natural Language Processing: Embeddings Machine Learning: Online Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Yuyin Lu and Xin Cheng and Ziran Liang and Yanghui Rao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/594},
  pages     = {4280-4288},
  title     = {Graph-based dynamic word embeddings},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abstract rule learning for paraphrase generation.
<em>IJCAI</em>, 4273–4279. (<a
href="https://doi.org/10.24963/ijcai.2022/593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In early years, paraphrase generation typically adopts rule-based methods, which are interpretable and able to make global transformations to the original sentence. But they struggle to produce fluent paraphrases. Recently, deep neural networks have shown impressive performances in generating paraphrases. However, the current neural models are black boxes and are prone to make local modifications to the inputs. In this work, we combine these two approaches into RULER, a novel approach that performs abstract rule learning for paraphrasing. The key idea is to explicitly learn generalizable rules that could enhance the paraphrase generation process of neural networks. In RULER, we first propose a rule generalizability metric to guide the model to generate rules underlying the paraphrasing. Then, we leverage neural networks to generate paraphrases by refining the sentences transformed by the learned rules. Extensive experimental results demonstrate the superiority of RULER over previous state-of-the-art methods in terms of paraphrase quality, generalization ability and interpretability. Keywords: Natural Language Processing: Language Generation Natural Language Processing: Summarization Knowledge Representation and Reasoning: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Xianggen Liu and Wenqiang Lei and Jiancheng Lv and Jizhe Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/593},
  pages     = {4273-4279},
  title     = {Abstract rule learning for paraphrase generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). “My nose is running.” “Are you also coughing?”: Building a
medical diagnosis agent with interpretable inquiry logics.
<em>IJCAI</em>, 4266–4272. (<a
href="https://doi.org/10.24963/ijcai.2022/592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rise of telemedicine, the task of developing Dialogue Systems for Medical Diagnosis (DSMD) has received much attention in recent years. Different from early researches that needed to rely on extra human resources and expertise to build the system, recent researches focused on how to build DSMD in a data-driven manner. However, the previous data-driven DSMD methods largely overlooked the system interpretability, which is critical for a medical application, and they also suffered from the data sparsity issue at the same time. In this paper, we explore how to bring interpretability to data-driven DSMD. Specifically, we propose a more interpretable decision process to implement the dialogue manager of DSMD by reasonably mimicking real doctors&#39; inquiry logics, and we devise a model with highly transparent components to conduct the inference. Moreover, we collect a new DSMD dataset, which has a much larger scale, more diverse patterns, and is of higher quality than the existing ones. The experiments show that our method obtains 7.7\%, 10.0\%, 3.0\% absolute improvement in diagnosis accuracy respectively on three datasets, demonstrating the effectiveness of its rational decision process and model design. Our codes and the GMD-12 dataset are available at https://github.com/lwgkzl/BR-Agent. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Applications Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Wenge Liu and Yi Cheng and Hao Wang and Jianheng Tang and Yafei Liu and Ruihui Zhao and Wenjie Li and Yefeng Zheng and Xiaodan Liang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/592},
  pages     = {4266-4272},
  title     = {“My nose is running.” “Are you also coughing?”: Building a medical diagnosis agent with interpretable inquiry logics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Generating a structured summary of numerous academic papers:
Dataset and method. <em>IJCAI</em>, 4259–4265. (<a
href="https://doi.org/10.24963/ijcai.2022/591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Writing a survey paper on one research topic usually needs to cover the salient content from numerous related papers, which can be modeled as a multi-document summarization (MDS) task. Existing MDS datasets usually focus on producing the structureless summary covering a few input documents. Meanwhile, previous structured summary generation works focus on summarizing a single document into a multi-section summary. These existing datasets and methods cannot meet the requirements of summarizing numerous academic papers into a structured summary. To deal with the scarcity of available data, we propose BigSurvey, the first large-scale dataset for generating comprehensive summaries of numerous academic papers on each topic. We collect target summaries from more than seven thousand survey papers and utilize their 430 thousand reference papers’ abstracts as input documents. To organize the diverse content from dozens of input documents and ensure the efficiency of processing long text sequences, we propose a summarization method named category-based alignment and sparse transformer (CAST). The experimental results show that our CAST method outperforms various advanced summarization methods. Keywords: Natural Language Processing: Summarization Natural Language Processing: Language Generation Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Shuaiqi LIU and Jiannong Cao and Ruosong Yang and Zhiyuan Wen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/591},
  pages     = {4259-4265},
  title     = {Generating a structured summary of numerous academic papers: Dataset and method},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Low-resource NER by data augmentation with prompting.
<em>IJCAI</em>, 4252–4258. (<a
href="https://doi.org/10.24963/ijcai.2022/590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Named entity recognition (NER) is a fundamental information extraction task that seeks to identify entity mentions of certain types in text. Despite numerous advances, the existing NER methods rely on extensive supervision for model training, which struggle in a low-resource scenario with limited training data. In this paper, we propose a new data augmentation method for low-resource NER, by eliciting knowledge from BERT with prompting strategies. Particularly, we devise a label-conditioned word replacement strategy that can produce more label-consistent examples by capturing the underlying word-label dependencies, and a prompting with question answering method to generate new training data from unlabeled texts. The experimental results have widely confirmed the effectiveness of our approach. Particularly, in a low-resource scenario with only 150 training sentences, our approach outperforms previous methods without data augmentation by over 40\% in F1 and prior best data augmentation methods by over 2.0\% in F1. Furthermore, our approach also fits with a zero-shot scenario, yielding promising results without using any human-labeled data for the task. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Jian Liu and Yufeng Chen and Jinan Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/590},
  pages     = {4252-4258},
  title     = {Low-resource NER by data augmentation with prompting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CUP: Curriculum learning based prompt tuning for implicit
event argument extraction. <em>IJCAI</em>, 4245–4251. (<a
href="https://doi.org/10.24963/ijcai.2022/589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Implicit event argument extraction (EAE) aims to identify arguments that could scatter over the document. Most previous work focuses on learning the direct relations between arguments and the given trigger, while the implicit relations with long-range dependency are not well studied. Moreover, recent neural network based approaches rely on a large amount of labeled data for training, which is unavailable due to the high labelling cost. In this paper, we propose a Curriculum learning based Prompt tuning (CUP) approach, which resolves implicit EAE by four learning stages. The stages are defined according to the relations with the trigger node in a semantic graph, which well captures the long-range dependency between arguments and the trigger. In addition, we integrate a prompt-based encoder-decoder model to elicit related knowledge from pre-trained language models (PLMs) in each stage, where the prompt templates are adapted with the learning progress to enhance the reasoning for arguments. Experimental results on two well-known benchmark datasets show the great advantages of our proposed approach. In particular, we outperform the state-of-the-art models in both fully-supervised and low-data scenarios. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Language Models},
  archive   = {C_IJCAI},
  author    = {Jiaju Lin and Qin Chen and Jie Zhou and Jian Jin and Liang He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/589},
  pages     = {4245-4251},
  title     = {CUP: Curriculum learning based prompt tuning for implicit event argument extraction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lyra: A benchmark for turducken-style code generation.
<em>IJCAI</em>, 4238–4244. (<a
href="https://doi.org/10.24963/ijcai.2022/588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, neural techniques have been used to generate source code automatically. While promising for declarative languages, these approaches achieve much poorer performance on datasets for imperative languages. Since a declarative language is typically embedded in an imperative language (i.e., the turducken-style programming) in real-world software development, the promising results on declarative languages can hardly lead to significant reduction of manual software development efforts. In this paper, we define a new code generation task: given a natural language comment, this task aims to generate a program in a base imperative language with an embedded declarative language. To our knowledge, this is the first turducken-style code generation task. For this task, we present Lyra: a dataset in Python with embedded SQL. This dataset contains 2, 000 carefully annotated database manipulation programs from real usage projects. Each program is paired with both a Chinese comment and an English comment. In our experiment, we adopted Transformer, BERT-style, and GPT-style models as baselines. In the best setting, GPT-style model can achieve 24\% and 25.5\% AST exact matching accuracy using Chinese and English comments, respectively. Therefore, we believe that Lyra provides a new challenge for code generation. Yet, overcoming this challenge may significantly boost the applicability of code generation techniques for real-world software development. Keywords: Natural Language Processing: Resources and Evaluation Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Qingyuan Liang and Zeyu Sun and Qihao Zhu and Wenjie Zhang and Lian Yu and Yingfei Xiong and Lu Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/588},
  pages     = {4238-4244},
  title     = {Lyra: A benchmark for turducken-style code generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022c). Explicit alignment learning for neural machine translation.
<em>IJCAI</em>, 4230–4237. (<a
href="https://doi.org/10.24963/ijcai.2022/587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Even though neural machine translation (NMT) has become the state-of-the-art solution for end-to-end translation, it still suffers from a lack of translation interpretability, which may be conveniently enhanced by explicit alignment learning (EAL), as performed in traditional statistical machine translation (SMT). To provide the benefits of both NMT and SMT, this paper presents a novel model design that enhances NMT with an additional training process for EAL, in addition to the end-to-end translation training. Thus, we propose two approaches an explicit alignment learning approach, in which we further remove the need for the additional alignment model, and perform embedding mixup with the alignment based on encoder--decoder attention weights in the NMT model. We conducted experiments on both small-scale (IWSLT14 De-&gt;En and IWSLT13 Fr-&gt;En) and large-scale (WMT14 En-&gt;De, En-&gt;Fr, WMT17 Zh-&gt;En) benchmarks. Evaluation results show that our EAL methods significantly outperformed strong baseline methods, which shows the effectiveness of EAL. Further explorations show that the translation improvements are due to a better spatial alignment of the source and target language embeddings. Our method improves translation performance without the need to increase model parameters and training data, which verifies that the idea of incorporating techniques of SMT into NMT is worthwhile. Keywords: Natural Language Processing: Machine Translation and Multilinguality Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Zuchao Li and Hai Zhao and Fengshun Xiao and Masao Utiyama and Eiichiro Sumita},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/587},
  pages     = {4230-4237},
  title     = {Explicit alignment learning for neural machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameter-efficient sparsity for large language models
fine-tuning. <em>IJCAI</em>, 4223–4229. (<a
href="https://doi.org/10.24963/ijcai.2022/586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the dramatically increased number of parameters in language models, sparsity methods have received ever-increasing research focus to compress and accelerate the models. While most research focuses on how to accurately retain appropriate weights while maintaining the performance of the compressed model, there are challenges in the computational overhead and memory footprint of sparse training when compressing large-scale language models. To address this problem, we propose a Parameter-efficient Sparse Training (PST) method to reduce the number of trainable parameters during sparse-aware training in downstream tasks. Specifically, we first combine the data-free and data-driven criteria to efficiently and accurately measure the importance of weights. Then we investigate the intrinsic redundancy of data-driven weight importance and derive two obvious characteristics i.e. low-rankness and structuredness. Based on that, two groups of small matrices are introduced to compute the data-driven importance of weights, instead of using the original large importance score matrix, which therefore makes the sparse training resource-efficient and parameter-efficient. Experiments with diverse networks (i.e. BERT, RoBERTa and GPT-2) on dozens of datasets demonstrate PST performs on par or better than previous sparsity methods, despite only training a small number of parameters. For instance, compared with previous sparsity methods, our PST only requires 1.5\% trainable parameters to achieve comparable performance on BERT. Keywords: Natural Language Processing: Language Models Machine Learning: Learning Sparse Models},
  archive   = {C_IJCAI},
  author    = {Yuchao Li and Fuli Luo and Chuanqi Tan and Mengdi Wang and Songfang Huang and Shen Li and Junjie Bai},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/586},
  pages     = {4223-4229},
  title     = {Parameter-efficient sparsity for large language models fine-tuning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain-adaptive text classification with structured
knowledge from unlabeled data. <em>IJCAI</em>, 4216–4222. (<a
href="https://doi.org/10.24963/ijcai.2022/585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptive text classification is a challenging problem for the large-scale pretrained language models because they often require expensive additional labeled data to adapt to new domains. Existing works usually fails to leverage the implicit relationships among words across domains. In this paper, we propose a novel method, called Domain Adaptation with Structured Knowledge (DASK), to enhance domain adaptation by exploiting word-level semantic relationships. DASK first builds a knowledge graph to capture the relationship between pivot terms (domain-independent words) and non-pivot terms in the target domain. Then during training, DASK injects pivot-related knowledge graph information into source domain texts. For the downstream task, these knowledge-injected texts are fed into a BERT variant capable of processing knowledge-injected textual data. Thanks to the knowledge injection, our model learns domain-invariant features for non-pivots according to their relationships with pivots. DASK ensures the pivots to have domain-invariant behaviors by dynamically inferring via the polarity scores of candidate pivots during training with pseudo-labels. We validate DASK on a wide range of cross-domain sentiment classification tasks and observe up to 2.9\% absolute performance improvement over baselines for 20 different domain pairs. Code is available at https://github.com/hikaru-nara/DASK. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Knowledge Extraction Natural Language Processing: Natural Language Semantics Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Tian Li and Xiang Chen and Zhen Dong and Kurt Keutzer and Shanghang Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/585},
  pages     = {4216-4222},
  title     = {Domain-adaptive text classification with structured knowledge from unlabeled data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neutral utterances are also causes: Enhancing conversational
causal emotion entailment with social commonsense knowledge.
<em>IJCAI</em>, 4209–4215. (<a
href="https://doi.org/10.24963/ijcai.2022/584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational Causal Emotion Entailment aims to detect causal utterances for a non-neutral targeted utterance from a conversation. In this work, we build conversations as graphs to overcome implicit contextual modelling of the original entailment style. Following the previous work, we further introduce the emotion information into graphs. Emotion information can markedly promote the detection of causal utterances whose emotion is the same as the targeted utterance. However, it is still hard to detect causal utterances with different emotions, especially neutral ones. The reason is that models are limited in reasoning causal clues and passing them between utterances. To alleviate this problem, we introduce social commonsense knowledge (CSK) and propose a Knowledge Enhanced Conversation graph (KEC). KEC propagates the CSK between two utterances. As not all CSK is emotionally suitable for utterances, we therefore propose a sentiment-realized knowledge selecting strategy to filter CSK. To process KEC, we further construct the Knowledge Enhanced Directed Acyclic Graph networks. Experimental results show that our method outperforms baselines and infers more causes with different emotions from the targeted utterance. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Jiangnan Li and Fandong Meng and Zheng Lin and Rui Liu and Peng Fu and Yanan Cao and Weiping Wang and Jie Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/584},
  pages     = {4209-4215},
  title     = {Neutral utterances are also causes: Enhancing conversational causal emotion entailment with social commonsense knowledge},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FastRE: Towards fast relation extraction with convolutional
encoder and improved cascade binary tagging framework. <em>IJCAI</em>,
4201–4208. (<a href="https://doi.org/10.24963/ijcai.2022/583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work for extracting relations from texts has achieved excellent performance. However, most existing methods pay less attention to the efficiency, making it still challenging to quickly extract relations from massive or streaming text data in realistic scenarios. The main efficiency bottleneck is that these methods use a Transformer-based pre-trained language model for encoding, which heavily affects the training speed and inference speed. To address this issue, we propose a fast relation extraction model (FastRE) based on convolutional encoder and improved cascade binary tagging framework. Compared to previous work, FastRE employs several innovations to improve efficiency while also keeping promising performance. Concretely, FastRE adopts a novel convolutional encoder architecture combined with dilated convolution, gated unit and residual connection, which significantly reduces the computation cost of training and inference, while maintaining the satisfactory performance. Moreover, to improve the cascade binary tagging framework, FastRE first introduces a type-relation mapping mechanism to accelerate tagging efficiency and alleviate relation redundancy, and then utilizes a position-dependent adaptive thresholding strategy to obtain higher tagging accuracy and better model generalization. Experimental results demonstrate that FastRE is well balanced between efficiency and performance, and achieves 3-10$\times$ training speed, 7-15$\times$ inference speed faster, and 1/100 parameters compared to the state-of-the-art models, while the performance is still competitive. Our code is available at \url{https://github.com/seukgcode/FastRE}. Keywords: Natural Language Processing: Knowledge Extraction Knowledge Representation and Reasoning: Other Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Guozheng Li and Xu Chen and Peng Wang and Jiafeng Xie and Qiqing Luo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/583},
  pages     = {4201-4208},
  title     = {FastRE: Towards fast relation extraction with convolutional encoder and improved cascade binary tagging framework},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Taylor, can you hear me now? A taylor-unfolding framework
for monaural speech enhancement. <em>IJCAI</em>, 4193–4200. (<a
href="https://doi.org/10.24963/ijcai.2022/582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While the deep learning techniques promote the rapid development of the speech enhancement (SE) community, most schemes only pursue the performance in a black-box manner and lack adequate model interpretability. Inspired by Taylor&#39;s approximation theory, we propose an interpretable decoupling-style SE framework, which disentangles the complex spectrum recovery into two separate optimization problems i.e., magnitude and complex residual estimation. Specifically, serving as the 0th-order term in Taylor&#39;s series, a filter network is delicately devised to suppress the noise component only in the magnitude domain and obtain a coarse spectrum. To refine the phase distribution, we estimate the sparse complex residual, which is defined as the difference between target and coarse spectra, and measures the phase gap. In this study, we formulate the residual component as the combination of various high-order Taylor terms and propose a lightweight trainable module to replace the complicated derivative operator between adjacent terms. Finally, following Taylor&#39;s formula, we can reconstruct the target spectrum by the superimposition between 0th-order and high-order terms. Experimental results on two benchmark datasets show that our framework achieves state-of-the-art performance over previous competing baselines in various evaluation metrics. The source code is available at https://github.com/Andong-Li-speech/TaylorSENet. Keywords: Natural Language Processing: Speech Machine Learning: Applications Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Andong Li and Shan You and Guochen Yu and Chengshi Zheng and Xiaodong Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/582},
  pages     = {4193-4200},
  title     = {Taylor, can you hear me now? a taylor-unfolding framework for monaural speech enhancement},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deexaggeration. <em>IJCAI</em>, 4185–4192. (<a
href="https://doi.org/10.24963/ijcai.2022/581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a new task in hyperbole processing, deexaggeration, which concerns the recovery of the meaning of what is being exaggerated in a hyperbolic sentence in the form of a structured representation. In this paper, we lay the groundwork for the computational study of understanding hyperbole by (1) defining a structured representation to encode what is being exaggerated in a hyperbole in a non-hyperbolic manner, (2) annotating the hyperbolic sentences in two existing datasets, HYPO and HYPO-cn, using this structured representation, (3) conducting an empirical analysis of our annotated corpora, and (4) presenting preliminary results on the deexaggeration task. Keywords: Natural Language Processing: Applications Natural Language Processing: Information Retrieval and Text Mining},
  archive   = {C_IJCAI},
  author    = {Li Kong and Chuanyi Li and Vincent Ng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/581},
  pages     = {4185-4192},
  title     = {Deexaggeration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Curriculum-based self-training makes better few-shot
learners for data-to-text generation. <em>IJCAI</em>, 4178–4184. (<a
href="https://doi.org/10.24963/ijcai.2022/580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the success of text-to-text pre-trained models in various natural language generation (NLG) tasks, the generation performance is largely restricted by the number of labeled data in downstream tasks, particularly in data-to-text generation tasks. Existing works mostly utilize abundant unlabeled structured data to conduct unsupervised pre-training for task adaption, which fail to model the complex relationship between source structured data and target texts. Thus, we introduce self-training as a better few-shot learner than task-adaptive pre-training, which explicitly captures this relationship via pseudo-labeled data generated by the pre-trained model. To alleviate the side-effect of low-quality pseudo-labeled data during self-training, we propose a novel method called Curriculum-Based Self-Training (CBST) to effectively leverage unlabeled data in a rearranged order determined by the difficulty of text generation. Experimental results show that our method can outperform fine-tuning and task-adaptive pre-training methods, and achieve state-of-the-art performance in the few-shot setting of data-to-text generation. Keywords: Natural Language Processing: Language Generation Natural Language Processing: Language Models},
  archive   = {C_IJCAI},
  author    = {Pei Ke and Haozhe Ji and Zhenyu Yang and Yi Huang and Junlan Feng and Xiaoyan Zhu and Minlie Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/580},
  pages     = {4178-4184},
  title     = {Curriculum-based self-training makes better few-shot learners for data-to-text generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AdMix: A mixed sample data augmentation method for neural
machine translation. <em>IJCAI</em>, 4171–4177. (<a
href="https://doi.org/10.24963/ijcai.2022/579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In Neural Machine Translation (NMT), data augmentation methods such as back-translation have proven their effectiveness in improving translation performance. In this paper, we propose a novel data augmentation approach for NMT, which is independent of any additional training data. Our approach, AdMix, consists of two parts: 1) introduce faint discrete noise (word replacement, word dropping, word swapping) into the original sentence pairs to form augmented samples; 2) generate new synthetic training data by softly mixing the augmented samples with their original samples in training corpus. Experiments on three translation datasets of different scales show that AdMix achieves significant improvements (1.0 to 2.7 BLEU points) over strong Transformer baseline. When combined with other data augmentation techniques (e.g., back-translation), our approach can obtain further improvements. Keywords: Natural Language Processing: Machine Translation and Multilinguality},
  archive   = {C_IJCAI},
  author    = {Chang Jin and Shigui Qiu and Nini Xiao and Hao Jia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/579},
  pages     = {4171-4177},
  title     = {AdMix: A mixed sample data augmentation method for neural machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MuiDial: Improving dialogue disentanglement with
intent-based mutual learning. <em>IJCAI</em>, 4164–4170. (<a
href="https://doi.org/10.24963/ijcai.2022/578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The main goal of dialogue disentanglement is to separate the mixed utterances from a chat slice into independent dialogues. Existing models often utilize either an utterance-to-utterance (U2U) prediction to determine whether two utterances that have the “reply-to” relationship belong to one dialogue, or an utterance-to-thread (U2T) prediction to determine which dialogue-thread a given utterance should belong to. Inspired by mutual leaning, we propose MuiDial, a novel dialogue disentanglement model, to exploit the intent of each utterance and feed the intent to a mutual learning U2U-U2T disentanglement model. Experimental results and in-depth analysis on several benchmark datasets demonstrate the effectiveness and generalizability of our approach. Keywords: Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Applications Natural Language Processing: Knowledge Extraction},
  archive   = {C_IJCAI},
  author    = {Ziyou Jiang and Lin Shi and Celia Chen and Fangwen Mu and Yumin Zhang and Qing Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/578},
  pages     = {4164-4170},
  title     = {MuiDial: Improving dialogue disentanglement with intent-based mutual learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FastDiff: A fast conditional diffusion model for
high-quality speech synthesis. <em>IJCAI</em>, 4157–4163. (<a
href="https://doi.org/10.24963/ijcai.2022/577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Denoising diffusion probabilistic models (DDPMs) have recently achieved leading performances in many generative tasks. However, the inherited iterative sampling process costs hindered their applications to speech synthesis. This paper proposes FastDiff, a fast conditional diffusion model for high-quality speech synthesis. FastDiff employs a stack of time-aware location-variable convolutions of diverse receptive field patterns to efficiently model long-term time dependencies with adaptive conditions. A noise schedule predictor is also adopted to reduce the sampling steps without sacrificing the generation quality. Based on FastDiff, we design an end-to-end text-to-speech synthesizer, FastDiff-TTS, which generates high-fidelity speech waveforms without any intermediate feature (e.g., Mel-spectrogram). Our evaluation of FastDiff demonstrates the state-of-the-art results with higher-quality (MOS 4.28) speech samples. Also, FastDiff enables a sampling speed of 58x faster than real-time on a V100 GPU, making diffusion models practically applicable to speech synthesis deployment for the first time. We further show that FastDiff generalized well to the mel-spectrogram inversion of unseen speakers, and FastDiff-TTS outperformed other competing methods in end-to-end text-to-speech synthesis. Audio samples are available at https://FastDiff.github.io/. Keywords: Natural Language Processing: Speech Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Rongjie Huang and Max W. Y. Lam and Jun Wang and Dan Su and Dong Yu and Yi Ren and Zhou Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/577},
  pages     = {4157-4163},
  title     = {FastDiff: A fast conditional diffusion model for high-quality speech synthesis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving few-shot text-to-SQL with meta self-training via
column specificity. <em>IJCAI</em>, 4150–4156. (<a
href="https://doi.org/10.24963/ijcai.2022/576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The few-shot problem is an urgent challenge for single-table text-to-SQL. Existing methods ignore the potential value of unlabeled data, and merely rely on a coarse-grained Meta-Learning (ML) algorithm that neglects the differences of column contributions to the optimization object. This paper proposes a Meta Self-Training text-to-SQL (MST-SQL) method to solve the problem. Specifically, MST-SQL is based on column-wise HydraNet and adopts self-training as an effective mechanism to learn from readily available unlabeled samples. During each epoch of training, it first predicts pseudo-labels for unlabeled samples and then leverages them to update the parameters. A fine-grained ML algorithm is used in updating, which weighs the contribution of columns by their specificity, in order to further improve the generalizability. Extensive experimental results on both open-domain and domain-specific benchmarks reveal that our MST-SQL has significant advantages in few-shot scenarios, and is also competitive in standard supervised settings. Keywords: Natural Language Processing: Question Answering Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Xinnan Guo and Yongrui Chen and Guilin Qi and Tianxing Wu and Hao Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/576},
  pages     = {4150-4156},
  title     = {Improving few-shot text-to-SQL with meta self-training via column specificity},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fallacious argument classification in political debates.
<em>IJCAI</em>, 4143–4149. (<a
href="https://doi.org/10.24963/ijcai.2022/575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fallacies play a prominent role in argumentation since antiquity due to their contribution to argumentation in critical thinking education. Their role is even more crucial nowadays as contemporary argumentation technologies face challenging tasks as misleading and manipulative information detection in news articles and political discourse, and counter-narrative generation. Despite some work in this direction, the issue of classifying arguments as being fallacious largely remains a challenging and an unsolved task. Our contribution is twofold: first, we present a novel annotated resource of 31 political debates from the U.S. Presidential Campaigns, where we annotated six main categories of fallacious arguments (i.e., ad hominem, appeal to authority, appeal to emotion, false cause, slogan, slippery slope) leading to 1628 annotated fallacious arguments; second, we tackle this novel task of fallacious argument classification and we define a neural architecture based on transformers outperforming state-of-the-art results and standard baselines. Our results show the important role played by argument components and relations in this task. Keywords: Natural Language Processing: Text Classification Knowledge Representation and Reasoning: Argumentation Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Pierpaolo Goffredo and Shohreh Haddadan and Vorakit Vorakitphan and Elena Cabrio and Serena Villata},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/575},
  pages     = {4143-4149},
  title     = {Fallacious argument classification in political debates},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging the wikipedia graph for evaluating word
embeddings. <em>IJCAI</em>, 4136–4142. (<a
href="https://doi.org/10.24963/ijcai.2022/574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning models for different NLP tasks often rely on pre-trained word embeddings, that is, vector representations of words. Therefore, it is crucial to evaluate pre-trained word embeddings independently of downstream tasks. Such evaluations try to assess whether the geometry induced by a word embedding captures connections made in natural language, such as, analogies, clustering of words, or word similarities. Here, traditionally, similarity is measured by comparison to human judgment. However, explicitly annotating word pairs with similarity scores by surveying humans is expensive. We tackle this problem by formulating a similarity measure that is based on an agent for routing the Wikipedia hyperlink graph. In this graph, word similarities are implicitly encoded by edges between articles. We show on the English Wikipedia that our measure correlates well with a large group of traditional similarity measures, while covering a much larger proportion of words and avoiding explicit human labeling. Moreover, since Wikipedia is available in more than 300 languages, our measure can easily be adapted to other languages, in contrast to traditional similarity measures. Keywords: Natural Language Processing: Embeddings Agent-based and Multi-agent Systems: Applications Natural Language Processing: Resources and Evaluation Search: Local search},
  archive   = {C_IJCAI},
  author    = {Joachim Giesen and Paul Kahlmeyer and Frank Nussbaum and Sina Zarrieß},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/574},
  pages     = {4136-4142},
  title     = {Leveraging the wikipedia graph for evaluating word embeddings},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logically consistent adversarial attacks for soft theorem
provers. <em>IJCAI</em>, 4129–4135. (<a
href="https://doi.org/10.24963/ijcai.2022/573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent efforts within the AI community have yielded impressive results towards “soft theorem proving” over natural language sentences using language models. We propose a novel, generative adversarial framework for probing and improving these models’ reasoning capabilities. Adversarial attacks in this domain suffer from the logical inconsistency problem, whereby perturbations to the input may alter the label. Our Logically consistent AdVersarial Attacker, LAVA, addresses this by combining a structured generative process with a symbolic solver, guaranteeing logical consistency. Our framework successfully generates adversarial attacks and identifies global weaknesses common across multiple target models. Our analyses reveal naive heuristics and vulnerabilities in these models’ reasoning capabilities, exposing an incomplete grasp of logical deduction under logic programs. Finally, in addition to effective probing of these models, we show that training on the generated samples improves the target model’s performance. Keywords: Natural Language Processing: Text Classification Machine Learning: Adversarial Machine Learning Natural Language Processing: Language Models Natural Language Processing: Question Answering Machine Learning: Neuro-Symbolic Methods},
  archive   = {C_IJCAI},
  author    = {Alexander Gaskell and Yishu Miao and Francesca Toni and Lucia Specia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/573},
  pages     = {4129-4135},
  title     = {Logically consistent adversarial attacks for soft theorem provers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inheriting the wisdom of predecessors: A multiplex cascade
framework for unified aspect-based sentiment analysis. <em>IJCAI</em>,
4121–4128. (<a href="https://doi.org/10.24963/ijcai.2022/572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {So far, aspect-based sentiment analysis (ABSA) has involved with total seven subtasks, in which, however the interactions among them have been left unexplored sufficiently. This work presents a novel multiplex cascade framework for unified ABSA and maintaining such interactions. First, we model total seven subtasks as a hierarchical dependency in the easy-to-hard order, based on which we then propose a multiplex decoding mechanism, transferring the sentiment layouts and clues in lower tasks to upper ones. The multiplex strategy enables highly-efficient subtask interflows and avoids repetitive training; meanwhile it sufficiently utilizes the existing data without requiring any further annotation. Further, based on the characteristics of aspect-opinion term extraction and pairing, we enhance our multiplex framework by integrating POS tag and syntactic dependency information for term boundary and pairing identification. The proposed Syntax-aware Multiplex (SyMux) framework enhances the ABSA performances on 28 subtasks (7×4 datasets) with big margins. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Information Extraction Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Hao Fei and Fei Li and Chenliang Li and Shengqiong Wu and Jingye Li and Donghong Ji},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/572},
  pages     = {4121-4128},
  title     = {Inheriting the wisdom of predecessors: A multiplex cascade framework for unified aspect-based sentiment analysis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conversational semantic role labeling with
predicate-oriented latent graph. <em>IJCAI</em>, 4114–4120. (<a
href="https://doi.org/10.24963/ijcai.2022/571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conversational semantic role labeling (CSRL) is a newly proposed task that uncovers the shallow semantic structures in a dialogue text. Unfortunately several important characteristics of the CSRL task have been overlooked by the existing works, such as the structural information integration, near-neighbor influence. In this work, we investigate the integration of a latent graph for CSRL. We propose to automatically induce a predicate-oriented latent graph (POLar) with a predicate-centered gaussian mechanism, by which the nearer and informative words to the predicate will be allocated with more attention. The POLar structure is then dynamically pruned and refined so as to best fit the task need. We additionally introduce an effective dialogue-level pre-trained language model, CoDiaBERT, for better supporting multiple utterance sentences and handling the speaker coreference issue in CSRL. Our system outperforms best-performing baselines on three benchmark CSRL datasets with big margins, especially achieving over 4\% F1 score improvements on the cross-utterance argument detection. Further analyses are presented to better understand the effectiveness of our proposed methods. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Tagging, Chunking, and Parsing},
  archive   = {C_IJCAI},
  author    = {Hao Fei and Shengqiong Wu and Meishan Zhang and Yafeng Ren and Donghong Ji},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/571},
  pages     = {4114-4120},
  title     = {Conversational semantic role labeling with predicate-oriented latent graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Global inference with explicit syntactic and discourse
structures for dialogue-level relation extraction. <em>IJCAI</em>,
4107–4113. (<a href="https://doi.org/10.24963/ijcai.2022/570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent research attention for relation extraction has been paid to the dialogue scenario, i.e., dialogue-level relation extraction (DiaRE). Existing DiaRE methods either simply concatenate the utterances in a dialogue into a long piece of text, or employ naive words, sentences or entities to build dialogue graphs, while the structural characteristics in dialogues have not been fully utilized. In this work, we investigate a novel dialogue-level mixed dependency graph (D2G) and an argument reasoning graph (ARG) for DiaRE with a global relation reasoning mechanism. First, we model the entire dialogue into a unified and coherent D2G by explicitly integrating both syntactic and discourse structures, which enables richer semantic and feature learning for relation extraction. Second, we stack an ARG graph on top of D2G to further focus on argument inter-dependency learning and argument representation refinement, for sufficient argument relation inference. In our global reasoning framework, D2G and ARG work collaboratively, iteratively performing lexical, syntactic and semantic information exchange and representation learning over the entire dialogue context. On two DiaRE benchmarks, our framework shows considerable improvements over the current state-of-the-art baselines. Further analyses show that the model effectively solves the long-range dependence issue, and meanwhile gives explainable predictions. Keywords: Natural Language Processing: Information Extraction Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Knowledge Extraction Natural Language Processing: Named Entities},
  archive   = {C_IJCAI},
  author    = {Hao Fei and Jingye Li and Shengqiong Wu and Chenliang Li and Donghong Ji and Fei Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/570},
  pages     = {4107-4113},
  title     = {Global inference with explicit syntactic and discourse structures for dialogue-level relation extraction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interactive information extraction by semantic information
graph. <em>IJCAI</em>, 4100–4106. (<a
href="https://doi.org/10.24963/ijcai.2022/569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Information extraction (IE) mainly focuses on three highly correlated subtasks, i.e., entity extraction, relation extraction and event extraction. Recently, there are studies using Abstract Meaning Representation (AMR) to utilize the intrinsic correlations among these three subtasks. AMR based models are capable of building the relationship of arguments. However, they are hard to deal with relations. In addition, the noises of AMR (i.e., tags unrelated to IE tasks, nodes with unconcerned conception, and edge types with complicated hierarchical structures) disturb the decoding processing of IE. As a result, the decoding processing limited by the AMR cannot be worked effectively. To overcome the shortages, we propose an Interactive Information Extraction (InterIE) model based on a novel Semantic Information Graph (SIG). SIG can guide our InterIE model to tackle the three subtasks jointly. Furthermore, the well-designed SIG without noise is capable of enriching entity and event trigger representation, and capturing the edge connection between the information types. Experimental results show that our InterIE achieves state-of-the-art performance on all IE subtasks on the benchmark dataset (i.e., ACE05-E+ and ACE05-E). More importantly, the proposed model is not sensitive to the decoding order, which goes beyond the limitations of AMR based methods. Keywords: Natural Language Processing: Applications Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Siqi Fan and Yequan Wang and Jing Li and Zheng Zhang and Shuo Shang and Peng Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/569},
  pages     = {4100-4106},
  title     = {Interactive information extraction by semantic information graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Interpretable AMR-based question decomposition for multi-hop
question answering. <em>IJCAI</em>, 4093–4099. (<a
href="https://doi.org/10.24963/ijcai.2022/568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Effective multi-hop question answering (QA) requires reasoning over multiple scattered paragraphs and providing explanations for answers. Most existing approaches cannot provide an interpretable reasoning process to illustrate how these models arrive at an answer. In this paper, we propose a Question Decomposition method based on Abstract Meaning Representation (QDAMR) for multi-hop QA, which achieves interpretable reasoning by decomposing a multi-hop question into simpler subquestions and answering them in order. Since annotating the decomposition is expensive, we first delegate the complexity of understanding the multi-hop question to an AMR parser. We then achieve decomposition of a multi-hop question via segmentation of the corresponding AMR graph based on the required reasoning type. Finally, we generate sub-questions using an AMR-to-Text generation model and answer them with an off-the-shelf QA model. Experimental results on HotpotQA demonstrate that our approach is competitive for interpretable reasoning and that the sub-questions generated by QDAMR are well-formed, outperforming existing question-decomposition-based multihop QA approaches. Keywords: Natural Language Processing: Question Answering Natural Language Processing: Interpretability and Analysis of Models for NLP Natural Language Processing: Language Generation AI Ethics, Trust, Fairness: Explainability and Interpretability Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Zhenyun Deng and Yonghua Zhu and Yang Chen and Michael Witbrock and Patricia Riddle},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/568},
  pages     = {4093-4099},
  title     = {Interpretable AMR-based question decomposition for multi-hop question answering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DictBERT: Dictionary description knowledge enhanced language
model pre-training via contrastive learning. <em>IJCAI</em>, 4086–4092.
(<a href="https://doi.org/10.24963/ijcai.2022/567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although pre-trained language models (PLMs) have achieved state-of-the-art performance on various natural language processing (NLP) tasks, they are shown to be lacking in knowledge when dealing with knowledge driven tasks. Despite the many efforts made for injecting knowledge into PLMs, this problem remains open. To address the challenge, we propose DictBERT, a novel approach that enhances PLMs with dictionary knowledge which is easier to acquire than knowledge graph (KG). During pre-training, we present two novel pre-training tasks to inject dictionary knowledge into PLMs via contrastive learning: dictionary entry prediction and entry description discrimination. In fine-tuning, we use the pre-trained DictBERT as a plugin knowledge base (KB) to retrieve implicit knowledge for identified entries in an input sequence, and infuse the retrieved knowledge into the input to enhance its representation via a novel extra-hop attention mechanism. We evaluate our approach on a variety of knowledge driven and language understanding tasks, including NER, relation extraction, CommonsenseQA, OpenBookQA and GLUE. Experimental results demonstrate that our model can significantly improve typical PLMs: it gains a substantial improvement of 0.5\%, 2.9\%, 9.0\%, 7.1\% and 3.3\% on BERT-large respectively, and is also effective on RoBERTa-large. Keywords: Natural Language Processing: Language Models Natural Language Processing: Applications Natural Language Processing: Natural Language Semantics Natural Language Processing: Question Answering Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Qianglong Chen and Feng-Lin Li and Guohai Xu and Ming Yan and Ji Zhang and Yin Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/567},
  pages     = {4086-4092},
  title     = {DictBERT: Dictionary description knowledge enhanced language model pre-training via contrastive learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Effective graph context representation for document-level
machine translation. <em>IJCAI</em>, 4079–4085. (<a
href="https://doi.org/10.24963/ijcai.2022/566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Document-level neural machine translation (DocNMT) universally encodes several local sentences or the entire document. Thus, DocNMT does not consider the relevance of document-level contextual information, for example, some context (i.e., content words, logical order, and co-occurrence relation) is more effective than another auxiliary context (i.e., functional and auxiliary words). To address this issue, we first utilize the word frequency information to recognize content words in the input document, and then use heuristical relations to summarize content words and sentences as a graph structure without relying on external syntactic knowledge. Furthermore, we apply graph attention networks to this graph structure to learn its feature representation, which allows DocNMT to more effectively capture the document-level context. Experimental results on several widely-used document-level benchmarks demonstrated the effectiveness of the proposed approach. Keywords: Natural Language Processing: Machine Translation and Multilinguality Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Kehai Chen and Muyun Yang and Masao Utiyama and Eiichiro Sumita and Rui Wang and Min Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/566},
  pages     = {4079-4085},
  title     = {Effective graph context representation for document-level machine translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards joint intent detection and slot filling via
higher-order attention. <em>IJCAI</em>, 4072–4078. (<a
href="https://doi.org/10.24963/ijcai.2022/565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, attention-based models for joint intent detection and slot filling have achieved state-of-the-art performance. However, we think the conventional attention can only capture the first-order feature interaction between two tasks and is insufficient. To address this issue, we propose a unified BiLinear attention block, which leverages bilinear pooling to synchronously explore both the contextual and channel-wise bilinear attention distributions to capture the second-order interactions between the input intent and slot features. Higher-order interactions are constructed by combining many such blocks and exploiting Exponential Linear activations. Furthermore, we present a Higher-order Attention Network (HAN) to jointly model them. The experimental results show that our approach outperforms the state-of-the-art results. We also conduct experiments on the new SLURP dataset, and give a discussion on HAN’s properties, i.e., robustness and generalization. Keywords: Natural Language Processing: Applications Natural Language Processing: Dialogue and Interactive Systems Natural Language Processing: Interpretability and Analysis of Models for NLP},
  archive   = {C_IJCAI},
  author    = {Dongsheng Chen and Zhiqi Huang and Xian Wu and Shen Ge and Yuexian Zou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/565},
  pages     = {4072-4078},
  title     = {Towards joint intent detection and slot filling via higher-order attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PCVAE: Generating prior context for dialogue response
generation. <em>IJCAI</em>, 4065–4071. (<a
href="https://doi.org/10.24963/ijcai.2022/564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional Variational AutoEncoder (CVAE) is promising for modeling one-to-many relationships in dialogue generation, as it can naturally generate many responses from a given context. However, the conventional used continual latent variables in CVAE are more likely to generate generic rather than distinct and specific responses. To resolve this problem, we introduce a novel discrete variable called prior context which enables the generation of favorable responses. Specifically, we present Prior Context VAE (PCVAE), a hierarchical VAE that learns prior context from data automatically for dialogue generation. Meanwhile, we design Active Codeword Transport (ACT) to help the model actively discover potential prior context. Moreover, we propose Autoregressive Compatible Arrangement (ACA) that enables modeling prior context in autoregressive style, which is crucial for selecting appropriate prior context according to a given context. Extensive experiments demonstrate that PCVAE can generate distinct responses and significantly outperforms strong baselines. Keywords: Natural Language Processing: Language Generation Machine Learning: Autoencoders Natural Language Processing: Dialogue and Interactive Systems},
  archive   = {C_IJCAI},
  author    = {Zefeng Cai and Zerui Cai},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/564},
  pages     = {4065-4071},
  title     = {PCVAE: Generating prior context for dialogue response generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning meta word embeddings by unsupervised weighted
concatenation of source embeddings. <em>IJCAI</em>, 4058–4064. (<a
href="https://doi.org/10.24963/ijcai.2022/563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given multiple source word embeddings learnt using diverse algorithms and lexical resources, meta word embedding learning methods attempt to learn more accurate and wide-coverage word embeddings. Prior work on meta-embedding has repeatedly discovered that simple vector concatenation of the source embeddings to be a competitive baseline. However, it remains unclear as to why and when simple vector concatenation can produce accurate meta-embeddings. We show that weighted concatenation can be seen as a spectrum matching operation between each source embedding and the meta-embedding, minimising the pairwise inner-product loss. Following this theoretical analysis, we propose two \emph{unsupervised} methods to learn the optimal concatenation weights for creating meta-embeddings from a given set of source embeddings. Experimental results on multiple benchmark datasets show that the proposed weighted concatenated meta-embedding methods outperform previously proposed meta-embedding learning methods. Keywords: Natural Language Processing: Embeddings Natural Language Processing: Natural Language Semantics Machine Learning: Representation learning Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Danushka Bollegala},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/563},
  pages     = {4058-4064},
  title     = {Learning meta word embeddings by unsupervised weighted concatenation of source embeddings},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Speaker-guided encoder-decoder framework for emotion
recognition in conversation. <em>IJCAI</em>, 4051–4057. (<a
href="https://doi.org/10.24963/ijcai.2022/562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The emotion recognition in conversation (ERC) task aims to predict the emotion label of an utterance in a conversation. Since the dependencies between speakers are complex and dynamic, which consist of intra- and inter-speaker dependencies, the modeling of speaker-specific information is a vital role in ERC. Although existing researchers have proposed various methods of speaker interaction modeling, they cannot explore dynamic intra- and inter-speaker dependencies jointly, leading to the insufficient comprehension of context and further hindering emotion prediction. To this end, we design a novel speaker modeling scheme that explores intra- and inter-speaker dependencies jointly in a dynamic manner. Besides, we propose a Speaker-Guided Encoder-Decoder (SGED) framework for ERC, which fully exploits speaker information for the decoding of emotion. We use different existing methods as the conversational context encoder of our framework, showing the high scalability and flexibility of the proposed framework. Experimental results demonstrate the superiority and effectiveness of SGED. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Text Classification Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Yinan Bao and Qianwen Ma and Lingwei Wei and Wei Zhou and Songlin Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/562},
  pages     = {4051-4057},
  title     = {Speaker-guided encoder-decoder framework for emotion recognition in conversation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Aspect-based sentiment analysis with opinion tree
generation. <em>IJCAI</em>, 4044–4050. (<a
href="https://doi.org/10.24963/ijcai.2022/561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing studies usually extract these sentiment elements by decomposing the complex structure prediction task into multiple subtasks. Despite their effectiveness, these methods ignore the semantic structure in ABSA problems and require extensive task-specific designs. In this study, we introduce an Opinion Tree Generation task, which aims to jointly detect all sentiment elements in a tree. We believe that the opinion tree can reveal a more comprehensive and complete aspect-level sentiment structure. Furthermore, we propose a pre-trained model to integrate both syntax and semantic features for opinion tree generation. On one hand, a pre-trained model with large-scale unlabeled data is important for the tree generation model. On the other hand, the syntax and semantic features are very effective for forming the opinion tree structure. Extensive experiments show the superiority of our proposed method. The results also validate the tree structure is effective to generate sentimental elements. Keywords: Natural Language Processing: Sentiment Analysis and Text Mining Natural Language Processing: Information Extraction},
  archive   = {C_IJCAI},
  author    = {Xiaoyi Bao and Wang Zhongqing and Xiaotong Jiang and Rong Xiao and Shoushan Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/561},
  pages     = {4044-4050},
  title     = {Aspect-based sentiment analysis with opinion tree generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing entity representations with prompt learning for
biomedical entity linking. <em>IJCAI</em>, 4036–4042. (<a
href="https://doi.org/10.24963/ijcai.2022/560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Biomedical entity linking aims to map mentions in biomedical text to standardized concepts or entities in a curated knowledge base (KB) such as Unified Medical Language System (UMLS). The latest research tends to solve this problem in a unified framework solely based on surface form matching between mentions and entities. Specifically, these methods focus on addressing the variety challenge of the heterogeneous naming of biomedical concepts. Yet, the ambiguity challenge that the same word under different contexts may refer to distinct entities is usually ignored. To address this challenge, we propose a two-stage linking algorithm to enhance the entity representations based on prompt learning. The first stage includes a coarser-grained retrieval from a representation space defined by a bi-encoder that independently embeds the mention and entity’s surface forms. Unlike previous one-model-fits-all systems, each candidate is then re-ranked with a finer-grained encoder based on prompt-tuning that utilizes the contextual information. Extensive experiments show that our model achieves promising performance improvements compared with several state-of-the-art techniques on the largest biomedical public dataset MedMentions and the NCBI disease corpus. We also observe by cases that the proposed prompt-tuning strategy is effective in solving both the variety and ambiguity challenges in the linking task. Keywords: Multidisciplinary Topics and Applications: Bioinformatics Multidisciplinary Topics and Applications: Health and Medicine Natural Language Processing: Applications},
  archive   = {C_IJCAI},
  author    = {Tiantian Zhu and Yang Qin and Qingcai Chen and Baotian Hu and Yang Xiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/560},
  pages     = {4036-4042},
  title     = {Enhancing entity representations with prompt learning for biomedical entity linking},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Post-processing of differentially private data: A fairness
perspective. <em>IJCAI</em>, 4029–4035. (<a
href="https://doi.org/10.24963/ijcai.2022/559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Post-processing immunity is a fundamental property of differential privacy: it enables arbitrary data-independent transformations to differentially private outputs without affecting their privacy guarantees. Post-processing is routinely applied in data-release applications, including census data, which are then used to make allocations with substantial societal impacts. This paper shows that post-processing causes disparate impacts on individuals or groups and analyzes two critical settings: the release of differentially private datasets and the use of such private datasets for downstream decisions, such as the allocation of funds informed by US Census data. In the first setting, the paper proposes tight bounds on the unfairness for traditional post-processing mechanisms, giving a unique tool to decision makers to quantify the disparate impacts introduced by their release. In the second setting, this paper proposes a novel post-processing mechanism that is (approximately) optimal under different fairness metrics, either reducing fairness issues substantially or reducing the cost of privacy. The theoretical analysis is complemented with numerical simulations on Census data. Keywords: Multidisciplinary Topics and Applications: Security and Privacy AI Ethics, Trust, Fairness: Bias AI Ethics, Trust, Fairness: Fairness &amp; Diversity Constraint Satisfaction and Optimization: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Keyu Zhu and Ferdinando Fioretto and Pascal Van Hentenryck},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/559},
  pages     = {4029-4035},
  title     = {Post-processing of differentially private data: A fairness perspective},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Temporality spatialization: A scalable and faithful
time-travelling visualization for deep classifier training.
<em>IJCAI</em>, 4022–4028. (<a
href="https://doi.org/10.24963/ijcai.2022/558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time-travelling visualization answers how the predictions of a deep classifier are formed during the training. It visualizes in two or three dimensional space how the classification boundaries and sample embeddings are evolved during training. In this work, we propose TimeVis, a novel time-travelling visualization solution for deep classifiers. Comparing to the state-of-the-art solution DeepVisualInsight (DVI), TimeVis can significantly (1) reduce visualization errors for rendering samples’ travel across different training epochs, and (2) improve the visualization efficiency. To this end, we design a technique called temporality spatialization, which unifies the spatial relation (e.g., neighbouring samples in single epoch) and temporal relation (e.g., one identical sample in neighbouring training epochs) into one high-dimensional topological complex. Such spatio-temporal complex can be used to efficiently train one visualization model to accurately project and inverse-project any high and low dimensional data across epochs. Our extensive experiment shows that, in comparison to DVI, TimeVis not only is more accurate to preserve the visualized time-travelling semantics, but 15X faster in visualization efficiency, achieving a new state-of-the-art in time-travelling visualization. Keywords: Multidisciplinary Topics and Applications: Software Engineering AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Xianglin Yang and Yun Lin and Ruofan Liu and Jin Song Dong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/558},
  pages     = {4022-4028},
  title     = {Temporality spatialization: A scalable and faithful time-travelling visualization for deep classifier training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A smart trader for portfolio management based on normalizing
flows. <em>IJCAI</em>, 4014–4021. (<a
href="https://doi.org/10.24963/ijcai.2022/557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study a new kind of portfolio problem, named trading point aware portfolio optimization (TPPO), which aims to obtain excess intraday profit by deciding the portfolio weights and their trading points simultaneously based on microscopic information. However, a strategy for the TPPO problem faces two challenging problems, i.e., modeling the ever-changing and irregular microscopic stock price time series and deciding the scattering candidate trading points. To address these problems, we propose a novel TPPO strategy named STrader based on normalizing flows. STrader is not only promising in reversibly transforming the geometric Brownian motion process to the unobservable and complicated stochastic process of the microscopic stock price time series for modeling such series, but also has the ability to earn excess intraday profit by capturing the appropriate trading points of the portfolio. Extensive experiments conducted on three public datasets demonstrate STrader&#39;s superiority over the state-of-the-art portfolio strategies. Keywords: Multidisciplinary Topics and Applications: Finance Machine Learning: Deep Reinforcement Learning Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Mengyuan Yang and Xiaolin Zheng and Qianqiao Liang and Bing Han and Mengying Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/557},
  pages     = {4014-4021},
  title     = {A smart trader for portfolio management based on normalizing flows},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ARCANE: An efficient architecture for exact machine
unlearning. <em>IJCAI</em>, 4006–4013. (<a
href="https://doi.org/10.24963/ijcai.2022/556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently users’ right-to-be-forgotten is stipulated by many laws and regulations. However, only removing the data from the dataset is not enough, as machine learning models would memorize the training data once the data is involved in model training, increasing the risk of exposing users’ privacy. To solve this problem, currently, the straightforward method, naive retraining, is to discard these data and retrain the model from scratch, which is reliable but brings much computational and time overhead. In this paper, we propose an exact unlearning architecture called ARCANE. Based on ensemble learning, we transform the naive retraining into multiple one-class classiﬁcation tasks to reduce retraining cost while ensuring model performance, especially in the case of a large number of unlearning requests not considered by previous works. Then we further introduce data preprocessing methods to reduce the retraining overhead and speed up the unlearning, which includes representative data selection for redundancy removal, training state saving to reuse previous calculation results, and sorting to cope with unlearning requests of different distributions. We extensively evaluate ARCANE on three typical datasets with three common model architectures. Experiment results show the effectiveness and superiority of ARCANE over both the naive retraining and the state-of-the-art method in terms of model performance and unlearning speed. Keywords: Multidisciplinary Topics and Applications: Security and Privacy AI Ethics, Trust, Fairness: AI and Law, Governance, Regulation AI Ethics, Trust, Fairness: Trustworthy AI Machine Learning: Ensemble Methods Machine Learning: Experimental Methodology},
  archive   = {C_IJCAI},
  author    = {Haonan Yan and Xiaoguang Li and Ziyao Guo and Hui Li and Fenghua Li and Xiaodong Lin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/556},
  pages     = {4006-4013},
  title     = {ARCANE: An efficient architecture for exact machine unlearning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TinyLight: Adaptive traffic signal control on devices with
extremely limited resources. <em>IJCAI</em>, 3999–4005. (<a
href="https://doi.org/10.24963/ijcai.2022/555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in deep reinforcement learning (DRL) have largely promoted the performance of adaptive traffic signal control (ATSC). Nevertheless, regarding the implementation, most works are cumbersome in terms of storage and computation. This hinders their deployment on scenarios where resources are limited. In this work, we propose TinyLight, the first DRL-based ATSC model that is designed for devices with extremely limited resources. TinyLight first constructs a super-graph to associate a rich set of candidate features with a group of light-weighted network blocks. Then, to diminish the model&#39;s resource consumption, we ablate edges in the super-graph automatically with a novel entropy-minimized objective function. This enables TinyLight to work on a standalone microcontroller with merely 2KB RAM and 32KB ROM. We evaluate TinyLight on multiple road networks with real-world traffic demands. Experiments show that even with extremely limited resources, TinyLight still achieves competitive performance. The source code and appendix of this work can be found at https://bit.ly/38hH8t8. Keywords: Multidisciplinary Topics and Applications: Transportation Multidisciplinary Topics and Applications: Smart Cities},
  archive   = {C_IJCAI},
  author    = {Dong Xing and Qian Zheng and Qianhui Liu and Gang Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/555},
  pages     = {3999-4005},
  title     = {TinyLight: Adaptive traffic signal control on devices with extremely limited resources},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-efficient backdoor attacks. <em>IJCAI</em>, 3992–3998.
(<a href="https://doi.org/10.24963/ijcai.2022/554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent studies have proven that deep neural networks are vulnerable to backdoor attacks. Specifically, by mixing a small number of poisoned samples into the training set, the behavior of the trained model can be maliciously controlled. Existing attack methods construct such adversaries by randomly selecting some clean data from the benign set and then embedding a trigger into them. However, this selection strategy ignores the fact that each poisoned sample contributes inequally to the backdoor injection, which reduces the efficiency of poisoning. In this paper, we formulate improving the poisoned data efficiency by the selection as an optimization problem and propose a Filtering-and-Updating Strategy (FUS) to solve it. The experimental results on CIFAR-10 and ImageNet-10 indicate that the proposed method is effective: the same attack success rate can be achieved with only 47\% to 75\% of the poisoned sample volume compared to the random selection strategy. More importantly, the adversaries selected according to one setting can generalize well to other settings, exhibiting strong transferability. The prototype code of our method is now available at https://github.com/xpf/Data-Efficient-Backdoor-Attacks. Keywords: Multidisciplinary Topics and Applications: Security and Privacy AI Ethics, Trust, Fairness: Safety &amp; Robustness},
  archive   = {C_IJCAI},
  author    = {Pengfei Xia and Ziqiang Li and Wei Zhang and Bin Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/554},
  pages     = {3992-3998},
  title     = {Data-efficient backdoor attacks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learnability of competitive threshold models.
<em>IJCAI</em>, 3985–3991. (<a
href="https://doi.org/10.24963/ijcai.2022/553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling the spread of social contagions is central to various applications in social computing. In this paper, we study the learnability of the competitive threshold model from a theoretical perspective. We demonstrate how competitive threshold models can be seamlessly simulated by artificial neural networks with finite VC dimensions, which enables analytical sample complexity and generalization bounds. Based on the proposed hypothesis space, we design efficient algorithms under the empirical risk minimization scheme. The theoretical insights are finally translated into practical and explainable modeling methods, the effectiveness of which is verified through a sanity check over a few synthetic and real datasets. The experimental results promisingly show that our method enjoys a decent performance without using excessive data points, outperforming off-the-shelf methods. Keywords: Multidisciplinary Topics and Applications: Web and Social Networks Data Mining: Mining Graphs Data Mining: Theoretical Foundations of Data Mining Machine Learning: Learning Theory Multidisciplinary Topics and Applications: Social Sciences},
  archive   = {C_IJCAI},
  author    = {Yifan Wang and Guangmo Tong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/553},
  pages     = {3985-3991},
  title     = {Learnability of competitive threshold models},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bridging the gap between reality and ideality of entity
matching: A revisting and benchmark re-constrcution. <em>IJCAI</em>,
3978–3984. (<a href="https://doi.org/10.24963/ijcai.2022/552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Entity matching (EM) is the most critical step for entity resolution (ER). While current deep learning-based methods achieve very impressive performance on standard EM benchmarks, their real-world application performance is much frustrating. In this paper, we highlight that such the gap between reality and ideality stems from the unreasonable benchmark construction process, which is inconsistent with the nature of entity matching and therefore leads to biased evaluations of current EM approaches. To this end, we build a new EM corpus and re-construct EM benchmarks to challenge critical assumptions implicit in the previous benchmark construction process by step-wisely changing the restricted entities, balanced labels, and single-modal records in previous benchmarks into open entities, imbalanced labels, and multi-modal records in an open environment. Experimental results demonstrate that the assumptions made in the previous benchmark construction process are not coincidental with the open environment, which conceal the main challenges of the task and therefore significantly overestimate the current progress of entity matching. The constructed benchmarks and code are publicly released at https://github.com/tshu-w/ember. Keywords: Multidisciplinary Topics and Applications: Databases Data Mining: Intelligent Database Systems},
  archive   = {C_IJCAI},
  author    = {Tianshu Wang and Hongyu Lin and Cheng Fu and Xianpei Han and Le Sun and Feiyu Xiong and Hui Chen and Minlong Lu and Xiuwen Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/552},
  pages     = {3978-3984},
  title     = {Bridging the gap between reality and ideality of entity matching: A revisting and benchmark re-constrcution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive long-short pattern transformer for stock investment
selection. <em>IJCAI</em>, 3970–3977. (<a
href="https://doi.org/10.24963/ijcai.2022/551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stock investment selection is a hard issue in the Fintech field due to non-stationary dynamics and complex market interdependencies. Existing studies are mostly based on RNNs, which struggle to capture interactive information among fine granular volatility patterns. Besides, they either treat stocks as isolated, or presuppose a fixed graph structure heavily relying on prior domain knowledge. In this paper, we propose a novel Adaptive Long-Short Pattern Transformer (ALSP-TF) for stock ranking in terms of expected returns. Specifically, we overcome the limitations of canonical self-attention including context and position agnostic, with two additional capacities: (i) fine-grained pattern distiller to contextualize queries and keys based on localized feature scales, and (ii) time-adaptive modulator to let the dependency modeling among pattern pairs sensitive to different time intervals. Attention heads in stacked layers gradually harvest short- and long-term transition traits, spontaneously boosting the diversity of representations. Moreover, we devise a graph self-supervised regularization, which helps automatically assimilate the collective synergy of stocks and improve the generalization ability of overall model. Experiments on three exchange market datasets show ALSP-TF’s superiority over state-of-the-art stock forecast methods. Keywords: Multidisciplinary Topics and Applications: Finance Data Mining: Applications},
  archive   = {C_IJCAI},
  author    = {Heyuan Wang and Tengjiao Wang and Shun Li and Jiayi Zheng and Shijie Guan and Wei Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/551},
  pages     = {3970-3977},
  title     = {Adaptive long-short pattern transformer for stock investment selection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous interactive snapshot network for
review-enhanced stock profiling and recommendation. <em>IJCAI</em>,
3962–3969. (<a href="https://doi.org/10.24963/ijcai.2022/550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Stock recommendation plays a critical role in modern quantitative trading. The large volumes of social media information such as investment reviews that delegate emotion-driven factors, together with price technical indicators formulate a “snapshot” of the evolving stock market profile. However, previous studies usually model the temporal trajectories of price and media modalities separately while losing their interrelated influences. Moreover, they mainly extract review semantics via sequential or attentive models, whereas the rich text associated knowledge is largely neglected. In this paper, we propose a novel heterogeneous interactive snapshot network for stock profiling and recommendation. We model investment reviews in each snapshot as a heterogeneous document graph, and develop a flexible hierarchical attentive propagation framework to capture fine-grained proximity features. Further, to learn stock embedding for ranking, we introduce a novel twins-GRU method, which tightly couples the media and price parallel sequences in a cross-interactive fashion to catch dynamic dependencies between successive snapshots. Our approach excels state-of-the-arts over 7.6\% in terms of cumulative and risk-adjusted returns in trading simulations on both English and Chinese benchmarks. Keywords: Multidisciplinary Topics and Applications: Finance Data Mining: Applications},
  archive   = {C_IJCAI},
  author    = {Heyuan Wang and Tengjiao Wang and Shun Li and Shijie Guan and Jiayi Zheng and Wei Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/550},
  pages     = {3962-3969},
  title     = {Heterogeneous interactive snapshot network for review-enhanced stock profiling and recommendation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring the vulnerability of deep reinforcement
learning-based emergency control for low carbon power systems.
<em>IJCAI</em>, 3954–3961. (<a
href="https://doi.org/10.24963/ijcai.2022/549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Decarbonization of global power systems significantly increases the operational uncertainty and modeling complexity that drive the necessity of widely exploiting cutting-edge Deep Reinforcement Learning (DRL) technologies to realize adaptive and real-time emergency control, which is the last resort for system stability and resiliency. The vulnerability of the DRL-based emergency control scheme may lead to severe real-world security issues if it can not be fully explored before implementing it practically. To this end, this is the first work that comprehensively investigates adversarial attacks and defense mechanisms for DRL-based power system emergency control. In particular, recovery-targeted (RT) adversarial attacks are designed for gradient-based approaches, aiming to dramatically degrade the effectiveness of the conducted emergency control actions to prevent the system from restoring to a stable state. Furthermore, the corresponding robust defense (RD) mechanisms are proposed to actively modify the observations based on the distances of sequential states. Experiments are conducted based on the standard IEEE reliability test system, and the results show that security risks indeed exist in the state-of-the-art DRL-based power system emergency control models. The effectiveness, stealthiness, instantaneity, and transferability of the proposed attacks and defense mechanisms are demonstrated with both white-box and black-box settings. Keywords: Multidisciplinary Topics and Applications: Smart Cities Machine Learning: Reinforcement Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Xu Wan and Lanting Zeng and Mingyang Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/549},
  pages     = {3954-3961},
  title     = {Exploring the vulnerability of deep reinforcement learning-based emergency control for low carbon power systems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Private stochastic convex optimization and sparse learning
with heavy-tailed data revisited. <em>IJCAI</em>, 3947–3953. (<a
href="https://doi.org/10.24963/ijcai.2022/548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) with heavy-tailed data, where the gradient of the loss function has bounded moments. Instead of the case where the loss function is Lipschitz or each coordinate of the gradient has bounded second moment studied previously, we consider a relaxed scenario where each coordinate of the gradient only has bounded (1+v)-th moment with some v∈(0, 1]. Firstly, we start from the one dimensional private mean estimation for heavy-tailed distributions. We propose a novel robust and private mean estimator which is optimal. Based on its idea, we then extend to the general d-dimensional space and study DP-SCO with general convex and strongly convex loss functions. We also provide lower bounds for these two classes of loss under our setting and show that our upper bounds are optimal up to a factor of O(Poly(d)). To address the high dimensionality issue, we also study DP-SCO with heavy-tailed gradient under some sparsity constraint (DP sparse learning). We propose a new method and show it is also optimal up to a factor of O(s*), where s* is the underlying sparsity of the constraint. Keywords: Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Youming Tao and Yulian Wu and Xiuzhen Cheng and Di Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/548},
  pages     = {3947-3953},
  title     = {Private stochastic convex optimization and sparse learning with heavy-tailed data revisited},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Local differential privacy meets computational social choice
- resilience under voter deletion. <em>IJCAI</em>, 3940–3946. (<a
href="https://doi.org/10.24963/ijcai.2022/547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The resilience of a voting system has been a central topic in computational social choice. Many voting rules, like plurality, are shown to be vulnerable as the attacker can target specific voters to manipulate the result. What if a local differential privacy (LDP) mechanism is adopted such that the true preference of a voter is never revealed in pre-election polls? In this case, the attacker can only infer stochastic information about a voter&#39;s true preference, and this may cause the manipulation of the electoral result significantly harder. The goal of this paper is to provide a quantitative study on the effect of adopting LDP mechanisms on a voting system. We introduce the metric PoLDP (power of LDP) that quantitatively measures the difference between the attacker&#39;s manipulation cost under LDP mechanisms and that without LDP mechanisms. The larger PoLDP is, the more robustness LDP mechanisms can add to a voting system. We give a full characterization of PoLDP for the voting system with plurality rule and provide general guidance towards the application of LDP mechanisms. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Liangde Tao and Lin Chen and Lei Xu and Weidong Shi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/547},
  pages     = {3940-3946},
  title     = {Local differential privacy meets computational social choice - resilience under voter deletion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Offline vehicle routing problem with online bookings: A
novel problem formulation with applications to paratransit.
<em>IJCAI</em>, 3933–3939. (<a
href="https://doi.org/10.24963/ijcai.2022/546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vehicle routing problems (VRPs) can be divided into two major categories: offline VRPs, which consider a given set of trip requests to be served, and online VRPs, which consider requests as they arrive in real-time. Based on discussions with public transit agencies, we identify a real-world problem that is not addressed by existing formulations: booking trips with flexible pickup windows (e.g., 3 hours) in advance (e.g., the day before) and confirming tight pickup windows (e.g., 30 minutes) at the time of booking. Such a service model is often required in paratransit service settings, where passengers typically book trips for the next day over the phone. To address this gap between offline and online problems, we introduce a novel formulation, the offline vehicle routing problem with online bookings. This problem is very challenging computationally since it faces the complexity of considering large sets of requests—similar to offline VRPs—but must abide by strict constraints on running time—similar to online VRPs. To solve this problem, we propose a novel computational approach, which combines an anytime algorithm with a learning-based policy for real-time decisions. Based on a paratransit dataset obtained from the public transit agency of Chattanooga, TN, we demonstrate that our novel formulation and computational approach lead to significantly better outcomes in this setting than existing algorithms. Keywords: Multidisciplinary Topics and Applications: Transportation Constraint Satisfaction and Optimization: Applications Machine Learning: Reinforcement Learning Planning and Scheduling: Learning in Planning and Scheduling Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Amutheezan Sivagnanam and Salah Uddin Kadir and Ayan Mukhopadhyay and Philip Pugliese and Abhishek Dubey and Samitha Samaranayake and Aron Laszka},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/546},
  pages     = {3933-3939},
  title     = {Offline vehicle routing problem with online bookings: A novel problem formulation with applications to paratransit},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FOGS: First-order gradient supervision with learning-based
graph for traffic flow forecasting. <em>IJCAI</em>, 3926–3932. (<a
href="https://doi.org/10.24963/ijcai.2022/545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traffic flow forecasting plays a vital role in the transportation domain. Existing studies usually manually construct correlation graphs and design sophisticated models for learning spatial and temporal features to predict future traffic states. However, manually constructed correlation graphs cannot accurately extract the complex patterns hidden in the traffic data. In addition, it is challenging for the prediction model to fit traffic data due to its irregularly-shaped distribution. To solve the above-mentioned problems, in this paper, we propose a novel learning-based method to learn a spatial-temporal correlation graph, which could make good use of the traffic flow data. Moreover, we propose First-Order Gradient Supervision (FOGS), a novel method for traffic flow forecasting. FOGS utilizes first-order gradients, rather than specific flows, to train prediction model, which effectively avoids the problem of fitting irregularly-shaped distributions. Comprehensive numerical evaluations on four real-world datasets reveal that the proposed methods achieve state-of-the-art performance and significantly outperform the benchmarks. Keywords: Multidisciplinary Topics and Applications: Transportation Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Xuan Rao and Hao Wang and Liang Zhang and Jing Li and Shuo Shang and Peng Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/545},
  pages     = {3926-3932},
  title     = {FOGS: First-order gradient supervision with learning-based graph for traffic flow forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Communicative subgraph representation learning for
multi-relational inductive drug-gene interaction prediction.
<em>IJCAI</em>, 3919–3925. (<a
href="https://doi.org/10.24963/ijcai.2022/544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Illuminating the interconnections between drugs and genes is an important topic in drug development and precision medicine. Currently, computational predictions of drug-gene interactions mainly focus on the binding interactions without considering other relation types like agonist, antagonist, etc. In addition, existing methods either heavily rely on high-quality domain features or are intrinsically transductive, which limits the capacity of models to generalize to drugs/genes that lack external information or are unseen during the training process. To address these problems, we propose a novel Communicative Subgraph representation learning for Multi-relational Inductive drug-Gene interactions prediction (CoSMIG), where the predictions of drug-gene relations are made through subgraph patterns, and thus are naturally inductive for unseen drugs/genes without retraining or utilizing external domain features. Moreover, the model strengthened the relations on the drug-gene graph through a communicative message passing mechanism. To evaluate our method, we compiled two new benchmark datasets from DrugBank and DGIdb. The comprehensive experiments on the two datasets showed that our method outperformed state-of-the-art baselines in the transductive scenarios and achieved superior performance in the inductive ones. Further experimental analysis including LINCS experimental validation and literature verification also demonstrated the value of our model. Keywords: Multidisciplinary Topics and Applications: Bioinformatics Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Jiahua Rao and Shuangjia Zheng and Sijie Mai and Yuedong Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/544},
  pages     = {3919-3925},
  title     = {Communicative subgraph representation learning for multi-relational inductive drug-gene interaction prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learn continuously, act discretely: Hybrid action-space
reinforcement learning for optimal execution. <em>IJCAI</em>, 3912–3918.
(<a href="https://doi.org/10.24963/ijcai.2022/543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Optimal execution is a sequential decision-making problem for cost-saving in algorithmic trading. Studies have found that reinforcement learning (RL) can help decide the order-splitting sizes. However, a problem remains unsolved: how to place limit orders at appropriate limit prices? The key challenge lies in the ``continuous-discrete duality&#39;&#39; of the action space. On the one hand, the continuous action space using percentage changes in prices is preferred for generalization. On the other hand, the trader eventually needs to choose limit prices discretely due to the existence of the tick size, which requires specialization for every single stock with different characteristics (e.g., the liquidity and the price range). So we need continuous control for generalization and discrete control for specialization. To this end, we propose a hybrid RL method to combine the advantages of both of them. We first use a continuous control agent to scope an action subset, then deploy a fine-grained agent to choose a specific limit price. Extensive experiments show that our method has higher sample efficiency and better training stability than existing RL algorithms and significantly outperforms previous learning-based methods for order execution. Keywords: Multidisciplinary Topics and Applications: Finance Machine Learning: Deep Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Feiyang Pan and Tongzhe Zhang and Ling Luo and Jia He and Shuoling Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/543},
  pages     = {3912-3918},
  title     = {Learn continuously, act discretely: Hybrid action-space reinforcement learning for optimal execution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monolith to microservices: Representing application software
through heterogeneous graph neural network. <em>IJCAI</em>, 3905–3911.
(<a href="https://doi.org/10.24963/ijcai.2022/542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Monolithic software encapsulates all functional capabilities into a single deployable unit. But managing it becomes harder as the demand for new functionalities grow. Microservice architecture is seen as an alternative as it advocates building an application through a set of loosely coupled small services wherein each service owns a single functional responsibility. But the challenges associated with the separation of functional modules, slows down the migration of a monolithic code into microservices. In this work, we propose a representation learning based solution to tackle this problem. We use a heterogeneous graph to jointly represent software artifacts (like programs and resources) and the different relationships they share (function calls, inheritance, etc.), and perform a constraint-based clustering through a novel heterogeneous graph neural network. Experimental studies show that our approach is effective on monoliths of different types. Keywords: Multidisciplinary Topics and Applications: Software Engineering Machine Learning: Applications Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Alex Mathai and Sambaran Bandyopadhyay and Utkarsh Desai and Srikanth Tamilselvam},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/542},
  pages     = {3905-3911},
  title     = {Monolith to microservices: Representing application software through heterogeneous graph neural network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distilling governing laws and source input for dynamical
systems from videos. <em>IJCAI</em>, 3898–3904. (<a
href="https://doi.org/10.24963/ijcai.2022/541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Distilling interpretable physical laws from videos has led to expanded interest in the computer vision community recently thanks to the advances in deep learning, but still remains a great challenge. This paper introduces an end-to-end unsupervised deep learning framework to uncover the explicit governing equations of dynamics presented by moving object(s), based on recorded videos. Instead in the pixel (spatial) coordinate system of image space, the physical law is modeled in a regressed underlying physical coordinate system where the physical states follow potential explicit governing equations. A numerical integrator-based sparse regression module is designed and serves as a physical constraint to the autoencoder and coordinate system regression, and, in the meanwhile, uncover the parsimonious closed-form governing equations from the learned physical states. Experiments on simulated dynamical scenes show that the proposed method is able to distill closed-form governing equations and simultaneously identify unknown excitation input for several dynamical systems recorded by videos, which fills in the gap in literature where no existing methods are available and applicable for solving this type of problem. Keywords: Multidisciplinary Topics and Applications: Physical Science Computer Vision: Interpretability and Transparency Computer Vision: Video analysis and understanding Machine Learning: Autoencoders Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Lele Luan and Yang Liu and Hao Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/541},
  pages     = {3898-3904},
  title     = {Distilling governing laws and source input for dynamical systems from videos},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards controlling the transmission of diseases: Continuous
exposure discovery over massive-scale moving objects. <em>IJCAI</em>,
3891–3897. (<a href="https://doi.org/10.24963/ijcai.2022/540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Infectious diseases have been recognized as major public health concerns for decades. Close contact discovery is playing an indispensable role in preventing epidemic transmission. In this light, we study the continuous exposure search problem: Given a collection of moving objects and a collection of moving queries, we continuously discover all objects that have been directly and indirectly exposed to at least one query over a period of time. Our problem targets a variety of applications, including but not limited to disease control, epidemic pre-warning, information spreading, and co-movement mining. To answer this problem, we develop an exact group processing algorithm with optimization strategies. Further, we propose an approximate algorithm that substantially improves the efficiency without false dismissal. Extensive experiments offer insight into effectiveness and efficiency of our proposed algorithms. Keywords: Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Ke Li and Lisi Chen and Shuo Shang and Haiyan Wang and Yang Liu and Panos Kalnis and Bin Yao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/540},
  pages     = {3891-3897},
  title     = {Towards controlling the transmission of diseases: Continuous exposure discovery over massive-scale moving objects},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transformer-based objective-reinforced generative
adversarial network to generate desired molecules. <em>IJCAI</em>,
3884–3890. (<a href="https://doi.org/10.24963/ijcai.2022/539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep generative models of sequence-structure data have attracted widespread attention in drug discovery. However, such models cannot fully extract the semantic features of molecules from sequential representations. Moreover, mode collapse reduces the diversity of the generated molecules. This paper proposes a transformer-based objective-reinforced generative adversarial network (TransORGAN) to generate molecules. TransORGAN leverages a transformer architecture as a generator and uses a stochastic policy gradient for reinforcement learning to generate plausible molecules with rich semantic features. The discriminator grants rewards that guide the policy update of the generator, while an objective-reinforced penalty encourages the generation of diverse molecules. Experiments were performed using the ZINC chemical dataset, and the results demonstrated the usefulness of TransORGAN in terms of uniqueness, novelty, and diversity of the generated molecules. Keywords: Multidisciplinary Topics and Applications: Bioinformatics Multidisciplinary Topics and Applications: Health and Medicine Multidisciplinary Topics and Applications: Life Science},
  archive   = {C_IJCAI},
  author    = {Chen Li and Chikashige Yamanaka and Kazuma Kaitoh and Yoshihiro Yamanishi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/539},
  pages     = {3884-3890},
  title     = {Transformer-based objective-reinforced generative adversarial network to generate desired molecules},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning curricula for humans: An empirical study with
puzzles from the witness. <em>IJCAI</em>, 3877–3883. (<a
href="https://doi.org/10.24963/ijcai.2022/538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The combination of tree search and neural networks has achieved super-human performance in challenging domains. We are interested in transferring to humans the knowledge these learning systems generate. We hypothesize the process in which neural-guided tree search algorithms learn how to solve a set of problems can be used to generate curricula for helping human learners. In this paper we show how the Bootstrap learning system can be modified to learn curricula for humans in a puzzle domain. We evaluate our system in two curriculum learning settings. First, given a small set of problem instances, our system orders the instances to ease the learning process of human learners. Second, given a large set of problem instances, our system returns a small ordered subset of the initial set that can be presented to human learners. We evaluate our curricula with a user study where participants learn how to solve a class of puzzles from the game `The Witness.&#39; The user-study results suggest one of the curricula our system generates compares favorably with simple baselines and is competitive with the curriculum from the original `The Witness&#39; game in terms of user retention and effort. Keywords: Multidisciplinary Topics and Applications: Computer Games Humans and AI: Applications Search: Heuristic Search},
  archive   = {C_IJCAI},
  author    = {Levi H.S. Lelis and João G.G.V. Nova and Eugene Chen and Nathan R. Sturtevant and Carrie Demmans Epp and Michael Bowling},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/538},
  pages     = {3877-3883},
  title     = {Learning curricula for humans: An empirical study with puzzles from the witness},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised learning with attention-based latent signal
augmentation for sleep staging with limited labeled data.
<em>IJCAI</em>, 3868–3876. (<a
href="https://doi.org/10.24963/ijcai.2022/537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sleep staging is an important task that enables sleep quality assessment and disorder diagnosis. Due to dependency on manually labeled data, many researches have turned from supervised approaches to self-supervised learning (SSL) for sleep staging. While existing SSL methods have made significant progress in terms of its comparable performance to supervised methods, there are still some limitations. Contrastive learning could potentially lead to false negative pair assignments in sleep signal data. Moreover, existing data augmentation techniques directly modify the original signal data, making it likely to lose important information. To mitigate these issues, we propose Self-Supervised Learning with Attention-aided Positive Pairs (SSLAPP). Instead of the contrastive learning, SSLAPP carefully draws high-quality positive pairs and exploits them in representation learning. Here, we propose attention-based latent signal augmentation, which plays a key role by capturing important features without losing valuable signal information. Experimental results show that our proposed method achieves state-of-the-art performance in sleep stage classification with limited labeled data. The code is available at: https://github.com/DILAB-HYU/SSLAPP Keywords: Multidisciplinary Topics and Applications: Bioinformatics Data Mining: Mining Data Streams Machine Learning: Self-supervised Learning Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Harim Lee and Eunseon Seong and Dong-Kyu Chae},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/537},
  pages     = {3868-3876},
  title     = {Self-supervised learning with attention-based latent signal augmentation for sleep staging with limited labeled data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cumulative stay-time representation for electronic health
records in medical event time prediction. <em>IJCAI</em>, 3861–3867. (<a
href="https://doi.org/10.24963/ijcai.2022/536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the problem of predicting when a disease will develop, i.e., medical event time (MET), from a patient&#39;s electronic health record (EHR). The MET of non-communicable diseases like diabetes is highly correlated to cumulative health conditions, more specifically, how much time the patient spent with specific health conditions in the past. The common time-series representation is indirect in extracting such information from EHR because it focuses on detailed dependencies between values in successive observations, not cumulative information. We propose a novel data representation for EHR called cumulative stay-time representation (CTR), which directly models such cumulative health conditions. We derive a trainable construction of CTR based on neural networks that has the flexibility to fit the target data and scalability to handle high-dimensional EHR. Numerical experiments using synthetic and real-world datasets demonstrate that CTR alone achieves a high prediction performance, and it enhances the performance of existing models when combined with them. Keywords: Multidisciplinary Topics and Applications: Health and Medicine Machine Learning: Applications Machine Learning: Feature Extraction, Selection and Dimensionality Reduction Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Takayuki Katsuki and Kohei Miyaguchi and Akira Koseki and Toshiya Iwamori and Ryosuke Yanagiya and Atsushi Suzuki},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/536},
  pages     = {3861-3867},
  title     = {Cumulative stay-time representation for electronic health records in medical event time prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent reinforcement learning for traffic signal
control through universal communication method. <em>IJCAI</em>,
3854–3860. (<a href="https://doi.org/10.24963/ijcai.2022/535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How to coordinate the communication among intersections effectively in real complex traffic scenarios with multi-intersection is challenging. Existing approaches only enable the communication in a heuristic manner without considering the content/importance of information to be shared. In this paper, we propose a universal communication form UniComm between intersections. UniComm embeds massive observations collected at one agent into crucial predictions of their impact on its neighbors, which improves the communication efficiency and is universal across existing methods. We also propose a concise network UniLight to make full use of communications enabled by UniComm. Experimental results on real datasets demonstrate that UniComm universally improves the performance of existing state-of-the-art methods, and UniLight significantly outperforms existing methods on a wide range of traffic situations. Source codes are available at https://github.com/zyr17/UniLight. Keywords: Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Qize Jiang and Minhao Qin and Shengmin Shi and Weiwei Sun and Baihua Zheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/535},
  pages     = {3854-3860},
  title     = {Multi-agent reinforcement learning for traffic signal control through universal communication method},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A polynomial-time decentralised algorithm for coordinated
management of multiple intersections. <em>IJCAI</em>, 3847–3853. (<a
href="https://doi.org/10.24963/ijcai.2022/534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Autonomous intersection management has the potential to reduce road traffic congestion and energy consumption. To realize this potential, efficient algorithms are needed. However, most existing studies locally optimize one intersection at a time, and this can cause negative externalities on the traffic network as a whole. Here, we focus on coordinating multiple intersections, and formulate the problem as a distributed constraint optimisation problem (DCOP). We consider three utility design approaches that trade off efficiency and fairness. Our polynomial-time algorithm for coordinating multiple intersections reduces the traffic delay by about 41 percentage points compared to independent single intersection management approaches. Keywords: Multidisciplinary Topics and Applications: Transportation Agent-based and Multi-agent Systems: Coordination and Cooperation Constraint Satisfaction and Optimization: Distributed Constraints},
  archive   = {C_IJCAI},
  author    = {Tatsuya Iwase and Sebastian Stein and Enrico H. Gerding and Archie Chapman},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/534},
  pages     = {3847-3853},
  title     = {A polynomial-time decentralised algorithm for coordinated management of multiple intersections},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A universal PINNs method for solving partial differential
equations with a point source. <em>IJCAI</em>, 3839–3846. (<a
href="https://doi.org/10.24963/ijcai.2022/533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, deep learning technology has been used to solve partial differential equations (PDEs), among which the physics-informed neural networks (PINNs)method emerges to be a promising method for solving both forward and inverse PDE problems. PDEs with a point source that is expressed as a Dirac delta function in the governing equations are mathematical models of many physical processes. However, they cannot be solved directly by conventional PINNs method due to the singularity brought by the Dirac delta function. In this paper, we propose a universal solution to tackle this problem by proposing three novel techniques. Firstly the Dirac delta function is modeled as a continuous probability density function to eliminate the singularity at the point source; secondly a lower bound constrained uncertainty weighting algorithm is proposed to balance the physics-informed loss terms of point source area and the remaining areas; and thirdly a multi-scale deep neural network with periodic activation function is used to improve the accuracy and convergence speed. We evaluate the proposed method with three representative PDEs, and the experimental results show that our method outperforms existing deep learning based methods with respect to the accuracy, the efficiency and the versatility. Keywords: Multidisciplinary Topics and Applications: Physical Science Machine Learning: Multi-task and Transfer Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiang Huang and Hongsheng Liu and Beiji Shi and Zidong Wang and Kang Yang and Yang Li and Min Wang and Haotian Chu and Jing Zhou and Fan Yu and Bei Hua and Bin Dong and Lei Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/533},
  pages     = {3839-3846},
  title     = {A universal PINNs method for solving partial differential equations with a point source},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Membership inference via backdooring. <em>IJCAI</em>,
3832–3838. (<a href="https://doi.org/10.24963/ijcai.2022/532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently issued data privacy regulations like GDPR (General Data Protection Regulation) grant individuals the right to be forgotten. In the context of machine learning, this requires a model to forget about a training data sample if requested by the data owner (i.e., machine unlearning). As an essential step prior to machine unlearning, it is still a challenge for a data owner to tell whether or not her data have been used by an unauthorized party to train a machine learning model. Membership inference is a recently emerging technique to identify whether a data sample was used to train a target model, and seems to be a promising solution to this challenge. However, straightforward adoption of existing membership inference approaches fails to address the challenge effectively due to being originally designed for attacking membership privacy and suffering from several severe limitations such as low inference accuracy on well-generalized models. In this paper, we propose a novel membership inference approach inspired by the backdoor technology to address the said challenge. Specifically, our approach of Membership Inference via Backdooring (MIB) leverages the key observation that a backdoored model behaves very differently from a clean model when predicting on deliberately marked samples created by a data owner. Appealingly, MIB requires data owners&#39; marking a small number of samples for membership inference and only black-box access to the target model, with theoretical guarantees for inference results. We perform extensive experiments on various datasets and deep neural network architectures, and the results validate the efficacy of our approach, e.g., marking only 0.1\% of the training dataset is practically sufficient for effective membership inference. Keywords: Multidisciplinary Topics and Applications: Security and Privacy AI Ethics, Trust, Fairness: AI and Law, Governance, Regulation Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Hongsheng Hu and Zoran Salčić and Gillian Dobbie and Jinjun Chen and Lichao Sun and Xuyun Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/532},
  pages     = {3832-3838},
  title     = {Membership inference via backdooring},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Placing green bridges optimally, with habitats inducing
cycles. <em>IJCAI</em>, 3825–3831. (<a
href="https://doi.org/10.24963/ijcai.2022/531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Choosing the placement of wildlife crossings (i.e., green bridges) to reconnect animal species&#39; fragmented habitats is among the 17 goals towards sustainable development by the UN. We consider the following established model: Given a graph whose vertices represent the fragmented habitat areas and whose weighted edges represent possible green bridge locations, as well as the habitable vertex set for each species, find the cheapest set of edges such that each species&#39; habitat is connected. We study this problem from a theoretical (algorithms and complexity) and an experimental perspective, while focusing on the case where habitats induce cycles. We prove that the NP-hardness persists in this case even if the graph structure is restricted. If the habitats additionally induce faces in plane graphs however, the problem becomes efficiently solvable. In our empirical evaluation we compare this algorithm as well as ILP formulations for more general variants and an approximation algorithm with another. Our evaluation underlines that each specialization is beneficial in terms of running time, whereas the approximation provides highly competitive solutions in practice. Keywords: Multidisciplinary Topics and Applications: Computational Sustainability Search: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Maike Herkenrath and Till Fluschnik and Francesco Grothe and Leon Kellerhals},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/531},
  pages     = {3825-3831},
  title     = {Placing green bridges optimally, with habitats inducing cycles},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). 3E-solver: An effortless, easy-to-update, and end-to-end
solver with semi-supervised learning for breaking text-based captchas.
<em>IJCAI</em>, 3817–3824. (<a
href="https://doi.org/10.24963/ijcai.2022/530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Text-based captchas are the most widely used security mechanism currently. Due to the limitations and specificity of the segmentation algorithm, the early segmentation-based attack method has been unable to deal with the current captchas with newly introduced security features (e.g., occluding lines and overlapping). Recently, some works have designed captcha solvers based on deep learning methods with powerful feature extraction capabilities, which have greater generality and higher accuracy. However, these works still suffer from two main intrinsic limitations: (1) many labor costs are required to label the training data, and (2) the solver cannot be updated with unlabeled data to recognize captchas more accurately. In this paper, we present a novel solver using improved FixMatch for semi-supervised captcha recognition to tackle these problems. Specifically, we first build an end-to-end baseline model to effectively break text-based captchas by leveraging encoder-decoder architecture and attention mechanism. Then we construct our solver with a few labeled samples and many unlabeled samples by improved FixMatch, which introduces teacher forcing, adaptive batch normalization, and consistency loss to achieve more effective training. Experiment results show that our solver outperforms state-of-the-arts by a large margin on current captcha schemes. We hope that our work can help security experts to revisit the design and usability of text-based captchas. The source code of this work is available at https://github.com/SJTU-dxw/3E-Solver-CAPTCHA. Keywords: Multidisciplinary Topics and Applications: Security and Privacy Multidisciplinary Topics and Applications: Other},
  archive   = {C_IJCAI},
  author    = {Xianwen Deng and Ruijie Zhao and Yanhao Wang and Libo Chen and Yijun Wang and Zhi Xue},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/530},
  pages     = {3817-3824},
  title     = {3E-solver: An effortless, easy-to-update, and end-to-end solver with semi-supervised learning for breaking text-based captchas},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subsequence-based graph routing network for capturing
multiple risk propagation processes. <em>IJCAI</em>, 3810–3816. (<a
href="https://doi.org/10.24963/ijcai.2022/529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In finance, the risk of an entity depends not only on its historical information but also on the risk propagated by its related peers. Pilot studies rely on Graph Neural Networks (GNNs) to model this risk propagation, where each entity is treated as a node and represented by its time-series information. However, conventional GNNs are constrained by their unified messaging mechanism with an assumption that the risk of a given entity only propagates to its related peers with the same time lag and has the same effect, which is against the ground truth. In this study, we propose the subsequence-based graph routing network (S-GRN) for capturing the variant risk propagation processes among different time-series represented entities. In S-GRN, the messaging mechanism between each node pair is dynamically and independently selected from multiple messaging mechanisms based on the dependencies of variant subsequence patterns. The S-GRN is extensively evaluated on two synthetic tasks and three real-world datasets and demonstrates state-of-the-art performance. Keywords: Multidisciplinary Topics and Applications: Finance Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Rui Cheng and Qing Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/529},
  pages     = {3810-3816},
  title     = {Subsequence-based graph routing network for capturing multiple risk propagation processes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-constraint deep reinforcement learning for smooth
action control. <em>IJCAI</em>, 3802–3808. (<a
href="https://doi.org/10.24963/ijcai.2022/528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning (DRL) has been studied in a variety of challenging decision-making tasks, e.g., autonomous driving. \textcolor{black}{However, DRL typically suffers from the action shaking problem, which means that agents can select actions with big difference even though states only slightly differ.} One of the crucial reasons for this issue is the inappropriate design of the reward in DRL. In this paper, to address this issue, we propose a novel way to incorporate the smoothness of actions in the reward. Specifically, we introduce sub-rewards and add multiple constraints related to these sub-rewards. In addition, we propose a multi-constraint proximal policy optimization (MCPPO) method to solve the multi-constraint DRL problem. Extensive simulation results show that the proposed MCPPO method has better action smoothness compared with the traditional proportional-integral-differential (PID) and mainstream DRL algorithms. The video is available at https://youtu.be/F2jpaSm7YOg. Keywords: Machine Learning: Deep Reinforcement Learning Robotics: Behavior and Control},
  archive   = {C_IJCAI},
  author    = {Guangyuan Zou and Ying He and F. Richard Yu and Longquan Chen and Weike Pan and Zhong Ming},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/528},
  pages     = {3802-3808},
  title     = {Multi-constraint deep reinforcement learning for smooth action control},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RoSA: A robust self-aligned framework for node-node graph
contrastive learning. <em>IJCAI</em>, 3795–3801. (<a
href="https://doi.org/10.24963/ijcai.2022/527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph contrastive learning has gained significant progress recently. However, existing works have rarely explored non-aligned node-node contrasting. In this paper, we propose a novel graph contrastive learning method named RoSA that focuses on utilizing non-aligned augmented views for node-level representation learning. First, we leverage the earth mover&#39;s distance to model the minimum effort to transform the distribution of one view to the other as our contrastive objective, which does not require alignment between views. Then we introduce adversarial training as an auxiliary method to increase sampling diversity and enhance the robustness of our model. Experimental results show that RoSA outperforms a series of graph contrastive learning frameworks on homophilous, non-homophilous and dynamic graphs, which validates the effectiveness of our work. To the best of our awareness, RoSA is the first work focuses on the non-aligned node-node graph contrastive learning problem. Our codes are available at: https://github.com/ZhuYun97/RoSA Keywords: Machine Learning: Sequence and Graph Learning Machine Learning: Self-supervised Learning Machine Learning: Representation learning Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Yun Zhu and Jianhao Guo and Fei Wu and Siliang Tang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/527},
  pages     = {3795-3801},
  title     = {RoSA: A robust self-aligned framework for node-node graph contrastive learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised voice-face representation learning by
cross-modal prototype contrast. <em>IJCAI</em>, 3787–3794. (<a
href="https://doi.org/10.24963/ijcai.2022/526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an approach to learn voice-face representations from the talking face videos, without any identity labels. Previous works employ cross-modal instance discrimination tasks to establish the correlation of voice and face. These methods neglect the semantic content of different videos, introducing false-negative pairs as training noise. Furthermore, the positive pairs are constructed based on the natural correlation between audio clips and visual frames. However, this correlation might be weak or inaccurate in a large amount of real-world data, which leads to deviating positives into the contrastive paradigm. To address these issues, we propose the cross-modal prototype contrastive learning (CMPC), which takes advantage of contrastive methods and resists adverse effects of false negatives and deviate positives. On one hand, CMPC could learn the intra-class invariance by constructing semantic-wise positives via unsupervised clustering in different modalities. On the other hand, by comparing the similarities of cross-modal instances from that of cross-modal prototypes, we dynamically recalibrate the unlearnable instances&#39; contribution to overall loss. Experiments show that the proposed approach outperforms state-of-the-art unsupervised methods on various voice-face association evaluation protocols. Additionally, in the low-shot supervision setting, our method also has a significant improvement compared to previous instance-wise contrastive learning. Keywords: Machine Learning: Multi-modal learning Computer Vision: Biometrics, Face, Gesture and Pose Recognition Machine Learning: Self-supervised Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Boqing Zhu and Kele Xu and Changjian Wang and Zheng Qin and Tao Sun and Huaimin Wang and Yuxing Peng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/526},
  pages     = {3787-3794},
  title     = {Unsupervised voice-face representation learning by cross-modal prototype contrast},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Learning mixtures of random utility models with features
from incomplete preferences. <em>IJCAI</em>, 3780–3786. (<a
href="https://doi.org/10.24963/ijcai.2022/525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Random Utility Models (RUMs), which subsume Plackett-Luce model (PL) as a special case, are among the most popular models for preference learning. In this paper, we consider RUMs with features and their mixtures, where each alternative has a vector of features, possibly different across agents. Such models significantly generalize the standard PL and RUMs, but are not as well investigated in the literature. We extend mixtures of RUMs with features to models that generate incomplete preferences and characterize their identifiability. For PL, we prove that when PL with features is identifiable, its MLE is consistent with a strictly concave objective function under mild assumptions, by characterizing a bound on root-mean-square-error (RMSE), which naturally leads to a sample complexity bound. We also characterize identifiability of more general RUMs with features and propose a generalized RBCML to learn them. Our experiments on synthetic data demonstrate the effectiveness of MLE on PL with features with tradeoffs between statistical efficiency and computational efficiency. Our experiments on real-world data show the prediction power of PL with features and its mixtures. Keywords: Machine Learning: Learning Preferences or Rankings},
  archive   = {C_IJCAI},
  author    = {Zhibing Zhao and Ao Liu and Lirong Xia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/525},
  pages     = {3780-3786},
  title     = {Learning mixtures of random utility models with features from incomplete preferences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fusion label enhancement for multi-label learning.
<em>IJCAI</em>, 3773–3779. (<a
href="https://doi.org/10.24963/ijcai.2022/524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-label learning (MLL) refers to the problem of tagging a given instance with a set of relevant labels. In MLL, the implicit relative importance of different labels representing a single instance is generally different, which recently gained considerable attention and should be fully leveraged. Therefore, label enhancement (LE) has been widely applied in various MLL tasks as the ability to effectively mine the implicit relative importance information of different labels. However, due to the fact that the label enhancement process in previous LE-based MLL methods is decoupled from the training process on the predictive models, the objective of LE does not match the training process and finally affects the whole learning system. In this paper, we propose a novel approach named Fusion Label Enhancement for Multi-label learning (FLEM) to effectively integrate the LE process and the training process. Specifically, we design a matching and interaction mechanism which leverages a novel interaction label enhancement loss to avoid that the recovered label distribution does not match the need of the predictive model. In the meantime, we present a unified label distribution loss for establishing the corresponding relationship between the recovered label distribution and the training of the predictive model. With the proposed loss, the label distributions recovered from the LE process can be efficiently utilized for training the predictive model. Experimental results on multiple benchmark datasets validate the effectiveness of the proposed approach. Keywords: Machine Learning: Multi-label},
  archive   = {C_IJCAI},
  author    = {Xingyu Zhao and Yuexuan An and Ning Xu and Xin Geng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/524},
  pages     = {3773-3779},
  title     = {Fusion label enhancement for multi-label learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning mixture of neural temporal point processes for
multi-dimensional event sequence clustering. <em>IJCAI</em>, 3766–3772.
(<a href="https://doi.org/10.24963/ijcai.2022/523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-dimensional event sequence clustering applies to many scenarios e.g. e-Commerce and electronic health. Traditional clustering models fail to characterize complex real-world processes due to the strong parametric assumption. While Neural Temporal Point Processes (NTPPs) mainly focus on modeling similar sequences instead of clustering. To fill the gap, we propose Mixture of Neural Temporal Point Processes (NTPP-MIX), a general framework that can utilize many existing NTPPs for multi-dimensional event sequence clustering. In NTPP-MIX, the prior distribution of coefficients for cluster assignment is modeled by a Dirichlet distribution. When the assignment is given, the conditional probability of a sequence is modeled by the mixture of a series of NTPPs. We combine variational EM algorithm and Stochastic Gradient Descent (SGD) to efficiently train the framework. In E-step, we fix parameters for NTPPs and approximate the true posterior with variational distributions. In M-step, we fix variational distributions and use SGD to update parameters of NTPPs. Extensive experimental results on four synthetic datasets and three real-world datasets show the effectiveness of NTPP-MIX against state-of-the-arts. Keywords: Machine Learning: Time-series; Data Streams Machine Learning: Clustering},
  archive   = {C_IJCAI},
  author    = {Yunhao Zhang and Junchi Yan and Xiaolu Zhang and Jun Zhou and Xiaokang Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/523},
  pages     = {3766-3772},
  title     = {Learning mixture of neural temporal point processes for multi-dimensional event sequence clustering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Het2Hom: Representation of heterogeneous attributes into
homogeneous concept spaces for categorical-and-numerical-attribute data
clustering. <em>IJCAI</em>, 3758–3765. (<a
href="https://doi.org/10.24963/ijcai.2022/522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Data sets composed of a mixture of categorical and numerical attributes (also called mixed data hereinafter) are common in real-world cluster analysis. However, insightful analysis of such data under an unsupervised scenario using clustering is extremely challenging because the information provided by the two different types of attributes is heterogeneous, being at different concept hierarchies. That is, the values of a categorical attribute represent a set of different concepts (e.g., professor, lawyer, and doctor of the attribute &quot;occupation&quot;), while the values of a numerical attribute describe the tendencies toward two different concepts (e.g., low and high of the attribute &quot;income&quot;). To appropriately use such heterogeneous information in clustering, this paper therefore proposes a novel attribute representation learning method called Het2Hom, which first converts the heterogeneous attributes into a homogeneous form, and then learns attribute representations and data partitions on such a homogeneous basis. Het2Hom features low time complexity and intuitive interpretability. Extensive experiments show that Het2Hom outperforms the state-of-the-art counterparts. Keywords: Machine Learning: Clustering},
  archive   = {C_IJCAI},
  author    = {Yiqun Zhang and Yiu-ming Cheung and An Zeng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/522},
  pages     = {3758-3765},
  title     = {Het2Hom: Representation of heterogeneous attributes into homogeneous concept spaces for categorical-and-numerical-attribute data clustering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Next point-of-interest recommendation with inferring
multi-step future preferences. <em>IJCAI</em>, 3751–3757. (<a
href="https://doi.org/10.24963/ijcai.2022/521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing studies on next point-of-interest (POI) recommendation mainly attempt to learn user preference from the past and current sequential behaviors. They, however, completely ignore the impact of future behaviors on the decision-making, thus hindering the quality of user preference learning. Intuitively, users&#39; next POI visits may also be affected by their multi-step future behaviors, as users may often have activity planning in mind. To fill this gap, we propose a novel Context-aware Future Preference inference Recommender (CFPRec) to help infer user future preference in a self-ensembling manner. In particular, it delicately derives multi-step future preferences from the learned past preference thanks to the periodic property of users&#39; daily check-ins, so as to implicitly mimic user’s activity planning before her next visit. The inferred future preferences are then seamlessly integrated with the current preference for more expressive user preference learning. Extensive experiments on three datasets demonstrate the superiority of CFPRec against state-of-the-arts. Keywords: Machine Learning: Recommender Systems Humans and AI: Personalization and User Modeling},
  archive   = {C_IJCAI},
  author    = {Lu Zhang and Zhu Sun and Ziqing Wu and Jie Zhang and Yew Soon Ong and Xinghua Qu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/521},
  pages     = {3751-3757},
  title     = {Next point-of-interest recommendation with inferring multi-step future preferences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Penalized proximal policy optimization for safe
reinforcement learning. <em>IJCAI</em>, 3744–3750. (<a
href="https://doi.org/10.24963/ijcai.2022/520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Safe reinforcement learning aims to learn the optimal policy while satisfying safety constraints, which is essential in real-world applications. However, current algorithms still struggle for efficient policy updates with hard constraint satisfaction. In this paper, we propose Penalized Proximal Policy Optimization (P3O), which solves the cumbersome constrained policy iteration via a single minimization of an equivalent unconstrained problem. Specifically, P3O utilizes a simple yet effective penalty approach to eliminate cost constraints and removes the trust-region constraint by the clipped surrogate objective. We theoretically prove the exactness of the penalized method with a finite penalty factor and provide a worst-case analysis for approximate error when evaluated on sample trajectories. Moreover, we extend P3O to more challenging multi-constraint and multi-agent scenarios which are less studied in previous work. Extensive experiments show that P3O outperforms state-of-the-art algorithms with respect to both reward improvement and constraint satisfaction on a set of constrained locomotive tasks. Keywords: Machine Learning: Deep Reinforcement Learning Constraint Satisfaction and Optimization: Constraint Optimization Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Linrui Zhang and Li Shen and Long Yang and Shixiang Chen and Xueqian Wang and Bo Yuan and Dacheng Tao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/520},
  pages     = {3744-3750},
  title     = {Penalized proximal policy optimization for safe reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical diffusion scattering graph neural network.
<em>IJCAI</em>, 3737–3743. (<a
href="https://doi.org/10.24963/ijcai.2022/519">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural network (GNN) is popular now to solve the tasks in non-Euclidean space and most of them learn deep embeddings by aggregating the neighboring nodes. However, these methods are prone to some problems such as over-smoothing because of the single-scale perspective field and the nature of low-pass filter. To address these limitations, we introduce diffusion scattering network (DSN) to exploit high-order patterns. With observing the complementary relationship between multi-layer GNN and DSN, we propose Hierarchical Diffusion Scattering Graph Neural Network (HDS-GNN) to efficiently bridge DSN and GNN layer by layer to supplement GNN with multi-scale information and band-pass signals. Our model extracts node-level scattering representations by intercepting the low-pass filtering, and adaptively tunes the different scales to regularize multi-scale information. Then we apply hierarchical representation enhancement to improve GNN with the scattering features. We benchmark our model on nine real-world networks on the transductive semi-supervised node classification task. The experimental results demonstrate the effectiveness of our method. Keywords: Machine Learning: Geometric Learning Machine Learning: Representation learning Machine Learning: Semi-Supervised Learning Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Ke Zhang and Xinyan Pu and Jiaxing Li and Jiasong Wu and Huazhong Shu and Youyong Kong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/519},
  pages     = {3737-3743},
  title     = {Hierarchical diffusion scattering graph neural network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-tuning graph neural networks via graph topology induced
optimal transport. <em>IJCAI</em>, 3730–3736. (<a
href="https://doi.org/10.24963/ijcai.2022/518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, the pretrain-finetuning paradigm has attracted tons of attention in graph learning community due to its power of alleviating the lack of labels problem in many real-world applications. Current studies use existing techniques, such as weight constraint, representation constraint, which are derived from images or text data, to transfer the invariant knowledge from the pre-train stage to fine-tuning stage. However, these methods failed to preserve invariances from graph structure and Graph Neural Network (GNN) style models. In this paper, we present a novel optimal transport-based fine-tuning framework called GTOT-Tuning, namely, Graph Topology induced Optimal Transport fine-Tuning, for GNN style backbones. GTOT-Tuning is required to utilize the property of graph data to enhance the preservation of representation produced by fine-tuned networks. Toward this goal, we formulate graph local knowledge transfer as an Optimal Transport (OT) problem with a structural prior and construct the GTOT regularizer to constrain the fine-tuned model behaviors. By using the adjacency relationship amongst nodes, the GTOT regularizer achieves node-level optimal transport procedures and reduces redundant transport procedures, resulting in efficient knowledge transfer from the pre-trained models. We evaluate GTOT-Tuning on eight downstream tasks with various GNN backbones and demonstrate that it achieves state-of-the-art fine-tuning performance for GNNs. Keywords: Machine Learning: Sequence and Graph Learning Data Mining: Mining Graphs Machine Learning: Multi-task and Transfer Learning},
  archive   = {C_IJCAI},
  author    = {Jiying Zhang and Xi Xiao and Long-Kai Huang and Yu Rong and Yatao Bian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/518},
  pages     = {3730-3736},
  title     = {Fine-tuning graph neural networks via graph topology induced optimal transport},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hyperbolic knowledge transfer with class hierarchy for
few-shot learning. <em>IJCAI</em>, 3723–3729. (<a
href="https://doi.org/10.24963/ijcai.2022/517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning (FSL) aims to recognize a novel class with very few instances, which is a challenging task since it suffers from a data scarcity issue. One way to effectively alleviate this issue is introducing explicit knowledge summarized from human past experiences to achieve knowledge transfer for FSL. Based on this idea, in this paper, we introduce the explicit knowledge of class hierarchy (i.e., the hierarchy relations between classes) as FSL priors and propose a novel hyperbolic knowledge transfer framework for FSL, namely, HyperKT. Our insight is, in the hyperbolic space, the hierarchy relation between classes can be well preserved by resorting to the exponential growth characters of hyperbolic volume, so that better knowledge transfer can be achieved for FSL. Specifically, we first regard the class hierarchy as a tree-like structure. Then, 1) a hyperbolic representation learning module and a hyperbolic prototype inference module are employed to encode/infer each image and class prototype to the hyperbolic space, respectively; and 2) a novel hierarchical classification and relation reconstruction loss are carefully designed to learn the class hierarchy. Finally, the novel class prediction is performed in a nearest-prototype manner. Extensive experiments on three datasets show our method achieves superior performance over state-of-the-art methods, especially on 1-shot tasks. Keywords: Machine Learning: Few-shot learning Machine Learning: Meta-Learning Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Baoquan Zhang and Hao Jiang and Shanshan Feng and Xutao Li and Yunming Ye and Rui Ye},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/517},
  pages     = {3723-3729},
  title     = {Hyperbolic knowledge transfer with class hierarchy for few-shot learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model-based offline planning with trajectory pruning.
<em>IJCAI</em>, 3716–3722. (<a
href="https://doi.org/10.24963/ijcai.2022/516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent offline reinforcement learning (RL) studies have achieved much progress to make RL usable in real-world systems by learning policies from pre-collected datasets without environment interaction. Unfortunately, existing offline RL methods still face many practical challenges in real-world system control tasks, such as computational restriction during agent training and the requirement of extra control flexibility. The model-based planning framework provides an attractive alternative. However, most model-based planning algorithms are not designed for offline settings. Simply combining the ingredients of offline RL with existing methods either provides over-restrictive planning or leads to inferior performance. We propose a new light-weighted model-based offline planning framework, namely MOPP, which tackles the dilemma between the restrictions of offline learning and high-performance planning. MOPP encourages more aggressive trajectory rollout guided by the behavior policy learned from data, and prunes out problematic trajectories to avoid potential out-of-distribution samples. Experimental results show that MOPP provides competitive performance compared with existing model-based offline planning and RL approaches. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Planning and Scheduling: Markov Decisions Processes Planning and Scheduling: Planning Algorithms},
  archive   = {C_IJCAI},
  author    = {Xianyuan Zhan and Xiangyu Zhu and Haoran Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/516},
  pages     = {3716-3722},
  title     = {Model-based offline planning with trajectory pruning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved pure exploration in linear bandits with no-regret
learning. <em>IJCAI</em>, 3709–3715. (<a
href="https://doi.org/10.24963/ijcai.2022/515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the best arm identification problem in linear multi-armed bandits (LMAB) in the fixed confidence setting ; this is also the problem of optimizing an unknown linear function over a discrete domain with noisy, zeroth-order access. We propose an explicitly implementable and provably order-optimal sample-complexity algorithm for best arm identification. Existing approaches that achieve optimal sample complexity assume either access to a nontrivial minimax optimization oracle (e.g. RAGE and Lazy-TS) or knowledge of an upper-bound on the norm of the unknown parameter vector(e.g. LinGame). Our algorithm, which we call the Phased Elimination Linear Exploration Game (PELEG), maintains a high-probability confidence ellipsoid containing the unknown vector, and uses it to eliminate suboptimal arms in phases, where a minimax problem is essentially solved in each phase using two-player low regret learners. PELEG does not require to know a bound on norm of the unknown vector, and is asymptotically-optimal, settling an open problem. We show that the sample complexity of PELEG matches, up to order and in a non-asymptotic sense, an instance-dependent universal lower bound for linear bandits. PELEG is thus the first algorithm to achieve both order-optimal sample complexity and explicit implementability for this setting. We also provide numerical results for the proposed algorithm consistent with its theoretical guarantees. Keywords: Machine Learning: Online Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Mohammadi Zaki and Avi Mohan and Aditya Gopalan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/515},
  pages     = {3709-3715},
  title     = {Improved pure exploration in linear bandits with no-regret learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Don’t touch what matters: Task-aware lipschitz data
augmentation for visual reinforcement learning. <em>IJCAI</em>,
3702–3708. (<a href="https://doi.org/10.24963/ijcai.2022/514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One of the key challenges in visual Reinforcement Learning (RL) is to learn policies that can generalize to unseen environments. Recently, data augmentation techniques aiming at enhancing data diversity have demonstrated proven performance in improving the generalization ability of learned policies. However, due to the sensitivity of RL training, naively applying data augmentation, which transforms each pixel in a task-agnostic manner, may suffer from instability and damage the sample efficiency, thus further exacerbating the generalization performance. At the heart of this phenomenon is the diverged action distribution and high-variance value estimation in the face of augmented images. To alleviate this issue, we propose Task-aware Lipschitz Data Augmentation (TLDA) for visual RL, which explicitly identifies the task-correlated pixels with large Lipschitz constants, and only augments the task-irrelevant pixels for stability. We verify the effectiveness of our approach on DeepMind Control suite, CARLA and DeepMind Manipulation tasks. The extensive empirical results show that TLDA improves both sample efficiency and generalization; it outperforms previous state-of-the-art methods across 3 different visual control benchmarks. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Robotics: Learning in Robotics},
  archive   = {C_IJCAI},
  author    = {Zhecheng Yuan and Guozheng Ma and Yao Mu and Bo Xia and Bo Yuan and Xueqian Wang and Ping Luo and Huazhe Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/514},
  pages     = {3702-3708},
  title     = {Don’t touch what matters: Task-aware lipschitz data augmentation for visual reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Masked feature generation network for few-shot learning.
<em>IJCAI</em>, 3695–3701. (<a
href="https://doi.org/10.24963/ijcai.2022/513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a feature-augmentation approach called Masked Feature Generation Network (MFGN) for Few-Shot Learning (FSL), a challenging task that attempts to recognize the novel classes with a few visual instances for each class. Most of the feature-augmentation approaches tackle FSL tasks via modeling the intra-class distributions. We extend this idea further to explicitly capture the intra-class variations in a one-to-many manner. Specifically, MFGN consists of an encoder-decoder architecture, with an encoder that performs as a feature extractor and extracts the feature embeddings of the available visual instances (the unavailable instances are seen to be masked), along with a decoder that performs as a feature generator and reconstructs the feature embeddings of the unavailable visual instances from both the available feature embeddings and the masked tokens. Equipped with this generative architecture, MFGN produces nontrivial visual features for the novel classes with limited visual instances. In extensive experiments on four FSL benchmarks, MFGN performs competitively and outperforms the state-of-the-art competitors on most of the few-shot classification tasks. Keywords: Machine Learning: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Yunlong Yu and Dingyi Zhang and Zhong Ji},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/513},
  pages     = {3695-3701},
  title     = {Masked feature generation network for few-shot learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust weight perturbation for adversarial training.
<em>IJCAI</em>, 3688–3694. (<a
href="https://doi.org/10.24963/ijcai.2022/512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Overfitting widely exists in adversarial robust training of deep networks. An effective remedy is adversarial weight perturbation, which injects the worst-case weight perturbation during network training by maximizing the classification loss on adversarial examples. Adversarial weight perturbation helps reduce the robust generalization gap; however, it also undermines the robustness improvement. A criterion that regulates the weight perturbation is therefore crucial for adversarial training. In this paper, we propose such a criterion, namely Loss Stationary Condition (LSC) for constrained perturbation. With LSC, we find that it is essential to conduct weight perturbation on adversarial data with small classification loss to eliminate robust overfitting. Weight perturbation on adversarial data with large classification loss is not necessary and may even lead to poor robustness. Based on these observations, we propose a robust perturbation strategy to constrain the extent of weight perturbation. The perturbation strategy prevents deep networks from overfitting while avoiding the side effect of excessive weight perturbation, significantly improving the robustness of adversarial training. Extensive experiments demonstrate the superiority of the proposed method over the state-of-the-art adversarial training methods. Keywords: Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Chaojian Yu and Bo Han and Mingming Gong and Li Shen and Shiming Ge and Du Bo and Tongliang Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/512},
  pages     = {3688-3694},
  title     = {Robust weight perturbation for adversarial training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EGCN: An ensemble-based learning framework for exploring
effective skeleton-based rehabilitation exercise assessment.
<em>IJCAI</em>, 3681–3687. (<a
href="https://doi.org/10.24963/ijcai.2022/511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, some skeleton-based physical therapy systems have been attempted to automatically evaluate the correctness or quality of an exercise performed by rehabilitation subjects. However, in terms of algorithms and evaluation criteria, the task remains not fully explored regarding making full use of different skeleton features. To advance the prior work, we propose a learning framework called Ensemble-based Graph Convolutional Network (EGCN) for skeleton-based rehabilitation exercise assessment. As far as we know, this is the first attempt that utilizes both two skeleton feature groups and investigates different ensemble strategies for the task. We also examine the properness of existing evaluation criteria and focus on evaluating the prediction ability of our proposed method. We then conduct extensive cross-validation experiments on two latest public datasets: UI-PRMD and KIMORE. Results indicate that the model-level ensemble scheme of our EGCN achieves better performance than existing methods. Code is available: https://github.com/bruceyo/EGCN. Keywords: Machine Learning: Ensemble Methods Multidisciplinary Topics and Applications: Sports Computer Vision: Action and Behaviour Recognition},
  archive   = {C_IJCAI},
  author    = {Bruce X.B. Yu and Yan Liu and Xiang Zhang and Gong Chen and Keith C.C. Chan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/511},
  pages     = {3681-3687},
  title     = {EGCN: An ensemble-based learning framework for exploring effective skeleton-based rehabilitation exercise assessment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards safe reinforcement learning via constraining
conditional value-at-risk. <em>IJCAI</em>, 3673–3680. (<a
href="https://doi.org/10.24963/ijcai.2022/510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Though deep reinforcement learning (DRL) has obtained substantial success, it may encounter catastrophic failures due to the intrinsic uncertainty of both transition and observation. Most of the existing methods for safe reinforcement learning can only handle transition disturbance or observation disturbance since these two kinds of disturbance affect different parts of the agent; besides, the popular worst-case return may lead to overly pessimistic policies. To address these issues, we first theoretically prove that the performance degradation under transition disturbance and observation disturbance depends on a novel metric of Value Function Range (VFR), which corresponds to the gap in the value function between the best state and the worst state. Based on the analysis, we adopt conditional value-at-risk (CVaR) as an assessment of risk and propose a novel reinforcement learning algorithm of CVaR-Proximal-Policy-Optimization (CPPO) which formalizes the risk-sensitive constrained optimization problem by keeping its CVaR under a given threshold. Experimental results show that CPPO achieves a higher cumulative reward and is more robust against both observation and transition disturbances on a series of continuous control tasks in MuJoCo. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {ChengYang Ying and Xinning Zhou and Hang Su and Dong Yan and Ning Chen and Jun Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/510},
  pages     = {3673-3680},
  title     = {Towards safe reinforcement learning via constraining conditional value-at-risk},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online ECG emotion recognition for unknown subjects via
hypergraph-based transfer learning. <em>IJCAI</em>, 3666–3672. (<a
href="https://doi.org/10.24963/ijcai.2022/509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electrocardiogram (ECG) signal based cross-subject emotion recognition methods reduce the influence of individual differences using domain adaptation (DA) techniques. These methods generally assume that the entire unlabeled data of unknown target subjects are available in training phase. However, this assumption does not hold in some practical scenarios where the data of target subjects arrive one by one in an online manner instead of being acquired at a time. Thus, existing DA methods cannot be directly applied in this case since the unknown target data is inaccessible in training phase. To tackle the problem, we propose a novel online cross-subject ECG emotion recognition method leveraging hypergraph-based online transfer learning (HOTL). Specifically, the proposed hypergraph structure is capable of learning the high-order correlation among data, such that the recognition model trained on source subjects can be more effectively generalized to target subjects. Meanwhile, the structure can be easily updated by adding a hyperedge which connects a newly coming sample with the current hypergraph, resulting in further reduce the individual differences in online manner without re-training the model. Consequently, HOTL can effectively deal with the online cross-subject scenario where unknown target ECG data arrive one by one and varying overtime. Extensive experiments conducted on the Amigos dataset validate the superiority of the proposed method. Keywords: Machine Learning: Online Learning Humans and AI: Personalization and User Modeling Machine Learning: Feature Extraction, Selection and Dimensionality Reduction Machine Learning: Multi-task and Transfer Learning},
  archive   = {C_IJCAI},
  author    = {Yalan Ye and Tongjie Pan and Qianhe Meng and Jingjing Li and Li Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/509},
  pages     = {3666-3672},
  title     = {Online ECG emotion recognition for unknown subjects via hypergraph-based transfer learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards applicable reinforcement learning: Improving the
generalization and sample efficiency with policy ensemble.
<em>IJCAI</em>, 3659–3665. (<a
href="https://doi.org/10.24963/ijcai.2022/508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is challenging for reinforcement learning (RL) algorithms to succeed in real-world applications. Take financial trading as an example, the market information is noisy yet imperfect and the macroeconomic regulation or other factors may shift between training and evaluation, thus it requires both generalization and high sample efficiency for resolving the task. However, directly applying typical RL algorithms can lead to poor performance in such scenarios. To derive a robust and applicable RL algorithm, in this work, we design a simple but effective method named Ensemble Proximal Policy Optimization (EPPO), which learns ensemble policies in an end-to-end manner. Notably, EPPO combines each policy and the policy ensemble organically and optimizes both simultaneously. In addition, EPPO adopts a diversity enhancement regularization over the policy space which helps to generalize to unseen states and promotes exploration. We theoretically prove that EPPO can increase exploration efficacy, and through comprehensive experimental evaluations on various tasks, we demonstrate that EPPO achieves higher efficiency and is robust for real-world applications compared with vanilla policy optimization algorithms and other ensemble methods. Code and supplemental materials are available at https://seqml.github.io/eppo. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Ensemble Methods},
  archive   = {C_IJCAI},
  author    = {Zhengyu Yang and Kan Ren and Xufang Luo and Minghuan Liu and Weiqing Liu and Jiang Bian and Weinan Zhang and Dongsheng Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/508},
  pages     = {3659-3665},
  title     = {Towards applicable reinforcement learning: Improving the generalization and sample efficiency with policy ensemble},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the (in)tractability of reinforcement learning for LTL
objectives. <em>IJCAI</em>, 3650–3658. (<a
href="https://doi.org/10.24963/ijcai.2022/507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, researchers have made significant progress in devising reinforcement-learning algorithms for optimizing linear temporal logic (LTL) objectives and LTL-like objectives. Despite these advancements, there are fundamental limitations to how well this problem can be solved. Previous studies have alluded to this fact but have not examined it in depth. In this paper, we address the tractability of reinforcement learning for general LTL objectives from a theoretical perspective. We formalize the problem under the probably approximately correct learning in Markov decision processes (PAC-MDP) framework, a standard framework for measuring sample complexity in reinforcement learning. In this formalization, we prove that the optimal policy for any LTL formula is PAC-MDP-learnable if and only if the formula is in the most limited class in the LTL hierarchy, consisting of formulas that are decidable within a finite horizon. Practically, our result implies that it is impossible for a reinforcement-learning algorithm to obtain a PAC-MDP guarantee on the performance of its learned policy after finitely many interactions with an unconstrained environment for LTL objectives that are not decidable within a finite horizon. Keywords: Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Cambridge Yang and Michael L. Littman and Michael Carbin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/507},
  pages     = {3650-3658},
  title     = {On the (In)Tractability of reinforcement learning for LTL objectives},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Active contrastive set mining for robust audio-visual
instance discrimination. <em>IJCAI</em>, 3643–3649. (<a
href="https://doi.org/10.24963/ijcai.2022/506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The recent success of audio-visual representation learning can be largely attributed to their pervasive property of audio-visual synchronization, which can be used as self-annotated supervision. As a state-of-the-art solution, Audio-Visual Instance Discrimination (AVID) extends instance discrimination to the audio-visual realm. Existing AVID methods construct the contrastive set by random sampling based on the assumption that the audio and visual clips from all other videos are not semantically related. We argue that this assumption is rough, since the resulting contrastive sets have a large number of faulty negatives. In this paper, we overcome this limitation by proposing a novel Active Contrastive Set Mining (ACSM) that aims to mine the contrastive sets with informative and diverse negatives for robust AVID. Moreover, we also integrate a semantically-aware hard-sample mining strategy into our ACSM. The proposed ACSM is implemented into two most recent state-of-the-art AVID methods and significantly improves their performance. Extensive experiments conducted on both action and sound recognition on multiple datasets show the remarkably improved performance of our method. Keywords: Machine Learning: Multi-modal learning Machine Learning: Representation learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Hanyu Xuan and Yihong Xu and Shuo Chen and Zhiliang Wu and Jian Yang and Yan Yan and Xavier Alameda-Pineda},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/506},
  pages     = {3643-3649},
  title     = {Active contrastive set mining for robust audio-visual instance discrimination},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MemREIN: Rein the domain shift for cross-domain few-shot
learning. <em>IJCAI</em>, 3636–3642. (<a
href="https://doi.org/10.24963/ijcai.2022/505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot learning aims to enable models generalize to new categories (query instances) with only limited labeled samples (support instances) from each category. Metric-based mechanism is a promising direction which compares feature embeddings via different metrics. However, it always fail to generalize to unseen domains due to the considerable domain gap challenge. In this paper, we propose a novel framework, MemREIN, which considers Memorized, Restitution, and Instance Normalization for cross-domain few-shot learning. Specifically, an instance normalization algorithm is explored to alleviate feature dissimilarity, which provides the initial model generalization ability. However, naively normalizing the feature would lose fine-grained discriminative knowledge between different classes. To this end, a memorized module is further proposed to separate the most refined knowledge and remember it. Then, a restitution module is utilized to restitute the discrimination ability from the learned knowledge. A novel reverse contrastive learning strategy is proposed to stabilize the distillation process. Extensive experiments on five popular benchmark datasets demonstrate that MemREIN well addresses the domain shift challenge, and significantly improves the performance up to 16.43\% compared with state-of-the-art baselines. Keywords: Machine Learning: Few-shot learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Other Machine Learning: Multi-task and Transfer Learning},
  archive   = {C_IJCAI},
  author    = {Yi Xu and Lichen Wang and Yizhou Wang and Can Qin and Yulun Zhang and Yun Fu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/505},
  pages     = {3636-3642},
  title     = {MemREIN: Rein the domain shift for cross-domain few-shot learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MultiQuant: Training once for multi-bit quantization of
neural networks. <em>IJCAI</em>, 3629–3635. (<a
href="https://doi.org/10.24963/ijcai.2022/504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantization has become a popular technique to compress deep neural networks (DNNs) and reduce computational costs, but most prior work focuses on training DNNs at each individual fixed bit-width and accuracy trade-off point. How to produce a model with flexible precision is largely unexplored. This work proposes a multi-bit quantization framework (MultiQuant) to make the learned DNNs robust for different precision configuration during inference by adopting Lowest-Random-Highest bit-width co-training method. Meanwhile, we propose an online adaptive label generation strategy to alleviate the problem of vicious competition under different precision caused by one-hot labels in the supernet training. The trained supernet model can be flexibly set to different bit widths to support dynamic speed and accuracy trade-off. Furthermore, we adopt the Monte Carlo sampling-based genetic algorithm search strategy with quantization-aware accuracy predictor as evaluation criterion to incorporate the mixed precision technology in our framework. Experiment results on ImageNet datasets demonstrate MultiQuant method can attain the quantization results under different bit-widths comparable with quantization-aware training without retraining. Keywords: Machine Learning: Automated Machine Learning Machine Learning: Convolutional Networks Machine Learning: Robustness Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Ke Xu and Qiantai Feng and Xingyi Zhang and Dong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/504},
  pages     = {3629-3635},
  title     = {MultiQuant: Training once for multi-bit quantization of neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neuro-symbolic verification of deep neural networks.
<em>IJCAI</em>, 3622–3628. (<a
href="https://doi.org/10.24963/ijcai.2022/503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Formal verification has emerged as a powerful approach to ensure the safety and reliability of deep neural networks. However, current verification tools are limited to only a handful of properties that can be expressed as first-order constraints over the inputs and output of a network. While adversarial robustness and fairness fall under this category, many real-world properties (e.g., &quot;an autonomous vehicle has to stop in front of a stop sign&quot;) remain outside the scope of existing verification technology. To mitigate this severe practical restriction, we introduce a novel framework for verifying neural networks, named neuro-symbolic verification. The key idea is to use neural networks as part of the otherwise logical specification, enabling the verification of a wide variety of complex, real-world properties, including the one above. A defining feature of our framework is that it can be implemented on top of existing verification infrastructure for neural networks, making it easily accessible to researchers and practitioners. Keywords: Machine Learning: Neuro-Symbolic Methods Constraint Satisfaction and Optimization: Satisfiabilty Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Xuan Xie and Kristian Kersting and Daniel Neider},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/503},
  pages     = {3622-3628},
  title     = {Neuro-symbolic verification of deep neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ambiguity-induced contrastive learning for
instance-dependent partial label learning. <em>IJCAI</em>, 3615–3621.
(<a href="https://doi.org/10.24963/ijcai.2022/502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial label learning (PLL) learns from a typical weak supervision, where each training instance is labeled with a set of ambiguous candidate labels (CLs) instead of its exact ground-truth label. Most existing PLL works directly eliminate, rather than exploiting the label ambiguity, since they explicitly or implicitly assume that incorrect CLs are noise independent of the instance. While a more practical setting in the wild should be instance-dependent, namely, the CLs depend on both the true label and the instance itself, such that each CL may describe the instance from some sensory channel, thereby providing some noisy but really valid information about the instance. In this paper, we leverage such additional information acquired from the ambiguity and propose AmBiguity-induced contrastive LEarning (ABLE) under the framework of contrastive learning. Specifically, for each CL of an anchor, we select a group of samples currently predicted as that class as ambiguity-induced positives, based on which we synchronously learn a representor (RP) that minimizes the weighted sum of contrastive losses of all groups and a classifier (CS) that minimizes a classification loss. Although they are circularly dependent: RP requires the ambiguity-induced positives on-the-fly induced by CS, and CS needs the first half of RP as the representation extractor, ABLE still enables RP and CS to be trained simultaneously within a coherent framework. Experiments on benchmark datasets demonstrate its substantial improvements over state-of-the-art methods for learning from the instance-dependent partially labeled data. Keywords: Machine Learning: Weakly Supervised Learning Machine Learning: Classification Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Shi-Yu Xia and Jiaqi Lv and Ning Xu and Xin Geng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/502},
  pages     = {3615-3621},
  title     = {Ambiguity-induced contrastive learning for instance-dependent partial label learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial bi-regressor network for domain adaptive
regression. <em>IJCAI</em>, 3608–3614. (<a
href="https://doi.org/10.24963/ijcai.2022/501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain adaptation (DA) aims to transfer the knowledge of a well-labeled source domain to facilitate unlabeled target learning. When turning to specific tasks such as indoor (Wi-Fi) localization, it is essential to learn a cross-domain regressor to mitigate the domain shift. This paper proposes a novel method Adversarial Bi-Regressor Network (ABRNet) to seek more effective cross- domain regression model. Specifically, a discrepant bi-regressor architecture is developed to maximize the difference of bi-regressor to discover uncertain target instances far from the source distribution, and then an adversarial training mechanism is adopted between feature extractor and dual regressors to produce domain-invariant representations. To further bridge the large domain gap, a domain- specific augmentation module is designed to synthesize two source-similar and target-similar inter- mediate domains to gradually eliminate the original domain mismatch. The empirical studies on two cross-domain regressive benchmarks illustrate the power of our method on solving the domain adaptive regression (DAR) problem. Keywords: Machine Learning: Representation learning Machine Learning: Regression Machine Learning: Unsupervised Learning Robotics: Localization, Mapping, State Estimatino},
  archive   = {C_IJCAI},
  author    = {Haifeng Xia and Pu Wang and Toshiaki Koike-Akino and Ye Wang and Philip Orlik and Zhengming Ding},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/501},
  pages     = {3608-3614},
  title     = {Adversarial bi-regressor network for domain adaptive regression},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Information augmentation for few-shot node classification.
<em>IJCAI</em>, 3601–3607. (<a
href="https://doi.org/10.24963/ijcai.2022/500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although meta-learning and metric learning have been widely applied for few-shot node classification (FSNC), some limitations still need to be addressed, such as expensive time costs for the meta-train and difficult of exploring the complex structure inherent the graph data. To address in issues, this paper proposes a new data augmentation method to conduct FSNC on the graph data including parameter initialization and parameter fine-tuning. Specifically, parameter initialization only conducts a multi-classification task on the base classes, resulting in good generalization ability and less time cost. Parameter fine-tuning designs two data augmentation methods (i.e., support augmentation and shot augmentation) on the novel classes to generate sufficient node features so that any traditional supervised classifiers can be used to classify the query set. As a result, the proposed method is the first work of data augmentation for FSNC. Experiment results show the effectiveness and the efficiency of our proposed method, compared to state-of-the-art methods, in terms of different classification tasks. Keywords: Machine Learning: Few-shot learning Machine Learning: Classification Machine Learning: Convolutional Networks Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zongqian Wu and Peng Zhou and Guoqiu Wen and Yingying Wan and Junbo Ma and Debo Cheng and Xiaofeng Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/500},
  pages     = {3601-3607},
  title     = {Information augmentation for few-shot node classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatically gating multi-frequency patterns through
rectified continuous bernoulli units with theoretical principles.
<em>IJCAI</em>, 3594–3600. (<a
href="https://doi.org/10.24963/ijcai.2022/499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Different nonlinearities are only suitable for responding to different frequency signals. The locally-responding ReLU is incapable of modeling high-frequency features due to the spectral bias, whereas the globally-responding sinusoidal function is intractable to represent low-frequency concepts cheaply owing to the optimization dilemma. Moreover, nearly all the practical tasks are composed of complex multi-frequency patterns, whereas there is little prospect of designing or searching a heterogeneous network containing various types of neurons matching the frequencies, because of their exponentially-increasing combinatorial states. In this paper, our contributions are three-fold: 1) we propose a general Rectified Continuous Bernoulli (ReCB) unit paired with an efficient variational Bayesian learning paradigm, to automatically detect/gate/represent different frequency responses; 2) our numerically-tight theoretical framework proves that ReCB-based networks can achieve the optimal representation ability, which is O(m^{η/(d^2)}) times better than that of popular neural networks, for a hidden dimension of m, an input dimension of d, and a Lipschitz constant of η; 3) we provide comprehensive empirical evidence showing that ReCB-based networks can keenly learn multi-frequency patterns and push the state-of-the-art performance. Keywords: Machine Learning: Kernel Methods Machine Learning: Optimisation Machine Learning: Automated Machine Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Zheng-Fan Wu and Yi-Nan Feng and Hui Xue},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/499},
  pages     = {3594-3600},
  title     = {Automatically gating multi-frequency patterns through rectified continuous bernoulli units with theoretical principles},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stabilizing and enhancing link prediction through deepened
graph auto-encoders. <em>IJCAI</em>, 3587–3593. (<a
href="https://doi.org/10.24963/ijcai.2022/498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks have been widely used for a variety of learning tasks. Link prediction is a relatively under-studied graph learning task, with current state-of-the-art models based on one- or two-layer shallow graph auto-encoder (GAE) architectures. In this paper, we overcome the limitation of current methods for link prediction of non-Euclidean network data, which can only use shallow GAEs and variational GAEs. Our proposed methods innovatively incorporate standard auto-encoders (AEs) into the architectures of GAEs to capitalize on the intimate coupling of node and edge information in complex network data. Empirically, extensive experiments on various datasets demonstrate the competitive performance of our proposed approach. Theoretically, we prove that our deep extensions can inclusively express multiple polynomial filters with different orders. The codes of this paper are available at https://github.com/xinxingwu-uk/DGAE. Keywords: Machine Learning: Relational Learning Data Mining: Networks Machine Learning: Learning Graphical Models Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Xinxing wu and Qiang Cheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/498},
  pages     = {3587-3593},
  title     = {Stabilizing and enhancing link prediction through deepened graph auto-encoders},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A simple yet effective method for graph classification.
<em>IJCAI</em>, 3580–3586. (<a
href="https://doi.org/10.24963/ijcai.2022/497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In deep neural networks, better results can often be obtained by increasing the complexity of previously developed basic models. However, it is unclear whether there is a way to boost performance by decreasing the complexity of such models. Intuitively, given a problem, a simpler data structure comes with a simpler algorithm. Here, we investigate the feasibility of improving graph classification performance while simplifying the learning process. Inspired by structural entropy on graphs, we transform the data sample from graphs to coding trees, which is a simpler but essential structure for graph data. Furthermore, we propose a novel message passing scheme, termed hierarchical reporting, in which features are transferred from leaf nodes to root nodes by following the hierarchical structure of coding trees. We then present a tree kernel and a convolutional network to implement our scheme for graph classification. With the designed message passing scheme, the tree kernel and convolutional network have a lower runtime complexity of O(n) than Weisfeiler-Lehman subtree kernel and other graph neural networks of at least O(hm). We empirically validate our methods with several graph classification benchmarks and demonstrate that they achieve better performance and lower computational consumption than competing approaches. Keywords: Machine Learning: Sequence and Graph Learning Machine Learning: Classification Machine Learning: Optimisation Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Junran Wu and Shangzhe Li and Jianhao Li and Yicheng Pan and Ke Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/497},
  pages     = {3580-3586},
  title     = {A simple yet effective method for graph classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified meta-learning framework for dynamic transfer
learning. <em>IJCAI</em>, 3573–3579. (<a
href="https://doi.org/10.24963/ijcai.2022/496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transfer learning refers to the transfer of knowledge or information from a relevant source task to a target task. However, most existing works assume both tasks are sampled from a stationary task distribution, thereby leading to the sub-optimal performance for dynamic tasks drawn from a non-stationary task distribution in real scenarios. To bridge this gap, in this paper, we study a more realistic and challenging transfer learning setting with dynamic tasks, i.e., source and target tasks are continuously evolving over time. We theoretically show that the expected error on the dynamic target task can be tightly bounded in terms of source knowledge and consecutive distribution discrepancy across tasks. This result motivates us to propose a generic meta-learning framework L2E for modeling the knowledge transferability on dynamic tasks. It is centered around a task-guided meta-learning problem with a group of meta-pairs of tasks, based on which we are able to learn the prior model initialization for fast adaptation on the newest target task. L2E enjoys the following properties: (1) effective knowledge transferability across dynamic tasks; (2) fast adaptation to the new target task; (3) mitigation of catastrophic forgetting on historical target tasks; and (4) flexibility in incorporating any existing static transfer learning algorithms. Extensive experiments on various image data sets demonstrate the effectiveness of the proposed L2E framework. Keywords: Machine Learning: Multi-task and Transfer Learning Machine Learning: Meta-Learning},
  archive   = {C_IJCAI},
  author    = {Jun Wu and Jingrui He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/496},
  pages     = {3573-3579},
  title     = {A unified meta-learning framework for dynamic transfer learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). EMGC²F: Efficient multi-view graph clustering with
comprehensive fusion. <em>IJCAI</em>, 3566–3572. (<a
href="https://doi.org/10.24963/ijcai.2022/495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes an Efficient Multi-view Graph Clustering with Comprehensive Fusion (EMGC²F) model and a corresponding efficient optimization algorithm to address multi-view graph clustering tasks effectively and efficiently. Compared to existing works, our proposals have the following highlights: 1) EMGC²F directly finds a consistent cluster indicator matrix with a Super Nodes Similarity Minimization module from multiple views, which avoids time-consuming spectral decomposition in previous works. 2) EMGC²F comprehensively mines information from multiple views. More formally, it captures the consistency of multiple views via a Cross-view Nearest Neighbors Voting (CN²V) mechanism, meanwhile capturing the importance of multiple views via an adaptive weighted-learning mechanism. 3) EMGC²F is a parameter-free model and the time complexity of the proposed algorithm is far less than existing works, demonstrating the practicability. Empirical results on several benchmark datasets demonstrate that our proposals outperform SOTA competitors both in effectiveness and efficiency. Keywords: Machine Learning: Clustering Machine Learning: Multi-view learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Danyang Wu and Jitao Lu and Feiping Nie and Rong Wang and Yuan Yuan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/495},
  pages     = {3566-3572},
  title     = {EMGC²F: Efficient multi-view graph clustering with comprehensive fusion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Value refinement network (VRN). <em>IJCAI</em>, 3558–3565.
(<a href="https://doi.org/10.24963/ijcai.2022/494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In robotic tasks, we encounter the unique strengths of (1) reinforcement learning (RL) that can handle high-dimensional observations as well as unknown, complex dynamics and (2) planning that can handle sparse and delayed rewards given a dynamics model. Combining these strengths of RL and planning, we propose the Value Refinement Network (VRN), in this work. Our VRN is an RL-trained neural network architecture that learns to locally refine an initial (value-based) plan in a simplified (2D) problem abstraction based on detailed local sensory observations. We evaluate the VRN on simulated robotic (navigation) tasks and demonstrate that it can successfully refine sub-optimal plans to match the performance of more costly planning in the non-simplified problem. Furthermore, in a dynamic environment, the VRN still enables high task completion without global re-planning. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Planning and Scheduling: Learning in Planning and Scheduling},
  archive   = {C_IJCAI},
  author    = {Jan Wöhlke and Felix Schmitt and Herke van Hoof},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/494},
  pages     = {3558-3565},
  title     = {Value refinement network (VRN)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-paced supervision for multi-source domain adaptation.
<em>IJCAI</em>, 3551–3557. (<a
href="https://doi.org/10.24963/ijcai.2022/493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-source domain adaptation has attracted great attention in machine learning community. Most of these methods focus on weighting the predictions produced by the adaptation networks of different domains. Thus the domain shifts between certain of domains and target domain are not effectively relieved, resulting in that these domains are not fully exploited and even may have a negative influence on multi-source domain adaptation task. To address such challenge, we propose a multi-source domain adaptation method to gradually improve the adaptation ability of each source domain by producing more high-confident pseudo-labels with self-paced learning for conditional distribution alignment. The proposed method first trains several separate domain branch networks with single domains and an ensemble branch network with all domains. Then we obtain some high-confident pseudo-labels with the branch networks and learn the branch specific pseudo-labels with self-paced learning. Each branch network reduces the domain gap by aligning the conditional distribution with its branch specific pseudo-labels and the pseudo-labels provided by all branch networks. Experiments on Office31, Office-Home and DomainNet show that the proposed method outperforms the state-of-the-art methods. Keywords: Machine Learning: Multi-task and Transfer Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision},
  archive   = {C_IJCAI},
  author    = {Zengmao Wang and Chaoyang Zhou and Bo Du and Fengxiang He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/493},
  pages     = {3551-3557},
  title     = {Self-paced supervision for multi-source domain adaptation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Estimation and comparison of linear regions for ReLU
networks. <em>IJCAI</em>, 3544–3550. (<a
href="https://doi.org/10.24963/ijcai.2022/492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the relationship between the arrangement of neurons and the complexity of the ReLU-activated neural networks measured by the number of linear regions. More specifically, we provide both theoretical and empirical evidence for the point of view that shallow networks tend to have higher complexity than deep ones when the total number of neurons is fixed. In the theoretical part, we prove that this is the case for networks whose neurons in the hidden layers are arranged in the forms of 1x2n, 2xn and nx2; in the empirical part, we implement an algorithm that precisely tracks (hence counts) all the linear regions, and run it on networks with various structures. Although the time complexity of the algorithm is quite high, we verify that the problem of calculating the number of linear regions of a ReLU network is itself NP-hard. So currently there is no surprisingly efficient way to solve it. Roughly speaking, in the algorithm we divide the linear regions into subregions called the &quot;activation regions&quot;, which are convex and easy to propagate through the network. The relationship between the number of the linear regions and that of the activation regions is also discussed. Keywords: Machine Learning: Learning Theory Machine Learning: Optimisation Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Yuan Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/492},
  pages     = {3544-3550},
  title     = {Estimation and comparison of linear regions for ReLU networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-player multi-armed bandits with finite shareable
resources arms: Learning algorithms &amp; applications. <em>IJCAI</em>,
3537–3543. (<a href="https://doi.org/10.24963/ijcai.2022/491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-player multi-armed bandits (MMAB) study how decentralized players cooperatively play the same multi-armed bandit so as to maximize their total cumulative rewards. Existing MMAB models mostly assume when more than one player pulls the same arm, they either have a collision and obtain zero rewards or have no collision and gain independent rewards, both of which are usually too restrictive in practical scenarios. In this paper, we propose an MMAB with shareable resources as an extension of the collision and non-collision settings. Each shareable arm has finite shareable resources and a “per-load” reward random variable, both of which are unknown to players. The reward from a shareable arm is equal to the “per-load” reward multiplied by the minimum between the number of players pulling the arm and the arm’s maximal shareable resources. We consider two types of feedback: sharing demand information (SDI) and sharing demand awareness (SDA), each of which provides different signals of resource sharing. We design the DPE-SDI and SIC-SDA algorithms to address the shareable arm problem under these two cases of feedback respectively and prove that both algorithms have logarithmic regrets that are tight in the number of rounds. We conduct simulations to validate both algorithms’ performance and show their utilities in wireless networking and edge computing. Keywords: Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Xuchuang Wang and Hong Xie and John C. S. Lui},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/491},
  pages     = {3537-3543},
  title     = {Multi-player multi-armed bandits with finite shareable resources arms: Learning algorithms &amp;amp; applications},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling spatio-temporal neighbourhood for personalized
point-of-interest recommendation. <em>IJCAI</em>, 3530–3536. (<a
href="https://doi.org/10.24963/ijcai.2022/490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point-of-interest (POI) recommendations can help users explore attractive locations, which is playing an important role in location-based social networks (LBSNs). In POI recommendations, the results are largely impacted by users&#39; preferences. However, the existing POI methods model user and location almost separately, which cannot capture users&#39; personal and dynamic preferences to location. In addition, they also ignore users&#39; acceptance to distance/time of location. To overcome the limitations of the existing methods, we first introduce Knowledge Graph with temporal information (known as TKG) into POI recommendation, including both user and location with timestamps. Then, based on TKG, we propose a Spatial-Temporal Graph Convolutional Attention Network (STGCAN), a novel network that learns users&#39; preferences on TKG by dynamically capturing the spatial-temporal neighbourhoods. Specifically, in STGCAN, we construct receptive fields on TKG to aggregate neighbourhoods of user and location respectively at each timestamp. And we measure the spatial-temporal interval as users&#39; acceptance to distance/time with self-attention. Experiments on three real-world datasets demonstrate that the proposed model outperforms the state-of-the-art POI recommendation approaches. Keywords: Machine Learning: Recommender Systems Data Mining: Knowledge Graphs and Knowledge Base Completion},
  archive   = {C_IJCAI},
  author    = {Xiaolin Wang and Guohao Sun and Xiu Fang and Jian Yang and Shoujin Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/490},
  pages     = {3530-3536},
  title     = {Modeling spatio-temporal neighbourhood for personalized point-of-interest recommendation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IMO^3: Interactive multi-objective off-policy optimization.
<em>IJCAI</em>, 3523–3529. (<a
href="https://doi.org/10.24963/ijcai.2022/489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most real-world optimization problems have multiple objectives. A system designer needs to find a policy that trades off these objectives to reach a desired operating point. This problem has been studied extensively in the setting of known objective functions. However, we consider a more practical but challenging setting of unknown objective functions. In industry, optimization under this setting is mostly approached with online A/B testing, which is often costly and inefficient. As an alternative, we propose Interactive Multi-Objective Off-policy Optimization (IMO^3). The key idea of IMO^3 is to interact with a system designer using policies evaluated in an off-policy fashion to uncover which policy maximizes her unknown utility function. We theoretically show that IMO^3 identifies a near-optimal policy with high probability, depending on the amount of designer&#39;s feedback and training data for off-policy estimation. We demonstrate its effectiveness empirically on several multi-objective optimization problems. Keywords: Machine Learning: Experimental Methodology Machine Learning: Optimisation Uncertainty in AI: Decision and Utility Theory Knowledge Representation and Reasoning: Preference Modelling and Preference-Based Reasoning Humans and AI: Human-AI Collaboration},
  archive   = {C_IJCAI},
  author    = {Nan Wang and Hongning Wang and Maryam Karimzadehgan and Branislav Kveton and Craig Boutilier},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/489},
  pages     = {3523-3529},
  title     = {IMO^3: Interactive multi-objective off-policy optimization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-task personalized learning with sparse network lasso.
<em>IJCAI</em>, 3516–3522. (<a
href="https://doi.org/10.24963/ijcai.2022/488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-task learning learns multiple related tasks together, in order to improve the generalization performance. Existing methods typically build a global model shared by all the samples, which saves the homogeneity but ignores the individuality (heterogeneity) of samples. Personalized learning is recently proposed to learn sample-specific local models by utilizing sample heterogeneity, however, directly applying it in the multi-task learning setting poses three key challenges: 1) model sample homogeneity, 2) prevent from over-parameterization and 3) capture task correlations. In this paper, we propose a novel multi-task personalized learning method to handle these challenges. For 1), each model is decomposed into a sum of global and local components, that saves sample homogeneity and sample heterogeneity, respectively. For 2), regularized by sparse network Lasso, the joint models are embedded into a low-dimensional subspace and exhibit sparse group structures, leading to a significantly reduced number of effective parameters. For 3), the subspace is further separated into two parts, so as to save both commonality and specificity of tasks. We develop an alternating algorithm to solve the proposed optimization problem, and extensive experiments on various synthetic and real-world datasets demonstrate its robustness and effectiveness. Keywords: Machine Learning: Multi-task and Transfer Learning Humans and AI: Personalization and User Modeling Machine Learning: Learning Sparse Models Machine Learning: Regression},
  archive   = {C_IJCAI},
  author    = {Jiankun Wang and Lu Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/488},
  pages     = {3516-3522},
  title     = {Multi-task personalized learning with sparse network lasso},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised misaligned infrared and visible image fusion
via cross-modality image generation and registration. <em>IJCAI</em>,
3508–3515. (<a href="https://doi.org/10.24963/ijcai.2022/487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent learning-based image fusion methods have marked numerous progress in pre-registered multi-modality data, but suffered serious ghosts dealing with misaligned multi-modality data, due to the spatial deformation and the difficulty narrowing cross-modality discrepancy. To overcome the obstacles, in this paper, we present a robust cross-modality generation-registration paradigm for unsupervised misaligned infrared and visible image fusion (IVIF). Specifically, we propose a Cross-modality Perceptual Style Transfer Network (CPSTN) to generate a pseudo infrared image taking a visible image as input. Benefiting from the favorable geometry preservation ability of the CPSTN, the generated pseudo infrared image embraces a sharp structure, which is more conducive to transforming cross-modality image alignment into mono-modality registration coupled with the structure-sensitive of the infrared image. In this case, we introduce a Multi-level Refinement Registration Network (MRRN) to predict the displacement vector field between distorted and pseudo infrared images and reconstruct registered infrared image under the mono-modality setting. Moreover, to better fuse the registered infrared images and visible images, we present a feature Interaction Fusion Module (IFM) to adaptively select more meaningful features for fusion in the Dual-path Interaction Fusion Network (DIFN). Extensive experimental results suggest that the proposed method performs superior capability on misaligned cross-modality image fusion. Keywords: Machine Learning: Multi-modal learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Di Wang and Jinyuan Liu and Xin Fan and Risheng Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/487},
  pages     = {3508-3515},
  title     = {Unsupervised misaligned infrared and visible image fusion via cross-modality image generation and registration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bounded memory adversarial bandits with composite anonymous
delayed feedback. <em>IJCAI</em>, 3501–3507. (<a
href="https://doi.org/10.24963/ijcai.2022/486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the adversarial bandit problem with composite anonymous delayed feedback. In this setting, losses of an action are split into d components, spreading over consecutive rounds after the action is chosen. And in each round, the algorithm observes the aggregation of losses that come from the latest d rounds. Previous works focus on oblivious adversarial setting, while we investigate the harder nonoblivious setting. We show nonoblivious setting incurs Omega(T) pseudo regret even when the loss sequence is bounded memory. However, we propose a wrapper algorithm which enjoys o(T) policy regret on many adversarial bandit problems with the assumption that the loss sequence is bounded memory. Especially, for K armed bandit and bandit convex optimization, our policy regret bound is in the order of T to the two third. We also prove a matching lower bound for K armed bandit. Our lower bound works even when the loss sequence is oblivious but the delay is nonoblivious. It answers the open problem proposed in [Wang, Wang, Huang 2021], showing that nonoblivious delay is enough to incur the regret in the order of T to the two third. Keywords: Machine Learning: Online Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Zongqi Wan and Xiaoming Sun and Jialin Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/486},
  pages     = {3501-3507},
  title     = {Bounded memory adversarial bandits with composite anonymous delayed feedback},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Initializing then refining: A simple graph attribute
imputation network. <em>IJCAI</em>, 3494–3500. (<a
href="https://doi.org/10.24963/ijcai.2022/485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Representation learning on the attribute-missing graphs, whose connection information is complete while the attribute information of some nodes is missing, is an important yet challenging task. To impute the missing attributes, existing methods isolate the learning processes of attribute and structure information embeddings, and force both resultant representations to align with a common in-discriminative normal distribution, leading to inaccurate imputation. To tackle these issues, we propose a novel graph-oriented imputation framework called initializing then refining (ITR), where we first employ the structure information for initial imputation, and then leverage observed attribute and structure information to adaptively refine the imputed latent variables. Specifically, we first adopt the structure embeddings of attribute-missing samples as the embedding initialization, and then refine these initial values by aggregating the reliable and informative embeddings of attribute-observed samples according to the affinity structure. Specially, in our refining process, the affinity structure is adaptively updated through iterations by calculating the sample-wise correlations upon the recomposed embeddings. Extensive experiments on four benchmark datasets verify the superiority of ITR against state-of-the-art methods. Keywords: Machine Learning: Representation learning Machine Learning: Self-supervised Learning Machine Learning: Autoencoders Machine Learning: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Wenxuan Tu and Sihang Zhou and Xinwang Liu and Yue Liu and Zhiping Cai and En Zhu and Changwang Zhang and Jieren Cheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/485},
  pages     = {3494-3500},
  title     = {Initializing then refining: A simple graph attribute imputation network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate exploitability: Learning a best response.
<em>IJCAI</em>, 3487–3493. (<a
href="https://doi.org/10.24963/ijcai.2022/484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Researchers have shown that neural networks are vulnerable to adversarial examples and subtle environment changes. The resulting errors can look like blunders to humans, eroding trust in these agents. In prior games research, agent evaluation often focused on the in-practice game outcomes. Such evaluation typically fails to evaluate robustness to worst-case outcomes. Computer poker research has examined how to assess such worst-case performance. Unfortunately, exact computation is infeasible with larger domains, and existing approximations are poker-specific. We introduce ISMCTS-BR, a scalable search-based deep reinforcement learning algorithm for learning a best response to an agent, approximating worst-case performance. We demonstrate the technique in several games against a variety of agents, including several AlphaZero-based agents. Supplementary material is available at https://arxiv.org/abs/2004.09677. Keywords: Machine Learning: Reinforcement Learning Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Finbarr Timbers and Nolan Bard and Edward Lockhart and Marc Lanctot and Martin Schmid and Neil Burch and Julian Schrittwieser and Thomas Hubert and Michael Bowling},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/484},
  pages     = {3487-3493},
  title     = {Approximate exploitability: Learning a best response},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Stochastic coherence over attention trajectory for
continuous learning in video streams. <em>IJCAI</em>, 3480–3486. (<a
href="https://doi.org/10.24963/ijcai.2022/483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Devising intelligent agents able to live in an environment and learn by observing the surroundings is a longstanding goal of Artificial Intelligence. From a bare Machine Learning perspective, challenges arise when the agent is prevented from leveraging large fully-annotated dataset, but rather the interactions with supervisory signals are sparsely distributed over space and time. This paper proposes a novel neural-network-based approach to progressively and autonomously develop pixel-wise representations in a video stream. The proposed method is based on a human-like attention mechanism that allows the agent to learn by observing what is moving in the attended locations. Spatio-temporal stochastic coherence along the attention trajectory, paired with a contrastive term, leads to an unsupervised learning criterion that naturally copes with the considered setting. Differently from most existing works, the learned representations are used in open-set class-incremental classification of each frame pixel, relying on few supervisions. Our experiments leverage 3D virtual environments and they show that the proposed agents can learn to distinguish objects just by observing the video stream. Inheriting features from state-of-the art models is not as powerful as one might expect. Keywords: Machine Learning: Online Learning Computer Vision: Machine Learning for Vision Machine Learning: Unsupervised Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Matteo Tiezzi and Simone Marullo and Lapo Faggi and Enrico Meloni and Alessandro Betti and Stefano Melacci},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/483},
  pages     = {3480-3486},
  title     = {Stochastic coherence over attention trajectory for continuous learning in video streams},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Recipe2Vec: Multi-modal recipe representation learning with
graph neural networks. <em>IJCAI</em>, 3473–3479. (<a
href="https://doi.org/10.24963/ijcai.2022/482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning effective recipe representations is essential in food studies. Unlike what has been developed for image-based recipe retrieval or learning structural text embeddings, the combined effect of multi-modal information (i.e., recipe images, text, and relation data) receives less attention. In this paper, we formalize the problem of multi-modal recipe representation learning to integrate the visual, textual, and relational information into recipe embeddings. In particular, we first present Large-RG, a new recipe graph data with over half a million nodes, making it the largest recipe graph to date. We then propose Recipe2Vec, a novel graph neural network based recipe embedding model to capture multi-modal information. Additionally, we introduce an adversarial attack strategy to ensure stable learning and improve performance. Finally, we design a joint objective function of node classification and adversarial learning to optimize the model. Extensive experiments demonstrate that Recipe2Vec outperforms state-of-the-art baselines on two classic food study tasks, i.e., cuisine category classification and region prediction. Dataset and codes are available at https://github.com/meettyj/Recipe2Vec. Keywords: Machine Learning: Multi-modal learning Machine Learning: Representation learning Data Mining: Mining Graphs Data Mining: Mining Heterogenous Data},
  archive   = {C_IJCAI},
  author    = {Yijun Tian and Chuxu Zhang and Zhichun Guo and Yihong Ma and Ronald Metoyer and Nitesh V. Chawla},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/482},
  pages     = {3473-3479},
  title     = {Recipe2Vec: Multi-modal recipe representation learning with graph neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RecipeRec: A heterogeneous graph learning model for recipe
recommendation. <em>IJCAI</em>, 3466–3472. (<a
href="https://doi.org/10.24963/ijcai.2022/481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recipe recommendation systems play an essential role in helping people decide what to eat. Existing recipe recommendation systems typically focused on content-based or collaborative filtering approaches, ignoring the higher-order collaborative signal such as relational structure information among users, recipes and food items. In this paper, we formalize the problem of recipe recommendation with graphs to incorporate the collaborative signal into recipe recommendation through graph modeling. In particular, we first present URI-Graph, a new and large-scale user-recipe-ingredient graph. We then propose RecipeRec, a novel heterogeneous graph learning model for recipe recommendation. The proposed model can capture recipe content and collaborative signal through a heterogeneous graph neural network with hierarchical attention and an ingredient set transformer. We also introduce a graph contrastive augmentation strategy to extract informative graph knowledge in a self-supervised manner. Finally, we design a joint objective function of recommendation and contrastive learning to optimize the model. Extensive experiments demonstrate that RecipeRec outperforms state-of-the-art methods for recipe recommendation. Dataset and codes are available at https://github.com/meettyj/RecipeRec. Keywords: Machine Learning: Recommender Systems Data Mining: Mining Graphs Data Mining: Mining Heterogenous Data Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Yijun Tian and Chuxu Zhang and Zhichun Guo and Chao Huang and Ronald Metoyer and Nitesh V. Chawla},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/481},
  pages     = {3466-3472},
  title     = {RecipeRec: A heterogeneous graph learning model for recipe recommendation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MMT: Multi-way multi-modal transformer for multimodal
learning. <em>IJCAI</em>, 3458–3465. (<a
href="https://doi.org/10.24963/ijcai.2022/480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The heart of multimodal learning research lies the challenge of effectively exploiting fusion representations among multiple modalities.However, existing two-way cross-modality unidirectional attention could only exploit the intermodal interactions from one source to one target modality. This indeed fails to unleash the complete expressive power of multimodal fusion with restricted number of modalities and fixed interactive direction.In this work, the multiway multimodal transformer (MMT) is proposed to simultaneously explore multiway multimodal intercorrelations for each modality via single block rather than multiple stacked cross-modality blocks. The core idea of MMT is the multiway multimodal attention, where the multiple modalities are leveraged to compute the multiway attention tensor. This naturally benefits us to exploit comprehensive many-to-many multimodal interactive paths. Specifically, the multiway tensor is comprised of multiple interconnected modality-aware core tensors that consist of the intramodal interactions. Additionally, the tensor contraction operation is utilized to investigate intermodal dependencies between distinct core tensors.Essentially, our tensor-based multiway structure allows for easily extending MMT to the case associated with an arbitrary number of modalities. Taking MMT as the basis, the hierarchical network is further established to recursively transmit the low-level multiway multimodal interactions to high-level ones. The experiments demonstrate that MMT can achieve state-of-the-art or comparable performance. Keywords: Machine Learning: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Jiajia Tang and Kang Li and Ming Hou and Xuanyu Jin and Wanzeng Kong and Yu Ding and Qibin Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/480},
  pages     = {3458-3465},
  title     = {MMT: Multi-way multi-modal transformer for multimodal learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Memory augmented state space model for time series
forecasting. <em>IJCAI</em>, 3451–3457. (<a
href="https://doi.org/10.24963/ijcai.2022/479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {State space model (SSM) provides a general and flexible forecasting framework for time series. Conventional SSM with fixed-order Markovian assumption often falls short in handling the long-range temporal dependencies and/or highly non-linear correlation in time-series data, which is crucial for accurate forecasting. To this extend, we present External Memory Augmented State Space Model (EMSSM) within the sequential Monte Carlo (SMC) framework. Unlike the common fixed-order Markovian SSM, our model features an external memory system, in which we store informative latent state experience, whereby to create ``memoryful&quot; latent dynamics modeling complex long-term dependencies. Moreover, conditional normalizing flows are incorporated in our emission model, enabling the adaptation to a broad class of underlying data distributions. We further propose a Monte Carlo Objective that employs an efficient variational proposal distribution, which fuses the filtering and the dynamic prior information, to approximate the posterior state with proper particles. Our results demonstrate the competitiveness of forecasting performance of our proposed model comparing with other state-of-the-art SSMs. Keywords: Machine Learning: Time-series; Data Streams Machine Learning: Bayesian Learning Machine Learning: Probabilistic Machine Learning Uncertainty in AI: Inference},
  archive   = {C_IJCAI},
  author    = {Yinbo Sun and Lintao Ma and Yu Liu and Shijun Wang and James Zhang and YangFei Zheng and Hu Yun and Lei Lei and Yulin Kang and Llinbao Ye},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/479},
  pages     = {3451-3457},
  title     = {Memory augmented state space model for time series forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CCLF: A contrastive-curiosity-driven learning framework for
sample-efficient reinforcement learning. <em>IJCAI</em>, 3444–3450. (<a
href="https://doi.org/10.24963/ijcai.2022/478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In reinforcement learning (RL), it is challenging to learn directly from high-dimensional observations, where data augmentation has recently remedied it via encoding invariances from raw pixels. Nevertheless, we empirically find that not all samples are equally important and hence simply injecting more augmented inputs may instead cause instability in Q-learning. In this paper, we approach this problem systematically by developing a model-agnostic Contrastive-Curiosity-driven Learning Framework (CCLF), which can fully exploit sample importance and improve learning efficiency in a self-supervised manner. Facilitated by the proposed contrastive curiosity, CCLF is capable of prioritizing the experience replay, selecting the most informative augmented inputs, and more importantly regularizing the Q-function as well as the encoder to concentrate more on under-learned data. Moreover, it encourages the agent to explore with a curiosity-based reward. As a result, the agent can focus on more informative samples and learn representation invariances more efficiently, with significantly reduced augmented inputs. We apply CCLF to several base RL algorithms and evaluate on the DeepMind Control Suite, Atari, and MiniGrid benchmarks, where our approach demonstrates superior sample efficiency and learning performances compared with other state-of-the-art methods. Our code is available at https://github.com/csun001/CCLF. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning Machine Learning: Representation learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chenyu Sun and Hangwei Qian and Chunyan Miao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/478},
  pages     = {3444-3450},
  title     = {CCLF: A contrastive-curiosity-driven learning framework for sample-efficient reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic sparse training for deep reinforcement learning.
<em>IJCAI</em>, 3437–3443. (<a
href="https://doi.org/10.24963/ijcai.2022/477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep reinforcement learning (DRL) agents are trained through trial-and-error interactions with the environment. This leads to a long training time for dense neural networks to achieve good performance. Hence, prohibitive computation and memory resources are consumed. Recently, learning efficient DRL agents has received increasing attention. Yet, current methods focus on accelerating inference time. In this paper, we introduce for the first time a dynamic sparse training approach for deep reinforcement learning to accelerate the training process. The proposed approach trains a sparse neural network from scratch and dynamically adapts its topology to the changing data distribution during training. Experiments on continuous control tasks show that our dynamic sparse agents achieve higher performance than the equivalent dense methods, reduce the parameter count and floating-point operations (FLOPs) by 50\%, and have a faster learning speed that enables reaching the performance of dense agents with 40−50\% reduction in the training steps. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Learning Sparse Models Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Ghada Sokar and Elena Mocanu and Decebal Constantin Mocanu and Mykola Pechenizkiy and Peter Stone},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/477},
  pages     = {3437-3443},
  title     = {Dynamic sparse training for deep reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lexicographic multi-objective reinforcement learning.
<em>IJCAI</em>, 3430–3436. (<a
href="https://doi.org/10.24963/ijcai.2022/476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we introduce reinforcement learning techniques for solving lexicographic multi-objective problems. These are problems that involve multiple reward signals, and where the goal is to learn a policy that maximises the first reward signal, and subject to this constraint also maximises the second reward signal, and so on. We present a family of both action-value and policy gradient algorithms that can be used to solve such problems, and prove that they converge to policies that are lexicographically optimal. We evaluate the scalability and performance of these algorithms empirically, and demonstrate their applicability in practical settings. As a more specific application, we show how our algorithms can be used to impose safety constraints on the behaviour of an agent, and compare their performance in this context with that of other constrained reinforcement learning algorithms. Keywords: Machine Learning: Reinforcement Learning AI Ethics, Trust, Fairness: Safety &amp; Robustness Constraint Satisfaction and Optimization: Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Joar Skalse and Lewis Hammond and Charlie Griffin and Alessandro Abate},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/476},
  pages     = {3430-3436},
  title     = {Lexicographic multi-objective reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated multi-task attention for cross-individual human
activity recognition. <em>IJCAI</em>, 3423–3429. (<a
href="https://doi.org/10.24963/ijcai.2022/475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated Learning (FL) is an emerging privacy-aware machine learning technique that applies successfully to the collaborative learning of global models for Human Activity Recognition (HAR). As of now, the applications of FL for HAR assume that the data associated with diverse individuals follow the same distribution. However, this assumption is impractical in real-world scenarios where the same activity is frequently performed differently by different individuals. To tackle this issue, we propose FedMAT, a Federated Multi-task ATtention framework for HAR, which extracts and fuses shared as well as individual-specific multi-modal sensor data features. Specifically, we treat the HAR problem associated with each individual as a different task and train a federated multi-task model, composed of a shared feature representation network in a central server plus multiple individual-specific networks with attention modules stored in decentralized nodes. In this architecture, the attention module operates as a mask that allows to learn individual-specific features from the global model, whilst simultaneously allowing for features to be shared among different individuals. We conduct extensive experiments based on publicly available HAR datasets, which are collected in both controlled environments and real-world scenarios. Numeric results verify that our proposed FedMAT significantly outperforms baselines not only in generalizing to existing individuals but also in adapting to new individuals. Keywords: Machine Learning: Multi-task and Transfer Learning Humans and AI: Computational Sustainability and Human Well-Being Knowledge Representation and Reasoning: Reasong about actions Machine Learning: Meta-Learning Machine Learning: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Qiang Shen and Haotian Feng and Rui Song and Stefano Teso and Fausto Giunchiglia and Hao Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/475},
  pages     = {3423-3429},
  title     = {Federated multi-task attention for cross-individual human activity recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PAnDR: Fast adaptation to new environments from offline
experiences via decoupling policy and environment representations.
<em>IJCAI</em>, 3416–3422. (<a
href="https://doi.org/10.24963/ijcai.2022/474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Reinforcement Learning (DRL) has been a promising solution to many complex decision-making problems. Nevertheless, the notorious weakness in generalization among environments prevent widespread application of DRL agents in real-world scenarios. Although advances have been made recently, most prior works assume sufficient online interaction on training environments, which can be costly in practical cases. To this end, we focus on an offline-training-online-adaptation setting, in which the agent first learns from offline experiences collected in environments with different dynamics and then performs online policy adaptation in environments with new dynamics. In this paper, we propose Policy Adaptation with Decoupled Representations (PAnDR) for fast policy adaptation. In offline training phase, the environment representation and policy representation are learned through contrastive learning and policy recovery, respectively. The representations are further refined by mutual information optimization to make them more decoupled and complete. With learned representations, a Policy-Dynamics Value Function (PDVF) network is trained to approximate the values for different combinations of policies and environments from offline experiences. In online adaptation phase, with the environment context inferred from few experiences collected in new environments, the policy is optimized by gradient ascent with respect to the PDVF. Our experiments show that PAnDR outperforms existing algorithms in several representative policy adaptation problems. Keywords: Machine Learning: Deep Reinforcement Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Tong Sang and Hongyao Tang and Yi Ma and Jianye Hao and Yan Zheng and Zhaopeng Meng and Boyan Li and Zhen Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/474},
  pages     = {3416-3422},
  title     = {PAnDR: Fast adaptation to new environments from offline experiences via decoupling policy and environment representations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Markov abstractions for PAC reinforcement learning in
non-markov decision processes. <em>IJCAI</em>, 3408–3415. (<a
href="https://doi.org/10.24963/ijcai.2022/473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Our work aims at developing reinforcement learning algorithms that do not rely on the Markov assumption. We consider the class of Non-Markov Decision Processes where histories can be abstracted into a finite set of states while preserving the dynamics. We call it a Markov abstraction since it induces a Markov Decision Process over a set of states that encode the non-Markov dynamics. This phenomenon underlies the recently introduced Regular Decision Processes (as well as POMDPs where only a finite number of belief states is reachable). In all such kinds of decision process, an agent that uses a Markov abstraction can rely on the Markov property to achieve optimal behaviour. We show that Markov abstractions can be learned during reinforcement learning. Our approach combines automata learning and classic reinforcement learning. For these two tasks, standard algorithms can be employed. We show that our approach has PAC guarantees when the employed algorithms have PAC guarantees, and we also provide an experimental evaluation. Keywords: Machine Learning: Reinforcement Learning Planning and Scheduling: Markov Decisions Processes Knowledge Representation and Reasoning: Reasoning about actions Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis},
  archive   = {C_IJCAI},
  author    = {Alessandro Ronca and Gabriel Paludo Licks and Giuseppe De Giacomo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/473},
  pages     = {3408-3415},
  title     = {Markov abstractions for PAC reinforcement learning in non-markov decision processes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-armed bandit problem with temporally-partitioned
rewards: When partial feedback counts. <em>IJCAI</em>, 3401–3407. (<a
href="https://doi.org/10.24963/ijcai.2022/472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a rising interest in industrial online applications where data becomes available sequentially. Inspired by the recommendation of playlists to users where their preferences can be collected during the listening of the entire playlist, we study a novel bandit setting, namely Multi-Armed Bandit with Temporally-Partitioned Rewards (TP-MAB), in which the stochastic reward associated with the pull of an arm is partitioned over a finite number of consecutive rounds following the pull. This setting, unexplored so far to the best of our knowledge, is a natural extension of delayed-feedback bandits to the case in which rewards may be dilated over a finite-time span after the pull instead of being fully disclosed in a single, potentially delayed round. We provide two algorithms to address TP-MAB problems, namely, TP-UCB-FR and TP-UCB-EW, which exploit the partial information disclosed by the reward collected over time. We show that our algorithms provide better asymptotical regret upper bounds than delayed-feedback bandit algorithms when a property characterizing a broad set of reward structures of practical interest, namely α-smoothness, holds. We also empirically evaluate their performance across a wide range of settings, both synthetically generated and from a real-world media recommendation problem. Keywords: Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Giulia Romano and Andrea Agostini and Francesco Trovò and Nicola Gatti and Marcello Restelli},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/472},
  pages     = {3401-3407},
  title     = {Multi-armed bandit problem with temporally-partitioned rewards: When partial feedback counts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding the limits of poisoning attacks in episodic
reinforcement learning. <em>IJCAI</em>, 3394–3400. (<a
href="https://doi.org/10.24963/ijcai.2022/471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To understand the security threats to reinforcement learning (RL) algorithms, this paper studies poisoning attacks to manipulate any order-optimal learning algorithm towards a targeted policy in episodic RL and examines the potential damage of two natural types of poisoning attacks, i.e., the manipulation of reward or action. We discover that the effect of attacks crucially depends on whether the rewards are bounded or unbounded. In bounded reward settings, we show that only reward manipulation or only action manipulation cannot guarantee a successful attack. However, by combining reward and action manipulation, the adversary can manipulate any order-optimal learning algorithm to follow any targeted policy with \Theta(\sqrt{T}) total attack cost, which is order-optimal, without any knowledge of the underlying MDP. In contrast, in unbounded reward settings, we show that reward manipulation attacks are sufficient for an adversary to successfully manipulate any order-optimal learning algorithm to follow any targeted policy using \tilde{O}(\sqrt{T}) amount of contamination. Our results reveal useful insights about what can or cannot be achieved by poisoning attacks, and are set to spur more work on the design of robust RL algorithms. Keywords: Machine Learning: Online Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Anshuka Rangi and Haifeng Xu and Long Tran-Thanh and Massimo Franceschetti},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/471},
  pages     = {3394-3400},
  title     = {Understanding the limits of poisoning attacks in episodic reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the optimization of margin distribution. <em>IJCAI</em>,
3387–3393. (<a href="https://doi.org/10.24963/ijcai.2022/470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Margin has played an important role on the design and analysis of learning algorithms during the past years, mostly working with the maximization of the minimum margin. Recent years have witnessed the increasing empirical studies on the optimization of margin distribution according to different statistics such as medium margin, average margin, margin variance, etc., whereas there is a relative paucity of theoretical understanding. In this work, we take one step on this direction by providing a new generalization error bound, which is heavily relevant to margin distribution by incorporating ingredients such as average margin and semi-variance, a new margin statistics for the characterization of margin distribution. Inspired by the theoretical findings, we propose the MSVMAv, an efficient approach to achieve better performance by optimizing margin distribution in terms of its empirical average margin and semi-variance. We finally conduct extensive experiments to show the superiority of the proposed MSVMAv approach. Keywords: Machine Learning: Learning Theory Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Meng-Zhang Qian and Zheng Ai and Teng Zhang and Wei Gao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/470},
  pages     = {3387-3393},
  title     = {On the optimization of margin distribution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Search-based reinforcement learning through bandit linear
optimization. <em>IJCAI</em>, 3380–3386. (<a
href="https://doi.org/10.24963/ijcai.2022/469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The development of AlphaZero was a breakthrough in search-based reinforcement learning, by employing a given world model in a Monte-Carlo tree search (MCTS) algorithm to incrementally learn both an action policy and a value estimation. When extending this paradigm to the setting of simultaneous move games we find that the selection strategy of AlphaZero has theoretical shortcomings, including that convergence to a Nash equilibrium is not guaranteed. By analyzing these shortcomings, we find that the selection strategy corresponds to an approximated version of bandit linear optimization using Tsallis entropy regularization with α parameter set to zero, which is equivalent to log-barrier regularization. This observation allows us to refine the search method used by AlphaZero to obtain an algorithm that has theoretically optimal regret as well as superior empirical performance on our evaluation benchmark. Keywords: Machine Learning: Reinforcement Learning Agent-based and Multi-agent Systems: Algorithmic Game Theory Search: Game Playing},
  archive   = {C_IJCAI},
  author    = {Milan Peelman and Antoon Bronselaer and Guy De Tré},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/469},
  pages     = {3380-3386},
  title     = {Search-based reinforcement learning through bandit linear optimization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakly-supervised text classification with wasserstein
barycenters regularization. <em>IJCAI</em>, 3373–3379. (<a
href="https://doi.org/10.24963/ijcai.2022/468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly-supervised text classification aims to train predictive models with unlabeled texts and a few representative words of classes, referred to as category words, rather than labeled texts. These weak supervisions are much more cheaper and easy to collect in real-world scenarios. To resolve this task, we propose a novel deep classification model, namely Weakly-supervised Text Classification with Wasserstein Barycenter Regularization (WTC-WBR). Specifically, we initialize the pseudo-labels of texts by using the category word occurrences, and formulate a weakly self-training framework to iteratively update the weakly-supervised targets by combining the pseudo-labels with the sharpened predictions. Most importantly, we suggest a Wasserstein barycenter regularization with the weakly-supervised targets on the deep feature space. The intuition is that the texts tend to be close to the corresponding Wasserstein barycenter indicated by weakly-supervised targets. Another benefit is that the regularization can capture the geometric information of deep feature space to boost the discriminative power of deep features. Experimental results demonstrate that WTC-WBR outperforms the existing weakly-supervised baselines, and achieves comparable performance to semi-supervised and supervised baselines. Keywords: Machine Learning: Classification Machine Learning: Weakly Supervised Learning Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Jihong Ouyang and Yiming Wang and Ximing Li and Changchun Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/468},
  pages     = {3373-3379},
  title     = {Weakly-supervised text classification with wasserstein barycenters regularization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Certified robustness via randomized smoothing over
multiplicative parameters of input transformations. <em>IJCAI</em>,
3366–3372. (<a href="https://doi.org/10.24963/ijcai.2022/467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Currently the most popular method of providing robustness certificates is randomized smoothing where an input is smoothed via some probability distribution. We propose a novel approach to randomized smoothing over multiplicative parameters. Using this method we construct certifiably robust classifiers with respect to a gamma correction perturbation and compare the result with classifiers obtained via other smoothing distributions (Gaussian, Laplace, uniform). The experiments show that asymmetrical Rayleigh distribution allows to obtain better certificates for some values of perturbation parameters. To the best of our knowledge it is the first work concerning certified robustness against the multiplicative gamma correction transformation and the first to study effects of asymmetrical distributions in randomized smoothing. Keywords: Machine Learning: Robustness Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Nikita Muravev and Aleksandr Petiushko},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/467},
  pages     = {3366-3372},
  title     = {Certified robustness via randomized smoothing over multiplicative parameters of input transformations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Composing neural learning and symbolic reasoning with an
application to visual discrimination. <em>IJCAI</em>, 3358–3365. (<a
href="https://doi.org/10.24963/ijcai.2022/466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of combining machine learning models to perform higher-level cognitive tasks with clear specifications. We propose the novel problem of Visual Discrimination Puzzles (VDP) that requires finding interpretable discriminators that classify images according to a logical specification. Humans can solve these puzzles with ease and they give robust, verifiable, and interpretable discriminators as answers. We propose a compositional neurosymbolic framework that combines a neural network to detect objects and relationships with a symbolic learner that finds interpretable discriminators. We create large classes of VDP datasets involving natural and artificial images and show that our neurosymbolic framework performs favorably compared to several purely neural approaches. Keywords: Machine Learning: Neuro-Symbolic Methods Computer Vision: Visual reasoning and symbolic representation Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Few-shot learning AI Ethics, Trust, Fairness: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Adithya Murali and Atharva Sehgal and Paul Krogmeier and P. Madhusudan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/466},
  pages     = {3358-3365},
  title     = {Composing neural learning and symbolic reasoning with an application to visual discrimination},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Escaping feature twist: A variational graph auto-encoder for
node clustering. <em>IJCAI</em>, 3351–3357. (<a
href="https://doi.org/10.24963/ijcai.2022/465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most recent graph clustering methods rely on pretraining graph auto-encoders using self-supervision techniques (pretext task) and finetuning based on pseudo-supervision (main task). However, the transition from self-supervision to pseudo-supervision has never been studied from a geometric perspective. Herein, we establish the first systematic exploration of the latent manifolds&#39; geometry under the deep clustering paradigm; we study the evolution of their intrinsic dimension and linear intrinsic dimension. We find that the embedded manifolds undergo coarse geometric transformations under the transition regime: from curved low-dimensional to flattened higher-dimensional. Moreover, we find that this inappropriate flattening leads to clustering deterioration by twisting the curved structures. To address this problem, which we call Feature Twist, we propose a variational graph auto-encoder that can smooth the local curves before gradually flattening the global structures. Our results show a notable improvement over multiple state-of-the-art approaches by escaping Feature Twist. Keywords: Machine Learning: Unsupervised Learning Machine Learning: Autoencoders Machine Learning: Clustering Machine Learning: Representation learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Nairouz Mrabah and Mohamed Bouguessa and Riadh Ksantini},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/465},
  pages     = {3351-3357},
  title     = {Escaping feature twist: A variational graph auto-encoder for node clustering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A few seconds can change everything: Fast decision-based
attacks against DNNs. <em>IJCAI</em>, 3342–3350. (<a
href="https://doi.org/10.24963/ijcai.2022/464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Previous researches have demonstrated deep learning models&#39; vulnerabilities to decision-based adversarial attacks, which craft adversarial examples based solely on information from output decisions (top-1 labels). However, existing decision-based attacks have two major limitations, i.e., expensive query cost and being easy to detect. To bridge the gap and enlarge real threats to commercial applications, we propose a novel and efficient decision-based attack against black-box models, dubbed FastDrop, which only requires a few queries and work well under strong defenses. The crux of the innovation is that, unlike existing adversarial attacks that rely on gradient estimation and additive noise, FastDrop generates adversarial examples by dropping information in the frequency domain. Extensive experiments on three datasets demonstrate that FastDrop can escape the detection of the state-of-the-art (SOTA) black-box defenses and reduce the number of queries by 13~133× under the same level of perturbations compared with the SOTA attacks. FastDrop only needs 10~20 queries to conduct an attack against various black-box models within 1s. Besides, on commercial vision APIs provided by Baidu and Tencent, FastDrop achieves an attack success rate (ASR) of 100\% with 10 queries on average, which poses a real and severe threat to real-world applications. Keywords: Machine Learning: Adversarial Machine Learning Computer Vision: Adversarial learning, adversarial attack and defense methods},
  archive   = {C_IJCAI},
  author    = {Ningping Mou and Baolin Zheng and Qian Wang and Yunjie Ge and Binqing Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/464},
  pages     = {3342-3350},
  title     = {A few seconds can change everything: Fast decision-based attacks against DNNs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tessellation-filtering ReLU neural networks. <em>IJCAI</em>,
3335–3341. (<a href="https://doi.org/10.24963/ijcai.2022/463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We identify tessellation-filtering ReLU neural networks that, when composed with another ReLU network, keep its non-redundant tessellation unchanged or reduce it.The additional network complexity modifies the shape of the decision surface without increasing the number of linear regions. We provide a mathematical understanding of the related additional expressiveness by means of a novel measure of shape complexity by counting deviations from convexity which results in a Boolean algebraic characterization of this special class. A local representation theorem gives rise to novel approaches for pruning and decision surface analysis. Keywords: Machine Learning: Theory of Deep Learning Machine Learning: Learning Theory},
  archive   = {C_IJCAI},
  author    = {Bernhard A. Moser and Michal Lewandowski and Somayeh Kargaran and Werner Zellinger and Battista Biggio and Christoph Koutschan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/463},
  pages     = {3335-3341},
  title     = {Tessellation-filtering ReLU neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). COMET flows: Towards generative modeling of multivariate
extremes and tail dependence. <em>IJCAI</em>, 3328–3334. (<a
href="https://doi.org/10.24963/ijcai.2022/462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Normalizing flows—a popular class of deep generative models—often fail to represent extreme phenomena observed in real-world processes. In particular, existing normalizing flow architectures struggle to model multivariate extremes, characterized by heavy-tailed marginal distributions and asymmetric tail dependence among variables. In light of this shortcoming, we propose COMET (COpula Multivariate ExTreme) Flows, which decompose the process of modeling a joint distribution into two parts: (i) modeling its marginal distributions, and (ii) modeling its copula distribution. COMET Flows capture heavy-tailed marginal distributions by combining a parametric tail belief at extreme quantiles of the marginals with an empirical kernel density function at mid-quantiles. In addition, COMET Flows capture asymmetric tail dependence among multivariate extremes by viewing such dependence as inducing a low-dimensional manifold structure in feature space. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of COMET flows in capturing both heavy-tailed marginals and asymmetric tail dependence compared to other state-of-the-art baseline architectures. All code is available at https://github.com/andrewmcdonald27/COMETFlows. Keywords: Machine Learning: Probabilistic Machine Learning Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Applications Machine Learning: Unsupervised Learning Multidisciplinary Topics and Applications: Physical Science},
  archive   = {C_IJCAI},
  author    = {Andrew McDonald and Pang-Ning Tan and Lifeng Luo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/462},
  pages     = {3328-3334},
  title     = {COMET flows: Towards generative modeling of multivariate extremes and tail dependence},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Game redesign in no-regret game playing. <em>IJCAI</em>,
3321–3327. (<a href="https://doi.org/10.24963/ijcai.2022/461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the game redesign problem in which an external designer has the ability to change the payoff function in each round, but incurs a design cost for deviating from the original game. The players apply no-regret learning algorithms to repeatedly play the changed games with limited feedback. The goals of the designer are to (i) incentivize players to take a specific target action profile frequently; (ii) incur small cumulative design cost. We present game redesign algorithms with the guarantee that the target action profile is played in T-o(T) rounds while incurring only o(T) cumulative design cost. Simulations on four classic games confirm the ef- fectiveness of our proposed redesign algorithms. Keywords: Machine Learning: Adversarial Machine Learning Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Yuzhe Ma and Young Wu and Xiaojin Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/461},
  pages     = {3321-3327},
  title     = {Game redesign in no-regret game playing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Locally normalized soft contrastive clustering for compact
clusters. <em>IJCAI</em>, 3313–3320. (<a
href="https://doi.org/10.24963/ijcai.2022/460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent deep clustering algorithms take advantage of self-supervised learning and self-training techniques to map the original data into a latent space, where the data embedding and clustering assignment can be jointly optimized. However, as many recent datasets are enormous and noisy, getting a clear boundary between different clusters is challenging with existing methods that mainly focus on contracting similar samples together and overlooking samples near boundary of clusters in the latent space. In this regard, we propose an end-to-end deep clustering algorithm, i.e., Locally Normalized Soft Contrastive Clustering (LNSCC). It takes advantage of similarities among each sample&#39;s local neighborhood and globally disconnected samples to leverage positiveness and negativeness of sample pairs in a contrastive way to separate different clusters. Experimental results on various datasets illustrate that our proposed approach achieves outstanding clustering performance over most of the state-of-the-art clustering methods for both image and non-image data even without convolution. Keywords: Machine Learning: Clustering Computer Vision: Representation Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Xin Ma and Won Hwa Kim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/460},
  pages     = {3313-3320},
  title     = {Locally normalized soft contrastive clustering for compact clusters},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep graph matching for partial label learning.
<em>IJCAI</em>, 3306–3312. (<a
href="https://doi.org/10.24963/ijcai.2022/459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial Label Learning (PLL) aims to learn from training data where each instance is associated with a set of candidate labels, among which only one is correct. In this paper, we formulate the task of PLL problem as an ``instance-label&#39;&#39; matching selection problem, and propose a DeepGNN-based graph matching PLL approach to solve it. Specifically, we first construct all instances and labels as graph nodes into two different graphs respectively, and then integrate them into a unified matching graph by connecting each instance to its candidate labels. Afterwards, the graph attention mechanism is adopted to aggregate and update all nodes state on the instance graph to form structural representations for each instance. Finally, each candidate label is embedded into its corresponding instance and derives a matching affinity score for each instance-label correspondence with a progressive cross-entropy loss. Extensive experiments on various data sets have demonstrated the superiority of our proposed method. Keywords: Machine Learning: Multi-label},
  archive   = {C_IJCAI},
  author    = {Gengyu Lyu and Yanan Wu and Songhe Feng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/459},
  pages     = {3306-3312},
  title     = {Deep graph matching for partial label learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards robust unsupervised disentanglement of sequential
data — a case study using music audio. <em>IJCAI</em>, 3299–3305. (<a
href="https://doi.org/10.24963/ijcai.2022/458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Disentangled sequential autoencoders (DSAEs) represent a class of probabilistic graphical models that describes an observed sequence with dynamic latent variables and a static latent variable. The former encode information at a frame rate identical to the observation, while the latter globally governs the entire sequence. This introduces an inductive bias and facilitates unsupervised disentanglement of the underlying local and global factors. In this paper, we show that the vanilla DSAE suffers from being sensitive to the choice of model architecture and capacity of the dynamic latent variables, and is prone to collapse the static latent variable. As a countermeasure, we propose TS-DSAE, a two-stage training framework that first learns sequence-level prior distributions, which are subsequently employed to regularise the model and facilitate auxiliary objectives to promote disentanglement. The proposed framework is fully unsupervised and robust against the global factor collapse problem across a wide range of model configurations. It also avoids typical solutions such as adversarial training which usually involves laborious parameter tuning, and domain-specific data augmentation. We conduct quantitative and qualitative evaluations to demonstrate its robustness in terms of disentanglement on both artificial and real-world music audio datasets. Keywords: Machine Learning: Unsupervised Learning Machine Learning: Representation learning Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Time-series; Data Streams Machine Learning: Autoencoders},
  archive   = {C_IJCAI},
  author    = {Yin-Jyun Luo and Sebastian Ewert and Simon Dixon},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/458},
  pages     = {3299-3305},
  title     = {Towards robust unsupervised disentanglement of sequential data — a case study using music audio},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Teaching LTLf satisfiability checking to neural networks.
<em>IJCAI</em>, 3292–3298. (<a
href="https://doi.org/10.24963/ijcai.2022/457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Linear temporal logic over finite traces (LTLf) satisfiability checking is a fundamental and hard (PSPACE-complete) problem in the artificial intelligence community. We explore teaching end-to-end neural networks to check satisfiability in polynomial time. It is a challenge to characterize the syntactic and semantic features of LTLf via neural networks. To tackle this challenge, we propose LTLfNet, a recursive neural network that captures syntactic features of LTLf by recursively combining the embeddings of sub-formulae. LTLfNet models permutation invariance and sequentiality in the semantics of LTLf through different aggregation mechanisms of sub-formulae. Experimental results demonstrate that LTLfNet achieves good performance in synthetic datasets and generalizes across large-scale datasets. They also show that LTLfNet is competitive with state-of-the-art symbolic approaches such as nuXmv and CDLSC. Keywords: Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Weilin Luo and Hai Wan and Jianfeng Du and Xiaoda Li and Yuze Fu and Rongzhen Ye and Delong Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/457},
  pages     = {3292-3298},
  title     = {Teaching LTLf satisfiability checking to neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring binary classification hidden within partial label
learning. <em>IJCAI</em>, 3285–3291. (<a
href="https://doi.org/10.24963/ijcai.2022/456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Partial label learning (PLL) is to learn a discriminative model under incomplete supervision, where each instance is annotated with a candidate label set. The basic principle of PLL is that the unknown correct label y of an instance x resides in its candidate label set s, i.e., P(y ∈ s | x) = 1. On which basis, current researches either directly model P(x | y) under different data generation assumptions or propose various surrogate multiclass losses, which all aim to encourage the model-based Pθ(y ∈ s | x)→1 implicitly. In this work, instead, we explicitly construct a binary classification task toward P(y ∈ s | x) based on the discriminative model, that is to predict whether the model-output label of x is one of its candidate labels. We formulate a novel risk estimator with estimation error bound for the proposed PLL binary classification risk. By applying logit adjustment based on disambiguation strategy, the practical approach directly maximizes Pθ(y ∈ s | x) while implicitly disambiguating the correct one from candidate labels simultaneously. Thorough experiments validate that the proposed approach achieves competitive performance against the state-of-the-art PLL methods. Keywords: Machine Learning: Weakly Supervised Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Hengheng Luo and Yabin Zhang and Suyun Zhao and Hong Chen and Cuiping Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/456},
  pages     = {3285-3291},
  title     = {Exploring binary classification hidden within partial label learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SELC: Self-ensemble label correction improves learning with
noisy labels. <em>IJCAI</em>, 3278–3284. (<a
href="https://doi.org/10.24963/ijcai.2022/455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks are prone to overfitting noisy labels, resulting in poor generalization performance. To overcome this problem, we present a simple and effective method self-ensemble label correction (SELC) to progressively correct noisy labels and refine the model. We look deeper into the memorization behavior in training with noisy labels and observe that the network outputs are reliable in the early stage. To retain this reliable knowledge, SELC uses ensemble predictions formed by an exponential moving average of network outputs to update the original noisy labels. We show that training with SELC refines the model by gradually reducing supervision from noisy labels and increasing supervision from ensemble predictions. Despite its simplicity, compared with many state-of-the-art methods, SELC obtains more promising and stable results in the presence of class-conditional, instance-dependent, and real-world label noise. The code is available at https://github.com/MacLLL/SELC. Keywords: Machine Learning: Weakly Supervised Learning Machine Learning: Classification Machine Learning: Ensemble Methods},
  archive   = {C_IJCAI},
  author    = {Yangdi Lu and Wenbo He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/455},
  pages     = {3278-3284},
  title     = {SELC: Self-ensemble label correction improves learning with noisy labels},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Projected gradient descent algorithms for solving nonlinear
inverse problems with generative priors. <em>IJCAI</em>, 3271–3277. (<a
href="https://doi.org/10.24963/ijcai.2022/454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose projected gradient descent (PGD) algorithms for signal estimation from noisy nonlinear measurements. We assume that the unknown signal lies near the range of a Lipschitz continuous generative model with bounded inputs. In particular, we consider two cases when the nonlinear link function is either unknown or known. For unknown nonlinearity, we make the assumption of sub-Gaussian observations and propose a linear least-squares estimator. We show that when there is no representation error, the sensing vectors are Gaussian, and the number of samples is sufficiently large, with high probability, a PGD algorithm converges linearly to a point achieving the optimal statistical rate using arbitrary initialization. For known nonlinearity, we assume monotonicity, and make much weaker assumptions on the sensing vectors and allow for representation error. We propose a nonlinear least-squares estimator that is guaranteed to enjoy an optimal statistical rate. A corresponding PGD algorithm is provided and is shown to also converge linearly to the estimator using arbitrary initialization. In addition, we present experimental results on image datasets to demonstrate the performance of our PGD algorithms. Keywords: Machine Learning: Unsupervised Learning Machine Learning: Learning Theory Machine Learning: Probabilistic Machine Learning Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Zhaoqiang Liu and Jun Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/454},
  pages     = {3271-3277},
  title     = {Projected gradient descent algorithms for solving nonlinear inverse problems with generative priors},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Declaration-based prompt tuning for visual question
answering. <em>IJCAI</em>, 3264–3270. (<a
href="https://doi.org/10.24963/ijcai.2022/453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, the pre-training-then-fine-tuning paradigm has yielded immense success on a wide spectrum of cross-modal tasks, such as visual question answering (VQA), in which a visual-language (VL) model is first optimized via self-supervised task objectives, e.g., masked language modeling (MLM) and image-text matching (ITM), and then fine-tuned to adapt to downstream task (e.g., VQA) via a brand-new objective function, e.g., answer prediction. However, the inconsistency of the objective forms not only severely limits the generalization of pre-trained VL models to downstream tasks, but also requires a large amount of labeled data for fine-tuning. To alleviate the problem, we propose an innovative VL fine-tuning paradigm (named Declaration-based Prompt Tuning, abbreviated as DPT), which fine-tunes the model for downstream VQA using the pre-training objectives, boosting the effective adaptation of pre-trained models to the downstream task. Specifically, DPT reformulates the VQA task via (1) textual adaptation, which converts the given questions into declarative sentence form for prompt-tuning, and (2) task adaptation, which optimizes the objective function of VQA problem in the manner of pre-training phase. Experimental results on GQA dataset show that DPT outperforms the fine-tuned counterpart by a large margin regarding accuracy in both fully-supervised (2.68\%) and zero-shot/fewshot (over 31\%) settings. All the data and codes will be available to facilitate future research. Keywords: Machine Learning: Multi-modal learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Vision and language Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Yuhang Liu and Wei Wei and Daowan Peng and Feida Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/453},
  pages     = {3264-3270},
  title     = {Declaration-based prompt tuning for visual question answering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). JueWu-MC: Playing minecraft with sample-efficient
hierarchical reinforcement learning. <em>IJCAI</em>, 3257–3263. (<a
href="https://doi.org/10.24963/ijcai.2022/452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning rational behaviors in open-world games like Minecraft remains to be challenging for Reinforcement Learning (RL) research due to the compound challenge of partial observability, high-dimensional visual perception and delayed reward. To address this, we propose JueWu-MC, a sample-efficient hierarchical RL approach equipped with representation learning and imitation learning to deal with perception and exploration. Specifically, our approach includes two levels of hierarchy, where the high-level controller learns a policy to control over options and the low-level workers learn to solve each sub-task. To boost the learning of sub-tasks, we propose a combination of techniques including 1) action-aware representation learning which captures underlying relations between action and representation, 2) discriminator-based self-imitation learning for efficient exploration, and 3) ensemble behavior cloning with consistency filtering for policy robustness. Extensive experiments show that JueWu-MC significantly improves sample efficiency and outperforms a set of baselines by a large margin. Notably, we won the championship of the NeurIPS MineRL 2021 research competition and achieved the highest performance score ever. Keywords: Machine Learning: Deep Reinforcement Learning Search: Game Playing},
  archive   = {C_IJCAI},
  author    = {Zichuan Lin and Junyou Li and Jianing Shi and Deheng Ye and Qiang Fu and Wei Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/452},
  pages     = {3257-3263},
  title     = {JueWu-MC: Playing minecraft with sample-efficient hierarchical reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contrastive multi-view hyperbolic hierarchical clustering.
<em>IJCAI</em>, 3250–3256. (<a
href="https://doi.org/10.24963/ijcai.2022/451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hierarchical clustering recursively partitions data at an increasingly finer granularity. In real-world applications, multi-view data have become increasingly important. This raises a less investigated problem, i.e., multi-view hierarchical clustering, to better understand the hierarchical structure of multi-view data. To this end, we propose a novel neural network-based model, namely Contrastive Multi-view Hyperbolic Hierarchical Clustering(CMHHC). It consists of three components, i.e., multi-view alignment learning, aligned feature similarity learning, and continuous hyperbolic hierarchical clustering. First, we align sample-level representations across multiple views in a contrastive way to capture the view-invariance information. Next, we utilize both the manifold and Euclidean similarities to improve the metric property. Then, we embed the representations into a hyperbolic space and optimize the hyperbolic embeddings via a continuous relaxation of hierarchical clustering loss. Finally, a binary clustering tree is decoded from optimized hyperbolic embeddings. Experimental results on five real-world datasets demonstrate the effectiveness of the proposed method and its components. Keywords: Machine Learning: Clustering Machine Learning: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Fangfei Lin and Bing Bai and Kun Bai and Yazhou Ren and Peng Zhao and Zenglin Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/451},
  pages     = {3250-3256},
  title     = {Contrastive multi-view hyperbolic hierarchical clustering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking the setting of semi-supervised learning on
graphs. <em>IJCAI</em>, 3243–3249. (<a
href="https://doi.org/10.24963/ijcai.2022/450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We argue that the present setting of semisupervised learning on graphs may result in unfair comparisons, due to its potential risk of over-tuning hyper-parameters for models. In this paper, we highlight the significant influence of tuning hyper-parameters, which leverages the label information in the validation set to improve the performance. To explore the limit of over-tuning hyperparameters, we propose ValidUtil, an approach to fully utilize the label information in the validation set through an extra group of hyper-parameters. With ValidUtil, even GCN can easily get high accuracy of 85.8\% on Cora. To avoid over-tuning, we merge the training set and the validation set and construct an i.i.d. graph benchmark (IGB) consisting of 4 datasets. Each dataset contains 100 i.i.d. graphs sampled from a large graph to reduce the evaluation variance. Our experiments suggest that IGB is a more stable benchmark than previous datasets for semisupervised learning on graphs. Our code and data are released at https://github.com/THUDM/IGB/. Keywords: Machine Learning: Semi-Supervised Learning Machine Learning: Sequence and Graph Learning Multidisciplinary Topics and Applications: Web and Social Networks},
  archive   = {C_IJCAI},
  author    = {Ziang Li and Ming Ding and Weikai Li and Zihan Wang and Ziyu Zeng and Yukuo Cen and Jie Tang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/450},
  pages     = {3243-3249},
  title     = {Rethinking the setting of semi-supervised learning on graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Pruning-as-search: Efficient neural architecture search via
channel pruning and structural reparameterization. <em>IJCAI</em>,
3236–3242. (<a href="https://doi.org/10.24963/ijcai.2022/449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural architecture search (NAS) and network pruning are widely studied efficient AI techniques, but not yet perfect. NAS performs exhaustive candidate architecture search, incurring tremendous search cost. Though (structured) pruning can simply shrink model dimension, it remains unclear how to decide the per-layer sparsity automatically and optimally. In this work, we revisit the problem of layer-width optimization and propose Pruning-as-Search (PaS), an end-to-end channel pruning method to search out desired sub-network automatically and efficiently. Specifically, we add a depth-wise binary convolution to learn pruning policies directly through gradient descent. By combining the structural reparameterization and PaS, we successfully searched out a new family of VGG-like and lightweight networks, which enable the flexibility of arbitrary width with respect to each layer instead of each stage. Experimental results show that our proposed architecture outperforms prior arts by around 1.0\% top-1 accuracy under similar inference speed on ImageNet-1000 classification task. Furthermore, we demonstrate the effectiveness of our width search on complex tasks including instance segmentation and image translation. Code and models are released. Keywords: Machine Learning: Automated Machine Learning Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Yanyu Li and Pu Zhao and Geng Yuan and Xue Lin and Yanzhi Wang and Xin Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/449},
  pages     = {3236-3242},
  title     = {Pruning-as-search: Efficient neural architecture search via channel pruning and structural reparameterization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural PCA for flow-based representation learning.
<em>IJCAI</em>, 3229–3235. (<a
href="https://doi.org/10.24963/ijcai.2022/448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Of particular interest is to discover useful representations solely from observations in an unsupervised generative manner. However, the question of whether existing normalizing flows provide effective representations for downstream tasks remains mostly unanswered despite their strong ability for sample generation and density estimation. This paper investigates this problem for such a family of generative models that admits exact invertibility. We propose Neural Principal Component Analysis (Neural-PCA) that operates in full dimensionality while capturing principal components in descending order. Without exploiting any label information, the principal components recovered store the most informative elements in their leading dimensions and leave the negligible in the trailing ones, allowing for clear performance improvements of 5\%-10\% in downstream tasks. Such improvements are empirically found consistent irrespective of the number of latent trailing dimensions dropped. Our work suggests that necessary inductive bias be introduced into generative modeling when representation quality is of interest. Keywords: Machine Learning: Representation learning Computer Vision: Neural generative models, auto encoders, GANs},
  archive   = {C_IJCAI},
  author    = {Shen Li and Bryan Hooi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/448},
  pages     = {3229-3235},
  title     = {Neural PCA for flow-based representation learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cross-modal representation learning and relation reasoning
for bidirectional adaptive manipulation. <em>IJCAI</em>, 3222–3228. (<a
href="https://doi.org/10.24963/ijcai.2022/447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Since single-modal controllable manipulation typically requires supervision of information from other modalities or cooperation with complex software and experts, this paper addresses the problem of cross-modal adaptive manipulation (CAM). The novel task performs cross-modal semantic alignment from mutual supervision and implements bidirectional exchange of attributes, relations, or objects in parallel, benefiting both modalities while significantly reducing manual effort. We introduce a robust solution for CAM, which includes two essential modules, namely Heterogeneous Representation Learning (HRL) and Cross-modal Relation Reasoning (CRR). The former is designed to perform representation learning for cross-modal semantic alignment on heterogeneous graph nodes. The latter is adopted to identify and exchange the focused attributes, relations, or objects in both modalities. Our method produces pleasing cross-modal outputs on CUB and Visual Genome. Keywords: Machine Learning: Multi-modal learning Computer Vision: Vision and language Machine Learning: Relational Learning Machine Learning: Representation learning Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Lei Li and Kai Fan and Chun Yuan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/447},
  pages     = {3222-3228},
  title     = {Cross-modal representation learning and relation reasoning for bidirectional adaptive manipulation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning from students: Online contrastive distillation
network for general continual learning. <em>IJCAI</em>, 3215–3221. (<a
href="https://doi.org/10.24963/ijcai.2022/446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The goal of General Continual Learning (GCL) is to preserve learned knowledge and learn new knowledge with constant memory from an infinite data stream where task boundaries are blurry. Distilling the model&#39;s response of reserved samples between the old and the new models is an effective way to achieve promise performance on GCL. However, it accumulates the inherent old model&#39;s response bias and is not robust to model changes. To this end, we propose an Online Contrastive Distillation Network (OCD-Net) to tackle these problems, which explores the merit of the student model in each time step to guide the training process of the student model. Concretely, the teacher model is devised to help the student model to consolidate the learned knowledge, which is trained online via integrating the model weights of the student model to accumulate the new knowledge. Moreover, our OCD-Net incorporates both relation and adaptive response to help the student model alleviate the catastrophic forgetting, which is also beneficial for the teacher model preserves the learned knowledge. Extensive experiments on six benchmark datasets demonstrate that our proposed OCD-Net significantly outperforms state-of-the-art approaches in 3.26\%~8.71\% with various buffer sizes. Our code is available at https://github.com/lijincm/OCD-Net. Keywords: Machine Learning: Incremental Learning Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Jin Li and Zhong Ji and Gang Wang and Qiang Wang and Feng Gao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/446},
  pages     = {3215-3221},
  title     = {Learning from students: Online contrastive distillation network for general continual learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ridgeless regression with random features. <em>IJCAI</em>,
3208–3214. (<a href="https://doi.org/10.24963/ijcai.2022/445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent theoretical studies illustrated that kernel ridgeless regression can guarantee good generalization ability without an explicit regularization. In this paper, we investigate the statistical properties of ridgeless regression with random features and stochastic gradient descent. We explore the effect of factors in the stochastic gradient and random features, respectively. Specifically, random features error exhibits the double-descent curve. Motivated by the theoretical findings, we propose a tunable kernel algorithm that optimizes the spectral density of kernel during training. Our work bridges the interpolation theory and practical algorithm. Keywords: Machine Learning: Learning Theory Machine Learning: Kernel Methods},
  archive   = {C_IJCAI},
  author    = {Jian Li and Yong Liu and Yingying Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/445},
  pages     = {3208-3214},
  title     = {Ridgeless regression with random features},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning general gaussian mixture model with integral cosine
similarity. <em>IJCAI</em>, 3201–3207. (<a
href="https://doi.org/10.24963/ijcai.2022/444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gaussian mixture model (GMM) is a powerful statistical tool in data modeling, especially for unsupervised learning tasks. Traditional learning methods for GMM such as expectation maximization (EM) require the covariance of the Gaussian components to be non-singular, a condition that is often not satisfied in real-world applications. This paper presents a new learning method called G$^2$M$^2$ (General Gaussian Mixture Model) by fitting an unnormalized Gaussian mixture function (UGMF) to a data distribution. At the core of G$^2$M$^2$ is the introduction of an integral cosine similarity (ICS) function for comparing the UGMF and the unknown data density distribution without having to explicitly estimate it. By maximizing the ICS through Monte Carlo sampling, the UGMF can be made to overlap with the unknown data density distribution such that the two only differ by a constant scalar, and the UGMF can be normalized to obtain the data density distribution. A Siamese convolutional neural network is also designed for optimizing the ICS function. Experimental results show that our method is more competitive in modeling data having correlations that may lead to singular covariance matrices in GMM, and it outperforms state-of-the-art methods in unsupervised anomaly detection. Keywords: Machine Learning: Unsupervised Learning Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Guanglin Li and Bin Li and Changsheng Chen and Shunquan Tan and Guoping Qiu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/444},
  pages     = {3201-3207},
  title     = {Learning general gaussian mixture model with integral cosine similarity},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SGAT: Simplicial graph attention network. <em>IJCAI</em>,
3192–3200. (<a href="https://doi.org/10.24963/ijcai.2022/443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Heterogeneous graphs have multiple node and edge types and are semantically richer than homogeneous graphs. To learn such complex semantics, many graph neural network approaches for heterogeneous graphs use metapaths to capture multi-hop interactions between nodes. Typically, features from non-target nodes are not incorporated into the learning procedure. However, there can be nonlinear, high-order interactions involving multiple nodes or edges. In this paper, we present Simplicial Graph Attention Network (SGAT), a simplicial complex approach to represent such high-order interactions by placing features from non-target nodes on the simplices. We then use attention mechanisms and upper adjacencies to generate representations. We empirically demonstrate the efficacy of our approach with node classification tasks on heterogeneous graph datasets and further show SGAT&#39;s ability in extracting structural information by employing random node features. Numerical experiments indicate that SGAT performs better than other current state-of-the-art heterogeneous graph learning methods. Keywords: Machine Learning: Sequence and Graph Learning Data Mining: Mining Graphs Data Mining: Mining Heterogenous Data Machine Learning: Classification Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {See Hian Lee and Feng Ji and Wee Peng Tay},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/443},
  pages     = {3192-3200},
  title     = {SGAT: Simplicial graph attention network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Libra-CAM: An activation-based attribution based on the
linear approximation of deep neural nets and threshold calibration.
<em>IJCAI</em>, 3185–3191. (<a
href="https://doi.org/10.24963/ijcai.2022/442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Universal application of AI has increased the need to explain why an AI model makes a specific decision in a human-understandable form. Among many related works, the class activation map (CAM)-based methods have been successful recently, creating input attribution based on the weighted sum of activation maps in convolutional neural networks. However, existing methods use channel-wise importance weights with specific architectural assumptions, relying on arbitrarily chosen attribution threshold values in their quality assessment: we think these can degrade the quality of attribution. In this paper, we propose Libra-CAM, a new CAM-style attribution method based on the best linear approximation of the layer (as a function) between the penultimate activation and the target-class score output. From the approximation, we derive the base formula of Libra-CAM, which is applied with multiple reference activations from a pre-built library. We construct Libra-CAM by averaging these base attribution maps, taking a threshold calibration procedure to optimize its attribution quality. Our experiments show that Libra-CAM can be computed in a reasonable time and is superior to the existing attribution methods in quantitative and qualitative attribution quality evaluations. Keywords: Machine Learning: Explainable/Interpretable Machine Learning Computer Vision: Interpretability and Transparency AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Sangkyun Lee and Sungmin Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/442},
  pages     = {3185-3191},
  title     = {Libra-CAM: An activation-based attribution based on the linear approximation of deep neural nets and threshold calibration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Pseudo-spherical knowledge distillation. <em>IJCAI</em>,
3178–3184. (<a href="https://doi.org/10.24963/ijcai.2022/441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation aims to transfer the information by minimizing the cross-entropy between the probabilistic outputs of the teacher and student network. In this work, we propose an alternative distillation objective by maximizing the scoring rule, which quantitatively measures the agreement of a distribution to the reference distribution. We demonstrate that the proper and homogeneous scoring rule exhibits more preferable properties for distillation than the original cross entropy based approach. To that end, we present an efficient implementation of the distillation objective based on a pseudo-spherical scoring rule, which is a family of proper and homogeneous scoring rules. We refer to it as pseudo-spherical knowledge distillation. Through experiments on various model compression tasks, we validate the effectiveness of our method by showing its superiority over the original knowledge distillation. Moreover, together with structural distillation methods such as contrastive representation distillation, we achieve state of the art results in CIFAR100 benchmarks. Keywords: Machine Learning: Probabilistic Machine Learning},
  archive   = {C_IJCAI},
  author    = {Kyungmin Lee and Hyeongkeun Lee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/441},
  pages     = {3178-3184},
  title     = {Pseudo-spherical knowledge distillation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-policy grounding and ensemble policy learning for
transfer learning with dynamics mismatch. <em>IJCAI</em>, 3171–3177. (<a
href="https://doi.org/10.24963/ijcai.2022/440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new transfer learning algorithm between tasks with different dynamics. The proposed algorithm solves an Imitation from Observation problem (IfO) to ground the source environment to the target task before learning an optimal policy in the grounded environment. The learned policy is deployed in the target task without additional training. A particular feature of our algorithm is the employment of multiple rollout policies during training with a goal to ground the environment more globally; hence, it is named as Multi-Policy Grounding (MPG). The quality of final policy is further enhanced via ensemble policy learning. We demonstrate the superiority of the proposed algorithm analytically and numerically. Numerical studies show that the proposed multi-policy approach allows comparable grounding with single policy approach with a fraction of target samples, hence the algorithm is able to maintain the quality of obtained policy even as the number of interactions with the target environment becomes extremely small. Keywords: Machine Learning: Multi-task and Transfer Learning Machine Learning: Deep Reinforcement Learning Machine Learning: Ensemble Methods Machine Learning: Generative Adverserial Networks Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Hyun-Rok Lee and Ram Ananth Sreenivasan and Yeonjeong Jeong and Jongseong Jang and Dongsub Shim and Chi-Guhn Lee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/440},
  pages     = {3171-3177},
  title     = {Multi-policy grounding and ensemble policy learning for transfer learning with dynamics mismatch},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Thompson sampling for bandit learning in matching markets.
<em>IJCAI</em>, 3164–3170. (<a
href="https://doi.org/10.24963/ijcai.2022/439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of two-sided matching markets has a wide range of real-world applications and has been extensively studied in the literature. A line of recent works have focused on the problem setting where the preferences of one-side market participants are unknown a priori and are learned by iteratively interacting with the other side of participants. All these works are based on explore-then-commit (ETC) and upper confidence bound (UCB) algorithms, two common strategies in multi-armed bandits (MAB). Thompson sampling (TS) is another popular approach, which attracts lots of attention due to its easier implementation and better empirical performances. In many problems, even when UCB and ETC-type algorithms have already been analyzed, researchers are still trying to study TS for its benefits. However, the convergence analysis of TS is much more challenging and remains open in many problem settings. In this paper, we provide the first regret analysis for TS in the new setting of iterative matching markets. Extensive experiments demonstrate the practical advantages of the TS-type algorithm over the ETC and UCB-type baselines. Keywords: Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Fang Kong and Junming Yin and Shuai Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/439},
  pages     = {3164-3170},
  title     = {Thompson sampling for bandit learning in matching markets},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DyGRAIN: An incremental learning framework for dynamic
graphs. <em>IJCAI</em>, 3157–3163. (<a
href="https://doi.org/10.24963/ijcai.2022/438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-structured data provide a powerful representation of complex relations or interactions. Many variants of graph neural networks (GNNs) have emerged to learn graph-structured data where underlying graphs are static, although graphs in various real-world applications are dynamic (e.g., evolving structure). To consider the dynamic nature that a graph changes over time, the need for applying incremental learning (i.e., continual learning or lifelong learning) to the graph domain has been emphasized. However, unlike incremental learning on Euclidean data, graph-structured data contains dependency between the existing nodes and newly appeared nodes, resulting in the phenomenon that receptive fields of existing nodes vary by new inputs (e.g., nodes and edges). In this paper, we raise a crucial challenge of incremental learning for dynamic graphs as time-varying receptive fields, and propose a novel incremental learning framework, DyGRAIN, to mitigate time-varying receptive fields and catastrophic forgetting. Specifically, our proposed method incrementally learns dynamic graph representations by reflecting the influential change in receptive fields of existing nodes and maintaining previous knowledge of informational nodes prone to be forgotten. Our experiments on large-scale graph datasets demonstrate that our proposed method improves the performance by effectively capturing pivotal nodes and preventing catastrophic forgetting. Keywords: Machine Learning: Sequence and Graph Learning Data Mining: Mining Graphs Machine Learning: Incremental Learning},
  archive   = {C_IJCAI},
  author    = {Seoyoon Kim and Seongjun Yun and Jaewoo Kang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/438},
  pages     = {3157-3163},
  title     = {DyGRAIN: An incremental learning framework for dynamic graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-predictive dynamics for generalization of vision-based
reinforcement learning. <em>IJCAI</em>, 3150–3156. (<a
href="https://doi.org/10.24963/ijcai.2022/437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision-based reinforcement learning requires efficient and robust representations of image-based observations, especially when the images contain distracting (task-irrelevant) elements such as shadows, clouds, and light. It becomes more important if those distractions are not exposed during training. We design a Self-Predictive Dynamics (SPD) method to extract task-relevant features efficiently, even in unseen observations after training. SPD uses weak and strong augmentations in parallel, and learns representations by predicting inverse and forward transitions across the two-way augmented versions. In a set of MuJoCo visual control tasks and an autonomous driving task (CARLA), SPD outperforms previous studies in complex observations, and significantly improves the generalization performance for unseen observations. Our code is available at https://github.com/unigary/SPD. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Representation learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Kyungsoo Kim and Jeongsoo Ha and Yusung Kim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/437},
  pages     = {3150-3156},
  title     = {Self-predictive dynamics for generalization of vision-based reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data augmentation for learning to play in text-based games.
<em>IJCAI</em>, 3143–3149. (<a
href="https://doi.org/10.24963/ijcai.2022/436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving generalization in text-based games serves as a useful stepping-stone towards reinforcement learning (RL) agents with generic linguistic ability. Data augmentation for generalization in RL has shown to be very successful in classic control and visual tasks, but there is no prior work for text-based games. We propose Transition-Matching Permutation, a novel data augmentation technique for text-based games, where we identify phrase permutations that match as many transitions in the trajectory data. We show that applying this technique results in state-of-the-art performance in the Cooking Game benchmark suite for text-based games. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Deep Reinforcement Learning Natural Language Processing: Other Planning and Scheduling: POMDPs},
  archive   = {C_IJCAI},
  author    = {Jinhyeon Kim and Kee-Eung Kim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/436},
  pages     = {3143-3149},
  title     = {Data augmentation for learning to play in text-based games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Relational abstractions for generalized reinforcement
learning on symbolic problems. <em>IJCAI</em>, 3135–3142. (<a
href="https://doi.org/10.24963/ijcai.2022/435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning in problems with symbolic state spaces is challenging due to the need for reasoning over long horizons. This paper presents a new approach that utilizes relational abstractions in conjunction with deep learning to learn a generalizable Q-function for such problems. The learned Q-function can be efficiently transferred to related problems that have different object names and object quantities, and thus, entirely different state spaces. We show that the learned, generalized Q-function can be utilized for zero-shot transfer to related problems without an explicit, hand-coded curriculum. Empirical evaluations on a range of problems show that our method facilitates efficient zero-shot transfer of learned knowledge to much larger problem instances containing many objects. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Deep Reinforcement Learning Planning and Scheduling: Learning in Planning and Scheduling Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Rushang Karia and Siddharth Srivastava},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/435},
  pages     = {3135-3142},
  title     = {Relational abstractions for generalized reinforcement learning on symbolic problems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Set interdependence transformer: Set-to-sequence neural
networks for permutation learning and structure prediction.
<em>IJCAI</em>, 3128–3134. (<a
href="https://doi.org/10.24963/ijcai.2022/434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The task of learning to map an input set onto a permuted sequence of its elements is challenging for neural networks. Set-to-sequence problems occur in natural language processing, computer vision and structure prediction, where interactions between elements of large sets define the optimal output. Models must exhibit relational reasoning, handle varying cardinalities and manage combinatorial complexity. Previous attention-based methods require n layers of their set transformations to explicitly represent n-th order relations. Our aim is to enhance their ability to efficiently model higher-order interactions through an additional interdependence component. We propose a novel neural set encoding method called the Set Interdependence Transformer, capable of relating the set&#39;s permutation invariant representation to its elements within sets of any cardinality. We combine it with a permutation learning module into a complete, 3-part set-to-sequence model and demonstrate its state-of-the-art performance on a number of tasks. These range from combinatorial optimization problems, through permutation learning challenges on both synthetic and established NLP datasets for sentence ordering, to a novel domain of product catalog structure prediction. Additionally, the network&#39;s ability to generalize to unseen sequence lengths is investigated and a comparative empirical analysis of the existing methods&#39; ability to learn higher-order interactions is provided. Keywords: Machine Learning: Structured Prediction Machine Learning: Attention Models Machine Learning: Relational Learning Machine Learning: Sequence and Graph Learning Natural Language Processing: Other},
  archive   = {C_IJCAI},
  author    = {Mateusz Jurewicz and Leon Derczynski},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/434},
  pages     = {3128-3134},
  title     = {Set interdependence transformer: Set-to-sequence neural networks for permutation learning and structure prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online evasion attacks on recurrent models: The power of
hallucinating the future. <em>IJCAI</em>, 3121–3127. (<a
href="https://doi.org/10.24963/ijcai.2022/433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recurrent models are frequently being used in online tasks such as autonomous driving, and a comprehensive study of their vulnerability is called for. Existing research is limited in generality only addressing application-specific vulnerability or making implausible assumptions such as the knowledge of future input. In this paper, we present a general attack framework for online tasks incorporating the unique constraints of the online setting different from offline tasks. Our framework is versatile in that it covers time-varying adversarial objectives and various optimization constraints, allowing for a comprehensive study of robustness. Using the framework, we also present a novel white-box attack called Predictive Attack that `hallucinates&#39; the future. The attack achieves 98 percent of the performance of the ideal but infeasible clairvoyant attack on average. We validate the effectiveness of the proposed framework and attacks through various experiments. Keywords: Machine Learning: Adversarial Machine Learning Computer Vision: Adversarial learning, adversarial attack and defense methods Machine Learning: Recurrent Networks Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Byunggill Joe and Insik Shin and Jihun Hamm},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/433},
  pages     = {3121-3127},
  title     = {Online evasion attacks on recurrent models: The power of hallucinating the future},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Graph masked autoencoder enhanced predictor for neural
architecture search. <em>IJCAI</em>, 3114–3120. (<a
href="https://doi.org/10.24963/ijcai.2022/432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Performance estimation of neural architecture is a crucial component of neural architecture search (NAS). Meanwhile, neural predictor is a current mainstream performance estimation method. However, it is a challenging task to train the predictor with few architecture evaluations for efficient NAS. In this paper, we propose a graph masked autoencoder (GMAE) enhanced predictor, which can reduce the dependence on supervision data by self-supervised pre-training with untrained architectures. We compare our GMAE-enhanced predictor with existing predictors in different search spaces, and experimental results show that our predictor has high query utilization. Moreover, GMAE-enhanced predictor with different search strategies can discover competitive architectures in different search spaces. Code and supplementary materials are available at https://github.com/kunjing96/GMAENAS.git. Keywords: Machine Learning: Automated Machine Learning Computer Vision: Recognition (object detection, categorization) Machine Learning: Learning Graphical Models Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Kun Jing and Jungang Xu and Pengfei Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/432},
  pages     = {3114-3120},
  title     = {Graph masked autoencoder enhanced predictor for neural architecture search},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the channel pruning using graph convolution network for
convolutional neural network acceleration. <em>IJCAI</em>, 3107–3113.
(<a href="https://doi.org/10.24963/ijcai.2022/431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network pruning is considered efficient for sparsification and acceleration of Convolutional Neural Network (CNN) based models that can be adopted in re-source-constrained environments. Inspired by two popular pruning criteria, i.e. magnitude and similarity, this paper proposes a novel structural pruning method based on Graph Convolution Network (GCN) to further promote compression performance. The channel features are firstly extracted by Global Average Pooling (GAP) from a batch of samples, and a graph model for each layer is generated based on the similarity of features. A set of agents for individual CNN layers are implemented by GCN and utilized to synthesize comprehensive channel information and determine the pruning scheme for the overall CNN model. The training process of each agent is carried out using Reinforcement Learning (RL) to ensure their convergence and adaptability to various network architectures. The proposed solution is assessed based on a range of image classification datasets i.e., CIFAR and Tiny-ImageNet. The numerical results indicate that the proposed pruning method outperforms the pure magnitude-based or similarity-based pruning solutions and other SOTA methods (e.g., HRank and SCP). For example, the proposed method can prune VGG16 by removing 93\% of the model parameters without any accuracy reduction in the CIFAR10 dataset. Keywords: Machine Learning: Learning Sparse Models Machine Learning: Learning Graphical Models Machine Learning: Deep Reinforcement Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Di Jiang and Yuan Cao and Qiang Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/431},
  pages     = {3107-3113},
  title     = {On the channel pruning using graph convolution network for convolutional neural network acceleration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust reinforcement learning as a stackelberg game via
adaptively-regularized adversarial training. <em>IJCAI</em>, 3099–3106.
(<a href="https://doi.org/10.24963/ijcai.2022/430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Robust Reinforcement Learning (RL) focuses on improving performances under model errors or adversarial attacks, which facilitates the real-life deployment of RL agents. Robust Adversarial Reinforcement Learning (RARL) is one of the most popular frameworks for robust RL. However, most of the existing literature models RARL as a zero-sum simultaneous game with Nash equilibrium as the solution concept, which could overlook the sequential nature of RL deployments, produce overly conservative agents, and induce training instability. In this paper, we introduce a novel hierarchical formulation of robust RL -- a general-sum Stackelberg game model called RRL-Stack -- to formalize the sequential nature and provide extra flexibility for robust training. We develop the Stackelberg Policy Gradient algorithm to solve RRL-Stack, leveraging the Stackelberg learning dynamics by considering the adversary&#39;s response. Our method generates challenging yet solvable adversarial environments which benefit RL agents&#39; robust learning. Our algorithm demonstrates better training stability and robustness against different testing conditions in the single-agent robotics control and multi-agent highway merging tasks. Keywords: Machine Learning: Deep Reinforcement Learning Agent-based and Multi-agent Systems: Multi-agent Learning Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Peide Huang and Mengdi Xu and Fei Fang and Ding Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/430},
  pages     = {3099-3106},
  title     = {Robust reinforcement learning as a stackelberg game via adaptively-regularized adversarial training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FLS: A new local search algorithm for k-means with smaller
search space. <em>IJCAI</em>, 3092–3098. (<a
href="https://doi.org/10.24963/ijcai.2022/429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The k-means problem is an extensively studied unsupervised learning problem with various applications in decision making and data mining. In this paper, we propose a fast and practical local search algorithm for the k-means problem. Our method reduces the search space of swap pairs from O(nk) to O(k^2), and applies random mutations to find potentially better solutions when local search falls into poor local optimum. With the assumption of data distribution that each optimal cluster has &quot;average&quot; size of \Omega(n/k), which is common in many datasets and k-means benchmarks, we prove that our proposed algorithm gives a (100+\epsilon)-approximate solution in expectation. Empirical experiments show that our algorithm achieves better performance compared to existing state-of-the-art local search methods on k-means benchmarks and large datasets. Keywords: Machine Learning: Clustering Search: Applications Search: Combinatorial Search and Optimisation Search: Heuristic Search Search: Local search},
  archive   = {C_IJCAI},
  author    = {Junyu Huang and Qilong Feng and Ziyun Huang and Jinhui Xu and Jianxin Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/429},
  pages     = {3092-3098},
  title     = {FLS: A new local search algorithm for K-means with smaller search space},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconstructing diffusion networks from incomplete data.
<em>IJCAI</em>, 3085–3091. (<a
href="https://doi.org/10.24963/ijcai.2022/428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To reconstruct the topology of a diffusion network, existing approaches customarily demand not only eventual infection statuses of nodes, but also the exact times when infections occur. In real-world settings, such as the spread of epidemics, tracing the exact infection times is often infeasible; even obtaining the eventual infection statuses of all nodes is a challenging task. In this work, we study topology reconstruction of a diffusion network with incomplete observations of the node infection statuses. To this end, we iteratively infer the network topology based on observed infection statuses and estimated values for unobserved infection statuses by investigating the correlation of node infections, and learn the most probable probabilities of the infection propagations among nodes w.r.t. current inferred topology, as well as the corresponding probability distribution of each unobserved infection status, which in turn helps update the estimate of unobserved data. Extensive experimental results on both synthetic and real-world networks verify the effectiveness and efficiency of our approach. Keywords: Machine Learning: Relational Learning Machine Learning: Learning Graphical Models},
  archive   = {C_IJCAI},
  author    = {Hao Huang and Keqi Han and Beicheng Xu and Ting Gan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/428},
  pages     = {3085-3091},
  title     = {Reconstructing diffusion networks from incomplete data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Type-aware embeddings for multi-hop reasoning over knowledge
graphs. <em>IJCAI</em>, 3078–3084. (<a
href="https://doi.org/10.24963/ijcai.2022/427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-hop reasoning over real-life knowledge graphs (KGs) is a highly challenging problem as traditional subgraph matching methods are not capable to deal with noise and missing information. Recently, to address this problem a promising approach based on jointly embedding logical queries and KGs into a low-dimensional space to identify answer entities has emerged. However, existing proposals ignore critical semantic knowledge inherently available in KGs, such as type information. To leverage type information, we propose a novel type-aware model, TypE-aware Message Passing (TEMP), which enhances the entity and relation representation in queries, and simultaneously improves generalization, and deductive and inductive reasoning. Remarkably, TEMP is a plug-and-play model that can be easily incorporated into existing embedding-based models to improve their performance. Extensive experiments on three real-world datasets demonstrate TEMP’s effectiveness. Keywords: Machine Learning: Knowledge Aided Learning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Zhiwei Hu and Victor Gutierrez Basulto and Zhiliang Xiang and Xiaoli Li and Ru Li and Jeff Z. Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/427},
  pages     = {3078-3084},
  title     = {Type-aware embeddings for multi-hop reasoning over knowledge graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing unsupervised domain adaptation via semantic
similarity constraint for medical image segmentation. <em>IJCAI</em>,
3071–3077. (<a href="https://doi.org/10.24963/ijcai.2022/426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work proposes a novel unsupervised cross-modality adaptive segmentation method for medical images to tackle the performance degradation caused by the severe domain shift when neural networks are being deployed to unseen modalities. The proposed method is an end-2-end framework, which conducts appearance transformation via a domain-shared shallow content encoder and two domain-specific decoders. The feature extracted from the encoder is enhanced to be more domain-invariant by a similarity learning task using the proposed Semantic Similarity Mining (SSM) module which has a strong help of domain adaptation. The domain-invariant latent feature is then fused into the target domain segmentation sub-network, trained using the original target domain images and the translated target images from the source domain in the framework of adversarial training. The adversarial training is effective to narrow the remaining gap between domains in semantic space after appearance alignment. Experimental results on two challenging datasets demonstrate that our method outperforms the state-of-the-art approaches. Keywords: Machine Learning: Multi-modal learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Tao Hu and Shiliang Sun and Jing Zhao and Dongyu Shi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/426},
  pages     = {3071-3077},
  title     = {Enhancing unsupervised domain adaptation via semantic similarity constraint for medical image segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SHAPE: An unified approach to evaluate the contribution and
cooperation of individual modalities. <em>IJCAI</em>, 3064–3070. (<a
href="https://doi.org/10.24963/ijcai.2022/425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As deep learning advances, there is an ever-growing demand for models capable of synthesizing information from multi-modal resources to address the complex tasks raised from real-life applications. Recently, many large multi-modal datasets have been collected, on which researchers actively explore different methods of fusing multi-modal information. However, little attention has been paid to quantifying the contribution of different modalities within the proposed models. In this paper, we propose the SHapley vAlue-based PErceptual (SHAPE) scores that measure the marginal contribution of individual modalities and the degree of cooperation across modalities. Using these scores, we systematically evaluate different fusion methods on different multi-modal datasets for different tasks. Our experiments suggest that for some tasks where different modalities are complementary, the multi-modal models still tend to use the dominant modality alone and ignore the cooperation across modalities. On the other hand, models learn to exploit cross-modal cooperation when different modalities are indispensable for the task. In this case, the scores indicate it is better to fuse different modalities at relatively early stages. We hope our scores can help improve the understanding of how the present multi-modal models operate on different modalities and encourage more sophisticated methods of integrating multiple modalities. Keywords: Machine Learning: Evaluation Machine Learning: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Pengbo Hu and Xingyu Li and Yi Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/425},
  pages     = {3064-3070},
  title     = {SHAPE: An unified approach to evaluate the contribution and cooperation of individual modalities},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning continuous graph structure with bilevel programming
for graph neural networks. <em>IJCAI</em>, 3057–3063. (<a
href="https://doi.org/10.24963/ijcai.2022/424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning graph structure for graph neural networks (GNNs) is crucial to facilitate the GNN-based downstream learning tasks. It is challenging due to the non-differentiable discrete graph structure and lack of ground-truth. In this paper, we address these problems and propose a novel graph structure learning framework for GNNs. Firstly, we directly model the continuous graph structure with dual-normalization, which implicitly imposes sparse constraint and reduces the influence of noisy edges. Secondly, we formulate the whole training process as a bilevel programming problem, where the inner objective is to optimize the GNNs given learned graphs, while the outer objective is to optimize the graph structure to minimize the generalization error of downstream task. Moreover, for bilevel optimization, we propose an improved Neumann-IFT algorithm to obtain an approximate solution, which is more stable and accurate than existing optimization methods. Besides, it makes the bilevel optimization process memory-efficient and scalable to large graphs. Experiments on node classification and scene graph generation show that our method can outperform related methods, especially with noisy graphs. Keywords: Machine Learning: Hyperparameter Optimization Computer Vision: Scene analysis and understanding Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Minyang Hu and Hong Chang and Bingpeng Ma and Shiguang Shan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/424},
  pages     = {3057-3063},
  title     = {Learning continuous graph structure with bilevel programming for graph neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Leveraging class abstraction for commonsense reinforcement
learning via residual policy gradient methods. <em>IJCAI</em>,
3050–3056. (<a href="https://doi.org/10.24963/ijcai.2022/423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Enabling reinforcement learning (RL) agents to leverage a knowledge base while learning from experience promises to advance RL in knowledge intensive domains. However, it has proven difficult to leverage knowledge that is not manually tailored to the environment. We propose to use the subclass relationships present in open-source knowledge graphs to abstract away from specific objects. We develop a residual policy gradient method that is able to integrate knowledge across different abstraction levels in the class hierarchy. Our method results in improved sample efficiency and generalisation to unseen objects in commonsense games, but we also investigate failure modes, such as excessive noise in the extracted class knowledge or environments with little class structure. Keywords: Machine Learning: Deep Reinforcement Learning Knowledge Representation and Reasoning: Common-Sense Reasoning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Niklas Hopner and Ilaria Tiddi and Herke van Hoof},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/423},
  pages     = {3050-3056},
  title     = {Leveraging class abstraction for commonsense reinforcement learning via residual policy gradient methods},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To trust or not to trust prediction scores for membership
inference attacks. <em>IJCAI</em>, 3043–3049. (<a
href="https://doi.org/10.24963/ijcai.2022/422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Membership inference attacks (MIAs) aim to determine whether a specific sample was used to train a predictive model. Knowing this may indeed lead to a privacy breach. Most MIAs, however, make use of the model&#39;s prediction scores - the probability of each output given some input - following the intuition that the trained model tends to behave differently on its training data. We argue that this is a fallacy for many modern deep network architectures. Consequently, MIAs will miserably fail since overconfidence leads to high false-positive rates not only on known domains but also on out-of-distribution data and implicitly acts as a defense against MIAs. Specifically, using generative adversarial networks, we are able to produce a potentially infinite number of samples falsely classified as part of the training data. In other words, the threat of MIAs is overestimated, and less information is leaked than previously assumed. Moreover, there is actually a trade-off between the overconfidence of models and their susceptibility to MIAs: the more classifiers know when they do not know, making low confidence predictions, the more they reveal the training data. Keywords: Machine Learning: Other Computer Vision: Bias, Fairness &amp; Privacy Machine Learning: Adversarial Machine Learning Machine Learning: Evaluation},
  archive   = {C_IJCAI},
  author    = {Dominik Hintersdorf and Lukas Struppek and Kristian Kersting},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/422},
  pages     = {3043-3049},
  title     = {To trust or not to trust prediction scores for membership inference attacks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Option transfer and SMDP abstraction with successor
features. <em>IJCAI</em>, 3036–3042. (<a
href="https://doi.org/10.24963/ijcai.2022/421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstraction plays an important role in the generalisation of knowledge and skills and is key to sample efficient learning. In this work, we study joint temporal and state abstraction in reinforcement learning, where temporally-extended actions in the form of options induce temporal abstractions, while aggregation of similar states with respect to abstract options induces state abstractions. Many existing abstraction schemes ignore the interplay of state and temporal abstraction. Consequently, the considered option policies often cannot be directly transferred to new environments due to changes in the state space and transition dynamics. To address this issue, we propose a novel abstraction scheme building on successor features. This includes an algorithm for transferring abstract options across different environments and a state abstraction mechanism that allows us to perform efficient planning with the transferred options. Keywords: Machine Learning: Reinforcement Learning Planning and Scheduling: Hierarchical Planning},
  archive   = {C_IJCAI},
  author    = {Dongge Han and Sebastian Tschiatschek},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/421},
  pages     = {3036-3042},
  title     = {Option transfer and SMDP abstraction with successor features},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RoboGNN: Robustifying node classification under link
perturbation. <em>IJCAI</em>, 3029–3035. (<a
href="https://doi.org/10.24963/ijcai.2022/420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have emerged as powerful approaches for graph representation learning and node classification. Nevertheless, they can be vulnerable (sensitive) to link perturbations due to structural noise or adversarial attacks. This paper introduces RoboGNN, a novel framework that simultaneously robustifies an input classifier to a counterpart with certifiable robustness, and suggests desired graph representation with auxiliary links to ensure the robustness guarantee. (1) We introduce (p, θ)-robustness, which characterizes the robustness guarantee of a GNN-based classifier if its performance is insensitive for at least θ fraction of a targeted set of nodes under any perturbation of a set of vulnerable links up to a bounded size p. (2) We present a co-learning framework that interacts model learning with graph structural learning to robustify an input model M to a (p, θ)-robustness counterpart. The framework also outputs the desired graph structures that ensure the robustness. Using real-world benchmark graphs, we experimentally verify that roboGNN can effectively robustify representative GNNs with guaranteed robustness, and desirable gains on accuracy. Keywords: Machine Learning: Classification Machine Learning: Adversarial Machine Learning Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Sheng Guan and Hanchao Ma and Yinghui Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/420},
  pages     = {3029-3035},
  title     = {RoboGNN: Robustifying node classification under link perturbation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Sample complexity bounds for robustly learning decision
lists against evasion attacks. <em>IJCAI</em>, 3022–3028. (<a
href="https://doi.org/10.24963/ijcai.2022/419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A fundamental problem in adversarial machine learning is to quantify how much training data is needed in the presence of evasion attacks. In this paper we address this issue within the framework of PAC learning, focusing on the class of decision lists. Given that distributional assumptions are essential in the adversarial setting, we work with probability distributions on the input data that satisfy a Lipschitz condition: nearby points have similar probability. Our key results illustrate that the adversary&#39;s budget (that is, the number of bits it can perturb on each input) is a fundamental quantity in determining the sample complexity of robust learning. Our first main result is a sample-complexity lower bound: the class of monotone conjunctions (essentially the simplest non-trivial hypothesis class on the Boolean hypercube) and any superclass has sample complexity at least exponential in the adversary&#39;s budget. Our second main result is a corresponding upper bound: for every fixed k the class of k-decision lists has polynomial sample complexity against a log(n)-bounded adversary. This sheds further light on the question of whether an efficient PAC learning algorithm can always be used as an efficient log(n)-robust learning algorithm under the uniform distribution. Keywords: Machine Learning: Learning Theory Machine Learning: Adversarial Machine Learning Machine Learning: Classification Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Pascale Gourdeau and Varun Kanade and Marta Kwiatkowska and James Worrell},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/419},
  pages     = {3022-3028},
  title     = {Sample complexity bounds for robustly learning decision lists against evasion attacks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attributed graph clustering with dual redundancy reduction.
<em>IJCAI</em>, 3015–3021. (<a
href="https://doi.org/10.24963/ijcai.2022/418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Attributed graph clustering is a basic yet essential method for graph data exploration. Recent efforts over graph contrastive learning have achieved impressive clustering performance. However, we observe that the commonly adopted InfoMax operation tends to capture redundant information, limiting the downstream clustering performance. To this end, we develop a novel method termed attributed graph clustering with dual redundancy reduction (AGC-DRR) to reduce the information redundancy in both input space and latent feature space. Specifically, for the input space redundancy reduction, we introduce an adversarial learning mechanism to adaptively learn a redundant edge-dropping matrix to ensure the diversity of the compared sample pairs. To reduce the redundancy in the latent space, we force the correlation matrix of the cross-augmentation sample embedding to approximate an identity matrix. Consequently, the learned network is forced to be robust against perturbation while discriminative against different samples. Extensive experiments have demonstrated that AGC-DRR outperforms the state-of-the-art clustering methods on most of our benchmarks. The corresponding code is available at https://github.com/gongleii/AGC-DRR. Keywords: Machine Learning: Clustering Machine Learning: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Lei Gong and Sihang Zhou and Wenxuan Tu and Xinwang Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/418},
  pages     = {3015-3021},
  title     = {Attributed graph clustering with dual redundancy reduction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning first-order rules with differentiable logic program
semantics. <em>IJCAI</em>, 3008–3014. (<a
href="https://doi.org/10.24963/ijcai.2022/417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning first-order logic programs (LPs) from relational facts which yields intuitive insights into the data is a challenging topic in neuro-symbolic research. We introduce a novel differentiable inductive logic programming (ILP) model, called differentiable first-order rule learner (DFOL), which finds the correct LPs from relational facts by searching for the interpretable matrix representations of LPs. These interpretable matrices are deemed as trainable tensors in neural networks (NNs). The NNs are devised according to the differentiable semantics of LPs. Specifically, we first adopt a novel propositionalization method that transfers facts to NN-readable vector pairs representing interpretation pairs. We replace the immediate consequence operator with NN constraint functions consisting of algebraic operations and a sigmoid-like activation function. We map the symbolic forward-chained format of LPs into NN constraint functions consisting of operations between subsymbolic vector representations of atoms. By applying gradient descent, the trained well parameters of NNs can be decoded into precise symbolic LPs in forward-chained logic format. We demonstrate that DFOL can perform on several standard ILP datasets, knowledge bases, and probabilistic relation facts and outperform several well-known differentiable ILP models. Experimental results indicate that DFOL is a precise, robust, scalable, and computationally cheap differentiable ILP model. Keywords: Machine Learning: Relational Learning Knowledge Representation and Reasoning: Learning and reasoning Machine Learning: Neuro-Symbolic Methods},
  archive   = {C_IJCAI},
  author    = {Kun Gao and Katsumi Inoue and Yongzhi Cao and Hanpin Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/417},
  pages     = {3008-3014},
  title     = {Learning first-order rules with differentiable logic program semantics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bootstrapping informative graph augmentation via a meta
learning approach. <em>IJCAI</em>, 3001–3007. (<a
href="https://doi.org/10.24963/ijcai.2022/416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent works explore learning graph representations in a self-supervised manner. In graph contrastive learning, benchmark methods apply various graph augmentation approaches. However, most of the augmentation methods are non-learnable, which causes the issue of generating unbeneficial augmented graphs. Such augmentation may degenerate the representation ability of graph contrastive learning methods. Therefore, we motivate our method to generate augmented graph with a learnable graph augmenter, called MEta Graph Augmentation (MEGA). We then clarify that a &quot;good&quot; graph augmentation must have uniformity at the instance-level and informativeness at the feature-level. To this end, we propose a novel approach to learning a graph augmenter that can generate an augmentation with uniformity and informativeness. The objective of the graph augmenter is to promote our feature extraction network to learn a more discriminative feature representation, which motivates us to propose a meta-learning paradigm. Empirically, the experiments across multiple benchmark datasets demonstrate that MEGA outperforms the state-of-the-art methods in graph self-supervised learning tasks. Further experimental studies prove the effectiveness of different terms of MEGA. Our codes are available at https://github.com/hang53/MEGA. Keywords: Machine Learning: Self-supervised Learning Machine Learning: Meta-Learning Machine Learning: Representation learning Machine Learning: Sequence and Graph Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Hang Gao and Jiangmeng Li and Wenwen Qiang and Lingyu Si and Fuchun Sun and Changwen Zheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/416},
  pages     = {3001-3007},
  title     = {Bootstrapping informative graph augmentation via a meta learning approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A reinforcement learning-informed pattern mining framework
for multivariate time series classification. <em>IJCAI</em>, 2994–3000.
(<a href="https://doi.org/10.24963/ijcai.2022/415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time series (MTS) classification is a challenging and important task in various domains and real-world applications. Much of prior work on MTS can be roughly divided into neural network (NN)- and pattern-based methods. The former can lead to robust classification performance, but many of the generated patterns are challenging to interpret; while the latter often produce interpretable patterns that may not be helpful for the classification task. In this work, we propose a reinforcement learning (RL) informed PAttern Mining framework (RLPAM) to identify interpretable yet important patterns for MTS classification. Our framework has been validated by 30 benchmark datasets as well as real-world large-scale electronic health records (EHRs) for an extremely challenging task: sepsis shock early prediction. We show that RLPAM outperforms the state-of-the-art NN-based methods on 14 out of 30 datasets as well as on the EHRs. Finally, we show how RL informed patterns can be interpretable and can improve our understanding of septic shock progression. Keywords: Machine Learning: Classification Machine Learning: Deep Reinforcement Learning Machine Learning: Time-series; Data Streams Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Ge Gao and Qitong Gao and Xi Yang and Miroslav Pajic and Min Chi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/415},
  pages     = {2994-3000},
  title     = {A reinforcement learning-informed pattern mining framework for multivariate time series classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view unsupervised graph representation learning.
<em>IJCAI</em>, 2987–2993. (<a
href="https://doi.org/10.24963/ijcai.2022/414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both data augmentation and contrastive loss are the key components of contrastive learning. In this paper, we design a new multi-view unsupervised graph representation learning method including adaptive data augmentation and multi-view contrastive learning, to address some issues of contrastive learning ignoring the information from feature space. Specifically, the adaptive data augmentation first builds a feature graph from the feature space, and then designs a deep graph learning model on the original representation and the topology graph to update the feature graph and the new representation. As a result, the adaptive data augmentation outputs multi-view information, which is fed into two GCNs to generate multi-view embedding features. Two kinds of contrastive losses are further designed on multi-view embedding features to explore the complementary information among the topology and feature graphs. Additionally, adaptive data augmentation and contrastive learning are embedded in a unified framework to form an end-to-end model. Experimental results verify the effectiveness of our proposed method, compared to state-of-the-art methods. Keywords: Machine Learning: Unsupervised Learning Machine Learning: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Jiangzhang Gan and Rongyao Hu and Mengmeng Zhan and Yujie Mo and Yingying Wan and Xiaofeng Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/414},
  pages     = {2987-2993},
  title     = {Multi-view unsupervised graph representation learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DeepExtrema: A deep learning approach for forecasting block
maxima in time series data. <em>IJCAI</em>, 2980–2986. (<a
href="https://doi.org/10.24963/ijcai.2022/413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate forecasting of extreme values in time series is critical due to the significant impact of extreme events on human and natural systems. This paper presents DeepExtrema, a novel framework that combines a deep neural network (DNN) with generalized extreme value (GEV) distribution to forecast the block maximum value of a time series. Implementing such a network is a challenge as the framework must preserve the inter-dependent constraints among the GEV model parameters even when the DNN is initialized. We describe our approach to address this challenge and present an architecture that enables both conditional mean and quantile prediction of the block maxima. The extensive experiments performed on both real-world and synthetic data demonstrated the superiority of DeepExtrema compared to other baseline methods. Keywords: Machine Learning: Time-series; Data Streams Data Mining: Anomaly/Outlier Detection Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Regression},
  archive   = {C_IJCAI},
  author    = {Asadullah Hill Galib and Andrew McDonald and Tyler Wilson and Lifeng Luo and Pang-Ning Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/413},
  pages     = {2980-2986},
  title     = {DeepExtrema: A deep learning approach for forecasting block maxima in time series data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-cheating teaching revisited: A new probabilistic machine
teaching model. <em>IJCAI</em>, 2973–2979. (<a
href="https://doi.org/10.24963/ijcai.2022/412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Over the past decades in the field of machine teaching, several restrictions have been introduced to avoid ‘cheating’, such as collusion-free or non-clashing teaching. However, these restrictions forbid several teaching situations that we intuitively consider natural and fair, especially those ‘changes of mind’ of the learner as more evidence is given, affecting the likelihood of concepts and ultimately their posteriors. Under a new generalised probabilistic teaching, not only do these non-cheating constraints look too narrow but we also show that the most relevant machine teaching models are particular cases of this framework: the consistency graph between concepts and elements simply becomes a joint probability distribution. We show a simple procedure that builds the witness joint distribution from the ground joint distribution. We prove a chain of relations, also with a theoretical lower bound, on the teaching dimension of the old and new models. Overall, this new setting is more general than the traditional machine teaching models, yet at the same time more intuitively capturing a less abrupt notion of non-cheating teaching. Keywords: Machine Learning: Learning Theory Machine Learning: Probabilistic Machine Learning},
  archive   = {C_IJCAI},
  author    = {Cèsar Ferri and José Hernández-Orallo and Jan Arne Telle},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/412},
  pages     = {2973-2979},
  title     = {Non-cheating teaching revisited: A new probabilistic machine teaching model},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Comparison knowledge translation for generalizable image
classification. <em>IJCAI</em>, 2966–2972. (<a
href="https://doi.org/10.24963/ijcai.2022/411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep learning has recently achieved remarkable performance in image classification tasks, which depends heavily on massive annotation. However, the classification mechanism of existing deep learning models seems to contrast to humans&#39; recognition mechanism. With only a glance at an image of the object even unknown type, humans can quickly and precisely find other same category objects from massive images, which benefits from daily recognition of various objects. In this paper, we attempt to build a generalizable framework that emulates the humans&#39; recognition mechanism in the image classification task, hoping to improve the classification performance on unseen categories with the support of annotations of other categories. Specifically, we investigate a new task termed Comparison Knowledge Translation (CKT). Given a set of fully labeled categories, CKT aims to translate the comparison knowledge learned from the labeled categories to a set of novel categories. To this end, we put forward a Comparison Classification Translation Network (CCT-Net), which comprises a comparison classifier and a matching discriminator. The comparison classifier is devised to classify whether two images belong to the same category or not, while the matching discriminator works together in an adversarial manner to ensure whether classified results match the truth. Exhaustive experiments show that CCT-Net achieves surprising generalization ability on unseen categories and SOTA performance on target categories. Keywords: Machine Learning: Classification Computer Vision: Transfer, low-shot, semi- and un- supervised learning Machine Learning: Semi-Supervised Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Zunlei Feng and Tian Qiu and Sai Wu and Xiaotuan Jin and Zengliang He and Mingli Song and Huiqiong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/411},
  pages     = {2966-2972},
  title     = {Comparison knowledge translation for generalizable image classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning unforgotten domain-invariant representations for
online unsupervised domain adaptation. <em>IJCAI</em>, 2958–2965. (<a
href="https://doi.org/10.24963/ijcai.2022/410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing unsupervised domain adaptation (UDA) studies focus on transferring knowledge in an offline manner. However, many tasks involve online requirements, especially in real-time systems. In this paper, we discuss Online UDA (OUDA) which assumes that the target samples are arriving sequentially as a small batch. OUDA tasks are challenging for prior UDA methods since online training suffers from catastrophic forgetting which leads to poor generalization. Intuitively, a good memory is a crucial factor in the success of OUDA. We formalize this intuition theoretically with a generalization bound where the OUDA target error can be bounded by the source error, the domain discrepancy distance, and a novel metric on forgetting in continuous online learning. Our theory illustrates the tradeoffs inherent in learning and remembering representations for OUDA. To minimize the proposed forgetting metric, we propose a novel source feature distillation (SFD) method which utilizes the source-only model as a teacher to guide the online training. In the experiment, we modify three UDA algorithms, i.e., DANN, CDAN, and MCC, and evaluate their performance on OUDA tasks with real-world datasets. By applying SFD, the performance of all baselines is significantly improved. Keywords: Machine Learning: Online Learning Machine Learning: Learning Theory Machine Learning: Theory of Deep Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Cheng Feng and Chaoliang Zhong and Jie Wang and Ying Zhang and Jun Sun and Yasuto Yokota},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/410},
  pages     = {2958-2965},
  title     = {Learning unforgotten domain-invariant representations for online unsupervised domain adaptation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-vector embedding on networks with taxonomies.
<em>IJCAI</em>, 2944–2950. (<a
href="https://doi.org/10.24963/ijcai.2022/408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A network can effectively depict close relationships among its nodes, with labels in a taxonomy describing the nodes&#39; rich attributes. Network embedding aims at learning a representation vector for each node and label to preserve their proximity, while most existing methods suffer from serious underfitting when dealing with datasets with dense node-label links. For instance, a node could have dozens of labels describing its diverse properties, causing the single node vector overloaded and hard to fit all the labels. We propose HIerarchical Multi-vector Embedding (HIME), which solves the underfitting problem by adaptively learning multiple &#39;branch vectors&#39; for each node to dynamically fit separate sets of labels in a hierarchy-aware embedding space. Moreover, a &#39;root vector&#39; is learned for each node based on its branch vectors to better predict the sparse but valuable node-node links with the knowledge of its labels. Experiments reveal HIME’s comprehensive advantages over existing methods on tasks such as proximity search, link prediction and hierarchical classification. Keywords: Machine Learning: Representation learning Data Mining: Mining Heterogenous Data Data Mining: Networks Machine Learning: Multi-label Multidisciplinary Topics and Applications: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Yue Fan and Xiuli Ma},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/408},
  pages     = {2944-2950},
  title     = {Multi-vector embedding on networks with taxonomies},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Function-words adaptively enhanced attention networks for
few-shot inverse relation classification. <em>IJCAI</em>, 2937–2943. (<a
href="https://doi.org/10.24963/ijcai.2022/407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The relation classification is to identify semantic relations between two entities in a given text. While existing models perform well for classifying inverse relations with large datasets, their performance is significantly reduced for few-shot learning. In this paper, we propose a function words adaptively enhanced attention framework (FAEA) for few-shot inverse relation classification, in which a hybrid attention model is designed to attend class-related function words based on meta-learning. As the involvement of function words brings in significant intra-class redundancy, an adaptive message passing mechanism is introduced to capture and transfer inter-class differences.We mathematically analyze the negative impact of function words from dot-product measurement, which explains why the message passing mechanism effectively reduces the impact. Our experimental results show that FAEA outperforms strong baselines, especially the inverse relation accuracy is improved by 14.33\% under 1-shot setting in FewRel1.0. Keywords: Machine Learning: Few-shot learning Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Chunliu Dou and Shaojuan Wu and Xiaowang Zhang and Zhiyong Feng and Kewen Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/407},
  pages     = {2937-2943},
  title     = {Function-words adaptively enhanced attention networks for few-shot inverse relation classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Residual contrastive learning for image reconstruction:
Learning transferable representations from noisy images. <em>IJCAI</em>,
2930–2936. (<a href="https://doi.org/10.24963/ijcai.2022/406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper is concerned with contrastive learning (CL) for low-level image restoration and enhancement tasks. We propose a new label-efficient learning paradigm based on residuals, residual contrastive learning (RCL), and derive an unsupervised visual representation learning framework, suitable for low-level vision tasks with noisy inputs. While supervised image reconstruction aims to minimize residual terms directly, RCL alternatively builds a connection between residuals and CL by defining a novel instance discrimination pretext task, using residuals as the discriminative feature. Our formulation mitigates the severe task misalignment between instance discrimination pretext tasks and downstream image reconstruction tasks, present in existing CL frameworks. Experimentally, we find that RCL can learn robust and transferable representations that improve the performance of various downstream tasks, such as denoising and super resolution, in comparison with recent self-supervised methods designed specifically for noisy inputs. Additionally, our unsupervised pre-training can significantly reduce annotation costs whilst maintaining performance competitive with fully-supervised image reconstruction. Keywords: Machine Learning: Self-supervised Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Machine Learning: Multi-task and Transfer Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Nanqing Dong and Matteo Maggioni and Yongxin Yang and Eduardo Pérez-Pellitero and Ales Leonardis and Steven McDonagh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/406},
  pages     = {2930-2936},
  title     = {Residual contrastive learning for image reconstruction: Learning transferable representations from noisy images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Taylor-lagrange neural ordinary differential equations:
Toward fast training and evaluation of neural ODEs. <em>IJCAI</em>,
2923–2929. (<a href="https://doi.org/10.24963/ijcai.2022/405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Neural ordinary differential equations (NODEs) -- parametrizations of differential equations using neural networks -- have shown tremendous promise in learning models of unknown continuous-time dynamical systems from data. However, every forward evaluation of a NODE requires numerical integration of the neural network used to capture the system dynamics, making their training prohibitively expensive. Existing works rely on off-the-shelf adaptive step-size numerical integration schemes, which often require an excessive number of evaluations of the underlying dynamics network to obtain sufficient accuracy for training. By contrast, we accelerate the evaluation and the training of NODEs by proposing a data-driven approach to their numerical integration. The proposed Taylor-Lagrange NODEs (TL-NODEs) use a fixed-order Taylor expansion for numerical integration, while also learning to estimate the expansion&#39;s approximation error. As a result, the proposed approach achieves the same accuracy as adaptive step-size schemes while employing only low-order Taylor expansions, thus greatly reducing the computational cost necessary to integrate the NODE. A suite of numerical experiments, including modeling dynamical systems, image classification, and density estimation, demonstrate that TL-NODEs can be trained more than an order of magnitude faster than state-of-the-art approaches, without any loss in performance. Keywords: Machine Learning: Recurrent Networks Machine Learning: Other Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Franck Djeumou and Cyrus Neary and Eric Goubault and Sylvie Putot and Ufuk Topcu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/405},
  pages     = {2923-2929},
  title     = {Taylor-lagrange neural ordinary differential equations: Toward fast training and evaluation of neural ODEs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Coherent probabilistic aggregate queries on long-horizon
forecasts. <em>IJCAI</em>, 2916–2922. (<a
href="https://doi.org/10.24963/ijcai.2022/404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Long range forecasts are the starting point of many decision support systems that need to draw inference from high-level aggregate patterns on forecasted values. State of the art time-series forecasting methods are either subject to concept drift on long-horizon forecasts, or fail to accurately predict coherent and accurate high-level aggregates. In this work, we present a novel probabilistic forecasting method that produces forecasts that are coherent in terms of base level and predicted aggregate statistics. We achieve the coherency between predicted base-level and aggregate statistics using a novel inference method based on KL-divergence that can be solved efficiently in closed form. We show that our method improves forecast performance across both base level and unseen aggregates post inference on real datasets ranging three diverse domains. (Project URL) Keywords: Machine Learning: Time-series; Data Streams Data Mining: Mining Data Streams Machine Learning: Probabilistic Machine Learning Machine Learning: Multi-view learning},
  archive   = {C_IJCAI},
  author    = {Prathamesh Deshpande and Sunita Sarawagi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/404},
  pages     = {2916-2922},
  title     = {Coherent probabilistic aggregate queries on long-horizon forecasts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reinforcement learning with option machines. <em>IJCAI</em>,
2909–2915. (<a href="https://doi.org/10.24963/ijcai.2022/403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Reinforcement learning (RL) is a powerful framework for learning complex behaviors, but lacks adoption in many settings due to sample size requirements. We introduce a framework for increasing sample efficiency of RL algorithms. Our approach focuses on optimizing environment rewards with high-level instructions. These are modeled as a high-level controller over temporally extended actions known as options. These options can be looped, interleaved and partially ordered with a rich language for high-level instructions. Crucially, the instructions may be underspecified in the sense that following them does not guarantee high reward in the environment. We present an algorithm for control with these so-called option machines (OMs), discuss option selection for the partially ordered case and describe an algorithm for learning with OMs. We compare our approach in zero-shot, single- and multi-task settings in an environment with fully specified and underspecified instructions. We find that OMs perform significantly better than or comparable to the state-of-art in all environments and learning settings. Keywords: Machine Learning: Reinforcement Learning Machine Learning: Deep Reinforcement Learning Planning and Scheduling: Planning with Incomplete Information},
  archive   = {C_IJCAI},
  author    = {Floris den Hengst and Vincent Francois-Lavet and Mark Hoogendoorn and Frank van Harmelen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/403},
  pages     = {2909-2915},
  title     = {Reinforcement learning with option machines},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiband VAE: Latent space alignment for knowledge
consolidation in continual learning. <em>IJCAI</em>, 2902–2908. (<a
href="https://doi.org/10.24963/ijcai.2022/402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new method for unsupervised generative continual learning through realignment of Variational Autoencoder&#39;s latent space. Deep generative models suffer from catastrophic forgetting in the same way as other neural structures. Recent generative continual learning works approach this problem and try to learn from new data without forgetting previous knowledge. However, those methods usually focus on artificial scenarios where examples share almost no similarity between subsequent portions of data - an assumption not realistic in the real-life applications of continual learning. In this work, we identify this limitation and posit the goal of generative continual learning as a knowledge accumulation task. We solve it by continuously aligning latent representations of new data that we call bands in additional latent space where examples are encoded independently of their source task. In addition, we introduce a method for controlled forgetting of past data that simplifies this process. On top of the standard continual learning benchmarks, we propose a novel challenging knowledge consolidation scenario and show that the proposed approach outperforms state-of-the-art by up to twofold across all experiments and additional real-life evaluation. To our knowledge, Multiband VAE is the first method to show forward and backward knowledge transfer in generative continual learning. Keywords: Machine Learning: Incremental Learning Computer Vision: Neural generative models, auto encoders, GANs},
  archive   = {C_IJCAI},
  author    = {Kamil Deja and Paweł Wawrzyński and Wojciech Masarczyk and Daniel Marczak and Tomasz Trzciński},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/402},
  pages     = {2902-2908},
  title     = {Multiband VAE: Latent space alignment for knowledge consolidation in continual learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Geometric transformer for end-to-end molecule properties
prediction. <em>IJCAI</em>, 2895–2901. (<a
href="https://doi.org/10.24963/ijcai.2022/401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformers have become methods of choice in many applications thanks to their ability to represent complex interactions between elements. However, extending the Transformer architecture to non-sequential data such as molecules and enabling its training on small datasets remains a challenge. In this work, we introduce a Transformer-based architecture for molecule property prediction, which is able to capture the geometry of the molecule. We modify the classical positional encoder by an initial encoding of the molecule geometry, as well as a learned gated self-attention mechanism. We further suggest an augmentation scheme for molecular data capable of avoiding the overfitting induced by the overparameterized architecture. The proposed framework outperforms the state-of-the-art methods while being based on pure machine learning solely, i.e. the method does not incorporate domain knowledge from quantum chemistry and does not use extended geometric inputs besides the pairwise atomic distances. Keywords: Machine Learning: Attention Models Machine Learning: Representation learning Machine Learning: Sequence and Graph Learning Multidisciplinary Topics and Applications: Physical Science},
  archive   = {C_IJCAI},
  author    = {Yoni Choukroun and Lior Wolf},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/401},
  pages     = {2895-2901},
  title     = {Geometric transformer for end-to-end molecule properties prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can we find neurons that cause unrealistic images in deep
generative networks? <em>IJCAI</em>, 2888–2894. (<a
href="https://doi.org/10.24963/ijcai.2022/400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Even though Generative Adversarial Networks (GANs) have shown a remarkable ability to generate high-quality images, GANs do not always guarantee the generation of photorealistic images. Occasionally, they generate images that have defective or unnatural objects, which are referred to as `artifacts&#39;. Research to investigate why these artifacts emerge and how they can be detected and removed has yet to be sufficiently carried out. To analyze this, we first hypothesize that rarely activated neurons and frequently activated neurons have different purposes and responsibilities for the progress of generating images. In this study, by analyzing the statistics and the roles for those neurons, we empirically show that rarely activated neurons are related to the failure results of making diverse objects and inducing artifacts. In addition, we suggest a correction method, called `Sequential Ablation’, to repair the defective part of the generated images without high computational cost and manual efforts. Keywords: Machine Learning: Generative Adverserial Networks Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Hwanil Choi and Wonjoon Chang and Jaesik Choi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/400},
  pages     = {2888-2894},
  title     = {Can we find neurons that cause unrealistic images in deep generative networks?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Heterogeneous ensemble knowledge transfer for training large
models in federated learning. <em>IJCAI</em>, 2881–2887. (<a
href="https://doi.org/10.24963/ijcai.2022/399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) enables edge-devices to collaboratively learn a model without disclosing their private data to a central aggregating server. Most existing FL algorithms require models of identical architecture to be deployed across the clients and server, making it infeasible to train large models due to clients&#39; limited system resources. In this work, we propose a novel ensemble knowledge transfer method named Fed-ET in which small models (different in architecture) are trained on clients, and used to train a larger model at the server. Unlike in conventional ensemble learning, in FL the ensemble can be trained on clients&#39; highly heterogeneous data. Cognizant of this property, Fed-ET uses a weighted consensus distillation scheme with diversity regularization that efficiently extracts reliable consensus from the ensemble while improving generalization by exploiting the diversity within the ensemble. We show the generalization bound for the ensemble of weighted models trained on heterogeneous datasets that supports the intuition of Fed-ET. Our experiments on image and language tasks show that Fed-ET significantly outperforms other state-of-the-art FL algorithms with fewer communicated parameters, and is also robust against high data-heterogeneity. Keywords: Machine Learning: Ensemble Methods Knowledge Representation and Reasoning: Applications},
  archive   = {C_IJCAI},
  author    = {Yae Jee Cho and Andre Manoel and Gauri Joshi and Robert Sim and Dimitrios Dimitriadis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/399},
  pages     = {2881-2887},
  title     = {Heterogeneous ensemble knowledge transfer for training large models in federated learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Better embedding and more shots for few-shot learning.
<em>IJCAI</em>, 2874–2880. (<a
href="https://doi.org/10.24963/ijcai.2022/398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In few-shot learning, methods are enslaved to the scarce labeled data, resulting in suboptimal embedding. Recent studies learn the embedding network by other large-scale labeled data. However, the trained network may give rise to the distorted embedding of target data. We argue two respects are required for an unprecedented and promising solution. We call them Better Embedding and More Shots (BEMS). Suppose we propose to extract embedding from the embedding network. BE maximizes the extraction of general representation and prevents over-fitting information. For this purpose, we introduce the topological relation for global reconstruction, avoiding excessive memorizing. MS maximizes the relevance between the reconstructed embedding and the target class space. In this respect, increasing the number of shots is a pivotal but intractable strategy. As a creative method, we derive the bound of information-theory-based loss function and implicitly achieve infinite shots with negligible cost. A substantial experimental analysis is carried out to demonstrate the state-of-the-art performance. Compared to the baseline, our method improves by up to 10\%+. We also prove that BEMS is suitable for both standard pre-trained and meta-learning embedded networks. Keywords: Machine Learning: Few-shot learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision Machine Learning: Classification Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Ziqiu Chi and Zhe Wang and Mengping Yang and Wei Guo and Xinlei Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/398},
  pages     = {2874-2880},
  title     = {Better embedding and more shots for few-shot learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DDDM: A brain-inspired framework for robust classification.
<em>IJCAI</em>, 2867–2873. (<a
href="https://doi.org/10.24963/ijcai.2022/397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite their outstanding performance in a broad spectrum of real-world tasks, deep artificial neural networks are sensitive to input noises, particularly adversarial perturbations. On the contrary, human and animal brains are much less vulnerable. In contrast to the one-shot inference performed by most deep neural networks, the brain often solves decision-making with an evidence accumulation mechanism that may trade time for accuracy when facing noisy inputs. The mechanism is well described by the Drift-Diffusion Model (DDM). In the DDM, decision-making is modeled as a process in which noisy evidence is accumulated toward a threshold. Drawing inspiration from the DDM, we propose the Dropout-based Drift-Diffusion Model (DDDM) that combines test-phase dropout and the DDM for improving the robustness for arbitrary neural networks. The dropouts create temporally uncorrelated noises in the network that counter perturbations, while the evidence accumulation mechanism guarantees a reasonable decision accuracy. Neural networks enhanced with the DDDM tested in image, speech, and text classification tasks all significantly outperform their native counterparts, demonstrating the DDDM as a task-agnostic defense against adversarial attacks. Keywords: Machine Learning: Robustness Humans and AI: Brain Sciences},
  archive   = {C_IJCAI},
  author    = {Xiyuan Chen and Xingyu Li and Yi Zhou and Tianming Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/397},
  pages     = {2867-2873},
  title     = {DDDM: A brain-inspired framework for robust classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised mutual learning for dynamic scene
reconstruction of spiking camera. <em>IJCAI</em>, 2859–2866. (<a
href="https://doi.org/10.24963/ijcai.2022/396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mimicking the sampling mechanism of the primate fovea, a retina-inspired vision sensor named spiking camera has been developed, which has shown great potential for capturing high-speed dynamic scenes with a sampling rate of 40, 000 Hz. Unlike conventional digital cameras, the spiking camera continuously captures photons and outputs asynchronous binary spikes with various inter-spike intervals to record dynamic scenes. However, how to reconstruct dynamic scenes from asynchronous spike streams remains challenging. In this work, we propose a novel pretext task to build a self-supervised reconstruction framework for spiking cameras. Specifically, we utilize the blind-spot network commonly used in self-supervised denoising tasks as our backbone, and perform self-supervised learning by constructing proper pseudo-labels. In addition, in view of the poor scalability and insufficient information utilization of the blind-spot network, we present a mutual learning framework to improve the overall performance of the network through mutual distillation between a non-blind-spot network and a blind-spot network. This also enables the network to bypass constraints of the blind-spot network, allowing state-of-the-art modules to be used to further improve performance. The experimental results demonstrate that our methods evidently outperform previous unsupervised spiking camera reconstruction methods and achieve desirable results compared with supervised methods. Keywords: Machine Learning: Self-supervised Learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Shiyan Chen and Chaoteng Duan and Zhaofei Yu and Ruiqin Xiong and Tiejun Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/396},
  pages     = {2859-2866},
  title     = {Self-supervised mutual learning for dynamic scene reconstruction of spiking camera},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking the promotion brought by contrastive learning to
semi-supervised node classification. <em>IJCAI</em>, 2852–2858. (<a
href="https://doi.org/10.24963/ijcai.2022/395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Contrastive Learning (GCL) has proven highly effective in promoting the performance of Semi-Supervised Node Classification (SSNC). However, existing GCL methods are generally transferred from other fields like CV or NLP, whose underlying working mechanism remains underexplored. In this work, we first deeply probe the working mechanism of GCL in SSNC, and find that the promotion brought by GCL is severely unevenly distributed: the improvement mainly comes from subgraphs with less annotated information, which is fundamentally different from contrastive learning in other fields. However, existing GCL methods generally ignore this uneven distribution of annotated information and apply GCL evenly to the whole graph. To remedy this issue and further improve GCL in SSNC, we propose the Topology InFormation gain-Aware Graph Contrastive Learning (TIFA-GCL) framework that considers the annotated information distribution across graph in GCL. Extensive experiments on six benchmark graph datasets, including the enormous OGB-Products graph, show that TIFA-GCL can bring a larger improvement than existing GCL methods in both transductive and inductive settings. Further experiments demonstrate the generalizability and interpretability of TIFA-GCL. Keywords: Machine Learning: Sequence and Graph Learning Data Mining: Mining Graphs Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Deli Chen and Yankai Lin and Lei Li and Xuancheng Ren and Peng Li and Jie Zhou and Xu Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/395},
  pages     = {2852-2858},
  title     = {Rethinking the promotion brought by contrastive learning to semi-supervised node classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Neural contextual anomaly detection for time series.
<em>IJCAI</em>, 2843–2851. (<a
href="https://doi.org/10.24963/ijcai.2022/394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce Neural Contextual Anomaly Detection (NCAD), a framework for anomaly detection on time series that scales seamlessly from the unsupervised to supervised setting, and is applicable to both univariate and multivariate time series. This is achieved by combining recent developments in representation learning for multivariate time series, with techniques for deep anomaly detection originally developed for computer vision that we tailor to the time series setting. Our window-based approach facilitates learning the boundary between normal and anomalous classes by injecting generic synthetic anomalies into the available data. NCAD can effectively take advantage of domain knowledge and of any available training labels. We demonstrate empirically on standard benchmark datasets that our approach obtains a state-of-the-art performance in the supervised, semi-supervised, and unsupervised settings. Keywords: Machine Learning: Time-series; Data Streams Data Mining: Anomaly/Outlier Detection},
  archive   = {C_IJCAI},
  author    = {Chris U. Carmona and François-Xavier Aubet and Valentin Flunkert and Jan Gasthaus},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/394},
  pages     = {2843-2851},
  title     = {Neural contextual anomaly detection for time series},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Posistive-unlabeled learning via optimal transport and
margin distribution. <em>IJCAI</em>, 2836–2842. (<a
href="https://doi.org/10.24963/ijcai.2022/393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Positive-unlabeled (PU) learning deals with the circumstances where only a portion of positive instances are labeled, while the rest and all negative instances are unlabeled, and due to this confusion, the class prior can not be directly available. Existing PU learning methods usually estimate the class prior by training a nontraditional probabilistic classifier, which is prone to give an overestimation. Moreover, these methods learn the decision boundary by optimizing the minimum margin, which is not suitable in PU learning due to its sensitivity to label noise. In this paper, we enhance PU learning methods from the above two aspects. More specifically, we first explicitly learn a transformation from unlabeled data to positive data by entropy regularized optimal transport to achieve a much more precise estimation for class prior. Then we switch to optimizing the margin distribution, rather than the minimum margin, to obtain a label noise insensitive classifier. Extensive empirical studies on both synthetic and real-world data sets demonstrate the superiority of our proposed method. Keywords: Machine Learning: Classification Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Nan Cao and Teng Zhang and Xuanhua Shi and Hai Jin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/393},
  pages     = {2836-2842},
  title     = {Posistive-unlabeled learning via optimal transport and margin distribution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Not a number: Identifying instance features for
capability-oriented evaluation. <em>IJCAI</em>, 2827–2835. (<a
href="https://doi.org/10.24963/ijcai.2022/392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In AI evaluation, performance is often calculated by averaging across various instances. But to fully understand the capabilities of an AI system, we need to understand the factors that cause its pattern of success and failure. In this paper, we present a new methodology to identify and build informative instance features that can provide explanatory and predictive power to analyse the behaviour of AI systems more robustly. The methodology builds on these relevant features that should relate monotonically with success, and represents patterns of performance in a new type of plots known as ‘agent characteristic grids’. We illustrate this methodology with the Animal-AI competition as a representative example of how we can revisit existing competitions and benchmarks in AI—even when evaluation data is sparse. Agents with the same average performance can show very different patterns of performance at the instance level. With this methodology, these patterns can be visualised, explained and predicted, progressing towards a capability-oriented evaluation rather than relying on a less informative average performance score. Keywords: Machine Learning: Evaluation AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Safety &amp; Robustness Machine Learning: Experimental Methodology},
  archive   = {C_IJCAI},
  author    = {Ryan Burnell and John Burden and Danaja Rutar and Konstantinos Voudouris and Lucy Cheke and José Hernández-Orallo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/392},
  pages     = {2827-2835},
  title     = {Not a number: Identifying instance features for capability-oriented evaluation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adversarial explanations for knowledge graph embeddings.
<em>IJCAI</em>, 2820–2826. (<a
href="https://doi.org/10.24963/ijcai.2022/391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a novel black-box approach for performing adversarial attacks against knowledge graph embedding models. An adversarial attack is a small perturbation of the data at training time to cause model failure at test time. We make use of an efficient rule learning approach and use abductive reasoning to identify triples which are logical explanations for a particular prediction. The proposed attack is then based on the simple idea to suppress or modify one of the triples in the most confident explanation. Although our attack scheme is model independent and only needs access to the training data, we report results on par with state-of-the-art white-box attack methods that additionally require full access to the model architecture, the learned embeddings, and the loss functions. This is a surprising result which indicates that knowledge graph embedding models can partly be explained post hoc with the help of symbolic methods. Keywords: Machine Learning: Relational Learning Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning Knowledge Representation and Reasoning: Learning and reasoning Machine Learning: Adversarial Machine Learning Machine Learning: Explainable/Interpretable Machine Learning},
  archive   = {C_IJCAI},
  author    = {Patrick Betz and Christian Meilicke and Heiner Stuckenschmidt},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/391},
  pages     = {2820-2826},
  title     = {Adversarial explanations for knowledge graph embeddings},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Logit mixing training for more reliable and accurate
prediction. <em>IJCAI</em>, 2812–2819. (<a
href="https://doi.org/10.24963/ijcai.2022/390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {When a person solves the multi-choice problem, she considers not only what is the answer but also what is not the answer. Knowing what choice is not the answer and utilizing the relationships between choices, she can improve the prediction accuracy. Inspired by this human reasoning process, we propose a new training strategy to fully utilize inter-class relationships, namely LogitMix. Our strategy is combined with recent data augmentation techniques, e.g., Mixup, Manifold Mixup, CutMix, and PuzzleMix. Then, we suggest using a mixed logit, i.e., a mixture of two logits, as an auxiliary training objective. Since the logit can preserve both positive and negative inter-class relationships, it can impose a network to learn the probability of wrong answers correctly. Our extensive experimental results on the image- and language-based tasks demonstrate that LogitMix achieves state-of-the-art performance among recent data augmentation techniques regarding calibration error and prediction accuracy. Keywords: Machine Learning: Classification Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Duhyeon Bang and Kyungjune Baek and Jiwoo Kim and Yunho Jeon and Jin-Hwa Kim and Jiwon Kim and Jongwuk Lee and Hyunjung Shim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/390},
  pages     = {2812-2819},
  title     = {Logit mixing training for more reliable and accurate prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). One weird trick to improve your semi-weakly supervised
semantic segmentation model. <em>IJCAI</em>, 2805–2811. (<a
href="https://doi.org/10.24963/ijcai.2022/389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-weakly supervised semantic segmentation (SWSSS) aims to train a model to identify objects in images based on a small number of images with pixel-level labels, and many more images with only image-level labels. Most existing SWSSS algorithms extract pixel-level pseudo-labels from an image classifier - a very difficult task to do well, hence requiring complicated architectures and extensive hyperparameter tuning on fully-supervised validation sets. We propose a method called prediction filtering, which instead of extracting pseudo-labels, just uses the classifier as a classifier: it ignores any segmentation predictions from classes which the classifier is confident are not present. Adding this simple post-processing method to baselines gives results competitive with or better than prior SWSSS algorithms. Moreover, it is compatible with pseudo-label methods: adding prediction filtering to existing SWSSS algorithms further improves segmentation performance. Keywords: Machine Learning: Weakly Supervised Learning Computer Vision: Segmentation Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wonho Bae and Junhyug Noh and Milad Jalali Asadabadi and Danica J. Sutherland},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/389},
  pages     = {2805-2811},
  title     = {One weird trick to improve your semi-weakly supervised semantic segmentation model},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixed-budget best-arm identification in structured bandits.
<em>IJCAI</em>, 2798–2804. (<a
href="https://doi.org/10.24963/ijcai.2022/388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Best-arm identification (BAI) in a fixed-budget setting is a bandit problem where the learning agent maximizes the probability of identifying the optimal (best) arm after a fixed number of observations. Most works on this topic study unstructured problems with a small number of arms, which limits their applicability. We propose a general tractable algorithm that incorporates the structure, by successively eliminating suboptimal arms based on their mean reward estimates from a joint generalization model. We analyze our algorithm in linear and generalized linear models (GLMs), and propose a practical implementation based on a G-optimal design. In linear models, our algorithm has competitive error guarantees to prior works and performs at least as well empirically. In GLMs, this is the first practical algorithm with analysis for fixed-budget BAI. Keywords: Machine Learning: Online Learning Machine Learning: Active Learning Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {MohammadJavad Azizi and Branislav Kveton and Mohammad Ghavamzadeh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/388},
  pages     = {2798-2804},
  title     = {Fixed-budget best-arm identification in structured bandits},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning label initialization for time-dependent harmonic
extension. <em>IJCAI</em>, 2791–2797. (<a
href="https://doi.org/10.24963/ijcai.2022/387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Node classification on graphs can be formulated as the Dirichlet problem on graphs where the signal is given at the labeled nodes, and the harmonic extension is done on the unlabeled nodes. This paper considers a time-dependent version of the Dirichlet problem on graphs and shows how to improve its solution by learning the proper initialization vector on the unlabeled nodes. Further, we show that the improved solution is at par with state-of-the-art methods used for node classification. Finally, we conclude this paper by discussing the importance of parameter t, pros, and future directions. Keywords: Machine Learning: Semi-Supervised Learning Machine Learning: Representation learning AI Ethics, Trust, Fairness: Trustworthy AI Machine Learning: Other},
  archive   = {C_IJCAI},
  author    = {Amitoz Azad},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/387},
  pages     = {2791-2797},
  title     = {Learning label initialization for time-dependent harmonic extension.},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Synthesis of maximally permissive strategies for LTLf
specifications. <em>IJCAI</em>, 2783–2789. (<a
href="https://doi.org/10.24963/ijcai.2022/386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study synthesis of maximally permissive strategies for Linear Temporal Logic on finite traces (LTLf) specifications. That is, instead of computing a single strategy (aka plan, or policy), we aim at computing the entire set of strategies at once and then choosing among them while in execution, without committing to a single one beforehand. Maximally permissive strategies have been introduced and investigated for safety properties, especially in the context of Discrete Event Control Theory. However, the available results for safety properties do not apply to reachability properties (eventually reach a given state of affair) nor to LTLf properties in general. In this paper, we show that maximally permissive strategies do exist also for reachability and general LTLf properties, and can in fact be computed with minimal overhead wrt the computation of a single strategy using state-of-the-art tools. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis},
  archive   = {C_IJCAI},
  author    = {Shufang Zhu and Giuseppe De Giacomo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/386},
  pages     = {2783-2789},
  title     = {Synthesis of maximally permissive strategies for LTLf specifications},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FedDUAP: Federated learning with dynamic update and adaptive
pruning using shared data on the server. <em>IJCAI</em>, 2776–2782. (<a
href="https://doi.org/10.24963/ijcai.2022/385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite achieving remarkable performance, Federated Learning (FL) suffers from two critical challenges, i.e., limited computational resources and low training efficiency. In this paper, we propose a novel FL framework, i.e., FedDUAP, with two original contributions, to exploit the insensitive data on the server and the decentralized data in edge devices to further improve the training efficiency. First, a dynamic server update algorithm is designed to exploit the insensitive data on the server, in order to dynamically determine the optimal steps of the server update for improving the convergence and accuracy of the global model. Second, a layer-adaptive model pruning method is developed to perform unique pruning operations adapted to the different dimensions and importance of multiple layers, to achieve a good balance between efficiency and effectiveness. By integrating the two original techniques together, our proposed FL model, FedDUAP, significantly outperforms baseline approaches in terms of accuracy (up to 4.8\% higher), efficiency (up to 2.8 times faster), and computational cost (up to 61.9\% smaller). Keywords: Knowledge Representation and Reasoning: Reasong about actions Data Mining: Federated Learning},
  archive   = {C_IJCAI},
  author    = {Hong Zhang and Ji Liu and Juncheng Jia and Yang Zhou and Huaiyu Dai and Dejing Dou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/385},
  pages     = {2776-2782},
  title     = {FedDUAP: Federated learning with dynamic update and adaptive pruning using shared data on the server},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GL-RG: Global-local representation granularity for video
captioning. <em>IJCAI</em>, 2769–2775. (<a
href="https://doi.org/10.24963/ijcai.2022/384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video captioning is a challenging task as it needs to accurately transform visual understanding into natural language description. To date, state-of-the-art methods inadequately model global-local representation across video frames for caption generation, leaving plenty of room for improvement. In this work, we approach the video captioning task from a new perspective and propose a GL-RG framework for video captioning, namely a Global-Local Representation Granularity. Our GL-RG demonstrates three advantages over the prior efforts: 1) we explicitly exploit extensive visual representations from different video ranges to improve linguistic expression; 2) we devise a novel global-local encoder to produce rich semantic vocabulary to obtain a descriptive granularity of video contents across frames; 3) we develop an incremental training strategy which organizes model learning in an incremental fashion to incur an optimal captioning behavior. Experimental results on the challenging MSR-VTT and MSVD datasets show that our DL-RG outperforms recent state-of-the-art methods by a significant margin. Code is available at https://github.com/ylqi/GL-RG. Keywords: Knowledge Representation and Reasoning: Applications Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Liqi Yan and Qifan Wang and Yiming Cui and Fuli Feng and Xiaojun Quan and Xiangyu Zhang and Dongfang Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/384},
  pages     = {2769-2775},
  title     = {GL-RG: Global-local representation granularity for video captioning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Human parity on CommonsenseQA: Augmenting self-attention
with external attention. <em>IJCAI</em>, 2762–2768. (<a
href="https://doi.org/10.24963/ijcai.2022/383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most of today&#39;s AI systems focus on using self-attention mechanisms and transformer architectures on large amounts of diverse data to achieve impressive performance gains. In this paper, we propose to augment the transformer architecture with an external attention mechanism to bring external knowledge and context to bear. By integrating external information into the prediction process, we hope to reduce the need for ever-larger models and increase the democratization of AI systems. We find that the proposed external attention mechanism can significantly improve the performance of existing AI systems, allowing practitioners to easily customize foundation AI models to many diverse downstream applications. In particular, we focus on the task of Commonsense Reasoning, demonstrating that the proposed external attention mechanism can augment existing transformer models and significantly improve the model&#39;s reasoning capabilities. The proposed system, Knowledgeable External Attention for commonsense Reasoning (KEAR), reaches human parity on the open CommonsenseQA research benchmark with an accuracy of 89.4\% in comparison to the human accuracy of 88.9\%. Keywords: Knowledge Representation and Reasoning: Common-Sense Reasoning Natural Language Processing: Question Answering Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Yichong Xu and Chenguang Zhu and Shuohang Wang and Siqi Sun and Hao Cheng and Xiaodong Liu and Jianfeng Gao and Pengcheng He and Michael Zeng and Xuedong Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/383},
  pages     = {2762-2768},
  title     = {Human parity on CommonsenseQA: Augmenting self-attention with external attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simple and effective relation-based embedding propagation
for knowledge representation learning. <em>IJCAI</em>, 2755–2761. (<a
href="https://doi.org/10.24963/ijcai.2022/382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Relational graph neural networks have garnered particular attention to encode graph context in knowledge graphs (KGs). Although they achieved competitive performance on small KGs, how to efficiently and effectively utilize graph context for large KGs remains an open problem. To this end, we propose the Relation-based Embedding Propagation (REP) method. It is a post-processing technique to adapt pre-trained KG embeddings with graph context. As relations in KGs are directional, we model the incoming head context and the outgoing tail context separately. Accordingly, we design relational context functions with no external parameters. Besides, we use averaging to aggregate context information, making REP more computation-efficient. We theoretically prove that such designs can avoid information distortion during propagation. Extensive experiments also demonstrate that REP has significant scalability while improving or maintaining prediction quality. Particularly, it averagely brings about 10\% relative improvement to triplet-based embedding methods on OGBL-WikiKG2 and takes 5\%-83\% time to achieve comparable results as the state-of-the-art GC-OTE. Keywords: Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Learning and reasoning Knowledge Representation and Reasoning: Other Knowledge Representation and Reasoning: Semantic Web Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Huijuan Wang and Siming Dai and Weiyue Su and Hui Zhong and Zeyang Fang and Zhengjie Huang and Shikun Feng and Zeyu Chen and Yu Sun and Dianhai Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/382},
  pages     = {2755-2761},
  title     = {Simple and effective relation-based embedding propagation for knowledge representation learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Updating probability intervals with uncertain inputs.
<em>IJCAI</em>, 2748–2754. (<a
href="https://doi.org/10.24963/ijcai.2022/381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Probability intervals provide an intuitive, powerful and unifying setting for encoding and reasoning with imprecise beliefs. This paper addresses the problem of updating uncertain information specified in the form of probability intervals with new uncertain inputs also expressed as probability intervals. We place ourselves in the framework of Jeffrey&#39;s rule of conditioning and propose extensions of this conditioning for the interval-based setting. More precisely, we first extend Jeffrey&#39;s rule to credal sets then propose extensions of Jeffrey&#39;s rule to three common conditioning rules for probability intervals (robust, Dempster and geometric conditionings). While the first extension is based on conditioning the extreme points of the credal sets induced by the probability intervals, the other methods directly revise the interval bounds of the distributions to be updated. Finally, the paper discusses related issues and relates the proposed methods with respect to the state-of-the-art. Keywords: Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Karim Tabia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/381},
  pages     = {2748-2754},
  title     = {Updating probability intervals with uncertain inputs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Considering constraint monotonicity and foundedness in
answer set programming. <em>IJCAI</em>, 2741–2747. (<a
href="https://doi.org/10.24963/ijcai.2022/380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Should the properties of constraint monotonicity and foundedness be mandatory requirements that every answer set and world view semantics must satisfy? This question is challenging and has incurred a debate in answer set programming (ASP). In this paper we address the question by introducing natural logic programs whose expected answer sets and world views violate these properties and thus may be viewed as counter-examples to these requirements. Specifically we use instances of the generalized strategic companies problem for ASP benchmark competitions as concrete examples to demonstrate that the requirements of constraint monotonicity and foundedness may exclude expected answer sets for some simple disjunctive programs and world views for some epistemic specifications. In conclusion these properties should not be mandatory conditions for an answer set and world view semantics in general. Keywords: Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Non-monotonic Reasoning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Yi-Dong Shen and Thomas Eiter},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/380},
  pages     = {2741-2747},
  title     = {Considering constraint monotonicity and foundedness in answer set programming},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Revision by comparison for ranking functions.
<em>IJCAI</em>, 2734–2740. (<a
href="https://doi.org/10.24963/ijcai.2022/379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Revision by Comparison (RbC) is a non-prioritized belief revision mechanism on epistemic states that specifies constraints on the plausibility of an input sentence via a designated reference sentence, allowing for kind of relative belief revision. In this paper, we make the strategy underlying RbC more explicit and transfer the mechanism together with its intuitive strengths to a semi-quantitative framework based on ordinal conditional functions where a more elegant implementation of RbC is possible. We furthermore show that RbC can be realized as an iterated revision by so-called weak conditionals. Finally, we point out relations of RbC to credibility-limited belief revision, illustrating the versatility of RbC for advanced belief revision operations. Keywords: Knowledge Representation and Reasoning: Non-monotonic Reasoning Knowledge Representation and Reasoning: Belief Change},
  archive   = {C_IJCAI},
  author    = {Meliha Sezgin and Gabriele Kern-Isberner},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/379},
  pages     = {2734-2740},
  title     = {Revision by comparison for ranking functions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning higher-order logic programs from failures.
<em>IJCAI</em>, 2726–2733. (<a
href="https://doi.org/10.24963/ijcai.2022/378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning complex programs through inductive logic programming (ILP) remains a formidable challenge. Existing higher-order enabled ILP systems show improved accuracy and learning performance, though remain hampered by the limitations of the underlying learning mechanism. Experimental results show that our extension of the versatile Learning From Failures paradigm by higher-order definitions significantly improves learning performance without the burdensome human guidance required by existing systems. Our theoretical framework captures a class of higher-order definitions preserving soundness of existing subsumption-based pruning methods. Keywords: Knowledge Representation and Reasoning: Learning and reasoning Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Logic Programming},
  archive   = {C_IJCAI},
  author    = {Stanisław J. Purgał and David M. Cerna and Cezary Kaliszyk},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/378},
  pages     = {2726-2733},
  title     = {Learning higher-order logic programs from failures},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverse problems for gradual semantics. <em>IJCAI</em>,
2719–2725. (<a href="https://doi.org/10.24963/ijcai.2022/377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gradual semantics with abstract argumentation provide each argument with a score reflecting its acceptability. Many different gradual semantics have been proposed in the literature, each following different principles and producing different argument rankings. A sub-class of such semantics, the so-called weighted semantics, takes, in addition to the graph structure, an initial set of weights over the arguments as input, with these weights affecting the resultant argument ranking. In this work, we consider the inverse problem over such weighted semantics. That is, given an argumentation framework and a desired argument ranking, we ask whether there exist initial weights such that a particular semantics produces the given ranking. The contribution of this paper are: (1) an algorithm to answer this problem, (2) a characterisation of the properties that a gradual semantics must satisfy for the algorithm to operate, and (3) an empirical evaluation of the proposed algorithm. Keywords: Knowledge Representation and Reasoning: Argumentation Agent-based and Multi-agent Systems: Agreement Technologies: Argumentation},
  archive   = {C_IJCAI},
  author    = {Nir Oren and Bruno Yun and Srdjan Vesic and Murilo Baptista},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/377},
  pages     = {2719-2725},
  title     = {Inverse problems for gradual semantics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Causes of effects: Learning individual responses from
population data. <em>IJCAI</em>, 2712–2718. (<a
href="https://doi.org/10.24963/ijcai.2022/376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of individualization is crucial in almost every field of science. Identifying causes of specific observed events is likewise essential for accurate decision making as well as explanation. However, such tasks invoke counterfactual relationships, and are therefore indeterminable from population data. For example, the probability of benefiting from a treatment concerns an individual having a favorable outcome if treated and an unfavorable outcome if untreated; it cannot be estimated from experimental data, even when conditioned on fine-grained features, because we cannot test both possibilities for an individual. Tian and Pearl provided bounds on this and other probabilities of causation using a combination of experimental and observational data. Those bounds, though tight, can be narrowed significantly when structural information is available in the form of a causal model. This added information may provide the power to solve central problems, such as explainable AI, legal responsibility, and personalized medicine, all of which demand counterfactual logic. This paper derives, analyzes, and characterizes these new bounds, and illustrates some of their practical applications. Keywords: Knowledge Representation and Reasoning: Causality Uncertainty in AI: Causality, Structural Causal Models and Causal Inference Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Scott Mueller and Ang Li and Judea Pearl},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/376},
  pages     = {2712-2718},
  title     = {Causes of effects: Learning individual responses from population data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explanations for negative query answers under
inconsistency-tolerant semantics. <em>IJCAI</em>, 2705–2711. (<a
href="https://doi.org/10.24963/ijcai.2022/375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inconsistency-tolerant semantics have been proposed to provide meaningful query answers even in the presence of inconsistent knowledge. Recently, explainability has also become a prominent problem in different areas of AI. While the complexity of inconsistency-tolerant semantics is rather well-understood, not much attention has been paid yet to the problem of explaining query answers when inconsistencies may exist. Recent work on existential rules in the inconsistent setting has focused only on understanding why a query is entailed. In this paper, we address another important problem, which is explaining why a query is not entailed under an inconsistency-tolerant semantics. In particular, we consider three popular semantics, namely, the ABox repair, the intersection of repairs, and the intersection of closed repairs. We provide a thorough complexity analysis for a wide range of existential rule languages and for several complexity measures. Keywords: Knowledge Representation and Reasoning: Computational Complexity of Reasoning},
  archive   = {C_IJCAI},
  author    = {Thomas Lukasiewicz and Enrico Malizia and Cristian Molinaro},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/375},
  pages     = {2705-2711},
  title     = {Explanations for negative query answers under inconsistency-tolerant semantics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Search space expansion for efficient incremental inductive
logic programming from streamed data. <em>IJCAI</em>, 2697–2704. (<a
href="https://doi.org/10.24963/ijcai.2022/374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the past decade, several systems for learning Answer Set Programs (ASP) have been proposed, including the recent FastLAS system. Compared to other state-of-the-art approaches to learning ASP, FastLAS is more scalable, as rather than computing the hypothesis space in full, it computes a much smaller subset relative to a given set of examples that is nonetheless guaranteed to contain an optimal solution to the task (called an OPT-sufficient subset). On the other hand, like many other Inductive Logic Programming (ILP) systems, FastLAS is designed to be run on a fixed learning task meaning that if new examples are discovered after learning, the whole process must be run again. In many real applications, data arrives in a stream. Rerunning an ILP system from scratch each time new examples arrive is inefficient. In this paper we address this problem by presenting IncrementalLAS, a system that uses a new technique, called hypothesis space expansion, to enable a FastLAS-like OPT-sufficient subset to be expanded each time new examples are discovered. We prove that this preserves FastLAS&#39;s guarantee of finding an optimal solution to the full task (including the new examples), while removing the need to repeat previous computations. Through our evaluation, we demonstrate that running IncrementalLAS on tasks updated with sequences of new examples is significantly faster than re-running FastLAS from scratch on each updated task. Keywords: Knowledge Representation and Reasoning: Learning and reasoning Knowledge Representation and Reasoning: Logic Programming},
  archive   = {C_IJCAI},
  author    = {Mark Law and Krysia Broda and Alessandra Russo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/374},
  pages     = {2697-2704},
  title     = {Search space expansion for efficient incremental inductive logic programming from streamed data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Conditional independence for iterated belief revision.
<em>IJCAI</em>, 2690–2696. (<a
href="https://doi.org/10.24963/ijcai.2022/373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conditional independence is a crucial concept for efficient probabilistic reasoning. For symbolic and qualitative reasoning, however, it has played only a minor role. Recently, Lynn, Delgrande, and Peppas have considered conditional independence in terms of syntactic multivalued dependencies. In this paper, we define conditional independence as a semantic property of epistemic states and present axioms for iterated belief revision operators to obey conditional independence in general. We show that c-revisions for ranking functions satisfy these axioms, and exploit the relevance of these results for iterated belief revision in general. Keywords: Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Non-monotonic Reasoning Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Gabriele Kern-Isberner and Jesse Heyninck and Christoph Beierle},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/373},
  pages     = {2690-2696},
  title     = {Conditional independence for iterated belief revision},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). In data we trust: The logic of trust-based beliefs.
<em>IJCAI</em>, 2683–2689. (<a
href="https://doi.org/10.24963/ijcai.2022/372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper proposes a data-centred approach to reasoning about the interplay between trust and beliefs. At its core, is the modality &quot;under the assumption that one dataset is trustworthy, another dataset informs a belief in a statement&quot;. The main technical result is a sound and complete logical system capturing the properties of this modality. Keywords: Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Junli Jiang and Pavel Naumov},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/372},
  pages     = {2683-2689},
  title     = {In data we trust: The logic of trust-based beliefs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). The egocentric logic of preferences. <em>IJCAI</em>,
2676–2682. (<a href="https://doi.org/10.24963/ijcai.2022/371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The paper studies preferences of agents about other agents in a social network. It proposes a logical system that captures the properties of such preferences, called &quot;likes&quot;. The system can express nested constructions &quot;agent likes humbled people&quot;, &quot;agent likes those who like humbled people&quot;, etc. The main technical results are a model checking algorithm and a sound, complete, and decidable axiomatization of the proposed system. Keywords: Knowledge Representation and Reasoning: Preference Modelling and Preference-Based Reasoning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Junli Jiang and Pavel Naumov},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/371},
  pages     = {2676-2682},
  title     = {The egocentric logic of preferences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Computing concept referring expressions for queries on horn
ALC ontologies. <em>IJCAI</em>, 2669–2675. (<a
href="https://doi.org/10.24963/ijcai.2022/370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Classical instance queries over an ontology only consider explicitly named individuals. Concept referring expressions (CREs) also allow for returning answers in the form of concepts that describe implicitly given individuals in terms of their relation to an explicitly named one. Existing approaches, e.g., based on tree automata, can neither be integrated into state-of-the-art OWL reasoners nor are they directly amenable for an efficient implementation. To address this, we devise a novel algorithm that uses highly optimized OWL reasoners as a black box. In addition to the standard criteria of singularity and certainty for CREs, we devise and consider the criterion of uniqueness of CREs for Horn ALC ontologies. The evaluation of our prototypical implementation shows that computing CREs for the most general concept (Top) can be done in less than one minute for ontologies with thousands of individuals and concepts. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Moritz Illich and Birte Glimm},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/370},
  pages     = {2669-2675},
  title     = {Computing concept referring expressions for queries on horn ALC ontologies},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lexicographic entailment, syntax splitting and the drowning
problem. <em>IJCAI</em>, 2662–2668. (<a
href="https://doi.org/10.24963/ijcai.2022/369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Lexicographic inference is a well-known and popular approach to reasoning with non-monotonic conditionals. It is a logic of very high-quality, as it extends rational closure and avoids the so-called drowning problem. It seems, however, this high quality comes at a cost, as reasoning on the basis of lexicographic inference is of high computational complexity. In this paper, we show that lexicographic inference satisfies syntax splitting, which means that we can restrict our attention to parts of the belief base that share atoms with a given query, thus seriously restricting the computational costs for many concrete queries. Furthermore, we make some observations on the relationship between c-representations and lexicographic inference, and reflect on the relation between syntax splitting and the drowning problem. Keywords: Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Jesse Heyninck and Gabriele Kern-Isberner and Thomas Meyer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/369},
  pages     = {2662-2668},
  title     = {Lexicographic entailment, syntax splitting and the drowning problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Possibilistic logic underlies abstract dialectical
frameworks. <em>IJCAI</em>, 2655–2661. (<a
href="https://doi.org/10.24963/ijcai.2022/368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abstract dialectical frameworks (in short, ADFs) are one of the most general and unifying approaches to formal argumentation. As the semantics of ADFs are based on three-valued interpretations, we ask which monotonic three-valued logic allows to capture the main semantic concepts underlying ADFs. We show that possibilistic logic is the unique logic that can faithfully encode all other semantical concepts for ADFs. Based on this result, we also characterise strong equivalence and introduce possibilistic ADFs. Keywords: Knowledge Representation and Reasoning: Argumentation Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Jesse Heyninck and Gabriele Kern-Isberner and Tjitze Rienstra and Kenneth Skiba and Matthias Thimm},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/368},
  pages     = {2655-2661},
  title     = {Possibilistic logic underlies abstract dialectical frameworks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A computationally grounded logic of ’seeing-to-it-that’.
<em>IJCAI</em>, 2648–2654. (<a
href="https://doi.org/10.24963/ijcai.2022/367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a simple model of agency that is based on the concepts of control and attempt. Both relate agents and propositional variables. Moreover, they can be nested: an agent i may control whether another agent j controls a propositional variable p; i may control whether j attempts to change p; i may attempt to change whether j controls p; i may attempt to change whether j attempts to change p; and so on. In this framework we define several modal operators of time and agency: the LTL operators on the one hand, and the Chellas and the deliberative stit operator on the other. While in the standard stit framework the model checking problem is unfeasible because its models are infinite, in our framework models are represented in a finite and compact way: they are grounded on the primitive concepts of control and attempt. This makes model checking practically feasible. We prove its PSPACE-completeness and we show how the concept of social influence can be captured. Keywords: Knowledge Representation and Reasoning: Knowledge Representation Languages Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Knowledge Representation and Reasoning: Reasoning about actions},
  archive   = {C_IJCAI},
  author    = {Andreas Herzig and Emiliano Lorini and Elise Perrotin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/367},
  pages     = {2648-2654},
  title     = {A computationally grounded logic of &#39;Seeing-to-it-that&#39;},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Linear temporal logic modulo theories over finite traces.
<em>IJCAI</em>, 2641–2647. (<a
href="https://doi.org/10.24963/ijcai.2022/366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies Linear Temporal Logic over Finite Traces (LTLf) where proposition letters are replaced with first-order formulas interpreted over arbitrary theories, in the spirit of Satisfiability Modulo Theories. The resulting logic, called LTLf Modulo Theories (LTLfMT), is semi-decidable. Nevertheless, its high expressiveness comes useful in a number of use cases, such as model-checking of data-aware processes and data-aware planning. Despite the general undecidability of these problems, being able to solve satisfiable instances is a compromise worth studying. After motivating and describing such use cases, we provide a sound and complete semi-decision procedure for LTLfMT based on the SMT encoding of a one-pass tree-shaped tableau system. The algorithm is implemented in the BLACK satisfiability checking tool, and an experimental evaluation shows the feasibility of the approach on novel benchmarks. Keywords: Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning},
  archive   = {C_IJCAI},
  author    = {Luca Geatti and Alessandro Gianola and Nicola Gigante},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/366},
  pages     = {2641-2647},
  title     = {Linear temporal logic modulo theories over finite traces},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Simulating sets in answer set programming. <em>IJCAI</em>,
2634–2640. (<a href="https://doi.org/10.24963/ijcai.2022/365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the extension of non-monotonic disjunctive logic programs with terms that represent sets of constants, called DLP(S), under the stable model semantics. This strictly increases expressive power, but keeps reasoning decidable, though cautious entailment is coNEXPTIME^NP-complete, even for data complexity. We present two new reasoning methods for DLP(S): a semantics-preserving translation of DLP(S) to logic programming with function symbols, which can take advantage of lazy grounding techniques, and a ground-and-solve approach that uses non-monotonic existential rules in the grounding stage. Our evaluation considers problems of ontological reasoning that are not in scope for traditional ASP (unless EXPTIME =ΠP2 ), and we find that our new existential-rule grounding performs well in comparison with native implementations of set terms in ASP. Keywords: Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Sarah Alice Gaggl and Philipp Hanisch and Markus Krötzsch},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/365},
  pages     = {2634-2640},
  title     = {Simulating sets in answer set programming},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Frontiers and exact learning of ELI queries under DL-lite
ontologies. <em>IJCAI</em>, 2627–2633. (<a
href="https://doi.org/10.24963/ijcai.2022/364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study ELI queries (ELIQs) in the presence of ontologies formulated in the description logic DL-Lite. For the dialect DL-LiteH, we show that ELIQs have a frontier (set of least general generalizations) that is of polynomial size and can be computed in polynomial time. In the dialect DL-LiteF, in contrast, frontiers may be infinite. We identify a natural syntactic restriction that enables the same positive results as for DL-LiteH. We use our results on frontiers to show that ELIQs are learnable in polynomial time in the presence of a DL-LiteH / restricted DL-LiteF ontology in Angluin&#39;s framework of exact learning with only membership queries. Keywords: Knowledge Representation and Reasoning: Description Logics and Ontologies},
  archive   = {C_IJCAI},
  author    = {Maurice Funk and Jean Christoph Jung and Carsten Lutz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/364},
  pages     = {2627-2633},
  title     = {Frontiers and exact learning of ELI queries under DL-lite ontologies},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plausibility reasoning via projected answer set counting - a
hybrid approach. <em>IJCAI</em>, 2620–2626. (<a
href="https://doi.org/10.24963/ijcai.2022/363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer set programming is a form of declarative programming widely used to solve difficult search problems. Probabilistic applications however require to go beyond simple search for one solution and need counting. One such application is plausibility reasoning, which provides more fine-grained reasoning mode between simple brave and cautious reasoning. When modeling with ASP, we oftentimes introduce auxiliary atoms in the program. If these atoms are functionally independent of the atoms of interest, we need to hide the auxiliary atoms and project the count to the atoms of interest resulting in the problem projected answer set counting. In practice, counting becomes quickly infeasible with standard systems such as clasp. In this paper, we present a novel hybrid approach for plausibility reasoning under projections, thereby relying on projected answer set counting as basis. Our approach combines existing systems with fast dynamic programming, which in our experiments shows advantages over existing ASP systems. Keywords: Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Applications Knowledge Representation and Reasoning: Argumentation Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Johannes K. Fichte and Markus Hecher and Mohamed A. Nadeem},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/363},
  pages     = {2620-2626},
  title     = {Plausibility reasoning via projected answer set counting - a hybrid approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Abstract argumentation frameworks with marginal
probabilities. <em>IJCAI</em>, 2613–2619. (<a
href="https://doi.org/10.24963/ijcai.2022/362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the context of probabilistic AAFs, we intro- duce AAFs with marginal probabilities (mAAFs) requiring only marginal probabilities of argu- ments/attacks to be specified and not relying on the independence assumption. Reasoning over mAAFs requires taking into account multiple probability distributions over the possible worlds, so that the probability of extensions is not determined by a unique value, but by an interval. We focus on the problems of computing the max and min probabil- ities of extensions over mAAFs under Dung’s se- mantics, characterize their complexity, and provide closed formulas for polynomial cases. Keywords: Knowledge Representation and Reasoning: Argumentation Agent-based and Multi-agent Systems: Agreement Technologies: Argumentation Knowledge Representation and Reasoning: Computational Complexity of Reasoning},
  archive   = {C_IJCAI},
  author    = {Bettina Fazzinga and Sergio Flesca and Filippo Furfaro},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/362},
  pages     = {2613-2619},
  title     = {Abstract argumentation frameworks with marginal probabilities},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LTL on weighted finite traces: Formal foundations and
algorithms. <em>IJCAI</em>, 2606–2612. (<a
href="https://doi.org/10.24963/ijcai.2022/361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {LTL on finite traces (LTLf ) is a logic that attracted much attention in recent literature, for its ability to formalize the qualitative behavior of dynamical systems in several application domains. However, its practical usage is still rather limited, as LTLf cannot deal with any quantitative aspect, such as with the costs of realizing some desired behaviour. The paper fills the gap by proposing a weighting framework for LTLf encoding such quantitative aspects in the traces over which it is evaluated. The complexity of reasoning problems on weighted traces is analyzed and compared to that of standard LTLf, by considering arbitrary formulas as well as classes of formulas defined in terms of relevant syntactic restrictions. Moreover, a reasoner for LTL on weighted finite traces is presented, and its performances are assessed on benchmark data. Keywords: Knowledge Representation and Reasoning: Knowledge Representation Languages Knowledge Representation and Reasoning: Learning and reasoning},
  archive   = {C_IJCAI},
  author    = {Carmine Dodaro and Valeria Fionda and Gianluigi Greco},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/361},
  pages     = {2606-2612},
  title     = {LTL on weighted finite traces: Formal foundations and algorithms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Epistemic logic of likelihood and belief. <em>IJCAI</em>,
2599–2605. (<a href="https://doi.org/10.24963/ijcai.2022/360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A major challenge in AI is dealing with uncertain information. While probabilistic approaches have been employed to address this issue, in many situations probabilities may not be available or may be unsuitable. As an alternative, qualitative approaches have been introduced to express that one event is no more probable than another. We provide an approach where an agent may reason deductively about notions of likelihood, and may hold beliefs where the subjective probability for a belief is less than 1. Thus, an agent can believe that p holds (with probability &lt;1); and if the agent believes that q is more likely than p, then the agent will also believe q. Our language allows for arbitrary nesting of beliefs and qualitative likelihoods. We provide a sound and complete proof system for the logic with respect to an underlying probabilistic semantics, and show that the language is equivalent to a sublanguage with no nested modalities. Keywords: Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Agent-based and Multi-agent Systems: Agent Theories and Models Knowledge Representation and Reasoning: Knowledge Representation Languages},
  archive   = {C_IJCAI},
  author    = {James P. Delgrande and Joshua Sack and Gerhard Lakemeyer and Maurice Pagnucco},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/360},
  pages     = {2599-2605},
  title     = {Epistemic logic of likelihood and belief},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). LTLf synthesis as AND-OR graph search: Knowledge compilation
at work. <em>IJCAI</em>, 2591–2598. (<a
href="https://doi.org/10.24963/ijcai.2022/359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthesis techniques for temporal logic specifications are typically based on exploiting symbolic techniques, as done in model checking. These symbolic techniques typically use backward fixpoint computation. Planning, which can be seen as a specific form of synthesis, is a witness of the success of forward search approaches. In this paper, we develop a forward-search approach to full-fledged Linear Temporal Logic on finite traces (LTLf) synthesis. We show how to compute the Deterministic Finite Automaton (DFA) of an LTLf formula on-the-fly, while performing an adversarial forward search towards the final states, by considering the DFA as a sort of AND-OR graph. Our approach is characterized by branching on suitable propositional formulas, instead of individual evaluations, hence radically reducing the branching factor of the search space. Specifically, we take advantage of techniques developed for knowledge compilation, such as Sentential Decision Diagrams (SDDs), to implement the approach efficiently. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Giuseppe De Giacomo and Marco Favorito and Jianwen Li and Moshe Y. Vardi and Shengping Xiao and Shufang Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/359},
  pages     = {2591-2598},
  title     = {LTLf synthesis as AND-OR graph search: Knowledge compilation at work},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the complexity of enumerating prime implicants from
decision-DNNF circuits. <em>IJCAI</em>, 2583–2590. (<a
href="https://doi.org/10.24963/ijcai.2022/358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem Enum·IP of enumerating prime implicants of Boolean functions represented by decision decomposable negation normal form (dec-DNNF) circuits. We study Enum·IP from dec-DNNF within the framework of enumeration complexity and prove that it is in OutputP, the class of output polynomial enumeration problems, and more precisely in IncP, the class of polynomial incremental time enumeration problems. We then focus on two closely related, but seemingly harder, enumeration problems where further restrictions are put on the prime implicants to be generated. In the first problem, one is only interested in prime implicants representing subset-minimal abductive explanations, a notion much investigated in AI for more than thirty years. In the second problem, the target is prime implicants representing sufficient reasons, a recent yet important notion in the emerging field of eXplainable AI, since they aim to explain predictions achieved by machine learning classifiers. We provide evidence showing that enumerating specific prime implicants corresponding to subset-minimal abductive explanations or to sufficient reasons is not in OutputP. Keywords: Knowledge Representation and Reasoning: Knowledge Compilation and Tractable Languages},
  archive   = {C_IJCAI},
  author    = {Alexis de Colnet and Pierre Marquis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/358},
  pages     = {2583-2590},
  title     = {On the complexity of enumerating prime implicants from decision-DNNF circuits},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized federated learning with a graph.
<em>IJCAI</em>, 2575–2582. (<a
href="https://doi.org/10.24963/ijcai.2022/357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge sharing and model personalization are two key components in the conceptual framework of personalized federated learning (PFL). Existing PFL methods focus on proposing new model personalization mechanisms while simply implementing knowledge sharing by aggregating models from all clients, regardless of their relation graph. This paper aims to enhance the knowledge-sharing process in PFL by leveraging the graph-based structural information among clients. We propose a novel structured federated learning (SFL) framework to learn both the global and personalized models simultaneously using client-wise relation graphs and clients&#39; private data. We cast SFL with graph into a novel optimization problem that can model the client-wise complex relations and graph-based structural topology by a unified framework. Moreover, in addition to using an existing relation graph, SFL could be expanded to learn the hidden relations among clients. Experiments on traffic and image benchmark datasets can demonstrate the effectiveness of the proposed method. Keywords: Knowledge Representation and Reasoning: Reasong about actions Data Mining: Federated Learning},
  archive   = {C_IJCAI},
  author    = {Fengwen Chen and Guodong Long and Zonghan Wu and Tianyi Zhou and Jing Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/357},
  pages     = {2575-2582},
  title     = {Personalized federated learning with a graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On verifying expectations and observations of intelligent
agents. <em>IJCAI</em>, 2568–2574. (<a
href="https://doi.org/10.24963/ijcai.2022/356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Public observation logic (POL) is a variant of dynamic epistemic logic to reason about agent expectations and agent observations. Agents have certain expectations, regarding the situation at hand, that are actuated by the relevant protocols, and they eliminate possible worlds in which their expectations do not match with their observations. In this work, we investigate the computational complexity of the model checking problem for POL and prove its PSPACE-completeness. We also study various syntactic fragments of POL. We exemplify the applicability of POL model checking in verifying different characteristics and features of an interactive system with respect to the distinct expectations and (matching) observations of the system. Finally, we provide a discussion on the implementation of the model checking algorithms. Keywords: Knowledge Representation and Reasoning: Computational Complexity of Reasoning Knowledge Representation and Reasoning: Reasoning about actions Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief},
  archive   = {C_IJCAI},
  author    = {Sourav Chakraborty and Avijeet Ghosh and Sujata Ghosh and François Schwarzentruber},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/356},
  pages     = {2568-2574},
  title     = {On verifying expectations and observations of intelligent agents},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The limits of morality in strategic games. <em>IJCAI</em>,
2561–2567. (<a href="https://doi.org/10.24963/ijcai.2022/355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An agent, or a coalition of agents, is blameable for an outcome if she had a strategy to prevent it. In this paper we introduce a notion of limited blameworthiness, with a constraint on the amount of sacrifice required to prevent the outcome. The main technical contribution is a sound and complete logical system for reasoning about limited blameworthiness in the strategic game setting. Keywords: Knowledge Representation and Reasoning: Reasoning about actions},
  archive   = {C_IJCAI},
  author    = {Rui Cao and Pavel Naumov},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/355},
  pages     = {2561-2567},
  title     = {The limits of morality in strategic games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Verification and monitoring for first-order LTL with
persistence-preserving quantification over finite and infinite traces.
<em>IJCAI</em>, 2553–2560. (<a
href="https://doi.org/10.24963/ijcai.2022/354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the problem of model checking first-order dynamic systems where new objects can be injected in the active domain during execution. Notable examples are systems induced by a first-order action theory, e.g., expressed in the Situation Calculus. Recent results have shown that, under the state-boundedness assumption, such systems, in spite of having a first-order representation of the state, admit decidable model checking for full first-order mu-calculus. However, interestingly, model checking remains undecidable in the case of first-order LTL (LTL-FO). In this paper, we show that in LTL-FOp, which is the fragment of LTL-FO in which quantification is over objects that persist along traces, model checking state-bounded systems becomes decidable over finite and infinite traces. We then employ this result to show how to handle monitoring of LTL-FOp properties against a trace stemming from an unknown state-bounded dynamic system, simultaneously considering the finite trace up to the current point, and all its possibly infinite future continuations. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Diego Calvanese and Giuseppe De Giacomo and Marco Montali and Fabio Patrizi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/354},
  pages     = {2553-2560},
  title     = {Verification and monitoring for first-order LTL with persistence-preserving quantification over finite and infinite traces},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Body-decoupled grounding via solving: A novel approach on
the ASP bottleneck. <em>IJCAI</em>, 2546–2552. (<a
href="https://doi.org/10.24963/ijcai.2022/353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Answer-Set Programming (ASP) has seen tremendous progress over the last two decades and is nowadays successfully applied in many real-world domains. However, for certain types of problems, the well-known ASP grounding bottleneck still causes severe problems. This becomes virulent when grounding of rules, where the variables have to be replaced by constants, leads to a ground pro- gram that is too huge to be processed by the ASP solver. In this work, we tackle this problem by a novel method that decouples non-ground atoms in rules in order to delegate the evaluation of rule bodies to the solving process. Our procedure translates a non-ground normal program into a ground disjunctive program that is exponential only in the maximum predicate arity, and thus polynomial if this arity is assumed to be bounded by a constant. We demonstrate the feasibility of this new method experimentally by comparing it to standard ASP technology in terms of grounding size, grounding time and total runtime. Keywords: Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Computational Complexity of Reasoning},
  archive   = {C_IJCAI},
  author    = {Viktor Besin and Markus Hecher and Stefan Woltran},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/353},
  pages     = {2546-2552},
  title     = {Body-decoupled grounding via solving: A novel approach on the ASP bottleneck},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Limits and possibilities of forgetting in abstract
argumentation. <em>IJCAI</em>, 2539–2545. (<a
href="https://doi.org/10.24963/ijcai.2022/352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The topic of forgetting has been extensively studied in the field of knowledge representation and reasoning for many major formalisms. Quite recently it has been introduced to abstract argumentation. However, many already known as well as essential aspects about forgetting like strong persistence or strong invariance have been left unconsidered. We show that forgetting in abstract argumentation cannot be reduced to forgetting in logic programming. In addition, we deal with the more general problem of forgetting whole sets of arguments and show that iterative application of existing operators for single arguments does not necessarily yield a desirable result as it may not produce an informationally economic argumentation framework. As a consequence we provide a systematic and exhaustive study of forgetting desiderata and associated operations adapted to the intrinsics of abstract argumentation. We show the limits and shed light on the possibilities. Keywords: Knowledge Representation and Reasoning: Argumentation Knowledge Representation and Reasoning: Belief Change Knowledge Representation and Reasoning: Logic Programming Knowledge Representation and Reasoning: Non-monotonic Reasoning},
  archive   = {C_IJCAI},
  author    = {Ringo Baumann and Matti Berthold},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/352},
  pages     = {2539-2545},
  title     = {Limits and possibilities of forgetting in abstract argumentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Annotated sequent calculi for paraconsistent reasoning and
their relations to logical argumentation. <em>IJCAI</em>, 2532–2538. (<a
href="https://doi.org/10.24963/ijcai.2022/351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce annotated sequent calculi, which are extensions of standard sequent calculi, where sequents are combined with annotations that represent their derivation statuses. Unlike in ordinary calculi, sequents that are derived in annotated calculi may still be retracted in the presence of conflicting sequents, thus inferences are made under stricter conditions. Conflicts in the resulting systems are handled like in adaptive logics and argumentation theory. The outcome is a robust family of proof systems for non-monotonic reasoning with inconsistent information, where revision considerations are fully integrated into the object level of the proofs. These systems are shown to be strongly connected to logical argumentation. Keywords: Knowledge Representation and Reasoning: Non-monotonic Reasoning Knowledge Representation and Reasoning: Argumentation Knowledge Representation and Reasoning: Common-Sense Reasoning},
  archive   = {C_IJCAI},
  author    = {Ofer Arieli and Kees van Berkel and Christian Straßer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/351},
  pages     = {2532-2538},
  title     = {Annotated sequent calculi for paraconsistent reasoning and their relations to logical argumentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond strong-cyclic: Doing your best in stochastic
environments. <em>IJCAI</em>, 2525–2531. (<a
href="https://doi.org/10.24963/ijcai.2022/350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {``Strong-cyclic policies&quot; were introduced to formalize trial-and-error strategies and are known to work in Markovian stochastic domains, i.e., they guarantee that the goal is reached with probability 1. We introduce ``best-effort&quot; policies for (not necessarily Markovian) stochastic domains. These generalize strong-cyclic policies by taking advantage of stochasticity even if the goal cannot be reached with probability 1. We compare such policies with optimal policies, i.e., policies that maximize the probability that the goal is achieved, and show that optimal policies are best-effort, but that the converse is false in general. With this framework at hand, we revisit the foundational problem of what it means to plan in nondeterministic domains when the nondeterminism has a stochastic nature. We show that one can view a nondeterministic planning domain as a representation of infinitely many stochastic domains with the same support but different probabilities, and that for temporally extended goals expressed in LTL/LTLf a finite-state best-effort policy in one of these domains is best-effort in each of the domains. In particular, this gives an approach for finding such policies that reduces to solving finite-state MDPs with LTL/LTLf goals. All this shows that ``best-effort&quot; policies are robust to changes in the probabilities, as long as the support is unchanged. Keywords: Knowledge Representation and Reasoning: Reasoning about actions Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Benjamin Aminof and Giuseppe De Giacomo and Sasha Rubin and Florian Zuleger},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/350},
  pages     = {2525-2531},
  title     = {Beyond strong-cyclic: Doing your best in stochastic environments},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On preferences and priority rules in abstract argumentation.
<em>IJCAI</em>, 2517–2524. (<a
href="https://doi.org/10.24963/ijcai.2022/349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dung&#39;s abstract Argumentation Framework (AF) has emerged as a central formalism for argumentation in AI. Preferences in AF allow to represent the comparative strength of arguments in a simple yet expressive way. In this paper we first investigate the complexity of the verification as well as credulous and skeptical acceptance problems in Preference-based AF (PAF) that extends AF with preferences over arguments. Next, after introducing new semantics for AF where extensions are selected using cardinality (instead of set inclusion) criteria and investigating their complexity, we introduce a framework called AF with Priority rules (AFP) that extends AF with sequences of priority rules. AFP generalizes AF with classical set-inclusion and cardinality based semantics, suggesting that argumentation semantics can be viewed as ways to express priorities among extensions. Finally, we extend AFP by proposing AF with Priority rules and Preferences (AFP^2), where also preferences over arguments can be used to define priority rules, and study the complexity of the above-mentioned problems. Keywords: Knowledge Representation and Reasoning: Argumentation},
  archive   = {C_IJCAI},
  author    = {Gianvincenzo Alfano and Sergio Greco and Francesco Parisi and Irina Trubitsyna},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/349},
  pages     = {2517-2524},
  title     = {On preferences and priority rules in abstract argumentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking InfoNCE: How many negative samples do you need?
<em>IJCAI</em>, 2509–2515. (<a
href="https://doi.org/10.24963/ijcai.2022/348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {InfoNCE is a widely used contrastive training loss. It aims to estimate the mutual information between a pair of variables by discriminating between each positive pair and its associated K negative pairs. It is proved that when the sample labels are clean, the lower bound of mutual information estimation is tighter when more negative samples are incorporated, which usually yields better model performance. However, in practice the labels often contain noise, and incorporating too many noisy negative samples into model training may be suboptimal. In this paper, we study how many negative samples are optimal for InfoNCE in different scenarios via a semi-quantitative theoretical framework. More specifically, we first propose a probabilistic model to analyze the influence of the negative sampling ratio K on training sample informativeness. Then, we design a training effectiveness function to measure the overall influence of training samples based on their informativeness. We estimate the optimal negative sampling ratio using the K value that maximizes the training effectiveness function. Based on our framework, we further propose an adaptive negative sampling method that can dynamically adjust the negative sampling ratio to improve InfoNCE-based model training. Extensive experiments in three different tasks show our framework can accurately predict the optimal negative sampling ratio, and various models can benefit from our adaptive negative sampling method. Keywords: Humans and AI: Personalization and User Modeling Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Chuhan Wu and Fangzhao Wu and Yongfeng Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/348},
  pages     = {2509-2515},
  title     = {Rethinking InfoNCE: How many negative samples do you need?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Signed neuron with memory: Towards simple, accurate and
high-efficient ANN-SNN conversion. <em>IJCAI</em>, 2501–2508. (<a
href="https://doi.org/10.24963/ijcai.2022/347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking Neural Networks (SNNs) are receiving increasing attention due to their biological plausibility and the potential for ultra-low-power event-driven neuromorphic hardware implementation. Due to the complex temporal dynamics and discontinuity of spikes, training SNNs directly usually suffers from high computing resources and a long training time. As an alternative, SNN can be converted from a pre-trained artificial neural network (ANN) to bypass the difficulty in SNNs learning. However, the existing ANN-to-SNN methods neglect the inconsistency of information transmission between synchronous ANNs and asynchronous SNNs. In this work, we first analyze how the asynchronous spikes in SNNs may cause conversion errors between ANN and SNN. To address this problem, we propose a signed neuron with memory function, which enables almost no accuracy loss during the conversion process, and maintains the properties of asynchronous transmission in the converted SNNs. We further propose a new normalization method, named neuron-wise normalization, to significantly shorten the inference latency in the converted SNNs. We conduct experiments on challenging datasets including CIFAR10 (95.44\% top-1), CIFAR100 (78.3\% top-1) and ImageNet (73.16\% top-1). Experimental results demonstrate that the proposed method outperforms the state-of-the-art works in terms of accuracy and inference time. The code is available at https://github.com/ppppps/ANN2SNNConversion_SNM_NeuronNorm. Keywords: Humans and AI: Cognitive Modeling Humans and AI: Applications Humans and AI: Cognitive Systems},
  archive   = {C_IJCAI},
  author    = {Yuchen Wang and Malu Zhang and Yi Chen and Hong Qu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/347},
  pages     = {2501-2508},
  title     = {Signed neuron with memory: Towards simple, accurate and high-efficient ANN-SNN conversion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semi-supervised imitation learning of team policies from
suboptimal demonstrations. <em>IJCAI</em>, 2492–2500. (<a
href="https://doi.org/10.24963/ijcai.2022/346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present Bayesian Team Imitation Learner (BTIL), an imitation learning algorithm to model the behavior of teams performing sequential tasks in Markovian domains. In contrast to existing multi-agent imitation learning techniques, BTIL explicitly models and infers the time-varying mental states of team members, thereby enabling learning of decentralized team policies from demonstrations of suboptimal teamwork. Further, to allow for sample- and label-efficient policy learning from small datasets, BTIL employs a Bayesian perspective and is capable of learning from semi-supervised demonstrations. We demonstrate and benchmark the performance of BTIL on synthetic multi-agent tasks as well as a novel dataset of human-agent teamwork. Our experiments show that BTIL can successfully learn team policies from demonstrations despite the influence of team members&#39; (time-varying and potentially misaligned) mental states on their behavior. Keywords: Humans and AI: Human-AI Collaboration Agent-based and Multi-agent Systems: Human-Agent Interaction Machine Learning: Bayesian Learning Robotics: Human Robot Interaction Uncertainty in AI: Sequential Decision Making},
  archive   = {C_IJCAI},
  author    = {Sangwon Seo and Vaibhav V. Unhelkar},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/346},
  pages     = {2492-2500},
  title     = {Semi-supervised imitation learning of team policies from suboptimal demonstrations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient and accurate conversion of spiking neural network
with burst spikes. <em>IJCAI</em>, 2485–2491. (<a
href="https://doi.org/10.24963/ijcai.2022/345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking neural network (SNN), as a brain-inspired energy-efficient neural network, has attracted the interest of researchers. While the training of spiking neural networks is still an open problem. One effective way is to map the weight of trained ANN to SNN to achieve high reasoning ability. However, the converted spiking neural network often suffers from performance degradation and a considerable time delay. To speed up the inference process and obtain higher accuracy, we theoretically analyze the errors in the conversion process from three perspectives: the differences between IF and ReLU, time dimension, and pooling operation. We propose a neuron model for releasing burst spikes, a cheap but highly efficient method to solve residual information. In addition, Lateral Inhibition Pooling (LIPooling) is proposed to solve the inaccuracy problem caused by MaxPooling in the conversion process. Experimental results on CIFAR and ImageNet demonstrate that our algorithm is efficient and accurate. For example, our method can ensure nearly lossless conversion of SNN and only use about 1/10 (less than 100) simulation time under 0.693x energy consumption of the typical method. Our code is available at https://github.com/Brain-Inspired-Cognitive-Engine/Conversion_Burst. Keywords: Humans and AI: Cognitive Modeling},
  archive   = {C_IJCAI},
  author    = {Yang Li and Yi Zeng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/345},
  pages     = {2485-2491},
  title     = {Efficient and accurate conversion of spiking neural network with burst spikes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forming effective human-AI teams: Building machine learning
models that complement the capabilities of multiple experts.
<em>IJCAI</em>, 2478–2484. (<a
href="https://doi.org/10.24963/ijcai.2022/344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Machine learning (ML) models are increasingly being used in application domains that often involve working together with human experts. In this context, it can be advantageous to defer certain instances to a single human expert when they are difficult to predict for the ML model. While previous work has focused on scenarios with one distinct human expert, in many real-world situations several human experts with varying capabilities may be available. In this work, we propose an approach that trains a classification model to complement the capabilities of multiple human experts. By jointly training the classifier together with an allocation system, the classifier learns to accurately predict those instances that are difficult for the human experts, while the allocation system learns to pass each instance to the most suitable team member—either the classifier or one of the human experts. We evaluate our proposed approach in multiple experiments on public datasets with “synthetic” experts and a real-world medical dataset annotated by multiple radiologists. Our approach outperforms prior work and is more accurate than the best human expert or a classifier. Furthermore, it is flexibly adaptable to teams of varying sizes and different levels of expert diversity. Keywords: Humans and AI: Human-AI Collaboration},
  archive   = {C_IJCAI},
  author    = {Patrick Hemmer and Sebastian Schellhammer and Michael Vössing and Johannes Jakubik and Gerhard Satzger},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/344},
  pages     = {2478-2484},
  title     = {Forming effective human-AI teams: Building machine learning models that complement the capabilities of multiple experts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level firing with spiking DS-ResNet: Enabling better
and deeper directly-trained spiking neural networks. <em>IJCAI</em>,
2471–2477. (<a href="https://doi.org/10.24963/ijcai.2022/343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatio-temporal information to directly train SNNs by backpropagation. However, the binary and non-differentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level firing (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormant-suppressed residual network (spiking DS-ResNet). MLF enables more efficient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efficiently perform identity mapping of discrete spikes, as well as provide a more suitable connection for gradient propagation in deep SNNs. With the proposed method, our model achieves superior performances on a non-neuromorphic dataset and two neuromorphic datasets with much fewer trainable parameters and demonstrates the great ability to combat the gradient vanishing and degradation problem in deep SNNs. Keywords: Humans and AI: Cognitive Modeling Humans and AI: Cognitive Systems},
  archive   = {C_IJCAI},
  author    = {Lang Feng and Qianhui Liu and Huajin Tang and De Ma and Gang Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/343},
  pages     = {2471-2477},
  title     = {Multi-level firing with spiking DS-ResNet: Enabling better and deeper directly-trained spiking neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-tier platform for cognizing massive
electroencephalogram. <em>IJCAI</em>, 2464–2470. (<a
href="https://doi.org/10.24963/ijcai.2022/342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An end-to-end platform assembling multiple tiers is built for precisely cognizing brain activities. Being fed massive electroencephalogram (EEG) data, the time-frequency spectrograms are conventionally projected into the episode-wise feature matrices (seen as tier-1). A spiking neural network (SNN) based tier is designed to distill the principle information in terms of spike-streams from the rare features, which maintains the temporal implication in the nature of EEGs. The proposed tier-3 transposes time- and space-domain of spike patterns from the SNN; and feeds the transposed pattern-matrices into an artificial neural network (ANN, Transformer specifically) known as tier-4, where a special spanning topology is proposed to match the two-dimensional input form. In this manner, cognition such as classification is conducted with high accuracy. For proof-of-concept, the sleep stage scoring problem is demonstrated by introducing multiple EEG datasets with the largest comprising 42, 560 hours recorded from 5, 793 subjects. From experiment results, our platform achieves the general cognition overall accuracy of 87\% by leveraging sole EEG, which is 2\% superior to the state-of-the-art. Moreover, our developed multi-tier methodology offers visible and graphical interpretations of the temporal characteristics of EEG by identifying the critical episodes, which is demanded in neurodynamics but hardly appears in conventional cognition scenarios. Keywords: Humans and AI: Cognitive Systems Humans and AI: Brain Sciences Humans and AI: Cognitive Modeling Humans and AI: Applications},
  archive   = {C_IJCAI},
  author    = {Zheng Chen and Lingwei Zhu and Ziwei Yang and Renyuan Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/342},
  pages     = {2464-2470},
  title     = {Multi-tier platform for cognizing massive electroencephalogram},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the utility of prediction sets in human-AI teams.
<em>IJCAI</em>, 2457–2463. (<a
href="https://doi.org/10.24963/ijcai.2022/341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Research on human-AI teams usually provides experts with a single label, which ignores the uncertainty in a model&#39;s recommendation. Conformal prediction (CP) is a well established line of research that focuses on building a theoretically grounded, calibrated prediction set, which may contain multiple labels. We explore how such prediction sets impact expert decision-making in human-AI teams. Our evaluation on human subjects finds that set valued predictions positively impact experts. However, we notice that the predictive sets provided by CP can be very large, which leads to unhelpful AI assistants. To mitigate this, we introduce D-CP, a method to perform CP on some examples and defer to experts. We prove that D-CP can reduce the prediction set size of non-deferred examples. We show how D-CP performs in quantitative and in human subject experiments (n=120). Our results suggest that CP prediction sets improve human-AI team performance over showing the top-1 prediction alone, and that experts find D-CP prediction sets are more useful than CP prediction sets. Keywords: Humans and AI: Human-AI Collaboration AI Ethics, Trust, Fairness: Trustworthy AI Uncertainty in AI: Uncertainty Representations Machine Learning: Probabilistic Machine Learning},
  archive   = {C_IJCAI},
  author    = {Varun Babbar and Umang Bhatt and Adrian Weller},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/341},
  pages     = {2457-2463},
  title     = {On the utility of prediction sets in human-AI teams},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proximity enhanced graph neural networks with channel
contrast. <em>IJCAI</em>, 2448–2455. (<a
href="https://doi.org/10.24963/ijcai.2022/340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider graph representation learning in an unsupervised manner. Graph neural networks use neighborhood aggregation as a core component that results in feature smoothing among nodes in proximity. While successful in various prediction tasks, such a paradigm falls short of capturing nodes&#39; similarities over a long distance, which proves to be important for high-quality learning. To tackle this problem, we strengthen the graph with three types of additional graph views, in which each node is directly linked to a set of nodes with the highest similarity in terms of node features, neighborhood features or local structures. Not restricted by connectivity in the original graph, the generated views provide new and complementary perspectives from which to look at the relationship between nodes. Inspired by the recent success of contrastive learning approaches, we propose a self-supervised method that aims to learn node representations by maximizing the agreement between representations across generated views and the original graph, without the requirement of any label information. We also propose a channel-level contrast approach that greatly reduces computation cost. Extensive experiments on six assortative graphs and three disassortative graphs demonstrate the effectiveness of our approach. Keywords: Data Mining: Mining Graphs Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wei Zhuo and Guang Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/340},
  pages     = {2448-2455},
  title     = {Proximity enhanced graph neural networks with channel contrast},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Data-free adversarial knowledge distillation for graph
neural networks. <em>IJCAI</em>, 2441–2447. (<a
href="https://doi.org/10.24963/ijcai.2022/339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have been widely used in modeling graph structured data, owing to its impressive performance in a wide range of practical applications. Recently, knowledge distillation (KD) for GNNs has enabled remarkable progress in graph model compression and knowledge transfer. However, most of the existing KD methods require a large volume of real data, which are not readily available in practice, and may preclude their applicability in scenarios where the teacher model is trained on rare or hard to acquire datasets. To address this problem, we propose the first end-to-end framework for data-free adversarial knowledge distillation on graph structured data (DFAD-GNN). To be specific, our DFAD-GNN employs a generative adversarial network, which mainly consists of three components: a pre-trained teacher model and a student model are regarded as two discriminators, and a generator is utilized for deriving training graphs to distill knowledge from the teacher model into the student model. Extensive experiments on various benchmark models and six representative datasets demonstrate that our DFAD-GNN significantly surpasses state-of-the-art data-free baselines in the graph classification task. Keywords: Data Mining: Mining Graphs Machine Learning: Adversarial Machine Learning Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Yuanxin Zhuang and Lingjuan Lyu and Chuan Shi and Carl Yang and Lichao Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/339},
  pages     = {2441-2447},
  title     = {Data-free adversarial knowledge distillation for graph neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Spiking graph convolutional networks. <em>IJCAI</em>,
2434–2440. (<a href="https://doi.org/10.24963/ijcai.2022/338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Convolutional Networks (GCNs) achieve an impressive performance due to the remarkable representation ability in learning the graph information. However, GCNs, when implemented on a deep network, require expensive computation power, making them difficult to be deployed on battery-powered devices. In contrast, Spiking Neural Networks (SNNs), which perform a bio-fidelity inference process, offer an energy-efficient neural architecture. In this work, we propose SpikingGCN, an end-to-end framework that aims to integrate the embedding of GCNs with the biofidelity characteristics of SNNs. The original graph data are encoded into spike trains based on the incorporation of graph convolution. We further model biological information processing by utilizing a fully connected layer combined with neuron nodes. In a wide range of scenarios (e.g., citation networks, image graph classification, and recommender systems), our experimental results show that the proposed method could gain competitive performance against state-of-the-art approaches. Furthermore, we show that SpikingGCN on a neuromorphic chip can bring a clear advantage of energy efficiency into graph data analysis, which demonstrates its great potential to construct environment-friendly machine learning models. Keywords: Data Mining: Mining Graphs Humans and AI: Brain Sciences Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zulun Zhu and Jiaying Peng and Jintang Li and Liang Chen and Qi Yu and Siqiang Luo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/338},
  pages     = {2434-2440},
  title     = {Spiking graph convolutional networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Bridging differential privacy and byzantine-robustness via
model aggregation. <em>IJCAI</em>, 2427–2433. (<a
href="https://doi.org/10.24963/ijcai.2022/337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper aims at jointly addressing two seemly conflicting issues in federated learning: differential privacy (DP) and Byzantine-robustness, which are particularly challenging when the distributed data are non-i.i.d. (independent and identically distributed). The standard DP mechanisms add noise to the transmitted messages, and entangles with robust stochastic gradient aggregation to defend against Byzantine attacks. In this paper, we decouple the two issues via robust stochastic model aggregation, in the sense that our proposed DP mechanisms and the defense against Byzantine attacks have separated influence on the learning performance. Leveraging robust stochastic model aggregation, at each iteration, each worker calculates the difference between the local model and the global one, followed by sending the element-wise signs to the master node, which enables robustness to Byzantine attacks. Further, we design two DP mechanisms to perturb the uploaded signs for the purpose of privacy preservation, and prove that they are (epsilon, 0)-DP by exploiting the properties of noise distributions. With the tools of Moreau envelop and proximal point projection, we establish the convergence of the proposed algorithm when the cost function is nonconvex. We analyze the trade-off between privacy preservation and learning performance, and show that the influence of our proposed DP mechanisms is decoupled with that of robust stochastic model aggregation. Numerical experiments demonstrate the effectiveness of the proposed algorithm. Keywords: Data Mining: Federated Learning Machine Learning: Robustness AI Ethics, Trust, Fairness: Safety &amp; Robustness},
  archive   = {C_IJCAI},
  author    = {Heng Zhu and Qing Ling},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/337},
  pages     = {2427-2433},
  title     = {Bridging differential privacy and byzantine-robustness via model aggregation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Table2Graph: Transforming tabular data to unified weighted
graph. <em>IJCAI</em>, 2420–2426. (<a
href="https://doi.org/10.24963/ijcai.2022/336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning useful interactions between input features is crucial for tabular data modeling. Recent efforts start to explicitly model the feature interactions with graph, where each feature is treated as an individual node. However, the existing graph construction methods either heuristically formulate a fixed feature-interaction graph based on specific domain knowledge, or simply apply attention function to compute the pairwise feature similarities for each sample. While the fixed graph may be sub-optimal to downstream tasks, the sample-wise graph construction is time-consuming during model training and inference. To tackle these issues, we propose a framework named Table2Graph to transform the feature interaction modeling to learning a unified graph. Represented as a probability adjacency matrix, the unified graph learns to model the key feature interactions shared by the diverse samples in the tabular data. To well optimize the unified graph, we employ the reinforcement learning policy to capture the key feature interactions stably. A sparsity constraint is also proposed to regularize the learned graph from being overly-sparse/smooth. The experimental results in a variety of real-world applications demonstrate the effectiveness and efficiency of our Table2Graph, in terms of the prediction accuracy and feature interaction detection. Keywords: Data Mining: Recommender Systems Data Mining: Mining Graphs Data Mining: Information Retrieval Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Kaixiong Zhou and Zirui Liu and Rui Chen and Li Li and Soo-Hyun Choi and Xia Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/336},
  pages     = {2420-2426},
  title     = {Table2Graph: Transforming tabular data to unified weighted graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MFAN: Multi-modal feature-enhanced attention networks for
rumor detection. <em>IJCAI</em>, 2413–2419. (<a
href="https://doi.org/10.24963/ijcai.2022/335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rumor spreaders are increasingly taking advantage of multimedia content to attract and mislead news consumers on social media. Although recent multimedia rumor detection models have exploited both textual and visual features for classification, they do not integrate the social structure features simultaneously, which have shown promising performance for rumor identification. It is challenging to combine the heterogeneous multi-modal data in consideration of their complex relationships. In this work, we propose a novel Multi-modal Feature-enhanced Attention Networks (MFAN) for rumor detection, which makes the first attempt to integrate textual, visual, and social graph features in one unified framework. Specifically, it considers both the complement and alignment relationships between different modalities to achieve better fusion. Moreover, it takes into account the incomplete links in the social network data due to data collection constraints and proposes to infer hidden links to learn better social graph features. The experimental results show that MFAN can detect rumors effectively and outperform state-of-the-art methods. Keywords: Data Mining: Mining Text, Web, Social Media Machine Learning: Multi-modal learning Machine Learning: Attention Models Natural Language Processing: Text Classification Natural Language Processing: Information Retrieval and Text Mining},
  archive   = {C_IJCAI},
  author    = {Jiaqi Zheng and Xi Zhang and Sanchuan Guo and Quan Wang and Wenyu Zang and Yongdong Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/335},
  pages     = {2413-2419},
  title     = {MFAN: Multi-modal feature-enhanced attention networks for rumor detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). T-SMOTE: Temporal-oriented synthetic minority oversampling
technique for imbalanced time series classification. <em>IJCAI</em>,
2406–2412. (<a href="https://doi.org/10.24963/ijcai.2022/334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Time series classification is a popular and important topic in machine learning, and it suffers from the class imbalance problem in many real-world applications. In this paper, to address the class imbalance problem, we propose a novel and practical oversampling method named T-SMOTE, which can make full use of the temporal information of time-series data. In particular, for each sample of minority class, T-SMOTE generates multiple samples that are close to class border. Then, based on those samples near class border, T-SMOTE synthesizes more samples. Finally, a weighted sampling method is called on both generated samples near class border and synthetic samples. Extensive experiments on a diverse set of both univariate and multivariate time-series datasets demonstrate that T-SMOTE consistently outperforms the current state-of-the-art methods on imbalanced time series classification. More encouragingly, our empirical evaluations show that T-SMOTE performs better in the scenario of early prediction, an important application scenario in industry, which indicates that T-SMOTE could bring benefits in practice. Keywords: Data Mining: Class Imbalance and Unequal Cost Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Pu Zhao and Chuan Luo and Bo Qiao and Lu Wang and Saravan Rajmohan and Qingwei Lin and Dongmei Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/334},
  pages     = {2406-2412},
  title     = {T-SMOTE: Temporal-oriented synthetic minority oversampling technique for imbalanced time series classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing sequential recommendation with graph contrastive
learning. <em>IJCAI</em>, 2398–2405. (<a
href="https://doi.org/10.24963/ijcai.2022/333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The sequential recommendation systems capture users&#39; dynamic behavior patterns to predict their next interaction behaviors. Most existing sequential recommendation methods only exploit the local context information of an individual interaction sequence and learn model parameters solely based on the item prediction loss. Thus, they usually fail to learn appropriate sequence representations. This paper proposes a novel recommendation framework, namely Graph Contrastive Learning for Sequential Recommendation (GCL4SR). Specifically, GCL4SR employs a Weighted Item Transition Graph (WITG), built based on interaction sequences of all users, to provide global context information for each interaction and weaken the noise information in the sequence data. Moreover, GCL4SR uses subgraphs of WITG to augment the representation of each interaction sequence. Two auxiliary learning objectives have also been proposed to maximize the consistency between augmented representations induced by the same interaction sequence on WITG, and minimize the difference between the representations augmented by the global context on WITG and the local representation of the original sequence. Extensive experiments on real-world datasets demonstrate that GCL4SR consistently outperforms state-of-the-art sequential recommendation methods. Keywords: Data Mining: Recommender Systems Machine Learning: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Yixin Zhang and Yong Liu and Yonghui Xu and Hao Xiong and Chenyi Lei and Wei He and Lizhen Cui and Chunyan Miao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/333},
  pages     = {2398-2405},
  title     = {Enhancing sequential recommendation with graph contrastive learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GRELEN: Multivariate time series anomaly detection from the
perspective of graph relational learning. <em>IJCAI</em>, 2390–2397. (<a
href="https://doi.org/10.24963/ijcai.2022/332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {System monitoring and anomaly detection is a crucial task in daily operation. With the rapid development of cyber-physical systems and IT systems, multiple sensors get involved to represent the system state from different perspectives, which inspires us to detect anomalies considering feature dependence relationship among sensors instead of focusing on individual sensor&#39;s behavior. In this paper, we propose a novel Graph Relational Learning Network (GReLeN) to detect multivariate time series anomalies from the perspective of between-sensor dependence relationship learning. Variational AutoEncoder (VAE) serves as the overall framework for feature extraction and system representation. Graph Neural Network (GNN) and stochastic graph relational learning strategy are also imposed to capture the between-sensor dependence. Then a composite anomaly metric is established with the learned dependence structure explicitly. The experiments on four real-world datasets show our superiority in detection accuracy, anomaly diagnosis, and model interpretation. Keywords: Data Mining: Anomaly/Outlier Detection Data Mining: Applications Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Weiqi Zhang and Chen Zhang and Fugee Tsung},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/332},
  pages     = {2390-2397},
  title     = {GRELEN: Multivariate time series anomaly detection from the perspective of graph relational learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic graph learning based on hierarchical memory for
origin-destination demand prediction. <em>IJCAI</em>, 2383–2389. (<a
href="https://doi.org/10.24963/ijcai.2022/331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent years have witnessed a rapid growth of applying deep spatiotemporal methods in traffic forecasting. However, the prediction of origin-destination (OD) demands is still a challenging problem since the number of OD pairs is usually quadratic to the number of stations. In this case, most of the existing spatiotemporal methods fail to handle spatial relations on such a large scale. To address this problem, this paper provides a dynamic graph representation learning framework for OD demands prediction. In particular, a hierarchical memory updater is first proposed to maintain a time-aware representation for each node, and the representations are updated according to the most recently observed OD trips in continuous-time and multiple discrete-time ways. Second, a spatiotemporal propagation mechanism is provided to aggregate representations of neighbor nodes along a random spatiotemporal route which treats origin and destination as two different semantic entities. Last, an objective function is designed to derive the future OD demands according to the most recent node representations, and also to tackle the data sparsity problem in OD prediction. Extensive experiments have been conducted on two real-world datasets, and the experimental results demonstrate the superiority of the proposed method. The code and data are available at https://github.com/Rising0321/HMOD. Keywords: Data Mining: Mining Graphs Data Mining: Mining Spatial and/or Temporal Data Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Ruixing Zhang and Liangzhe Han and Boyi Liu and Jiayuan Zeng and Leilei Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/331},
  pages     = {2383-2389},
  title     = {Dynamic graph learning based on hierarchical memory for origin-destination demand prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconstruction enhanced multi-view contrastive learning for
anomaly detection on attributed networks. <em>IJCAI</em>, 2376–2382. (<a
href="https://doi.org/10.24963/ijcai.2022/330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Detecting abnormal nodes from attributed networks is of great importance in many real applications, such as financial fraud detection and cyber security. This task is challenging due to both the complex interactions between the anomalous nodes with other counterparts and their inconsistency in terms of attributes. This paper proposes a self-supervised learning framework that jointly optimizes a multi-view contrastive learning-based module and an attribute reconstruction-based module to more accurately detect anomalies on attributed networks. Specifically, two contrastive learning views are firstly established, which allow the model to better encode rich local and global information related to the abnormality. Motivated by the attribute consistency principle between neighboring nodes, a masked autoencoder-based reconstruction module is also introduced to identify the nodes which have large reconstruction errors, then are regarded as anomalies. Finally, the two complementary modules are integrated for more accurately detecting the anomalous nodes. Extensive experiments conducted on five benchmark datasets show our model outperforms current state-of-the-art models. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Self-supervised Learning Machine Learning: Multi-view learning Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Jiaqiang Zhang and Senzhang Wang and Songcan Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/330},
  pages     = {2376-2382},
  title     = {Reconstruction enhanced multi-view contrastive learning for anomaly detection on attributed networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CERT: Continual pre-training on sketches for
library-oriented code generation. <em>IJCAI</em>, 2369–2375. (<a
href="https://doi.org/10.24963/ijcai.2022/329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Code generation is a longstanding challenge, aiming to generate a code snippet based on a natural language description. Usually, expensive text-code paired data is essential for training a code generation model. Recently, thanks to the success of pre-training techniques, large language models are trained on large unlabelled code corpora and perform well in generating code. In this paper, we investigate how to leverage an unlabelled code corpus to train a model for library-oriented code generation. Since it is a common practice for programmers to reuse third-party libraries, in which case the text-code paired data are harder to obtain due to the huge number of libraries. We observe that library-oriented code snippets are more likely to share similar code sketches. Hence, we present CERT with two steps: a sketcher generates the sketch, then a generator fills the details in the sketch. Both the sketcher and generator are continually pre-trained upon a base model using unlabelled data. Also, we carefully craft two benchmarks to evaluate library-oriented code generation named PandasEval and NumpyEval. Experimental results have shown the impressive performance of CERT. For example, it surpasses the base model by an absolute 15.67\% improvement in terms of pass@1 on PandasEval. Our work is available at https://github.com/microsoft/PyCodeGPT. Keywords: Data Mining: Mining Codebase and Software Repository Multidisciplinary Topics and Applications: Software Engineering Natural Language Processing: Language Models Natural Language Processing: Resources and Evaluation},
  archive   = {C_IJCAI},
  author    = {Daoguang Zan and Bei Chen and Dejian Yang and Zeqi Lin and Minsu Kim and Bei Guan and Yongji Wang and Weizhu Chen and Jian-Guang Lou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/329},
  pages     = {2369-2375},
  title     = {CERT: Continual pre-training on sketches for library-oriented code generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Regularized graph structure learning with semantic knowledge
for multi-variates time-series forecasting. <em>IJCAI</em>, 2362–2368.
(<a href="https://doi.org/10.24963/ijcai.2022/328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multivariate time-series forecasting is a critical task for many applications, and graph time-series network is widely studied due to its capability to capture the spatial-temporal correlation simultaneously. However, most existing works focus more on learning with the explicit prior graph structure, while ignoring potential information from the implicit graph structure, yielding incomplete structure modeling. Some recent works attempts to learn the intrinsic or implicit graph structure directly, while lacking a way to combine explicit prior structure with implicit structure together. In this paper, we propose Regularized Graph Structure Learning (RGSL) model to incorporate both explicit prior structure and implicit structure together, and learn the forecasting deep networks along with the graph structure. RGSL consists of two innovative modules. First, we derive an implicit dense similarity matrix through node embedding, and learn the sparse graph structure using the Regularized Graph Generation (RGG) based on the Gumbel Softmax trick. Second, we propose a Laplacian Matrix Mixed-up Module (LM3) to fuse the explicit graph and implicit graph together. We conduct experiments on three real-word datasets. Results show that the proposed RGSL model outperforms existing graph forecasting algorithms with a notable margin, while learning meaningful graph structure simultaneously. Our code and models are made publicly available at https://github.com/alipay/RGSL.git. Keywords: Data Mining: Mining Graphs Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Hongyuan Yu and Ting Li and Weichen Yu and Jianguo Li and Yan Huang and Liang Wang and Alex Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/328},
  pages     = {2362-2368},
  title     = {Regularized graph structure learning with semantic knowledge for multi-variates time-series forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Trading hard negatives and true negatives: A debiased
contrastive collaborative filtering approach. <em>IJCAI</em>, 2355–2361.
(<a href="https://doi.org/10.24963/ijcai.2022/327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collaborative filtering (CF), as a standard method for recommendation with implicit feedback, tackles a semi-supervised learning problem where most interaction data are unobserved. Such a nature makes existing approaches highly rely on mining negatives for providing correct training signals. However, mining proper negatives is not a free lunch, encountering with a tricky trade-off between mining informative hard negatives and avoiding false ones. We devise a new approach named as Hardness-Aware Debiased Contrastive Collaborative Filtering (HDCCF) to resolve the dilemma. It could sufficiently explore hard negatives from two-fold aspects: 1) adaptively sharpening the gradients of harder instances through a set-wise objective, and 2) implicitly leveraging item/user frequency information with a new sampling strategy. To circumvent false negatives, we develop a principled approach to improve the reliability of negative instances and prove that the objective is an unbiased estimation of sampling from the true negative distribution. Extensive experiments demonstrate the superiority of the proposed model over existing CF models and hard negative mining methods. Keywords: Data Mining: Collaborative Filtering Data Mining: Information Retrieval Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Chenxiao Yang and Qitian Wu and Jipeng Jin and Xiaofeng Gao and Junwei Pan and Guihai Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/327},
  pages     = {2355-2361},
  title     = {Trading hard negatives and true negatives: A debiased contrastive collaborative filtering approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GOCPT: Generalized online canonical polyadic tensor
factorization and completion. <em>IJCAI</em>, 2348–2354. (<a
href="https://doi.org/10.24963/ijcai.2022/326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Low-rank tensor factorization or completion is well-studied and applied in various online settings, such as online tensor factorization (where the temporal mode grows) and online tensor completion (where incomplete slices arrive gradually). However, in many real-world settings, tensors may have more complex evolving patterns: (i) one or more modes can grow; (ii) missing entries may be filled; (iii) existing tensor elements can change. Existing methods cannot support such complex scenarios. To fill the gap, this paper proposes a Generalized Online Canonical Polyadic (CP) Tensor factorization and completion framework (named GOCPT) for this general setting, where we maintain the CP structure of such dynamic tensors during the evolution. We show that existing online tensor factorization and completion setups can be unified under the GOCPT framework. Furthermore, we propose a variant, named GOCPTE, to deal with cases where historical tensor elements are unavailable (e.g., privacy protection), which achieves similar fitness as GOCPT but with much less computational cost. Experimental results demonstrate that our GOCPT can improve fitness by up to 2.8\% on the JHU Covid data and 9.2\% on a proprietary patient claim dataset over baselines. Our variant GOCPTE shows up to 1.2\% and 5.5\% fitness improvement on two datasets with about 20\% speedup compared to the best model. Keywords: Data Mining: Mining Spatial and/or Temporal Data Constraint Satisfaction and Optimization: Solvers and Tools Data Mining: Mining Data Streams Machine Learning: Online Learning},
  archive   = {C_IJCAI},
  author    = {Chaoqi Yang and Cheng Qian and Jimeng Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/326},
  pages     = {2348-2354},
  title     = {GOCPT: Generalized online canonical polyadic tensor factorization and completion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Subgraph neighboring relations infomax for inductive link
prediction on knowledge graphs. <em>IJCAI</em>, 2341–2347. (<a
href="https://doi.org/10.24963/ijcai.2022/325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inductive link prediction for knowledge graph aims at predicting missing links between unseen entities, those not shown in training stage. Most previous works learn entity-specific embeddings of entities, which cannot handle unseen entities. Recent several methods utilize enclosing subgraph to obtain inductive ability. However, all these works only consider the enclosing part of subgraph without complete neighboring relations, which leads to the issue that partial neighboring relations are neglected, and sparse subgraphs are hard to be handled. To address that, we propose Subgraph Neighboring Relations Infomax, SNRI, which sufficiently exploits complete neighboring relations from two aspects: neighboring relational feature for node feature and neighboring relational path for sparse subgraph. To further model neighboring relations in a global way, we innovatively apply mutual information (MI) maximization for knowledge graph. Experiments show that SNRI outperforms existing state-of-art methods by a large margin on inductive link prediction task, and verify the effectiveness of exploring complete neighboring relations in a global way to characterize node features and reason on sparse subgraphs. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Knowledge Representation and Reasoning: Learning and reasoning Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Machine Learning: Representation learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiaohan Xu and Peng Zhang and Yongquan He and Chengpeng Chao and Chaoyang Yan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/325},
  pages     = {2341-2347},
  title     = {Subgraph neighboring relations infomax for inductive link prediction on knowledge graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FedCG: Leverage conditional GAN for protecting privacy and
maintaining competitive performance in federated learning.
<em>IJCAI</em>, 2334–2340. (<a
href="https://doi.org/10.24963/ijcai.2022/324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) aims to protect data privacy by enabling clients to build machine learning models collaboratively without sharing their private data. Recent works demonstrate that information exchanged during FL is subject to gradient-based privacy attacks and, consequently, a variety of privacy-preserving methods have been adopted to thwart such attacks. However, these defensive methods either introduce orders of magnitudes more computational and communication overheads (e.g., with homomorphic encryption) or incur substantial model performance losses in terms of prediction accuracy (e.g., with differential privacy). In this work, we propose FEDCG, a novel federated learning method that leverages conditional generative adversarial networks to achieve high-level privacy protection while still maintaining competitive model performance. FEDCG decomposes each client&#39;s local network into a private extractor and a public classifier and keeps the extractor local to protect privacy. Instead of exposing extractors, FEDCG shares clients&#39; generators with the server for aggregating clients&#39; shared knowledge aiming to enhance the performance of each client&#39;s local networks. Extensive experiments demonstrate that FEDCG can achieve competitive model performance compared with FL baselines, and privacy analysis shows that FEDCG has a high-level privacy-preserving capability. Keywords: Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining Machine Learning: Generative Adverserial Networks Knowledge Representation and Reasoning: Reasong about actions},
  archive   = {C_IJCAI},
  author    = {Yuezhou Wu and Yan Kang and Jiahuan Luo and Yuanqin He and Lixin Fan and Rong Pan and Qiang Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/324},
  pages     = {2334-2340},
  title     = {FedCG: Leverage conditional GAN for protecting privacy and maintaining competitive performance in federated learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Decentralized unsupervised learning of visual
representations. <em>IJCAI</em>, 2326–2333. (<a
href="https://doi.org/10.24963/ijcai.2022/323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Collaborative learning enables distributed clients to learn a shared model for prediction while keeping the training data local on each client. However, existing collaborative learning methods require fully-labeled data for training, which is inconvenient or sometimes infeasible to obtain due to the high labeling cost and the requirement of expertise. The lack of labels makes collaborative learning impractical in many realistic settings. Self-supervised learning can address this challenge by learning from unlabeled data. Contrastive learning (CL), a self-supervised learning approach, can effectively learn visual representations from unlabeled image data. However, the distributed data collected on clients are usually not independent and identically distributed (non-IID) among clients, and each client may only have few classes of data, which degrades the performance of CL and learned representations. To tackle this problem, we propose a collaborative contrastive learning framework consisting of two approaches: feature fusion and neighborhood matching, by which a unified feature space among clients is learned for better data representations. Feature fusion provides remote features as accurate contrastive information to each client for better local learning. Neighborhood matching further aligns each client’s local features to the remote features such that well-clustered features among clients can be learned. Extensive experiments show the effectiveness of the proposed framework. It outperforms other methods by 11\% on IID data and matches the performance of centralized learning. Keywords: Data Mining: Federated Learning Machine Learning: Self-supervised Learning Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Yawen Wu and Zhepeng Wang and Dewen Zeng and Meng Li and Yiyu Shi and Jingtong Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/323},
  pages     = {2326-2333},
  title     = {Decentralized unsupervised learning of visual representations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding and mitigating data contamination in deep
anomaly detection: A kernel-based approach. <em>IJCAI</em>, 2319–2325.
(<a href="https://doi.org/10.24963/ijcai.2022/322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep anomaly detection has become popular for its capability of handling complex data. However, training a deep detector is fragile to data contamination due to overfitting. In this work, we study the performance of the anomaly detectors under data contamination and construct a data-efficient countermeasure against data contamination. We show that training a deep anomaly detector induces an implicit kernel machine. We then derive an information-theoretic bound of performance degradation with respect to the data contamination ratio. To mitigate the degradation, we propose a contradicting training approach. Apart from learning normality on the contaminated dataset, our approach discourages learning an additional small auxiliary dataset of labeled anomalies. Our approach is much more affordable than constructing a completely clean training dataset. Experiments on public datasets show that our approach significantly improves anomaly detection in the presence of contamination and outperforms some recently proposed detectors. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Kernel Methods},
  archive   = {C_IJCAI},
  author    = {Shuang Wu and Jingyu Zhao and Guangjian Tian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/322},
  pages     = {2319-2325},
  title     = {Understanding and mitigating data contamination in deep anomaly detection: A kernel-based approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-graph fusion networks for urban region embedding.
<em>IJCAI</em>, 2312–2318. (<a
href="https://doi.org/10.24963/ijcai.2022/321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning the embeddings for urban regions from human mobility data can reveal the functionality of regions, and then enables the correlated but distinct tasks such as crime prediction. Human mobility data contains rich but abundant information, which yields to the comprehensive region embeddings for cross domain tasks. In this paper, we propose multi-graph fusion networks (MGFN) to enable the cross domain prediction tasks. First, we integrate the graphs with spatio-temporal similarity as mobility patterns through a mobility graph fusion module. Then, in the mobility pattern joint learning module, we design the multi-level cross-attention mechanism to learn the comprehensive embeddings from multiple mobility patterns based on intra-pattern and inter-pattern messages. Finally, we conduct extensive experiments on real-world urban datasets. Experimental results demonstrate that the proposed MGFN outperforms the state-of-the-art methods by up to 12.35\% improvement. https://github.com/wushangbin/MGFN Keywords: Data Mining: Mining Graphs Data Mining: Mining Heterogenous Data Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Shangbin Wu and Xu Yan and Xiaoliang Fan and Shirui Pan and Shichao Zhu and Chuanpan Zheng and Ming Cheng and Cheng Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/321},
  pages     = {2312-2318},
  title     = {Multi-graph fusion networks for urban region embedding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CTL-MTNet: A novel CapsNet and transfer learning-based mixed
task net for single-corpus and cross-corpus speech emotion recognition.
<em>IJCAI</em>, 2305–2311. (<a
href="https://doi.org/10.24963/ijcai.2022/320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Speech Emotion Recognition (SER) has become a growing focus of research in human-computer interaction. An essential challenge in SER is to extract common attributes from different speakers or languages, especially when a specific source corpus has to be trained to recognize the unknown data coming from another speech corpus. To address this challenge, a Capsule Network (CapsNet) and Transfer Learning based Mixed Task Net (CTL-MTNet) are proposed to deal with both the single-corpus and cross-corpus SER tasks simultaneously in this paper. For the single-corpus task, the combination of Convolution-Pooling and Attention CapsNet module (CPAC) is designed by embedding the self-attention mechanism to the CapsNet, guiding the module to focus on the important features that can be fed into different capsules. The extracted high-level features by CPAC provide sufficient discriminative ability. Furthermore, to handle the cross-corpus task, CTL-MTNet employs a Corpus Adaptation Adversarial Module (CAAM) by combining CPAC with Margin Disparity Discrepancy (MDD), which can learn the domain-invariant emotion representations through extracting the strong emotion commonness. Experiments including ablation studies and visualizations on both single- and cross-corpus tasks using four well-known SER datasets in different languages are conducted for performance evaluation and comparison. The results indicate that in both tasks the CTL-MTNet showed better performance in all cases compared to a number of state-of-the-art methods. The source code and the supplementary materials are available at: https://github.com/MLDMXM2017/CTLMTNet. Keywords: Data Mining: Applications Humans and AI: Cognitive Modeling Humans and AI: Human-Computer Interaction Machine Learning: Classification Natural Language Processing: Speech},
  archive   = {C_IJCAI},
  author    = {Xin-Cheng Wen and JiaXin Ye and Yan Luo and Yong Xu and Xuan-Ze Wang and Chang-Li Wu and Kun-Hong Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/320},
  pages     = {2305-2311},
  title     = {CTL-MTNet: A novel CapsNet and transfer learning-based mixed task net for single-corpus and cross-corpus speech emotion recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Ensemble multi-relational graph neural networks.
<em>IJCAI</em>, 2298–2304. (<a
href="https://doi.org/10.24963/ijcai.2022/319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {It is well established that graph neural networks (GNNs) can be interpreted and designed from the perspective of optimization objective. With this clear optimization objective, the deduced GNNs architecture has sound theoretical foundation, which is able to flexibly remedy the weakness of GNNs. However, this optimization objective is only proved for GNNs with single-relational graph. Can we infer a new type of GNNs for multi-relational graphs by extending this optimization objective, so as to simultaneously solve the issues in previous multi-relational GNNs, e.g., over-parameterization? In this paper, we propose a novel ensemble multi-relational GNNs by designing an ensemble multi-relational (EMR) optimization objective. This EMR optimization objective is able to derive an iterative updating rule, which can be formalized as an ensemble message passing (EnMP) layer with multi-relations. We further analyze the nice properties of EnMP layer, e.g., the relationship with multi-relational personalized PageRank. Finally, a new multi-relational GNNs which well alleviate the over-smoothing and over-parameterization issues are proposed. Extensive experiments conducted on four benchmark datasets well demonstrate the effectiveness of the proposed model. Keywords: Data Mining: Mining Graphs Data Mining: Mining Heterogenous Data Machine Learning: Representation learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yuling Wang and Hao Xu and Yanhua Yu and Mengdi Zhang and Zhenhao Li and Yuji Yang and Wei Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/319},
  pages     = {2298-2304},
  title     = {Ensemble multi-relational graph neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Language models as knowledge embeddings. <em>IJCAI</em>,
2291–2297. (<a href="https://doi.org/10.24963/ijcai.2022/318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental results show that LMKE achieves state-of-the-art performance on KE benchmarks of link prediction and triple classification, especially for long-tail entities. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Natural Language Processing: Language Models Natural Language Processing: Embeddings Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Xintao Wang and Qianyu He and Jiaqing Liang and Yanghua Xiao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/318},
  pages     = {2291-2297},
  title     = {Language models as knowledge embeddings},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FAITH: Few-shot graph classification with hierarchical task
graphs. <em>IJCAI</em>, 2284–2290. (<a
href="https://doi.org/10.24963/ijcai.2022/317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot graph classification aims at predicting classes for graphs, given limited labeled graphs for each class. To tackle the bottleneck of label scarcity, recent works propose to incorporate few-shot learning frameworks for fast adaptations to graph classes with limited labeled graphs. Specifically, these works propose to accumulate meta-knowledge across diverse meta-training tasks, and then generalize such meta-knowledge to the target task with a disjoint label set. However, existing methods generally ignore task correlations among meta-training tasks while treating them independently. Nevertheless, such task correlations can advance the model generalization to the target task for better classification performance. On the other hand, it remains non-trivial to utilize task correlations due to the complex components in a large number of meta-training tasks. To deal with this, we propose a novel few-shot learning framework FAITH that captures task correlations via constructing a hierarchical task graph at different granularities. Then we further design a loss-based sampling strategy to select tasks with more correlated classes. Moreover, a task-specific classifier is proposed to utilize the learned task correlations for few-shot classification. Extensive experiments on four prevalent few-shot graph classification datasets demonstrate the superiority of FAITH over other state-of-the-art baselines. Keywords: Data Mining: Mining Graphs Machine Learning: Classification Machine Learning: Meta-Learning Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Song Wang and Yushun Dong and Xiao Huang and Chen Chen and Jundong Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/317},
  pages     = {2284-2290},
  title     = {FAITH: Few-shot graph classification with hierarchical task graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting knowledge graphs for better link prediction.
<em>IJCAI</em>, 2277–2283. (<a
href="https://doi.org/10.24963/ijcai.2022/316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Embedding methods have demonstrated robust performance on the task of link prediction in knowledge graphs, by mostly encoding entity relationships. Recent methods propose to enhance the loss function with a literal-aware term. In this paper, we propose KGA: a knowledge graph augmentation method that incorporates literals in an embedding model without modifying its loss function. KGA discretizes quantity and year values into bins, and chains these bins both horizontally, modeling neighboring values, and vertically, modeling multiple levels of granularity. KGA is scalable and can be used as a pre-processing step for any existing knowledge graph embedding model. Experiments on legacy benchmarks and a new large benchmark, DWD, show that augmenting the knowledge graph with quantities and years is beneficial for predicting both entities and numbers, as KGA outperforms the vanilla models and other relevant baselines. Our ablation studies confirm that both quantities and years contribute to KGA&#39;s performance, and that its performance depends on the discretization and binning settings. We make the code, models, and the DWD benchmark publicly available to facilitate reproducibility and future research. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Knowledge Representation and Reasoning: Learning and reasoning Knowledge Representation and Reasoning: Semantic Web Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Jiang Wang and Filip Ilievski and Pedro Szekely and Ke-Thia Yao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/316},
  pages     = {2277-2283},
  title     = {Augmenting knowledge graphs for better link prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HCFRec: Hash collaborative filtering via normalized flow
with structural consensus for efficient recommendation. <em>IJCAI</em>,
2270–2276. (<a href="https://doi.org/10.24963/ijcai.2022/315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The ever-increasing data scale of user-item interactions makes it challenging for an effective and efficient recommender system. Recently, hash-based collaborative filtering (Hash-CF) approaches employ efficient Hamming distance of learned binary representations of users and items to accelerate recommendations. However, Hash-CF often faces two challenging problems, i.e., optimization on discrete representations and preserving semantic information in learned representations. To address the above two challenges, we propose HCFRec, a novel Hash-CF approach for effective and efficient recommendations. Specifically, HCFRec not only innovatively introduces normalized flow to learn the optimal hash code by efficiently fitting a proposed approximate mixture multivariate normal distribution, a continuous but approximately discrete distribution, but also deploys a cluster consistency preserving mechanism to preserve the semantic structure in representations for more accurate recommendations. Extensive experiments conducted on six real-world datasets demonstrate the superiority of our HCFRec compared to the state-of-art methods in terms of effectiveness and efficiency. Keywords: Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Fan Wang and Weiming Liu and Chaochao Chen and Mengying Zhu and Xiaolin Zheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/315},
  pages     = {2270-2276},
  title     = {HCFRec: Hash collaborative filtering via normalized flow with structural consensus for efficient recommendation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MEIM: Multi-partition embedding interaction beyond block
term format for efficient and expressive link prediction.
<em>IJCAI</em>, 2262–2269. (<a
href="https://doi.org/10.24963/ijcai.2022/314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge graph embedding aims to predict the missing relations between entities in knowledge graphs. Tensor-decomposition-based models, such as ComplEx, provide a good trade-off between efficiency and expressiveness, that is crucial because of the large size of real world knowledge graphs. The recent multi-partition embedding interaction (MEI) model subsumes these models by using the block term tensor format and provides a systematic solution for the trade-off. However, MEI has several drawbacks, some of which carried from its subsumed tensor-decomposition-based models. In this paper, we address these drawbacks and introduce the Multi-partition Embedding Interaction iMproved beyond block term format (MEIM) model, with independent core tensor for ensemble effects and soft orthogonality for max-rank mapping, in addition to multi-partition embedding. MEIM improves expressiveness while still being highly efficient, helping it to outperform strong baselines and achieve state-of-the-art results on difficult link prediction benchmarks using fairly small embedding sizes. The source code is released at https://github.com/tranhungnghiep/MEIM. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Machine Learning: Representation learning Machine Learning: Relational Learning Natural Language Processing: Embeddings},
  archive   = {C_IJCAI},
  author    = {Hung-Nghiep Tran and Atsuhiro Takasu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/314},
  pages     = {2262-2269},
  title     = {MEIM: Multi-partition embedding interaction beyond block term format for efficient and expressive link prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anomaly detection by leveraging incomplete anomalous
knowledge with anomaly-aware bidirectional GANs. <em>IJCAI</em>,
2255–2261. (<a href="https://doi.org/10.24963/ijcai.2022/313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The goal of anomaly detection is to identify anomalous samples from normal ones. In this paper, a small number of anomalies are assumed to be available at the training stage, but they are assumed to be collected only from several anomaly types, leaving the majority of anomaly types not represented in the collected anomaly dataset at all. To effectively leverage this kind of incomplete anomalous knowledge represented by the collected anomalies, we propose to learn a probability distribution that can not only model the normal samples, but also guarantee to assign low density values for the collected anomalies. To this end, an anomaly-aware generative adversarial network (GAN) is developed, which, in addition to modeling the normal samples as most GANs do, is able to explicitly avoid assigning probabilities for collected anomalous samples. Moreover, to facilitate the computation of anomaly detection criteria like reconstruction error, the proposed anomaly-aware GAN is designed to be bidirectional, attaching an encoder for the generator. Extensive experimental results demonstrate that our proposed method is able to effectively make use of the incomplete anomalous information, leading to significant performance gains comparing to existing methods. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Generative Adverserial Networks},
  archive   = {C_IJCAI},
  author    = {Bowen Tian and Qinliang Su and Jian Yin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/313},
  pages     = {2255-2261},
  title     = {Anomaly detection by leveraging incomplete anomalous knowledge with anomaly-aware bidirectional GANs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Positive-unlabeled learning with adversarial data
augmentation for knowledge graph completion. <em>IJCAI</em>, 2248–2254.
(<a href="https://doi.org/10.24963/ijcai.2022/312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most real-world knowledge graphs (KG) are far from complete and comprehensive. This problem has motivated efforts in predicting the most plausible missing facts to complete a given KG, i.e., knowledge graph completion (KGC). However, existing KGC methods suffer from two main issues, 1) the false negative issue, i.e., the sampled negative training instances may include potential true facts; and 2) the data sparsity issue, i.e., true facts account for only a tiny part of all possible facts. To this end, we propose positive-unlabeled learning with adversarial data augmentation (PUDA) for KGC. In particular, PUDA tailors positive-unlabeled risk estimator for the KGC task to deal with the false negative issue. Furthermore, to address the data sparsity issue, PUDA achieves a data augmentation strategy by unifying adversarial training and positive-unlabeled learning under the positive-unlabeled minimax game. Extensive experimental results on real-world benchmark datasets demonstrate the effectiveness and compatibility of our proposed method. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Zhenwei Tang and Shichao Pei and Zhao Zhang and Yongchun Zhu and Fuzhen Zhuang and Robert Hoehndorf and Xiangliang Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/312},
  pages     = {2248-2254},
  title     = {Positive-unlabeled learning with adversarial data augmentation for knowledge graph completion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Personalized federated learning with contextualized
generalization. <em>IJCAI</em>, 2241–2247. (<a
href="https://doi.org/10.24963/ijcai.2022/311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The prevalent personalized federated learning (PFL) usually pursues a trade-off between personalization and generalization by maintaining a shared global model to guide the training process of local models. However, the sole global model may easily transfer deviated context knowledge to some local models when multiple latent contexts exist across the local datasets. In this paper, we propose a novel concept called contextualized generalization (CG) to provide each client with fine-grained context knowledge that can better fit the local data distributions and facilitate faster model convergence, based on which we properly design a framework of PFL, dubbed CGPFL. We conduct detailed theoretical analysis, in which the convergence guarantee is presented and a speedup of order 1/2 w.r.t the number of contexts over most existing methods is granted. To quantitatively study the generalization-personalization trade-off, we introduce the generalization error measure and prove that the proposed CGPFL can achieve a better trade-off than existing solutions. Moreover, our theoretical analysis further inspires a heuristic algorithm to find a near-optimal trade-off in CGPFL. Experimental results on multiple real-world datasets show that our approach surpasses the state-of-the-art methods on test accuracy by a significant margin. Keywords: Data Mining: Federated Learning Data Mining: Mining Heterogenous Data Data Mining: Parallel, Distributed and Cloud-based High Performance Mining Humans and AI: Personalization and User Modeling Machine Learning: Optimisation},
  archive   = {C_IJCAI},
  author    = {Xueyang Tang and Song Guo and Jingcai Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/311},
  pages     = {2241-2247},
  title     = {Personalized federated learning with contextualized generalization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond homophily: Structure-aware path aggregation graph
neural network. <em>IJCAI</em>, 2233–2240. (<a
href="https://doi.org/10.24963/ijcai.2022/310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph neural networks (GNNs) have been intensively studied in various real-world tasks. However, the homophily assumption of GNNs&#39; aggregation function limits their representation learning ability in heterophily graphs. In this paper, we shed light on the path level patterns in graphs that can explicitly reflect rich semantic and structural information. We therefore propose a novel Structure-aware Path Aggregation Graph Neural Network (PathNet) aiming to generalize GNNs for both homophily and heterophily graphs. Specifically, we first introduce a maximal entropy path sampler, which helps us sample a number of paths containing structural context. Then, we introduce a structure-aware recurrent cell consisting of order-preserving and distance-aware components to learn the semantic information of neighborhoods. Finally, we model the preference of different paths to target node after path encoding. Experimental results demonstrate that our model achieves superior performance in node classification on both heterophily and homophily graphs. Keywords: Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Yifei Sun and Haoran Deng and Yang Yang and Chunping Wang and Jiarong Xu and Renhong Huang and Linfeng Cao and Yang Wang and Lei Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/310},
  pages     = {2233-2240},
  title     = {Beyond homophily: Structure-aware path aggregation graph neural network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-term spatio-temporal forecasting via dynamic
multiple-graph attention. <em>IJCAI</em>, 2225–2232. (<a
href="https://doi.org/10.24963/ijcai.2022/309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many real-world ubiquitous applications, such as parking recommendations and air pollution monitoring, benefit significantly from accurate long-term spatio-temporal forecasting (LSTF). LSTF makes use of long-term dependency structure between the spatial and temporal domains, as well as the contextual information. Recent studies have revealed the potential of multi-graph neural networks (MGNNs) to improve prediction performance. However, existing MGNN methods do not work well when applied to LSTF due to several issues: the low level of generality, insufficient use of contextual information, and the imbalanced graph fusion approach. To address these issues, we construct new graph models to represent the contextual information of each node and exploit the long-term spatio-temporal data dependency structure. To aggregate the information across multiple graphs, we propose a new dynamic multi-graph fusion module to characterize the correlations of nodes within a graph and the nodes across graphs via the spatial attention and graph attention mechanisms. Furthermore, we introduce a trainable weight tensor to indicate the importance of each node in different graphs. Extensive experiments on two large-scale datasets demonstrate that our proposed approaches significantly improve the performance of existing graph neural network models in LSTF prediction tasks. Keywords: Data Mining: Mining Spatial and/or Temporal Data Multidisciplinary Topics and Applications: Smart Cities},
  archive   = {C_IJCAI},
  author    = {Wei Shao and Zhiling Jin and Shuo Wang and Yufan Kang and Xiao Xiao and Hamid Menouar and Zhaofeng Zhang and Junshan Zhang and Flora Salim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/309},
  pages     = {2225-2232},
  title     = {Long-term spatio-temporal forecasting via dynamic multiple-graph attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Federated learning on heterogeneous and long-tailed data via
classifier re-training with federated features. <em>IJCAI</em>,
2218–2224. (<a href="https://doi.org/10.24963/ijcai.2022/308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) provides a privacy-preserving solution for distributed machine learning tasks. One challenging problem that severely damages the performance of FL models is the co-occurrence of data heterogeneity and long-tail distribution, which frequently appears in real FL applications. In this paper, we reveal an intriguing fact that the biased classifier is the primary factor leading to the poor performance of the global model. Motivated by the above finding, we propose a novel and privacy-preserving FL method for heterogeneous and long-tailed data via Classifier Re-training with Federated Features (CReFF). The classifier re-trained on federated features can produce comparable performance as the one re-trained on real data in a privacy-preserving manner without information leakage of local data or class distribution. Experiments on several benchmark datasets show that the proposed CReFF is an effective solution to obtain a promising FL model under heterogeneous and long-tailed data. Comparative results with the state-of-the-art FL methods also validate the superiority of CReFF. Our code is available at https://github.com/shangxinyi/CReFF-FL. Keywords: Data Mining: Federated Learning Data Mining: Class Imbalance and Unequal Cost Computer Vision: Machine Learning for Vision Data Mining: Privacy Preserving Data Mining},
  archive   = {C_IJCAI},
  author    = {Xinyi Shang and Yang Lu and Gang Huang and Hanzi Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/308},
  pages     = {2218-2224},
  title     = {Federated learning on heterogeneous and long-tailed data via classifier re-training with federated features},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards resolving propensity contradiction in offline
recommender learning. <em>IJCAI</em>, 2211–2217. (<a
href="https://doi.org/10.24963/ijcai.2022/307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study offline recommender learning from explicit rating feedback in the presence of selection bias. A current promising solution for dealing with the bias is the inverse propensity score (IPS) estimation. However, the existing propensity-based methods can suffer significantly from the propensity estimation bias. In fact, most of the previous IPS-based methods require some amount of missing-completely-at-random (MCAR) data to accurately estimate the propensity. This leads to a critical self-contradiction; IPS is ineffective without MCAR data, even though it originally aims to learn recommenders from only missing-not-at-random feedback. To resolve this propensity contradiction, we derive a propensity-independent generalization error bound and propose a novel algorithm to minimize the theoretical bound via adversarial learning. Our theory and algorithm do not require a propensity estimation procedure, thereby leading to a well-performing rating predictor without the true propensity information. Extensive experiments demonstrate that the proposed algorithm is superior to a range of existing methods both in rating prediction and ranking metrics in practical settings without MCAR data. Full version of the paper (including the appendix) is available at: https://arxiv.org/abs/1910.07295. Keywords: Data Mining: Recommender Systems Data Mining: Collaborative Filtering Data Mining: Information Retrieval Data Mining: Theoretical Foundations of Data Mining Machine Learning: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Yuta Saito and Masahiro Nomura},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/307},
  pages     = {2211-2217},
  title     = {Towards resolving propensity contradiction in offline recommender learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Poisoning deep learning based recommender model in federated
learning scenarios. <em>IJCAI</em>, 2204–2210. (<a
href="https://doi.org/10.24963/ijcai.2022/306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Various attack methods against recommender systems have been proposed in the past years, and the security issues of recommender systems have drawn considerable attention. Traditional attacks attempt to make target items recommended to as many users as possible by poisoning the training data. Benifiting from the feature of protecting users&#39; private data, federated recommendation can effectively defend such attacks. Therefore, quite a few works have devoted themselves to developing federated recommender systems. For proving current federated recommendation is still vulnerable, in this work we probe to design attack approaches targeting deep learning based recommender models in federated learning scenarios. Specifically, our attacks generate poisoned gradients for manipulated malicious users to upload based on two strategies (i.e., random approximation and hard user mining). Extensive experiments show that our well-designed attacks can effectively poison the target models, and the attack effectiveness sets the state-of-the-art. Keywords: Data Mining: Recommender Systems Data Mining: Federated Learning Machine Learning: Adversarial Machine Learning Data Mining: Collaborative Filtering},
  archive   = {C_IJCAI},
  author    = {Dazhong Rong and Qinming He and Jianhai Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/306},
  pages     = {2204-2210},
  title     = {Poisoning deep learning based recommender model in federated learning scenarios},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Raising the bar in graph-level anomaly detection.
<em>IJCAI</em>, 2196–2203. (<a
href="https://doi.org/10.24963/ijcai.2022/305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-level anomaly detection has become a critical topic in diverse areas, such as financial fraud detection and detecting anomalous activities in social networks. While most research has focused on anomaly detection for visual data such as images, where high detection accuracies have been obtained, existing deep learning approaches for graphs currently show considerably worse performance. This paper raises the bar on graph-level anomaly detection, i.e., the task of detecting abnormal graphs in a set of graphs. By drawing on ideas from self-supervised learning and transformation learning, we present a new deep learning approach that significantly improves existing deep one-class approaches by fixing some of their known problems, including hypersphere collapse and performance flip. Experiments on nine real-world data sets involving nine techniques reveal that our method achieves an average performance improvement of 11.8\% AUC compared to the best existing approach. Keywords: Data Mining: Anomaly/Outlier Detection Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chen Qiu and Marius Kloft and Stephan Mandt and Maja Rudolph},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/305},
  pages     = {2196-2203},
  title     = {Raising the bar in graph-level anomaly detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Physics-informed long-sequence forecasting from
multi-resolution spatiotemporal data. <em>IJCAI</em>, 2189–2195. (<a
href="https://doi.org/10.24963/ijcai.2022/304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatiotemporal data aggregated over regions or time windows at various resolutions demonstrate heterogeneous patterns and dynamics in each resolution. Meanwhile, the multi-resolution characteristic provides rich contextual information, which is critical for effective long-sequence forecasting. The importance of such inter-resolution information is more significant in practical cases, where fine-grained data is usually collected via approaches with lower costs but also lower qualities compared to those for coarse-grained data. However, existing works focus on uni-resolution data and cannot be directly applied to fully utilize the aforementioned extra information in multi-resolution data. In this work, we propose Spatiotemporal Koopman Multi-Resolution Network (ST-KMRN), a physics-informed learning framework for long-sequence forecasting from multi-resolution spatiotemporal data. Our method jointly models data aggregated in multiple resolutions and captures the inter-resolution dynamics with the self-attention mechanism. We also propose downsampling and upsampling modules among resolutions to further strengthen the connections among data of multiple resolutions. Moreover, we enhance the modeling of intra-resolution dynamics with physics-informed modules based on Koopman theory. Experimental results demonstrate that our proposed approach achieves the best performance on the long-sequence forecasting tasks compared to baselines without a specific design for multi-resolution data. Keywords: Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Chuizheng Meng and Hao Niu and Guillaume Habault and Roberto Legaspi and Shinya Wada and Chihiro Ono and Yan Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/304},
  pages     = {2189-2195},
  title     = {Physics-informed long-sequence forecasting from multi-resolution spatiotemporal data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continual federated learning based on knowledge
distillation. <em>IJCAI</em>, 2182–2188. (<a
href="https://doi.org/10.24963/ijcai.2022/303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) is a promising approach for learning a shared global model on decentralized data owned by multiple clients without exposing their privacy. In real-world scenarios, data accumulated at the client-side varies in distribution over time. As a consequence, the global model tends to forget the knowledge obtained from previous tasks while learning new tasks, showing signs of &quot;catastrophic forgetting&quot;. Previous studies in centralized learning use techniques such as data replay and parameter regularization to mitigate catastrophic forgetting. Unfortunately, these techniques cannot adequately solve the non-trivial problem in FL. We propose Continual Federated Learning with Distillation (CFeD) to address catastrophic forgetting under FL. CFeD performs knowledge distillation on both the clients and the server, with each party independently having an unlabeled surrogate dataset, to mitigate forgetting. Moreover, CFeD assigns different learning objectives, namely learning the new task and reviewing old tasks, to different clients, aiming to improve the learning ability of the model. The results show that our method performs well in mitigating catastrophic forgetting and achieves a good trade-off between the two objectives. Keywords: Data Mining: Federated Learning Machine Learning: Incremental Learning},
  archive   = {C_IJCAI},
  author    = {Yuhang Ma and Zhongle Xie and Jue Wang and Ke Chen and Lidan Shou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/303},
  pages     = {2182-2188},
  title     = {Continual federated learning based on knowledge distillation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Reconciling cognitive modeling with knowledge forgetting: A
continuous time-aware neural network approach. <em>IJCAI</em>,
2174–2181. (<a href="https://doi.org/10.24963/ijcai.2022/302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As an emerging technology of computer-aided education, cognitive modeling aims at discovering the knowledge proficiency or learning ability of students, which can enable a wide range of intelligent educational applications. While considerable efforts have been made in this direction, a long-standing research challenge is how to naturally integrate the forgetting mechanism into the learning process of knowledge concepts. To this end, in this paper, we propose a novel Continuous Time based Neural Cognitive Modeling(CT-NCM) approach to integrate the dynamism and continuity of knowledge forgetting into students&#39; learning process modeling in a realistic manner. To be specific, we first adapt the neural Hawkes process with a specially-designed learning event encoding method to model the relationship between knowledge learning and forgetting with continuous time. Then, we propose a learning function with extendable settings to jointly model the change of different knowledge states and their interactions with the exercises at each moment. In this way, CT-NCM can simultaneously predict the future knowledge state and exercise performance of students. Finally, we conduct extensive experiments on five real-world datasets with various benchmark methods. The experimental results clearly validate the effectiveness of CT-NCM and show its interpretability in terms of knowledge learning visualization. Keywords: Data Mining: Applications Humans and AI: Cognitive Modeling Humans and AI: Computer-Aided Education Multidisciplinary Topics and Applications: Education},
  archive   = {C_IJCAI},
  author    = {Haiping Ma and Jingyuan Wang and Hengshu Zhu and Xin Xia and Haifeng Zhang and Xingyi Zhang and Lei Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/302},
  pages     = {2174-2181},
  title     = {Reconciling cognitive modeling with knowledge forgetting: A continuous time-aware neural network approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adapt to adaptation: Learning personalization for cross-silo
federated learning. <em>IJCAI</em>, 2166–2173. (<a
href="https://doi.org/10.24963/ijcai.2022/301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional federated learning (FL) trains one global model for a federation of clients with decentralized data, reducing the privacy risk of centralized training. However, the distribution shift across non-IID datasets, often poses a challenge to this one-model-fits-all solution. Personalized FL aims to mitigate this issue systematically. In this work, we propose APPLE, a personalized cross-silo FL framework that adaptively learns how much each client can benefit from other clients’ models. We also introduce a method to flexibly control the focus of training APPLE between global and local objectives. We empirically evaluate our method&#39;s convergence and generalization behaviors, and perform extensive experiments on two benchmark datasets and two medical imaging datasets under two non-IID settings. The results show that the proposed personalized FL framework, APPLE, achieves state-of-the-art performance compared to several other personalized FL approaches in the literature. The code is publicly available at https://github.com/ljaiverson/pFL-APPLE. Keywords: Data Mining: Federated Learning Computer Vision: Biomedical Image Analysis Knowledge Representation and Reasoning: Reasong about actions},
  archive   = {C_IJCAI},
  author    = {Jun Luo and Shandong Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/301},
  pages     = {2166-2173},
  title     = {Adapt to adaptation: Learning personalization for cross-silo federated learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Discrete listwise personalized ranking for fast top-n
recommendation with implicit feedback. <em>IJCAI</em>, 2159–2165. (<a
href="https://doi.org/10.24963/ijcai.2022/300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address the efficiency problem of personalized ranking from implicit feedback by hashing users and items with binary codes, so that top-N recommendation can be fast executed in a Hamming space by bit operations. However, current hashing methods for top-N recommendation fail to align their learning objectives (such as pointwise or pairwise loss) with the benchmark metrics for ranking quality (e.g. Average Precision, AP), resulting in sub-optimal accuracy. To this end, we propose a Discrete Listwise Personalized Ranking (DLPR) model that optimizes AP under discrete constraints for fast and accurate top-N recommendation. To resolve the challenging DLPR problem, we devise an efficient algorithm that can directly learn binary codes in a relaxed continuous solution space. Specifically, theoretical analysis shows that the optimal solution to the relaxed continuous optimization problem is exactly the same as that of the original discrete DLPR problem. Through extensive experiments on two real-world datasets, we show that DLPR consistently surpasses state-of-the-art hashing methods for top-N recommendation. Keywords: Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Fangyuan Luo and Jun Wu and Tao Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/300},
  pages     = {2159-2165},
  title     = {Discrete listwise personalized ranking for fast top-N recommendation with implicit feedback},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TiRGN: Time-guided recurrent graph network with local-global
historical patterns for temporal knowledge graph reasoning.
<em>IJCAI</em>, 2152–2158. (<a
href="https://doi.org/10.24963/ijcai.2022/299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal knowledge graphs (TKGs) have been widely used in various fields that model the dynamics of facts along the timeline. In the extrapolation setting of TKG reasoning, since facts happening in the future are entirely unknowable, insight into history is the key to predicting future facts. However, it is still a great challenge for existing models as they hardly learn the characteristics of historical events adequately. From the perspective of historical development laws, comprehensively considering the sequential, repetitive, and cyclical patterns of historical facts is conducive to predicting future facts. To this end, we propose a novel representation learning model for TKG reasoning, namely TiRGN, a time-guided recurrent graph network with local-global historical patterns. Specifically, TiRGN uses a local recurrent graph encoder network to model the historical dependency of events at adjacent timestamps and uses the global history encoder network to collect repeated historical facts. After the trade-off between the two encoders, the final inference is performed by a decoder with periodicity. We use six benchmark datasets to evaluate the proposed method. The experimental results show that TiRGN outperforms the state-of-the-art TKG reasoning methods in most cases. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Knowledge Representation and Reasoning: Qualitative, Geometric, Spatial, Temporal Reasoning},
  archive   = {C_IJCAI},
  author    = {Yujia Li and Shiliang Sun and Jing Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/299},
  pages     = {2152-2158},
  title     = {TiRGN: Time-guided recurrent graph network with local-global historical patterns for temporal knowledge graph reasoning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Community question answering entity linking via leveraging
auxiliary data. <em>IJCAI</em>, 2145–2151. (<a
href="https://doi.org/10.24963/ijcai.2022/298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Community Question Answering (CQA) platforms contain plenty of CQA texts (i.e., questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking methods mainly focus on linking entities in news documents, and are suboptimal over this new task of CQAEL since they cannot effectively leverage various informative auxiliary data involved in the CQA platform to aid entity linking, such as parallel answers and two types of meta-data (i.e., topic tags and users). To remedy this crucial issue, we propose a novel transformer-based framework to effectively harness the knowledge delivered by different kinds of auxiliary data to promote the linking performance. We validate the superiority of our framework through extensive experiments over a newly released CQAEL data set against state-of-the-art entity linking methods. Keywords: Data Mining: Mining Text, Web, Social Media},
  archive   = {C_IJCAI},
  author    = {Yuhan Li and Wei Shen and Jianbo Gao and Yadong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/298},
  pages     = {2145-2151},
  title     = {Community question answering entity linking via leveraging auxiliary data},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MLP4Rec: A pure MLP architecture for sequential
recommendations. <em>IJCAI</em>, 2138–2144. (<a
href="https://doi.org/10.24963/ijcai.2022/297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-attention models have achieved state-of-the-art performance in sequential recommender systems by capturing the sequential dependencies among user-item interactions. However, they rely on positional embeddings to retain the sequential information, which may break the semantics of item embeddings. In addition, most existing works assume that such sequential dependencies exist solely in the item embeddings, but neglect their existence among the item features. In this work, we propose a novel sequential recommender system (MLP4Rec) based on the recent advances of MLP-based architectures, which is naturally sensitive to the order of items in a sequence. To be specific, we develop a tri-directional fusion scheme to coherently capture sequential, cross-channel and cross-feature correlations. Extensive experiments demonstrate the effectiveness of MLP4Rec over various representative baselines upon two benchmark datasets. The simple architecture of MLP4Rec also leads to the linear computational complexity as well as much fewer model parameters than existing self-attention methods. Keywords: Data Mining: Recommender Systems},
  archive   = {C_IJCAI},
  author    = {Muyang Li and Xiangyu Zhao and Chuan Lyu and Minghao Zhao and Runze Wu and Ruocheng Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/297},
  pages     = {2138-2144},
  title     = {MLP4Rec: A pure MLP architecture for sequential recommendations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HashNWalk: Hash and random walk based anomaly detection in
hyperedge streams. <em>IJCAI</em>, 2129–2137. (<a
href="https://doi.org/10.24963/ijcai.2022/296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Sequences of group interactions, such as emails, online discussions, and co-authorships, are ubiquitous; and they are naturally represented as a stream of hyperedges (i.e., sets of nodes). Despite its broad potential applications, anomaly detection in hypergraphs (i.e., sets of hyperedges) has received surprisingly little attention, compared to anomaly detection in graphs. While it is tempting to reduce hypergraphs to graphs and apply existing graph-based methods, according to our experiments, taking higher-order structures of hypergraphs into consideration is worthwhile. We propose HashNWalk, an incremental algorithm that detects anomalies in a stream of hyperedges. It maintains and updates a constant-size summary of the structural and temporal information about the input stream. Using the summary, which is the form of a proximity matrix, HashNWalk measures the anomalousness of each new hyperedge as it appears. HashNWalk is (a) Fast: it processes each hyperedge in near real-time and billions of hyperedges within a few hours, (b) Space Efficient: the size of the maintained summary is a user-specific constant, (c) Effective: it successfully detects anomalous hyperedges in real-world hypergraphs. Keywords: Data Mining: Mining Graphs Data Mining: Networks Multidisciplinary Topics and Applications: Web and Social Networks},
  archive   = {C_IJCAI},
  author    = {Geon Lee and Minyoung Choe and Kijung Shin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/296},
  pages     = {2129-2137},
  title     = {HashNWalk: Hash and random walk based anomaly detection in hyperedge streams},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TGNN: A joint semi-supervised framework for graph-level
classification. <em>IJCAI</em>, 2122–2128. (<a
href="https://doi.org/10.24963/ijcai.2022/295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper studies semi-supervised graph classification, a crucial task with a wide range of applications in social network analysis and bioinformatics. Recent works typically adopt graph neural networks to learn graph-level representations for classification, failing to explicitly leverage features derived from graph topology (e.g., paths). Moreover, when labeled data is scarce, these methods are far from satisfactory due to their insufficient topology exploration of unlabeled data. We address the challenge by proposing a novel semi-supervised framework called Twin Graph Neural Network (TGNN). To explore graph structural information from complementary views, our TGNN has a message passing module and a graph kernel module. To fully utilize unlabeled data, for each module, we calculate the similarity of each unlabeled graph to other labeled graphs in the memory bank and our consistency loss encourages consistency between two similarity distributions in different embedding spaces. The two twin modules collaborate with each other by exchanging instance similarity knowledge to fully explore the structure information of both labeled and unlabeled data. We evaluate our TGNN on various public datasets and show that it achieves strong performance. Keywords: Data Mining: Mining Graphs Data Mining: Mining Semi Structured Data Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wei Ju and Xiao Luo and Meng Qu and Yifan Wang and Chong Chen and Minghua Deng and Xian-Sheng Hua and Ming Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/295},
  pages     = {2122-2128},
  title     = {TGNN: A joint semi-supervised framework for graph-level classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Gromov-wasserstein discrepancy with local differential
privacy for distributed structural graphs. <em>IJCAI</em>, 2115–2121.
(<a href="https://doi.org/10.24963/ijcai.2022/294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning the similarity between structured data, especially the graphs, is one of the essential problems. Besides the approach like graph kernels, Gromov-Wasserstein (GW) distance recently draws a big attention due to its flexibility to capture both topological and feature characteristics, as well as handling the permutation invariance. However, structured data are widely distributed for different data mining and machine learning applications. With privacy concerns, accessing the decentralized data is limited to either individual clients or different silos. To tackle these issues, we propose a privacy-preserving framework to analyze the GW discrepancy of node embedding learned locally from graph neural networks in a federated flavor, and then explicitly place local differential privacy (LDP) based on Multi-bit Encoder to protect sensitive information. Our experiments show that, with strong privacy protection guaranteed by ε-LDP algorithm, the proposed framework not only preserves privacy in graph learning, but also presents a noised structural metric under GW distance, resulting in comparable and even better performance in classification and clustering tasks. Moreover, we reason the rationale behind the LDP-based GW distance analytically and empirically. Keywords: Data Mining: Privacy Preserving Data Mining Data Mining: Federated Learning Data Mining: Mining Graphs},
  archive   = {C_IJCAI},
  author    = {Hongwei Jin and Xun Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/294},
  pages     = {2115-2121},
  title     = {Gromov-wasserstein discrepancy with local differential privacy for distributed structural graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RAW-GNN: RAndom walk aggregation based graph neural network.
<em>IJCAI</em>, 2108–2114. (<a
href="https://doi.org/10.24963/ijcai.2022/293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph-Convolution-based methods have been successfully applied to representation learning on homophily graphs where nodes with the same label or similar attributes tend to connect with one another. Due to the homophily assumption of Graph Convolutional Networks (GCNs) that these methods use, they are not suitable for heterophily graphs where nodes with different labels or dissimilar attributes tend to be adjacent. Several methods have attempted to address this heterophily problem, but they do not change the fundamental aggregation mechanism of GCNs because they rely on summation operators to aggregate information from neighboring nodes, which is implicitly subject to the homophily assumption. Here, we introduce a novel aggregation mechanism and develop a RAndom Walk Aggregation-based Graph Neural Network (called RAW-GNN) method. The proposed approach integrates the random walk strategy with graph neural networks. The new method utilizes breadth-first random walk search to capture homophily information and depth-first search to collect heterophily information. It replaces the conventional neighborhoods with path-based neighborhoods and introduces a new path-based aggregator based on Recurrent Neural Networks. These designs make RAW-GNN suitable for both homophily and heterophily graphs. Extensive experimental results showed that the new method achieved state-of-the-art performance on a variety of homophily and heterophily graphs. Keywords: Data Mining: Mining Graphs Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Di Jin and Rui Wang and Meng Ge and Dongxiao He and Xiang Li and Wei Lin and Weixiong Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/293},
  pages     = {2108-2114},
  title     = {RAW-GNN: RAndom walk aggregation based graph neural network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CGMN: A contrastive graph matching network for
self-supervised graph similarity learning. <em>IJCAI</em>, 2101–2107.
(<a href="https://doi.org/10.24963/ijcai.2022/292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph similarity learning refers to calculating the similarity score between two graphs, which is required in many realistic applications, such as visual tracking, graph classification, and collaborative filtering. As most of the existing graph neural networks yield effective graph representations of a single graph, little effort has been made for jointly learning two graph representations and calculating their similarity score. In addition, existing unsupervised graph similarity learning methods are mainly clustering-based, which ignores the valuable information embodied in graph pairs. To this end, we propose a contrastive graph matching network (CGMN) for self-supervised graph similarity learning in order to calculate the similarity between any two input graph objects. Specifically, we generate two augmented views for each graph in a pair respectively. Then, we employ two strategies, namely cross-view interaction and cross-graph interaction, for effective node representation learning. The former is resorted to strengthen the consistency of node representations in two views. The latter is utilized to identify node differences between different graphs. Finally, we transform node representations into graph-level representations via pooling operations for graph similarity computation. We have evaluated CGMN on eight real-world datasets, and the experiment results show that the proposed new approach is superior to the state-of-the-art methods in graph similarity learning downstream tasks. Keywords: Data Mining: Mining Graphs Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Di Jin and Luzhi Wang and Yizhen Zheng and Xiang Li and Fei Jiang and Wei Lin and Shirui Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/292},
  pages     = {2101-2107},
  title     = {CGMN: A contrastive graph matching network for self-supervised graph similarity learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A sparse-motif ensemble graph convolutional network against
over-smoothing. <em>IJCAI</em>, 2094–2100. (<a
href="https://doi.org/10.24963/ijcai.2022/291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The over-smoothing issue is a well-known challenge for Graph Convolutional Networks (GCN). Specifically, it is often observed that increasing the depth of GCN ends up in a trivial embedding subspace where the difference among node embeddings belonging to the same cluster tends to vanish. This paper believes that the main cause lies in the limited diversity along the message passing pipeline. Inspired by this, we propose a Sparse-Motif Ensemble Graph Convolutional Network (SMEGCN). We argue that merely employing the original graph Laplacian as the spectrum of the graph cannot capture the diversified local structure of complex graphs. Hence, to improve the diversity of the graph spectrum, we introduce local topological structures of complex graphs into GCN by employing the so-called graph motifs or the small network subgraphs. Moreover, we find that the motif connections are much denser than the edge connections, which might converge to an all-one matrix within a few times of message-passing. To fix this, we first propose the notion of sparse motif to avoid spurious motif connections. Subsequently, we propose a hierarchical motif aggregation mechanism to integrate the graph spectral information from a series of different sparse-motif message passing paths. Finally, we conduct a series of theoretical and experimental analyses to demonstrate the superiority of the proposed method. Keywords: Data Mining: Networks},
  archive   = {C_IJCAI},
  author    = {Xuan Jiang and Zhiyong Yang and Peisong Wen and Li Su and Qingming Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/291},
  pages     = {2094-2100},
  title     = {A sparse-motif ensemble graph convolutional network against over-smoothing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). End-to-end open-set semi-supervised node classification with
out-of-distribution detection. <em>IJCAI</em>, 2087–2093. (<a
href="https://doi.org/10.24963/ijcai.2022/290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Out-Of-Distribution (OOD) samples are prevalent in real-world applications. The OOD issue becomes even more severe on graph data, as the effect of OOD nodes can be potentially amplified by propagation through the graph topology. Recent works have considered the OOD detection problem, which is critical for reducing the uncertainty in learning and improving the robustness. However, no prior work considers simultaneously OOD detection and node classification on graphs in an end-to-end manner. In this paper, we study a novel problem of end-to-end open-set semi-supervised node classification (OSSNC) on graphs, which deals with node classification in the presence of OOD nodes. Given the lack of supervision on OOD nodes, we introduce a latent variable to indicate in-distribution or OOD nodes in a variational inference framework, and further propose a novel algorithm named as Learning to Mix Neighbors (LMN) which learns to dampen the influence of OOD nodes through the messaging-passing in typical graph neural networks. Extensive experiments on various datasets show that the proposed method outperforms state-of-the-art baselines in terms of both node classification and OOD detection. Keywords: Data Mining: Mining Graphs Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Tiancheng Huang and Donglin Wang and Yuan Fang and Zhengyu Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/290},
  pages     = {2087-2093},
  title     = {End-to-end open-set semi-supervised node classification with out-of-distribution detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). GraphDIVE: Graph classification by mixture of diverse
experts. <em>IJCAI</em>, 2080–2086. (<a
href="https://doi.org/10.24963/ijcai.2022/289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph classification is a challenging research task in many applications across a broad range of domains. Recently, Graph Neural Network (GNN) models have achieved superior performance on various real-world graph datasets. Despite their successes, most of current GNN models largely suffer from the ubiquitous class imbalance problem, which typically results in prediction bias towards majority classes. Although many imbalanced learning methods have been proposed, they mainly focus on regular Euclidean data and cannot well utilize topological structure of graph (non-Euclidean) data. To boost the performance of GNNs and investigate the relationship between topological structure and class imbalance, we propose GraphDIVE, which learns multi-view graph representations and combine multi-view experts (i.e., classifiers). Specifically, multi-view graph representations correspond to the intrinsic diverse graph topological structure characteristics. Extensive experiments on molecular benchmark datasets demonstrate the effectiveness of the proposed approach. Keywords: Data Mining: Mining Graphs Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Fenyu Hu and Liping Wang and Qiang Liu and Shu Wu and Liang Wang and Tieniu Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/289},
  pages     = {2080-2086},
  title     = {GraphDIVE: Graph classification by mixture of diverse experts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MERIT: Learning multi-level representations on temporal
graphs. <em>IJCAI</em>, 2073–2079. (<a
href="https://doi.org/10.24963/ijcai.2022/288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, representation learning on temporal graphs has drawn increasing attention, which aims at learning temporal patterns to characterize the evolving nature of dynamic graphs in real-world applications. Despite effectiveness, these methods commonly ignore the individual- and combinatorial-level patterns derived from different types of interactions (e.g., user-item), which are at the heart of the representation learning on temporal graphs. To fill this gap, we propose MERIT, a novel multi-level graph attention network for inductive representation learning on temporal graphs.We adaptively embed the original timestamps to a higher, continuous dimensional space for learn-ing individual-level periodicity through Personalized Time Encoding (PTE) module. Furthermore, we equip MERIT with Continuous time and Con-text aware Attention (Coco-Attention) mechanism which chronologically locates most relevant neighbors by jointly capturing multi-level context on temporal graphs. Finally, MERIT performs multiple aggregations and propagations to explore and exploit high-order structural information for down-stream tasks. Extensive experiments on four public datasets demonstrate the effectiveness of MERITon both (inductive / transductive) link prediction and node classification task. Keywords: Data Mining: Mining Graphs Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Binbin Hu and Zhengwei Wu and Jun Zhou and Ziqi Liu and Zhigang Huangfu and Zhiqiang Zhang and Chaochao Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/288},
  pages     = {2073-2079},
  title     = {MERIT: Learning multi-level representations on temporal graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Quaternion ordinal embedding. <em>IJCAI</em>, 2066–2072. (<a
href="https://doi.org/10.24963/ijcai.2022/287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Ordinal embedding (OE) aims to project objects into a low-dimensional space while preserving their ordinal constraints as well as possible. Generally speaking, a reasonable OE algorithm should simultaneously capture a) semantic meaning and b) the ordinal relationship of the objects. However, most of the existing methods merely focus on b). To address this issue, our goal in this paper is to seek a generic OE method to embrace the two features simultaneously. We argue that different dimensions of vector-based embedding are naturally entangled with each other. To realize a), we expect to decompose the D dimensional embedding space into D different semantic subspaces, where each subspace is associated with a matrix representation. Unfortunately, introducing a matrix-based representation requires far more complex parametric space than its vector-based counterparts. Thanks to the algebraic property of quaternions, we are able to find a more efficient way to represent a matrix with quaternions. For b), inspired by the classic chordal Grassmannian distance, a new distance function is defined to measure the distance between different quaternions/matrices, on top of which we construct a generic OE loss function. Experimental results for different tasks on both simulated and real-world datasets verify the effectiveness of our proposed method. Keywords: Data Mining: Applications},
  archive   = {C_IJCAI},
  author    = {Wenzheng Hou and Qianqian Xu and Ke Ma and Qianxiu Hao and Qingming Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/287},
  pages     = {2066-2072},
  title     = {Quaternion ordinal embedding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Constrained adaptive projection with pretrained features for
anomaly detection. <em>IJCAI</em>, 2059–2065. (<a
href="https://doi.org/10.24963/ijcai.2022/286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly detection aims to separate anomalies from normal samples, and the pretrained network is promising for anomaly detection. However, adapting the pretrained features would be confronted with the risk of pattern collapse when finetuning on one-class training data. In this paper, we propose an anomaly detection framework called constrained adaptive projection with pretrained features (CAP). Combined with pretrained features, a simple linear projection head applied on a specific input and its k most similar pretrained normal representations is designed for feature adaptation, and a reformed self-attention is leveraged to mine the inner-relationship among one-class semantic features. A loss function is proposed to avoid potential pattern collapse. Concretely, it considers the similarity between a specific data and its corresponding adaptive normal representation, and incorporates a constraint term slightly aligning pretrained and adaptive spaces. Our method achieves state-of-the-art anomaly detection performance on semantic anomaly detection and sensory anomaly detection benchmarks including 96.5\% AUROC on CIFAR-100 dataset, 97.0\% AUROC on CIFAR-10 dataset and 89.9\% AUROC on MvTec dataset. Keywords: Data Mining: Anomaly/Outlier Detection Computer Vision: Applications Data Mining: Applications},
  archive   = {C_IJCAI},
  author    = {Xingtai Gui and Di Wu and Yang Chang and Shicai Fan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/286},
  pages     = {2059-2065},
  title     = {Constrained adaptive projection with pretrained features for anomaly detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised graph neural networks for multi-behavior
recommendation. <em>IJCAI</em>, 2052–2058. (<a
href="https://doi.org/10.24963/ijcai.2022/285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Traditional recommendation usually focuses on utilizing only one target user behavior (e.g., purchase) but ignoring other auxiliary behaviors (e.g., click, add to cart). Early efforts of multi-behavior recommendation often emphasize the differences between multiple behaviors, i.e., they aim to extract useful information by distinguishing different behaviors. However, the commonality between them, which reflects user&#39;s common preference for items associated with different behaviors, is largely ignored. Meanwhile, the multi-behavior recommendation still severely suffers from limited supervision signal issue. In this paper, we propose a novel self-supervised graph collaborative filtering model for multi-behavior recommendation named S-MBRec. Specifically, for each behavior, we execute the GCNs to learn the user and item embeddings. Then we design a supervised task, distinguishing the importance of different behaviors, to capture the differences between embeddings. Meanwhile, we propose a star-style contrastive learning task to capture the embedding commonality between target and auxiliary behaviors, so as to alleviate the sparsity of supervision signal, reduce the redundancy among auxiliary behavior, and extract the most critical information. Finally, we jointly optimize the above two tasks. Extensive experiments, in comparison with state-of-the-arts, well demonstrate the effectiveness of S-MBRec, where the maximum improvement can reach to 20\%. Keywords: Data Mining: Mining Graphs Data Mining: Recommender Systems Machine Learning: Recommender Systems Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Shuyun Gu and Xiao Wang and Chuan Shi and Ding Xiao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/285},
  pages     = {2052-2058},
  title     = {Self-supervised graph neural networks for multi-behavior recommendation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modeling precursors for temporal knowledge graph reasoning
via auto-encoder structure. <em>IJCAI</em>, 2044–2051. (<a
href="https://doi.org/10.24963/ijcai.2022/284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Temporal knowledge graph (TKG) reasoning that infers missing facts in the future is an essential and challenging task. When predicting a future event, there must be a narrative evolutionary process composed of closely related historical facts to support the event&#39;s occurrence, namely fact precursors. However, most existing models employ a sequential reasoning process in an auto-regressive manner, which cannot capture precursor information. This paper proposes a novel auto-encoder architecture that introduces a relation-aware graph attention layer into transformer (rGalT) to accommodate inference over the TKG. Specifically, we first calculate the correlation between historical and predicted facts through multiple attention mechanisms along intra-graph and inter-graph dimensions, then constitute these mutually related facts into diverse fact segments. Next, we borrow the translation generation idea to decode in parallel the precursor information associated with the given query, which enables our model to infer future unknown facts by progressively generating graph structures. Experimental results on four benchmark datasets demonstrate that our model outperforms other state-of-the-art methods, and precursor identiﬁcation provides supporting evidence for prediction. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Knowledge Representation and Reasoning: Learning and reasoning Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Yifu Gao and Linhui Feng and Zhigang Kan and Yi Han and Linbo Qiao and Dongsheng Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/284},
  pages     = {2044-2051},
  title     = {Modeling precursors for temporal knowledge graph reasoning via auto-encoder structure},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Disentangling the computational complexity of network
untangling. <em>IJCAI</em>, 2037–2043. (<a
href="https://doi.org/10.24963/ijcai.2022/283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the recently introduced network untangling problem, a variant of Vertex Cover on temporal graphs---graphs whose edge set changes over discrete time steps. There are two versions of this problem. The goal is to select at most k time intervals for each vertex such that all time-edges are covered and (depending on the problem variant) either the maximum interval length or the total sum of interval lengths is minimized. This problem has data mining applications in finding activity timelines that explain the interactions of entities in complex networks. Both variants of the problem are NP-hard. In this paper, we initiate a multivariate complexity analysis involving the following parameters: number of vertices, lifetime of the temporal graph, number of intervals per vertex, and the interval length bound. For both problem versions, we (almost) completely settle the parameterized complexity for all combinations of those four parameters, thereby delineating the border of fixed-parameter tractability. Keywords: Data Mining: Mining Spatial and/or Temporal Data Data Mining: Mining Graphs Data Mining: Networks},
  archive   = {C_IJCAI},
  author    = {Vincent Froese and Pascal Kunz and Philipp Zschoche},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/283},
  pages     = {2037-2043},
  title     = {Disentangling the computational complexity of network untangling},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When transfer learning meets cross-city urban flow
prediction: Spatio-temporal adaptation matters. <em>IJCAI</em>,
2030–2036. (<a href="https://doi.org/10.24963/ijcai.2022/282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Urban flow prediction is a fundamental task to build smart cities, where neural networks have become the most popular method. However, the deep learning methods typically rely on massive training data that are probably inaccessible in real world. In light of this, the community calls for knowledge transfer. However, when adapting transfer learning for cross-city prediction tasks, existing studies are built on static knowledge transfer, ignoring the fact inter-city correlations change dynamically across time. The dynamic correlations make urban feature transfer challenging. This paper proposes a novel Spatio-Temporal Adaptation Network (STAN) to perform urban flow prediction for data-scarce cities via the spatio-temporal knowledge transferred from data-rich cities. STAN encompasses three modules: i) spatial adversarial adaptation module that adopts an adversarial manner to capture the transferable spatial features; ii) temporal attentive adaptation module to attend to critical dynamics for temporal feature transfer; iii) prediction module that aims to learn task-driven transferable knowledge. Extensive experiments on five real datasets show STAN substantially outperforms state-of-the-art methods. Keywords: Data Mining: Mining Spatial and/or Temporal Data},
  archive   = {C_IJCAI},
  author    = {Ziquan Fang and Dongen Wu and Lu Pan and Lu Chen and Yunjun Gao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/282},
  pages     = {2030-2036},
  title     = {When transfer learning meets cross-city urban flow prediction: Spatio-temporal adaptation matters},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MetaER-TTE: An adaptive meta-learning model for en route
travel time estimation. <em>IJCAI</em>, 2023–2029. (<a
href="https://doi.org/10.24963/ijcai.2022/281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {En route travel time estimation (ER-TTE) aims to predict the travel time on the remaining route. Since the traveled and remaining parts of a trip usually have some common characteristics like driving speed, it is desirable to explore these characteristics for improved performance via effective adaptation. This yet faces the severe problem of data sparsity due to the few sampled points in a traveled partial trajectory. Since trajectories with different contextual information tend to have different characteristics, the existing meta-learning method for ER-TTE cannot fit each trajectory well because it uses the same model for all trajectories. To this end, we propose a novel adaptive meta-learning model called MetaER-TTE. Particularly, we utilize soft-clustering and derive cluster-aware initialized parameters to better transfer the shared knowledge across trajectories with similar contextual information. In addition, we adopt a distribution-aware approach for adaptive learning rate optimization, so as to avoid task-overfitting which will occur when guiding the initial parameters with a fixed learning rate for tasks under imbalanced distribution. Finally, we conduct comprehensive experiments to demonstrate the superiority of MetaER-TTE. Keywords: Data Mining: Mining Spatial and/or Temporal Data Multidisciplinary Topics and Applications: Transportation},
  archive   = {C_IJCAI},
  author    = {Yu Fan and Jiajie Xu and Rui Zhou and Jianxin Li and Kai Zheng and Lu Chen and Chengfei Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/281},
  pages     = {2023-2029},
  title     = {MetaER-TTE: An adaptive meta-learning model for en route travel time estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature and instance joint selection: A reinforcement
learning perspective. <em>IJCAI</em>, 2016–2022. (<a
href="https://doi.org/10.24963/ijcai.2022/280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Feature selection and instance selection are two important techniques of data processing. However, such selections have mostly been studied separately, while existing work towards the joint selection conducts feature/instance selection coarsely; thus neglecting the latent fine-grained interaction between feature space and instance space. To address this challenge, we propose a reinforcement learning solution to accomplish the joint selection task and simultaneously capture the interaction between the selection of each feature and each instance. In particular, a sequential-scanning mechanism is designed as action strategy of agents and a collaborative-changing environment is used to enhance agent collaboration. In addition, an interactive paradigm introduces prior selection knowledge to help agents for more efficient exploration. Finally, extensive experiments on real-world datasets have demonstrated improved performances. Keywords: Data Mining: Applications Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Wei Fan and Kunpeng Liu and Hao Liu and Hengshu Zhu and Hui Xiong and Yanjie Fu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/280},
  pages     = {2016-2022},
  title     = {Feature and instance joint selection: A reinforcement learning perspective},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Private semi-supervised federated learning. <em>IJCAI</em>,
2009–2015. (<a href="https://doi.org/10.24963/ijcai.2022/279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a federated learning (FL) framework to effectively train models from scarce and skewly distributed labeled data. We consider a challenging yet practical scenario: a few data sources own a small amount of labeled data, while the rest mass sources own purely unlabeled data. Classical FL requires each client to have enough labeled data for local training, thus is not applicable in this scenario. In this work, we design an effective federated semi-supervised learning framework (FedSSL) to fully leverage both labeled and unlabeled data sources. We establish a unified data space across all participating agents, so that each agent can generate mixed data samples to boost semi-supervised learning (SSL), while keeping data locality. We further show that FedSSL can integrate differential privacy protection techniques to prevent labeled data leakage at the cost of minimum performance degradation. On SSL tasks with as small as 0.17\% and 1\% of MNIST and CIFAR-10 datasets as labeled data, respectively, our approach can achieve 5-20\% performance boost over the state-of-the-art methods. Keywords: Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining Machine Learning: Semi-Supervised Learning Machine Learning: Generative Adverserial Networks},
  archive   = {C_IJCAI},
  author    = {Chenyou Fan and Junjie Hu and Jianwei Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/279},
  pages     = {2009-2015},
  title     = {Private semi-supervised federated learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CADET: Calibrated anomaly detection for mitigating hardness
bias. <em>IJCAI</em>, 2002–2008. (<a
href="https://doi.org/10.24963/ijcai.2022/278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The detection of anomalous samples in large, high-dimensional datasets is a challenging task with numerous practical applications. Recently, state-of-the-art performance is achieved with deep learning methods: for example, using the reconstruction error from an autoencoder as anomaly scores. However, the scores are uncalibrated: that is, they follow an unknown distribution and lack a clear interpretation. Furthermore, the reconstruction error is highly influenced by the `hardness&#39; of a given sample, which leads to false negative and false positive errors. In this paper, we empirically show the significance of this hardness bias present in a range of recent deep anomaly detection methods. To mitigate this, we propose an efficient and plug-and-play error calibration method which mitigates this hardness bias in the anomaly scoring without the need to retrain the model. We verify the effectiveness of our method on a range of image, time-series, and tabular datasets and against several baseline methods. Keywords: Data Mining: Anomaly/Outlier Detection AI Ethics, Trust, Fairness: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Ailin Deng and Adam Goodge and Lang Yi Ang and Bryan Hooi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/278},
  pages     = {2002-2008},
  title     = {CADET: Calibrated anomaly detection for mitigating hardness bias},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Triformer: Triangular, variable-specific attentions for long
sequence multivariate time series forecasting. <em>IJCAI</em>,
1994–2001. (<a href="https://doi.org/10.24963/ijcai.2022/277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A variety of real-world applications rely on far future information to make decisions, thus calling for efficient and accurate long sequence multivariate time series forecasting. While recent attention-based forecasting models show strong abilities in capturing long-term dependencies, they still suffer from two key limitations. First, canonical self attention has a quadratic complexity w.r.t. the input time series length, thus falling short in efficiency. Second, different variables’ time series often have distinct temporal dynamics, which existing studies fail to capture, as they use the same model parameter space, e.g., projection matrices, for all variables’ time series, thus falling short in accuracy. To ensure high efficiency and accuracy, we propose Triformer, a triangular, variable-specific attention. (i) Linear complexity: we introduce a novel patch attention with linear complexity. When stacking multiple layers of the patch attentions, a triangular structure is proposed such that the layer sizes shrink exponentially, thus maintaining linear complexity. (ii) Variable-specific parameters: we propose a light-weight method to enable distinct sets of model parameters for different variables’ time series to enhance accuracy without compromising efficiency and memory usage. Strong empirical evidence on four datasets from multiple domains justifies our design choices, and it demonstrates that Triformer outperforms state-of-the-art methods w.r.t. both accuracy and efficiency. Source code is publicly available at https://github.com/razvanc92/triformer. Keywords: Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Recurrent Networks Machine Learning: Regression Machine Learning: Time-series; Data Streams},
  archive   = {C_IJCAI},
  author    = {Razvan-Gabriel Cirstea and Chenjuan Guo and Bin Yang and Tung Kieu and Xuanyi Dong and Shirui Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/277},
  pages     = {1994-2001},
  title     = {Triformer: Triangular, variable-specific attentions for long sequence multivariate time series forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Filtration-enhanced graph transformation. <em>IJCAI</em>,
1987–1993. (<a href="https://doi.org/10.24963/ijcai.2022/276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph kernels and graph neural networks (GNNs) are widely used for the classification of graph data. However, many existing graph kernels and GNNs have limited expressive power, because they cannot distinguish graphs if the classic 1-dimensional Weisfeiler-Leman (1-WL) algorithm does not distinguish them. To break the 1-WL expressiveness barrier, we propose a novel method called filtration-enhanced graph transformation, which is based on a concept from the area of topological data analysis. In a nutshell, our approach first transforms each original graph into a filtration-enhanced graph based on a certain pre-defined filtration operation, and then uses the transformed graphs as the inputs for graph kernels or GNNs. The striking feature of our approach is that it is a plug-in method and can be applied in any graph kernel and GNN to enhance their expressive power. We theoretically and experimentally demonstrate that our solutions exhibit significantly better performance than the state-of-the art solutions for graph classification tasks. Keywords: Data Mining: Mining Graphs Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Zijian Chen and Rong-Hua Li and Hongchao Qin and Huanzhong Duan and Yanxiong Lu and Qiangqiang Dai and Guoren Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/276},
  pages     = {1987-1993},
  title     = {Filtration-enhanced graph transformation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards robust dense retrieval via local ranking alignment.
<em>IJCAI</em>, 1980–1986. (<a
href="https://doi.org/10.24963/ijcai.2022/275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dense retrieval (DR) has extended the employment of pre-trained language models, like BERT, for text ranking. However, recent studies have raised the robustness issue of DR model against query variations, like query with typos, along with non-trivial performance losses. Herein, we argue that it would be beneficial to allow the DR model to learn to align the relative positions of query-passage pairs in the representation space, as query variations cause the query vector to drift away from its original position, affecting the subsequent DR effectiveness. To this end, we propose RoDR, a novel robust DR model that learns to calibrate the in-batch local ranking of query variation to that of original query for the DR space alignment. Extensive experiments on MS MARCO and ANTIQUE datasets show that RoDR significantly improves the retrieval results on both the original queries and different types of query variations. Meanwhile, RoDR provides a general query noise-tolerate learning framework that boosts the robustness and effectiveness of various existing DR models. Our code and models are openly available at https://github.com/cxa-unique/RoDR. Keywords: Data Mining: Information Retrieval Natural Language Processing: Information Retrieval and Text Mining Machine Learning: Robustness Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Xuanang Chen and Jian Luo and Ben He and Le Sun and Yingfei Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/275},
  pages     = {1980-1986},
  title     = {Towards robust dense retrieval via local ranking alignment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mutual distillation learning network for trajectory-user
linking. <em>IJCAI</em>, 1973–1979. (<a
href="https://doi.org/10.24963/ijcai.2022/274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Trajectory-User Linking (TUL), which links trajectories to users who generate them, has been a challenging problem due to the sparsity in check-in mobility data. Existing methods ignore the utilization of historical data or rich contextual features in check-in data, resulting in poor performance for TUL task. In this paper, we propose a novel Mutual distillation learning network to solve the TUL problem for sparse check-in mobility data, named MainTUL. Specifically, MainTUL is composed of a Recurrent Neural Network (RNN) trajectory encoder that models sequential patterns of input trajectory and a temporal-aware Transformer trajectory encoder that captures long-term time dependencies for the corresponding augmented historical trajectories. Then, the knowledge learned on historical trajectories is transferred between the two trajectory encoders to guide the learning of both encoders to achieve mutual distillation of information. Experimental results on two real-world check-in mobility datasets demonstrate the superiority of \model against state-of-the-art baselines. The source code of our model is available at https://github.com/Onedean/MainTUL. Keywords: Data Mining: Mining Spatial and/or Temporal Data Machine Learning: Representation learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wei Chen and ShuZhe Li and Chao Huang and Yanwei Yu and Yongguo Jiang and Junyu Dong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/274},
  pages     = {1973-1979},
  title     = {Mutual distillation learning network for trajectory-user linking},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Meta-learning based knowledge extrapolation for knowledge
graphs in the federated setting. <em>IJCAI</em>, 1966–1972. (<a
href="https://doi.org/10.24963/ijcai.2022/273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion},
  archive   = {C_IJCAI},
  author    = {Mingyang Chen and Wen Zhang and Zhen Yao and Xiangnan Chen and Mengxiao Ding and Fei Huang and Huajun Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/273},
  pages     = {1966-1972},
  title     = {Meta-learning based knowledge extrapolation for knowledge graphs in the federated setting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vertically federated graph neural network for
privacy-preserving node classification. <em>IJCAI</em>, 1959–1965. (<a
href="https://doi.org/10.24963/ijcai.2022/272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Graph Neural Network (GNN) has achieved remarkable progresses in various real-world tasks on graph data, consisting of node features and the adjacent information between different nodes. High-performance GNN models always depend on both rich features and complete edge information in graph. However, such information could possibly be isolated by different data holders in practice, which is the so-called data isolation problem. To solve this problem, in this paper, we propose VFGNN, a federated GNN learning paradigm for privacy-preserving node classification task under data vertically partitioned setting, which can be generalized to existing GNN models. Specifically, we split the computation graph into two parts. We leave the private data (i.e., features, edges, and labels) related computations on data holders, and delegate the rest of computations to a semi-honest server. We also propose to apply differential privacy to prevent potential information leakage from the server. We conduct experiments on three benchmarks and the results demonstrate the effectiveness of VFGNN. Keywords: Data Mining: Federated Learning Data Mining: Privacy Preserving Data Mining Uncertainty in AI: Graphical Models},
  archive   = {C_IJCAI},
  author    = {Chaochao Chen and Jun Zhou and Longfei Zheng and Huiwen Wu and Lingjuan Lyu and Jia Wu and Bingzhe Wu and Ziqi Liu and Li Wang and Xiaolin Zheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/272},
  pages     = {1959-1965},
  title     = {Vertically federated graph neural network for privacy-preserving node classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust high-dimensional classification from few positive
examples. <em>IJCAI</em>, 1952–1958. (<a
href="https://doi.org/10.24963/ijcai.2022/271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We tackle an extreme form of imbalanced classification, with up to 105 features but as few as 5 samples from the minority class. This problem occurs in predicting predicting tumor types and fraud detection, among others. Standard imbalanced classification methods are not designed for such severe data scarcity. Sampling-based methods need too many samples due to the high-dimensionality, while cost-based methods must place too high a weight on the limited minority samples. Our proposed method, called DIRECT, bypasses sample generation by training the classifier over a robust smoothed distribution of the minority class. DIRECT is fast, simple, robust, parameter-free, and easy to interpret. We validate DIRECT on several real-world datasets spanning document, image, and medical classification. DIRECT is up to 5x − 7x better than SMOTE-like methods, 30−200\% better than ensemble methods, 3x − 7x better than cost-sensitive methods. The greatest gains are for settings with the fewest samples in the minority class, where DIRECT’s robustness is most helpful. Keywords: Data Mining: Class Imbalance and Unequal Cost Machine Learning: Robustness Machine Learning: Classification Data Mining: Applications},
  archive   = {C_IJCAI},
  author    = {Deepayan Chakrabarti and Benjamin Fauber},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/271},
  pages     = {1952-1958},
  title     = {Robust high-dimensional classification from few positive examples},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can abnormality be detected by graph neural networks?
<em>IJCAI</em>, 1945–1951. (<a
href="https://doi.org/10.24963/ijcai.2022/270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Anomaly detection in graphs has attracted considerable interests in both academia and industry due to its wide applications in numerous domains ranging from finance to biology. Meanwhile, graph neural networks (GNNs) is emerging as a powerful tool for modeling graph data. A natural and fundamental question that arises here is: can abnormality be detected by graph neural networks? In this paper, we aim to answer this question, which is nontrivial. As many existing works have explored, graph neural networks can be seen as filters for graph signals, with the favor of low frequency in graphs. In other words, GNN will smooth the signals of adjacent nodes. However, abnormality in a graph intuitively has the characteristic that it tends to be dissimilar to its neighbors, which are mostly normal samples. It thereby conflicts with the general assumption with traditional GNNs. To solve this, we propose a novel Adaptive Multi-frequency Graph Neural Network (AMNet), aiming to capture both low-frequency and high-frequency signals, and adaptively combine signals of different frequencies. Experimental results on real-world datasets demonstrate that our model achieves a significant improvement comparing with several state-of-the-art baseline methods. Keywords: Data Mining: Mining Graphs Data Mining: Networks},
  archive   = {C_IJCAI},
  author    = {Ziwei Chai and Siqi You and Yang Yang and Shiliang Pu and Jiarong Xu and Haoyang Cai and Weihao Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/270},
  pages     = {1945-1951},
  title     = {Can abnormality be detected by graph neural networks?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Non-euclidean self-organizing maps. <em>IJCAI</em>,
1938–1944. (<a href="https://doi.org/10.24963/ijcai.2022/269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Self-Organizing Maps (SOMs, Kohonen networks) belong to neural network models of the unsupervised class. In this paper, we present the generalized setup for non-Euclidean SOMs. Most data analysts take it for granted to use some subregions of a flat space as their data model; however, by the assumption that the underlying geometry is non-Euclidean we obtain a new degree of freedom for the techniques that translate the similarities into spatial neighborhood relationships. We improve the traditional SOM algorithm by introducing topology-related extensions. Our proposition can be successfully applied to dimension reduction, clustering or finding similarities in big data (both hierarchical and non-hierarchical). Keywords: Data Mining: Exploratory Data Mining Data Mining: Data Visualisation Data Mining: Other Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Dorota Celińska-Kopczyńska and Eryk Kopczyński},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/269},
  pages     = {1938-1944},
  title     = {Non-euclidean self-organizing maps},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entity alignment with reliable path reasoning and
relation-aware heterogeneous graph transformer. <em>IJCAI</em>,
1930–1937. (<a href="https://doi.org/10.24963/ijcai.2022/268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Entity Alignment (EA) has attracted widespread attention in both academia and industry, which aims to seek entities with same meanings from different Knowledge Graphs (KGs). There are substantial multi-step relation paths between entities in KGs, indicating the semantic relations of entities. However, existing methods rarely consider path information because not all natural paths facilitate for EA judgment. In this paper, we propose a more effective entity alignment framework, RPR-RHGT, which integrates relation and path structure information, as well as the heterogeneous information in KGs. Impressively, an initial reliable path reasoning algorithm is developed to generate the paths favorable for EA task from the relation structures of KGs. This is the first algorithm in the literature to successfully use unrestricted path information. In addition, to efficiently capture heterogeneous features in entity neighborhoods, a relation-aware heterogeneous graph transformer is designed to model the relation and path structures of KGs. Extensive experiments on three well-known datasets show RPR-RHGT significantly outperforms 10 state-of-the-art methods, exceeding the best performing baseline up to 8.62\% on Hits@1. We also show its better performance than the baselines on different ratios of training set, and harder datasets. Keywords: Data Mining: Knowledge Graphs and Knowledge Base Completion Knowledge Representation and Reasoning: Semantic Web},
  archive   = {C_IJCAI},
  author    = {Weishan Cai and Wenjun Ma and Jieyu Zhan and Yuncheng Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/268},
  pages     = {1930-1937},
  title     = {Entity alignment with reliable path reasoning and relation-aware heterogeneous graph transformer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypergraph structure learning for hypergraph neural
networks. <em>IJCAI</em>, 1923–1929. (<a
href="https://doi.org/10.24963/ijcai.2022/267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Hypergraphs are natural and expressive modeling tools to encode high-order relationships among entities. Several variations of Hypergraph Neural Networks (HGNNs) are proposed to learn the node representations and complex relationships in the hypergraphs. Most current approaches assume that the input hypergraph structure accurately depicts the relations in the hypergraphs. However, the input hypergraph structure inevitably contains noise, task-irrelevant information, or false-negative connections. Treating the input hypergraph structure as ground-truth information unavoidably leads to sub-optimal performance. In this paper, we propose a Hypergraph Structure Learning (HSL) framework, which optimizes the hypergraph structure and the HGNNs simultaneously in an end-to-end way. HSL learns an informative and concise hypergraph structure that is optimized for downstream tasks. To efficiently learn the hypergraph structure, HSL adopts a two-stage sampling process: hyperedge sampling for pruning redundant hyperedges and incident node sampling for pruning irrelevant incident nodes and discovering potential implicit connections. The consistency between the optimized structure and the original structure is maintained by the intra-hyperedge contrastive learning module. The sampling processes are jointly optimized with HGNNs towards the objective of the downstream tasks. Experiments conducted on 7 datasets show shat HSL outperforms the state-of-the-art baselines while adaptively sparsifying hypergraph structures. Keywords: Data Mining: Mining Graphs Machine Learning: Geometric Learning},
  archive   = {C_IJCAI},
  author    = {Derun Cai and Moxian Song and Chenxi Sun and Baofeng Zhang and Shenda Hong and Hongyan Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/267},
  pages     = {1923-1929},
  title     = {Hypergraph structure learning for hypergraph neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Doubly sparse asynchronous learning for stochastic composite
optimization. <em>IJCAI</em>, 1916–1922. (<a
href="https://doi.org/10.24963/ijcai.2022/266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Parallel optimization has become popular for large-scale learning in the past decades. However, existing methods suffer from huge computational costs, memory usage, and communication burden in high-dimensional scenarios. To address the challenges, we propose a new accelerated doubly sparse asynchronous learning (DSAL) method for stochastic composite optimization, under which two algorithms are proposed on shared-memory and distributed-memory architecture respectively, which only conducts gradient descent on the nonzero coordinates (data sparsity) and active set (model sparsity). The proposed algorithm can converge much faster and achieve significant speedup by simultaneously enjoying the sparsity of the model and data. Moreover, by sending the gradients on the active set only, communication costs are dramatically reduced. Theoretically, we prove that the proposed method achieves the linear convergence rate with lower overall complexity and can achieve the model identification in a finite number of iterations almost surely. Finally, extensive experimental results on benchmark datasets confirm the superiority of our proposed method. Keywords: Data Mining: Big Data and Scalability Data Mining: Parallel, Distributed and Cloud-based High Performance Mining Machine Learning: Optimisation Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Runxue Bao and Xidong Wu and Wenhan Xian and Heng Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/266},
  pages     = {1916-1922},
  title     = {Doubly sparse asynchronous learning for stochastic composite optimization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A strengthened branch and bound algorithm for the maximum
common (connected) subgraph problem. <em>IJCAI</em>, 1908–1914. (<a
href="https://doi.org/10.24963/ijcai.2022/265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose a new and strengthened Branch-and-Bound (BnB) algorithm for the maximum common (connected) induced subgraph problem based on two new operators, Long-Short Memory (LSM) and Leaf vertex Union Match (LUM). Given two graphs for which we search for the maximum common (connected) induced subgraph, the first operator of LSM maintains a score for the branching node using the short-term reward of each vertex of the first graph and the long-term reward of each vertex pair of the two graphs. In this way, the BnB process learns to reduce the search tree size significantly and boost the algorithm performance. The second operator of LUM further improves the performance by simultaneously matching the leaf vertices connected to the current matched vertices, and allows the algorithm to match multiple vertex pairs without affecting the optimality of solution. We incorporate the two operators into the state-of-the-art BnB algorithm McSplit, and denote the resulting algorithm as McSplit+LL. Experiments show that McSplit+LL outperforms McSplit+RL, a more recent variant of McSplit using reinforcement learning that is superior than McSplit. Keywords: Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Jianrong Zhou and Kun He and Jiongzhi Zheng and Chu-Min Li and Yanli Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/265},
  pages     = {1908-1914},
  title     = {A strengthened branch and bound algorithm for the maximum common (Connected) subgraph problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BandMaxSAT: A local search MaxSAT solver with multi-armed
bandit. <em>IJCAI</em>, 1901–1907. (<a
href="https://doi.org/10.24963/ijcai.2022/264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We address Partial MaxSAT (PMS) and Weighted PMS (WPMS), two practical generalizations of the MaxSAT problem, and propose a local search algorithm called BandMaxSAT, that applies a multi-armed bandit to guide the search direction, for these problems. The bandit in our method is associated with all the soft clauses in the input (W)PMS instance. Each arm corresponds to a soft clause. The bandit model can help BandMaxSAT to select a good direction to escape from local optima by selecting a soft clause to be satisfied in the current step, that is, selecting an arm to be pulled. We further propose an initialization method for (W)PMS that prioritizes both unit and binary clauses when producing the initial solutions. Extensive experiments demonstrate that BandMaxSAT significantly outperforms the state-of-the-art (W)PMS local search algorithm SATLike3.0. Specifically, the number of instances in which BandMaxSAT obtains better results is about twice that obtained by SATLike3.0. We further combine BandMaxSAT with the complete solver TT-Open-WBO-Inc. The resulting solver BandMaxSAT-c also outperforms some of the best state-of-the-art complete (W)PMS solvers, including SATLike-c, Loandra and TT-Open-WBO-Inc. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Jiongzhi Zheng and Kun He and Jianrong Zhou and Yan Jin and Chu-Min Li and Felip Manyà},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/264},
  pages     = {1901-1907},
  title     = {BandMaxSAT: A local search MaxSAT solver with multi-armed bandit},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Inverting 43-step MD4 via cube-and-conquer. <em>IJCAI</em>,
1894–1900. (<a href="https://doi.org/10.24963/ijcai.2022/263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {MD4 is a prominent cryptographic hash function proposed in 1990. The full version consists of 48 steps and produces a hash of size 128 bits given a message of an arbitrary finite size. In 2007, its truncated 39-step version was inverted via reducing to SAT and applying a CDCL solver. Since that time, several attempts have been made but the 40-step version still remains unbroken. In this study, 40-, 41-, 42-, and 43-step versions of MD4 are successfully inverted. The problems are reduced to SAT and solved via the Cube-and-Conquer approach. Two algorithms are proposed for this purpose. The first one generates inversion problems for MD4 by adding special constraints. The second one is aimed at finding a proper threshold for the cubing phase of Cube-and-Conquer. While the first algorithm is focused on inverting MD4 and similar cryptographic hash functions, the second one is not area specific and so is applicable to a variety of classes of hard SAT instances. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Applications Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Oleg Zaikin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/263},
  pages     = {1894-1900},
  title     = {Inverting 43-step MD4 via cube-and-conquer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An exact MaxSAT algorithm: Further observations and further
improvements. <em>IJCAI</em>, 1887–1893. (<a
href="https://doi.org/10.24963/ijcai.2022/262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the maximum satisfiability problem (MaxSAT), given a CNF formula with m clauses and n variables, we are asked to find an assignment of the variables to satisfy the maximum number of clauses. Chen and Kanj showed that this problem can be solved in O*(1.3248^m) time (DAM 2004) and the running time bound was improved to O*(1.2989^m) by Xu et al. (IJCAI 2019). In this paper, we further improve the result to O*(1.2886^m). By using some new reduction and branching techniques we can avoid several bottlenecks in previous algorithms and get the improvement on this important problem. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty},
  archive   = {C_IJCAI},
  author    = {Mingyu Xiao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/262},
  pages     = {1887-1893},
  title     = {An exact MaxSAT algorithm: Further observations and further improvements},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Threshold-free pattern mining meets multi-objective
optimization: Application to association rules. <em>IJCAI</em>,
1880–1886. (<a href="https://doi.org/10.24963/ijcai.2022/261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Constraint-based pattern mining is at the core of numerous data mining tasks. Unfortunately, thresholds which are involved in these constraints cannot be easily chosen. This paper investigates a Multi-objective Optimization approach where several (often conflicting) functions need to be optimized at the same time. We introduce a new model for efficiently mining Pareto optimal patterns with constraint programming. Our model exploits condensed pattern representations to reduce the mining effort. To this end, we design a new global constraint for ensuring the closeness of patterns over a set of measures. We show how our approach can be applied to derive high-quality non redundant association rules without the use of thresholds whose added-value is studied on both UCI datasets and case study related to the analysis of genes expression data integrating multiple external genes annotations. Keywords: Constraint Satisfaction and Optimization: Constraint Programming Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Constraints and Machine Learning Data Mining: Exploratory Data Mining Data Mining: Frequent Pattern Mining},
  archive   = {C_IJCAI},
  author    = {Charles Vernerey and Samir Loudni and Noureddine Aribi and Yahia Lebbah},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/261},
  pages     = {1880-1886},
  title     = {Threshold-free pattern mining meets multi-objective optimization: Application to association rules},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated program analysis: Revisiting precondition
inference through constraint acquisition. <em>IJCAI</em>, 1873–1879. (<a
href="https://doi.org/10.24963/ijcai.2022/260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Program annotations under the form of function pre/postconditions are crucial for many software engineering and program verification applications. Unfortunately, such annotations are rarely available and must be retrofit by hand. In this paper, we explore how Constraint Acquisition (CA), a learning framework from Constraint Programming, can be leveraged to automatically infer program preconditions in a black-box manner, from input-output observations. We propose PreCA, the first ever framework based on active constraint acquisition dedicated to infer memory-related preconditions. PreCA overpasses prior techniques based on program analysis and formal methods, offering well-identified guarantees and returning more precise results in practice. Keywords: Constraint Satisfaction and Optimization: Constraints and Machine Learning Machine Learning: Active Learning Multidisciplinary Topics and Applications: Software Engineering Multidisciplinary Topics and Applications: Validation and Verification},
  archive   = {C_IJCAI},
  author    = {Grégoire Menguy and Sébastien Bardin and Nadjib Lazaar and Arnaud Gotlieb},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/260},
  pages     = {1873-1879},
  title     = {Automated program analysis: Revisiting precondition inference through constraint acquisition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AllSATCC: Boosting AllSAT solving with efficient component
analysis. <em>IJCAI</em>, 1866–1872. (<a
href="https://doi.org/10.24963/ijcai.2022/259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {All Solution SAT (AllSAT) is a variant of Propositional Satisfiability, which aims to find all satisfying assignments for a given formula. AllSAT has significant applications in different domains, such as software testing, data mining, and network verification. In this paper, observing that the lack of component analysis may result in more work for algorithms with non-chronological backtracking, we propose a DPLL-based algorithm for solving AllSAT problem, named AllSATCC, which takes advantage of component analysis to reduce work repetition caused by non-chronological backtracking. The experimental results show that our algorithm outperforms the state-of-the-art algorithms on most instances. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Jiaxin Liang and Feifei Ma and Junping Zhou and Minghao Yin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/259},
  pages     = {1866-1872},
  title     = {AllSATCC: Boosting AllSAT solving with efficient component analysis},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Best heuristic identification for constraint satisfaction.
<em>IJCAI</em>, 1859–1865. (<a
href="https://doi.org/10.24963/ijcai.2022/258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In constraint satisfaction problems, the variable ordering heuristic takes a central place by selecting the variables to branch on during backtrack search. As many hand-crafted branching heuristics have been proposed in the literature, a key issue is to identify, from a pool of candidate heuristics, which one is the best for solving a given constraint satisfaction task. Based on the observation that modern constraint solvers are using restart sequences, the best heuristic identification problem can be cast in the context of multi-armed bandits as a non-stochastic best arm identification problem. Namely, during each run of some given restart sequence, the bandit algorithm selects a branching heuristic and receives a reward for this heuristic before proceeding to the next run. The goal is to identify the best heuristic using few runs, and without any stochastic assumption about the constraint solver. In this study, we propose an adaptive variant of Successive Halving that exploits Luby&#39;s universal restart sequence. We analyze the convergence of this bandit algorithm in the non-stochastic setting, and we demonstrate its empirical effectiveness on various constraint satisfaction benchmarks. Keywords: Constraint Satisfaction and Optimization: Constraints and Machine Learning Constraint Satisfaction and Optimization: Constraint Satisfaction Machine Learning: Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Frederic Koriche and Christophe Lecoutre and Anastasia Paparrizou and Hugues Wattez},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/258},
  pages     = {1859-1865},
  title     = {Best heuristic identification for constraint satisfaction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Using constraint programming and graph representation
learning for generating interpretable cloud security policies.
<em>IJCAI</em>, 1850–1858. (<a
href="https://doi.org/10.24963/ijcai.2022/257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing dormant permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances. Keywords: Constraint Satisfaction and Optimization: Applications Constraint Satisfaction and Optimization: Constraint Programming Constraint Satisfaction and Optimization: Constraints and Machine Learning Constraint Satisfaction and Optimization: Modeling Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Mikhail Kazdagli and Mohit Tiwari and Akshat Kumar},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/257},
  pages     = {1850-1858},
  title     = {Using constraint programming and graph representation learning for generating interpretable cloud security policies},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Degradation accordant plug-and-play for low-rank tensor
completion. <em>IJCAI</em>, 1843–1849. (<a
href="https://doi.org/10.24963/ijcai.2022/256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Tensor completion aims at estimating missing values from an incomplete observation, playing a fundamental role for many applications. This work proposes a novel low-rank tensor completion model, in which the inherent low-rank prior and external degradation accordant data-driven prior are simultaneously utilized. Specifically, the tensor nuclear norm (TNN) is adopted to characterize the overall low-dimensionality of the tensor data. Meanwhile, an implicit regularizer is formulated and its related subproblem is solved via a deep convolutional neural network (CNN) under the plug-and-play framework. This CNN, pretrained for the inpainting task on a mass of natural images, is expected to express the external data-driven prior and this plugged inpainter is consistent with the original degradation process. Then, an efficient alternating direction method of multipliers (ADMM) is designed to solve the proposed optimization model. Extensive experiments are conducted on different types of tensor imaging data with the comparison with state-of-the-art methods, illustrating the effectiveness and the remarkable generalization ability of our method. Keywords: Constraint Satisfaction and Optimization: Modeling Computer Vision: Computational photography Computer Vision: Machine Learning for Vision Constraint Satisfaction and Optimization: Constraints and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yexun Hu and Tai-Xiang Jiang and Xi-Le Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/256},
  pages     = {1843-1849},
  title     = {Degradation accordant plug-and-play for low-rank tensor completion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Encoding probabilistic graphical models into stochastic
boolean satisfiability. <em>IJCAI</em>, 1834–1842. (<a
href="https://doi.org/10.24963/ijcai.2022/255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Statistical inference is a powerful technique in various applications. Although many statistical inference tools are available, answering inference queries involving complex quantification structures remains challenging. Recently, solvers for Stochastic Boolean Satisfiability (SSAT), a powerful formalism allowing concise encodings of PSPACE decision problems under uncertainty, are under active development and applied in more and more applications. In this work, we exploit SSAT solvers for the inference of Probabilistic Graphical Models (PGMs), an essential representation for probabilistic reasoning. Specifically, we develop encoding methods to systematically convert PGM inference problems into SSAT formulas for effective solving. Experimental results demonstrate that, by using our encoding, SSAT-based solving can complement existing PGM tools, especially in answering complex queries. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Applications Constraint Satisfaction and Optimization: Constraint Satisfaction Constraint Satisfaction and Optimization: Modeling Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Cheng-Han Hsieh and Jie-Hong R. Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/255},
  pages     = {1834-1842},
  title     = {Encoding probabilistic graphical models into stochastic boolean satisfiability},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online matching with controllable rewards and arrival
probabilities. <em>IJCAI</em>, 1825–1833. (<a
href="https://doi.org/10.24963/ijcai.2022/254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Online bipartite matching has attracted much attention due to its importance in various applications such as advertising, ride-sharing, and crowdsourcing. In most online matching problems, the rewards and node arrival probabilities are given in advance and are not controllable. However, many real-world matching services require them to be controllable and the decision-maker faces a non-trivial problem of optimizing them. In this study, we formulate a new optimization problem, Online Matching with Controllable Rewards and Arrival probabilities (OM-CRA), to simultaneously determine not only the matching strategy but also the rewards and arrival probabilities. Even though our problem is more complex than the existing ones, we propose a fast 1/2-approximation algorithm for OM-CRA. The proposed approach transforms OM-CRA to a saddle-point problem by approximating the objective function, and then solves it by the Primal-Dual Hybrid Gradient (PDHG) method with acceleration through the use of the problem structure. In simulations on real data from crowdsourcing and ride-sharing platforms, we show that the proposed algorithm can find solutions with high total rewards in practical times. Keywords: Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Applications Constraint Satisfaction and Optimization: Modeling},
  archive   = {C_IJCAI},
  author    = {Yuya Hikima and Yasunori Akagi and Naoki Marumo and Hideaki Kim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/254},
  pages     = {1825-1833},
  title     = {Online matching with controllable rewards and arrival probabilities},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Large neighbourhood search for anytime MaxSAT solving.
<em>IJCAI</em>, 1818–1824. (<a
href="https://doi.org/10.24963/ijcai.2022/253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Large Neighbourhood Search (LNS) is an algorithmic framework for optimization problems that can yield good performance in many domains. In this paper, we present a method for applying LNS to improve anytime maximum satisfiability (MaxSAT) solving by introducing a neighbourhood selection policy that shows good empirical performance. We show that our LNS solver can often improve the suboptimal solutions produced by other anytime MaxSAT solvers. When starting with a suboptimal solution of reasonable quality, our approach often finds a better solution than the original anytime solver can achieve. We demonstrate that implementing our LNS solver on top of three different state-of-the-art anytime solvers improves the anytime performance of all three solvers within the standard time limit used in the incomplete tracks of the annual MaxSAT Evaluation. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Randy Hickey and Fahiem Bacchus},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/253},
  pages     = {1818-1824},
  title     = {Large neighbourhood search for anytime MaxSAT solving},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Accelerated multiplicative weights update avoids saddle
points almost always. <em>IJCAI</em>, 1811–1817. (<a
href="https://doi.org/10.24963/ijcai.2022/252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider nonconvex optimization problem with constraint that is a product of simplices. A commonly used algorithm in solving this type of problem is the Multiplicative Weights Update (MWU), an algorithm that is widely used in game theory, machine learning and multi agent systems. Despite it has been known that MWU avoids saddle points, there is a question that remains unaddressed: ``Is there an accelerated version of MWU that avoids saddle points provably?&#39;&#39; In this paper we provide a positive answer to above question. We provide an accelerated MWU based on Riemannian Accelerated Gradient Descent, and prove that the Riemannian Accelerated Gradient Descent, thus the accelerated MWU, avoid saddle points. Keywords: Constraint Satisfaction and Optimization: Constraint Optimization Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Yi Feng and Ioannis Panageas and Xiao Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/252},
  pages     = {1811-1817},
  title     = {Accelerated multiplicative weights update avoids saddle points almost always},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A multivariate complexity analysis of qualitative reasoning
problems. <em>IJCAI</em>, 1804–1810. (<a
href="https://doi.org/10.24963/ijcai.2022/251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Qualitative reasoning is an important subfield of artificial intelligence where one describes relationships with qualitative, rather than numerical, relations. Many such reasoning tasks, e.g., Allen&#39;s interval algebra, can be solved in 2^O(n*log n) time, but single-exponential running times 2^O(n) are currently far out of reach. In this paper we consider single-exponential algorithms via a multivariate analysis consisting of a fine-grained parameter n (e.g., the number of variables) and a coarse-grained parameter k expected to be relatively small. We introduce the classes FPE and XE of problems solvable in f(k)*2^O(n), respectively f(k)^n, time, and prove several fundamental properties of these classes. We proceed by studying temporal reasoning problems and (1) show that the partially ordered time problem of effective width k is solvable in 16^{kn} time and is thus included in XE, and (2) that the network consistency problem for Allen&#39;s interval algebra with no interval overlapping with more than k others is solvable in (2nk)^{2k}*2^n time and is included in FPE. Our multivariate approach is in no way limited to these to specific problems and may be a generally useful approach for obtaining single-exponential algorithms. Keywords: Constraint Satisfaction and Optimization: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Leif Eriksson and Victor Lagerkvist},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/251},
  pages     = {1804-1810},
  title     = {A multivariate complexity analysis of qualitative reasoning problems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DPSampler: Exact weighted sampling using dynamic
programming. <em>IJCAI</em>, 1795–1803. (<a
href="https://doi.org/10.24963/ijcai.2022/250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The problem of exact weighted sampling of solutions of Boolean formulas has applications in Bayesian inference, testing, and verification. The state-of-the-art approach to sampling involves carefully decomposing the input formula and compiling a data structure called d-DNNF in the process. Recent work in the closely connected field of model counting, however, has shown that smartly composing different subformulas using dynamic programming and Algebraic Decision Diagrams (ADDs) can outperform d-DNNF-style approaches on many benchmarks. In this work, we present a modular algorithm called DPSampler that extends such dynamic-programming techniques to the problem of exact weighted sampling. DPSampler operates in three phases. First, an execution plan in the form of a project-join tree is computed using tree decompositions. Second, the plan is used to compile the input formula into a succinct tree-of-ADDs representation. Third, this tree is traversed to generate a random sample. This decoupling of planning, compilation and sampling phases enables usage of specialized libraries for each purpose in a black-box fashion. Further, our novel ADD-sampling algorithm avoids the need for expensive dynamic memory allocation required in previous work. Extensive experiments over diverse sets of benchmarks show DPSampler is more scalable and versatile than existing approaches. Keywords: Constraint Satisfaction and Optimization: Solvers and Tools Constraint Satisfaction and Optimization: Applications Constraint Satisfaction and Optimization: Constraint Satisfaction Constraint Satisfaction and Optimization: Other Constraint Satisfaction and Optimization: Satisfiabilty},
  archive   = {C_IJCAI},
  author    = {Jeffrey M. Dudek and Aditya A. Shrotri and Moshe Y. Vardi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/250},
  pages     = {1795-1803},
  title     = {DPSampler: Exact weighted sampling using dynamic programming},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Combining constraint solving and bayesian techniques for
system optimization. <em>IJCAI</em>, 1788–1794. (<a
href="https://doi.org/10.24963/ijcai.2022/249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Application domains of Bayesian optimization include optimizing black-box functions or very complex functions. The functions we are interested in describe complex real-world systems applied in industrial settings. Even though they do have explicit representations, standard optimization techniques fail to provide validated solutions and correctness guarantees for them. In this paper we present a combination of Bayesian optimization and SMT-based constraint solving to achieve safe and stable solutions with optimality guarantees. Keywords: Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Constraints and Machine Learning Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Solvers and Tools Machine Learning: Optimisation},
  archive   = {C_IJCAI},
  author    = {Franz Brauße and Zurab Khasidashvili and Konstantin Korovin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/249},
  pages     = {1788-1794},
  title     = {Combining constraint solving and bayesian techniques for system optimization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). QCDCL with cube learning or pure literal elimination - what
is best? <em>IJCAI</em>, 1781–1787. (<a
href="https://doi.org/10.24963/ijcai.2022/248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Quantified conflict-driven clause learning (QCDCL) is one of the main approaches for solving quantified Boolean formulas (QBF). We formalise and investigate several versions of QCDCL that include cube learning and/or pure-literal elimination, and formally compare the resulting solving models via proof complexity techniques. Our results show that almost all of the QCDCL models are exponentially incomparable with respect to proof size (and hence solver running time), pointing towards different orthogonal ways how to practically implement QCDCL. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Solvers and Tools},
  archive   = {C_IJCAI},
  author    = {Benjamin Böhm and Tomáš Peitl and Olaf Beyersdorff},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/248},
  pages     = {1781-1787},
  title     = {QCDCL with cube learning or pure literal elimination - what is best?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fine-grained complexity of partial minimum satisfiability.
<em>IJCAI</em>, 1774–1780. (<a
href="https://doi.org/10.24963/ijcai.2022/247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {There is a well-known approach to cope with NP-hard problems in practice: reduce the given problem to SAT or MAXSAT and run a SAT or a MaxSAT solver. This method is very efficient since SAT/MaxSAT solvers are extremely well-studied, as well as the complexity of these problems. At AAAI 2011, Li et al. proposed an alternative to this approach and suggested the Partial Minimum Satisfiability problem as a reduction target for NP-hard problems. They developed the MinSatz solver and showed that reducing to Partial Minimum Satisfiability and using MinSatz is in some cases more efficient than reductions to SAT or MaxSAT. Since then many results connected to the Partial Minimum Satisfiability problem were published. However, to the best of our knowledge, the worst-case complexity of Partial Minimum Satisfiability has not been studied up until now. Our goal is to fix the issue and show a O*((2-ɛ)^m) lower bound under the SETH assumption (here m is the total number of clauses), as well as several other lower bounds and parameterized exact algorithms with better-than-trivial running time. Keywords: Constraint Satisfaction and Optimization: Satisfiabilty Constraint Satisfaction and Optimization: Constraint Optimization Constraint Satisfaction and Optimization: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Ivan Bliznets and Danil Sagunov and Kirill Simonov},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/247},
  pages     = {1774-1780},
  title     = {Fine-grained complexity of partial minimum satisfiability},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A solver + gradient descent training algorithm for deep
neural networks. <em>IJCAI</em>, 1766–1773. (<a
href="https://doi.org/10.24963/ijcai.2022/246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a novel hybrid algorithm for training Deep Neural Networks that combines the state-of-the-art Gradient Descent (GD) method with a Mixed Integer Linear Programming (MILP) solver, outperforming GD and variants in terms of accuracy, as well as resource and data efficiency for both regression and classification tasks. Our GD+Solver hybrid algorithm, called GDSolver, works as follows: given a DNN D as input, GDSolver invokes GD to partially train D until it gets stuck in a local minima, at which point GDSolver invokes an MILP solver to exhaustively search a region of the loss landscape around the weight assignments of D’s final layer parameters with the goal of tunnelling through and escaping the local minima. The process is repeated until desired accuracy is achieved. In our experiments, we find that GDSolver not only scales well to additional data and very large model sizes, but also outperforms all other competing methods in terms of rates of convergence and data efficiency. For regression tasks, GDSolver produced models that, on average, had 31.5\% lower MSE in 48\% less time, and for classification tasks on MNIST and CIFAR10, GDSolver was able to achieve the highest accuracy over all competing methods, using only 50\% of the training data that GD baselines required. Keywords: Constraint Satisfaction and Optimization: Solvers and Tools Constraint Satisfaction and Optimization: Constraints and Machine Learning Constraint Satisfaction and Optimization: Constraint Programming Constraint Satisfaction and Optimization: Constraint Satisfaction Constraint Satisfaction and Optimization: Constraint Optimization},
  archive   = {C_IJCAI},
  author    = {Dhananjay Ashok and Vineel Nagisetty and Christopher Srinivasa and Vijay Ganesh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/246},
  pages     = {1766-1773},
  title     = {A solver + gradient descent training algorithm for deep neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hierarchical bilevel learning with architecture and loss
search for hadamard-based image restoration. <em>IJCAI</em>, 1757–1764.
(<a href="https://doi.org/10.24963/ijcai.2022/245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the past few decades, Hadamard-based image restoration problems (e.g., low-light image enhancement) attract wide concerns in multiple areas related to artificial intelligence. However, existing works mostly focus on heuristically defining architecture and loss by the engineering experiences that came from extensive practices. This way brings about expensive verification costs for seeking out the optimal solution. To this end, we develop a novel hierarchical bilevel learning scheme to discover the architecture and loss simultaneously for different Hadamard-based image restoration tasks. More concretely, we first establish a new Hadamard-inspired neural unit to aggregate domain knowledge into the network design. Then we model a triple-level optimization that consists of the architecture, loss and parameters optimizations to deliver a macro perspective for network learning. Then we introduce a new hierarchical bilevel learning scheme for solving the built triple-level model to progressively generate the desired architecture and loss. We also define an architecture search space consisting of a series of simple operations and an image quality-oriented loss search space. Extensive experiments on three Hadamard-based image restoration tasks (including low-light image enhancement, single image haze removal and underwater image enhancement) fully verify our superiority against state-of-the-art methods. Keywords: Computer Vision: Computational photography Computer Vision: Other},
  archive   = {C_IJCAI},
  author    = {Guijing Zhu and Long Ma and Xin Fan and Risheng Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/245},
  pages     = {1757-1764},
  title     = {Hierarchical bilevel learning with architecture and loss search for hadamard-based image restoration},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). HifiHead: One-shot high fidelity neural head synthesis with
3D control. <em>IJCAI</em>, 1750–1756. (<a
href="https://doi.org/10.24963/ijcai.2022/244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We propose HifiHead, a high fidelity neural talking head synthesis method, which can well preserve the source image&#39;s appearance and control the motion (e.g., pose, expression, gaze) flexibly with 3D morphable face models (3DMMs) parameters derived from a driving image or indicated by users. Existing head synthesis works mainly focus on low-resolution inputs. Instead, we exploit the powerful generative prior embedded in StyleGAN to achieve high-quality head synthesis and editing. Specifically, we first extract the source image&#39;s appearance and driving image&#39;s motion to construct 3D face descriptors, which are employed as latent style codes for the generator. Meanwhile, hierarchical representations are extracted from the source and rendered 3D images respectively to provide faithful appearance and shape guidance. Considering the appearance representations need high-resolution flow fields for spatial transform, we propose a coarse-to-fine style-based generator consisting of a series of feature alignment and refinement (FAR) blocks. Each FAR block updates the dense flow fields and refines RGB outputs simultaneously for efficiency. Extensive experiments show that our method blends source appearance and target motion more accurately along with more photo-realistic results than previous state-of-the-art approaches. Keywords: Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: 3D Computer Vision Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Feida Zhu and Junwei Zhu and Wenqing Chu and Ying Tai and Zhifeng Xie and Xiaoming Huang and Chengjie Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/244},
  pages     = {1750-1756},
  title     = {HifiHead: One-shot high fidelity neural head synthesis with 3D control},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rainy WCity: A real rainfall dataset with diverse conditions
for semantic driving scene understanding. <em>IJCAI</em>, 1743–1749. (<a
href="https://doi.org/10.24963/ijcai.2022/243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene understanding in adverse weather conditions (e.g. rainy and foggy days) has drawn increasing attention, arising some specific benchmarks and algorithms. However, scene segmentation under rainy weather is still challenging and under-explored due to the following limitations on the datasets and methods: 1) Manually synthetic rainy samples with empirically settings and human subjective assumptions; 2) Limited rainy conditions, including the rain patterns, intensity, and degradation factors; 3) Separated training manners for image deraining and semantic segmentation. To break these limitations, we pioneer a real, comprehensive, and well-annotated scene understanding dataset under rainy weather, named Rainy WCity. It covers various rain patterns and their bring-in negative visual effects, covering wiper, droplet, reflection, refraction, shadow, windshield-blurring, etc. In addition, to alleviate dependence on paired training samples, we design an unsupervised contrastive learning network for real image deraining and the final rainy scene semantic segmentation via multi-task joint optimization. A comprehensive comparison analysis is also provided, which shows that scene understanding in rainy weather is a largely open problem. Finally, we summarize our general observations, identify open research challenges, and point out future directions. Keywords: Computer Vision: Scene analysis and understanding Computer Vision: Segmentation Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Xian Zhong and Shidong Tu and Xianzheng Ma and Kui Jiang and Wenxin Huang and Zheng Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/243},
  pages     = {1743-1749},
  title     = {Rainy WCity: A real rainfall dataset with diverse conditions for semantic driving scene understanding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Imperceptible backdoor attack: From input space to feature
representation. <em>IJCAI</em>, 1736–1742. (<a
href="https://doi.org/10.24963/ijcai.2022/242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Backdoor attacks are rapidly emerging threats to deep neural networks (DNNs). In the backdoor attack scenario, attackers usually implant the backdoor into the target model by manipulating the training dataset or training process. Then, the compromised model behaves normally for benign input yet makes mistakes when the pre-defined trigger appears. In this paper, we analyze the drawbacks of existing attack approaches and propose a novel imperceptible backdoor attack. We treat the trigger pattern as a special kind of noise following a multinomial distribution. A U-net-based network is employed to generate concrete parameters of multinomial distribution for each benign input. This elaborated trigger ensures that our approach is invisible to both humans and statistical detection. Besides the design of the trigger, we also consider the robustness of our approach against model diagnose-based defences. We force the feature representation of malicious input stamped with the trigger to be entangled with the benign one. We demonstrate the effectiveness and robustness against multiple state-of-the-art defences through extensive datasets and networks. Our trigger only modifies less than 1\% pixels of a benign image while the modification magnitude is 1. Our source code is available at https://github.com/Ekko-zn/IJCAI2022-Backdoor. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods AI Ethics, Trust, Fairness: Trustworthy AI},
  archive   = {C_IJCAI},
  author    = {Nan Zhong and Zhenxing Qian and Xinpeng Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/242},
  pages     = {1736-1742},
  title     = {Imperceptible backdoor attack: From input space to feature representation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Visual similarity attention. <em>IJCAI</em>, 1728–1735. (<a
href="https://doi.org/10.24963/ijcai.2022/241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While there has been substantial progress in learning suitable distance metrics, these techniques in general lack transparency and decision reasoning, i.e., explaining why the input set of images is similar or dissimilar. In this work, we solve this key problem by proposing the first method to generate generic visual similarity explanations with gradient-based attention. We demonstrate that our technique is agnostic to the specific similarity model type, e.g., we show applicability to Siamese, triplet, and quadruplet models. Furthermore, we make our proposed similarity attention a principled part of the learning process, resulting in a new paradigm for learning similarity functions. We demonstrate that our learning mechanism results in more generalizable, as well as explainable, similarity models. Finally, we demonstrate the generality of our framework by means of experiments on a variety of tasks, including image retrieval, person re-identification, and low-shot semantic segmentation. Keywords: Computer Vision: Interpretability and Transparency Computer Vision: Image and Video retrieval Computer Vision: Representation Learning Computer Vision: Segmentation Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Meng Zheng and Srikrishna Karanam and Terrence Chen and Richard J. Radke and Ziyan Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/241},
  pages     = {1728-1735},
  title     = {Visual similarity attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Test-time fourier style calibration for domain
generalization. <em>IJCAI</em>, 1721–1727. (<a
href="https://doi.org/10.24963/ijcai.2022/240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The topic of generalizing machine learning models learned on a collection of source domains to unknown target domains is challenging. While many domain generalization (DG) methods have achieved promising results, they primarily rely on the source domains at train-time without manipulating the target domains at test-time. Thus, it is still possible that those methods can overfit to source domains and perform poorly on target domains. Driven by the observation that domains are strongly related to styles, we argue that reducing the gap between source and target styles can boost models’ generalizability. To solve the dilemma of having no access to the target domain during training, we introduce Test-time Fourier Style Calibration (TF-Cal) for calibrating the target domain style on the fly during testing. To access styles, we utilize Fourier transformation to decompose features into amplitude (style) features and phase (semantic) features. Furthermore, we present an effective technique to Augment Amplitude Features (AAF) to complement TF-Cal. Extensive experiments on several popular DG benchmarks and a segmentation dataset for medical images demonstrate that our method outperforms state-of-the-art methods. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision},
  archive   = {C_IJCAI},
  author    = {Xingchen Zhao and Chang Liu and Anthony Sicilia and Seong Jae Hwang and Yun Fu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/240},
  pages     = {1721-1727},
  title     = {Test-time fourier style calibration for domain generalization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to generate image source-agnostic universal
adversarial perturbations. <em>IJCAI</em>, 1714–1720. (<a
href="https://doi.org/10.24963/ijcai.2022/239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial perturbations are critical for certifying the robustness of deep learning models. A ``universal adversarial perturbation&#39;&#39; (UAP) can simultaneously attack multiple images, and thus offers a more unified threat model, obviating an image-wise attack algorithm. However, the existing UAP generator is underdeveloped when images are drawn from different image sources (e.g., with different image resolutions). Towards an authentic universality across image sources, we take a novel view of UAP generation as a customized instance of ``few-shot learning&#39;&#39;, which leverages bilevel optimization and learning-to-optimize (L2O) techniques for UAP generation with improved attack success rate (ASR). We begin by considering the popular model agnostic meta-learning (MAML) framework to meta-learn a UAP generator. However, we see that the MAML framework does not directly offer the universal attack across image sources, requiring us to integrate it with another meta-learning framework of L2O. The resulting scheme for meta-learning a UAP generator (i) has better performance (50\% higher ASR) than baselines such as Projected Gradient Descent, (ii) has better performance (37\% faster) than the vanilla L2O and MAML frameworks (when applicable), and (iii) is able to simultaneously handle UAP generation for different victim models and data sources. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Machine Learning: Meta-Learning},
  archive   = {C_IJCAI},
  author    = {Pu Zhao and Parikshit Ram and Songtao Lu and Yuguang Yao and Djallel Bouneffouf and Xue Lin and Sijia Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/239},
  pages     = {1714-1720},
  title     = {Learning to generate image source-agnostic universal adversarial perturbations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). C3-STISR: Scene text image super-resolution with triple
clues. <em>IJCAI</em>, 1707–1713. (<a
href="https://doi.org/10.24963/ijcai.2022/238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Scene text image super-resolution (STISR) has been regarded as an important pre-processing task for text recognition from low-resolution scene text images. Most recent approaches use the recognizer&#39;s feedback as clues to guide super-resolution. However, directly using recognition clue has two problems: 1) Compatibility. It is in the form of probability distribution, has an obvious modal gap with STISR - a pixel-level task; 2) Inaccuracy. it usually contains wrong information, thus will mislead the main task and degrade super-resolution performance. In this paper, we present a novel method C3-STISR that jointly exploits the recognizer&#39;s feedback, visual and linguistical information as clues to guide super-resolution. Here, visual clue is from the images of texts predicted by the recognizer, which is informative and more compatible with the STISR task; while linguistical clue is generated by a pre-trained character-level language model, which is able to correct the predicted texts. We design effective extraction and fusion mechanisms for the triple cross-modal clues to generate a comprehensive and unified guidance for super-resolution. Extensive experiments on TextZoom show that C3-STISR outperforms the SOTA methods in fidelity and recognition performance. Code is available in https://github.com/zhaominyiz/C3-STISR. Keywords: Computer Vision: Applications Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Minyi Zhao and Miao Wang and Fan Bai and Bingjia Li and Jie Wang and Shuigeng Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/238},
  pages     = {1707-1713},
  title     = {C3-STISR: Scene text image super-resolution with triple clues},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adaptation via maximizing surrogate mutual
information. <em>IJCAI</em>, 1700–1706. (<a
href="https://doi.org/10.24963/ijcai.2022/237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised domain adaptation (UDA), which is an important topic in transfer learning, aims to predict unlabeled data from target domain with access to labeled data from the source domain. In this work, we propose a novel framework called SIDA (Surrogate Mutual Information Maximization Domain Adaptation) with strong theoretical guarantees. To be specific, SIDA implements adaptation by maximizing mutual information (MI) between features. In the framework, a surrogate joint distribution models the underlying joint distribution of the unlabeled target domain. Our theoretical analysis validates SIDA by bounding the expected risk on target domain with MI and surrogate distribution bias. Experiments show that our approach is comparable with state-of-the-art unsupervised adaptation methods on standard UDA tasks. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Haiteng Zhao and Chang Ma and Qinyu Chen and Zhi-Hong Deng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/237},
  pages     = {1700-1706},
  title     = {Domain adaptation via maximizing surrogate mutual information},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain adversarial learning for color constancy.
<em>IJCAI</em>, 1693–1699. (<a
href="https://doi.org/10.24963/ijcai.2022/236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Color Constancy aims to eliminate the color cast of RAW images caused by non-neutral illuminants. Though contemporary approaches based on convolutional neural networks significantly improve illuminant estimation, they suffer from the seriously insufficient data problem. To solve this problem by effectively utilizing multi-domain data, we propose the Domain Adversarial Learning Color Constancy (DALCC) which consists of the Domain Adversarial Learning Branch (DALB) and the Feature Reweighting Module (FRM). In DALB, the Camera Domain Classifier and the feature extractor compete against each other in an adversarial way to encourage the emergence of domain-invariant features. At the same time, the Illuminant Transformation Module performs color space conversion to solve the inconsistent color space problem caused by those domain-invariant features. They collaboratively avoid model degradation of multi-device training caused by the domain discrepancy of feature distribution, which enables our DALCC to benefit from multi-domain data. Besides, to better utilize multi-domain data, we propose the FRM that reweights the feature map to suppress Non-Primary Illuminant regions, which reduces the influence of misleading illuminant information. Experiments show that the proposed DALCC can more effectively take advantage of multi-domain data and thus achieve state-of-the-art performance on commonly used benchmark datasets. Keywords: Computer Vision: Computational photography Computer Vision: Machine Learning for Vision Machine Learning: Adversarial Machine Learning Machine Learning: Convolutional Networks Machine Learning: Multi-task and Transfer Learning},
  archive   = {C_IJCAI},
  author    = {Zhifeng Zhang and Xuejing Kang and Anlong Ming},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/236},
  pages     = {1693-1699},
  title     = {Domain adversarial learning for color constancy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distilling inter-class distance for semantic segmentation.
<em>IJCAI</em>, 1686–1692. (<a
href="https://doi.org/10.24963/ijcai.2022/235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knowledge distillation is widely adopted in semantic segmentation to reduce the computation cost. The previous knowledge distillation methods for semantic segmentation focus on pixel-wise feature alignment and intra-class feature variation distillation, neglecting to transfer the knowledge of the inter-class distance in the feature space, which is important for semantic segmentation such a pixel-wise classification task. To address this issue, we propose an Inter-class Distance Distillation (IDD) method to transfer the inter-class distance in the feature space from the teacher network to the student network. Furthermore, semantic segmentation is a position-dependent task, thus we exploit a position information distillation module to help the student network encode more position information. Extensive experiments on three popular datasets: Cityscapes, Pascal VOC and ADE20K show that our method is helpful to improve the accuracy of semantic segmentation models and achieves the state-of-the-art performance. E.g. it boosts the benchmark model (``PSPNet+ResNet18&quot;) by 7.50\% in accuracy on the Cityscapes dataset. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Recognition (object detection, categorization) Computer Vision: Scene analysis and understanding Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Zhengbo Zhang and Chunluan Zhou and Zhigang Tu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/235},
  pages     = {1686-1692},
  title     = {Distilling inter-class distance for semantic segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Visual emotion representation learning via emotion-aware
pre-training. <em>IJCAI</em>, 1679–1685. (<a
href="https://doi.org/10.24963/ijcai.2022/234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite recent progress in deep learning, visual emotion recognition remains a challenging problem due to ambiguity of emotion perception, diverse concepts related to visual emotion and lack of large-scale annotated dataset. In this paper, we present a large-scale multimodal pre-training method to learn visual emotion representation by aligning emotion, object, attribute triplet with a contrastive loss. We conduct our pre-training on a large web dataset with noisy tags and fine-tune on visual emotion classification datasets. Our method achieves state-of-the-art performance for visual emotion classification. Keywords: Computer Vision: Vision and language Natural Language Processing: Sentiment Analysis and Text Mining Humans and AI: Cognitive Modeling},
  archive   = {C_IJCAI},
  author    = {Yue Zhang and Wanying Ding and Ran Xu and Xiaohua Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/234},
  pages     = {1679-1685},
  title     = {Visual emotion representation learning via emotion-aware pre-training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Enhancing the transferability of adversarial examples with
random patch. <em>IJCAI</em>, 1672–1678. (<a
href="https://doi.org/10.24963/ijcai.2022/233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial examples can fool deep learning models, and their transferability is critical for attacking black-box models in real-world scenarios. Existing state-of-the-art transferable adversarial attacks tend to exploit intrinsic features of objects to generate adversarial examples. This paper proposes the Random Patch Attack (RPA) to significantly improve the transferability of adversarial examples by the patch-wise random transformation that effectively highlights important intrinsic features of objects. Specifically, we introduce random patch transformations to original images to variate model-specific features. Important object-related features are preserved after aggregating the transformed images since they stay consistent in multiple transformations while model-specific elements are neutralized. The obtained essential features steer noises to perturb the object-related regions, generating the adversarial examples of superior transferability across different models. Extensive experimental results demonstrate the effectiveness of the proposed RPA. Compared to the state-of-the-art transferable attacks, our attacks improve the black-box attack success rate by 2.9\% against normally trained models, 4.7\% against defense models, and 4.6\% against vision transformers on average, reaching a maximum of 99.1\%, 93.2\%, and 87.8\%, respectively. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Yaoyuan Zhang and Yu-an Tan and Tian Chen and Xinrui Liu and Quanxin Zhang and Yuanzhang Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/233},
  pages     = {1672-1678},
  title     = {Enhancing the transferability of adversarial examples with random patch},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). Few-shot adaptation of pre-trained networks for domain
shift. <em>IJCAI</em>, 1665–1671. (<a
href="https://doi.org/10.24963/ijcai.2022/232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep networks are prone to performance degradation when there is a domain shift between the source (training) data and target (test) data. Recent test-time adaptation methods update batch normalization layers of pre-trained source models deployed in new target environments with streaming data. Although these methods can adapt on-the-fly without first collecting a large target domain dataset, their performance is dependent on streaming conditions such as mini-batch size and class-distribution which can be unpredictable in practice. In this work, we propose a framework for few-shot domain adaptation to address the practical challenges of data-efficient adaptation. Specifically, we propose a constrained optimization of feature normalization statistics in pre-trained source models supervised by a small target domain support set. Our method is easy to implement and improves source model performance with as little as one sample per class for classification tasks. Extensive experiments on 5 cross-domain classification and 4 semantic segmentation datasets show that our proposed method achieves more accurate and reliable performance than test-time adaptation, while not being constrained by streaming conditions. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Wenyu Zhang and Li Shen and Wanyue Zhang and Chuan-Sheng Foo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/232},
  pages     = {1665-1671},
  title     = {Few-shot adaptation of pre-trained networks for domain shift},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). CATrans: Context and affinity transformer for few-shot
segmentation. <em>IJCAI</em>, 1658–1664. (<a
href="https://doi.org/10.24963/ijcai.2022/231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot segmentation (FSS) aims to segment novel categories given scarce annotated support images. The crux of FSS is how to aggregate dense correlations between support and query images for query segmentation while being robust to the large variations in appearance and context. To this end, previous Transformer-based methods explore global consensus either on context similarity or affinity map between support-query pairs. In this work, we effectively integrate the context and affinity information via the proposed novel Context and Affinity Transformer (CATrans) in a hierarchical architecture. Specifically, the Relation-guided Context Transformer (RCT) propagates context information from support to query images conditioned on more informative support features. Based on the observation that a huge feature distinction between support and query pairs brings barriers for context knowledge transfer, the Relation-guided Affinity Transformer (RAT) measures attention-aware affinity as auxiliary information for FSS, in which the self-affinity is responsible for more reliable cross-affinity. We conduct experiments to demonstrate the effectiveness of the proposed model, outperforming the state-of-the-art methods. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision},
  archive   = {C_IJCAI},
  author    = {Shan Zhang and Tianyi Wu and Sitong Wu and Guodong Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/231},
  pages     = {1658-1664},
  title     = {CATrans: Context and affinity transformer for few-shot segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A probabilistic code balance constraint with compactness and
informativeness enhancement for deep supervised hashing. <em>IJCAI</em>,
1651–1657. (<a href="https://doi.org/10.24963/ijcai.2022/230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Building on deep representation learning, deep supervised hashing has achieved promising performance in tasks like similarity retrieval. However, conventional code balance constraints (i.e., bit balance and bit uncorrelation) imposed on avoiding overfitting and improving hash code quality are unsuitable for deep supervised hashing owing to their inefficiency and impracticality of simultaneously learning deep data representations and hash functions. To address this issue, we propose probabilistic code balance constraints on deep supervised hashing to force each hash code to conform to a discrete uniform distribution. Accordingly, a Wasserstein regularizer aligns the distribution of generated hash codes to a uniform distribution. Theoretical analyses reveal that the proposed constraints form a general deep hashing framework for both bit balance and bit uncorrelation and maximizing the mutual information between data input and their corresponding hash codes. Extensive empirical analyses on two benchmark datasets further demonstrate the enhancement of compactness and informativeness of hash codes for deep supervised hash to improve retrieval performance (code available at: https://github.com/mumuxi/dshwr). Keywords: Computer Vision: Image and Video retrieval Data Mining: Applications Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Qi Zhang and Liang Hu and Longbing Cao and Chongyang Shi and Shoujin Wang and Dora D. Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/230},
  pages     = {1651-1657},
  title     = {A probabilistic code balance constraint with compactness and informativeness enhancement for deep supervised hashing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SAR-to-optical image translation via neural partial
differential equations. <em>IJCAI</em>, 1644–1650. (<a
href="https://doi.org/10.24963/ijcai.2022/229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Synthetic Aperture Radar (SAR) becomes prevailing in remote sensing while SAR images are challenging to interpret by human visual perception due to the active imaging mechanism and speckle noise. Recent researches on SAR-to-optical image translation provide a promising solution and have attracted increasing attentions, though still suffering from low optical image quality with geometric distortion due to the large domain gap. In this paper, we mitigate this issue from a novel perspective, i.e., neural partial differential equations (PDE). First, based on the efficient numerical scheme for solving PDE, i.e., Taylor Central Difference (TCD), we devise a basic TCD residual block to build the backbone network, which promotes the extraction of useful information in SAR images by aggregating and enhancing features from different levels. Furthermore, inspired by the Perona-Malik Diffusion (PMD), we devise a PMD neural module to implement feature diffusion through layers, aiming at removing the noises in smooth regions while preserving the geometric structures. Assembling them together, we propose a novel SAR-to-Optical image translation network named S2O-NPDE, which delivers optical images with finer structures and less noise while enjoying an explainability advantage from explicit mathematical derivation. Experiments on the popular SEN1-2 dataset show that our model outperforms state-of-the-art methods in terms of both objective metrics and visual quality. Keywords: Computer Vision: Applications Computer Vision: Neural generative models, auto encoders, GANs},
  archive   = {C_IJCAI},
  author    = {Mingjin Zhang and Chengyu He and Jing Zhang and Yuxiang Yang and Xiaoqi Peng and Jie Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/229},
  pages     = {1644-1650},
  title     = {SAR-to-optical image translation via neural partial differential equations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plane geometry diagram parsing. <em>IJCAI</em>, 1636–1643.
(<a href="https://doi.org/10.24963/ijcai.2022/228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Geometry diagram parsing plays a key role in geometry problem solving, wherein the primitive extraction and relation parsing remain challenging due to the complex layout and between-primitive relationship. In this paper, we propose a powerful diagram parser based on deep learning and graph reasoning. Specifically, a modified instance segmentation method is proposed to extract geometric primitives, and the graph neural network (GNN) is leveraged to realize relation parsing and primitive classification incorporating geometric features and prior knowledge. All the modules are integrated into an end-to-end model called PGDPNet to perform all the sub-tasks simultaneously. In addition, we build a new large-scale geometry diagram dataset named PGDP5K with primitive level annotations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K show that our model outperforms state-of-the-art methods in four sub-tasks remarkably. Our code, dataset and appendix material are available at https://github.com/mingliangzhang2018/PGDP. Keywords: Computer Vision: Scene analysis and understanding Computer Vision: Recognition (object detection, categorization) Computer Vision: Segmentation Computer Vision: Visual reasoning and symbolic representation Multidisciplinary Topics and Applications: Education},
  archive   = {C_IJCAI},
  author    = {Ming-Liang Zhang and Fei Yin and Yi-Han Hao and Cheng-Lin Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/228},
  pages     = {1636-1643},
  title     = {Plane geometry diagram parsing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improving transferability of adversarial examples with
virtual step and auxiliary gradients. <em>IJCAI</em>, 1629–1635. (<a
href="https://doi.org/10.24963/ijcai.2022/227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep neural networks have been demonstrated to be vulnerable to adversarial examples, which fool networks by adding human-imperceptible perturbations to benign examples. At present, the practical transfer-based black-box attacks are attracting significant attention. However, most existing transfer-based attacks achieve only relatively limited success rates. We propose to improve the transferability of adversarial examples through the use of a virtual step and auxiliary gradients. Here, the “virtual step” refers to using an unusual step size and clipping adversarial perturbations only in the last iteration, while the “auxiliary gradients” refer to using not only gradients corresponding to the ground-truth label (for untargeted attacks), but also gradients corresponding to some other labels to generate adversarial perturbations. Our proposed virtual step and auxiliary gradients can be easily integrated into existing gradient-based attacks. Extensive experiments on ImageNet show that the adversarial examples crafted by our method can effectively transfer to different networks. For single-model attacks, our method outperforms the state-of-the-art baselines, improving the success rates by a large margin of 12\%~28\%. Our code is publicly available at https://github.com/mingcheung/Virtual-Step-and-Auxiliary-Gradients. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Machine Learning: Adversarial Machine Learning Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Ming Zhang and Xiaohui Kuang and Hu Li and Zhendong Wu and Yuanping Nie and Gang Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/227},
  pages     = {1629-1635},
  title     = {Improving transferability of adversarial examples with virtual step and auxiliary gradients},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Region-level contrastive and consistency learning for
semi-supervised semantic segmentation. <em>IJCAI</em>, 1622–1628. (<a
href="https://doi.org/10.24963/ijcai.2022/226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Current semi-supervised semantic segmentation methods mainly focus on designing pixel-level consistency and contrastive regularization. However, pixel-level regularization is sensitive to noise from pixels with incorrect predictions, and pixel-level contrastive regularization has a large memory and computational cost. To address the issues, we propose a novel region-level contrastive and consistency learning framework (RC^2L) for semi-supervised semantic segmentation. Specifically, we first propose a Region Mask Contrastive (RMC) loss and a Region Feature Contrastive (RFC) loss to accomplish region-level contrastive property. Furthermore, Region Class Consistency (RCC) loss and Semantic Mask Consistency (SMC) loss are proposed for achieving region-level consistency. Based on the proposed region-level contrastive and consistency regularization, we develop a region-level contrastive and consistency learning framework (RC^2L) for semi-supervised semantic segmentation, and evaluate our RC^2L on two challenging benchmarks (PASCAL VOC 2012 and Cityscapes), outperforming the state-of-the-art. Keywords: Computer Vision: Segmentation Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Jianrong Zhang and Tianyi Wu and Chuanghao Ding and Hongwei Zhao and Guodong Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/226},
  pages     = {1622-1628},
  title     = {Region-level contrastive and consistency learning for semi-supervised semantic segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards universal backward-compatible representation
learning. <em>IJCAI</em>, 1615–1621. (<a
href="https://doi.org/10.24963/ijcai.2022/225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Conventional model upgrades for visual search systems require offline refresh of gallery features by feeding gallery images into new models (dubbed as “backfill”), which is time-consuming and expensive, especially in large-scale applications. The task of backward-compatible representation learning is therefore introduced to support backfill-free model upgrades, where the new query features are interoperable with the old gallery features. Despite the success, previous works only investigated a close-set training scenario (i.e., the new training set shares the same classes as the old one), and are limited by more realistic and challenging open-set scenarios. To this end, we first introduce a new problem of universal backward-compatible representation learning, covering all possible data split in model upgrades. We further propose a simple yet effective method, dubbed as Universal Backward-Compatible Training (UniBCT) with a novel structural prototype refinement algorithm, to learn compatible representations in all kinds of model upgrading benchmarks in a unified manner. Comprehensive experiments on the large-scale face recognition datasets MS1Mv3 and IJB-C fully demonstrate the effectiveness of our method. Source code is available at https://github.com/TencentARC/OpenCompatible. Keywords: Computer Vision: Representation Learning Computer Vision: Image and Video retrieval},
  archive   = {C_IJCAI},
  author    = {Binjie Zhang and Yixiao Ge and Yantao Shen and Shupeng Su and Fanzi Wu and Chun Yuan and Xuyuan Xu and Yexin Wang and Ying Shan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/225},
  pages     = {1615-1621},
  title     = {Towards universal backward-compatible representation learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). S2 transformer for image captioning. <em>IJCAI</em>,
1608–1614. (<a href="https://doi.org/10.24963/ijcai.2022/224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer-based architectures with grid features represent the state-of-the-art in visual and language reasoning tasks, such as visual question answering and image-text matching. However, directly applying them to image captioning may result in spatial and fine-grained semantic information loss. Their applicability to image captioning is still largely under-explored. Towards this goal, we propose a simple yet effective method, Spatial- and Scale-aware Transformer (S2 Transformer) for image captioning. Specifically, we firstly propose a Spatial-aware Pseudo-supervised (SP) module, which resorts to feature clustering to help preserve spatial information for grid features. Next, to maintain the model size and produce superior results, we build a simple weighted residual connection, named Scale-wise Reinforcement (SR) module, to simultaneously explore both low- and high-level encoded features with rich semantics. Extensive experiments on the MSCOCO benchmark demonstrate that our method achieves new state-of-art performance without bringing excessive parameters compared with the vanilla transformer. The source code is available at https://github.com/zchoi/S2-Transformer Keywords: Computer Vision: Vision and language Computer Vision: Visual reasoning and symbolic representation},
  archive   = {C_IJCAI},
  author    = {Pengpeng Zeng and Haonan Zhang and Jingkuan Song and Lianli Gao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/224},
  pages     = {1608-1614},
  title     = {S2 transformer for image captioning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). To fold or not to fold: A necessary and sufficient condition
on batch-normalization layers folding. <em>IJCAI</em>, 1601–1607. (<a
href="https://doi.org/10.24963/ijcai.2022/223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Batch-Normalization (BN) layers have become fundamental components in the evermore complex deep neural network architectures. Such models require acceleration processes for deployment on edge devices. However, BN layers add computation bottlenecks due to the sequential operation processing: thus, a key, yet often overlooked component of the acceleration process is BN layers folding. In this paper, we demonstrate that the current BN folding approaches are suboptimal in terms of how many layers can be removed. We therefore provide a necessary and sufficient condition for BN folding and a corresponding optimal algorithm. The proposed approach systematically outperforms existing baselines and allows to dramatically reduce the inference time of deep neural networks. Keywords: Computer Vision: Machine Learning for Vision Machine Learning: Learning Sparse Models Machine Learning: Other},
  archive   = {C_IJCAI},
  author    = {Edouard Yvinec and Arnaud Dapogny and Kevin Bailly},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/223},
  pages     = {1601-1607},
  title     = {To fold or not to fold: A necessary and sufficient condition on batch-normalization layers folding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-proxy learning from an entropy optimization
perspective. <em>IJCAI</em>, 1594–1600. (<a
href="https://doi.org/10.24963/ijcai.2022/222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep Metric Learning, a task that learns a feature embedding space where semantically similar samples are located closer than dissimilar samples, is a cornerstone of many computer vision applications. Most of the existing proxy-based approaches usually exploit the global context via learning a single proxy for each training class, which struggles in capturing the complex non-uniform data distribution with different patterns. In this work, we present an easy-to-implement framework to effectively capture the local neighbor relationships via learning multiple proxies for each class that collectively approximate the intra-class distribution. In the context of large intra-class visual diversity, we revisit the entropy learning under the multi-proxy learning framework and provide a training routine that both minimizes the entropy of intra-class probability distribution and maximizes the entropy of inter-class probability distribution. In this way, our model is able to better capture the intra-class variations and smooth the inter-class differences and thus facilitates to extract more semantic feature representations for the downstream tasks. Extensive experimental results demonstrate that the proposed approach achieves competitive performances. Codes and an appendix are provided. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Image and Video retrieval Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Yunlong Yu and Dingyi Zhang and Yingming Li and Zhongfei Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/222},
  pages     = {1594-1600},
  title     = {Multi-proxy learning from an entropy optimization perspective},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to hash naturally sorts. <em>IJCAI</em>, 1587–1593.
(<a href="https://doi.org/10.24963/ijcai.2022/221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Learning to hash pictures a list-wise sorting problem. Its testing metrics, e.g., mean-average precision, count on a sorted candidate list ordered by pair-wise code similarity. However, scarcely does one train a deep hashing model with the sorted results end-to-end because of the non-differentiable nature of the sorting operation. This inconsistency in the objectives of training and test may lead to sub-optimal performance since the training loss often fails to reflect the actual retrieval metric. In this paper, we tackle this problem by introducing Naturally-Sorted Hashing (NSH). We sort the Hamming distances of samples&#39; hash codes and accordingly gather their latent representations for self-supervised training. Thanks to the recent advances in differentiable sorting approximations, the hash head receives gradients from the sorter so that the hash encoder can be optimized along with the training procedure. Additionally, we describe a novel Sorted Noise-Contrastive Estimation (SortedNCE) loss that selectively picks positive and negative samples for contrastive learning, which allows NSH to mine data semantic relations during training in an unsupervised manner. Our extensive experiments show the proposed NSH model significantly outperforms the existing unsupervised hashing methods on three benchmarked datasets. Keywords: Computer Vision: Image and Video retrieval Computer Vision: Representation Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Jiaguo Yu and Yuming Shen and Menghan Wang and Haofeng Zhang and Philip H.S. Torr},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/221},
  pages     = {1587-1593},
  title     = {Learning to hash naturally sorts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning sparse interpretable features for NAS scoring from
liver biopsy images. <em>IJCAI</em>, 1580–1586. (<a
href="https://doi.org/10.24963/ijcai.2022/220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Liver biopsy images play a key role in the diagnosis of global non-alcoholic fatty liver disease (NAFLD). The NAFLD activity score (NAS) on liver biopsy images grades the amount of histological findings that reflect the progression of NAFLD. However, liver biopsy image analysis remains a challenging task due to its complex tissue structures and sparse distribution of histological findings. In this paper, we propose a sparse interpretable feature learning method (SparseX) to efficiently estimate NAS scores. First, we introduce an interpretable spatial sampling strategy based on histological features to effectively select informative tissue regions containing tissue alterations. Then, SparseX formulates the feature learning as a low-rank decomposition problem. Non-negative matrix factorization (NMF)-based attributes learning is embedded into a deep network to compress and select sparse features for a small portion of tissue alterations contributing to diagnosis. Experiments conducted on the internal Liver-NAS and public SteatosisRaw datasets show the effectiveness of the proposed method in terms of classification performance and interpretability. regions containing tissue alterations. Then, SparseX formulates the feature learning as a low-rank decomposition problem. Non-negative matrix factorization (NMF)-based attributes learning is embedded into a deep network to compress and select sparse features for a small portion of tissue alterations contributing to diagnosis. Experiments conducted on the internal Liver-NAS and public SteatosisRaw datasets show the effectiveness of the proposed method in terms of classification performance and interpretability. Keywords: Computer Vision: Biomedical Image Analysis Computer Vision: Interpretability and Transparency Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Chong Yin and Siqi Liu and Vincent Wai-Sun Wong and Pong C Yuen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/220},
  pages     = {1580-1586},
  title     = {Learning sparse interpretable features for NAS scoring from liver biopsy images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RAPQ: Rescuing accuracy for power-of-two low-bit
post-training quantization. <em>IJCAI</em>, 1573–1579. (<a
href="https://doi.org/10.24963/ijcai.2022/219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a Power-of-Two post-training quantization( PTQ) method for deep neural network that meets hardware requirements and does not call for long-time retraining. PTQ requires a small set of calibration data and is easier for deployment, but results in lower accuracy than Quantization-Aware Training( QAT). Power-of-Two quantization can convert the multiplication introduced by quantization and dequantization to bit-shift that is adopted by many efficient accelerators. However, the Power-of-Two scale has fewer candidate values, which leads to more rounding or clipping errors. We propose a novel Power-of-Two PTQ framework, dubbed RAPQ, which dynamically adjusts the Power-of-Two scales of the whole network instead of statically determining them layer by layer. It can theoretically trade off the rounding error and clipping error of the whole network. Meanwhile, the reconstruction method in RAPQ is based on the BN information of every unit. Extensive experiments on ImageNet prove the excellent performance of our proposed method. Without bells and whistles, RAPQ can reach accuracy of 65\% and 48\% on ResNet-18 and MobileNetV2 respectively with weight INT2 activation INT4. We are the first to propose PTQ for the more constrained but hardware-friendly Power-of-Two quantization and prove that it can achieve nearly the same accuracy as SOTA PTQ method. The code will be released. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Recognition (object detection, categorization) Multidisciplinary Topics and Applications: AI Hardware},
  archive   = {C_IJCAI},
  author    = {Hongyi Yao and Pu Li and Jian Cao and Xiangcheng Liu and Chenying Xie and Bingzhang Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/219},
  pages     = {1573-1579},
  title     = {RAPQ: Rescuing accuracy for power-of-two low-bit post-training quantization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning implicit body representations from double diffusion
based neural radiance fields. <em>IJCAI</em>, 1566–1572. (<a
href="https://doi.org/10.24963/ijcai.2022/218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present a novel double diffusion based neural radiance field, dubbed DD-NeRF, to reconstruct human body geometry and render the human body appearance in novel views from a sparse set of images. We first propose a double diffusion mechanism to achieve expressive representations of input images by fully exploiting human body priors and image appearance details at two levels. At the coarse level, we first model the coarse human body poses and shapes via an unclothed 3D deformable vertex model as guidance. At the fine level, we present a multi-view sampling network to capture subtle geometric deformations and image detailed appearances, such as clothing and hair, from multiple input views. Considering the sparsity of the two level features, we diffuse them into feature volumes in the canonical space to construct neural radiance fields. Then, we present a signed distance function (SDF) regression network to construct body surfaces from the diffused features. Thanks to our double diffused representations, our method can even synthesize novel views of unseen subjects. Experiments on various datasets demonstrate that our approach outperforms the state-of-the-art in both geometric reconstruction and novel view synthesis. Keywords: Computer Vision: 3D Computer Vision Computer Vision: Applications Computer Vision: Neural generative models, auto encoders, GANs},
  archive   = {C_IJCAI},
  author    = {Guangming Yao and Hongzhi Wu and Yi Yuan and Lincheng Li and Kun Zhou and Xin Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/218},
  pages     = {1566-1572},
  title     = {Learning implicit body representations from double diffusion based neural radiance fields},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning prototype via placeholder for zero-shot
recognition. <em>IJCAI</em>, 1559–1565. (<a
href="https://doi.org/10.24963/ijcai.2022/217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Zero-shot learning (ZSL) aims to recognize unseen classes by exploiting semantic descriptions shared between seen classes and unseen classes. Current methods show that it is effective to learn visual-semantic alignment by projecting semantic embeddings into the visual space as class prototypes. However, such a projection function is only concerned with seen classes. When applied to unseen classes, the prototypes often perform suboptimally due to domain shift. In this paper, we propose to learn prototypes via placeholders, termed LPL, to eliminate the domain shift between seen and unseen classes. Specifically, we combine seen classes to hallucinate new classes which play as placeholders of the unseen classes in the visual and semantic space. Placed between seen classes, the placeholders encourage prototypes of seen classes to be highly dispersed. And more space is spared for the insertion of well-separated unseen ones. Empirically, well-separated prototypes help counteract visual-semantic misalignment caused by domain shift. Furthermore, we exploit a novel semantic-oriented fine-tuning method to guarantee the semantic reliability of placeholders. Extensive experiments on five benchmark datasets demonstrate the significant performance gain of LPL over the state-of-the-art methods. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Recognition (object detection, categorization) Computer Vision: Representation Learning Computer Vision: Vision and language},
  archive   = {C_IJCAI},
  author    = {Zaiquan Yang and Yang Liu and Wenjia Xu and Chong Huang and Lei Zhou and Chao Tong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/217},
  pages     = {1559-1565},
  title     = {Learning prototype via placeholder for zero-shot recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Entity-aware and motion-aware transformers for
language-driven action localization. <em>IJCAI</em>, 1552–1558. (<a
href="https://doi.org/10.24963/ijcai.2022/216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Language-driven action localization in videos is a challenging task that involves not only visual-linguistic matching but also action boundary prediction. Recent progress has been achieved through aligning language queries to video segments, but estimating precise boundaries is still under-explored. In this paper, we propose entity-aware and motion-aware Transformers that progressively localize actions in videos by first coarsely locating clips with entity queries and then finely predicting exact boundaries in a shrunken temporal region with motion queries. The entity-aware Transformer incorporates the textual entities into visual representation learning via cross-modal and cross-frame attentions to facilitate attending action-related video clips. The motion-aware Transformer captures fine-grained motion changes at multiple temporal scales via integrating long short-term memory into the self-attention module to further improve the precision of action boundary prediction. Extensive experiments on the Charades-STA and TACoS datasets demonstrate that our method achieves better performance than existing methods. Keywords: Computer Vision: Vision and language Computer Vision: Image and Video retrieval Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Shuo Yang and Xinxiao Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/216},
  pages     = {1552-1558},
  title     = {Entity-aware and motion-aware transformers for language-driven action localization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CrowdFormer: An overlap patching vision transformer for
top-down crowd counting. <em>IJCAI</em>, 1545–1551. (<a
href="https://doi.org/10.24963/ijcai.2022/215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Crowd counting methods typically predict a density map as an intermediate representation of counting, and achieve good performance. However, due to the perspective phenomenon, there is a scale variation in real scenes, which causes the density map-based methods suffer from a severe scene generalization problem because only a limited number of scales are fitted in density map prediction and generation. To address this issue, we propose a novel vision transformer network, i.e., CrowdFormer, and a density kernels fusion framework for more accurate density map estimation and generation, respectively. Thereafter, we incorporate these two innovations into an adaptive learning system, which can take both the annotation dot map and original image as input, and jointly learns the density map estimator and generator within an end-to-end framework. The experimental results demonstrate that the proposed model achieves the state-of-the-art in the terms of MAE and MSE (e.g., it achieved a MAE of 67.1 and MSE of 301.6 on NWPU-Crowd dataset.), and confirm the effectiveness of the proposed two designs. The code is https://github.com/special-yang/Top_Down-CrowdCounting. Keywords: Computer Vision: Scene analysis and understanding Computer Vision: Machine Learning for Vision Computer Vision: Recognition (object detection, categorization) Computer Vision: Representation Learning Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Shaopeng Yang and Weiyu Guo and Yuheng Ren},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/215},
  pages     = {1545-1551},
  title     = {CrowdFormer: An overlap patching vision transformer for top-down crowd counting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Perceptual learned video compression with recurrent
conditional GAN. <em>IJCAI</em>, 1537–1544. (<a
href="https://doi.org/10.24963/ijcai.2022/214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper proposes a Perceptual Learned Video Compression (PLVC) approach with recurrent conditional GAN. We employ the recurrent auto-encoder-based compression network as the generator, and most importantly, we propose a recurrent conditional discriminator, which judges raw vs. compressed video conditioned on both spatial and temporal features, including the latent representation, temporal motion and hidden states in recurrent cells. This way, the adversarial training pushes the generated video to be not only spatially photo-realistic but also temporally consistent with the groundtruth and coherent among video frames. The experimental results show that the learned PLVC model compresses video with good perceptual quality at low bit-rate, and that it outperforms the official HEVC test model (HM 16.20) and the existing learned video compression approaches for several perceptual quality metrics and user studies. The project page is available at https://github.com/RenYang-home/PLVC. Keywords: Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Ren Yang and Radu Timofte and Luc Van Gool},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/214},
  pages     = {1537-1544},
  title     = {Perceptual learned video compression with recurrent conditional GAN},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-level consistency learning for semi-supervised domain
adaptation. <em>IJCAI</em>, 1530–1536. (<a
href="https://doi.org/10.24963/ijcai.2022/213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-supervised domain adaptation (SSDA) aims to apply knowledge learned from a fully labeled source domain to a scarcely labeled target domain. In this paper, we propose a Multi-level Consistency Learning (MCL) framework for SSDA. Specifically, our MCL regularizes the consistency of different views of target domain samples at three levels: (i) at inter-domain level, we robustly and accurately align the source and target domains using a prototype-based optimal transport method that utilizes the pros and cons of different views of target samples; (ii) at intra-domain level, we facilitate the learning of both discriminative and compact target feature representations by proposing a novel class-wise contrastive clustering loss; (iii) at sample level, we follow standard practice and improve the prediction accuracy by conducting a consistency-based self-training. Empirically, we verified the effectiveness of our MCL framework on three popular SSDA benchmarks, i.e., VisDA2017, DomainNet, and Office-Home datasets, and the experimental results demonstrate that our MCL framework achieves the state-of-the-art performance. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Zizheng Yan and Yushuang Wu and Guanbin Li and Yipeng Qin and Xiaoguang Han and Shuguang Cui},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/213},
  pages     = {1530-1536},
  title     = {Multi-level consistency learning for semi-supervised domain adaptation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Weakening the influence of clothing: Universal clothing
attribute disentanglement for person re-identification. <em>IJCAI</em>,
1523–1529. (<a href="https://doi.org/10.24963/ijcai.2022/212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Most existing Re-ID studies focus on the short-term cloth-consistent setting and thus dominate by the visual appearance of clothing. However, the same person would wear different clothes and different people would wear the same clothes in reality, which invalidates these methods. To tackle the challenge of clothes change, we propose a Universal Clothing Attribute Disentanglement network (UCAD) which can effectively weaken the influence of clothing (identity-unrelated) and force the model to learn identity-related features that are unrelated to the worn clothing. For further study of Re-ID in cloth-changing scenarios, we construct a large-scale dataset called CSCC with the following unique features: (1) Severe: A large number of people have cloth-changing over four seasons. (2) High definition: The resolution of the cameras ranges from 1920×1080 to 3840×2160, which ensures that the recorded people are clear. Furthermore, we provide two variants of CSCC considering different degrees of cloth-changing, namely moderate and severe, so that researchers can effectively evaluate their models from various aspects. Experiments on several cloth-changing datasets including our CSCC and short-term dataset Market-1501 prove the superiority of UCAD. The dataset is available at https://github.com/yomin-y/UCAD. Keywords: Computer Vision: Image and Video retrieval Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Yuming Yan and Huimin Yu and Shuzhao Li and Zhaohui Lu and Jianfeng He and Haozhuo Zhang and Runfa Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/212},
  pages     = {1523-1529},
  title     = {Weakening the influence of clothing: Universal clothing attribute disentanglement for person re-identification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Towards adversarially robust deep image denoising.
<em>IJCAI</em>, 1516–1522. (<a
href="https://doi.org/10.24963/ijcai.2022/211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This work systematically investigates the adversarial robustness of deep image denoisers (DIDs), i.e, how well DIDs can recover the ground truth from noisy observations degraded by adversarial perturbations. Firstly, to evaluate DIDs’ robustness, we propose a novel adversarial attack, namely Observation-based Zero-mean Attack (OBSATK), to craft adversarial zero-mean perturbations on given noisy images. We find that existing DIDs are vulnerable to the adversarial noise generated by OBSATK. Secondly, to robustify DIDs, we pro- pose an adversarial training strategy, hybrid adversarial training (HAT), that jointly trains DIDs with adversarial and non-adversarial noisy data to ensure that the reconstruction quality is high and the denoisers around non-adversarial data are locally smooth. The resultant DIDs can effectively remove various types of synthetic and adversarial noise. We also uncover that the robustness of DIDs benefits their generalization capability on unseen real-world noise. Indeed, HAT-trained DIDs can recover high-quality clean images from real-world noise even without training on real noisy data. Extensive experiments on benchmark datasets, including Set68, PolyU, and SIDD, corroborate the effectiveness of OBSATK and HAT. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods AI Ethics, Trust, Fairness: Safety &amp; Robustness AI Ethics, Trust, Fairness: Trustworthy AI Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Hanshu Yan and Jingfeng Zhang and Jiashi Feng and Masashi Sugiyama and Vincent Y. F. Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/211},
  pages     = {1516-1522},
  title     = {Towards adversarially robust deep image denoising},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BiCo-net: Regress globally, match locally for robust 6D pose
estimation. <em>IJCAI</em>, 1509–1515. (<a
href="https://doi.org/10.24963/ijcai.2022/210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The challenges of learning a robust 6D pose function lie in 1) severe occlusion and 2) systematic noises in depth images. Inspired by the success of point-pair features, the goal of this paper is to recover the 6D pose of an object instance segmented from RGB-D images by locally matching pairs of oriented points between the model and camera space. To this end, we propose a novel Bi-directional Correspondence Mapping Network (BiCo-Net) to first generate point clouds guided by a typical pose regression, which can thus incorporate pose-sensitive information to optimize generation of local coordinates and their normal vectors. As pose predictions via geometric computation only rely on one single pair of local oriented points, our BiCo-Net can achieve robustness against sparse and occluded point clouds. An ensemble of redundant pose predictions from locally matching and direct pose regression further refines final pose output against noisy observations. Experimental results on three popularly benchmarking datasets can verify that our method can achieve state-of-the-art performance, especially for the more challenging severe occluded scenes. Source codes are available at https://github.com/Gorilla-Lab-SCUT/BiCo-Net. Keywords: Computer Vision: 3D Computer Vision Robotics: Perception},
  archive   = {C_IJCAI},
  author    = {Zelin Xu and Yichen Zhang and Ke Chen and Kui Jia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/210},
  pages     = {1509-1515},
  title     = {BiCo-net: Regress globally, match locally for robust 6D pose estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Webly-supervised fine-grained recognition with partial label
learning. <em>IJCAI</em>, 1502–1508. (<a
href="https://doi.org/10.24963/ijcai.2022/209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The task of webly-supervised fine-grained recognition is to boost recognition accuracy of classifying subordinate categories (e.g., different bird species) by utilizing freely available but noisy web data. As the label noises significantly hurt the network training, it is desirable to distinguish and eliminate noisy images. In this paper, we propose two strategies, i.e., open-set noise removal and closed-set noise correction, to both remove such two kinds of web noises w.r.t. fine-grained recognition. Specifically, for open-set noise removal, we utilize a pre-trained deep model to perform deep descriptor transformation to estimate the positive correlation between these web images, and detect the open-set noises based on the correlation values. Regarding closed-set noise correction, we develop a top-k recall optimization loss for firstly assigning a label set towards each web image to reduce the impact of hard label assignment for closed-set noises. Then, we further propose to correct the sample with its label set as the true single label from a partial label learning perspective. Experiments on several webly-supervised fine-grained benchmark datasets show that our method obviously outperforms other existing state-of-the-art methods. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Machine Learning for Vision Computer Vision: Representation Learning Machine Learning: Multi-label Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Yu-Yan Xu and Yang Shen and Xiu-Shen Wei and Jian Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/209},
  pages     = {1502-1508},
  title     = {Webly-supervised fine-grained recognition with partial label learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boosting multi-label image classification with complementary
parallel self-distillation. <em>IJCAI</em>, 1495–1501. (<a
href="https://doi.org/10.24963/ijcai.2022/208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-Label Image Classification (MLIC) appro-aches usually exploit label correlations to achieve good performance. However, emphasizing correlation like co-occurrence may overlook discriminative features and lead to model overfitting. In this study, we propose a generic framework named Parallel Self-Distillation (PSD) for boosting MLIC models. PSD decomposes the original MLIC task into several simpler MLIC sub-tasks via two elaborated complementary task decomposition strategies named Co-occurrence Graph Partition (CGP) and Dis-occurrence Graph Partition (DGP). Then, the MLIC models of fewer categories are trained with these sub-tasks in parallel for respectively learning the joint patterns and the category-specific patterns of labels. Finally, knowledge distillation is leveraged to learn a compact global ensemble of full categories with these learned patterns for reconciling the label correlation exploitation and model overfitting. Extensive results on MS-COCO and NUS-WIDE datasets demonstrate that our framework can be easily plugged into many MLIC approaches and improve performances of recent state-of-the-art approaches. The source code is released at https://github.com/Robbie-Xu/CPSD. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Machine Learning for Vision Machine Learning: Multi-label},
  archive   = {C_IJCAI},
  author    = {Jiazhi Xu and Sheng Huang and Fengtao Zhou and Luwen Huangfu and Daniel Zeng and Bo Liu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/208},
  pages     = {1495-1501},
  title     = {Boosting multi-label image classification with complementary parallel self-distillation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SCMT: Self-correction mean teacher for semi-supervised
object detection. <em>IJCAI</em>, 1488–1494. (<a
href="https://doi.org/10.24963/ijcai.2022/207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semi-Supervised Object Detection (SSOD) aims to improve performance by leveraging a large amount of unlabeled data. Existing works usually adopt the teacher-student framework to enforce student to learn consistent predictions over the pseudo-labels generated by teacher. However, the performance of the student model is limited since the noise inherently exists in pseudo-labels. In this paper, we investigate the causes and effects of noisy pseudo-labels and propose a simple yet effective approach denoted as Self-Correction Mean Teacher(SCMT) to reduce the adverse effects. Specifically, we propose to dynamically re-weight the unsupervised loss of each student&#39;s proposal with additional supervision information from the teacher model, and assign smaller loss weights to possible noisy proposals. Extensive experiments on MS-COCO benchmark have shown the superiority of our proposed SCMT, which can significantly improve the supervised baseline by more than 11\% mAP under all 1\%, 5\% and 10\% COCO-standard settings, and surpasses state-of-the-art methods by about 1.5\% mAP. Even under the challenging COCO-additional setting, SCMT still improves the supervised baseline by 4.9\% mAP, and significantly outperforms previous methods by 1.2\% mAP, achieving a new state-of-the-art performance. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Feng Xiong and Jiayi Tian and Zhihui Hao and Yulin He and Xiaofeng Ren},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/207},
  pages     = {1488-1494},
  title     = {SCMT: Self-correction mean teacher for semi-supervised object detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Eliminating backdoor triggers for deep neural networks using
attention relation graph distillation. <em>IJCAI</em>, 1481–1487. (<a
href="https://doi.org/10.24963/ijcai.2022/206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Due to the prosperity of Artificial Intelligence (AI) techniques, more and more backdoors are designed by adversaries to attack Deep Neural Networks (DNNs). Although the state-of-the-art method Neural Attention Distillation (NAD) can effectively erase backdoor triggers from DNNs, it still suffers from non-negligible Attack Success Rate (ASR) together with lowered classification ACCuracy (ACC), since NAD focuses on backdoor defense using attention features (i.e., attention maps) of the same order. In this paper, we introduce a novel backdoor defense framework named Attention Relation Graph Distillation (ARGD), which fully explores the correlation among attention features with different orders using our proposed Attention Relation Graphs (ARGs). Based on the alignment of ARGs between teacher and student models during knowledge distillation, ARGD can more effectively eradicate backdoors than NAD. Comprehensive experimental results show that, against six latest backdoor attacks, ARGD outperforms NAD by up to 94.85\% reduction in ASR, while ACC can be improved by up to 3.23\%. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Machine Learning: Adversarial Machine Learning Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Jun Xia and Ting Wang and Jiepin Ding and Xian Wei and Mingsong Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/206},
  pages     = {1481-1487},
  title     = {Eliminating backdoor triggers for deep neural networks using attention relation graph distillation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A decoder-free transformer-like architecture for
high-efficiency single image deraining. <em>IJCAI</em>, 1474–1480. (<a
href="https://doi.org/10.24963/ijcai.2022/205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the success of vision Transformers for the image deraining task, they are limited by computation-heavy and slow runtime. In this work, we investigate Transformer decoder is not necessary and has huge computational costs. Therefore, we revisit the standard vision Transformer as well as its successful variants and propose a novel Decoder-Free Transformer-Like (DFTL) architecture for fast and accurate single image deraining. Specifically, we adopt a cheap linear projection to represent visual information with lower computational costs than previous linear projections. Then we replace standard Transformer decoder block with designed Progressive Patch Merging (PPM), which attains comparable performance and efficiency. DFTL could significantly alleviate the computation and GPU memory requirements through proposed modules. Extensive experiments demonstrate the superiority of DFTL compared with competitive Transformer architectures, e.g., ViT, DETR, IPT, Uformer, and Restormer. The code is available at https://github.com/XiaoXiao-Woo/derain. Keywords: Computer Vision: Machine Learning for Vision Machine Learning: Applications Machine Learning: Convolutional Networks Machine Learning: Other},
  archive   = {C_IJCAI},
  author    = {Xiao Wu and Ting-Zhu Huang and Liang-Jian Deng and Tian-Jing Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/205},
  pages     = {1474-1480},
  title     = {A decoder-free transformer-like architecture for high-efficiency single image deraining},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-scale spatial representation learning via recursive
hermite polynomial networks. <em>IJCAI</em>, 1465–1473. (<a
href="https://doi.org/10.24963/ijcai.2022/204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-scale representation learning aims to leverage diverse features from different layers of Convolutional Neural Networks (CNNs) for boosting the feature robustness to scale variance. For dense prediction tasks, two key properties should be satisfied: the high spatial variance across convolutional layers, and the sub-scale granularity inside a convolutional layer for fine-grained features. To pursue the two properties, this paper proposes Recursive Hermite Polynomial Networks (RHP-Nets for short). The proposed RHP-Nets consist of two major components: 1) a dilated convolution to maintain the spatial resolution across layers, and 2) a family of Hermite polynomials over a subset of dilated grids, which recursively constructs sub-scale representations to avoid the artifacts caused by naively applying the dilation convolution. The resultant sub-scale granular features are fused via trainable Hermite coefficients to form the multi-resolution representations that can be fed into the next deeper layer, and thus allowing feature interchanging at all levels. Extensive experiments are conducted to demonstrate the efficacy of our design, and reveal its superiority over state-of-the-art alternatives on a variety of image recognition tasks. Besides, introspective studies are provided to further understand the properties of our method. Keywords: Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Lin (Yuanbo) Wu and Deyin Liu and Xiaojie Guo and Richang Hong and Liangchen Liu and Rui Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/204},
  pages     = {1465-1473},
  title     = {Multi-scale spatial representation learning via recursive hermite polynomial networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Corner affinity: A robust grouping algorithm to make
corner-guided detector great again. <em>IJCAI</em>, 1458–1464. (<a
href="https://doi.org/10.24963/ijcai.2022/203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Corner-guided detector enjoys potential ability to yield precise bounding boxes. However, unreliable corner pairs, generated by heuristic grouping guidance, hinder the development of this detector. In this paper, we propose a novel corner grouping algorithm, termed as Corner Affinity, to significantly boost the reliability and robustness of corner grouping. The proposed Corner Affinity is a couple of two interactional factors, namely, 1) the structure affinity (SA), applying to generate preliminary corner pairs through the corresponding object&#39;s shallow construction information. 2) the contexts affinity (CA), running as optimizing corner pairs via embedding deeper semantic features of affiliated instances. Equipped with the Corner Affinity, a detector can produce high-quality bounding boxes upon preferable paired corner keypoints. Experimental results show the superiority of our design on multiple benchmark datasets. Specifically, for CornerNet baseline, the proposed Corner Affinity brings AP boostings of 5.8\% on COCO, 35.8\% on Citypersons, and 17.2\% on UCAS-AOD without bells and whistles. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Haoran Wei and Chenglong Liu and Ping Guo and Yangguang Zhu and Jiamei Fu and Bing Wang and Peng Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/203},
  pages     = {1458-1464},
  title     = {Corner affinity: A robust grouping algorithm to make corner-guided detector great again},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CARD: Semi-supervised semantic segmentation via
class-agnostic relation based denoising. <em>IJCAI</em>, 1451–1457. (<a
href="https://doi.org/10.24963/ijcai.2022/202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent semi-supervised semantic segmentation methods focus on mining extra supervision from unlabeled data by generating pseudo labels. However, noisy labels are inevitable in this process which prevent effective self-supervision. This paper proposes that noisy labels can be corrected based on semantic connections among features. Since a segmentation classifier produces both high and low-quality predictions, we can trace back to feature encoder to investigate how a feature in a noisy group is related to those in the confident groups. Discarding the weak predictions from the classifier, rectified predictions are assigned to the wrongly predicted features through the feature relations. The key to such an idea lies in mining reliable feature connections. With this goal, we propose a class-agnostic relation network to precisely capture semantic connections among features while ignoring their semantic categories. The feature relations enable us to perform effective noisy label corrections to boost self-training performance. Extensive experiments on PASCAL VOC and Cityscapes demonstrate the state-of-the-art performances of the proposed methods under various semi-supervised settings. Keywords: Computer Vision: Segmentation Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Xiaoyang Wang and Jimin Xiao and Bingfeng Zhang and Limin Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/202},
  pages     = {1451-1457},
  title     = {CARD: Semi-supervised semantic segmentation via class-agnostic relation based denoising},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty-guided pixel contrastive learning for
semi-supervised medical image segmentation. <em>IJCAI</em>, 1444–1450.
(<a href="https://doi.org/10.24963/ijcai.2022/201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, contrastive learning has shown great potential in medical image segmentation. Due to the lack of expert annotations, however, it is challenging to apply contrastive learning in semi-supervised scenes. To solve this problem, we propose a novel uncertainty-guided pixel contrastive learning method for semi-supervised medical image segmentation. Specifically, we construct an uncertainty map for each unlabeled image and then remove the uncertainty region in the uncertainty map to reduce the possibility of noise sampling. The uncertainty map is determined by a well-designed consistency learning mechanism, which generates comprehensive predictions for unlabeled data by encouraging consistent network outputs from two different decoders. In addition, we suggest that the effective global representations learned by an image encoder should be equivariant to different geometric transformations. To this end, we construct an equivariant contrastive loss to strengthen global representation learning ability of the encoder. Extensive experiments conducted on popular medical image benchmarks demonstrate that the proposed method achieves better segmentation performance than the state-of-the-art methods. Keywords: Computer Vision: Segmentation Computer Vision: Biomedical Image Analysis Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Tao Wang and Jianglin Lu and Zhihui Lai and Jiajun Wen and Heng Kong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/201},
  pages     = {1444-1450},
  title     = {Uncertainty-guided pixel contrastive learning for semi-supervised medical image segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RePre: Improving self-supervised vision transformer with
reconstructive pre-training. <em>IJCAI</em>, 1437–1443. (<a
href="https://doi.org/10.24963/ijcai.2022/200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, self-supervised vision transformers have attracted unprecedented attention for their impressive representation learning ability. However, the dominant method, contrastive learning, mainly relies on an instance discrimination pretext task, which learns a global understanding of the image. This paper incorporates local feature learning into self-supervised vision transformers via Reconstructive Pre-training (RePre). Our RePre extends contrastive frameworks by adding a branch for reconstructing raw image pixels in parallel with the existing contrastive objective. RePre equips with a lightweight convolution-based decoder that fuses the multi-hierarchy features from the transformer encoder. The multi-hierarchy features provide rich supervisions from low to high semantic information, crucial for our RePre. Our RePre brings decent improvements on various contrastive frameworks with different vision transformer architectures. Transfer performance in downstream tasks outperforms supervised pre-training and state-of-the-art (SOTA) self-supervised counterparts. Keywords: Computer Vision: Representation Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Luya Wang and Feng Liang and Yangguang Li and Honggang Zhang and Wanli Ouyang and Jing Shao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/200},
  pages     = {1437-1443},
  title     = {RePre: Improving self-supervised vision transformer with reconstructive pre-training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Double-check soft teacher for semi-supervised object
detection. <em>IJCAI</em>, 1430–1436. (<a
href="https://doi.org/10.24963/ijcai.2022/199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the semi-supervised object detection task, due to the scarcity of labeled data and the diversity and complexity of objects to be detected, the quality of pseudo-labels generated by existing methods for unlabeled data is relatively low, which severely restricts the performance of semi-supervised object detection. In this paper, we revisit the pseudo-labeling based Teacher-Student mutual learning framework for semi-supervised object detection and identify that the inconsistency of the location and feature of the candidate object proposals between the Teacher and the Student branches are the fatal cause of the low quality of the pseudo labels. To address this issue, we propose a simple yet effective technique within the mainstream teacher-student framework, called Double Check Soft Teacher, to overcome the harm caused by insufficient quality of pseudo labels. Specifically, our proposed method leverages teacher model to generate pseudo labels for the student model. Especially, the candidate boxes generated by the student model based on the pseudo label will be sent to the teacher model for &quot;double check&quot;, and then the teacher model will output probabilistic soft label with background class for those candidate boxes, which will be used to train the student model. Together with a pseudo labeling mechanism based on the sum of the TOP-K prediction score, which improves the recall rate of pseudo labels, Double Check Soft Teacher consistently surpasses state-of-the-art methods by significant margins on the MS-COCO benchmark, pushing the new state-of-the-art. Source codes are available at https://github.com/wkfdb/DCST. Keywords: Computer Vision: Recognition (object detection, categorization) Machine Learning: Semi-Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Kuo Wang and Yuxiang Nie and Chaowei Fang and Chengzhi Han and Xuewen Wu and Xiaohui Wang Wang and Liang Lin and Fan Zhou and Guanbin Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/199},
  pages     = {1430-1436},
  title     = {Double-check soft teacher for semi-supervised object detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022b). PACE: Predictive and contrastive embedding for unsupervised
action segmentation. <em>IJCAI</em>, 1423–1429. (<a
href="https://doi.org/10.24963/ijcai.2022/198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Action segmentation, inferring temporal positions of human actions in an untrimmed video, is an important prerequisite for various video understanding tasks. Recently, unsupervised action segmentation (UAS) has emerged as a more challenging task due to the unavailability of frame-level annotations. Existing clustering- or prediction-based UAS approaches suffer from either over-segmentation or overfitting, leading to unsatisfactory results. To address those problems, we propose Predictive And Contrastive Embedding (PACE), a unified UAS framework leveraging both predictability and similarity information for more accurate action segmentation. On the basis of an auto-regressive transformer encoder, predictive embeddings are learned by exploiting the predictability of video context, while contrastive embeddings are generated by leveraging the similarity of adjacent short video clips. Extensive experiments on three challenging benchmarks demonstrate the superiority of our method, with up to 26.9\% improvements in F1-score over the state of the art. Keywords: Computer Vision: Video analysis and understanding Computer Vision: Action and Behaviour Recognition Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Jiahao Wang and Jie Qin and Yunhong Wang and Annan Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/198},
  pages     = {1423-1429},
  title     = {PACE: Predictive and contrastive embedding for unsupervised action segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I2CNet: An intra- and inter-class context information fusion
network for blastocyst segmentation. <em>IJCAI</em>, 1415–1422. (<a
href="https://doi.org/10.24963/ijcai.2022/197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The quality of a blastocyst directly determines the embryo&#39;s implantation potential, thus making it essential to objectively and accurately identify the blastocyst morphology. In this work, we propose an automatic framework named I2CNet to perform the blastocyst segmentation task in human embryo images. The I2CNet contains two components: IntrA-Class Context Module (IACCM) and InteR-Class Context Module (IRCCM). The IACCM aggregates the representations of specific areas sharing the same category for each pixel, where the categorized regions are learned under the supervision of the groundtruth. This aggregation decomposes a K-category recognition task into K recognition tasks of two labels while maintaining the ability of garnering intra-class features. In addition, the IRCCM is designed based on the blastocyst morphology to compensate for inter-class information which is gradually gathered from inside out. Meanwhile, a weighted mapping function is applied to facilitate edges of the inter classes and stimulate some hard samples. Eventually, the learned intra- and inter-class cues are integrated from coarse to fine, rendering sufficient information interaction and fusion between multi-scale features. Quantitative and qualitative experiments demonstrate that the superiority of our model compared with other representative methods. The I2CNet achieves accuracy of 94.14\% and Jaccard of 85.25\% on blastocyst public dataset. Keywords: Computer Vision: Biomedical Image Analysis Computer Vision: Segmentation Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Hua Wang and Linwei Qiu and Jingfei Hu and Jicong Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/197},
  pages     = {1415-1422},
  title     = {I2CNet: An intra- and inter-class context information fusion network for blastocyst segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KUNet: Imaging knowledge-inspired single HDR image
reconstruction. <em>IJCAI</em>, 1408–1414. (<a
href="https://doi.org/10.24963/ijcai.2022/196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, with the rise of high dynamic range (HDR) display devices, there is a great demand to transfer traditional low dynamic range (LDR) images into HDR versions. The key to success is how to solve the many-to-many mapping problem. However, the existing approaches either do not consider constraining solution space or just simply imitate the inverse camera imaging pipeline in stages, without directly formulating the HDR image generation process. In this work, we address this problem by integrating LDR-to-HDR imaging knowledge into an UNet architecture, dubbed as Knowledge-inspired UNet (KUNet). The conversion from LDR-to-HDR image is mathematically formulated, and can be conceptually divided into recovering missing details, adjusting imaging parameters and reducing imaging noise. Accordingly, we develop a basic knowledge-inspired block (KIB) including three subnetworks corresponding to the three procedures in this HDR imaging process. The KIB blocks are cascaded in the similar way to the UNet to construct HDR image with rich global information. In addition, we also propose a knowledge inspired jump-connect structure to fit a dynamic range gap between HDR and LDR images. Experimental results demonstrate that the proposed KUNet achieves superior performance compared with the state-of-the-art methods. The code, dataset and appendix materials are available at https://github.com/wanghu178/KUNet.git. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Applications Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Hu Wang and Mao Ye and Xiatian Zhu and Shuai Li and Ce Zhu and Xue Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/196},
  pages     = {1408-1414},
  title     = {KUNet: Imaging knowledge-inspired single HDR image reconstruction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Adaptive convolutional dictionary network for CT metal
artifact reduction. <em>IJCAI</em>, 1401–1407. (<a
href="https://doi.org/10.24963/ijcai.2022/195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Inspired by the great success of deep neural networks, learning-based methods have gained promising performances for metal artifact reduction (MAR) in computed tomography (CT) images. However, most of the existing approaches put less emphasis on modelling and embedding the intrinsic prior knowledge underlying this specific MAR task into their network designs. Against this issue, we propose an adaptive convolutional dictionary network (ACDNet), which leverages both model-based and learning-based methods. Specifically, we explore the prior structures of metal artifacts, e.g., non-local repetitive streaking patterns, and encode them as an explicit weighted convolutional dictionary model. Then, a simple-yet-effective algorithm is carefully designed to solve the model. By unfolding every iterative substep of the proposed algorithm into a network module, we explicitly embed the prior structure into a deep network , i.e., a clear interpretability for the MAR task. Furthermore, our ACDNet can automatically learn the prior for artifact-free CT images via training data and adaptively adjust the representation kernels for each input CT image based on its content. Hence, our method inherits the clear interpretability of model-based methods and maintains the powerful representation ability of learning-based methods. Comprehensive experiments executed on synthetic and clinical datasets show the superiority of our ACDNet in terms of effectiveness and model generalization. Code and supplementary material are available at https://github.com/hongwang01/ACDNet. Keywords: Computer Vision: Biomedical Image Analysis},
  archive   = {C_IJCAI},
  author    = {Hong Wang and Yuexiang Li and Deyu Meng and Yefeng Zheng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/195},
  pages     = {1401-1407},
  title     = {Adaptive convolutional dictionary network for CT metal artifact reduction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Spatiality-guided transformer for 3D dense captioning on
point clouds. <em>IJCAI</em>, 1393–1400. (<a
href="https://doi.org/10.24963/ijcai.2022/194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dense captioning in 3D point clouds is an emerging vision-and-language task involving object-level 3D scene understanding. Apart from coarse semantic class prediction and bounding box regression as in traditional 3D object detection, 3D dense captioning aims at producing a further and finer instance-level label of natural language description on visual appearance and spatial relations for each scene object of interest. To detect and describe objects in a scene, following the spirit of neural machine translation, we propose a transformer-based encoder-decoder architecture, namely SpaCap3D, to transform objects into descriptions, where we especially investigate the relative spatiality of objects in 3D scenes and design a spatiality-guided encoder via a token-to-token spatial relation learning objective and an object-centric decoder for precise and spatiality-enhanced object caption generation. Evaluated on two benchmark datasets, ScanRefer and ReferIt3D, our proposed SpaCap3D outperforms the baseline method Scan2Cap by 4.94\% and 9.61\% in CIDEr@0.5IoU, respectively. Our project page with source code and supplementary files is available at https://SpaCap3D.github.io/. Keywords: Computer Vision: 3D Computer Vision Computer Vision: Vision and language Computer Vision: Scene analysis and understanding Computer Vision: Machine Learning for Vision Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Heng Wang and Chaoyi Zhang and Jianhui Yu and Weidong Cai},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/194},
  pages     = {1393-1400},
  title     = {Spatiality-guided transformer for 3D dense captioning on point clouds},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Iterative few-shot semantic segmentation from image label
text. <em>IJCAI</em>, 1385–1392. (<a
href="https://doi.org/10.24963/ijcai.2022/193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot semantic segmentation aims to learn to segment unseen class objects with the guidance of only a few support images. Most previous methods rely on the pixel-level label of support images. In this paper, we focus on a more challenging setting, in which only the image-level labels are available. We propose a general framework to firstly generate coarse masks with the help of the powerful vision-language model CLIP, and then iteratively and mutually refine the mask predictions of support and query images. Extensive experiments on PASCAL-5i and COCO-20i datasets demonstrate that our method not only outperforms the state-of-the-art weakly supervised approaches by a significant margin, but also achieves comparable or better results to recent supervised methods. Moreover, our method owns an excellent generalization ability for the images in the wild and uncommon classes. Code will be available at https://github.com/Whileherham/IMR-HSNet. Keywords: Computer Vision: Segmentation Machine Learning: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Haohan Wang and Liang Liu and Wuhao Zhang and Jiangning Zhang and Zhenye Gan and Yabiao Wang and Chengjie Wang and Haoqian Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/193},
  pages     = {1385-1392},
  title     = {Iterative few-shot semantic segmentation from image label text},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Absolute wrong makes better: Boosting weakly supervised
object detection via negative deterministic information. <em>IJCAI</em>,
1378–1384. (<a href="https://doi.org/10.24963/ijcai.2022/192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Weakly supervised object detection (WSOD) is a challenging task, in which image-level labels (e.g., categories of the instances in the whole image) are used to train an object detector. Many existing methods follow the standard multiple instance learning (MIL) paradigm and have achieved promising performance. However, the lack of deterministic information leads to part domination and missing instances. To address these issues, this paper focuses on identifying and fully exploiting the deterministic information in WSOD. We discover that negative instances (i.e. absolutely wrong instances), ignored in most of the previous studies, normally contain valuable deterministic information. Based on this observation, we here propose a negative deterministic information (NDI) based method for improving WSOD, namely NDI-WSOD. Specifically, our method consists of two stages: NDI collecting and exploiting. In the collecting stage, we design several processes to identify and distill the NDI from negative instances online. In the exploiting stage, we utilize the extracted NDI to construct a novel negative contrastive learning mechanism and a negative guided instance selection strategy for dealing with the issues of part domination and missing instances, respectively. Experimental results on several public benchmarks including VOC 2007, VOC 2012 and MS COCO show that our method achieves satisfactory performance. Keywords: Computer Vision: Recognition (object detection, categorization) Machine Learning: Convolutional Networks Machine Learning: Multi-instance Machine Learning: Multi-label Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Guanchun Wang and Xiangrong Zhang and Zelin Peng and Xu Tang and Huiyu Zhou and Licheng Jiao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/192},
  pages     = {1378-1384},
  title     = {Absolute wrong makes better: Boosting weakly supervised object detection via negative deterministic information},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Augmenting anchors by the detector itself. <em>IJCAI</em>,
1371–1377. (<a href="https://doi.org/10.24963/ijcai.2022/191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Usually, it is difficult to determine the scale and aspect ratio of anchors for anchor-based object detection methods. Current state-of-the-art object detectors either determine anchor parameters according to objects&#39; shape and scale in a dataset, or avoid this problem by utilizing anchor-free methods, however, the former scheme is dataset-specific and the latter methods could not get better performance than the former ones. In this paper, we propose a novel anchor augmentation method named AADI, which means Augmenting Anchors by the Detector Itself. AADI is not an anchor-free method, instead, it can convert the scale and aspect ratio of anchors from a continuous space to a discrete space, which greatly alleviates the problem of anchors&#39; designation. Furthermore, AADI is a learning-based anchor augmentation method, but it does not add any parameters or hyper-parameters, which is beneficial for research and downstream tasks. Extensive experiments on COCO dataset demonstrate the effectiveness of AADI, specifically, AADI achieves significant performance boosts on many state-of-the-art object detectors (eg. at least +2.4 box AP on Faster R-CNN, +2.2 box AP on Mask R-CNN, and +0.9 box AP on Cascade Mask R-CNN). We hope that this simple and cost-efficient method can be widely used in object detection. Code and models are available at https://github.com/WanXiaopei/aadi. Keywords: Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Xiaopei Wan and Guoqiu Li and Yujiu Yang and Zhenhua Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/191},
  pages     = {1371-1377},
  title     = {Augmenting anchors by the detector itself},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automatic recognition of emotional subgroups in images.
<em>IJCAI</em>, 1363–1370. (<a
href="https://doi.org/10.24963/ijcai.2022/190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Both social group detection and group emotion recognition in images are growing fields of interest, but never before have they been combined. In this work we aim to detect emotional subgroups in images, which can be of great importance for crowd surveillance or event analysis. To this end, human annotators are instructed to label a set of 171 images, and their recognition strategies are analysed. Three main strategies for labeling images are identified, with each strategy assigning either 1) more weight to emotions (emotion-based fusion), 2) more weight to spatial structures (group-based fusion), or 3) equal weight to both (summation strategy). Based on these strategies, algorithms are developed to automatically recognize emotional subgroups. In particular, K-means and hierarchical clustering are used with location and emotion features derived from a fine-tuned VGG network. Additionally, we experiment with face size and gaze direction as extra input features. The best performance comes from hierarchical clustering with emotion, location and gaze direction as input. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Biometrics, Face, Gesture and Pose Recognition Machine Learning: Clustering Machine Learning: Classification Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Emmeke Veltmeijer and Charlotte Gerritsen and Koen Hindriks},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/190},
  pages     = {1363-1370},
  title     = {Automatic recognition of emotional subgroups in images},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Hypertron: Explicit social-temporal hypergraph framework for
multi-agent forecasting. <em>IJCAI</em>, 1356–1362. (<a
href="https://doi.org/10.24963/ijcai.2022/189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Forecasting the future trajectories of multiple agents is a core technology for human-robot interaction systems. To predict multi-agent trajectories more accurately, it is inevitable that models need to improve interpretability and reduce redundancy. However, many methods adopt implicit weight calculation or black-box networks to learn the semantic interaction of agents, which obviously lack enough interpretation. In addition, most of the existing works model the relation among all agents in a one-to-one manner, which might lead to irrational trajectory predictions due to its redundancy and noise. To address the above issues, we present Hypertron, a human-understandable and lightweight hypergraph-based multi-agent forecasting framework, to explicitly estimate the motions of multiple agents and generate reasonable trajectories. The framework explicitly interacts among multiple agents and learns their latent intentions by our coarse-to-fine hypergraph convolution interaction module. Our experiments on several challenging real-world trajectory forecasting datasets show that Hypertron outperforms a wide array of state-of-the-art methods while saving over 60\% parameters and reducing 30\% inference time. Keywords: Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Yu Tian and Xingliang Huang and Ruigang Niu and Hongfeng Yu and Peijin Wang and Xian Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/189},
  pages     = {1356-1362},
  title     = {Hypertron: Explicit social-temporal hypergraph framework for multi-agent forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Video frame interpolation based on deformable kernel region.
<em>IJCAI</em>, 1349–1355. (<a
href="https://doi.org/10.24963/ijcai.2022/188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video frame interpolation task has recently become more and more prevalent in the computer vision field. At present, a number of researches based on deep learning have achieved great success. Most of them are either based on optical flow information, or interpolation kernel, or a combination of these two methods. However, these methods have ignored that there are grid restrictions on the position of kernel region during synthesizing each target pixel. These limitations result in that they cannot well adapt to the irregularity of object shape and uncertainty of motion, which may lead to irrelevant reference pixels used for interpolation. In order to solve this problem, we revisit the deformable convolution for video interpolation, which can break the fixed grid restrictions on the kernel region, making the distribution of reference points more suitable for the shape of the object, and thus warp a more accurate interpolation frame. Experiments are conducted on four datasets to demonstrate the superior performance of the proposed model in comparison to the state-of-the-art alternatives. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Haoyue Tian and Pan Gao and Xiaojiang Peng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/188},
  pages     = {1349-1355},
  title     = {Video frame interpolation based on deformable kernel region},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic domain generalization. <em>IJCAI</em>, 1342–1348.
(<a href="https://doi.org/10.24963/ijcai.2022/187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization (DG) is a fundamental yet very challenging research topic in machine learning. The existing arts mainly focus on learning domain-invariant features with limited source domains in a static model. Unfortunately, there is a lack of training-free mechanism to adjust the model when generalized to the agnostic target domains. To tackle this problem, we develop a brand-new DG variant, namely Dynamic Domain Generalization (DDG), in which the model learns to twist the network parameters to adapt to the data from different domains. Specifically, we leverage a meta-adjuster to twist the network parameters based on the static model with respect to different data from different domains. In this way, the static model is optimized to learn domain-shared features, while the meta-adjuster is designed to learn domain-specific features. To enable this process, DomainMix is exploited to simulate data from diverse domains during teaching the meta-adjuster to adapt to the agnostic target domains. This learning mechanism urges the model to generalize to different agnostic target domains via adjusting the model without training. Extensive experiments demonstrate the effectiveness of our proposed method. Code is available: https://github.com/MetaVisionLab/DDG Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Zhishu Sun and Zhifeng Shen and Luojun Lin and Yuanlong Yu and Zhifeng Yang and Shicai Yang and Weijie Chen},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/187},
  pages     = {1342-1348},
  title     = {Dynamic domain generalization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Boundary-guided camouflaged object detection.
<em>IJCAI</em>, 1335–1341. (<a
href="https://doi.org/10.24963/ijcai.2022/186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Camouflaged object detection (COD), segmenting objects that are elegantly blended into their surroundings, is a valuable yet challenging task. Existing deep-learning methods often fall into the difficulty of accurately identifying the camouflaged object with complete and fine object structure. To this end, in this paper, we propose a novel boundary-guided network (BGNet) for camouflaged object detection. Our method explores valuable and extra object-related edge semantics to guide representation learning of COD, which forces the model to generate features that highlight object structure, thereby promoting camouflaged object detection of accurate boundary localization. Extensive experiments on three challenging benchmark datasets demonstrate that our BGNet significantly outperforms the existing 18 state-of-the-art methods under four widely-used evaluation metrics. Our code is publicly available at: https://github.com/thograce/BGNet. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Yujia Sun and Shuo Wang and Chenglizhao Chen and Tian-Zhu Xiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/186},
  pages     = {1335-1341},
  title     = {Boundary-guided camouflaged object detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Harnessing fourier isovists and geodesic interaction for
long-term crowd flow prediction. <em>IJCAI</em>, 1328–1334. (<a
href="https://doi.org/10.24963/ijcai.2022/185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the rise in popularity of short-term Human Trajectory Prediction (HTP), Long-Term Crowd Flow Prediction (LTCFP) has been proposed to forecast crowd movement in large and complex environments. However, the input representations, models, and datasets for LTCFP are currently limited. To this end, we propose Fourier Isovists, a novel input representation based on egocentric visibility, which consistently improves all existing models. We also propose GeoInteractNet (GINet), which couples the layers between a multi-scale attention network (M-SCAN) and a convolutional encoder-decoder network (CED). M-SCAN approximates a super-resolution map of where humans are likely to interact on the way to their goals and produces multi-scale attention maps. The CED then uses these maps in either its encoder&#39;s inputs or its decoder&#39;s attention gates, which allows GINet to produce super-resolution predictions with substantially higher accuracy than existing models even with Fourier Isovists. In order to evaluate the scalability of models to large and complex environments, which the only existing LTCFP dataset is unsuitable for, a new synthetic crowd dataset with both real and synthetic environments has been generated. In its nascent state, LTCFP has much to gain from our key contributions. The Supplementary Materials, dataset, and code are available at sssohn.github.io/GeoInteractNet. Keywords: Computer Vision: Applications Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Samuel S. Sohn and Seonghyeon Moon and Honglu Zhou and Mihee Lee and Sejong Yoon and Vladimir Pavlovic and Mubbasir Kapadia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/185},
  pages     = {1328-1334},
  title     = {Harnessing fourier isovists and geodesic interaction for long-term crowd flow prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Emotion-controllable generalized talking face generation.
<em>IJCAI</em>, 1320–1327. (<a
href="https://doi.org/10.24963/ijcai.2022/184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the significant progress in recent years, very few of the AI-based talking face generation methods attempt to render natural emotions. Moreover, the scope of the methods is majorly limited to the characteristics of the training dataset, hence they fail to generalize to arbitrary unseen faces. In this paper, we propose a one-shot facial geometry-aware emotional talking face generation method that can generalize to arbitrary faces. We propose a graph convolutional neural network that uses speech content feature, along with an independent emotion input to generate emotion and speech-induced motion on facial geometry-aware landmark representation. This representation is further used in our optical flow-guided texture generation network for producing the texture. We propose a two-branch texture generation network, with motion and texture branches designed to consider the motion and texture content independently. Compared to the previous emotion talking face methods, our method can adapt to arbitrary faces captured in-the-wild by fine-tuning with only a single image of the target identity in neutral emotion. Keywords: Computer Vision: Applications Computer Vision: Machine Learning for Vision Computer Vision: Neural generative models, auto encoders, GANs Humans and AI: Human-Computer Interaction Machine Learning: Applications},
  archive   = {C_IJCAI},
  author    = {Sanjana Sinha and Sandika Biswas and Ravindra Yadav and Brojeshwar Bhowmick},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/184},
  pages     = {1320-1327},
  title     = {Emotion-controllable generalized talking face generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A unified framework for adversarial attack and defense in
constrained feature space. <em>IJCAI</em>, 1313–1319. (<a
href="https://doi.org/10.24963/ijcai.2022/183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The generation of feasible adversarial examples is necessary for properly assessing models that work in constrained feature space. However, it remains a challenging task to enforce constraints into attacks that were designed for computer vision. We propose a unified framework to generate feasible adversarial examples that satisfy given domain constraints. Our framework can handle both linear and non-linear constraints. We instantiate our framework into two algorithms: a gradient-based attack that introduces constraints in the loss function to maximize, and a multi-objective search algorithm that aims for misclassification, perturbation minimization, and constraint satisfaction. We show that our approach is effective in four different domains, with a success rate of up to 100\%, where state-of-the-art attacks fail to generate a single feasible example. In addition to adversarial retraining, we propose to introduce engineered non-convex constraints to improve model adversarial robustness. We demonstrate that this new defense is as effective as adversarial retraining. Our framework forms the starting point for research on constrained adversarial attacks and provides relevant baselines and datasets that future research can exploit. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Constraint Satisfaction and Optimization: Constraints and Machine Learning Constraint Satisfaction and Optimization: Constraint Satisfaction Constraint Satisfaction and Optimization: Constraint Optimization Search: Evolutionary Computation},
  archive   = {C_IJCAI},
  author    = {Thibault Simonetto and Salijona Dyrmishi and Salah Ghamizi and Maxime Cordy and Yves Le Traon},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/183},
  pages     = {1313-1319},
  title     = {A unified framework for adversarial attack and defense in constrained feature space},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). IDPT: Interconnected dual pyramid transformer for face
super-resolution. <em>IJCAI</em>, 1306–1312. (<a
href="https://doi.org/10.24963/ijcai.2022/182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Face Super-resolution (FSR) task works for generating high-resolution (HR) face images from the corresponding low-resolution (LR) inputs, which has received a lot of attentions because of the wide application prospects. However, due to the diversity of facial texture and the difficulty of reconstructing detailed content from degraded images, FSR technology is still far away from being solved. In this paper, we propose a novel and effective face super-resolution framework based on Transformer, namely Interconnected Dual Pyramid Transformer (IDPT). Instead of straightly stacking cascaded feature reconstruction blocks, the proposed IDPT designs the pyramid encoder/decoder Transformer architecture to extract coarse and detailed facial textures respectively, while the relationship between the dual pyramid Transformers is further explored by a bottom pyramid feature extractor. The pyramid encoder/decoder structure is devised to adapt various characteristics of textures in different spatial spaces hierarchically. A novel fusing modulation module is inserted in each spatial layer to guide the refinement of detailed texture by the corresponding coarse texture, while fusing the shallow-layer coarse feature and corresponding deep-layer detailed feature simultaneously. Extensive experiments and visualizations on various datasets demonstrate the superiority of the proposed method for face super-resolution tasks. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Computational photography},
  archive   = {C_IJCAI},
  author    = {Jingang Shi and Yusi Wang and Songlin Dong and Xiaopeng Hong and Zitong Yu and Fei Wang and Changxin Wang and Yihong Gong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/182},
  pages     = {1306-1312},
  title     = {IDPT: Interconnected dual pyramid transformer for face super-resolution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ChimeraMix: Image classification on small datasets via
masked feature mixing. <em>IJCAI</em>, 1298–1305. (<a
href="https://doi.org/10.24963/ijcai.2022/181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep convolutional neural networks require large amounts of labeled data samples. For many real-world applications, this is a major limitation which is commonly treated by augmentation methods. In this work, we address the problem of learning deep neural networks on small datasets. Our proposed architecture called ChimeraMix learns a data augmentation by generating compositions of instances. The generative model encodes images in pairs, combines the features guided by a mask, and creates new samples. For evaluation, all methods are trained from scratch without any additional data. Several experiments on benchmark datasets, e.g. ciFAIR-10, STL-10, and ciFAIR-100, demonstrate the superior performance of ChimeraMix compared to current state-of-the-art methods for classification on small datasets. Code is available at https://github.com/creinders/ChimeraMix. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision Computer Vision: Neural generative models, auto encoders, GANs},
  archive   = {C_IJCAI},
  author    = {Christoph Reinders and Frederik Schubert and Bodo Rosenhahn},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/181},
  pages     = {1298-1305},
  title     = {ChimeraMix: Image classification on small datasets via masked feature mixing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SimMC: Simple masked contrastive learning of skeleton
representations for unsupervised person re-identification.
<em>IJCAI</em>, 1290–1297. (<a
href="https://doi.org/10.24963/ijcai.2022/180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in skeleton-based person re-identification (re-ID) obtain impressive performance via either hand-crafted skeleton descriptors or skeleton representation learning with deep learning paradigms. However, they typically require skeletal pre-modeling and label information for training, which leads to limited applicability of these methods. In this paper, we focus on unsupervised skeleton-based person re-ID, and present a generic Simple Masked Contrastive learning (SimMC) framework to learn effective representations from unlabeled 3D skeletons for person re-ID. Specifically, to fully exploit skeleton features within each skeleton sequence, we first devise a masked prototype contrastive learning (MPC) scheme to cluster the most typical skeleton features (skeleton prototypes) from different subsequences randomly masked from raw sequences, and contrast the inherent similarity between skeleton features and different prototypes to learn discriminative skeleton representations without using any label. Then, considering that different subsequences within the same sequence usually enjoy strong correlations due to the nature of motion continuity, we propose the masked intra-sequence contrastive learning (MIC) to capture intra-sequence pattern consistency between subsequences, so as to encourage learning more effective skeleton representations for person re-ID. Extensive experiments validate that the proposed SimMC outperforms most state-of-the-art skeleton-based methods. We further show its scalability and efficiency in enhancing the performance of existing models. Our codes are available at https://github.com/Kali-Hac/SimMC. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Other},
  archive   = {C_IJCAI},
  author    = {Haocong Rao and Chunyan Miao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/180},
  pages     = {1290-1297},
  title     = {SimMC: Simple masked contrastive learning of skeleton representations for unsupervised person re-identification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Source-adaptive discriminative kernels based network for
remote sensing pansharpening. <em>IJCAI</em>, 1283–1289. (<a
href="https://doi.org/10.24963/ijcai.2022/179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For the pansharpening problem, previous convolutional neural networks (CNNs) mainly concatenate high-resolution panchromatic (PAN) images and low-resolution multispectral (LR-MS) images in their architectures, which ignores the distinctive attributes of different sources. In this paper, we propose a convolution network with source-adaptive discriminative kernels, called ADKNet, for the pansharpening task. Those kernels consist of spatial kernels generated from PAN images containing rich spatial details and spectral kernels generated from LR-MS images containing abundant spectral information. The kernel generating process is specially designed to extract information discriminately and effectively. Furthermore, the kernels are learned in a pixel-by-pixel manner to characterize different information in distinct areas. Extensive experimental results indicate that ADKNet outperforms current state-of-the-art (SOTA) pansharpening methods in both quantitative and qualitative assessments, in the meanwhile only with about 60, 000 network parameters. Also, the proposed network is extended to the hyperspectral image super-resolution (HSISR) problem, still yields SOTA performance, proving the universality of our model. The code is available at http://github.com/liangjiandeng/ADKNet. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Applications Constraint Satisfaction and Optimization: Applications Machine Learning: Applications Machine Learning: Hyperparameter Optimization},
  archive   = {C_IJCAI},
  author    = {Siran Peng and Liang-Jian Deng and Jin-Fan Hu and Yuwei Zhuo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/179},
  pages     = {1283-1289},
  title     = {Source-adaptive discriminative kernels based network for remote sensing pansharpening},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multilevel hierarchical network with multiscale sampling for
video question answering. <em>IJCAI</em>, 1276–1282. (<a
href="https://doi.org/10.24963/ijcai.2022/178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video question answering (VideoQA) is challenging given its multimodal combination of visual understanding and natural language processing. While most existing approaches ignore the visual appearance-motion information at different temporal scales, it is unknown how to incorporate the multilevel processing capacity of a deep learning model with such multiscale information. Targeting these issues, this paper proposes a novel Multilevel Hierarchical Network (MHN) with multiscale sampling for VideoQA. MHN comprises two modules, namely Recurrent Multimodal Interaction (RMI) and Parallel Visual Reasoning (PVR). With a multiscale sampling, RMI iterates the interaction of appearance-motion information at each scale and the question embeddings to build the multilevel question-guided visual representations. Thereon, with a shared transformer encoder, PVR infers the visual cues at each level in parallel to fit with answering different question types that may rely on the visual information at relevant levels. Through extensive experiments on three VideoQA datasets, we demonstrate improved performances than previous state-of-the-arts and justify the effectiveness of each part of our method. Keywords: Computer Vision: Vision and language Computer Vision: Scene analysis and understanding Computer Vision: Video analysis and understanding Machine Learning: Multi-modal learning Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Min Peng and Chongyang Wang and Yuan Gao and Yu Shi and Xiang-Dong Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/178},
  pages     = {1276-1282},
  title     = {Multilevel hierarchical network with multiscale sampling for video question answering},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Continual semantic segmentation leveraging image-level
labels and rehearsal. <em>IJCAI</em>, 1268–1275. (<a
href="https://doi.org/10.24963/ijcai.2022/177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Despite the remarkable progress of deep learning models for semantic segmentation, the success of these models is strongly limited by the following aspects: 1) large datasets with pixel-level annotations must be available and 2) training must be performed with all classes simultaneously. Indeed, in incremental learning scenarios, where new classes are added to an existing framework, these models are prone to catastrophic forgetting of previous classes. To address these two limitations, we propose a weakly-supervised mechanism for continual semantic segmentation that can leverage cheap image-level annotations and a novel rehearsal strategy that intertwines the learning of past and new classes. Specifically, we explore two rehearsal technique variants: 1) imprinting past objects on new images and 2) transferring past representations in intermediate features maps. We conduct extensive experiments on Pascal-VOC by varying the proportion of fully- and weakly-supervised data in various setups and show that our contributions consistently improve the mIoU on both past and novel classes. Interestingly, we also observe that models trained with less data in incremental steps sometimes outperform the same architectures trained with more data. We discuss the significance of these results and propose some hypotheses regarding the dynamics between forgetting and learning. Keywords: Computer Vision: Segmentation Machine Learning: Incremental Learning Machine Learning: Weakly Supervised Learning},
  archive   = {C_IJCAI},
  author    = {Mathieu Pagé Fortin and Brahim Chaib-draa},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/177},
  pages     = {1268-1275},
  title     = {Continual semantic segmentation leveraging image-level labels and rehearsal},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning degradation uncertainty for unsupervised real-world
image super-resolution. <em>IJCAI</em>, 1261–1267. (<a
href="https://doi.org/10.24963/ijcai.2022/176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Acquiring degraded images with paired high-resolution (HR) images is often challenging, impeding the advance of image super-resolution in real-world applications. By generating realistic low-resolution (LR) images with degradation similar to that in real-world scenarios, simulated paired LR-HR data can be constructed for supervised training. However, most of the existing work ignores the degradation uncertainty of the generated realistic LR images, since only one LR image has been generated given an HR image. To address this weakness, we propose learning the degradation uncertainty of generated LR images and sampling multiple LR images from the learned LR image (mean) and degradation uncertainty (variance) and construct LR-HR pairs to train the super-resolution (SR) networks. Specifically, uncertainty can be learned by minimizing the proposed loss based on Kullback-Leibler (KL) divergence. Furthermore, the uncertainty in the feature domain is exploited by a novel perceptual loss; and we propose to calculate the adversarial loss from the gradient information in the SR stage for stable training performance and better visual quality. Experimental results on popular real-world datasets show that our proposed method has performed better than other unsupervised approaches. Keywords: Computer Vision: Computational photography Uncertainty in AI: Uncertainty Representations},
  archive   = {C_IJCAI},
  author    = {Qian Ning and Jingzhu Tang and Fangfang Wu and Weisheng Dong and Xin Li and Guangming Shi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/176},
  pages     = {1261-1267},
  title     = {Learning degradation uncertainty for unsupervised real-world image super-resolution},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Improved deep unsupervised hashing with fine-grained
semantic similarity mining for multi-label image retrieval.
<em>IJCAI</em>, 1254–1260. (<a
href="https://doi.org/10.24963/ijcai.2022/175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we study deep unsupervised hashing, a critical problem for approximate nearest neighbor research. Most recent methods solve this problem by semantic similarity reconstruction for guiding hashing network learning or contrastive learning of hash codes. However, in multi-label scenarios, these methods usually either generate an inaccurate similarity matrix without reflection of similarity ranking or suffer from the violation of the underlying assumption in contrastive learning, resulting in limited retrieval performance. To tackle this issue, we propose a novel method termed HAMAN, which explores semantics from a fine-grained view to enhance the ability of multi-label image retrieval. In particular, we reconstruct the pairwise similarity structure by matching fine-grained patch features generated by the pre-trained neural network, serving as reliable guidance for similarity preserving of hash codes. Moreover, a novel conditional contrastive learning on hash codes is proposed to adopt self-supervised learning in multi-label scenarios. According to extensive experiments on three multi-label datasets, the proposed method outperforms a broad range of state-of-the-art methods. Keywords: Computer Vision: Image and Video retrieval Computer Vision: Representation Learning Data Mining: Information Retrieval},
  archive   = {C_IJCAI},
  author    = {Zeyu Ma and Xiao Luo and Yingjie Chen and Mixiao Hou and Jinxing Li and Minghua Deng and Guangming Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/175},
  pages     = {1254-1260},
  title     = {Improved deep unsupervised hashing with fine-grained semantic similarity mining for multi-label image retrieval},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Long-short term cross-transformer in compressed domain for
few-shot video classification. <em>IJCAI</em>, 1247–1253. (<a
href="https://doi.org/10.24963/ijcai.2022/174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compared with image few-shot learning, most of the existing few-shot video classification methods perform worse on feature matching, because they fail to sufficiently exploit the temporal information and relation. Specifically, frames are usually evenly sampled, which may miss important frames. On the other hand, the heuristic model simply encodes the equally treated frames in sequence, which results in the lack of both long-term and short-term temporal modeling and interaction. To alleviate these limitations, we take advantage of the compressed domain knowledge and propose a long-short term Cross-Transformer (LSTC) for few-shot video classification. For short terms, the motion vector (MV) contains temporal cues and reflects the importance of each frame. For long terms, a video can be natively divided into a sequence of GOPs (Group Of Picture). Using this compressed domain knowledge helps to obtain a more accurate spatial-temporal feature space. Consequently, we design the long-short term selection module, short-term module, and long-term module to comprise the LSTC. Long-short term selection is performed to select informative compressed domain data. Long/short-term modules are utilized to sufficiently exploit the temporal information so that the query and support can be well-matched by cross-attention. Experimental results show the superiority of our method on various datasets. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Video analysis and understanding Machine Learning: Few-shot learning},
  archive   = {C_IJCAI},
  author    = {Wenyang Luo and Yufan Liu and Bing Li and Weiming Hu and Yanan Miao and Yangxi Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/174},
  pages     = {1247-1253},
  title     = {Long-short term cross-transformer in compressed domain for few-shot video classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning multi-dimensional edge feature-based AU relation
graph for facial action unit recognition. <em>IJCAI</em>, 1239–1246. (<a
href="https://doi.org/10.24963/ijcai.2022/173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The activations of Facial Action Units (AUs) mutually influence one another. While the relationship between a pair of AUs can be complex and unique, existing approaches fail to specifically and explicitly represent such cues for each pair of AUs in each facial display. This paper proposes an AU relationship modelling approach that deep learns a unique graph to explicitly describe the relationship between each pair of AUs of the target facial display. Our approach first encodes each AU&#39;s activation status and its association with other AUs into a node feature. Then, it learns a pair of multi-dimensional edge features to describe multiple task-specific relationship cues between each pair of AUs. During both node and edge feature learning, our approach also considers the influence of the unique facial display on AUs&#39; relationship by taking the full face representation as an input. Experimental results on BP4D and DISFA datasets show that both node and edge feature learning modules provide large performance improvements for CNN and transformer-based backbones, with our best systems achieving the state-of-the-art AU recognition results. Our approach not only has a strong capability in modelling relationship cues for AU recognition but also can be easily incorporated into various backbones. Our PyTorch code is made available at https://github.com/CVI-SZU/ME-GraphAU. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Action and Behaviour Recognition Computer Vision: Representation Learning Machine Learning: Multi-label Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Cheng Luo and Siyang Song and Weicheng Xie and Linlin Shen and Hatice Gunes},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/173},
  pages     = {1239-1246},
  title     = {Learning multi-dimensional edge feature-based AU relation graph for facial action unit recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Deep video harmonization with color mapping consistency.
<em>IJCAI</em>, 1232–1238. (<a
href="https://doi.org/10.24963/ijcai.2022/172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video harmonization aims to adjust the foreground of a composite video to make it compatible with the background. So far, video harmonization has only received limited attention and there is no public dataset for video harmonization. In this work, we construct a new video harmonization dataset HYouTube by adjusting the foreground of real videos to create synthetic composite videos. Moreover, we consider the temporal consistency in video harmonization task. Unlike previous works which establish the spatial correspondence, we design a novel framework based on the assumption of color mapping consistency, which leverages the color mapping of neighboring frames to refine the current frame. Extensive experiments on our HYouTube dataset prove the effectiveness of our proposed framework. Our dataset and code are available at https://github.com/bcmi/Video-Harmonization-Dataset-HYouTube. Keywords: Computer Vision: Video analysis and understanding Computer Vision: Other},
  archive   = {C_IJCAI},
  author    = {Xinyuan Lu and Shengyuan Huang and Li Niu and Wenyan Cong and Liqing Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/172},
  pages     = {1232-1238},
  title     = {Deep video harmonization with color mapping consistency},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Copy motion from one to another: Fake motion video
generation. <em>IJCAI</em>, 1223–1231. (<a
href="https://doi.org/10.24963/ijcai.2022/171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {One compelling application of artificial intelligence is to generate a video of a target person performing arbitrary desired motion (from a source person). While the state-of-the-art methods are able to synthesize a video demonstrating similar broad stroke motion details, they are generally lacking in texture details. A pertinent manifestation appears as distorted face, feet, and hands, and such flaws are very sensitively perceived by human observers. Furthermore, current methods typically employ GANs with a L2 loss to assess the authenticity of the generated videos, inherently requiring a large amount of training samples to learn the texture details for adequate video generation. In this work, we tackle these challenges from three aspects: 1) We disentangle each video frame into foreground (the person) and background, focusing on generating the foreground to reduce the underlying dimension of the network output. 2) We propose a theoretically motivated Gromov-Wasserstein loss that facilitates learning the mapping from a pose to a foreground image. 3) To enhance texture details, we encode facial features with geometric guidance and employ local GANs to refine the face, feet, and hands. Extensive experiments show that our method is able to generate realistic target person videos, faithfully copying complex motions from a source person. Our code and datasets are released at https://github.com/Sifann/FakeMotion. Keywords: Computer Vision: Motion and Tracking Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Zhenguang Liu and Sifan Wu and Chejian Xu and Xiang Wang and Lei Zhu and Shuang Wu and Fuli Feng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/171},
  pages     = {1223-1231},
  title     = {Copy motion from one to another: Fake motion video generation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Vision shared and representation isolated network for person
search. <em>IJCAI</em>, 1216–1222. (<a
href="https://doi.org/10.24963/ijcai.2022/170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Person search is a widely-concerned computer vision task that aims to jointly solve the problems of pedestrian detection and person re-identification in panoramic scenes. However, the pedestrian detection focuses on the consistency of pedestrians, while the person re-identification attempts to extract the discriminative features of pedestrians. The inevitable conflict greatly restricts the researches on the one-stage person search methods. To address this issue, we propose a Vision Shared and Representation Isolated (VSRI) network to decouple the two conflicted subtasks simultaneously, through which two independent representations are constructed for the two subtasks. To enhance the discrimination of the re-ID representation, a Multi-Level Feature Fusion (MLFF) module is proposed. The MLFF adopts the Spatial Pyramid Feature Fusion (SPFF) module to obtain diverse features from the stem network. Moreover, the multi-head self-attention mechanism is employed to construct a Multi-head Attention Driven Extraction (MADE) module and the cascaded convolution unit is adopted to devise a Feature Decomposition and Cascaded Integration (FDCI) module, which facilitates the MLFF to obtain more discriminative representations of the pedestrians. The proposed method outperforms the state-of-the-art methods on the mainstream datasets. Keywords: Computer Vision: Image and Video retrieval Computer Vision: Applications Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Yang Liu and Yingping Li and Chengyu Kong and Yuqiu Kong and Shenglan Liu and Feilong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/170},
  pages     = {1216-1222},
  title     = {Vision shared and representation isolated network for person search},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biological instance segmentation with a superpixel-guided
graph. <em>IJCAI</em>, 1209–1215. (<a
href="https://doi.org/10.24963/ijcai.2022/169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advanced proposal-free instance segmentation methods have made significant progress in biological images. However, existing methods are vulnerable to local imaging artifacts and similar object appearances, resulting in over-merge and over-segmentation. To reduce these two kinds of errors, we propose a new biological instance segmentation framework based on a superpixel-guided graph, which consists of two stages, i.e., superpixel-guided graph construction and superpixel agglomeration. Specifically, the first stage generates enough superpixels as graph nodes to avoid over-merge, and extracts node and edge features to construct an initialized graph. The second stage agglomerates superpixels into instances based on the relationship of graph nodes predicted by a graph neural network (GNN). To solve over-segmentation and prevent introducing additional over-merge, we specially design two loss functions to supervise the GNN, i.e., a repulsion-attraction (RA) loss to better distinguish the relationship of nodes in the feature space, and a maximin agglomeration score (MAS) loss to pay more attention to crucial edge classification. Extensive experiments on three representative biological datasets demonstrate the superiority of our method over existing state-of-the-art methods. Code is available at https://github.com/liuxy1103/BISSG. Keywords: Computer Vision: Biomedical Image Analysis Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Xiaoyu Liu and Wei Huang and Yueyi Zhang and Zhiwei Xiong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/169},
  pages     = {1209-1215},
  title     = {Biological instance segmentation with a superpixel-guided graph},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TopoSeg: Topology-aware segmentation for point clouds.
<em>IJCAI</em>, 1201–1208. (<a
href="https://doi.org/10.24963/ijcai.2022/168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Point cloud segmentation plays an important role in AI applications such as autonomous driving, AR, and VR. However, previous point cloud segmentation neural networks rarely pay attention to the topological correctness of the segmentation results. In this paper, focusing on the perspective of topology awareness. First, to optimize the distribution of segmented predictions from the perspective of topology, we introduce the persistent homology theory in topology into a 3D point cloud deep learning framework. Second, we propose a topology-aware 3D point cloud segmentation module, TopoSeg. Specifically, we design a topological loss function embedded in TopoSeg module, which imposes topological constraints on the segmentation of 3D point clouds. Experiments show that our proposed TopoSeg module can be easily embedded into the point cloud segmentation network and improve the segmentation performance. In addition, based on the constructed topology loss function, we propose a topology-aware point cloud edge extraction algorithm, which is demonstrated that has strong robustness. Keywords: Computer Vision: 3D Computer Vision Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Weiquan Liu and Hanyun Guo and Weini Zhang and Yu Zang and Cheng Wang and Jonathan Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/168},
  pages     = {1201-1208},
  title     = {TopoSeg: Topology-aware segmentation for point clouds},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cost ensemble with gradient selecting for GANs.
<em>IJCAI</em>, 1194–1200. (<a
href="https://doi.org/10.24963/ijcai.2022/167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative Adversarial Networks(GANs) are powerful generative models on numerous tasks and datasets but are also known for their training instability and mode collapse. The latter is because the optimal transportation map is discontinuous, but DNNs can only approximate continuous ones. One way to solve the problem is to introduce multiple discriminators or generators. However, their impacts are limited because the cost function of each component is the same. That is, they are homogeneous. In contrast, multiple discriminators with different cost functions can yield various gradients for the generator, which indicates we can use them to search for more transportation maps in the latent space. Inspired by this, we have proposed a framework to combat the mode collapse problem, containing multiple discriminators with different cost functions, named CES-GAN. Unfortunately, it may also lead to the generator being hard to train because the performance between discriminators is unbalanced, according to the Cannikin Law. Thus, a gradient selecting mechanism is also proposed to pick up proper gradients. We provide mathematical statements to prove our assumptions and conduct extensive experiments to verify the performance. The results show that CES-GAN is lightweight and more effective for fighting against the mode collapse problem than similar works. Keywords: Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: Adversarial learning, adversarial attack and defense methods},
  archive   = {C_IJCAI},
  author    = {Minghui Liu and Jiali Deng and Meiyi Yang and Xuan Cheng and Nianbo Liu and Ming Liu and Xiaomin Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/167},
  pages     = {1194-1200},
  title     = {Cost ensemble with gradient selecting for GANs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dynamic group transformer: A general vision transformer
backbone with dynamic group attention. <em>IJCAI</em>, 1187–1193. (<a
href="https://doi.org/10.24963/ijcai.2022/166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, Transformers have shown promising performance in various vision tasks. To reduce the quadratic computation complexity caused by each query attending to all keys/values, various methods have constrained the range of attention within local regions, where each query only attends to keys/values within a hand-crafted window. However, these hand-crafted window partition mechanisms are data-agnostic and ignore their input content, so it is likely that one query maybe attend to irrelevant keys/values. To address this issue, we propose a Dynamic Group Attention (DG-Attention), which dynamically divides all queries into multiple groups and selects the most relevant keys/values for each group. Our DG-Attention can flexibly model more relevant dependencies without any spatial constraint that is used in hand-crafted window based attention. Built on the DG-Attention, we develop a general vision transformer backbone named Dynamic Group Transformer (DGT). Extensive experiments show that our models can outperform the state-of-the-art methods on multiple common vision tasks, including image classification, semantic segmentation, object detection, and instance segmentation. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Kai Liu and Tianyi Wu and Cong Liu and Guodong Guo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/166},
  pages     = {1187-1193},
  title     = {Dynamic group transformer: A general vision transformer backbone with dynamic group attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MA-ViT: Modality-agnostic vision transformers for face
anti-spoofing. <em>IJCAI</em>, 1180–1186. (<a
href="https://doi.org/10.24963/ijcai.2022/165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The existing multi-modal face anti-spoofing (FAS) frameworks are designed based on two strategies: halfway and late fusion. However, the former requires test modalities consistent with the training input, which seriously limits its deployment scenarios. And the latter is built on multiple branches to process different modalities independently, which limits their use in applications with low memory or fast execution requirements. In this work, we present a single branch based Transformer framework, namely Modality-Agnostic Vision Transformer (MA-ViT), which aims to improve the performance of arbitrary modal attacks with the help of multi-modal data. Specifically, MA-ViT adopts the early fusion to aggregate all the available training modalities’ data and enables flexible testing of any given modal samples. Further, we develop the Modality-Agnostic Transformer Block (MATB) in MA-ViT, which consists of two stacked attentions named Modal-Disentangle Attention (MDA) and Cross-Modal Attention (CMA), to eliminate modality-related information for each modal sequences and supplement modality-agnostic liveness features from another modal sequences, respectively. Experiments demonstrate that the single model trained based on MA-ViT can not only flexibly evaluate different modal samples, but also outperforms existing single-modal frameworks by a large margin, and approaches the multi-modal frameworks introduced with smaller FLOPs and model parameters. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition},
  archive   = {C_IJCAI},
  author    = {Ajian Liu and Yanyan Liang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/165},
  pages     = {1180-1186},
  title     = {MA-ViT: Modality-agnostic vision transformers for face anti-spoofing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). FQ-ViT: Post-training quantization for fully quantized
vision transformer. <em>IJCAI</em>, 1173–1179. (<a
href="https://doi.org/10.24963/ijcai.2022/164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network quantization significantly reduces model inference complexity and has been widely used in real-world deployments. However, most existing quantization methods have been developed mainly on Convolutional Neural Networks (CNNs), and suffer severe degradation when applied to fully quantized vision transformers. In this work, we demonstrate that many of these difficulties arise because of serious inter-channel variation in LayerNorm inputs, and present, Power-of-Two Factor (PTF), a systematic method to reduce the performance degradation and inference complexity of fully quantized vision transformers. In addition, observing an extreme non-uniform distribution in attention maps, we propose Log-Int-Softmax (LIS) to sustain that and simplify inference by using 4-bit quantization and the BitShift operator. Comprehensive experiments on various transformer-based architectures and benchmarks show that our Fully Quantized Vision Transformer (FQ-ViT) outperforms previous works while even using lower bit-width on attention maps. For instance, we reach 84.89\% top-1 accuracy with ViT-L on ImageNet and 50.8 mAP with Cascade Mask R-CNN (Swin-S) on COCO. To our knowledge, we are the first to achieve lossless accuracy degradation (~1\%) on fully quantized vision transformers. The code is available at https://github.com/megvii-research/FQ-ViT. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Yang Lin and Tianyu Zhang and Peiqin Sun and Zheng Li and Shuchang Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/164},
  pages     = {1173-1179},
  title     = {FQ-ViT: Post-training quantization for fully quantized vision transformer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Intrinsic image decomposition by pursuing reflectance image.
<em>IJCAI</em>, 1166–1172. (<a
href="https://doi.org/10.24963/ijcai.2022/163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Intrinsic image decomposition is a fundamental problem for many computer vision applications. While recent deep learning based methods have achieved very promising results on the synthetic densely labeled datasets, the results on the real-world dataset are still far from human level performance. This is mostly because collecting dense supervision on a real-world dataset is impossible. Only a sparse set of pairwise judgement from human is often used. It&#39;s very difficult for models to learn in such settings. In this paper, we investigate the possibilities of only using reflectance images for supervision during training. In this way, the demand for labeled data is greatly reduced. In order to achieve this goal, we take a deep investigation into the reflectance images. We find that reflectance images are actually comprised of two components: the flat surfaces with low frequency information, and the boundaries with high frequency details. Then, we propose to disentangle the learning process of the two components of the reflectance images. We argue that through this procedure, the reflectance images can be better modeled, and in the meantime, the shading images, though not supervised, can also achieve decent result. Extensive experiments show that our proposed network outperforms current state-of-the-art results by a large margin on the most challenging real-world IIW dataset. We also surprisingly find that on the densely labeled datasets (MIT and MPI-Sintel), our network can also achieve state-of-the-art results on both reflectance and shading images, when we only apply supervision on the reflectance images during training. Keywords: Computer Vision: Scene analysis and understanding Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning},
  archive   = {C_IJCAI},
  author    = {Tzu-Heng Lin and Pengxiao Wang and Yizhou Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/163},
  pages     = {1166-1172},
  title     = {Intrinsic image decomposition by pursuing reflectance image},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to estimate object poses without real image
annotations. <em>IJCAI</em>, 1159–1165. (<a
href="https://doi.org/10.24963/ijcai.2022/162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a simple yet effective approach for learning 6DoF object poses without real image annotations. Previous methods have attempted to train pose estimators on synthetic data, but they do not generalize well to real images due to the sim-to-real domain gap and produce inaccurate pose estimates. We find that, in most cases, the synthetically trained pose estimators are able to provide reasonable initialization for depth-based pose refinement methods which yield accurate pose estimates. Motivated by this, we propose a novel learning framework, which utilizes the accurate results of depth-based pose refinement methods to supervise the RGB-based pose estimator. Our method significantly outperforms previous self-supervised methods on several benchmarks. Even compared with fully-supervised methods that use real annotated data, we achieve competitive results without using any real annotation. The code is available at https://github.com/zju3dv/pvnet-depth-sup. Keywords: Computer Vision: 3D Computer Vision Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Haotong Lin and Sida Peng and Zhize Zhou and Xiaowei Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/162},
  pages     = {1159-1165},
  title     = {Learning to estimate object poses without real image annotations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RMGN: A regional mask guided network for parser-free virtual
try-on. <em>IJCAI</em>, 1151–1158. (<a
href="https://doi.org/10.24963/ijcai.2022/161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Virtual try-on (VTON) aims at fitting target clothes to reference person images, which is widely adopted in e-commerce. Existing VTON approaches can be narrowly categorized into Parser-Based (PB) and Parser-Free (PF) by whether relying on the parser information to mask the persons’clothes and synthesize try-on images. Although abandoning parser information has improved the applicability of PF methods, the ability of detail synthesizing has also been sacrificed. As a result, the distraction from original cloth may persist in synthesized images, especially in complicated postures and high resolution applications. To address the aforementioned issue, we propose a novel PF method named Regional Mask Guided Network (RMGN). More specifically, a regional mask is proposed to explicitly fuse the features of target clothes and reference persons so that the persisted distraction can be eliminated. A posture awareness loss and a multi-level feature extractor are further proposed to handle the complicated postures and synthesize high resolution images. Extensive experiments demonstrate that our proposed RMGN outperforms both state-of-the-art PB and PF methods. Ablation studies further verify the effectiveness of modules in RMGN. Code is available at https://github.com/jokerlc/RMGN-VITON. Keywords: Computer Vision: Applications Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: Segmentation},
  archive   = {C_IJCAI},
  author    = {Chao Lin and Zhao Li and Sheng Zhou and Shichang Hu and Jialun Zhang and Linhao Luo and Jiarun Zhang and Longtao Huang and Yuan He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/161},
  pages     = {1151-1158},
  title     = {RMGN: A regional mask guided network for parser-free virtual try-on},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Feature dense relevance network for single image dehazing.
<em>IJCAI</em>, 1144–1150. (<a
href="https://doi.org/10.24963/ijcai.2022/160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing learning-based dehazing methods do not fully use non-local information, which makes the restoration of seriously degraded region very tough. We propose a novel dehazing network by defining the Feature Dense Relevance module (FDR) and the Shallow Feature Mapping module (SFM). The FDR is defined based on multi-head attention to construct the dense relationship between different local features in the whole image. It enables the network to restore the degraded local regions by non-local information in complex scenes. In addition, the raw distant skip-connection easily leads to artifacts while it cannot deal with the shallow features effectively. Therefore, we define the SFM by combining the atmospheric scattering model and the distant skip-connection to effectively deal with the shallow features in different scales. It not only maps the degraded textures into clear textures by distant dependence, but also reduces artifacts and color distortions effectively. We introduce contrastive loss and focal frequency loss in the network to obtain a realitic and clear image. The extensive experiments on several synthetic and real-world datasets demonstrate that our network surpasses most of the state-of-the-art methods. Keywords: Computer Vision: Computational photography Computer Vision: Machine Learning for Vision},
  archive   = {C_IJCAI},
  author    = {Yun Liang and Enze Huang and Zifeng Zhang and Zhuo Su and Dong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/160},
  pages     = {1144-1150},
  title     = {Feature dense relevance network for single image dehazing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised learning and adaptation for single image
dehazing. <em>IJCAI</em>, 1137–1143. (<a
href="https://doi.org/10.24963/ijcai.2022/159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Existing deep image dehazing methods usually depend on supervised learning with a large number of hazy-clean image pairs which are expensive or difficult to collect. Moreover, dehazing performance of the learned model may deteriorate significantly when the training hazy-clean image pairs are insufficient and are different from real hazy images in applications. In this paper, we show that exploiting large scale training set and adapting to real hazy images are two critical issues in learning effective deep dehazing models. Under the depth guidance estimated by a well-trained depth estimation network, we leverage the conventional atmospheric scattering model to generate massive hazy-clean image pairs for the self-supervised pre-training of dehazing network. Furthermore, self-supervised adaptation is presented to adapt pre-trained network to real hazy images. Learning without forgetting strategy is also deployed in self-supervised adaptation by combining self-supervision and model adaptation via contrastive learning. Experiments show that our proposed method performs favorably against the state-of-the-art methods, and is quite efficient, i.e., handling a 4K image in 23 ms. The codes are available at https://github.com/DongLiangSXU/SLAdehazing. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Neural generative models, auto encoders, GANs Computer Vision: Machine Learning for Vision Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Yudong Liang and Bin Wang and Wangmeng Zuo and Jiaying Liu and Wenqi Ren},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/159},
  pages     = {1137-1143},
  title     = {Self-supervised learning and adaptation for single image dehazing},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-view visual semantic embedding. <em>IJCAI</em>,
1130–1136. (<a href="https://doi.org/10.24963/ijcai.2022/158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Visual Semantic Embedding (VSE) is a dominant method for cross-modal vision-language retrieval. Its purpose is to learn an embedding space so that visual data can be embedded in a position close to the corresponding text description. However, there are large intra-class variations in the vision-language data. For example, multiple texts describing the same image may be described from different views, and the descriptions of different views are often dissimilar. The mainstream VSE method embeds samples from the same class in similar positions, which will suppress intra-class variations and lead to inferior generalization performance. This paper proposes a Multi-View Visual Semantic Embedding (MV-VSE) framework, which learns multiple embeddings for one visual data and explicitly models intra-class variations. To optimize MV-VSE, a multi-view upper bound loss is proposed, and the multi-view embeddings are jointly optimized while retaining intra-class variations. MV-VSE is plug-and-play and can be applied to various VSE models and loss functions without excessively increasing model complexity. Experimental results on the Flickr30K and MS-COCO datasets demonstrate the superior performance of our framework. Keywords: Computer Vision: Vision and language Computer Vision: Image and Video retrieval Machine Learning: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Zheng Li and Caili Guo and Zerun Feng and Jenq-Neng Hwang and Xijun Xue},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/158},
  pages     = {1130-1136},
  title     = {Multi-view visual semantic embedding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised embedding and association network for
multi-object tracking. <em>IJCAI</em>, 1123–1129. (<a
href="https://doi.org/10.24963/ijcai.2022/157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {How to generate robust trajectories of multiple objects without using any manual identity annotation? Recently, identity embedding features from Re-ID models are adopted to associate targets into trajectories. However, most previous methods equipped with embedding features heavily rely on manual identity annotations, which bring a high cost for the multi-object tracking (MOT) task. To address the above problem, we present an unsupervised embedding and association network (UEANet) for learning discriminative embedding features with pseudo identity labels. Specifically, we firstly generate the pseudo identity labels by adopting a Kalman filter tracker to associate multiple targets into trajectories and assign a unique identity label to each trajectory. Secondly, we train the transformer-based identity embedding branch and MLP-based data association branch of UEANet with these pseudo labels, and UEANet extracts branch-dependent features for the unsupervised MOT task. Experimental results show that UEANet confirms the outstanding ability to suppress IDS and achieves comparable performance compared with state-of-the-art methods on three MOT datasets. Keywords: Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Yu-Lei Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/157},
  pages     = {1123-1129},
  title     = {Unsupervised embedding and association network for multi-object tracking},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PRNet: Point-range fusion network for real-time LiDAR
semantic segmentation. <em>IJCAI</em>, 1116–1122. (<a
href="https://doi.org/10.24963/ijcai.2022/156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Accurate and real-time LiDAR semantic segmentation is necessary for advanced autonomous driving systems. To guarantee a fast inference speed, previous methods utilize the highly optimized 2D convolutions to extract features on the range view (RV), which is the most compact representation of the LiDAR point clouds. However, these methods often suffer from lower accuracy for two reasons: 1) the information loss during the projection from 3D points to the RV, 2) the semantic ambiguity when 3D points labels are assigned according to the RV predictions. In this work, we introduce an end-to-end point-range fusion network (PRNet) that extracts semantic features mainly on the RV and iteratively fuses the RV features back to the 3D points for the final prediction. Besides, a novel range view projection (RVP) operation is designed to alleviate the information loss during the projection to the RV, and a point-range convolution (PRConv) is proposed to automatically mitigate the semantic ambiguity during transmitting features from the RV back to 3D points. Experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the PRNet pushes the range-based methods to a new state-of-the-art, and achieves a better speed-accuracy trade-off. Keywords: Computer Vision: 3D Computer Vision Computer Vision: Scene analysis and understanding Computer Vision: Segmentation Robotics: Applications Robotics: Perception},
  archive   = {C_IJCAI},
  author    = {Xiaoyan Li and Gang Zhang and Tao Jiang and Xufen Cai and Zhenhua Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/156},
  pages     = {1116-1122},
  title     = {PRNet: Point-range fusion network for real-time LiDAR semantic segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). TCCNet: Temporally consistent context-free network for
semi-supervised video polyp segmentation. <em>IJCAI</em>, 1109–1115. (<a
href="https://doi.org/10.24963/ijcai.2022/155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic video polyp segmentation (VPS) is highly valued for the early diagnosis of colorectal cancer. However, existing methods are limited in three respects: 1) most of them work on static images, while ignoring the temporal information in consecutive video frames; 2) all of them are fully supervised and easily overfit in presence of limited annotations; 3) the context of polyp (i.e., lumen, specularity and mucosa tissue) varies in an endoscopic clip, which may affect the predictions of adjacent frames. To resolve these challenges, we propose a novel Temporally Consistent Context-Free Network (TCCNet) for semi-supervised VPS. It contains a segmentation branch and a propagation branch with a co-training scheme to supervise the predictions of unlabeled image. To maintain the temporal consistency of predictions, we design a Sequence-Corrected Reverse Attention module and a Propagation-Corrected Reverse Attention module. A Context-Free Loss is also proposed to mitigate the impact of varying contexts. Extensive experiments show that even trained under 1/15 label ratio, TCCNet is comparable to the state-of-the-art fully supervised methods for VPS. Also, TCCNet surpasses existing semi-supervised methods for natural image and other medical image segmentation tasks. Keywords: Computer Vision: Biomedical Image Analysis},
  archive   = {C_IJCAI},
  author    = {Xiaotong Li and Jilan Xu and Yuejie Zhang and Rui Feng and Rui-Wei Zhao and Tao Zhang and Xuequan Lu and Shang Gao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/155},
  pages     = {1109-1115},
  title     = {TCCNet: Temporally consistent context-free network for semi-supervised video polyp segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning graph-based residual aggregation network for group
activity recognition. <em>IJCAI</em>, 1102–1108. (<a
href="https://doi.org/10.24963/ijcai.2022/154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Group activity recognition aims to understand the overall behavior performed by a group of people. Recently, some graph-based methods have made progress by learning the relation graphs among multiple persons. However, the differences between an individual and others play an important role in identifying confusable group activities, which have not been elaborately explored by previous methods. In this paper, a novel Graph-based Residual AggregatIon Network (GRAIN) is proposed to model the differences among all persons of the whole group, which is end-to-end trainable. Specifically, a new local residual relation module is explicitly proposed to capture the local spatiotemporal differences of relevant persons, which is further combined with the multi-graph relation networks. Moreover, a weighted aggregation strategy is devised to adaptively select multi-level spatiotemporal features from the appearance-level information to high level relations. Finally, our model is capable of extracting a comprehensive representation and inferring the group activity in an end-to-end manner. The experimental results on two popular benchmarks for group activity recognition clearly demonstrate the superior performance of our method in comparison with the state-of-the-art methods. Keywords: Computer Vision: Action and Behaviour Recognition Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Wei Li and Tianzhao Yang and Xiao Wu and Zhaoquan Yuan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/154},
  pages     = {1102-1108},
  title     = {Learning graph-based residual aggregation network for group activity recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Dite-HRNet: Dynamic lightweight high-resolution network for
human pose estimation. <em>IJCAI</em>, 1095–1101. (<a
href="https://doi.org/10.24963/ijcai.2022/153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A high-resolution network exhibits remarkable capability in extracting multi-scale features for human pose estimation, but fails to capture long-range interactions between joints and has high computational complexity. To address these problems, we present a Dynamic lightweight High-Resolution Network (Dite-HRNet), which can efficiently extract multi-scale contextual information and model long-range spatial dependency for human pose estimation. Specifically, we propose two methods, dynamic split convolution and adaptive context modeling, and embed them into two novel lightweight blocks, which are named dynamic multi-scale context block and dynamic global context block. These two blocks, as the basic component units of our Dite-HRNet, are specially designed for the high-resolution networks to make full use of the parallel multi-resolution architecture. Experimental results show that the proposed network achieves superior performance on both COCO and MPII human pose estimation datasets, surpassing the state-of-the-art lightweight networks. Code is available at: https://github.com/ZiyiZhang27/Dite-HRNet. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Action and Behaviour Recognition Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Qun Li and Ziyi Zhang and Fu Xiao and Feng Zhang and Bir Bhanu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/153},
  pages     = {1095-1101},
  title     = {Dite-HRNet: Dynamic lightweight high-resolution network for human pose estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). RePFormer: Refinement pyramid transformer for robust facial
landmark detection. <em>IJCAI</em>, 1088–1094. (<a
href="https://doi.org/10.24963/ijcai.2022/152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a Refinement Pyramid Transformer (RePFormer) for robust facial landmark detection. Most facial landmark detectors focus on learning representative image features. However, these CNN-based feature representations are not robust enough to handle complex real-world scenarios due to ignoring the internal structure of landmarks, as well as the relations between landmarks and context. In this work, we formulate the facial landmark detection task as refining landmark queries along pyramid memories. Specifically, a pyramid transformer head (PTH) is introduced to build both homologous relations among landmarks and heterologous relations between landmarks and cross-scale contexts. Besides, a dynamic landmark refinement (DLR) module is designed to decompose the landmark regression into an end-to-end refinement procedure, where the dynamically aggregated queries are transformed to residual coordinates predictions. Extensive experimental results on four facial landmark detection benchmarks and their various subsets demonstrate the superior performance and high robustness of our framework. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Jinpeng Li and Haibo Jin and Shengcai Liao and Ling Shao and Pheng-Ann Heng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/152},
  pages     = {1088-1094},
  title     = {RePFormer: Refinement pyramid transformer for robust facial landmark detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ER-SAN: Enhanced-adaptive relation self-attention network
for image captioning. <em>IJCAI</em>, 1081–1087. (<a
href="https://doi.org/10.24963/ijcai.2022/151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image captioning (IC), bringing vision to language, has drawn extensive attention. Precisely describing visual relations between image objects is a key challenge in IC. We argue that the visual relations, that is geometric positions (i.e., distance and size) and semantic interactions (i.e., actions and possessives), indicate the mutual correlations between objects. Existing Transformer-based methods typically resort to geometric positions to enhance the representation of visual relations, yet only using the shallow geometric is unable to precisely cover the complex and actional correlations. In this paper, we propose to enhance the correlations between objects from a comprehensive view that jointly considers explicit semantic and geometric relations, generating plausible captions with accurate relationship predictions. Specifically, we propose a novel Enhanced-Adaptive Relation Self-Attention Network (ER-SAN). We design the direction-sensitive semantic-enhanced attention, which considers content objects to semantic relations and semantic relations to content objects attention to learn explicit semantic-aware relations. Further, we devise an adaptive re-weight relation module that determines how much semantic and geometric attention should be activated to each relation feature. Extensive experiments on MS-COCO dataset demonstrate the effectiveness of our ER-SAN, with improvements of CIDEr from 128.6\% to 135.3\%, achieving state-of-the-art performance. Codes will be released \url{https://github.com/CrossmodalGroup/ER-SAN}. Keywords: Computer Vision: Vision and language Natural Language Processing: Language Generation},
  archive   = {C_IJCAI},
  author    = {Jingyu Li and Zhendong Mao and Shancheng Fang and Hao Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/151},
  pages     = {1081-1087},
  title     = {ER-SAN: Enhanced-adaptive relation self-attention network for image captioning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MMNet: Muscle motion-guided network for micro-expression
recognition. <em>IJCAI</em>, 1074–1080. (<a
href="https://doi.org/10.24963/ijcai.2022/150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Facial micro-expressions (MEs) are involuntary facial motions revealing people’s real feelings and play an important role in the early intervention of mental illness, the national security, and many human-computer interaction systems. However, existing micro-expression datasets are limited and usually pose some challenges for training good classifiers. To model the subtle facial muscle motions, we propose a robust micro-expression recognition (MER) framework, namely muscle motion-guided network (MMNet). Specifically, a continuous attention (CA) block is introduced to focus on modeling local subtle muscle motion patterns with little identity information, which is different from most previous methods that directly extract features from complete video frames with much identity information. Besides, we design a position calibration (PC) module based on the vision transformer. By adding the position embeddings of the face generated by the PC module at the end of the two branches, the PC module can help to add position information to facial muscle motion-pattern features for the MER. Extensive experiments on three public micro-expression datasets demonstrate that our approach outperforms state-of-the-art methods by a large margin. Code is available at https://github.com/muse1998/MMNet. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Recognition (object detection, categorization) Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Hanting Li and Mingzhe Sui and Zhaoqing Zhu and Feng Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/150},
  pages     = {1074-1080},
  title     = {MMNet: Muscle motion-guided network for micro-expression recognition},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-guided hard negative generation for unsupervised person
re-identification. <em>IJCAI</em>, 1067–1073. (<a
href="https://doi.org/10.24963/ijcai.2022/149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent unsupervised person re-identification (reID) methods mostly apply pseudo labels from clustering algorithms as supervision signals. Despite great success, this fashion is very likely to aggregate different identities with similar appearances into the same cluster. In result, the hard negative samples, playing important role in training reID models, are significantly reduced. To alleviate this problem, we propose a self-guided hard negative generation method for unsupervised person re-ID. Specifically, a joint framework is developed which incorporates a hard negative generation network (HNGN) and a re-ID network. To continuously generate harder negative samples to provide effective supervisions in the contrastive learning, the two networks are alternately trained in an adversarial manner to improve each other, where the reID network guides HNGN to generate challenging data and HNGN enforces the re-ID network to enhance discrimination ability. During inference, the performance of re-ID network is improved without introducing any extra parameters. Extensive experiments demonstrate that the proposed method significantly outperforms a strong baseline and also achieves better results than state-of-the-art methods. Keywords: Computer Vision: Image and Video retrieval},
  archive   = {C_IJCAI},
  author    = {Dongdong Li and Zhigang Wang and Jian Wang and Xinyu Zhang and Errui Ding and Jingdong Wang and Zhaoxiang Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/149},
  pages     = {1067-1073},
  title     = {Self-guided hard negative generation for unsupervised person re-identification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Representation learning for compressed video action
recognition via attentive cross-modal interaction with motion
enhancement. <em>IJCAI</em>, 1060–1066. (<a
href="https://doi.org/10.24963/ijcai.2022/148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Compressed video action recognition has recently drawn growing attention, since it remarkably reduces the storage and computational cost via replacing raw videos by sparsely sampled RGB frames and compressed motion cues (e.g., motion vectors and residuals). However, this task severely suffers from the coarse and noisy dynamics and the insufficient fusion of the heterogeneous RGB and motion modalities. To address the two issues above, this paper proposes a novel framework, namely Attentive Cross-modal Interaction Network with Motion Enhancement (MEACI-Net). It follows the two-stream architecture, i.e. one for the RGB modality and the other for the motion modality. Particularly, the motion stream employs a multi-scale block embedded with a denoising module to enhance representation learning. The interaction between the two streams is then strengthened by introducing the Selective Motion Complement (SMC) and Cross-Modality Augment (CMA) modules, where SMC complements the RGB modality with spatio-temporally attentive local motion features and CMA further combines the two modalities with selective feature augmentation. Extensive experiments on the UCF-101, HMDB-51 and Kinetics-400 benchmarks demonstrate the effectiveness and efficiency of MEACI-Net. Keywords: Computer Vision: Video analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Bing Li and Jiaxin Chen and Dongming Zhang and Xiuguo Bao and Di Huang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/148},
  pages     = {1060-1066},
  title     = {Representation learning for compressed video action recognition via attentive cross-modal interaction with motion enhancement},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022a). Iterative geometry-aware cross guidance network for stereo
image inpainting. <em>IJCAI</em>, 1053–1059. (<a
href="https://doi.org/10.24963/ijcai.2022/147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Currently, single image inpainting has achieved promising results based on deep convolutional neural networks. However, inpainting on stereo images with missing regions has not been explored thoroughly, which is also a significant but different problem. One crucial requirement for stereo image inpainting is stereo consistency. To achieve it, we propose an Iterative Geometry-Aware Cross Guidance Network (IGGNet). The IGGNet contains two key ingredients, i.e., a Geometry-Aware Attention(GAA) module and an Iterative Cross Guidance(ICG) strategy. The GAA module relies on the epipolar geometry cues and learns the geometry-aware guidance from one view to another, which is beneficial to make the corresponding regions in two views consistent. However, learning guidance from co-existing missing regions is challenging. To address this issue, the ICG strategy is proposed, which can alternately narrow down the missing regions of the two views in an iterative manner. Experimental results demonstrate that our proposed network outperforms the latest stereo image inpainting model and state-of-the-art single image inpainting models. Keywords: Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Ang Li and Shanshan Zhao and Zhang Qingjie and Qiuhong Ke},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/147},
  pages     = {1053-1059},
  title     = {Iterative geometry-aware cross guidance network for stereo image inpainting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning to assemble geometric shapes. <em>IJCAI</em>,
1046–1052. (<a href="https://doi.org/10.24963/ijcai.2022/146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Assembling parts into an object is a combinatorial problem that arises in a variety of contexts in the real world and involves numerous applications in science and engineering. Previous related work tackles limited cases with identical unit parts or jigsaw-style parts of textured shapes, which greatly mitigate combinatorial challenges of the problem. In this work, we introduce the more challenging problem of shape assembly, which involves textureless fragments of arbitrary shapes with indistinctive junctions, and then propose a learning-based approach to solving it. We demonstrate the effectiveness on shape assembly tasks with various scenarios, including the ones with abnormal fragments (e.g., missing and distorted), the different number of fragments, and different rotation discretization. Keywords: Computer Vision: Applications Computer Vision: Machine Learning for Vision Machine Learning: Applications Machine Learning: Attention Models},
  archive   = {C_IJCAI},
  author    = {Jinhwi Lee and Jungtaek Kim and Hyunsoo Chung and Jaesik Park and Minsu Cho},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/146},
  pages     = {1046-1052},
  title     = {Learning to assemble geometric shapes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). What is right for me is not yet right for you: A dataset for
grounding relative directions via multi-task learning. <em>IJCAI</em>,
1039–1045. (<a href="https://doi.org/10.24963/ijcai.2022/145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding spatial relations is essential for intelligent agents to act and communicate in the physical world. Relative directions are spatial relations that describe the relative positions of target objects with regard to the intrinsic orientation of reference objects. Grounding relative directions is more difficult than grounding absolute directions because it not only requires a model to detect objects in the image and to identify spatial relation based on this information, but it also needs to recognize the orientation of objects and integrate this information into the reasoning process. We investigate the challenging problem of grounding relative directions with end-to-end neural networks. To this end, we provide GRiD-3D, a novel dataset that features relative directions and complements existing visual question answering (VQA) datasets, such as CLEVR, that involve only absolute directions. We also provide baselines for the dataset with two established end-to-end VQA models. Experimental evaluations show that answering questions on relative directions is feasible when questions in the dataset simulate the necessary subtasks for grounding relative directions. We discover that those subtasks are learned in an order that reflects the steps of an intuitive pipeline for processing relative directions. Keywords: Computer Vision: Vision and language Machine Learning: Multi-modal learning Machine Learning: Relational Learning Natural Language Processing: Language Grounding Natural Language Processing: Question Answering},
  archive   = {C_IJCAI},
  author    = {Jae Hee Lee and Matthias Kerzel and Kyra Ahrens and Cornelius Weber and Stefan Wermter},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/145},
  pages     = {1039-1045},
  title     = {What is right for me is not yet right for you: A dataset for grounding relative directions via multi-task learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PlaceNet: Neural spatial representation learning with
multimodal attention. <em>IJCAI</em>, 1031–1038. (<a
href="https://doi.org/10.24963/ijcai.2022/144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Spatial representation capable of learning a myriad of environmental features is a significant challenge for natural spatial understanding of mobile AI agents. Deep generative models have the potential of discovering rich representations of observed 3D scenes. However, previous approaches have been mainly evaluated on simple environments, or focused only on high-resolution rendering of small-scale scenes, hampering generalization of the representations to various spatial variability. To address this, we present PlaceNet, a neural representation that learns through random observations in a self-supervised manner, and represents observed scenes with triplet attention using visual, topographic, and semantic cues. We evaluate the proposed method on a large-scale multimodal scene dataset consisting of 120 million indoor scenes, and show that PlaceNet successfully generalizes to various environments with lower training loss, higher image quality and structural similarity of predicted scenes, compared to a competitive baseline model. Additionally, analyses of the representations demonstrate that PlaceNet activates more specialized and larger numbers of kernels in the spatial representation, capturing multimodal spatial properties in complex environments. Keywords: Computer Vision: Scene analysis and understanding Humans and AI: Cognitive Systems Machine Learning: Multi-modal learning Machine Learning: Representation learning Robotics: Perception},
  archive   = {C_IJCAI},
  author    = {Chung-Yeon Lee and Youngjae Yoo and Byoung-Tak Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/144},
  pages     = {1031-1038},
  title     = {PlaceNet: Neural spatial representation learning with multimodal attention},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Beyond the prototype: Divide-and-conquer proxies for
few-shot segmentation. <em>IJCAI</em>, 1024–1030. (<a
href="https://doi.org/10.24963/ijcai.2022/143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Few-shot segmentation, which aims to segment unseen-class objects given only a handful of densely labeled samples, has received widespread attention from the community. Existing approaches typically follow the prototype learning paradigm to perform meta-inference, which fails to fully exploit the underlying information from support image-mask pairs, resulting in various segmentation failures, e.g., incomplete objects, ambiguous boundaries, and distractor activation. To this end, we propose a simple yet versatile framework in the spirit of divide-and-conquer. Specifically, a novel self-reasoning scheme is first implemented on the annotated support image, and then the coarse segmentation mask is divided into multiple regions with different properties. Leveraging effective masked average pooling operations, a series of support-induced proxies are thus derived, each playing a specific role in conquering the above challenges. Moreover, we devise a unique parallel decoder structure that integrates proxies with similar attributes to boost the discrimination power. Our proposed approach, named divide-and-conquer proxies (DCP), allows for the development of appropriate and reliable information as a guide at the “episode” level, not just about the object cues themselves. Extensive experiments on PASCAL-5i and COCO-20i demonstrate the superiority of DCP over conventional prototype-based approaches (up to 5~10\% on average), which also establishes a new state-of-the-art. Code is available at github.com/chunbolang/DCP. Keywords: Computer Vision: Segmentation Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Chunbo Lang and Binfei Tu and Gong Cheng and Junwei Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/143},
  pages     = {1024-1030},
  title     = {Beyond the prototype: Divide-and-conquer proxies for few-shot segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Attention-guided contrastive hashing for long-tailed image
retrieval. <em>IJCAI</em>, 1017–1023. (<a
href="https://doi.org/10.24963/ijcai.2022/142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Image hashing is to represent an image using a binary code for efficient storage and accurate retrieval. Recently, deep hashing methods have shown great improvements on ideally balanced datasets, however, long-tailed data is more common due to rare samples or data collection costs in the real world. Toward that end, this paper introduces a simple yet effective model named Attention-guided Contrastive Hashing Network (ACHNet) for long-tailed hashing. Specifically, a cross attention feature enhancement module is proposed to predict the importance of features for hashing, alleviating the loss of information originated from data dimension reduction. Moreover, unlike recently sota contrastive methods that focus on instance-level discrimination, we optimize an innovative category-centered contrastive hashing to obtain discriminative results, which is more suitable for long-tailed scenarios. Experiments on two popular benchmarks verify the superiority of the proposed method. Our code is available at: https://github.com/KUXN98/ACHNet. Keywords: Computer Vision: Image and Video retrieval Computer Vision: Recognition (object detection, categorization) Computer Vision: Representation Learning},
  archive   = {C_IJCAI},
  author    = {Xuan Kou and Chenghao Xu and Xu Yang and Cheng Deng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/142},
  pages     = {1017-1023},
  title     = {Attention-guided contrastive hashing for long-tailed image retrieval},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robustifying vision transformer without retraining from
scratch by test-time class-conditional feature alignment.
<em>IJCAI</em>, 1009–1016. (<a
href="https://doi.org/10.24963/ijcai.2022/141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Vision Transformer (ViT) is becoming more popular in image processing. Specifically, we investigate the effectiveness of test-time adaptation (TTA) on ViT, a technique that has emerged to correct its prediction during test-time by itself. First, we benchmark various test-time adaptation approaches on ViT-B16 and ViT-L16. It is shown that the TTA is effective on ViT and the prior-convention (sensibly selecting modulation parameters) is not necessary when using proper loss function. Based on the observation, we propose a new test-time adaptation method called class-conditional feature alignment (CFA), which minimizes both the class-conditional distribution differences and the whole distribution differences of the hidden representation between the source and target in an online manner. Experiments of image classification tasks on common corruption (CIFAR-10-C, CIFAR-100-C, and ImageNet-C) and domain adaptation (digits datasets and ImageNet-Sketch) show that CFA stably outperforms the existing baselines on various datasets. We also verify that CFA is model agnostic by experimenting on ResNet, MLP-Mixer, and several ViT variants (ViT-AugReg, DeiT, and BeiT). Using BeiT backbone, CFA achieves 19.8\% top-1 error rate on ImageNet-C, outperforming the existing test-time adaptation baseline 44.0\%. This is a state-of-the-art result among TTA methods that do not need to alter training phase. Keywords: Computer Vision: Recognition (object detection, categorization) Machine Learning: Robustness},
  archive   = {C_IJCAI},
  author    = {Takeshi Kojima and Yutaka Matsuo and Yusuke Iwasawa},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/141},
  pages     = {1009-1016},
  title     = {Robustifying vision transformer without retraining from scratch by test-time class-conditional feature alignment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online hybrid lightweight representations learning: Its
application to visual tracking. <em>IJCAI</em>, 1002–1008. (<a
href="https://doi.org/10.24963/ijcai.2022/140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents a novel hybrid representation learning framework for streaming data, where an image frame in a video is modeled by an ensemble of two distinct deep neural networks; one is a low-bit quantized network and the other is a lightweight full-precision network. The former learns coarse primary information with low cost while the latter conveys residual information for high fidelity to original representations. The proposed parallel architecture is effective to maintain complementary information since fixed-point arithmetic can be utilized in the quantized network and the lightweight model provides precise representations given by a compact channel-pruned network. We incorporate the hybrid representation technique into an online visual tracking task, where deep neural networks need to handle temporal variations of target appearances in real-time. Compared to the state-of-the-art real-time trackers based on conventional deep neural networks, our tracking algorithm demonstrates competitive accuracy on the standard benchmarks with a small fraction of computational cost and memory footprint. Keywords: Computer Vision: Representation Learning Computer Vision: Applications Computer Vision: Machine Learning for Vision Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Ilchae Jung and Minji Kim and Eunhyeok Park and Bohyung Han},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/140},
  pages     = {1002-1008},
  title     = {Online hybrid lightweight representations learning: Its application to visual tracking},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Domain generalization through the lens of angular
invariance. <em>IJCAI</em>, 995–1001. (<a
href="https://doi.org/10.24963/ijcai.2022/139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Domain generalization (DG) aims at generalizing a classifier trained on multiple source domains to an unseen target domain with domain shift. A common pervasive theme in existing DG literature is domain-invariant representation learning with various invariance assumptions. However, prior works restrict themselves to an impractical assumption for real-world challenges: If a mapping induced by a deep neural network (DNN) could align the source domains well, then such a mapping aligns a target domain as well. In this paper, we simply take DNNs as feature extractors to relax the requirement of distribution alignment. Specifically, we put forward a novel angular invariance and the accompanied norm shift assumption. Based on the proposed term of invariance, we propose a novel deep DG method dubbed Angular Invariance Domain Generalization Network (AIDGN). The optimization objective of AIDGN is developed with a von-Mises Fisher (vMF) mixture model. Extensive experiments on multiple DG benchmark datasets validate the effectiveness of the proposed AIDGN method. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Machine Learning for Vision Machine Learning: Classification},
  archive   = {C_IJCAI},
  author    = {Yujie Jin and Xu Chu and Yasha Wang and Wenwu Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/139},
  pages     = {995-1001},
  title     = {Domain generalization through the lens of angular invariance},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SatFormer: Saliency-guided abnormality-aware transformer for
retinal disease classification in fundus image. <em>IJCAI</em>, 987–994.
(<a href="https://doi.org/10.24963/ijcai.2022/138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Automatic and accurate retinal disease diagnosis is critical to guide proper therapy and prevent potential vision loss. Previous works simply exploit the most discriminative features while ignoring the pathological visual clues of scattered subtle lesions. Therefore, without a comprehensive understanding of features from different lesion regions, they are vulnerable to noise from complex backgrounds and suffer from misclassification failures. In this paper, we address these limitations with a novel saliency-guided abnormality-aware transformer which explicitly captures the correlation between different lesion features from a global perspective with enhanced pathological semantics. The model has several merits. First, we propose a saliency enhancement module (SEM) which adaptively integrates disease related semantics and highlights potentially salient lesion regions. Second, to the best of our knowledge, this is the first work to explore comprehensive lesion feature dependencies via a tailored efficient self-attention. Third, with the saliency enhancement module and abnormality-aware attention, we propose a new variant of Vision Transformer models, called SatFormer, which outperforms the state-of-the-art methods on two public retinal disease classification benchmarks. Ablation study shows that the proposed components can be easily embedded into any Vision Transformers via a plug-and-play manner and effectively boost the performance. Keywords: Computer Vision: Biomedical Image Analysis Machine Learning: Attention Models Machine Learning: Classification Machine Learning: Convolutional Networks Multidisciplinary Topics and Applications: Bioinformatics},
  archive   = {C_IJCAI},
  author    = {Yankai Jiang and Ke Xu and Xinyue Wang and Yuan Li and Hongguang Cui and Yubo Tao and Hai Lin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/138},
  pages     = {987-994},
  title     = {SatFormer: Saliency-guided abnormality-aware transformer for retinal disease classification in fundus image},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). DANet: Image deraining via dynamic association learning.
<em>IJCAI</em>, 980–986. (<a
href="https://doi.org/10.24963/ijcai.2022/137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Rain streaks and background components in a rainy input are highly correlated, making the deraining task a composition of the rain streak removal and background restoration. However, the correlation of these two components is barely considered, leading to unsatisfied deraining results. To this end, we propose a dynamic associated network (DANet) to achieve the association learning between rain streak removal and background recovery. There are two key aspects to fulfill the association learning: 1) DANet unveils the latent association knowledge between rain streak prediction and background texture recovery, and leverages it as an extra prior via an associated learning module (ALM) to promote the texture recovery. 2) DANet introduces the parametric association constraint for enhancing the compatibility of deraining model with background reconstruction, enabling it to be automatically learned from the training data. Moreover, we observe that the sampled rainy image enjoys the similar distribution to the original one. We thus propose to learn the rain distribution at the sampling space, and exploit super-resolution to reconstruct high-frequency background details for computation and memory reduction. Our proposed DANet achieves the approximate deraining performance to the state-of-the-art MPRNet but only requires 52.6\% and 23\% inference time and computational cost, respectively. Keywords: Computer Vision: Computational photography Computer Vision: Applications Computer Vision: Other},
  archive   = {C_IJCAI},
  author    = {Kui Jiang and Zhongyuan Wang and Zheng Wang and Peng Yi and Junjun Jiang and Jinsheng Xiao and Chia-Wen Lin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/137},
  pages     = {980-986},
  title     = {DANet: Image deraining via dynamic association learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AQT: Adversarial query transformers for domain adaptive
object detection. <em>IJCAI</em>, 972–979. (<a
href="https://doi.org/10.24963/ijcai.2022/136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial feature alignment is widely used in domain adaptive object detection. Despite the effectiveness on CNN-based detectors, its applicability to transformer-based detectors is less studied. In this paper, we present AQT (adversarial query transformers) to integrate adversarial feature alignment into detection transformers. The generator is a detection transformer which yields a sequence of feature tokens, and the discriminator consists of a novel adversarial token and a stack of cross-attention layers. The cross-attention layers take the adversarial token as the query and the feature tokens from the generator as the key-value pairs. Through adversarial learning, the adversarial token in the discriminator attends to the domain-specific feature tokens, while the generator produces domain-invariant features, especially on the attended tokens, hence realizing adversarial feature alignment on transformers. Thorough experiments over several domain adaptive object detection benchmarks demonstrate that our approach performs favorably against the state-of-the-art methods. Source code is available at https://github.com/weii41392/AQT. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Wei-Jie Huang and Yu-Lin Lu and Shih-Yao Lin and Yusheng Xie and Yen-Yu Lin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/136},
  pages     = {972-979},
  title     = {AQT: Adversarial query transformers for domain adaptive object detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ScaleFormer: Revisiting the transformer-based backbones from
a scale-wise perspective for medical image segmentation. <em>IJCAI</em>,
964–971. (<a href="https://doi.org/10.24963/ijcai.2022/135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, a variety of vision transformers have been developed as their capability of modeling long-range dependency. In current transformer-based backbones for medical image segmentation, convolutional layers were replaced with pure transformers, or transformers were added to the deepest encoder to learn global context. However, there are mainly two challenges in a scale-wise perspective: (1) intra-scale problem: the existing methods lacked in extracting local-global cues in each scale, which may impact the signal propagation of small objects; (2) inter-scale problem: the existing methods failed to explore distinctive information from multiple scales, which may hinder the representation learning from objects with widely variable size, shape and location. To address these limitations, we propose a novel backbone, namely ScaleFormer, with two appealing designs: (1) A scale-wise intra-scale transformer is designed to couple the CNN-based local features with the transformer-based global cues in each scale, where the row-wise and column-wise global dependencies can be extracted by a lightweight Dual-Axis MSA. (2) A simple and effective spatial-aware inter-scale transformer is designed to interact among consensual regions in multiple scales, which can highlight the cross-scale dependency and resolve the complex scale variations. Experimental results on different benchmarks demonstrate that our Scale-Former outperforms the current state-of-the-art methods. The code is publicly available at: https://github.com/ZJUGiveLab/ScaleFormer. Keywords: Computer Vision: Segmentation Computer Vision: Biomedical Image Analysis},
  archive   = {C_IJCAI},
  author    = {Huimin Huang and Shiao Xie and Lanfen Lin and Yutaro Iwamoto and Xian-Hua Han and Yen-Wei Chen and Ruofeng Tong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/135},
  pages     = {964-971},
  title     = {ScaleFormer: Revisiting the transformer-based backbones from a scale-wise perspective for medical image segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Semantic compression embedding for generative zero-shot
learning. <em>IJCAI</em>, 956–963. (<a
href="https://doi.org/10.24963/ijcai.2022/134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generative methods have been successfully applied in zero-shot learning (ZSL) by learning an implicit mapping to alleviate the visual-semantic domain gaps and synthesizing unseen samples to handle the data imbalance between seen and unseen classes. However, existing generative methods simply use visual features extracted by the pre-trained CNN backbone. These visual features lack attribute-level semantic information. Consequently, seen classes are indistinguishable, and the knowledge transfer from seen to unseen classes is limited. To tackle this issue, we propose a novel Semantic Compression Embedding Guided Generation (SC-EGG) model, which cascades a semantic compression embedding network (SCEN) and an embedding guided generative network (EGGN). The SCEN extracts a group of attribute-level local features for each sample and further compresses them into the new low-dimension visual feature. Thus, a dense-semantic visual space is obtained. The EGGN learns a mapping from the class-level semantic space to the dense-semantic visual space, thus improving the discriminability of the synthesized dense-semantic unseen visual features. Extensive experiments on three benchmark datasets, i.e., CUB, SUN and AWA2, demonstrate the signiﬁcant performance gains of SC-EGG over current state-of-the-art methods and its baselines. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Ziming Hong and Shiming Chen and Guo-Sen Xie and Wenhan Yang and Jian Zhao and Yuanjie Shao and Qinmu Peng and Xinge You},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/134},
  pages     = {956-963},
  title     = {Semantic compression embedding for generative zero-shot learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Self-supervised semantic segmentation grounded in visual
concepts. <em>IJCAI</em>, 949–955. (<a
href="https://doi.org/10.24963/ijcai.2022/133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Unsupervised semantic segmentation requires assigning a label to every pixel without any human annotations. Despite recent advances in self-supervised representation learning for individual images, unsupervised semantic segmentation with pixel-level representations is still a challenging task and remains underexplored. In this work, we propose a self-supervised pixel representation learning method for semantic segmentation by using visual concepts (i.e., groups of pixels with semantic meanings, such as parts, objects, and scenes) extracted from images. To guide self-supervised learning, we leverage three types of relationships between pixels and concepts, including the relationships between pixels and local concepts, local and global concepts, as well as the co-occurrence of concepts. We evaluate the learned pixel embeddings and visual concepts on three datasets, including PASCAL VOC 2012, COCO 2017, and DAVIS 2017. Our results show that the proposed method gains consistent and substantial improvements over recent unsupervised semantic segmentation approaches, and also demonstrate that visual concepts can reveal insights into image datasets. Keywords: Computer Vision: Segmentation AI Ethics, Trust, Fairness: Explainability and Interpretability Computer Vision: Interpretability and Transparency Computer Vision: Representation Learning Machine Learning: Self-supervised Learning},
  archive   = {C_IJCAI},
  author    = {Wenbin He and William Surmeier and Arvind Kumar Shekar and Liang Gou and Liu Ren},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/133},
  pages     = {949-955},
  title     = {Self-supervised semantic segmentation grounded in visual concepts},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Rethinking image aesthetics assessment: Models, datasets and
benchmarks. <em>IJCAI</em>, 942–948. (<a
href="https://doi.org/10.24963/ijcai.2022/132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Challenges in image aesthetics assessment (IAA) arise from that images of different themes correspond to different evaluation criteria, and learning aesthetics directly from images while ignoring the impact of theme variations on human visual perception inhibits the further development of IAA; however, existing IAA datasets and models overlook this problem. To address this issue, we show that a theme-oriented dataset and model design are effective for IAA. Specifically, 1) we elaborately build a novel dataset, called TAD66K, that contains 66K images covering 47 popular themes, and each image is densely annotated by more than 1200 people with dedicated theme evaluation criteria. 2) We develop a baseline model, TANet, which can effectively extract theme information and adaptively establish perception rules to evaluate images with different themes. 3) We develop a large-scale benchmark (the most comprehensive thus far) by comparing 17 methods with TANet on three representative datasets: AVA, FLICKR-AES and the proposed TAD66K, TANet achieves state-of-the-art performance on all three datasets. Our work offers the community an opportunity to explore more challenging directions; the code, dataset and supplementary material are available at https://github.com/woshidandan/TANet. Keywords: Computer Vision: Computational photography Computer Vision: Machine Learning for Vision Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Shuai He and Yongchang Zhang and Rui Xie and Dongxiang Jiang and Anlong Ming},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/132},
  pages     = {942-948},
  title     = {Rethinking image aesthetics assessment: Models, datasets and benchmarks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring fourier prior for single image rain removal.
<em>IJCAI</em>, 935–941. (<a
href="https://doi.org/10.24963/ijcai.2022/131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Deep convolutional neural networks (CNNs) have become dominant in the task of single image rain removal. Most of current CNN methods, however, suffer from the problem of overfitting on one single synthetic dataset as they neglect the intrinsic prior of the physical properties of rain streaks. To address this issue, we propose a simple but effective prior - Fourier prior to improve the generalization ability of an image rain removal model. The Fourier prior is a kind of property of rainy images. It is based on a key observation of us - replacing the Fourier amplitude of rainy images with that of clean images greatly suppresses the synthetic and real-world rain streaks. This means the amplitude contains most of the rain streak information and the phase keeps the similar structures of the background. So it is natural for single image rain removal to process the amplitude and phase information of the rainy images separately. In this paper, we develop a two-stage model where the first stage restores the amplitude of rainy images to clean rain streaks, and the second stage restores the phase information to refine fine-grained background structures. Extensive experiments on synthetic rainy data demonstrate the power of Fourier prior. Moreover, when trained on synthetic data, a robust generalization ability to real-world images can also be obtained. The code will be publicly available at https://github.com/willinglucky/ExploringFourier-Prior-for-Single-Image-Rain-Removal. Keywords: Computer Vision: Computational photography},
  archive   = {C_IJCAI},
  author    = {Xin Guo and Xueyang Fu and Man Zhou and Zhen Huang and Jialun Peng and Zheng-Jun Zha},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/131},
  pages     = {935-941},
  title     = {Exploring fourier prior for single image rain removal},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning target-aware representation for visual tracking via
informative interactions. <em>IJCAI</em>, 927–934. (<a
href="https://doi.org/10.24963/ijcai.2022/130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce a novel backbone architecture to improve target-perception ability of feature representation for tracking. Having observed de facto frameworks perform feature matching simply using the backbone outputs for target localization, there is no direct feedback from the matching module to the backbone network, especially the shallow layers. Concretely, only the matching module can directly access the target information, while the representation learning of candidate frame is blind to the reference target. Therefore, the accumulated target-irrelevant interference in shallow stages may degrade the feature quality of deeper layers. In this paper, we approach the problem by conducting multiple branch-wise interactions inside the Siamese-like backbone networks (InBN). The core of InBN is a general interaction modeler (GIM) that injects the target information to different stages of the backbone network, leading to better target-perception of candidate feature representation with negligible computation cost. The proposed GIM module and InBN mechanism are general and applicable to different backbone types including CNN and Transformer for improvements, as evidenced on multiple benchmarks. In particular, the CNN version improves the baseline with 3.2/6.9 absolute gains of SUC on LaSOT/TNL2K. The Transformer version obtains SUC of 65.7/52.0 on LaSOT/TNL2K, which are on par with recent SOTAs. Keywords: Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Mingzhe Guo and Zhipeng Zhang and Heng Fan and Liping Jing and Yilin Lyu and Bing Li and Weiming Hu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/130},
  pages     = {927-934},
  title     = {Learning target-aware representation for visual tracking via informative interactions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Region-aware temporal inconsistency learning for DeepFake
video detection. <em>IJCAI</em>, 920–926. (<a
href="https://doi.org/10.24963/ijcai.2022/129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The rapid development of face forgery techniques has drawn growing attention due to security concerns. Existing deepfake video detection methods always attempt to capture the discriminative features by directly exploiting static temporal convolution to mine temporal inconsistency, without explicit exploration on the diverse temporal dynamics of different forged regions. To effectively and comprehensively capture the various inconsistency, in this paper, we propose a novel Region-Aware Temporal Filter (RATF) module which automatically generates corresponding temporal filters for different spatial regions. Specifically, we decouple the dynamic temporal kernel into a set of region-agnostic basic filters and region-sensitive aggregation weights. And different weights guide the corresponding regions to adaptively learn temporal inconsistency, which greatly enhances the overall representational ability. Moreover, to cover the long-term temporal dynamics, we divide the video into multiple snippets and propose a Cross-Snippet Attention (CSA) to promote the cross-snippet information interaction. Extensive experiments and visualizations on several benchmarks demonstrate the effectiveness of our method against state-of-the-art competitors. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition},
  archive   = {C_IJCAI},
  author    = {Zhihao Gu and Taiping Yao and Yang Chen and Ran Yi and Shouhong Ding and Lizhuang Ma},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/129},
  pages     = {920-926},
  title     = {Region-aware temporal inconsistency learning for DeepFake video detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Lightweight bimodal network for single-image
super-resolution via symmetric CNN and recursive transformer.
<em>IJCAI</em>, 913–919. (<a
href="https://doi.org/10.24963/ijcai.2022/128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Single-image super-resolution (SISR) has achieved significant breakthroughs with the development of deep learning. However, these methods are difficult to be applied in real-world scenarios since they are inevitably accompanied by the problems of computational and memory costs caused by the complex operations. To solve this issue, we propose a Lightweight Bimodal Network (LBNet) for SISR. Specifically, an effective Symmetric CNN is designed for local feature extraction and coarse image reconstruction. Meanwhile, we propose a Recursive Transformer to fully learn the long-term dependence of images thus the global information can be fully used to further refine texture details. Studies show that the hybrid of CNN and Transformer can build a more efficient model. Extensive experiments have proved that our LBNet achieves more prominent performance than other state-of-the-art methods with a relatively low computational cost and memory consumption. The code is available at https://github.com/IVIPLab/LBNet. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Computational photography Computer Vision: Representation Learning Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Guangwei Gao and Zhengxue Wang and Juncheng Li and Wenjie Li and Yi Yu and Tieyong Zeng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/128},
  pages     = {913-919},
  title     = {Lightweight bimodal network for single-image super-resolution via symmetric CNN and recursive transformer},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SparseTT: Visual tracking with sparse transformers.
<em>IJCAI</em>, 905–912. (<a
href="https://doi.org/10.24963/ijcai.2022/127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformers have been successfully applied to the visual tracking task and significantly promote tracking performance. The self-attention mechanism designed to model long-range dependencies is the key to the success of Transformers. However, self-attention lacks focusing on the most relevant information in the search regions, making it easy to be distracted by background. In this paper, we relieve this issue with a sparse attention mechanism by focusing the most relevant information in the search regions, which enables a much accurate tracking. Furthermore, we introduce a double-head predictor to boost the accuracy of foreground-background classification and regression of target bounding boxes, which further improve the tracking performance. Extensive experiments show that, without bells and whistles, our method significantly outperforms the state-of-the-art approaches on LaSOT, GOT-10k, TrackingNet, and UAV123, while running at 40 FPS. Notably, the training time of our method is reduced by 75\% compared to that of TransT. The source code and models are available at https://github.com/fzh0917/SparseTT. Keywords: Computer Vision: Motion and Tracking},
  archive   = {C_IJCAI},
  author    = {Zhihong Fu and Zehua Fu and Qingjie Liu and Wenrui Cai and Yunhong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/127},
  pages     = {905-912},
  title     = {SparseTT: Visual tracking with sparse transformers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). D-DPCC: Deep dynamic point cloud compression via 3D motion
prediction. <em>IJCAI</em>, 898–904. (<a
href="https://doi.org/10.24963/ijcai.2022/126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The non-uniformly distributed nature of the 3D Dynamic Point Cloud (DPC) brings significant challenges to its high-efficient inter-frame compression. This paper proposes a novel 3D sparse convolution-based Deep Dynamic Point Cloud Compression (D-DPCC) network to compensate and compress the DPC geometry with 3D motion estimation and motion compensation in the feature space. In the proposed D-DPCC network, we design a Multi-scale Motion Fusion (MMF) module to accurately estimate the 3D optical flow between the feature representations of adjacent point cloud frames. Specifically, we utilize a 3D sparse convolution-based encoder to obtain the latent representation for motion estimation in the feature space and introduce the proposed MMF module for fused 3D motion embedding. Besides, for motion compensation, we propose a 3D Adaptively Weighted Interpolation (3DAWI) algorithm with a penalty coefficient to adaptively decrease the impact of distant neighbours. We compress the motion embedding and the residual with a lossy autoencoder-based network. To our knowledge, this paper is the first work proposing an end-to-end deep dynamic point cloud compression framework. The experimental result shows that the proposed D-DPCC framework achieves an average 76\% BD-Rate (Bjontegaard Delta Rate) gains against state-of-the-art Video-based Point Cloud Compression (V-PCC) v13 in inter mode. Keywords: Computer Vision: Computational photography Computer Vision: 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Tingyu Fan and Linyao Gao and Yiling Xu and Zhu Li and Dong Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/126},
  pages     = {898-904},
  title     = {D-DPCC: Deep dynamic point cloud compression via 3D motion prediction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learning coated adversarial camouflages for object
detectors. <em>IJCAI</em>, 891–897. (<a
href="https://doi.org/10.24963/ijcai.2022/125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An adversary can fool deep neural network object detectors by generating adversarial noises. Most of the existing works focus on learning local visible noises in an adversarial &quot;patch&quot; fashion. However, the 2D patch attached to a 3D object tends to suffer from an inevitable reduction in attack performance as the viewpoint changes. To remedy this issue, this work proposes the Coated Adversarial Camouflage (CAC) to attack the detectors in arbitrary viewpoints. Unlike the patch trained in the 2D space, our camouflage generated by a conceptually different training framework consists of 3D rendering and dense proposals attack. Specifically, we make the camouflage perform 3D spatial transformations according to the pose changes of the object. Based on the multi-view rendering results, the top-n proposals of the region proposal network are fixed, and all the classifications in the fixed dense proposals are attacked simultaneously to output errors. In addition, we build a virtual 3D scene to fairly and reproducibly evaluate different attacks. Extensive experiments demonstrate the superiority of CAC over the existing attacks, and it shows impressive performance both in the virtual scene and the real world. This poses a potential threat to the security-critical computer vision systems. Keywords: Computer Vision: Adversarial learning, adversarial attack and defense methods Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Yexin Duan and Jialin Chen and Xingyu Zhou and Junhua Zou and Zhengyun He and Jin Zhang and Wu Zhang and Zhisong Pan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/125},
  pages     = {891-897},
  title     = {Learning coated adversarial camouflages for object detectors},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SVTR: Scene text recognition with a single visual model.
<em>IJCAI</em>, 884–890. (<a
href="https://doi.org/10.24963/ijcai.2022/124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Dominant scene text recognition models commonly contain two building blocks, a visual model for feature extraction and a sequence model for text transcription. This hybrid architecture, although accurate, is complex and less efficient. In this study, we propose a Single Visual model for Scene Text recognition within the patch-wise image tokenization framework, which dispenses with the sequential modeling entirely. The method, termed SVTR, firstly decomposes an image text into small patches named character components. Afterward, hierarchical stages are recurrently carried out by component-level mixing, merging and/or combining. Global and local mixing blocks are devised to perceive the inter-character and intra-character patterns, leading to a multi-grained character component perception. Thus, characters are recognized by a simple linear prediction. Experimental results on both English and Chinese scene text recognition tasks demonstrate the effectiveness of SVTR. SVTR-L (Large) achieves highly competitive accuracy in English and outperforms existing methods by a large margin in Chinese, while running faster. In addition, SVTR-T (Tiny) is an effective and much smaller model, which shows appealing speed at inference. The code is publicly available at https://github.com/PaddlePaddle/PaddleOCR. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Yongkun Du and Zhineng Chen and Caiyan Jia and Xiaoting Yin and Tianlun Zheng and Chenxia Li and Yuning Du and Yu-Gang Jiang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/124},
  pages     = {884-890},
  title     = {SVTR: Scene text recognition with a single visual model},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). ICGNet: Integration context-based reverse-contour guidance
network for polyp segmentation. <em>IJCAI</em>, 877–883. (<a
href="https://doi.org/10.24963/ijcai.2022/123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Precise segmentation of polyps from colonoscopic images is extremely significant for the early diagnosis and treatment of colorectal cancer. However, it is still a challenging task due to: (1)the boundary between the polyp and the background is blurred makes delineation difficult; (2)the various size and shapes causes feature representation of polyps difficult. In this paper, we propose an integration context-based reverse-contour guidance network (ICGNet) to solve these challenges. The ICGNet firstly utilizes a reverse-contour guidance module to aggregate low-level edge detail information and meanwhile constraint reverse region. Then, the newly designed adaptive context module is used to adaptively extract local-global information of the current layer and complementary information of the previous layer to get larger and denser features. Lastly, an innovative hybrid pyramid pooling fusion module fuses the multi-level features generated from the decoder in the case of considering salient features and less background. Our proposed approach is evaluated on the EndoScene, Kvasir-SEG and CVC-ColonDB datasets with eight evaluation metrics, and gives competitive results compared with other state-of-the-art methods in both learning ability and generalization capability. Keywords: Computer Vision: Biomedical Image Analysis Computer Vision: Segmentation Multidisciplinary Topics and Applications: Health and Medicine},
  archive   = {C_IJCAI},
  author    = {Xiuquan Du and Xuebin Xu and Kunpeng Ma},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/123},
  pages     = {877-883},
  title     = {ICGNet: Integration context-based reverse-contour guidance network for polyp segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MNet: Rethinking 2D/3D networks for anisotropic medical
image segmentation. <em>IJCAI</em>, 870–876. (<a
href="https://doi.org/10.24963/ijcai.2022/122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The nature of thick-slice scanning causes severe inter-slice discontinuities of 3D medical images, and the vanilla 2D/3D convolutional neural networks (CNNs) fail to represent sparse inter-slice information and dense intra-slice information in a balanced way, leading to severe underfitting to inter-slice features (for vanilla 2D CNNs) and overfitting to noise from long-range slices (for vanilla 3D CNNs). In this work, a novel mesh network (MNet) is proposed to balance the spatial representation inter axes via learning. 1) Our MNet latently fuses plenty of representation processes by embedding multi-dimensional convolutions deeply into basic modules, making the selections of representation processes flexible, thus balancing representation for sparse inter-slice information and dense intra-slice information adaptively. 2) Our MNet latently fuses multi-dimensional features inside each basic module, simultaneously taking the advantages of 2D (high segmentation accuracy of the easily recognized regions in 2D view) and 3D (high smoothness of 3D organ contour) representations, thus obtaining more accurate modeling for target regions. Comprehensive experiments are performed on four public datasets (CT\&amp;MR), the results consistently demonstrate the proposed MNet outperforms the other methods. The code and datasets are available at: https://github.com/zfdong-code/MNet Keywords: Computer Vision: Biomedical Image Analysis Computer Vision: Segmentation Computer Vision: 3D Computer Vision},
  archive   = {C_IJCAI},
  author    = {Zhangfu Dong and Yuting He and Xiaoming Qi and Yang Chen and Huazhong Shu and Jean-Louis Coatrieux and Guanyu Yang and Shuo Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/122},
  pages     = {870-876},
  title     = {MNet: Rethinking 2D/3D networks for anisotropic medical image segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Region-aware metric learning for open world semantic
segmentation via meta-channel aggregation. <em>IJCAI</em>, 863–869. (<a
href="https://doi.org/10.24963/ijcai.2022/121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As one of the most challenging and practical segmentation tasks, open-world semantic segmentation requires the model to segment the anomaly regions in the images and incrementally learn to segment out-of-distribution (OOD) objects, especially under a few-shot condition. The current state-of-the-art (SOTA) method, Deep Metric Learning Network (DMLNet), relies on pixel-level metric learning, with which the identification of similar regions having different semantics is difficult. Therefore, we propose a method called region-aware metric learning (RAML), which first separates the regions of the images and generates region-aware features for further metric learning. RAML improves the integrity of the segmented anomaly regions. Moreover, we propose a novel meta-channel aggregation (MCA) module to further separate anomaly regions, forming high-quality sub-region candidates and thereby improving the model performance for OOD objects. To evaluate the proposed RAML, we have conducted extensive experiments and ablation studies on Lost And Found and Road Anomaly datasets for anomaly segmentation and the CityScapes dataset for incremental few-shot learning. The results show that the proposed RAML achieves SOTA performance in both stages of open world segmentation. Our code and appendix are available at https://github.com/czifan/RAML. Keywords: Computer Vision: Segmentation Computer Vision: Representation Learning Computer Vision: Transfer, low-shot, semi- and un- supervised learning},
  archive   = {C_IJCAI},
  author    = {Hexin Dong and Zifan Chen and Mingze Yuan and Yutong Xie and Jie Zhao and Fei Yu and Bin Dong and Li Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/121},
  pages     = {863-869},
  title     = {Region-aware metric learning for open world semantic segmentation via meta-channel aggregation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I²R-net: Intra- and inter-human relation network for
multi-person pose estimation. <em>IJCAI</em>, 855–862. (<a
href="https://doi.org/10.24963/ijcai.2022/120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we present the Intra- and Inter-Human Relation Networks I²R-Net for Multi-Person Pose Estimation. It involves two basic modules. First, the Intra-Human Relation Module operates on a single person and aims to capture Intra-Human dependencies. Second, the Inter-Human Relation Module considers the relation between multiple instances and focuses on capturing Inter-Human interactions. The Inter-Human Relation Module can be designed very lightweight by reducing the resolution of feature map, yet learn useful relation information to significantly boost the performance of the Intra-Human Relation Module. Even without bells and whistles, our method can compete or outperform current competition winners. We conduct extensive experiments on COCO, CrowdPose, and OCHuman datasets. The results demonstrate that the proposed model surpasses all the state-of-the-art methods. Concretely, the proposed method achieves 77.4\% AP on CrowPose dataset and 67.8\% AP on OCHuman dataset respectively, outperforming existing methods by a large margin. Additionally, the ablation study and visualization analysis also prove the effectiveness of our model. Keywords: Computer Vision: Biometrics, Face, Gesture and Pose Recognition Computer Vision: Action and Behaviour Recognition Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {Yiwei Ding and Wenjin Deng and Yinglin Zheng and Pengfei Liu and Meihong Wang and Xuan Cheng and Jianmin Bao and Dong Chen and Ming Zeng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/120},
  pages     = {855-862},
  title     = {I²R-net: Intra- and inter-human relation network for multi-person pose estimation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust single image dehazing based on consistent and
contrast-assisted reconstruction. <em>IJCAI</em>, 848–854. (<a
href="https://doi.org/10.24963/ijcai.2022/119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Single image dehazing as a fundamental low-level vision task, is essential for the development of robust intelligent surveillance system. In this paper, we make an early effort to consider dehazing robustness under variational haze density, which is a realistic while under-studied problem in the research filed of singe image dehazing. To properly address this problem, we propose a novel density-variational learning framework to improve the robustness of the image dehzing model assisted by a variety of negative hazy images, to better deal with various complex hazy scenarios. Specifically, the dehazing network is optimized under the consistency-regularized framework with the proposed Contrast-Assisted Reconstruction Loss (CARL). The CARL can fully exploit the negative information to facilitate the traditional positive-orient dehazing objective function, by squeezing the dehazed image to its clean target from different directions. Meanwhile, the consistency regularization keeps consistent outputs given multi-level hazy images, thus improving the model robustness. Extensive experimental results on two synthetic and three real-world datasets demonstrate that our method significantly surpasses the state-of-the-art approaches. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Structural and Model-Based Approaches, Knowledge Representation and Reasoning Computer Vision: Visual reasoning and symbolic representation Computer Vision: Recognition (object detection, categorization)},
  archive   = {C_IJCAI},
  author    = {De Cheng and Yan Li and Dingwen Zhang and Nannan Wang and Xinbo Gao and Jiande Sun},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/119},
  pages     = {848-854},
  title     = {Robust single image dehazing based on consistent and contrast-assisted reconstruction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SpanConv: A new convolution via spanning kernel space for
lightweight pansharpening. <em>IJCAI</em>, 841–847. (<a
href="https://doi.org/10.24963/ijcai.2022/118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Standard convolution operations can effectively perform feature extraction and representation but result in high computational cost, largely due to the generation of the original convolution kernel corresponding to the channel dimension of the feature map, which will cause unnecessary redundancy. In this paper, we focus on kernel generation and present an interpretable span strategy, named SpanConv, for the effective construction of kernel space. Specifically, we first learn two navigated kernels with single channel as bases, then extend the two kernels by learnable coefficients, and finally span the two sets of kernels by their linear combination to construct the so-called SpanKernel. The proposed SpanConv is realized by replacing plain convolution kernel by SpanKernel. To verify the effectiveness of SpanConv, we design a simple network with SpanConv. Experiments demonstrate the proposed network significantly reduces parameters comparing with benchmark networks for remote sensing pansharpening, while achieving competitive performance and excellent generalization. Code is available at https://github.com/zhi-xuan-chen/IJCAI-2022 SpanConv. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Computational photography Machine Learning: Applications Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Zhi-Xuan Chen and Cheng Jin and Tian-Jing Zhang and Xiao Wu and Liang-Jian Deng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/118},
  pages     = {841-847},
  title     = {SpanConv: A new convolution via spanning kernel space for lightweight pansharpening},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Unsupervised multi-modal medical image registration via
discriminator-free image-to-image translation. <em>IJCAI</em>, 834–840.
(<a href="https://doi.org/10.24963/ijcai.2022/117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In clinical practice, well-aligned multi-modal images, such as Magnetic Resonance (MR) and Computed Tomography (CT), together can provide complementary information for image-guided therapies. Multi-modal image registration is essential for the accurate alignment of these multi-modal images. However, it remains a very challenging task due to complicated and unknown spatial correspondence between different modalities. In this paper, we propose a novel translation-based unsupervised deformable image registration approach to convert the multi-modal registration problem to a mono-modal one. Specifically, our approach incorporates a discriminator-free translation network to facilitate the training of the registration network and a patchwise contrastive loss to encourage the translation network to preserve object shapes. Furthermore, we propose to replace an adversarial loss, that is widely used in previous multi-modal image registration methods, with a pixel loss in order to integrate the output of translation into the target modality. This leads to an unsupervised method requiring no ground-truth deformation or pairs of aligned images for training. We evaluate four variants of our approach on the public Learn2Reg 2021 datasets. The experimental results demonstrate that the proposed architecture achieves state-of-the-art performance. Our code is available at https://github.com/heyblackC/DFMIR. Keywords: Computer Vision: Biomedical Image Analysis Machine Learning: Multi-modal learning Machine Learning: Unsupervised Learning},
  archive   = {C_IJCAI},
  author    = {Zekang Chen and Jia Wei and Rui Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/117},
  pages     = {834-840},
  title     = {Unsupervised multi-modal medical image registration via discriminator-free image-to-image translation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AutoAlign: Pixel-instance feature aggregation for
multi-modal 3D object detection. <em>IJCAI</em>, 827–833. (<a
href="https://doi.org/10.24963/ijcai.2022/116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Object detection through either RGB images or the LiDAR point clouds has been extensively explored in autonomous driving. However, it remains challenging to make these two data sources complementary and beneficial to each other. In this paper, we propose AutoAlign, an automatic feature fusion strategy for 3D object detection. Instead of establishing deterministic correspondence with camera projection matrix, we model the mapping relationship between the image and point clouds with a learnable alignment map. This map enables our model to automate the alignment of non-homogenous features in a dynamic and data-driven manner. Specifically, a cross-attention feature alignment module is devised to adaptively aggregate pixel-level image features for each voxel. To enhance the semantic consistency during feature alignment, we also design a self-supervised cross-modal feature interaction module, through which the model can learn feature aggregation with instance-level feature guidance. Extensive experimental results show that our approach can lead to 2.3 mAP and 7.0 mAP improvements on the KITTI and nuScenes datasets respectively. Notably, our best model reaches 70.9 NDS on the nuScenes testing leaderboard, achieving competitive performance among various state-of-the-arts. Keywords: Computer Vision: Recognition (object detection, categorization) Computer Vision: 3D Computer Vision Machine Learning: Multi-modal learning},
  archive   = {C_IJCAI},
  author    = {Zehui Chen and Zhenyu Li and Shiquan Zhang and Liangji Fang and Qinhong Jiang and Feng Zhao and Bolei Zhou and Hang Zhao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/116},
  pages     = {827-833},
  title     = {AutoAlign: Pixel-instance feature aggregation for multi-modal 3D object detection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Uncertainty-aware representation learning for action
segmentation. <em>IJCAI</em>, 820–826. (<a
href="https://doi.org/10.24963/ijcai.2022/115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper, we propose an uncertainty-aware representation Learning (UARL) method for action segmentation. Most existing action segmentation methods exploit continuity information of the action period to predict frame-level labels, which ignores the temporal ambiguity of the transition region between two actions. Moreover, similar periods of different actions, e.g., the beginning of some actions, will confuse the network if they are annotated with different labels, which causes spatial ambiguity. To address this, we design the UARL to exploit the transitional expression between two action periods by uncertainty learning. Specially, we model every frame of actions with an active distribution that represents the probabilities of different actions, which captures the uncertainty of the action and exploits the tendency during the action. We evaluate our method on three popular action prediction datasets: Breakfast, Georgia Tech Egocentric Activities (GTEA), and 50Salads. The experimental results demonstrate that our method achieves the performance with state-of-the-art. Keywords: Computer Vision: Action and Behaviour Recognition},
  archive   = {C_IJCAI},
  author    = {Lei Chen and Muheng Li and Yueqi Duan and Jie Zhou and Jiwen Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/115},
  pages     = {820-826},
  title     = {Uncertainty-aware representation learning for action segmentation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Zero-shot logit adjustment. <em>IJCAI</em>, 813–819. (<a
href="https://doi.org/10.24963/ijcai.2022/114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Semantic-descriptor-based Generalized Zero-Shot Learning (GZSL) poses challenges in recognizing novel classes in the test phase. The development of generative models enables current GZSL techniques to probe further into the semantic-visual link, culminating in a two-stage form that includes a generator and a classifier. However, existing generation-based methods focus on enhancing the generator&#39;s effect while neglecting the improvement of the classifier. In this paper, we first analyze of two properties of the generated pseudo unseen samples: bias and homogeneity. Then, we perform variational Bayesian inference to back-derive the evaluation metrics, which reflects the balance of the seen and unseen classes. As a consequence of our derivation, the aforementioned two properties are incorporated into the classifier training as seen-unseen priors via logit adjustment. The Zero-Shot Logit Adjustment further puts semantic-based classifiers into effect in generation-based GZSL. Our experiments demonstrate that the proposed technique achieves state-of-the-art when combined with the basic generator, and it can improve various generative Zero-Shot Learning frameworks. Our codes are available on https://github.com/cdb342/IJCAI-2022-ZLA. Keywords: Computer Vision: Transfer, low-shot, semi- and un- supervised learning Computer Vision: Recognition (object detection, categorization) Computer Vision: Vision and language},
  archive   = {C_IJCAI},
  author    = {Dubing Chen and Yuming Shen and Haofeng Zhang and Philip H.S. Torr},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/114},
  pages     = {813-819},
  title     = {Zero-shot logit adjustment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). KPN-MFI: A kernel prediction network with multi-frame
interaction for video inverse tone mapping. <em>IJCAI</em>, 806–812. (<a
href="https://doi.org/10.24963/ijcai.2022/113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Up to now, the image-based inverse tone mapping (iTM) models have been widely investigated, while there is little research on video-based iTM methods. It would be interesting to make use of these existing image-based models in the video iTM task. However, directly transferring the imagebased iTM models to video data without modeling spatial-temporal information remains nontrivial and challenging. Considering both the intra-frame quality and the inter-frame consistency of a video, this article presents a new video iTM method based on a kernel prediction network (KPN), which takes advantage of multi-frame interaction (MFI) module to capture temporal-spatial information for video data. Specifically, a basic encoder-decoder KPN, essentially designed for image iTM, is trained to guarantee the mapping quality within each frame. More importantly, the MFI module is incorporated to capture temporal-spatial context information and preserve the inter-frame consistency by exploiting the correction between adjacent frames. Notably, we can readily extend any existing image iTM models to video iTM ones by involving the proposed MFI module. Furthermore, we propose an inter-frame brightness consistency loss function based on the Gaussian pyramid to reduce the video temporal inconsistency. Extensive experiments demonstrate that our model outperforms state-ofthe-art image and video-based methods. The code is available at https://github.com/caogaofeng/KPNMFI. Keywords: Computer Vision: Machine Learning for Vision Computer Vision: Applications Computer Vision: Computational photography Machine Learning: Convolutional Networks},
  archive   = {C_IJCAI},
  author    = {Gaofeng Cao and Fei Zhou and Han Yan and Anjie Wang and Leidong Fan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/113},
  pages     = {806-812},
  title     = {KPN-MFI: A kernel prediction network with multi-frame interaction for video inverse tone mapping},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Event-driven video deblurring via spatio-temporal
relation-aware network. <em>IJCAI</em>, 799–805. (<a
href="https://doi.org/10.24963/ijcai.2022/112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Video deblurring with event information has attracted considerable attention. To help deblur each frame, existing methods usually compress a specific event sequence into a feature tensor with the same size as the corresponding video. However, this strategy neither considers the pixel-level spatial brightness changes nor the temporal correlation between events at each time step, resulting in insufficient use of spatio-temporal information. To address this issue, we propose a new Spatio-Temporal Relation-Attention network (STRA), for the specific event-based video deblurring. Concretely, to utilize spatial consistency between the frame and event, we model the brightness changes as an extra prior to aware blurring contexts in each frame; to record temporal relationship among different events, we develop a temporal memory block to restore long-range dependencies of event sequences continuously. In this way, the complementary information contained in the events and frames, as well as the correlation of neighboring events, can be fully utilized to recover spatial texture from events constantly. Experiments show that our STRA significantly outperforms several competing methods, e.g., on the HQF dataset, our network achieves up to 1.3 dB in terms of PSNR over the most advanced method. The code is available at https://github.com/Chengzhi-Cao/STRA. Keywords: Computer Vision: Computational photography Computer Vision: Applications},
  archive   = {C_IJCAI},
  author    = {Chengzhi Cao and Xueyang Fu and Yurui Zhu and Gege Shi and Zheng-Jun Zha},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/112},
  pages     = {799-805},
  title     = {Event-driven video deblurring via spatio-temporal relation-aware network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MotionMixer: MLP-based 3D human body pose forecasting.
<em>IJCAI</em>, 791–798. (<a
href="https://doi.org/10.24963/ijcai.2022/111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work, we present MotionMixer, an efficient 3D human body pose forecasting model based solely on multi-layer perceptrons (MLPs). MotionMixer learns the spatial-temporal 3D body pose dependencies by sequentially mixing both modalities. Given a stacked sequence of 3D body poses, a spatial-MLP extracts fine-grained spatial dependencies of the body joints. The interaction of the body joints over time is then modelled by a temporal MLP. The spatial-temporal mixed features are finally aggregated and decoded to obtain the future motion. To calibrate the influence of each time step in the pose sequence, we make use of squeeze-and-excitation (SE) blocks. We evaluate our approach on Human3.6M, AMASS, and 3DPW datasets using the standard evaluation protocols. For all evaluations, we demonstrate state-of-the-art performance, while having a model with a smaller number of parameters. Our code is available at: https://github.com/MotionMLP/MotionMixer. Keywords: Computer Vision: Motion and Tracking Computer Vision: Biometrics, Face, Gesture and Pose Recognition},
  archive   = {C_IJCAI},
  author    = {Arij Bouazizi and Adrian Holzbock and Ulrich Kressel and Klaus Dietmayer and Vasileios Belagiannis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/111},
  pages     = {791-798},
  title     = {MotionMixer: MLP-based 3D human body pose forecasting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximately EFX allocations for indivisible chores.
<em>IJCAI</em>, 783–789. (<a
href="https://doi.org/10.24963/ijcai.2022/110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we study how to fairly allocate a set of m indivisible chores to a group of n agents, each of which has a general additive cost function on the items. Since envy-free (EF) allocation is not guaranteed to exist, we consider the notion of envy-freeness up to any item (EFX). In contrast to the fruitful results regarding the (approximation of) EFX allocations for goods, very little is known for the allocation of chores. Prior to our work, for the allocation of chores, it is known that EFX allocations always exist for two agents, or general number of agents with identical ordering cost functions. For general instances, no non-trivial approximation result regarding EFX allocation is known. In this paper we make some progress in this direction by showing that for three agents we can always compute a 5-approximation of EFX allocation in polynomial time. For n&gt;=4 agents, our algorithm always computes an allocation that achieves an approximation ratio of 3n^2 regarding EFX. We also study the bi-valued instances, in which agents have at most two cost values on the chores, and provide polynomial time algorithms for the computation of EFX allocation when n=3, and (n-1)-approximation of EFX allocation when n&gt;=4. Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice Constraint Satisfaction and Optimization: Constraint Satisfaction},
  archive   = {C_IJCAI},
  author    = {Shengwei Zhou and Xiaowei Wu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/110},
  pages     = {783-789},
  title     = {Approximately EFX allocations for indivisible chores},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). MetaFinger: Fingerprinting the deep neural networks with
meta-training. <em>IJCAI</em>, 776–782. (<a
href="https://doi.org/10.24963/ijcai.2022/109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {As deep neural networks (DNNs) play a critical role in various fields, the models themselves hence are becoming an important asset that needs to be protected. To achieve this, various neural network fingerprint methods have been proposed. However, existing fingerprint methods fingerprint the decision boundary by adversarial examples, which is not robust to model modification and adversarial defenses. To fill this gap, we propose a robust fingerprint method MetaFinger, which fingerprints the inner decision area of the model by meta-training, rather than the decision boundary. Specifically, we first generate many shadow models with DNN augmentation as meta-data. Then we optimize some images by meta-training to ensure that only models derived from the protected model can recognize them. To demonstrate the robustness of our fingerprint approach, we evaluate our method against two types of attacks including input modification and model modification. Experiments show that our method achieves 99.34\% and 97.69\% query accuracy on average, surpassing existing methods over 30\%, 25\% on CIFAR-10 and Tiny-ImageNet, respectively. Our code is available at https://github.com/kangyangWHU/MetaFinger. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI AI Ethics, Trust, Fairness: Safety &amp; Robustness Computer Vision: Adversarial learning, adversarial attack and defense methods},
  archive   = {C_IJCAI},
  author    = {Kang Yang and Run Wang and Lina Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/109},
  pages     = {776-782},
  title     = {MetaFinger: Fingerprinting the deep neural networks with meta-training},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Cluster attack: Query-based adversarial attacks on graph
with graph-dependent priors. <em>IJCAI</em>, 768–775. (<a
href="https://doi.org/10.24963/ijcai.2022/108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While deep neural networks have achieved great success in graph analysis, recent work has shown that they are vulnerable to adversarial attacks. Compared with adversarial attacks on image classification, performing adversarial attacks on graphs is more challenging because of the discrete and non-differential nature of the adjacent matrix for a graph. In this work, we propose Cluster Attack --- a Graph Injection Attack (GIA) on node classification, which injects fake nodes into the original graph to degenerate the performance of graph neural networks (GNNs) on certain victim nodes while affecting the other nodes as little as possible. We demonstrate that a GIA problem can be equivalently formulated as a graph clustering problem; thus, the discrete optimization problem of the adjacency matrix can be solved in the context of graph clustering. In particular, we propose to measure the similarity between victim nodes by a metric of Adversarial Vulnerability, which is related to how the victim nodes will be affected by the injected fake node, and to cluster the victim nodes accordingly. Our attack is performed in a practical and unnoticeable query-based black-box manner with only a few nodes on the graphs that can be accessed. Theoretical analysis and extensive experiments demonstrate the effectiveness of our method by fooling the node classifiers with only a small number of queries. Keywords: AI Ethics, Trust, Fairness: Safety &amp; Robustness Machine Learning: Adversarial Machine Learning Machine Learning: Clustering Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Zhengyi Wang and Zhongkai Hao and Ziqiao Wang and Hang Su and Jun Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/108},
  pages     = {768-775},
  title     = {Cluster attack: Query-based adversarial attacks on graph with graph-dependent priors},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anti-forgery: Towards a stealthy and robust DeepFake
disruption attack via adversarial perceptual-aware perturbations.
<em>IJCAI</em>, 761–767. (<a
href="https://doi.org/10.24963/ijcai.2022/107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {DeepFake is becoming a real risk to society and brings potential threats to both individual privacy and political security due to the DeepFaked multimedia are realistic and convincing. However, the popular DeepFake passive detection is an ex-post forensics countermeasure and failed in blocking the disinformation spreading in advance. To address this limitation, researchers study the proactive defense techniques by adding adversarial noises into the source data to disrupt the DeepFake manipulation. However, the existing studies on proactive DeepFake defense via injecting adversarial noises are not robust, which could be easily bypassed by employing simple image reconstruction revealed in a recent study MagDR. In this paper, we investigate the vulnerability of the existing forgery techniques and propose a novel anti-forgery technique that helps users protect the shared facial images from attackers who are capable of applying the popular forgery techniques. Our proposed method generates perceptual-aware perturbations in an incessant manner which is vastly different from the prior studies by adding adversarial noises that is sparse. Experimental results reveal that our perceptual-aware perturbations are robust to diverse image transformations, especially the competitive evasion technique, MagDR via image reconstruction. Our findings potentially open up a new research direction towards thorough understanding and investigation of perceptual-aware adversarial attack for protecting facial images against DeepFakes in a proactive and robust manner. Code is available at https://github.com/AbstractTeen/AntiForgery. Keywords: AI Ethics, Trust, Fairness: Societal Impact of AI Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Run Wang and Ziheng Huang and Zhikai Chen and Li Liu and Jing Chen and Lina Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/107},
  pages     = {761-767},
  title     = {Anti-forgery: Towards a stealthy and robust DeepFake disruption attack via adversarial perceptual-aware perturbations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Shielding federated learning: Robust aggregation with
adaptive client selection. <em>IJCAI</em>, 753–760. (<a
href="https://doi.org/10.24963/ijcai.2022/106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Federated learning (FL) enables multiple clients to collaboratively train an accurate global model while protecting clients&#39; data privacy. However, FL is susceptible to Byzantine attacks from malicious participants. Although the problem has gained significant attention, existing defenses have several flaws: the server irrationally chooses malicious clients for aggregation even after they have been detected in previous rounds; the defenses perform ineffectively against sybil attacks or in the heterogeneous data setting. To overcome these issues, we propose MAB-RFL, a new method for robust aggregation in FL. By modelling the client selection as an extended multi-armed bandit (MAB) problem, we propose an adaptive client selection strategy to choose honest clients that are more likely to contribute high-quality updates. We then propose two approaches to identify malicious updates from sybil and non-sybil attacks, based on which rewards for each client selection decision can be accurately evaluated to discourage malicious behaviors. MAB-RFL achieves a satisfying balance between exploration and exploitation on the potential benign clients. Extensive experimental results show that MAB-RFL outperforms existing defenses in three attack scenarios under different percentages of attackers. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI Machine Learning: Adversarial Machine Learning},
  archive   = {C_IJCAI},
  author    = {Wei Wan and Shengshan Hu and jianrong Lu and Leo Yu Zhang and Hai Jin and Yuanyuan He},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/106},
  pages     = {753-760},
  title     = {Shielding federated learning: Robust aggregation with adaptive client selection},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). What does my GNN really capture? On exploring internal GNN
representations. <em>IJCAI</em>, 747–752. (<a
href="https://doi.org/10.24963/ijcai.2022/105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Graph Neural Networks (GNNs) are very efficient at classifying graphs but their internal functioning is opaque which limits their field of application. Existing methods to explain GNN focus on disclosing the relationships between input graphs and model decision. In this article, we propose a method that goes further and isolates the internal features, hidden in the network layers, that are automatically identified by the GNN and used in the decision process. We show that this method makes possible to know the parts of the input graphs used by GNN with much less bias that SOTA methods and thus to bring confidence in the decision process. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability Data Mining: Frequent Pattern Mining Machine Learning: Explainable/Interpretable Machine Learning Machine Learning: Sequence and Graph Learning},
  archive   = {C_IJCAI},
  author    = {Luca Veyrin-Forrer and Ataollah Kamal and Stefan Duffner and Marc Plantevit and Céline Robardet},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/105},
  pages     = {747-752},
  title     = {What does my GNN really capture? on exploring internal GNN representations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). BayCon: Model-agnostic bayesian counterfactual generator.
<em>IJCAI</em>, 740–746. (<a
href="https://doi.org/10.24963/ijcai.2022/104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Generating counterfactuals to discover hypothetical predictive scenarios is the de facto standard for explaining machine learning models and their predictions. However, building a counterfactual explainer that is time-efficient, scalable, and model-agnostic, in addition to being compatible with continuous and categorical attributes, remains an open challenge. To complicate matters even more, ensuring that the contrastive instances are optimised for feature sparsity, remain close to the explained instance, and are not drawn from outside of the data manifold, is far from trivial. To address this gap we propose BayCon: a novel counterfactual generator based on probabilistic feature sampling and Bayesian optimisation. Such an approach can combine multiple objectives by employing a surrogate model to guide the counterfactual search. We demonstrate the advantages of our method through a collection of experiments based on six real-life datasets representing three regression tasks and three classification tasks. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Trustworthy AI Constraint Satisfaction and Optimization: Applications Machine Learning: Hyperparameter Optimization},
  archive   = {C_IJCAI},
  author    = {Piotr Romashov and Martin Gjoreski and Kacper Sokol and Maria Vanina Martinez and Marc Langheinrich},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/104},
  pages     = {740-746},
  title     = {BayCon: Model-agnostic bayesian counterfactual generator},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Counterfactual interpolation augmentation (CIA): A unified
approach to enhance fairness and explainability of DNN. <em>IJCAI</em>,
732–739. (<a href="https://doi.org/10.24963/ijcai.2022/103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Bias in the training data can jeopardize fairness and explainability of deep neural network prediction on test data. We propose a novel bias-tailored data augmentation approach, Counterfactual Interpolation Augmentation (CIA), attempting to debias the training data by d-separating the spurious correlation between the target variable and the sensitive attribute. CIA generates counterfactual interpolations along a path simulating the distribution transitions between the input and its counterfactual example. CIA as a pre-processing approach enjoys two advantages: First, it couples with either plain training or debiasing training to markedly increase fairness over the sensitive attribute. Second, it enhances the explainability of deep neural networks by generating attribution maps via integrating counterfactual gradients. We demonstrate the superior performance of the CIA-trained deep neural network models using qualitative and quantitative experimental results. Our code is available at: https://github.com/qiangyao1988/CIA Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity AI Ethics, Trust, Fairness: Explainability and Interpretability},
  archive   = {C_IJCAI},
  author    = {Yao Qiang and Chengyin Li and Marco Brocanelli and Dongxiao Zhu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/103},
  pages     = {732-739},
  title     = {Counterfactual interpolation augmentation (CIA): A unified approach to enhance fairness and explainability of DNN},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). AttExplainer: Explain transformer via attention by
reinforcement learning. <em>IJCAI</em>, 724–731. (<a
href="https://doi.org/10.24963/ijcai.2022/102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Transformer and its variants, built based on attention mechanisms, have recently achieved remarkable performance in many NLP tasks. Most existing works on Transformer explanation tend to reveal and utilize the attention matrix with human subjective intuitions in a qualitative manner. However, the huge size of dimensions directly challenges these methods to quantitatively analyze the attention matrix. Therefore, in this paper, we propose a novel reinforcement learning (RL) based framework for Transformer explanation via attention matrix, namely AttExplainer. The RL agent learns to perform step-by-step masking operations by observing the change in attention matrices. We have adapted our method to two scenarios, perturbation-based model explanation and text adversarial attack. Experiments on three widely used text classification benchmarks validate the effectiveness of the proposed method compared to state-of-the-art baselines. Additional studies show that our method is highly transferable and consistent with human intuition. The code of this paper is available at https://github.com/niuzaisheng/AttExplainer . Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability Natural Language Processing: Interpretability and Analysis of Models for NLP Natural Language Processing: Text Classification},
  archive   = {C_IJCAI},
  author    = {Runliang Niu and Zhepei Wei and Yan Wang and Qi Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/102},
  pages     = {724-731},
  title     = {AttExplainer: Explain transformer via attention by reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Investigating and explaining the frequency bias in image
classification. <em>IJCAI</em>, 717–723. (<a
href="https://doi.org/10.24963/ijcai.2022/101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {CNNs exhibit many behaviors different from humans, one of which is the capability of employing high-frequency components. This paper discusses the frequency bias phenomenon in image classification tasks: the high-frequency components are actually much less exploited than the low- and mid- frequency components. We first investigate the frequency bias phenomenon by presenting two observations on feature discrimination and learning priority. Furthermore, we hypothesize that (1) the spectral density, (2) class consistency directly affect the frequency bias. Specifically, our investigations verify that the spectral density of datasets mainly affects the learning priority, while the class consistency mainly affects the feature discrimination. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI AI Ethics, Trust, Fairness: Bias AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Safety &amp; Robustness Computer Vision: Bias, Fairness &amp; Privacy},
  archive   = {C_IJCAI},
  author    = {Zhiyu Lin and Yifei Gao and Jitao Sang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/101},
  pages     = {717-723},
  title     = {Investigating and explaining the frequency bias in image classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Model stealing defense against exploiting information leak
through the interpretation of deep neural nets. <em>IJCAI</em>, 710–716.
(<a href="https://doi.org/10.24963/ijcai.2022/100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model stealing techniques allow adversaries to create attack models that mimic the functionality of black-box machine learning models, querying only class membership or probability outcomes. Recently, interpretable AI is getting increasing attention, to enhance our understanding of AI models, provide additional information for diagnoses, or satisfy legal requirements. However, it has been recently reported that providing such additional information can make AI models more vulnerable to model stealing attacks. In this paper, we propose DeepDefense, the first defense mechanism that protects an AI model against model stealing attackers exploiting both class probabilities and interpretations. DeepDefense uses a misdirection model to hide the critical information of the original model against model stealing attacks, with minimal degradation on both the class probability and the interpretability of prediction output. DeepDefense is highly applicable for any model stealing scenario since it makes minimal assumptions about the model stealing adversary. In our experiments, DeepDefense shows significantly higher defense performance than the existing state-of-the-art defenses on various datasets and interpreters. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI AI Ethics, Trust, Fairness: Safety &amp; Robustness Machine Learning: Explainable/Interpretable Machine Learning Computer Vision: Interpretability and Transparency},
  archive   = {C_IJCAI},
  author    = {Jeonghyun Lee and Sungmin Han and Sangkyun Lee},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/100},
  pages     = {710-716},
  title     = {Model stealing defense against exploiting information leak through the interpretation of deep neural nets},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Taking situation-based privacy decisions: Privacy assistants
working with humans. <em>IJCAI</em>, 703–709. (<a
href="https://doi.org/10.24963/ijcai.2022/99">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Privacy on the Web is typically managed by giving consent to individual Websites for various aspects of data usage. This paradigm requires too much human effort and thus is impractical for Internet of Things (IoT) applications where humans interact with many new devices on a daily basis. Ideally, software privacy assistants can help by making privacy decisions in different situations on behalf of the users. To realize this, we propose an agent-based model for a privacy assistant. The model identifies the contexts that a situation implies and computes the trustworthiness of these contexts. Contrary to traditional trust models that capture trust in an entity by observing large number of interactions, our proposed model can assess the trustworthiness even if the user has not interacted with the particular device before. Moreover, our model can decide which situations are inherently ambiguous and thus can request the human to make the decision. We evaluate various aspects of the model using a real-life data set and report adjustments that are needed to serve different types of users well. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI Agent-based and Multi-agent Systems: Applications Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Nadin Kökciyan and Pinar Yolum},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/99},
  pages     = {703-709},
  title     = {Taking situation-based privacy decisions: Privacy assistants working with humans},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fairness without the sensitive attribute via causal
variational autoencoder. <em>IJCAI</em>, 696–702. (<a
href="https://doi.org/10.24963/ijcai.2022/98">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In recent years, most fairness strategies in machine learning have focused on mitigating unwanted biases by assuming that the sensitive information is available. However, in practice this is not always the case: due to privacy purposes and regulations such as RGPD in EU, many personal sensitive attributes are frequently not collected. Yet, only a few prior works address the issue of mitigating bias in such a difficult setting, in particular to meet classical fairness objectives such as Demographic Parity and Equalized Odds. By leveraging recent developments for approximate inference, we propose in this paper an approach to fill this gap. To infer a sensitive information proxy, we introduce a new variational auto-encoding-based framework named SRCVAE that relies on knowledge of the underlying causal graph. The bias mitigation is then done in an adversarial fairness approach. Our proposed method empirically achieves significant improvements over existing works in the field. We observe that the generated proxy’s latent space correctly recovers sensitive information and that our approach achieves a higher accuracy while obtaining the same level of fairness on two real datasets. Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity AI Ethics, Trust, Fairness: Bias Machine Learning: Autoencoders Machine Learning: Bayesian Learning Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Vincent Grari and Sylvain Lamprier and Marcin Detyniecki},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/98},
  pages     = {696-702},
  title     = {Fairness without the sensitive attribute via causal variational autoencoder},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). SoFaiR: Single shot fair representation learning.
<em>IJCAI</em>, 687–695. (<a
href="https://doi.org/10.24963/ijcai.2022/97">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {To avoid discriminatory uses of their data, organizations can learn to map them into a representation that filters out information related to sensitive attributes. However, all existing methods in fair representation learning generate a fairness-information trade-off. To achieve different points on the fairness-information plane, one must train different models. In this paper, we first demonstrate that fairness-information trade-offs are fully characterized by rate-distortion trade-offs. Then, we use this key result and propose SoFaiR, a single shot fair representation learning method that generates with one trained model many points on the fairness-information plane. Besides its computational saving, our single-shot approach is, to the extent of our knowledge, the first fair representation learning method that explains what information is affected by changes in the fairness / distortion properties of the representation. Empirically, we find on three datasets that SoFaiR achieves similar fairness information trade-offs as its multi-shot counterparts. Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity Computer Vision: Bias, Fairness &amp; Privacy Machine Learning: Autoencoders Machine Learning: Representation learning},
  archive   = {C_IJCAI},
  author    = {Xavier Gitiaux and Huzefa Rangwala},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/97},
  pages     = {687-695},
  title     = {SoFaiR: Single shot fair representation learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). PPT: Backdoor attacks on pre-trained models via poisoned
prompt tuning. <em>IJCAI</em>, 680–686. (<a
href="https://doi.org/10.24963/ijcai.2022/96">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recently, prompt tuning has shown remarkable performance as a new learning paradigm, which freezes pre-trained language models (PLMs) and only tunes some soft prompts. A fixed PLM only needs to be loaded with different prompts to adapt different downstream tasks. However, the prompts associated with PLMs may be added with some malicious behaviors, such as backdoors. The victim model will be implanted with a backdoor by using the poisoned prompt. In this paper, we propose to obtain the poisoned prompt for PLMs and corresponding downstream tasks by prompt tuning. We name this Poisoned Prompt Tuning method &quot;PPT&quot;. The poisoned prompt can lead a shortcut between the specific trigger word and the target label word to be created for the PLM. So the attacker can simply manipulate the prediction of the entire model by just a small prompt. Our experiments on various text classification tasks show that PPT can achieve a 99\% attack success rate with almost no accuracy sacrificed on original task. We hope this work can raise the awareness of the possible security threats hidden in the prompt. Keywords: AI Ethics, Trust, Fairness: Safety &amp; Robustness Natural Language Processing: Language Models Natural Language Processing: Other},
  archive   = {C_IJCAI},
  author    = {Wei Du and Yichun Zhao and Boqun Li and Gongshen Liu and Shilin Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/96},
  pages     = {680-686},
  title     = {PPT: Backdoor attacks on pre-trained models via poisoned prompt tuning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). CAT: Customized adversarial training for improved
robustness. <em>IJCAI</em>, 673–679. (<a
href="https://doi.org/10.24963/ijcai.2022/95">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Adversarial training has become one of the most effective methods for improving robustness of neural networks. However, it often suffers from poor generalization on both clean and perturbed data. Current robust training method always use a uniformed perturbation strength for every samples to generate adversarial examples during model training for improving adversarial robustness. However, we show it would lead worse training and generalizaiton error and forcing the prediction to match one-hot label. In this paper, therefore, we propose a new algorithm, named Customized Adversarial Training (CAT), which adaptively customizes the perturbation level and the corresponding label for each training sample in adversarial training. We first show theoretically the CAT scheme improves the generalization. Also, through extensive experiments, we show that the proposed algorithm achieves better clean and robust accuracy than previous adversarial training methods. The full version of this paper is available at https://arxiv.org/abs/2002.06789. Keywords: AI Ethics, Trust, Fairness: Safety &amp; Robustness},
  archive   = {C_IJCAI},
  author    = {Minhao Cheng and Qi Lei and Pin-Yu Chen and Inderjit Dhillon and Cho-Jui Hsieh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/95},
  pages     = {673-679},
  title     = {CAT: Customized adversarial training for improved robustness},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Learn to reverse DNNs from AI programs automatically.
<em>IJCAI</em>, 666–672. (<a
href="https://doi.org/10.24963/ijcai.2022/94">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised significant concern. To quantify the model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantics of binary code for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type of a given function’s binary code. To represent assembly instructions semantics precisely, NNReverse proposes a more fine-grained embedding model to represent the textual and structural-semantic of assembly functions. Keywords: AI Ethics, Trust, Fairness: Trustworthy AI Natural Language Processing: Embeddings AI Ethics, Trust, Fairness: Societal Impact of AI},
  archive   = {C_IJCAI},
  author    = {Simin Chen and Hamed Khanpour and Cong Liu and Wei Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/94},
  pages     = {666-672},
  title     = {Learn to reverse DNNs from AI programs automatically},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How does frequency bias affect the robustness of neural
image classifiers against common corruption and adversarial
perturbations? <em>IJCAI</em>, 659–665. (<a
href="https://doi.org/10.24963/ijcai.2022/93">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Model robustness is vital for the reliable deployment of machine learning models in real-world applications. Recent studies have shown that data augmentation can result in model over-relying on features in the low-frequency domain, sacrificing performance against low-frequency corruptions, highlighting a connection between frequency and robustness. Here, we take one step further to more directly study the frequency bias of a model through the lens of its Jacobians and its implication to model robustness. To achieve this, we propose Jacobian frequency regularization for models&#39; Jacobians to have a larger ratio of low-frequency components. Through experiments on four image datasets, we show that biasing classifiers towards low (high)-frequency components can bring performance gain against high (low)-frequency corruption and adversarial perturbation, albeit with a tradeoff in performance for low (high)-frequency corruption. Our approach elucidates a more direct connection between the frequency bias and robustness of deep learning models. Keywords: AI Ethics, Trust, Fairness: Safety &amp; Robustness Computer Vision: Adversarial learning, adversarial attack and defense methods},
  archive   = {C_IJCAI},
  author    = {Alvin Chan and Yew Soon Ong and Clement Tan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/93},
  pages     = {659-665},
  title     = {How does frequency bias affect the robustness of neural image classifiers against common corruption and adversarial perturbations?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Individual fairness guarantees for neural networks.
<em>IJCAI</em>, 651–658. (<a
href="https://doi.org/10.24963/ijcai.2022/92">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of certifying the individual fairness (IF) of feed-forward neural networks (NNs). In particular, we work with the epsilon-delta-IF formulation, which, given a NN and a similarity metric learnt from data, requires that the output difference between any pair of epsilon-similar individuals is bounded by a maximum decision tolerance delta &gt;= 0. Working with a range of metrics, including the Mahalanobis distance, we propose a method to overapproximate the resulting optimisation problem using piecewise-linear functions to lower and upper bound the NN&#39;s non-linearities globally over the input space. We encode this computation as the solution of a Mixed-Integer Linear Programming problem and demonstrate that it can be used to compute IF guarantees on four datasets widely used for fairness benchmarking. We show how this formulation can be used to encourage models&#39; fairness at training time by modifying the NN loss, and empirically confirm our approach yields NNs that are orders of magnitude fairer than state-of-the-art methods. Keywords: AI Ethics, Trust, Fairness: Fairness &amp; Diversity},
  archive   = {C_IJCAI},
  author    = {Elias Benussi and Andrea Patane&#39; and Matthew Wicker and Luca Laurenti and Marta Kwiatkowska},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/92},
  pages     = {651-658},
  title     = {Individual fairness guarantees for neural networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On preferred abductive explanations for decision trees and
random forests. <em>IJCAI</em>, 643–650. (<a
href="https://doi.org/10.24963/ijcai.2022/91">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Abductive explanations take a central place in eXplainable Artificial Intelligence (XAI) by clarifying with few features the way data instances are classified. However, instances may have exponentially many minimum-size abductive explanations, and this source of complexity holds even for ``intelligible&#39;&#39; classifiers, such as decision trees. When the number of such abductive explanations is huge, computing one of them, only, is often not informative enough. Especially, better explanations than the one that is derived may exist. As a way to circumvent this issue, we propose to leverage a model of the explainee, making precise her / his preferences about explanations, and to compute only preferred explanations. In this paper, several models are pointed out and discussed. For each model, we present and evaluate an algorithm for computing preferred majoritary reasons, where majoritary reasons are specific abductive explanations suited to random forests. We show that in practice the preferred majoritary reasons for an instance can be far less numerous than its majoritary reasons. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability AI Ethics, Trust, Fairness: Trustworthy AI Constraint Satisfaction and Optimization: Constraints and Machine Learning Knowledge Representation and Reasoning: Preference Modelling and Preference-Based Reasoning},
  archive   = {C_IJCAI},
  author    = {Gilles Audemard and Steve Bellart and Louenas Bounia and Frederic Koriche and Jean-Marie Lagniez and Pierre Marquis},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/91},
  pages     = {643-650},
  title     = {On preferred abductive explanations for decision trees and random forests},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Axiomatic foundations of explainability. <em>IJCAI</em>,
636–642. (<a href="https://doi.org/10.24963/ijcai.2022/90">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving trust in decisions made by classification models is becoming crucial for the acceptance of automated systems, and an important way of doing that is by providing explanations for the behaviour of the models. Different explainers have been proposed in the recent literature for that purpose, however their formal properties are under-studied. This paper investigates theoretically explainers that provide reasons behind decisions independently of instances. Its contributions are fourfold. The first is to lay the foundations of such explainers by proposing key axioms, i.e., desirable properties they would satisfy. Two axioms are incompatible leading to two subsets. The second contribution consists of demonstrating that the first subset of axioms characterizes a family of explainers that return sufficient reasons while the second characterizes a family that provides necessary reasons. This sheds light on the axioms which distinguish the two types of reasons. As a third contribution, the paper introduces various explainers of both families, and fully characterizes some of them. Those explainers make use of the whole feature space. The fourth contribution is a family of explainers that generate explanations from finite datasets (subsets of the feature space). This family, seen as an abstraction of Anchors and LIME, violates some axioms including one which prevents incorrect explanations. Keywords: AI Ethics, Trust, Fairness: Explainability and Interpretability Knowledge Representation and Reasoning: Diagnosis and Abductive Reasoning},
  archive   = {C_IJCAI},
  author    = {Leila Amgoud and Jonathan Ben-Naim},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/90},
  pages     = {636-642},
  title     = {Axiomatic foundations of explainability},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Detecting out-of-context objects using graph contextual
reasoning network. <em>IJCAI</em>, 629–635. (<a
href="https://doi.org/10.24963/ijcai.2022/89">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper presents an approach for detecting out-of-context (OOC) objects in images. Given an image with a set of objects, our goal is to determine if an object is inconsistent with the contextual relations and detect the OOC object with a bounding box. In this work, we consider common contextual relations such as co-occurrence relations, the relative size of an object with respect to other objects, and the position of the object in the scene. We posit that contextual cues are useful to determine object labels for in-context objects and inconsistent context cues are detrimental to determining object labels for out-of-context objects. To realize this hypothesis, we propose a graph contextual reasoning network (GCRN) to detect OOC objects. GCRN consists of two separate graphs to predict object labels based on the contextual cues in the image: 1) a representation graph to learn object features based on the neighboring objects and 2) a context graph to explicitly capture contextual cues from the neighboring objects. GCRN explicitly captures the contextual cues to improve the detection of in-context objects and identify objects that violate contextual relations. In order to evaluate our approach, we create a large-scale dataset by adding OOC object instances to the COCO images. We also evaluate on recent OCD benchmark. Our results show that GCRN outperforms competitive baselines in detecting OOC objects and correctly detecting in-context objects. Code and data: https://nusci.csl.sri.com/project/trinity-ooc Keywords: AI Ethics, Trust, Fairness: Trustworthy AI Computer Vision: Recognition (object detection, categorization) Computer Vision: Scene analysis and understanding},
  archive   = {C_IJCAI},
  author    = {Manoj Acharya and Anirban Roy and Kaushik Koneripalli and Susmit Jha and Christopher Kanan and Ajay Divakaran},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/89},
  pages     = {629-635},
  title     = {Detecting out-of-context objects using graph contextual reasoning network},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Evolutionary approach to security games with signaling.
<em>IJCAI</em>, 620–627. (<a
href="https://doi.org/10.24963/ijcai.2022/88">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Green Security Games have become a popular way to model scenarios involving the protection of natural resources, such as wildlife. Sensors (e.g. drones equipped with cameras) have also begun to play a role in these scenarios by providing real-time information. Incorporating both human and sensor defender resources strategically is the subject of recent work on Security Games with Signaling (SGS). However, current methods to solve SGS do not scale well in terms of time or memory. We therefore propose a novel approach to SGS, which, for the first time in this domain, employs an Evolutionary Computation paradigm: EASGS. EASGS effectively searches the huge SGS solution space via suitable solution encoding in a chromosome and a specially-designed set of operators. The operators include three types of mutations, each focusing on a particular aspect of the SGS solution, optimized crossover and a local coverage improvement scheme (a memetic aspect of EASGS). We also introduce a new set of benchmark games, based on dense or locally-dense graphs that reflect real-world SGS settings. In the majority of 342 test game instances, EASGS outperforms state-of-the-art methods, including a reinforcement learning method, in terms of time scalability, nearly constant memory utilization, and quality of the returned defender&#39;s strategies (expected payoffs). Keywords: Agent-based and Multi-agent Systems: Noncooperative Games Search: Evolutionary Computation},
  archive   = {C_IJCAI},
  author    = {Adam Żychowski and Jacek Mańdziuk and Elizabeth Bondi and Aravind Venugopal and Milind Tambe and Balaraman Ravindran},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/88},
  pages     = {620-627},
  title     = {Evolutionary approach to security games with signaling},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategyproof mechanisms for group-fair facility location
problems. <em>IJCAI</em>, 613–619. (<a
href="https://doi.org/10.24963/ijcai.2022/87">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the facility location problems where agents are located on a real line and divided into groups based on criteria such as ethnicity or age. Our aim is to design mechanisms to locate a facility to approximately minimize the costs of groups of agents to the facility fairly while eliciting the agents&#39; locations truthfully. We first explore various well-motivated group fairness cost objectives for the problems and show that many natural objectives have an unbounded approximation ratio. We then consider minimizing the maximum total group cost and minimizing the average group cost objectives. For these objectives, we show that existing classical mechanisms (e.g., median) and new group-based mechanisms provide bounded approximation ratios, where the group-based mechanisms can achieve better ratios. We also provide lower bounds for both objectives. To measure fairness between groups and within each group, we study a new notion of intergroup and intragroup fairness (IIF) . We consider two IIF objectives and provide mechanisms with tight approximation ratios. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Houyu Zhou and Minming Li and Hau Chan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/87},
  pages     = {613-619},
  title     = {Strategyproof mechanisms for group-fair facility location problems},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Correlation-based algorithm for team-maxmin equilibrium in
multiplayer extensive-form games. <em>IJCAI</em>, 606–612. (<a
href="https://doi.org/10.24963/ijcai.2022/86">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Efficient algorithms computing a Nash equilibrium have been successfully applied to large zero- sum two-player extensive-form games (e.g., poker). However, in multiplayer games, computing a Nash equilibrium is generally hard, and the equilibria are not exchangeable, which makes players face the problem of selecting one of many different Nash equilibria. In this paper, we focus on an alternative solution concept in zero-sum multiplayer extensive-form games called Team-Maxmin Equilibrium (TME). It is a Nash equilibrium that maximizes each team member’s utility. As TME is unique in general, it avoids the equilibrium selection problem. However, it is still difficult (FNP- hard) to find a TME. Computing it can be formulated as a non-convex program, but existing algorithms are capable of solving this program for only very small games. In this paper, we first refine the complexity result for computing a TME by using a correlation plan to show that a TME can be found in polynomial time in a specific class of games according to our boundary for complexity. Second, we propose an efficient correlation-based algorithm to solve the non-convex program for TME in games not belonging to this class. The algorithm combines two special correlation plans based on McCormick envelopes for convex relaxation and von Stengel-Forges polytope for correlated equilibria. We show that restricting the feasible solution space to von Stengel-Forges polytope will strictly reduce the feasible solution space after convex re- laxation of nonlinear terms. Finally, experiments show that our algorithm is about four orders of magnitude faster than the prior state of the art and can solve many previously unsolvable games. Keywords: Agent-based and Multi-agent Systems: Noncooperative Games Agent-based and Multi-agent Systems: Cooperative Games},
  archive   = {C_IJCAI},
  author    = {Youzhi Zhang and Bo An and V. S. Subrahmanian},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/86},
  pages     = {606-612},
  title     = {Correlation-based algorithm for team-maxmin equilibrium in multiplayer extensive-form games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent concentrative coordination with decentralized
task representation. <em>IJCAI</em>, 599–605. (<a
href="https://doi.org/10.24963/ijcai.2022/85">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Value-based multi-agent reinforcement learning (MARL) methods hold the promise of promoting coordination in cooperative settings. Popular MARL methods mainly focus on the scalability or the representational capacity of value functions. Such a learning paradigm can reduce agents&#39; uncertainties and promote coordination. However, they fail to leverage the task structure decomposability, which generally exists in real-world multi-agent systems (MASs), leading to a significant amount of time exploring the optimal policy in complex scenarios. To address this limitation, we propose a novel framework Multi-Agent Concentrative Coordination (MACC) based on task decomposition, with which an agent can implicitly form local groups to reduce the learning space to facilitate coordination. In MACC, agents first learn representations for subtasks from their local information and then implement an attention mechanism to concentrate on the most relevant ones. Thus, agents can pay targeted attention to specific subtasks and improve coordination. Extensive experiments on various complex multi-agent benchmarks demonstrate that MACC achieves remarkable performance compared to existing methods. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Agent-based and Multi-agent Systems: Agreement Technologies: Argumentation Agent-based and Multi-agent Systems: Agreement Technologies: Negotiation and Contract-Based Systems Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Lei Yuan and Chenghe Wang and Jianhao Wang and Fuxiang Zhang and Feng Chen and Cong Guan and Zongzhang Zhang and Chongjie Zhang and Yang Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/85},
  pages     = {599-605},
  title     = {Multi-agent concentrative coordination with decentralized task representation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Environment design for biased decision makers.
<em>IJCAI</em>, 592–598. (<a
href="https://doi.org/10.24963/ijcai.2022/84">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the environment design problem for biased decision makers. In an environment design problem, an informed principal aims to update the decision making environment to influence the decisions made by the agent. This problem is ubiquitous in various domains, e.g., a social networking platform might want to update its website to encourage more user engagement. In this work, we focus on the scenario in which the agent might exhibit biases in decision making. We relax the common assumption that the agent is rational and aim to incorporate models of biased agents in environment design. We formulate the environment design problem under the Markov decision process (MDP) and incorporate common models of biased agents through introducing general time-discounting functions. We then formalize the environment design problem as constrained optimization problems and propose corresponding algorithms. We conduct both simulations and real human-subject experiments with workers recruited from Amazon Mechanical Turk to evaluate our proposed algorithms. Keywords: Agent-based and Multi-agent Systems: Human-Agent Interaction Humans and AI: Applications Humans and AI: Human-AI Collaboration Planning and Scheduling: Markov Decisions Processes},
  archive   = {C_IJCAI},
  author    = {Guanghui Yu and Chien-Ju Ho},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/84},
  pages     = {592-598},
  title     = {Environment design for biased decision makers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the complexity of calculating approval-based winners in
candidates-embedded metrics. <em>IJCAI</em>, 585–591. (<a
href="https://doi.org/10.24963/ijcai.2022/83">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study approval-based multiwinner voting where candidates are in a metric space and committees are valuated in terms of their distances to the given votes. In particular, we consider three different distance functions, and for each of them we study both the utilitarian rules and the egalitarian rules, resulting in six variants of winners determination problems. We focus on the (parameterized) complexity of these problems for both the general metric and several special metrics. For hardness results, we also discuss their approximability. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Yongjie Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/83},
  pages     = {585-591},
  title     = {On the complexity of calculating approval-based winners in candidates-embedded metrics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient multi-agent communication via shapley message
value. <em>IJCAI</em>, 578–584. (<a
href="https://doi.org/10.24963/ijcai.2022/82">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Utilizing messages from teammates is crucial in cooperative multi-agent tasks due to the partially observable nature of the environment. Naively asking messages from all teammates without pruning may confuse individual agents, hindering the learning process and impairing the whole system&#39;s performance. Most previous work either utilizes a gate or employs an attention mechanism to extract relatively important messages. However, they do not explicitly evaluate each message&#39;s value, failing to learn an efficient communication protocol in more complex scenarios. To tackle this issue, we model the teammates of an agent as a message coalition and calculate the Shapley Message Value (SMV) of each agent within it. SMV reflects the contribution of each message to an agent and redundant messages can be spotted in this way effectively. On top of that, we design a novel framework named Shapley Message Selector (SMS), which learns to predict the SMVs of teammates for an agent solely based on local information so that the agent can only query those teammates with positive SMVs. Empirically, we demonstrate that our method can prune redundant messages and achieve comparable or better performance in various multi-agent cooperative scenarios than full communication settings and existing strong baselines. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Agent Communication Machine Learning: Deep Reinforcement Learning},
  archive   = {C_IJCAI},
  author    = {Di Xue and Lei Yuan and Zongzhang Zhang and Yang Yu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/82},
  pages     = {578-584},
  title     = {Efficient multi-agent communication via shapley message value},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mechanism design with predictions. <em>IJCAI</em>, 571–577.
(<a href="https://doi.org/10.24963/ijcai.2022/81">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Improving algorithms via predictions is a very active research topic in recent years. This paper initiates the systematic study of mechanism design in this model. In a number of well-studied mechanism design settings, we make use of imperfect predictions to design mechanisms that perform much better than traditional mechanisms if the predictions are accurate (consistency), while always retaining worst-case guarantees even with very imprecise predictions (robustness). Furthermore, we refer to the largest prediction error sufficient to give a good performance as the error tolerance of a mechanism, and observe that an intrinsic tradeoff among consistency, robustness and error tolerance is common for mechanism design with predictions. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Chenyang Xu and Pinyan Lu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/81},
  pages     = {571-577},
  title     = {Mechanism design with predictions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fast and fine-grained autoscaler for streaming jobs with
reinforcement learning. <em>IJCAI</em>, 564–570. (<a
href="https://doi.org/10.24963/ijcai.2022/80">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {On computing clusters, the autoscaler is responsible for allocating resources for jobs or fine-grained tasks to ensure their Quality of Service. Due to a more precise resource management, fine-grained autoscaling can generally achieve better performance. However, the fine-grained autoscaling for streaming jobs needs intensive computation to model the complicated running states of tasks, and has not been adequately studied previously. In this paper, we propose a novel fine-grained autoscaler for streaming jobs based on reinforcement learning. We first organize the running states of streaming jobs as spatio-temporal graphs. To efficiently make autoscaling decisions, we propose a Neural Variational Subgraph Sampler to sample spatio-temporal subgraphs. Furthermore, we propose a mutual-information-based objective function to explicitly guide the sampler to extract more representative subgraphs. After that, the autoscaler makes decisions based on the learned subgraph representations. Experiments conducted on real-world datasets demonstrate the superiority of our method over six competitive baselines. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Data Mining: Mining Spatial and/or Temporal Data Data Mining: Parallel, Distributed and Cloud-based High Performance Mining Machine Learning: Deep Reinforcement Learning Planning and Scheduling: Scheduling},
  archive   = {C_IJCAI},
  author    = {Mingzhe Xing and Hangyu Mao and Zhen Xiao},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/80},
  pages     = {564-570},
  title     = {Fast and fine-grained autoscaler for streaming jobs with reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Manipulating elections by changing voter perceptions.
<em>IJCAI</em>, 557–563. (<a
href="https://doi.org/10.24963/ijcai.2022/79">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The integrity of elections is central to democratic systems. However, a myriad of malicious actors aspire to influence election outcomes for financial or political benefit. A common means to such ends is by manipulating perceptions of the voting public about select candidates, for example, through misinformation. We present a formal model of the impact of perception manipulation on election outcomes in the framework of spatial voting theory, in which the preferences of voters over candidates are generated based on their relative distance in the space of issues. We show that controlling elections in this model is, in general, NP-hard, whether issues are binary or real-valued. However, we demonstrate that critical to intractability is the diversity of opinions on issues exhibited by the voting public. When voter views lack diversity, and we can instead group them into a small number of categories---for example, as a result of political polarization---the election control problem can be solved in polynomial time in the number of issues and candidates for arbitrary scoring rules. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Multidisciplinary Topics and Applications: Security and Privacy},
  archive   = {C_IJCAI},
  author    = {Junlin Wu and Andrew Estornell and Lecheng Kong and Yevgeniy Vorobeychik},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/79},
  pages     = {557-563},
  title     = {Manipulating elections by changing voter perceptions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fourier analysis-based iterative combinatorial auctions.
<em>IJCAI</em>, 549–556. (<a
href="https://doi.org/10.24963/ijcai.2022/78">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent advances in Fourier analysis have brought new tools to efficiently represent and learn set functions. In this paper, we bring the power of Fourier analysis to the design of combinatorial auctions (CAs). The key idea is to approximate bidders&#39; value functions using Fourier-sparse set functions, which can be computed using a relatively small number of queries. Since this number is still too large for practical CAs, we propose a new hybrid design: we first use neural networks (NNs) to learn bidders’ values and then apply Fourier analysis to the learned representations. On a technical level, we formulate a Fourier transform-based winner determination problem and derive its mixed integer program formulation. Based on this, we devise an iterative CA that asks Fourier-based queries. We experimentally show that our hybrid ICA achieves higher efficiency than prior auction designs, leads to a fairer distribution of social welfare, and significantly reduces runtime. With this paper, we are the first to leverage Fourier analysis in CA design and lay the foundation for future work in this area. Our code is available on GitHub: https://github.com/marketdesignresearch/FA-based-ICAs. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Machine Learning: Learning Sparse Models Machine Learning: Regression Machine Learning: Feature Extraction, Selection and Dimensionality Reduction},
  archive   = {C_IJCAI},
  author    = {Jakob Weissteiner and Chris Wendler and Sven Seuken and Ben Lubin and Markus Püschel},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/78},
  pages     = {549-556},
  title     = {Fourier analysis-based iterative combinatorial auctions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Monotone-value neural networks: Exploiting preference
monotonicity in combinatorial assignment. <em>IJCAI</em>, 541–548. (<a
href="https://doi.org/10.24963/ijcai.2022/77">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Many important resource allocation problems involve the combinatorial assignment of items, e.g., auctions or course allocation. Because the bundle space grows exponentially in the number of items, preference elicitation is a key challenge in these domains. Recently, researchers have proposed ML-based mechanisms that outperform traditional mechanisms while reducing preference elicitation costs for agents. However, one major shortcoming of the ML algorithms that were used is their disregard of important prior knowledge about agents&#39; preferences. To address this, we introduce monotone-value neural networks (MVNNs), which are designed to capture combinatorial valuations, while enforcing monotonicity and normality. On a technical level, we prove that our MVNNs are universal in the class of monotone and normalized value functions, and we provide a mixed-integer linear program (MILP) formulation to make solving MVNN-based winner determination problems (WDPs) practically feasible. We evaluate our MVNNs experimentally in spectrum auction domains. Our results show that MVNNs improve the prediction performance, they yield state-of-the-art allocative efficiency in the auction, and they also reduce the run-time of the WDPs. Our code is available on GitHub: https://github.com/marketdesignresearch/MVNN. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Machine Learning: Regression Constraint Satisfaction and Optimization: Constraints and Machine Learning Machine Learning: Theory of Deep Learning},
  archive   = {C_IJCAI},
  author    = {Jakob Weissteiner and Jakob Heiss and Julien Siems and Sven Seuken},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/77},
  pages     = {541-548},
  title     = {Monotone-value neural networks: Exploiting preference monotonicity in combinatorial assignment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling the dynamics of regret minimization in large agent
populations: A master equation approach. <em>IJCAI</em>, 534–540. (<a
href="https://doi.org/10.24963/ijcai.2022/76">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Understanding the learning dynamics in multiagent systems is an important and challenging task. Past research on multi-agent learning mostly focuses on two-agent settings. In this paper, we consider the scenario in which a population of infinitely many agents apply regret minimization in repeated symmetric games. We propose a new formal model based on the master equation approach in statistical physics to describe the evolutionary dynamics in the agent population. Our model takes the form of a partial differential equation, which describes how the probability distribution of regret evolves over time. Through experiments, we show that our theoretical results are consistent with the agent-based simulation results. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence},
  archive   = {C_IJCAI},
  author    = {Zhen Wang and Chunjiang Mu and Shuyue Hu and Chen Chu and Xuelong Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/76},
  pages     = {534-540},
  title     = {Modelling the dynamics of regret minimization in large agent populations: A master equation approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Strategy proof mechanisms for facility location with
capacity limits. <em>IJCAI</em>, 527–533. (<a
href="https://doi.org/10.24963/ijcai.2022/75">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An important feature of many real world facility location problems are capacity limits on the number of agents served by each facility. We provide a comprehensive picture of strategy proof mechanisms for facility location problems with capacity constraints that are anonymous and Pareto optimal. First, we prove a strong characterization theorem. For locating two identical facilities with capacity limits and no spare capacity, the INNERPOINT mechanism is the unique strategy proof mechanism that is both anonymous and Pareto optimal. Second, when there is spare capacity, we identify a more general class of strategy proof mechanisms that interpolates smoothly between INNERPOINT and ENDPOINT which are anonymous and Pareto optimal. Third, with two facilities of different capacities, we prove a strong impossibility theorem that no mechanism can be both anonymous and Pareto optimal except when the capacities differ by just a single agent. Fourth, with three or more facilities we prove a second impossibility theorem that no mechanism can be both anonymous and Pareto optimal even when facilities have equal capacity. Our characterization and impossibility results are all minimal as multiple mechanisms exist if we drop one property. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Toby Walsh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/75},
  pages     = {527-533},
  title     = {Strategy proof mechanisms for facility location with capacity limits},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Max-sum with quadtrees for decentralized coordination in
continuous domains. <em>IJCAI</em>, 518–526. (<a
href="https://doi.org/10.24963/ijcai.2022/74">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this paper we put forward a novel extension of the classic Max-Sum algorithm to the framework of Continuous Distributed Constrained Optimization Problems (Continuous DCOPs), by utilizing a popular geometric algorithm, namely Quadtrees. In its standard form, Max-Sum can only solve Continuous DCOPs with an a priori discretization procedure. Existing Max-Sum extensions to continuous multiagent coordination domains require additional assumptions regarding the form of the factors, such as access to the gradient, or the ability to model them as continuous piecewise linear functions. Our proposed approach has no such requirements: we model the exchanged messages with Quadtrees, and, as such, the discretization procedure is dynamic and embedded in the internal Max-Sum operations (addition and marginal maximization). We apply Max-Sum with Quadtrees to lane-free autonomous driving. Our experimental evaluation showcases the effectiveness of our approach in this challenging coordination domain. Keywords: Agent-based and Multi-agent Systems: Coordination and Cooperation Multidisciplinary Topics and Applications: Other Multidisciplinary Topics and Applications: Transportation Planning and Scheduling: Distributed; Multi-agent Planning},
  archive   = {C_IJCAI},
  author    = {Dimitrios Troullinos and Georgios Chalkiadakis and Vasilis Samoladas and Markos Papageorgiou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/74},
  pages     = {518-526},
  title     = {Max-sum with quadtrees for decentralized coordination in continuous domains},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Real-time BDI agents: A model and its implementation.
<em>IJCAI</em>, 511–517. (<a
href="https://doi.org/10.24963/ijcai.2022/73">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The BDI model proved to be effective for the developing of applications requiring high-levels of autonomy and to deal with the complexity and unpredictability of real-world scenarios. The model, however, has significant limitations in reacting and handling contingencies within the given real-time constraints. Without an explicit representation of time, existing real-time BDI implementations overlook the temporal implications during the agent’s decision process that may result in delays or unresponsiveness of the system when it gets overloaded. In this paper, we redefine the BDI agent control loop inspired by traditional and well establish algorithms for real-time systems to ensure a proper reaction of agents and their effective application in typical real-time domains. Our model proposes an effective real-time management of goals, plans, and actions with respect to time constraints and resources availability. We propose an implementation of the model for a resource-collection video-game and we validate the approach against a set of significant scenarios. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Engineering Methods, Platforms, Languages and Tools Knowledge Representation and Reasoning: Knowledge Representation Languages Planning and Scheduling: Scheduling Planning and Scheduling: Real-time Planning},
  archive   = {C_IJCAI},
  author    = {Andrea Traldi and Francesco Bruschetti and Marco Robol and Marco Roveri and Paolo Giorgini},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/73},
  pages     = {511-517},
  title     = {Real-time BDI agents: A model and its implementation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Search-based testing of reinforcement learning.
<em>IJCAI</em>, 503–510. (<a
href="https://doi.org/10.24963/ijcai.2022/72">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Evaluation of deep reinforcement learning (RL) is inherently challenging. Especially the opaqueness of learned policies and the stochastic nature of both agents and environments make testing the behavior of deep RL agents difficult. We present a search-based testing framework that enables a wide range of novel analysis capabilities for evaluating the safety and performance of deep RL agents. For safety testing, our framework utilizes a search algorithm that searches for a reference trace that solves the RL task. The backtracking states of the search, called boundary states, pose safety-critical situations. We create safety test-suites that evaluate how well the RL agent escapes safety-critical situations near these boundary states. For robust performance testing, we create a diverse set of traces via fuzz testing. These fuzz traces are used to bring the agent into a wide variety of potentially unknown states from which the average performance of the agent is compared to the average performance of the fuzz traces. We apply our search-based testing approach on RL for Nintendo&#39;s Super Mario Bros. Keywords: Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis AI Ethics, Trust, Fairness: Safety &amp; Robustness Machine Learning: Deep Reinforcement Learning Search: Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Martin Tappler and Filip Cano Córdoba and Bernhard K. Aichernig and Bettina Könighofer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/72},
  pages     = {503-510},
  title     = {Search-based testing of reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How to sample approval elections? <em>IJCAI</em>, 496–502.
(<a href="https://doi.org/10.24963/ijcai.2022/71">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We extend the map-of-elections framework to the case of approval elections. While doing so, we study a number of statistical cultures, including some new ones, and we analyze their properties. We find that approval elections can be understood in terms of the average number of approvals in the votes, and the extent to which the votes are chaotic. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Stanisław Szufa and Piotr Faliszewski and Łukasz Janeczko and Martin Lackner and Arkadii Slinko and Krzysztof Sornat and Nimrod Talmon},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/71},
  pages     = {496-502},
  title     = {How to sample approval elections?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Maxmin participatory budgeting. <em>IJCAI</em>, 489–495. (<a
href="https://doi.org/10.24963/ijcai.2022/70">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Participatory Budgeting (PB) is a popular voting method by which a limited budget is divided among a set of projects, based on the preferences of voters over the projects. PB is broadly categorised as divisible PB (if the projects are fractionally implementable) and indivisible PB (if the projects are atomic). Egalitarianism, an important objective in PB, has not received much attention in the context of indivisible PB. This paper addresses this gap through a detailed study of a natural egalitarian rule, Maxmin Participatory Budgeting (MPB), in the context of indivisible PB. Our study is in two parts: (1) computational (2) axiomatic. In the first part, we prove that MPB is computationally hard and give pseudo-polynomial time and polynomial-time algorithms when parameterized by certain well-motivated parameters. We propose an algorithm that achieves for MPB, additive approximation guarantees for restricted spaces of instances and empirically show that our algorithm in fact gives exact optimal solutions on real-world PB datasets. We also establish an upper bound on the approximation ratio achievable for MPB by the family of exhaustive strategy-proof PB algorithms. In the second part, we undertake an axiomatic study of the MPB rule by generalizing known axioms in the literature. Our study leads to the proposal of a new axiom, maximal coverage, which captures fairness aspects. We prove that MPB satisfies maximal coverage. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Resource Allocation},
  archive   = {C_IJCAI},
  author    = {Gogulapati Sreedurga and Mayank Ratan Bhardwaj and Yadati Narahari},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/70},
  pages     = {489-495},
  title     = {Maxmin participatory budgeting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Near-tight algorithms for the chamberlin-courant and thiele
voting rules. <em>IJCAI</em>, 482–488. (<a
href="https://doi.org/10.24963/ijcai.2022/69">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present an almost optimal algorithm for the classic Chamberlin-Courant multiwinner voting rule (CC) on single-peaked preference profiles. Given n voters and m candidates, it runs in almost linear time in the input size improving the previous best O(nm^2) time algorithm. We also study multiwinner voting rules on nearly single-peaked preference profiles in terms of the candidate-deletion operation. We show a polynomial-time algorithm for CC where a given candidate-deletion set D has logarithmic size. Actually, our algorithm runs in 2^|D| * poly(n, m) time and the base of the power cannot be improved under the Strong Exponential Time Hypothesis. We also adapt these results to all non-constant Thiele rules which generalize CC with approval ballots. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Krzysztof Sornat and Virginia Vassilevska Williams and Yinzhan Xu},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/69},
  pages     = {482-488},
  title     = {Near-tight algorithms for the chamberlin-courant and thiele voting rules},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multiwinner elections under minimax chamberlin-courant rule
in euclidean space. <em>IJCAI</em>, 475–481. (<a
href="https://doi.org/10.24963/ijcai.2022/68">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider multiwinner elections in Euclidean space using the minimax Chamberlin-Courant rule. In this setting, voters and candidates are embedded in a d-dimensional Euclidean space, and the goal is to choose a committee of k candidates so that the rank of any voter&#39;s most preferred candidate in the committee is minimized. (The problem is also equivalent to the ordinal version of the classical k-center problem.) We show that the problem is NP-hard in any dimension d &gt;= 2, and also provably hard to approximate. Our main results are three polynomial-time approximation schemes, each of which finds a committee with provably good minimax score. In all cases, we show that our approximation bounds are tight or close to tight. We mainly focus on the 1-Borda rule but some of our results also hold for the more general r-Borda. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Chinmay Sonar and Subhash Suri and Jie Xue},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/68},
  pages     = {475-481},
  title     = {Multiwinner elections under minimax chamberlin-courant rule in euclidean space},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transfer learning based adaptive automated negotiating agent
framework. <em>IJCAI</em>, 468–474. (<a
href="https://doi.org/10.24963/ijcai.2022/67">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {With the availability of domain specific historical negotiation data, the practical applications of machine learning techniques can prove to be increasingly effective in the field of automated negotiation. Yet a large portion of the literature focuses on domain independent negotiation and thus passes the possibility of leveraging any domain specific insights from historical data. Moreover, during sequential negotiation, utility functions may alter due to various reasons including market demand, partner agreements, weather conditions, etc. This poses a unique set of challenges and one can easily infer that one strategy that fits all is rather impossible in such scenarios. In this work, we present a simple yet effective method of learning an end-to-end negotiation strategy from historical negotiation data. Next, we show that transfer learning based solutions are effective in designing adaptive strategies when underlying utility functions of agents change. Additionally, we also propose an online method of detecting and measuring such changes in the utility functions. Combining all three contributions we propose an adaptive automated negotiating agent framework that enables the automatic creation of transfer learning based negotiating agents capable of adapting to changes in utility functions. Finally, we present the results of an agent generated using our framework in different ANAC domains with 100 different utility functions each and show that our agent outperforms the benchmark score by domain independent agents by 6\%. Keywords: Agent-based and Multi-agent Systems: Agreement Technologies: Negotiation and Contract-Based Systems Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Ayan Sengupta and Shinji Nakadai and Yasser Mohammad},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/67},
  pages     = {468-474},
  title     = {Transfer learning based adaptive automated negotiating agent framework},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The power of media agencies in ad auctions: Improving
utility through coordinated bidding. <em>IJCAI</em>, 461–467. (<a
href="https://doi.org/10.24963/ijcai.2022/66">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The increasing competition in digital advertising induced a proliferation of media agencies playing the role of intermediaries between advertisers and platforms selling ad slots. When a group of competing advertisers is managed by a common agency, many forms of collusion, such as bid rigging, can be implemented by coordinating bidding strategies, dramatically increasing advertisers&#39; value. We study the problem of finding bids and monetary transfers maximizing the utility of a group of colluders, under GSP and VCG mechanisms. First, we introduce an abstract bid optimization problem---called weighted utility problem (WUP)---, which is useful in proving our results. We show that the utilities of bidding strategies are related to the length of paths in a directed acyclic weighted graph, whose structure and weights depend on the mechanism under study. This allows us to solve WUP in polynomial time by finding a shortest path of the graph. Next, we switch to our original problem, focusing on two settings that differ for the incentives they allow for. Incentive constraints ensure that colluders do not leave the agency, and they can be enforced by implementing monetary transfers between the agency and the advertisers. In particular, we study the arbitrary transfers setting, where any kind of monetary transfer to and from the advertisers is allowed, and the more realistic limited liability setting, in which no advertiser can be paid by the agency. In the former, we cast the problem as a WUP instance and solve it by our graph-based algorithm, while, in the latter, we formulate it as a linear program with exponentially-many variables efficiently solvable by applying the ellipsoid algorithm to its dual. This requires to solve a suitable separation problem in polynomial time, which can be done by reducing it to the weighted utility problem a WUP instance. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Giulia Romano and Matteo Castiglioni and Alberto Marchesi and Nicola Gatti},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/66},
  pages     = {461-467},
  title     = {The power of media agencies in ad auctions: Improving utility through coordinated bidding},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Exploring the benefits of teams in multiagent learning.
<em>IJCAI</em>, 454–460. (<a
href="https://doi.org/10.24963/ijcai.2022/65">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {For problems requiring cooperation, many multiagent systems implement solutions among either individual agents or across an entire population towards a common goal. Multiagent teams are primarily studied when in conflict; however, organizational psychology (OP) highlights the benefits of teams among human populations for learning how to coordinate and cooperate. In this paper, we propose a new model of multiagent teams for reinforcement learning (RL) agents inspired by OP and early work on teams in artificial intelligence. We validate our model using complex social dilemmas that are popular in recent multiagent RL and find that agents divided into teams develop cooperative pro-social policies despite incentives to not cooperate. Furthermore, agents are better able to coordinate and learn emergent roles within their teams and achieve higher rewards compared to when the interests of all agents are aligned. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {David Radke and Kate Larson and Tim Brecht},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/65},
  pages     = {454-460},
  title     = {Exploring the benefits of teams in multiagent learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fair, individually rational and cheap adjustment.
<em>IJCAI</em>, 447–453. (<a
href="https://doi.org/10.24963/ijcai.2022/64">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Consider the practical goal of making a desired action profile played, when the planner can only change the payoffs, bound by stringent constraints. Applications include motivating people to choose the closest school, the closest subway station, or to coordinate on a communication protocol or an investment strategy. Employing subsidies and tolls, we adjust the game so that choosing this predefined action profile becomes strictly dominant. Inspired mainly by the work of Monderer and Tennenholtz, where the promised subsidies do not materialise in the not played profiles, we provide a fair and individually rational game adjustment, such that the total outside investments sum up to zero at any profile, thereby facilitating easy and frequent usage of our adjustment without bearing costs, even if some players behave unexpectedly. The resultant action profile itself needs no adjustment. Importantly, we also prove that our adjustment minimises the general transfer among all such adjustments, counting the total subsidising and taxation. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Gleb Polevoy and Marcin Dziubiński},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/64},
  pages     = {447-453},
  title     = {Fair, individually rational and cheap adjustment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). I will have order! Optimizing orders for fair reviewer
assignment. <em>IJCAI</em>, 440–446. (<a
href="https://doi.org/10.24963/ijcai.2022/63">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study mechanisms that allocate reviewers to papers in a fair and efficient manner. We model reviewer assignment as an instance of a fair allocation problem, presenting an extension of the classic round-robin mechanism, called Reviewer Round Robin (RRR). Round-robin mechanisms are a standard tool to ensure envy-free up to one item (EF1) allocations. However, fairness often comes at the cost of decreased efficiency. To overcome this challenge, we carefully select an approximately optimal round-robin order. Applying a relaxation of submodularity, γ-weak submodularity, we show that greedily inserting papers into an order yields a (1+γ²)-approximation to the maximum welfare attainable by our round-robin mechanism under any order. Our Greedy Reviewer Round Robin (GRRR) approach outputs highly efficient EF1 allocations for three real conference datasets, offering comparable performance to state-of-the-art paper assignment methods in fairness, efficiency, and runtime, while providing the only EF1 guarantee. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Applications Agent-based and Multi-agent Systems: Computational Social Choice Search: Combinatorial Search and Optimisation},
  archive   = {C_IJCAI},
  author    = {Justin Payan and Yair Zick},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/63},
  pages     = {440-446},
  title     = {I will have order! optimizing orders for fair reviewer assignment},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Robust solutions for multi-defender stackelberg security
games. <em>IJCAI</em>, 433–439. (<a
href="https://doi.org/10.24963/ijcai.2022/62">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Multi-defender Stackelberg Security Games (MSSG) have recently gained increasing attention in the literature. However, the solutions offered to date are highly sensitive, wherein even small perturbations in the attacker&#39;s utility or slight uncertainties thereof can dramatically change the defenders&#39; resulting payoffs and alter the equilibrium. In this paper, we introduce a robust model for MSSGs, which admits solutions that are resistant to small perturbations or uncertainties in the game&#39;s parameters. First, we formally define the notion of robustness, as well as the robust MSSG model. Then, for the non-cooperative setting, we prove the existence of a robust approximate equilibrium in any such game, and provide an efficient construction thereof. For the cooperative setting, we show that any such game admits a robust approximate (alpha) core, and provide an efficient construction thereof. Lastly, we show that stronger types of the core may be empty. Interestingly, the robust solutions can substantially increase the defenders&#39; utilities over those of the non-robust ones. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Dolev Mutzari and Yonatan Aumann and Sarit Kraus},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/62},
  pages     = {433-439},
  title     = {Robust solutions for multi-defender stackelberg security games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Automated synthesis of mechanisms. <em>IJCAI</em>, 426–432.
(<a href="https://doi.org/10.24963/ijcai.2022/61">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Mechanism Design aims to design a game so that a desirable outcome is reached regardless of agents&#39; self-interests. In this paper, we show how this problem can be rephrased as a synthesis problem, where mechanisms are automatically synthesized from a partial or complete specification in a high-level logical language. We show that Quantitative Strategy Logic is a perfect candidate for specifying mechanisms as it can express complex strategic and quantitative properties. We solve automated mechanism design in two cases: when the number of actions is bounded, and when agents play in turn. Keywords: Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Munyque Mittelmann and Bastien Maubert and Aniello Murano and Laurent Perrussel},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/61},
  pages     = {426-432},
  title     = {Automated synthesis of mechanisms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Group wisdom at a price: Jury theorems with costly
information. <em>IJCAI</em>, 419–425. (<a
href="https://doi.org/10.24963/ijcai.2022/60">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study epistemic voting on binary issues where voters are characterized by their competence, i.e., the probability of voting for the correct alternative, and can choose between two actions: voting or abstaining. In our setting voting involves the expenditure of some effort, which is required to achieve the appropriate level of competence, whereas abstention carries no effort. We model this scenario as a game and characterize its equilibria under several variations. Our results show that when agents are aware of everyone&#39;s incentives, then the addition of effort may lead to Nash equilibria where wisdom of the crowds is lost. We further show that if agents&#39; awareness of each other is constrained by a social network, the topology of the network may actually mitigate this effect. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Matteo Michelini and Adrian Haret and Davide Grossi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/60},
  pages     = {419-425},
  title     = {Group wisdom at a price: Jury theorems with costly information},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fixing knockout tournaments with seeds. <em>IJCAI</em>,
412–418. (<a href="https://doi.org/10.24963/ijcai.2022/59">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Knockout tournaments constitute a popular format for organizing sports competitions. While prior results have shown that it is often possible to manipulate a knockout tournament by fixing the bracket, these results ignore the prevalent aspect of player seeds, which can significantly constrain the chosen bracket. We show that certain structural conditions that guarantee that a player can win a knockout tournament without seeds are no longer sufficient in light of seed constraints. On the other hand, we prove that when the pairwise match outcomes are generated randomly, all players are still likely to be knockout winners under the same probability threshold with seeds as without seeds. In addition, we investigate the complexity of deciding whether a manipulation is possible when seeds are present. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Pasin Manurangsi and Warut Suksompong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/59},
  pages     = {412-418},
  title     = {Fixing knockout tournaments with seeds},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized algorithms for kidney exchange.
<em>IJCAI</em>, 405–411. (<a
href="https://doi.org/10.24963/ijcai.2022/58">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In kidney exchange programs, multiple patient-donor pairs each of whom are otherwise incompatible, exchange their donors to receive compatible kidneys. The Kidney Exchange problem is typically modelled as a directed graph where every vertex is either an altruistic donor or a pair of patient and donor; directed edges are added from a donor to its compatible patients. The computational task is to find if there exists a collection of disjoint cycles and paths starting from altruistic donor vertices of length at most l_c and l_p respectively that covers at least some specific number t of non-altruistic vertices (patients). We study parameterized algorithms for the kidney exchange problem in this paper. Specifically, we design FPT algorithms parameterized by each of the following parameters: (1) the number of patients who receive kidney, (2) treewidth of the input graph + max{l_p, l_c}, and (3) the number of vertex types in the input graph when l_p &lt;= l_c. We also present interesting algorithmic and hardness results on the kernelization complexity of the problem. Finally, we present an approximation algorithm for an important special case of Kidney Exchange. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Arnab Maiti and Palash Dey},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/58},
  pages     = {405-411},
  title     = {Parameterized algorithms for kidney exchange},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Proportional budget allocations: Towards a systematization.
<em>IJCAI</em>, 398–404. (<a
href="https://doi.org/10.24963/ijcai.2022/57">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We contribute to the programme of lifting proportionality axioms from the multi-winner voting setting to participatory budgeting. We define novel proportionality axioms for participatory budgeting and test them on known proportionality-driven rules such as Phragmén and Rule X. We investigate logical implications among old and new axioms and provide a systematic overview of proportionality criteria in participatory budgeting. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Resource Allocation AI Ethics, Trust, Fairness: Fairness &amp; Diversity},
  archive   = {C_IJCAI},
  author    = {Maaike Los and Zoé Christoff and Davide Grossi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/57},
  pages     = {398-404},
  title     = {Proportional budget allocations: Towards a systematization},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Propositional gossip protocols under fair schedulers.
<em>IJCAI</em>, 391–397. (<a
href="https://doi.org/10.24963/ijcai.2022/56">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Gossip protocols are programs that can be used by a group of agents to synchronize what information they have. Namely, assuming each agent holds a secret, the goal of a protocol is to reach a situation in which all agents know all secrets. Distributed epistemic gossip protocols use epistemic formulas in the component programs for the agents. In this paper, we study the simplest classes of such gossip protocols: propositional gossip protocols, in which whether an agent wants to initiate a call depends only on the set of secrets that the agent currently knows. It was recently shown that such a protocol can be correct, i.e., always terminates in a state where all agents know all secrets, only when its communication graph is complete. We show here that this characterization dramatically changes when the usual fairness constraints are imposed on the call scheduler used. Finally, we establish that checking the correctness of a given propositional protocol under a fair scheduler is a coNP-complete problem. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Knowledge Representation and Reasoning: Reasoning about Knowledge and Belief Agent-based and Multi-agent Systems: Formal Verification, Validation and Synthesis Planning and Scheduling: Distributed; Multi-agent Planning Planning and Scheduling: Theoretical Foundations of Planning},
  archive   = {C_IJCAI},
  author    = {Joseph Livesey and Dominik Wojtczak},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/56},
  pages     = {391-397},
  title     = {Propositional gossip protocols under fair schedulers},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Modelling the dynamics of multi-agent q-learning: The
stochastic effects of local interaction and incomplete information.
<em>IJCAI</em>, 384–390. (<a
href="https://doi.org/10.24963/ijcai.2022/55">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The theoretical underpinnings of multiagent reinforcement learning has recently attracted much attention. In this work, we focus on the generalized social learning (GSL) protocol --- an agent interaction protocol that is widely adopted in the literature, and aim to develop an accurate theoretical model for the Q-learning dynamics under this protocol. Noting that previous models fail to characterize the effects of local interactions and incomplete information that arise from GSL, we model the Q-values dynamics of each individual agent as a system of stochastic differential equations (SDE). Based on the SDE, we express the time evolution of the probability density function of Q-values in the population with a Fokker-Planck equation. We validate the correctness of our model through extensive comparisons with agent-based simulation results across different types of symmetric games. In addition, we show that as the interactions between agents are more limited and information is less complete, the population can converge to a outcome that is qualitatively different than that with global interactions and complete information. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Multi-agent Learning},
  archive   = {C_IJCAI},
  author    = {Chin-wing Leung and Shuyue Hu and Ho-fung Leung},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/55},
  pages     = {384-390},
  title     = {Modelling the dynamics of multi-agent Q-learning: The stochastic effects of local interaction and incomplete information},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Biased majority opinion dynamics: Exploiting graph
k-domination. <em>IJCAI</em>, 377–383. (<a
href="https://doi.org/10.24963/ijcai.2022/54">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study opinion dynamics in multi-agent networks where agents hold binary opinions and are influenced by their neighbors while being biased towards one of the two opinions, called the superior opinion. The dynamics is modeled by the following process: at each round, a randomly selected agent chooses the superior opinion with some probability α, and with probability 1-α it conforms to the opinion manifested by the majority of its neighbors. In this work, we exhibit classes of network topologies for which we prove that the expected time for consensus on the superior opinion can be exponential. This answers an open conjecture in the literature. In contrast, we show that in all cubic graphs, convergence occurs after a polynomial number of rounds for every α. We rely on new structural graph properties by characterizing the opinion formation in terms of multiple domination, stable and decreasing structures in graphs, providing an interplay between bias, consensus and network structure. Finally, we provide both theoretical and experimental evidence for the existence of decreasing structures and relate it to the rich behavior observed on the expected convergence time of the opinion diffusion model. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Agent Societies},
  archive   = {C_IJCAI},
  author    = {Hicham Lesfari and Frédéric Giroire and Stéphane Pérennes},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/54},
  pages     = {377-383},
  title     = {Biased majority opinion dynamics: Exploiting graph k-domination},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Explaining preferences by multiple patterns in voters’
behavior. <em>IJCAI</em>, 370–376. (<a
href="https://doi.org/10.24963/ijcai.2022/53">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In some preference aggregation scenarios, voters&#39; preferences are highly structured: e.g., the set of candidates may have one-dimensional structure (so that voters&#39; preferences are single-peaked) or be described by a binary decision tree (so that voters&#39; preferences are group-separable). However, sometimes a single axis or a decision tree is insufficient to capture the voters&#39; preferences; rather, there is a small number K of axes or decision trees such that each vote in the profile is consistent with one of these axes (resp., trees). In this work, we study the complexity of deciding whether voters&#39; preferences can be explained in this manner. For K=2, we use the technique developed by Yang [2020, https://doi.org/10.3233/FAIA200099] in the context of single-peaked preferences to obtain a polynomial-time algorithm for several domains: value-restricted preferences, group-separable preferences, and a natural subdomain of group-separable preferences, namely, caterpillar group-separable preferences. For K &gt; 2, the problem is known to be hard for single-peaked preferences; we establish that it is also hard for value-restricted and group-separable preferences. Our positive results for K=2 make use of forbidden minor characterizations of the respective domains; in particular, we establish that the domain of caterpillar group-separable preferences admits a forbidden minor characterization. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Sonja Kraiczy and Edith Elkind},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/53},
  pages     = {370-376},
  title     = {Explaining preferences by multiple patterns in voters’ behavior},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Light agents searching for hot information. <em>IJCAI</em>,
363–369. (<a href="https://doi.org/10.24963/ijcai.2022/52">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Agent-based crawlers are commonly used in network maintenance and information gathering. In order not to disturb the main functionality of the system, whether acting at nodes or being in transit, they need to operate online, perform a single operation fast and use small memory. They should also be preferably deterministic, as crawling agents have limited capabilities of generating a large number of truly random bits. We consider a system in which an agent receives an update, typically an insertion or deletion, of some information upon visiting a node. On request, the agent needs to output hot information, i.e., with the net occurrence above certain frequency threshold. A desired time and memory complexity of such agent should be poly-logarithmic in the number of visited nodes and inversely proportional to the frequency threshold. Ours is the first such agent with rigorous analysis and a complementary almost-matching lower bound. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Data Mining: Mining Data Streams},
  archive   = {C_IJCAI},
  author    = {Dariusz R. Kowalski and Dominik Pajak},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/52},
  pages     = {363-369},
  title     = {Light agents searching for hot information},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The dichotomous affiliate stable matching problem:
Approval-based matching with applicant-employer relations.
<em>IJCAI</em>, 356–362. (<a
href="https://doi.org/10.24963/ijcai.2022/51">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {While the stable marriage problem and its variants model a vast range of matching markets, they fail to capture complex agent relationships, such as the affiliation of applicants and employers in an interview marketplace. To model this problem, the existing literature on matching with externalities permits agents to provide complete and total rankings over matchings based off of both their own and their affiliates&#39; matches. This complete ordering restriction is unrealistic, and further the model may have an empty core. To address this, we introduce the Dichotomous Affiliate Stable Matching (DASM) Problem, where agents&#39; preferences indicate dichotomous acceptance or rejection of another agent in the marketplace, both for themselves and their affiliates. We also assume the agent&#39;s preferences over entire matchings are determined by a general weighted valuation function of their (and their affiliates&#39;) matches. Our results are threefold: (1) we use a human study to show that real-world matching rankings follow our assumed valuation function; (2) we prove that there always exists a stable solution by providing an efficient, easily-implementable algorithm that finds such a solution; and (3) we experimentally validate the efficiency of our algorithm versus a linear-programming-based approach. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Marina Knittel and Samuel Dooley and John Dickerson},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/51},
  pages     = {356-362},
  title     = {The dichotomous affiliate stable matching problem: Approval-based matching with applicant-employer relations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Plurality veto: A simple voting rule achieving optimal
metric distortion. <em>IJCAI</em>, 349–355. (<a
href="https://doi.org/10.24963/ijcai.2022/50">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The metric distortion framework posits that n voters and m candidates are jointly embedded in a metric space such that voters rank candidates that are closer to them higher. A voting rule&#39;s purpose is to pick a candidate with minimum total distance to the voters, given only the rankings, but not the actual distances. As a result, in the worst case, each deterministic rule picks a candidate whose total distance is at least three times larger than that of an optimal one, i.e., has distortion at least 3. A recent breakthrough result showed that achieving this bound of 3 is possible; however, the proof is non-constructive, and the voting rule itself is a complicated exhaustive search. Our main result is an extremely simple voting rule, called Plurality Veto, which achieves the same optimal distortion of 3. Each candidate starts with a score equal to his number of first-place votes. These scores are then gradually decreased via an n-round veto process in which a candidate drops out when his score reaches zero. One after the other, voters decrement the score of their bottom choice among the standing candidates, and the last standing candidate wins. We give a one-paragraph proof that this voting rule achieves distortion 3. This rule is also immensely practical, and it only makes two queries to each voter, so it has low communication overhead. We also show that a straightforward extension can be used to give a constructive proof of the more general Ranking-Matching Lemma of Gkatzelis et al. We also generalize Plurality Veto into a class of randomized voting rules in the following way: Plurality veto is run only for k &lt; n rounds; then, a candidate is chosen with probability proportional to his residual score. This general rule interpolates between Random Dictatorship (for k=0) and Plurality Veto (for k=n-1), and k controls the variance of the output. We show that for all k, this rule has expected distortion at most 3. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Fatih Erdem Kizilkaya and David Kempe},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/50},
  pages     = {349-355},
  title     = {Plurality veto: A simple voting rule achieving optimal metric distortion},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On discrete truthful heterogeneous two-facility location.
<em>IJCAI</em>, 342–348. (<a
href="https://doi.org/10.24963/ijcai.2022/49">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We revisit the discrete heterogeneous two-facility location problem, in which there is a set of agents that occupy nodes of a line graph, and have private approval preferences over two facilities. When the facilities are located at some nodes of the line, each agent derives a cost that is equal to her total distance from the facilities she approves. The goal is to decide where to locate the two facilities, so as to (a) incentivize the agents to truthfully report their preferences, and (b) achieve a good approximation of the minimum total (social) cost or the maximum cost among all agents. For both objectives, we design deterministic strategyproof mechanisms with approximation ratios that significantly outperform the state-of-the-art, and complement these results with (almost) tight lower bounds. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Panagiotis Kanellopoulos and Alexandros A. Voudouris and Rongsen Zhang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/49},
  pages     = {342-348},
  title     = {On discrete truthful heterogeneous two-facility location},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Forgiving debt in financial network games. <em>IJCAI</em>,
335–341. (<a href="https://doi.org/10.24963/ijcai.2022/48">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider financial networks, where nodes correspond to banks and directed labeled edges correspond to debt contracts between banks. Maximizing systemic liquidity, i.e., the total money flow, is a natural objective of any financial authority. In particular, the financial authority may offer bailout money to some bank(s) or forgive the debts of others in order to maximize liquidity, and we examine efficient ways to achieve this. We study the computational hardness of finding the optimal debt-removal and budget-constrained optimal bailout policy, respectively, and we investigate the approximation ratio provided by the greedy bailout policy compared to the optimal one. We also study financial systems from a game-theoretic standpoint. We observe that the removal of some incoming debt might be in the best interest of a bank. Assuming that a bank&#39;s well-being (i.e., utility) is aligned with the incoming payments they receive from the network, we define and analyze a game among banks who want to maximize their utility by strategically giving up some incoming payments. In addition, we extend the previous game by considering bailout payments. After formally defining the above games, we prove results about the existence and quality of pure Nash equilibria, as well as the computational complexity of finding such equilibria. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Noncooperative Games Multidisciplinary Topics and Applications: Finance},
  archive   = {C_IJCAI},
  author    = {Panagiotis Kanellopoulos and Maria Kyropoulou and Hao Zhou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/48},
  pages     = {335-341},
  title     = {Forgiving debt in financial network games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Phragmén rules for degressive and regressive
proportionality. <em>IJCAI</em>, 328–334. (<a
href="https://doi.org/10.24963/ijcai.2022/47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study two concepts of proportionality in the model of approval-based committee elections. In degressive proportionality small minorities of voters are favored in comparison with the standard linear proportionality. Regressive proportionality, on the other hand, requires that larger subdivisions of voters are privileged. We introduce a new family of rules that broadly generalize Phragmén&#39;s Sequential Rule spanning the spectrum between degressive and regressive proportionality. We analyze and compare the two principles of proportionality assuming the voters and the candidates can be represented as points in an Euclidean issue space. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Michał Jaworski and Piotr Skowron},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/47},
  pages     = {328-334},
  title     = {Phragmén rules for degressive and regressive proportionality},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two for one &amp; one for all: Two-sided manipulation in
matching markets. <em>IJCAI</em>, 321–327. (<a
href="https://doi.org/10.24963/ijcai.2022/46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Strategic behavior in two-sided matching markets has been traditionally studied in a &quot;one-sided&quot; manipulation setting where the agent who misreports is also the intended beneficiary. Our work investigates &quot;two-sided&quot; manipulation of the deferred acceptance algorithm where the misreporting agent and the manipulator (or beneficiary) are on different sides. Specifically, we generalize the recently proposed accomplice manipulation model (where a man misreports on behalf of a woman) along two complementary dimensions: (a) the two for one model, with a pair of misreporting agents (man and woman) and a single beneficiary (the misreporting woman), and (b) the one for all model, with one misreporting agent (man) and a coalition of beneficiaries (all women). Our main contribution is to develop polynomial-time algorithms for finding an optimal manipulation in both settings. We obtain these results despite the fact that an optimal one for all strategy fails to be inconspicuous, while it is unclear whether an optimal two for one strategy satisfies the inconspicuousness property. We also study the conditions under which stability of the resulting matching is preserved. Experimentally, we show that two-sided manipulations are more frequently available and offer better quality matches than their one-sided counterparts. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Hadi Hosseini and Fatima Umar and Rohit Vaish},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/46},
  pages     = {321-327},
  title     = {Two for one &amp;amp; one for all: Two-sided manipulation in matching markets},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Can buyers reveal for a better deal? <em>IJCAI</em>,
314–320. (<a href="https://doi.org/10.24963/ijcai.2022/45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study market interactions in which buyers are allowed to credibly reveal partial information about their types to the seller. Previous recent work has studied the special case of one buyer and one good, showing that such communication can simultaneously improve social welfare and ex ante buyer utility. However, with multiple buyers, we find that the buyer-optimal signalling schemes from the one-buyer case are actually harmful to buyer welfare. Moreover, we prove several impossibility results showing that, with either multiple i.i.d. buyers or multiple i.i.d. goods, maximizing buyer utility can be at odds with social efficiency, which is surprising in contrast with the one-buyer, one-good case. Finally, we investigate the computational tractability of implementing desirable equilibrium outcomes. We find that, even with one buyer and one good, optimizing buyer utility is generally NP-hard but tractable in a practical restricted setting. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Daniel Halpern and Gregory Kehne and Jamie Tucker-Foltz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/45},
  pages     = {314-320},
  title     = {Can buyers reveal for a better deal?},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Picking the right winner: Why tie-breaking in crowdsourcing
contests matters. <em>IJCAI</em>, 307–313. (<a
href="https://doi.org/10.24963/ijcai.2022/44">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We present a complete information game-theoretic model for crowdsourcing contests. We observe that in design contests, coding contests and other domains, separating low quality submissions from high quality ones is often easy. However, pinning down the best submission is more challenging since there is no objective measure. We model this situation by assuming that each contestant has an ability, which we interpret as its probability of submitting a high-quality submission. After the contestants decide whether or not they want to participate, the organizer of the contest needs to break ties between the high quality submissions. A common assumption in the literature is that the exact tie-breaking rule does not matter as long as ties are broken consistently. However, we show that the choice of the tie-breaking rule may have significant implications on the efficiency of the contest. Our results highlight both qualitative and quantitative differences between various deterministic tie-breaking rules. Perhaps counterintuitively, we show that in many scenarios, the utility of the organizer is maximized when ties are broken in favor of successful players with lower ability. Nevertheless, we show that the natural rule of choosing the submission of the successful player with the highest ability guarantees the organizer at least 1/3 of its utility under any tie-breaking rule. To complement these results, we provide an upper bound of Hn ~ \ln(n) on the price of anarchy (the ratio between the social welfare of the optimal solution and the social welfare of the Nash equilibrium). We show that this ratio is tight when ties are broken in favor of players with higher abilities. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Coral Haggiag and Sigal Oren and Ella Segev},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/44},
  pages     = {307-313},
  title     = {Picking the right winner: Why tie-breaking in crowdsourcing contests matters},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approximate strategyproof mechanisms for the additively
separable group activity selection problem. <em>IJCAI</em>, 300–306. (<a
href="https://doi.org/10.24963/ijcai.2022/43">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We investigate strategyproof mechanisms in the Group Activity Selection Problem with the additively separable property. Namely, agents have distinct preferences for each activity and individual weights for the other agents. We evaluate our mechanisms in terms of their approximation ratio with respect to the maximum utilitarian social welfare. We first show that, for arbitrary non-negative preferences, no deterministic mechanism can achieve a bounded approximation ratio. Thus, we provide a randomized k-approximate mechanism, where k is the number of activities, and a corresponding 2-2/(k+1) lower bound. Furthermore, we propose a tight (2 - 1/k)-approximate randomized mechanism when activities are copyable. We then turn our attention to instances where preferences can only be unitary, that is 0 or 1. In this case, we provide a k-approximate deterministic mechanism, which we show to be the best possible one within the class of strategyproof and anonymous mechanisms. We also provide a general lower bound of Ω({\sqrt{k}}) when anonymity is no longer a constraint. Finally, we focus on unitary preferences and weights, and prove that, while any mechanism returning the optimum is not strategyproof, there exists a 2-approximate deterministic mechanism. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Michele Flammini and Giovanna Varricchio},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/43},
  pages     = {300-306},
  title     = {Approximate strategyproof mechanisms for the additively separable group activity selection problem},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Insight into voting problem complexity using randomized
classes. <em>IJCAI</em>, 293–299. (<a
href="https://doi.org/10.24963/ijcai.2022/42">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The first step in classifying the complexity of an NP problem is typically showing the problem in P or NP-complete. This has been a successful first step for many problems, including voting problems. However, in this paper we show that this may not always be the best first step. We consider the problem of constructive control by replacing voters (CCRV) introduced by Loreggia et al. [2015, https://dl.acm.org/doi/10.5555/2772879.2773411] for the scoring rule First-Last, which is defined by (1, 0, ..., 0, -1). We show that this problem is equivalent to Exact Perfect Bipartite Matching, and so CCRV for First-Last can be determined in random polynomial time. So on the one hand, if CCRV for First-Last is NP-complete then RP = NP, which is extremely unlikely. On the other hand, showing that CCRV for First-Last is in P would also show that Exact Perfect Bipartite Matching is in P, which would solve a well-studied 40-year-old open problem. Considering RP as an option for classifying problems can also help classify problems that until now had escaped classification. For example, the sole open problem in the comprehensive table from Erdélyi et al. [2021, https://doi.org/10.1007/s10458-021-09523-9] is CCRV for 2-Approval. We show that this problem is in RP, and thus easy since it is widely assumed that P = RP. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Zack Fitzsimmons and Edith Hemaspaandra},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/42},
  pages     = {293-299},
  title     = {Insight into voting problem complexity using randomized classes},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Representation matters: Characterisation and impossibility
results for interval aggregation. <em>IJCAI</em>, 286–292. (<a
href="https://doi.org/10.24963/ijcai.2022/41">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In the context of aggregating intervals reflecting the views of several agents into a single interval, we investigate the impact of the form of representation chosen for the intervals involved. Specifically, we ask whether there are natural rules we can define both as rules that aggregate separately the left and right endpoints of intervals and as rules that aggregate separately the left endpoints and the interval widths. We show that on discrete scales it is essentially impossible to do so, while on continuous scales we can characterise the rules meeting these requirements as those that compute a weighted average of the endpoints of the individual intervals. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Ulle Endriss and Arianna Novaro and Zoi Terzopoulou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/41},
  pages     = {286-292},
  title     = {Representation matters: Characterisation and impossibility results for interval aggregation},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Contests to incentivize a target group. <em>IJCAI</em>,
279–285. (<a href="https://doi.org/10.24963/ijcai.2022/40">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study how to incentivize agents in a target subpopulation to produce a higher output by means of rank-order allocation contests, in the context of incomplete information. We describe a symmetric Bayes--Nash equilibrium for contests that have two types of rank-based prizes: (1) prizes that are accessible only to the agents in the target group; (2) prizes that are accessible to everyone. We also specialize this equilibrium characterization to two important sub-cases: (i) contests that do not discriminate while awarding the prizes, i.e., only have prizes that are accessible to everyone; (ii) contests that have prize quotas for the groups, and each group can compete only for prizes in their share. For these models, we also study the properties of the contest that maximizes the expected total output by the agents in the target group. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems AI Ethics, Trust, Fairness: Fairness &amp; Diversity Multidisciplinary Topics and Applications: Economics},
  archive   = {C_IJCAI},
  author    = {Edith Elkind and Abheek Ghosh and Paul W. Goldberg},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/40},
  pages     = {279-285},
  title     = {Contests to incentivize a target group},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Efficient resource allocation with secretive agents.
<em>IJCAI</em>, 272–278. (<a
href="https://doi.org/10.24963/ijcai.2022/39">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the allocation of homogeneous divisible goods to agents with linear additive valuations. Our focus is on the case where some agents are secretive and reveal no preference information, while the remaining agents reveal full preference information. We study distortion, which is the worst-case approximation ratio when maximizing social welfare given such partial information about agent preferences. As a function of the number of secretive agents k relative to the overall number of agents n, we identify the exact distortion for every p-mean welfare function, which includes the utilitarian welfare (p=1), the Nash welfare (p -&gt; 0), and the egalitarian welfare (p -&gt; -Inf). Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Soroush Ebadian and Rupert Freeman and Nisarg Shah},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/39},
  pages     = {272-278},
  title     = {Efficient resource allocation with secretive agents},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Invasion dynamics in the biased voter process.
<em>IJCAI</em>, 265–271. (<a
href="https://doi.org/10.24963/ijcai.2022/38">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The voter process is a classic stochastic process that models the invasion of a mutant trait A (e.g., a new opinion, belief, legend, genetic mutation, magnetic spin) in a population of agents (e.g., people, genes, particles) who share a resident trait B, spread over the nodes of a graph. An agent may adopt the trait of one of its neighbors at any time, while the invasion bias r quantifies the stochastic preference towards (r&gt;1) or against (r1 and r1, the optimization function is submodular and thus can be greedily approximated within a factor 1-1/e. An experimental evaluation of some proposed heuristics corroborates our results. Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Agent Societies Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Multi-agent Learning Machine Learning: Optimisation},
  archive   = {C_IJCAI},
  author    = {Loke Durocher and Panagiotis Karras and Andreas Pavlogiannis and Josef Tkadlec},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/38},
  pages     = {265-271},
  title     = {Invasion dynamics in the biased voter process},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the ordinal invariance of power indices on coalitional
games. <em>IJCAI</em>, 258–264. (<a
href="https://doi.org/10.24963/ijcai.2022/37">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In a coalitional game, the coalitions are weakly ordered according to their worths in the game. When moreover a power index is given, the players are ranked according to the real numbers they are assigned by the power index. If any game inducing the same ordering of the coalitions generates the same ranking of the players then, by definition, the game is (ordinally) stable for the power index, which in turn is ordinally invariant for the game. If one is interested in ranking players of a game which is stable, re-computing the power indices when the coalitional worths slightly fluctuate or are uncertain becomes useless. Bivalued games are easy examples of games stable for any power index which is linear. Among general games, we characterize those that are stable for a given linear index. Note that the Shapley and Banzhaf scores, frequently used in AI, are particular semivalues, and all semivalues are linear indices. To check whether a game is stable for a specific semivalue, it suffices to inspect the ordering of the coalitions and to perform some direct computation based on the semivalue parameters. Keywords: Agent-based and Multi-agent Systems: Cooperative Games Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Jean-Paul Doignon and Stefano Moretti and Meltem Ozturk},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/37},
  pages     = {258-264},
  title     = {On the ordinal invariance of power indices on coalitional games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Online approval committee elections. <em>IJCAI</em>,
251–257. (<a href="https://doi.org/10.24963/ijcai.2022/36">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Assume k candidates need to be selected. The candidates appear over time. Each time one appears, it must be immediately selected or rejected---a decision that is made by a group of individuals through voting. Assume the voters use approval ballots, i.e., for each candidate they only specify whether they consider it acceptable or not. This setting can be seen as a voting variant of choosing k secretaries. Our contribution is twofold. (1) We assess to what extent the committees that are computed online can proportionally represent the voters. (2) If a prior probability over candidate approvals is available, we show how to compute committees with maximal expected score. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Virginie Do and Matthieu Hervouin and Jérôme Lang and Piotr Skowron},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/36},
  pages     = {251-257},
  title     = {Online approval committee elections},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Parameterized complexity of hotelling-downs with party
nominees. <em>IJCAI</em>, 244–250. (<a
href="https://doi.org/10.24963/ijcai.2022/35">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study a generalization of the Hotelling-Downs model through the lens of parameterized complexity. In this model, there is a set of voters on a line and a set of parties that compete over them. Each party has to choose a nominee from a set of candidates with predetermined positions on the line, where each candidate comes at a different cost. The goal of every party is to choose the most profitable nominee, given the nominees chosen by the rest of the parties; the profit of a party is the number of voters closer to their nominee minus its cost. We examine the complexity of deciding whether a pure Nash equilibrium exists for this model under several natural parameters: the number of different positions of the candidates, the discrepancy and the span of the nominees, and the overlap of the parties. We provide FPT and XP algorithms and we complement them with a W[1]-hardness result. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Argyrios Deligkas and Eduard Eiben and Tiger-Lily Goldsmith},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/35},
  pages     = {244-250},
  title     = {Parameterized complexity of hotelling-downs with party nominees},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). The complexity of envy-free graph cutting. <em>IJCAI</em>,
237–243. (<a href="https://doi.org/10.24963/ijcai.2022/34">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider the problem of fairly dividing a set of heterogeneous divisible resources among agents with different preferences. We focus on the setting where the resources correspond to the edges of a connected graph, every agent must be assigned a connected piece of this graph, and the fairness notion considered is the classical envy freeness. The problem is NP-complete, and we analyze its complexity with respect to two natural complexity measures: the number of agents and the number of edges in the graph. While the problem remains NP-hard even for instances with 2 agents, we provide a dichotomy characterizing the complexity of the problem when the number of agents is constant based on structural properties of the graph. For the latter case, we design a polynomial-time algorithm when the graph has a constant number of edges. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Argyrios Deligkas and Eduard Eiben and Robert Ganian and Thekla Hamm and Sebastian Ordyniak},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/34},
  pages     = {237-243},
  title     = {The complexity of envy-free graph cutting},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Approval with runoff. <em>IJCAI</em>, 230–236. (<a
href="https://doi.org/10.24963/ijcai.2022/33">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We define a family of runoff rules that work as follows: voters cast approval ballots over candidates; two finalists are selected; and the winner is decided by majority. With approval-type ballots, there are various ways to select the finalists. We leverage known approval-based committee rules and study the obtained runoff rules from an axiomatic point of view. Then we analyze the outcome of these rules on single-peaked profiles, and on real data. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Théo Delemazure and Jérôme Lang and Jean-François Laslier and M. Remzi Sanver},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/33},
  pages     = {230-236},
  title     = {Approval with runoff},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An analysis of the linear bilateral ANAC domains using the
MiCRO benchmark strategy. <em>IJCAI</em>, 223–229. (<a
href="https://doi.org/10.24963/ijcai.2022/32">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Automated Negotiating Agents Competition (ANAC) is an annual competition that compares the state-of-the-art algorithms in the field of automated negotiation. Although in recent years ANAC has given more and more attention to more complex scenarios, the linear and bilateral negotiation domains that were used for its first few editions are still widely used as the default benchmark in automated negotiations research. In this paper, however, we argue that these domains should no longer be used, because they are too simplistic. We demonstrate this with an extremely simple new negotiation strategy called MiCRO, which does not employ any form of opponent modeling or machine learning, but nevertheless outperforms the strongest participants of ANAC 2012, 2013, 2018 and 2019. Furthermore, we provide a theoretical analysis which explains why MiCRO performs so well in the ANAC domains. This analysis may help researchers to design more challenging negotiation domains in the future. Keywords: Agent-based and Multi-agent Systems: Agreement Technologies: Negotiation and Contract-Based Systems},
  archive   = {C_IJCAI},
  author    = {Dave De Jonge},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/32},
  pages     = {223-229},
  title     = {An analysis of the linear bilateral ANAC domains using the MiCRO benchmark strategy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Multi-agent intention progression with reward machines.
<em>IJCAI</em>, 215–222. (<a
href="https://doi.org/10.24963/ijcai.2022/31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Recent work in multi-agent intention scheduling has shown that enabling agents to predict the actions of other agents when choosing their own actions can be beneficial. However existing approaches to &#39;intention-aware&#39; scheduling assume that the programs of other agents are known, or are &quot;similar&quot; to that of the agent making the prediction. While this assumption is reasonable in some circumstances, it is less plausible when the agents are not co-designed. In this paper, we present a new approach to multi-agent intention scheduling in which agents predict the actions of other agents based on a high-level specification of the tasks performed by an agent in the form of a reward machine (RM) rather than on its (assumed) program. We show how a reward machine can be used to generate tree and rollout policies for an MCTS-based scheduler. We evaluate our approach in a range of multi-agent environments, and show that RM-based scheduling out-performs previous intention-aware scheduling approaches in settings where agents are not co-designed Keywords: Agent-based and Multi-agent Systems: Agent Theories and Models Agent-based and Multi-agent Systems: Engineering Methods, Platforms, Languages and Tools},
  archive   = {C_IJCAI},
  author    = {Michael Dann and Yuan Yao and Natasha Alechina and Brian Logan and John Thangarajah},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/31},
  pages     = {215-222},
  title     = {Multi-agent intention progression with reward machines},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Voting in two-crossing elections. <em>IJCAI</em>, 208–214.
(<a href="https://doi.org/10.24963/ijcai.2022/30">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We introduce two-crossing elections as a generalization of single-crossing elections, showing a number of new results. First, we show that two-crossing elections can be recognized in polynomial time, by reduction to the well-studied consecutive ones problem. Single-crossing elections exhibit a transitive majority relation, from which many important results follow. On the other hand, we show that the classical Debord-McGarvey theorem can still be proven two-crossing, implying that any weighted majority tournament is inducible by a two-crossing election. This shows that many voting rules are NP-hard under two-crossing elections, including Kemeny and Slater. This is in contrast to the single-crossing case and outlines an important complexity boundary between single- and two-crossing. Subsequently, we show that for two-crossing elections the Young scores of all candidates can be computed in polynomial time, by formulating a totally unimodular linear program. Finally, we consider the Chamberlin-Courant rule with arbitrary disutilities and show that a winning committee can be computed in polynomial time, using an approach based on dynamic programming. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Andrei Constantinescu and Roger Wattenhofer},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/30},
  pages     = {208-214},
  title     = {Voting in two-crossing elections},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Preserving consistency in multi-issue liquid democracy.
<em>IJCAI</em>, 201–207. (<a
href="https://doi.org/10.24963/ijcai.2022/29">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Liquid democracy bridges the gap between direct and representative democracy by allowing agents to vote directly on an issue or delegate to a trusted voter. Yet, when applied to votes on multiple interconnected issues, liquid democracy can lead agents to submit inconsistent votes. Two approaches are possible to maintain consistency: either modify the voters&#39; ballots by ignoring problematic delegations, or resolve all delegations and make changes to the final votes of the agents. We show that rules based on minimising such changes are NP-complete. We propose instead to elicit and apply the agents&#39; priorities over the delegated issues, designing and analysing two algorithms that find consistent votes from the agents&#39; delegations in polynomial time. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Rachael Colley and Umberto Grandi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/29},
  pages     = {201-207},
  title     = {Preserving consistency in multi-issue liquid democracy},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). A formal model for multiagent q-learning dynamics on regular
graphs. <em>IJCAI</em>, 194–200. (<a
href="https://doi.org/10.24963/ijcai.2022/28">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling the dynamics of multi-agent learning has long been an important research topic. The focus of previous research has been either on 2-agent settings or well-mixed infinitely large agent populations. In this paper, we consider the scenario where n Q-learning agents locate on regular graphs, such that agents can only interact with their neighbors. We examine the local interactions between individuals and their neighbors, and derive a formal model to capture the Q-value dynamics of the entire population. Through comparisons with agent-based simulations on different types of regular graphs, we show that our model describes the agent learning dynamics in an exact manner. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Agent Societies Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence},
  archive   = {C_IJCAI},
  author    = {Chen Chu and Yong Li and Jinzhuo Liu and Shuyue Hu and Xuelong Li and Zhen Wang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/28},
  pages     = {194-200},
  title     = {A formal model for multiagent Q-learning dynamics on regular graphs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Two-sided matching over social networks. <em>IJCAI</em>,
186–193. (<a href="https://doi.org/10.24963/ijcai.2022/27">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A new paradigm of mechanism design, called mechanism design over social networks, investigates agents’ incentives to diffuse the information of mechanisms to their followers over social networks. In this paper we consider it for two-sided matching, where the agents on one side, say students, are distributed over social networks and thus are not fully observable to the mechanism designer, while the agents on the other side, say colleges, are known a priori. The main purpose of this paper is to clarify the existence of mechanisms that satisfy several properties that are classified into four criteria: incentive constraints, efficiency constraints, stability constraints, and fairness constraints. We proposed three mechanisms and showed that no mechanism is better than these mechanisms, i.e., they are in the Pareto frontier according to the set of properties defined in this paper. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems},
  archive   = {C_IJCAI},
  author    = {Sung-Ho Cho and Taiki Todo and Makoto Yokoo},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/27},
  pages     = {186-193},
  title     = {Two-sided matching over social networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). On the convergence of fictitious play: A decomposition
approach. <em>IJCAI</em>, 179–185. (<a
href="https://doi.org/10.24963/ijcai.2022/26">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Fictitious play (FP) is one of the most fundamental game-theoretical learning frameworks for computing Nash equilibrium in n-player games, which builds the foundation for modern multi-agent learning algorithms. Although FP has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of FP has not been fully studied yet. In this paper, we extend the convergence results of FP to the combinations of such games and beyond. Specifically, we derive new conditions for FP to converge by leveraging game decomposition techniques. We further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. Finally, we analyse a non-convergent example of FP, the Shapley game, and develop sufficient conditions for FP to converge. Keywords: Agent-based and Multi-agent Systems: Noncooperative Games Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Yurong Chen and Xiaotie Deng and Chenchen Li and David Mguni and Jun Wang and Xiang Yan and Yaodong Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/26},
  pages     = {179-185},
  title     = {On the convergence of fictitious play: A decomposition approach},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Goal consistency: An effective multi-agent cooperative
method for multistage tasks. <em>IJCAI</em>, 172–178. (<a
href="https://doi.org/10.24963/ijcai.2022/25">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Although multistage tasks involving multiple sequential goals are common in real-world applications, they are not fully studied in multi-agent reinforcement learning (MARL). To accomplish a multi-stage task, agents have to achieve cooperation on different subtasks. Exploring the collaborative patterns of different subtasks and the sequence of completing the subtasks leads to an explosion in the search space, which poses great challenges to policy learning. Existing works designed for single-stage tasks where agents learn to cooperate only once usually suffer from low sample efficiency in multi-stage tasks as agents explore aimlessly. Inspired by human’s improving cooperation through goal consistency, we propose Multi-Agent Goal Consistency (MAGIC) framework to improve sample efficiency for learning in multi-stage tasks. MAGIC adopts a goal-oriented actor-critic model to learn both local and global views of goal cognition, which helps agents understand the task at the goal level so that they can conduct targeted exploration accordingly. Moreover, to improve exploration efficiency, MAGIC employs two-level goal consistency training to drive agents to formulate a consistent goal cognition. Experimental results show that MAGIC significantly improves sample efficiency and facilitates cooperation among agents compared with state-of-art MARL algorithms in several challenging multistage tasks. Keywords: Agent-based and Multi-agent Systems: Multi-agent Learning Agent-based and Multi-agent Systems: Coordination and Cooperation},
  archive   = {C_IJCAI},
  author    = {Xinning Chen and Xuan Liu and Shigeng Zhang and Bo Ding and Kenli Li},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/25},
  pages     = {172-178},
  title     = {Goal consistency: An effective multi-agent cooperative method for multistage tasks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Optimal anonymous independent reward scheme design.
<em>IJCAI</em>, 165–171. (<a
href="https://doi.org/10.24963/ijcai.2022/24">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider designing reward schemes that incentivize agents to create high-quality content (e.g., videos, images, text, ideas). The problem is at the center of a real-world application where the goal is to optimize the overall quality of generated content on user-generated content platforms. We focus on anonymous independent reward schemes (AIRS) that only take the quality of an agent&#39;s content as input. We prove the general problem is NP-hard. If the cost function is convex, we show the optimal AIRS can be formulated as a convex optimization problem and propose an efficient algorithm to solve it. Next, we explore the optimal linear reward scheme and prove it has a 1/2-approximation ratio, and the ratio is tight. Lastly, we show the proportional scheme can be arbitrarily bad compared to AIRS. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Mengjing Chen and Pingzhong Tang and Zihe Wang and Shenke Xiao and Xiwang Yang},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/24},
  pages     = {165-171},
  title     = {Optimal anonymous independent reward scheme design},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). VidyutVanika21: An autonomous intelligent broker for
smart-grids. <em>IJCAI</em>, 158–164. (<a
href="https://doi.org/10.24963/ijcai.2022/23">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {An autonomous broker that liaises between retail customers and power-generating companies (GenCos) is essential for the smart grid ecosystem. The efficiency brought in by such brokers to the smart grid setup can be studied through a well-developed simulation environment. In this paper, we describe the design of one such energy broker called VidyutVanika21 (VV21) and analyze its performance using a simulation platform called PowerTAC (PowerTrading Agent Competition). Specifically, we discuss the retail (VV21–RM) and wholesale market (VV21–WM) modules of VV21 that help the broker achieve high net profits in a competitive setup. Supported by game-theoretic analysis, the VV21–RM designs tariff contracts that a) maintain a balanced portfolio of different types of customers; b) sustain an appropriate level of market share, and c) introduce surcharges on customers to reduce energy usage during peak demand times. The VV21–WM aims to reduce the cost of procurement by following the supply curve of the GenCo to identify its lowest ask for a particular auction which is then used to generate suitable bids. We further demonstrate the efficacy of the retail and wholesale strategies of VV21 in PowerTAC 2021 finals and through several controlled experiments. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Applications},
  archive   = {C_IJCAI},
  author    = {Sanjay Chandlekar and Bala Suraj Pedasingu and Easwar Subramanian and Sanjay Bhat and Praveen Paruchuri and Sujit Gujar},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/23},
  pages     = {158-164},
  title     = {VidyutVanika21: An autonomous intelligent broker for smart-grids},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Network creation with homophilic agents. <em>IJCAI</em>,
151–157. (<a href="https://doi.org/10.24963/ijcai.2022/22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Network Creation Games are an important framework for understanding the formation of real-world networks. These games usually assume a set of indistinguishable agents strategically buying edges at a uniform price leading to a network among them. However, in real life, agents are heterogeneous and their relationships often display a bias towards similar agents, say of the same ethnic group. This homophilic behavior on the agent level can then lead to the emergent global phenomenon of social segregation. We study Network Creation Games with multiple types of homophilic agents and non-uniform edge cost, introducing two models focusing on the perception of same-type and different-type neighboring agents, respectively. Despite their different initial conditions, both our theoretical and experimental analysis show that both the composition and segregation strength of the resulting stable networks are almost identical, indicating a robust structure of social networks under homophily. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Martin Bullinger and Pascal Lenzner and Anna Melnichenko},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/22},
  pages     = {151-157},
  title     = {Network creation with homophilic agents},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). When votes change and committees should (not).
<em>IJCAI</em>, 144–150. (<a
href="https://doi.org/10.24963/ijcai.2022/21">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Electing a single committee of a small size is a classical and well-understood voting situation. Being interested in a sequence of committees, we introduce two time-dependent multistage models based on simple scoring-based voting. Therein, we are given a sequence of voting profiles (stages) over the same set of agents and candidates, and our task is to find a small committee for each stage of high score. In the conservative model we additionally require that any two consecutive committees have a small symmetric difference. Analogously, in the revolutionary model we require large symmetric differences. We prove both models to be NP-hard even for a constant number of agents, and, based on this, initiate a parameterized complexity analysis for the most natural parameters and combinations thereof. Among other results, we prove both models to be in XP yet W[1]-hard regarding the number of stages, and that being revolutionary seems to be &quot;easier&quot; than being conservative. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Robert Bredereck and Till Fluschnik and Andrzej Kaczmarczyk},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/21},
  pages     = {144-150},
  title     = {When votes change and committees should (Not)},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Single-peaked opinion updates. <em>IJCAI</em>, 137–143. (<a
href="https://doi.org/10.24963/ijcai.2022/20">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider opinion diffusion for undirected networks with sequential updates when the opinions of the agents are single-peaked preference rankings. Our starting point is the study of preserving single-peakedness. We identify voting rules that, when given a single-peaked profile, output at least one ranking that is single peaked w.r.t. a single-peaked axis of the input. For such voting rules we show convergence to a stable state of the diffusion process that uses the voting rule as the agents&#39; update rule. Further, we establish an efficient algorithm that maximises the spread of extreme opinions. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Robert Bredereck and Anne-Marie George and Jonas Israel and Leon Kellerhals},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/20},
  pages     = {137-143},
  title     = {Single-peaked opinion updates},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Incentives in social decision schemes with pairwise
comparison preferences. <em>IJCAI</em>, 130–136. (<a
href="https://doi.org/10.24963/ijcai.2022/19">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Social decision schemes (SDSs) map the preferences of individual voters over multiple alternatives to a probability distribution over the alternatives. In order to study properties such as efficiency, strategyproofness, and participation for SDSs, preferences over alternatives are typically lifted to preferences over lotteries using the notion of stochastic dominance (SD). However, requiring strategyproofness or strict participation with respect to this preference extension only leaves room for rather undesirable SDSs such as random dictatorships. Hence, we focus on the natural but little understood pairwise comparison (PC) preference extension, which postulates that one lottery is preferred to another if the former is more likely to return a preferred outcome. In particular, we settle three open questions raised by Brandt in Rolling the dice: Recent results in probabilistic social choice (2017): (i) there is no Condorcet-consistent SDS that satisfies PC-strategyproofness; (ii) there is no anonymous and neutral SDS that satisfies PC-efficiency and PC-strategyproofness; and (iii) there is no anonymous and neutral SDS that satisfies PC-efficiency and strict PC-participation. All three impossibilities require m&gt;=4 alternatives and turn into possibilities when m&lt;=3. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Felix Brandt and Patrick Lederer and Warut Suksompong},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/19},
  pages     = {130-136},
  title     = {Incentives in social decision schemes with pairwise comparison preferences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Let’s agree to agree: Targeting consensus for incomplete
preferences through majority dynamics. <em>IJCAI</em>, 123–129. (<a
href="https://doi.org/10.24963/ijcai.2022/18">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study settings in which agents with incomplete preferences need to make a collective decision. We focus on a process of majority dynamics where issues are addressed one at a time and undecided agents follow the opinion of the majority. We assess the effects of this process on various consensus notions—such as the Condorcet winner—and show that in the worst case, myopic adherence to the majority damages existing consensus; yet, simulation experiments indicate that the damage is often mild. We also examine scenarios where the chair of the decision process can control the existence (or the identity) of consensus, by determining the order in which the issues are discussed. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Sirin Botan and Simon Rey and Zoi Terzopoulou},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/18},
  pages     = {123-129},
  title     = {Let’s agree to agree: Targeting consensus for incomplete preferences through majority dynamics},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Distortion in voting with top-t preferences. <em>IJCAI</em>,
116–122. (<a href="https://doi.org/10.24963/ijcai.2022/17">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {A fundamental question in social choice and multi-agent systems is aggregating ordinal preferences expressed by agents into a measurably prudent collective choice. A promising line of recent work views ordinal preferences as a proxy for underlying cardinal preferences. It aims to optimize distortion, the worst-case approximation ratio of the (utilitarian) social welfare. When agents rank the set of alternatives, prior work identifies near-optimal voting rules for selecting one or more alternatives. However, ranking all the alternatives is prohibitive when there are many alternatives. In this work, we consider the setting where each agent ranks only her t favorite alternatives and identify almost tight bounds on the best possible distortion when selecting a single alternative or a committee of alternatives of a given size k. Our results also extend to approximating higher moments of social welfare. Along the way, we close a gap left open in prior work by identifying asymptotically tight distortion bounds for committee selection given full rankings. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Allan Borodin and Daniel Halpern and Mohamad Latifian and Nisarg Shah},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/17},
  pages     = {116-122},
  title     = {Distortion in voting with top-t preferences},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Toward policy explanations for multi-agent reinforcement
learning. <em>IJCAI</em>, 109–115. (<a
href="https://doi.org/10.24963/ijcai.2022/16">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Advances in multi-agent reinforcement learning (MARL) enable sequential decision making for a range of exciting multi-agent applications such as cooperative AI and autonomous driving. Explaining agent decisions is crucial for improving system transparency, increasing user satisfaction, and facilitating human-agent collaboration. However, existing works on explainable reinforcement learning mostly focus on the single-agent setting and are not suitable for addressing challenges posed by multi-agent environments. We present novel methods to generate two types of policy explanations for MARL: (i) policy summarization about the agent cooperation and task sequence, and (ii) language explanations to answer queries about agent behavior. Experimental results on three MARL domains demonstrate the scalability of our methods. A user study shows that the generated explanations significantly improve user performance and increase subjective ratings on metrics such as user satisfaction. Keywords: Agent-based and Multi-agent Systems: Human-Agent Interaction},
  archive   = {C_IJCAI},
  author    = {Kayla Boggess and Sarit Kraus and Lu Feng},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/16},
  pages     = {109-115},
  title     = {Toward policy explanations for multi-agent reinforcement learning},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Understanding distance measures among elections.
<em>IJCAI</em>, 102–108. (<a
href="https://doi.org/10.24963/ijcai.2022/15">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Motivated by putting empirical work based on (synthetic) election data on a more solid mathematical basis, we analyze six distances among elections, including, e.g., the challenging-to-compute but very precise swap distance and the distance used to form the so-called map of elections. Among the six, the latter seems to strike the best balance between its computational complexity and expressiveness. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Niclas Boehmer and Piotr Faliszewski and Rolf Niedermeier and Stanisław Szufa and Tomasz Wąs},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/15},
  pages     = {102-108},
  title     = {Understanding distance measures among elections},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Fair equilibria in sponsored search auctions: The
advertisers’ perspective. <em>IJCAI</em>, 95–101. (<a
href="https://doi.org/10.24963/ijcai.2022/14">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In this work we introduce a new class of mechanisms composed of a traditional Generalized Second Price (GSP) auction, and a fair division scheme in order to achieve some desired level of fairness between groups of Bayesian strategic advertisers. We propose two mechanisms, beta-Fair GSP and GSP-EFX, that compose GSP with, respectively, an envy-free up to one item, and an envy-free up to any item fair division scheme. The payments of GSP are adjusted in order to compensate advertisers that suffer a loss of efficiency due the fair division stage. We investigate the strategic learning implications of the deployment of sponsored search auction mechanisms that obey to such fairness criteria. We prove that, for both mechanisms, if bidders play so as to minimize their external regret they are guaranteed to reach an equilibrium with good social welfare. We also prove that the mechanisms are budget balanced, so that the payments charged by the traditional GSP mechanism are a good proxy of the total compensation offered to the advertisers. Finally, we evaluate the quality of the allocations through experiments on real-world data. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Georgios Birmpas and Andrea Celli and Riccardo Colini-Baldeschi and Stefano Leonardi},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/14},
  pages     = {95-101},
  title     = {Fair equilibria in sponsored search auctions: The advertisers’ perspective},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). General opinion formation games with social group
membership. <em>IJCAI</em>, 88–94. (<a
href="https://doi.org/10.24963/ijcai.2022/13">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Modeling how agents form their opinions is of paramount importance for designing marketing and electoral campaigns. In this work, we present a new framework for opinion formation which generalizes the well-known Friedkin-Johnsen model by incorporating three important features: (i) social group membership, that limits the amount of influence that people not belonging to the same group may lead on a given agent; (ii) both attraction among friends, and repulsion among enemies; (iii) different strengths of influence lead from different people on a given agent, even if the social relationships among them are the same. We show that, despite its generality, our model always admits a pure Nash equilibrium which, under opportune mild conditions, is even unique. Next, we analyze the performances of these equilibria with respect to a social objective function defined as a convex combination, parametrized by a value λ∈[0, 1], of the costs yielded by the untruthfulness of the declared opinions and the total cost of social pressure. We prove bounds on both the price of anarchy and the price of stability which show that, for not-too-extreme values of λ, performance at equilibrium are very close to optimal ones. For instance, in several interesting scenarios, the prices of anarchy and stability are both equal to max{2λ, 1-λ}/min{2λ, 1-λ} which never exceeds 2 for λ∈[1/5, 1/2]. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Vittorio Bilò and Diodato Ferraioli and Cosimo Vinci},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/13},
  pages     = {88-94},
  title     = {General opinion formation games with social group membership},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Tolerance is necessary for stability: Single-peaked swap
schelling games. <em>IJCAI</em>, 81–87. (<a
href="https://doi.org/10.24963/ijcai.2022/12">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Residential segregation in metropolitan areas is a phenomenon that can be observed all over the world. Recently, this was investigated via game-theoretic models. There, selfish agents of two types are equipped with a monotone utility function that ensures higher utility if an agent has more same-type neighbors. The agents strategically choose their location on a given graph that serves as residential area to maximize their utility. However, sociological polls suggest that real-world agents are actually favoring mixed-type neighborhoods, and hence should be modeled via non-monotone utility functions. To address this, we study Swap Schelling Games with single-peaked utility functions. Our main finding is that tolerance, i.e., agents favoring fifty-fifty neighborhoods or being in the minority, is necessary for equilibrium existence on almost regular or bipartite graphs. Regarding the quality of equilibria, we derive (almost) tight bounds on the Price of Anarchy and the Price of Stability. In particular, we show that the latter is constant on bipartite and almost regular graphs. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Noncooperative Games},
  archive   = {C_IJCAI},
  author    = {Davide Bilò and Vittorio Bilò and Pascal Lenzner and Louise Molitor},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/12},
  pages     = {81-87},
  title     = {Tolerance is necessary for stability: Single-peaked swap schelling games},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Time-constrained participatory budgeting under uncertain
project costs. <em>IJCAI</em>, 74–80. (<a
href="https://doi.org/10.24963/ijcai.2022/11">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {In participatory budgeting the stakeholders collectively decide which projects from a set of proposed projects should be implemented. This decision underlies both time and monetary constraints. In reality it is often impossible to figure out the exact cost of each project in advance, it is only known after a project is finished. To reduce risk, one can implement projects one after the other to be able to react to higher costs of a previous project. However, this will increase execution time drastically. We generalize existing frameworks to capture this setting, study desirable properties of algorithms for this problem, and show that some desirable properties are incompatible. Then we present and analyze algorithms that trade-off desirable properties. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Planning and Scheduling: Planning with Incomplete Information},
  archive   = {C_IJCAI},
  author    = {Dorothea Baumeister and Linus Boes and Christian Laußmann},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/11},
  pages     = {74-80},
  title     = {Time-constrained participatory budgeting under uncertain project costs},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Transparency, detection and imitation in strategic
classification. <em>IJCAI</em>, 67–73. (<a
href="https://doi.org/10.24963/ijcai.2022/10">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Given the ubiquity of AI-based decisions that affect individuals’ lives, providing transparent explanations about algorithms is ethically sound and often legally mandatory. How do individuals strategically adapt following explanations? What are the consequences of adaptation for algorithmic accuracy? We simulate the interplay between explanations shared by an Institution (e.g. a bank) and the dynamics of strategic adaptation by Individuals reacting to such feedback. Our model identifies key aspects related to strategic adaptation and the challenges that an institution could face as it attempts to provide explanations. Resorting to an agent-based approach, our model scrutinizes: i) the impact of transparency in explanations, ii) the interaction between faking behavior and detection capacity and iii) the role of behavior imitation. We find that the risks of transparent explanations are alleviated if effective methods to detect faking behaviors are in place. Furthermore, we observe that behavioral imitation --- as often happens across societies --- can alleviate malicious adaptation and contribute to accuracy, even after transparent explanations. Keywords: Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence AI Ethics, Trust, Fairness: Ethical, Legal and Societal Issues Multidisciplinary Topics and Applications: Finance},
  archive   = {C_IJCAI},
  author    = {Flavia Barsotti and Ruya Gokhan Kocer and Fernando P. Santos},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/10},
  pages     = {67-73},
  title     = {Transparency, detection and imitation in strategic classification},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Achieving envy-freeness with limited subsidies under
dichotomous valuations. <em>IJCAI</em>, 60–66. (<a
href="https://doi.org/10.24963/ijcai.2022/9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of allocating indivisible goods among agents in a fair manner. While envy-free allocations of indivisible goods are not guaranteed to exist, envy-freeness can be achieved by additionally providing some subsidy to the agents. These subsidies can be alternatively viewed as a divisible good (money) that is fractionally assigned among the agents to realize an envy-free outcome. In this setup, we bound the subsidy required to attain envy-freeness among agents with dichotomous valuations, i.e., among agents whose marginal value for any good is either zero or one. We prove that, under dichotomous valuations, there exists an allocation that achieves envy-freeness with a per-agent subsidy of either 0 or 1. Furthermore, such an envy-free solution can be computed efficiently in the standard value-oracle model. Notably, our results hold for general dichotomous valuations and, in particular, do not require the (dichotomous) valuations to be additive, submodular, or even subadditive. Also, our subsidy bounds are tight and provide a linear (in the number of agents) factor improvement over the bounds known for general monotone valuations. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Algorithmic Game Theory},
  archive   = {C_IJCAI},
  author    = {Siddharth Barman and Anand Krishna and Yadati Narahari and Soumyarup Sadhukhan},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/9},
  pages     = {60-66},
  title     = {Achieving envy-freeness with limited subsidies under dichotomous valuations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Envy-free and pareto-optimal allocations for agents with
asymmetric random valuations. <em>IJCAI</em>, 53–59. (<a
href="https://doi.org/10.24963/ijcai.2022/8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of allocating m indivisible items to n agents with additive utilities. It is desirable for the allocation to be both fair and efficient, which we formalize through the notions of envy-freeness and Pareto-optimality. While envy-free and Pareto-optimal allocations may not exist for arbitrary utility profiles, previous work has shown that such allocations exist with high probability assuming that all agents’ values for all items are independently drawn from a common distribution. In this paper, we consider a generalization of this model where each agent’s utilities are drawn independently from a distribution specific to the agent. We show that envy-free and Pareto-optimal allocations are likely to exist in this asymmetric model when m=Ω(n log n), which is tight up to a log log gap that also remains open in the symmetric subsetting. Furthermore, these guarantees can be achieved by a polynomial-time algorithm. Keywords: Agent-based and Multi-agent Systems: Resource Allocation Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Yushi Bai and Paul Gölz},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/8},
  pages     = {53-59},
  title     = {Envy-free and pareto-optimal allocations for agents with asymmetric random valuations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Mixed strategies for security games with general defending
requirements. <em>IJCAI</em>, 46–52. (<a
href="https://doi.org/10.24963/ijcai.2022/7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {The Stackelberg security game is played between a defender and an attacker, where the defender needs to allocate a limited amount of resources to multiple targets in order to minimize the loss due to adversarial attack by the attacker. While allowing targets to have different values, classic settings often assume uniform requirements to defend the targets. This enables existing results that study mixed strategies (randomized allocation algorithms) to adopt a compact representation of the mixed strategies. In this work, we initiate the study of mixed strategies for the security games in which the targets can have different defending requirements. In contrast to the case of uniform defending requirement, for which an optimal mixed strategy can be computed efficiently, we show that computing the optimal mixed strategy is NP-hard for the general defending requirements setting. However, we show that strong upper and lower bounds for the optimal mixed strategy defending result can be derived. We propose an efficient close-to-optimal Patching algorithm that computes mixed strategies that use only few pure strategies. We also study the setting when the game is played on a network and resource sharing is enabled between neighboring targets. Our experimental results demonstrate the effectiveness of our algorithm in several large real-world datasets. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory Agent-based and Multi-agent Systems: Resource Allocation Constraint Satisfaction and Optimization: Constraint Optimization Multidisciplinary Topics and Applications: Smart Cities},
  archive   = {C_IJCAI},
  author    = {Rufan Bai and Haoxing Lin and Xinyu Yang and Xiaowei Wu and Minming Li and Weijia Jia},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/7},
  pages     = {46-52},
  title     = {Mixed strategies for security games with general defending requirements},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Public signaling in bayesian ad auctions. <em>IJCAI</em>,
39–45. (<a href="https://doi.org/10.24963/ijcai.2022/6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study signaling in Bayesian ad auctions, in which bidders&#39; valuations depend on a random, unknown state of nature. The auction mechanism has complete knowledge of the actual state of nature, and it can send signals to bidders so as to disclose information about the state and increase revenue. For instance, a state may collectively encode some features of the user that are known to the mechanism only, since the latter has access to data sources unaccessible to the bidders. We study the problem of computing how the mechanism should send signals to bidders in order to maximize revenue. While this problem has already been addressed in the easier setting of second-price auctions, to the best of our knowledge, our work is the first to explore ad auctions with more than one slot. In this paper, we focus on public signaling and VCG mechanisms, under which bidders truthfully report their valuations. We start with a negative result, showing that, in general, the problem does not admit a PTAS unless P = NP, even when bidders&#39; valuations are known to the mechanism. The rest of the paper is devoted to settings in which such negative result can be circumvented. First, we prove that, with known valuations, the problem can indeed be solved in polynomial time when either the number of states d or the number of slots m is fixed. Moreover, in the same setting, we provide an FPTAS for the case in which bidders are single minded, but d and m can be arbitrary. Then, we switch to the random valuations setting, in which these are randomly drawn according to some probability distribution. In this case, we show that the problem admits an FPTAS, a PTAS, and a QPTAS, when, respectively, d is fixed, m is fixed, and bidders&#39; valuations are bounded away from zero. Keywords: Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Mechanism Design},
  archive   = {C_IJCAI},
  author    = {Francesco Bacchiocchi and Matteo Castiglioni and Alberto Marchesi and Giulia Romano and Nicola Gatti},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/6},
  pages     = {39-45},
  title     = {Public signaling in bayesian ad auctions},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). How should we vote? A comparison of voting systems within
social networks. <em>IJCAI</em>, 31–38. (<a
href="https://doi.org/10.24963/ijcai.2022/5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Voting is a crucial methodology for eliciting and combining agents&#39; preferences and information across many applications. Just as there are numerous voting rules exhibiting different properties, we also see many different voting systems. In this paper we investigate how different voting systems perform as a function of the characteristics of the underlying voting population and social network. In particular, we compare direct democracy, liquid democracy, and sortition in a ground truth voting context. Through simulations -- using both real and artificially generated social networks -- we illustrate how voter competency distributions and levels of direct participation affect group accuracy differently in each voting mechanism. Our results can be used to guide the selection of a suitable voting system based on the characteristics of a particular voting setting. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence},
  archive   = {C_IJCAI},
  author    = {Shiri Alouf-Heffetz and Ben Armstrong and Kate Larson and Nimrod Talmon},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/5},
  pages     = {31-38},
  title     = {How should we vote? a comparison of voting systems within social networks},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Better collective decisions via uncertainty reduction.
<em>IJCAI</em>, 24–30. (<a
href="https://doi.org/10.24963/ijcai.2022/4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We consider an agent community wishing to decide on several binary issues by means of issue-by-issue majority voting. For each issue and each agent, one of the two options is better than the other. However, some of the agents may be confused about some of the issues, in which case they may vote for the option that is objectively worse for them. A benevolent external party wants to help the agents to make better decisions, i.e., select the majority-preferred option for as many issues as possible. This party may have one of the following tools at its disposal: (1) educating some of the agents, so as to enable them to vote correctly on all issues, (2) appointing a subset of highly competent agents to make decisions on behalf of the entire group, or (3) guiding the agents on how to delegate their votes to other agents, in a way that is consistent with the agents&#39; opinions. For each of these tools, we study the complexity of the decision problem faced by this external party, obtaining both NP-hardness results and fixed-parameter tractability results. Keywords: Agent-based and Multi-agent Systems: Computational Social Choice},
  archive   = {C_IJCAI},
  author    = {Shiri Alouf-Heffetz and Laurent Bulteau and Edith Elkind and Nimrod Talmon and Nicholas Teh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/4},
  pages     = {24-30},
  title     = {Better collective decisions via uncertainty reduction},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). An EF2X allocation protocol for restricted additive
valuations. <em>IJCAI</em>, 17–23. (<a
href="https://doi.org/10.24963/ijcai.2022/3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {We study the problem of fairly allocating a set of indivisible goods to a set of n agents. Envy-freeness up to any good (EFX) criterion (which requires that no agent prefers the bundle of another agent after the removal of any single good) is known to be a remarkable analogue of envy-freeness when the resource is a set of indivisible goods. In this paper, we investigate EFX for restricted additive valuations, that is, every good has a non-negative value, and every agent is interested in only some of the goods. We introduce a natural relaxation of EFX called EFkX which requires that no agent envies another agent after the removal of any k goods. Our main contribution is an algorithm that finds a complete (i.e., no good is discarded) EF2X allocation for restricted additive valuations. In our algorithm we devise new concepts, namely configuration and envy-elimination that might be of independent interest. We also use our new tools to find an EFX allocation for restricted additive valuations that discards at most n/2 -1 goods. Keywords: Agent-based and Multi-agent Systems: Algorithmic Game Theory AI Ethics, Trust, Fairness: Fairness &amp; Diversity},
  archive   = {C_IJCAI},
  author    = {Hannaneh Akrami and Rojin Rezvan and Masoud Seddighin},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/3},
  pages     = {17-23},
  title     = {An EF2X allocation protocol for restricted additive valuations},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Socially intelligent genetic agents for the emergence of
explicit norms. <em>IJCAI</em>, 10–16. (<a
href="https://doi.org/10.24963/ijcai.2022/2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {Norms help regulate a society. Norms may be explicit (represented in structured form) or implicit. We address the emergence of explicit norms by developing agents who provide and reason about explanations for norm violations in deciding sanctions and identifying alternative norms. These agents use a genetic algorithm to produce norms and reinforcement learning to learn the values of these norms. We find that applying explanations leads to norms that provide better cohesion and goal satisfaction for the agents. Our results are stable for societies with differing attitudes of generosity. Keywords: Agent-based and Multi-agent Systems: Agent-Based Simulation and Emergence Agent-based and Multi-agent Systems: Normative systems},
  archive   = {C_IJCAI},
  author    = {Rishabh Agrawal and Nirav Ajmeri and Munindar Singh},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/2},
  pages     = {10-16},
  title     = {Socially intelligent genetic agents for the emergence of explicit norms},
  year      = {2022},
}
</textarea>
</details></li>
<li><details>
<summary>
(2022). Anytime capacity expansion in medical residency match by
monte carlo tree search. <em>IJCAI</em>, 3–9. (<a
href="https://doi.org/10.24963/ijcai.2022/1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@inproceedings{ ,
  abstract  = {This paper considers the capacity expansion problem in two-sided matchings, where the policymaker is allowed to allocate some extra seats as well as the standard seats. In medical residency match, each hospital accepts a limited number of doctors. Such capacity constraints are typically given in advance. However, such exogenous constraints can compromise the welfare of the doctors; some popular hospitals inevitably dismiss some of their favorite doctors. Meanwhile, it is often the case that the hospitals are also benefited to accept a few extra doctors. To tackle the problem, we propose an anytime method that the upper confidence tree searches the space of capacity expansions, each of which has a resident-optimal stable assignment that the deferred acceptance method finds. Constructing a good search tree representation significantly boosts the performance of the proposed method. Our simulation shows that the proposed method identifies an almost optimal capacity expansion with a significantly smaller computational budget than exact methods based on mixed-integer programming. Keywords: Agent-based and Multi-agent Systems: Mechanism Design Agent-based and Multi-agent Systems: Economic Paradigms, Auctions and Market-Based Systems Agent-based and Multi-agent Systems: Resource Allocation Search: Search and Machine Learning},
  archive   = {C_IJCAI},
  author    = {Kenshi Abe and Junpei Komiyama and Atsushi Iwasaki},
  booktitle = {Thirty-First International Joint Conference on Artificial Intelligence},
  doi       = {10.24963/ijcai.2022/1},
  pages     = {3-9},
  title     = {Anytime capacity expansion in medical residency match by monte carlo tree search},
  year      = {2022},
}
</textarea>
</details></li>
</ul>

</body>
</html>
