<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tiis---22">TIIS - 22</h2>
<ul>
<li><details>
<summary>
(2020). Generating and understanding personalized explanations in
hybrid recommender systems. <em>TIIS</em>, <em>10</em>(4), 1–40. (<a
href="https://doi.org/10.1145/3365843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are ubiquitous and shape the way users access information and make decisions. As these systems become more complex, there is a growing need for transparency and interpretability. In this article, we study the problem of generating and visualizing personalized explanations for recommender systems that incorporate signals from many different data sources. We use a flexible, extendable probabilistic programming approach and show how we can generate real-time personalized recommendations. We then turn these personalized recommendations into explanations. We perform an extensive user study to evaluate the benefits of explanations for hybrid recommender systems. We conduct a crowd-sourced user study where our system generates personalized recommendations and explanations for real users of the last.fm music platform. First, we evaluate the performance of the recommendations in terms of perceived accuracy and novelty. Next, we experiment with (1) different explanation styles (e.g., user-based, item-based), (2) manipulating the number of explanation styles presented, and (3) manipulating the presentation format (e.g., textual vs. visual). We also apply a mixed-model statistical analysis to consider user personality traits as a control variable and demonstrate the usefulness of our approach in creating personalized hybrid explanations with different style, number, and format. Finally, we perform a post analysis that shows different preferences for explanation styles between experienced and novice last.fm users.},
  archive      = {J_TIIS},
  doi          = {10.1145/3365843},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1-40},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Generating and understanding personalized explanations in hybrid recommender systems},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithmic and HCI aspects for explaining recommendations
of artistic images. <em>TIIS</em>, <em>10</em>(4), 1–31. (<a
href="https://doi.org/10.1145/3369396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining suggestions made by recommendation systems is key to make users trust and accept these systems. This is specially critical in areas such as art image recommendation. Traditionally, artworks are sold in galleries where people can see them physically, and artists have the chance to persuade the people into buying them. On the other side, online art stores only offer the user the action of navigating through the catalog, but nobody plays the persuading role of the artist. Moreover, few works in recommendation systems provide a perspective of the many variables involved in the user perception of several aspects of the system such as domain knowledge, relevance, explainability, and trust. In this article, we aim to fill this gap by studying several aspects of the user experience with a recommender system of artistic images, from algorithmic and HCI perspectives. We conducted two user studies in Amazon Mechanical Turk to evaluate different levels of explainability, combined with different algorithms. While in study 1 we focus only on a desktop interface, in study 2 we attempt to understand the effect of explanations in mobile devices. In general, our experiments confirm that explanations of recommendations in the image domain are useful and increase user satisfaction, perception of explainability and relevance. In the first study, our results show that the observed effects are dependent on the underlying recommendation algorithm used. In the second study, our results show that these effects are also dependent of the device used in the study but with a smaller effect. Finally, using the framework by Knijnenburg et al., we provide a comprehensive model, for each study, which synthesizes the effects between different variables involved in the user experience with explainable visual recommender systems of artistic images.},
  archive      = {J_TIIS},
  doi          = {10.1145/3369396},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1-31},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Algorithmic and HCI aspects for explaining recommendations of artistic images},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smell pittsburgh: Engaging community citizen science for air
quality. <em>TIIS</em>, <em>10</em>(4), 1–49. (<a
href="https://doi.org/10.1145/3369397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban air pollution has been linked to various human health concerns, including cardiopulmonary diseases. Communities who suffer from poor air quality often rely on experts to identify pollution sources due to the lack of accessible tools. Taking this into account, we developed Smell Pittsburgh , a system that enables community members to report odors and track where these odors are frequently concentrated. All smell report data are publicly accessible online. These reports are also sent to the local health department and visualized on a map along with air quality data from monitoring stations. This visualization provides a comprehensive overview of the local pollution landscape. Additionally, with these reports and air quality data, we developed a model to predict upcoming smell events and send push notifications to inform communities. We also applied regression analysis to identify statistically significant effects of push notifications on user engagement. Our evaluation of this system demonstrates that engaging residents in documenting their experiences with pollution odors can help identify local air pollution patterns and can empower communities to advocate for better air quality. All citizen-contributed smell data are publicly accessible and can be downloaded from https://smellpgh.org .},
  archive      = {J_TIIS},
  doi          = {10.1145/3369397},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1-49},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Smell pittsburgh: Engaging community citizen science for air quality},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A method and analysis to elicit user-reported problems in
intelligent everyday applications. <em>TIIS</em>, <em>10</em>(4), 1–27.
(<a href="https://doi.org/10.1145/3370927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex nature of intelligent systems motivates work on supporting users during interaction, for example, through explanations. However, as of yet, there is little empirical evidence in regard to specific problems users face when applying such systems in everyday situations. This article contributes a novel method and analysis to investigate such problems as reported by users: We analysed 45,448 reviews of four apps on the Google Play Store (Facebook, Netflix, Google Maps, and Google Assistant) with sentiment analysis and topic modelling to reveal problems during interaction that can be attributed to the apps’ algorithmic decision-making. We enriched this data with users’ coping and support strategies through a follow-up online survey (N = 286). In particular, we found problems and strategies related to content, algorithm, user choice, and feedback. We discuss corresponding implications for designing user support, highlighting the importance of user control and explanations of output rather than processes.},
  archive      = {J_TIIS},
  doi          = {10.1145/3370927},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1-27},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {A method and analysis to elicit user-reported problems in intelligent everyday applications},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Affect-aware word clouds. <em>TIIS</em>, <em>10</em>(4),
1–25. (<a href="https://doi.org/10.1145/3370928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word clouds are widely used for non-analytic purposes, such as introducing a topic to students, or creating a gift with personally meaningful text. Surveys show that users prefer tools that yield word clouds with a stronger emotional impact. Fonts and color palettes are powerful typographical signals that may determine this impact. Typically, these signals are assigned randomly, or expected to be chosen by the users. We present an affect-aware font and color palette selection methodology that aims to facilitate more informed choices. We infer associations of fonts with a set of eight affects, and evaluate the resulting data in a series of user studies both on individual words as well as in word clouds. Relying on a recent study to procure affective color palettes, we carry out a similar user study to understand the impact of color choices on word clouds. Our findings suggest that both fonts and color palettes are powerful tools contributing to the affects evoked by a word cloud. The experiments further confirm that the novel datasets we propose are successful in enabling this. We also find that, for the majority of the affects, both signals need to be congruent to create a stronger impact. Based on this data, we implement a prototype that allows users to specify a desired affect and recommends congruent fonts and color palettes for the word.},
  archive      = {J_TIIS},
  doi          = {10.1145/3370928},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Affect-aware word clouds},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introduction to the TiiS special column. <em>TIIS</em>,
<em>10</em>(4), 1. (<a href="https://doi.org/10.1145/3427592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TIIS},
  doi          = {10.1145/3427592},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {4},
  pages        = {1},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Introduction to the TiiS special column},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Photo sleuth: Identifying historical portraits with face
recognition and crowdsourced human expertise. <em>TIIS</em>,
<em>10</em>(4), 1–36. (<a
href="https://doi.org/10.1145/3365842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying people in historical photographs is important for preserving material culture, correcting the historical record, and creating economic value, but it is also a complex and challenging task. In this article, we focus on identifying portraits of soldiers who participated in the American Civil War (1861--65), the first widely photographed conflict. Many thousands of these portraits survive, but only 10%--20% are identified. We created Photo Sleuth, a web-based platform that combines crowdsourced human expertise and automated face recognition to support Civil War portrait identification. Our mixed-methods evaluations of Photo Sleuth one month and 11 months after its public launch showed that it helped users successfully identify unknown portraits and provided a sustainable model for volunteer contribution. We also discuss implications for crowd-AI interaction and person identification pipelines.},
  archive      = {J_TIIS},
  doi          = {10.1145/3365842},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {10},
  number       = {4},
  pages        = {1-36},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Photo sleuth: Identifying historical portraits with face recognition and crowdsourced human expertise},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Progressive disclosure: When, why, and how do users want
algorithmic transparency information? <em>TIIS</em>, <em>10</em>(4),
1–32. (<a href="https://doi.org/10.1145/3374218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is essential that users understand how algorithmic decisions are made, as we increasingly delegate important decisions to intelligent systems. Prior work has often taken a techno-centric approach, focusing on new computational techniques to support transparency. In contrast, this article employs empirical methods to better understand user reactions to transparent systems to motivate user-centric designs for transparent systems. We assess user reactions to transparency feedback in four studies of an emotional analytics system. In Study 1, users anticipated that a transparent system would perform better but unexpectedly retracted this evaluation after experience with the system. Study 2 offers an explanation for this paradox by showing that the benefits of transparency are context dependent. On the one hand, transparency can help users form a model of the underlying algorithm&#39;s operation. On the other hand, positive accuracy perceptions may be undermined when transparency reveals algorithmic errors. Study 3 explored real-time reactions to transparency. Results confirmed Study 2, in showing that users are both more likely to consult transparency information and to experience greater system insights when formulating a model of system operation. Study 4 used qualitative methods to explore real-time user reactions to motivate transparency design principles. Results again suggest that users may benefit from initially simplified feedback that hides potential system errors and assists users in building working heuristics about system operation. We use these findings to motivate new progressive disclosure principles for transparency in intelligent systems and discuss theoretical implications.},
  archive      = {J_TIIS},
  doi          = {10.1145/3374218},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {10},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Progressive disclosure: When, why, and how do users want algorithmic transparency information?},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bridging the gap between ethics and practice: Guidelines for
reliable, safe, and trustworthy human-centered AI systems.
<em>TIIS</em>, <em>10</em>(4), 1–31. (<a
href="https://doi.org/10.1145/3419764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, non-governmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society.},
  archive      = {J_TIIS},
  doi          = {10.1145/3419764},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {10},
  number       = {4},
  pages        = {1-31},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Bridging the gap between ethics and practice: Guidelines for reliable, safe, and trustworthy human-centered AI systems},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Being the center of attention: A person-context CNN
framework for personality recognition. <em>TIIS</em>, <em>10</em>(3),
1–20. (<a href="https://doi.org/10.1145/3338245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel study on personality recognition using video data from different scenarios. Our goal is to jointly model nonverbal behavioral cues with contextual information for a robust, multi-scenario, personality recognition system. Therefore, we build a novel multi-stream Convolutional Neural Network (CNN) framework, which considers multiple sources of information. From a given scenario, we extract spatio-temporal motion descriptors from every individual in the scene, spatio-temporal motion descriptors encoding social group dynamics, and proxemics descriptors to encode the interaction with the surrounding context. All the proposed descriptors are mapped to the same feature space facilitating the overall learning effort. Experiments on two public datasets demonstrate the effectiveness of jointly modeling the mutual Person-Context information, outperforming the state-of-the art-results for personality recognition in two different scenarios. Last, we present CNN class activation maps for each personality trait, shedding light on behavioral patterns linked with personality attributes.},
  archive      = {J_TIIS},
  doi          = {10.1145/3338245},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-20},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Being the center of attention: A person-context CNN framework for personality recognition},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling dyslexic students’ motivation for enhanced learning
in e-learning systems. <em>TIIS</em>, <em>10</em>(3), 1–34. (<a
href="https://doi.org/10.1145/3341197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-Learning systems can support real-time monitoring of learners’ learning desires and effects, thus offering opportunities for enhanced personalized learning. Recognition of the determinants of dyslexic users’ motivation to use e-learning systems is important to help developers improve the design of e-learning systems and educators direct their efforts to relevant factors to enhance dyslexic students’ motivation. Existing research has rarely attempted to model dyslexic users’ motivation in e-learning context from a comprehensive perspective. The present work has conceived a hybrid approach, namely, combining the strengths of qualitative and quantitative analysis methods, to motivation modeling. It examines a variety of factors that affect dyslexic students’ motivation to engage in e-learning systems from psychological, behavioral, and technical perspectives, and establishes their interrelationships. Specifically, the study collects data from a multi-item Likert-style questionnaire to measure relevant factors for conceptual motivation modeling. It then applies both covariance-based (CB-SEM) and variance-based structural equation modeling (PLS-SEM) approaches to determine the quantitative mapping between dyslexic students’ continued use intention and motivational factors, followed by discussions about theoretical findings and design instructions according to our motivation model. Our research has led to a novel motivation model with new constructs of Learning Experience, Reading Experience, Perceived Control, and Perceived Privacy. From both the CB-SEM and PLS-SEM analyses, results on the total effects have indicated consistently that Visual Attractiveness, Reading Experience, and Feedback have the strongest effects on continued use intention.},
  archive      = {J_TIIS},
  doi          = {10.1145/3341197},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-34},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Modeling dyslexic students’ motivation for enhanced learning in E-learning systems},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An autonomous cognitive empathy model responsive to users’
facial emotion expressions. <em>TIIS</em>, <em>10</em>(3), 1–23. (<a
href="https://doi.org/10.1145/3341198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Successful social robot services depend on how robots can interact with users. The effective service can be obtained through smooth, engaged, and humanoid interactions in which robots react properly to a user’s affective state. This article proposes a novel Automatic Cognitive Empathy Model, ACEM, for humanoid robots to achieve longer and more engaged human-robot interactions (HRI) by considering humans’ emotions and replying to them appropriately. The proposed model continuously detects the affective states of a user based on facial expressions and generates desired, either parallel or reactive, empathic behaviors that are already adapted to the user’s personality. Users’ affective states are detected using a stacked autoencoder network that is trained and tested on the RAVDESS dataset. The overall proposed empathic model is verified throughout an experiment, where different emotions are triggered in participants and then empathic behaviors are applied based on proposed hypothesis. The results confirm the effectiveness of the proposed model in terms of related social and friendship concepts that participants perceived during interaction with the robot.},
  archive      = {J_TIIS},
  doi          = {10.1145/3341198},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-23},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {An autonomous cognitive empathy model responsive to users’ facial emotion expressions},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How impactful is presentation in email? The effect of
avatars and signatures. <em>TIIS</em>, <em>10</em>(3), 1–26. (<a
href="https://doi.org/10.1145/3345641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary well-controlled study of 900 participants found that personal presentation choices in professional emails (non-content changes like Profile Avatar 8 Signature) impact the recipient’s perception of the sender’s personality and the quality of the email itself. By understanding the role these choices play, employees can gain better control over how they influence the recipient of their messages. Results further indicate that although some variations can positively impact the recipient’s view of the sender, these same variations often also have negative side effects. This implies that many seemingly innocuous presentation decisions should be made in the context of who is receiving the email, and if these effects negatively impact the content of the message. For example, although statements in a Signature about the email having been written on a phone are included to preemptively apologize for typing mistakes, this causes the sender to appear less agreeable, less conscientious, and less open, and the email itself appears less well written and more poorly formatted. This is surprising given that the email itself was not changed in the study.},
  archive      = {J_TIIS},
  doi          = {10.1145/3345641},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {How impactful is presentation in email? the effect of avatars and signatures},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning context-dependent personal preferences for adaptive
recommendation. <em>TIIS</em>, <em>10</em>(3), 1–26. (<a
href="https://doi.org/10.1145/3359755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two online-learning algorithms for modeling the personal preferences of users of interactive systems. The proposed algorithms leverage user feedback to estimate user behavior and provide personalized adaptive recommendation for supporting context-dependent decision-making. We formulate preference modeling as online prediction algorithms over a set of learned policies, i.e., policies generated via supervised learning with interaction and context data collected from previous users. The algorithms then adapt to a target user by learning the policy that best predicts that user’s behavior and preferences. We also generalize the proposed algorithms for a more challenging learning case in which they are restricted to a limited number of trained policies at each timestep, i.e., for mobile settings with limited resources. While the proposed algorithms are kept general for use in a variety of domains, we developed an image-filter-selection application. We used this application to demonstrate how the proposed algorithms can quickly learn to match the current user’s selections. Based on these evaluations, we show that (1) the proposed algorithms exhibit better prediction accuracy compared to traditional supervised learning and bandit algorithms, (2) our algorithms are robust under challenging limited prediction settings in which a smaller number of expert policies is assumed. Finally, we conducted a user study to demonstrate how presenting users with the prediction results of our algorithms significantly improves the efficiency of the overall interaction experience.},
  archive      = {J_TIIS},
  doi          = {10.1145/3359755},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-26},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Learning context-dependent personal preferences for adaptive recommendation},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on data-driven personality modeling for
intelligent human-computer interaction. <em>TIIS</em>, <em>10</em>(3),
1–3. (<a href="https://doi.org/10.1145/3402522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TIIS},
  doi          = {10.1145/3402522},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {11},
  number       = {3},
  pages        = {1-3},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Special issue on data-driven personality modeling for intelligent human-computer interaction},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting users’ movie preference and rating behavior from
personality and values. <em>TIIS</em>, <em>10</em>(3), 1–25. (<a
href="https://doi.org/10.1145/3338244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose novel techniques to predict a user’s movie genre preference and rating behavior from her psycholinguistic attributes obtained from the social media interactions. The motivation of this work comes from various psychological studies that demonstrate that psychological attributes such as personality and values can influence one’s decision or choice in real life. In this work, we integrate user interactions in Twitter and IMDb to derive interesting relations between human psychological attributes and their movie preferences. In particular, we first predict a user’s movie genre preferences from the personality and value scores of the user derived from her tweets. Second, we also develop models to predict user movie rating behavior from her tweets in Twitter and movie genre and storyline preferences from IMDb. We further strengthen the movie rating model by incorporating the user reviews. In the above models, we investigate the role of personality and values independently and combinedly while predicting movie genre preferences and movie rating behaviors. We find that our combined models significantly improve the accuracy than that of a single model that is built by using personality or values independently. We also compare our technique with the traditional movie genre and rating prediction techniques. The experimental results show that our models are effective in recommending movies to users.},
  archive      = {J_TIIS},
  doi          = {10.1145/3338244},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {10},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Predicting users’ movie preference and rating behavior from personality and values},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Personality sensing: Detection of personality traits using
physiological responses to image and video stimuli. <em>TIIS</em>,
<em>10</em>(3), 1–32. (<a
href="https://doi.org/10.1145/3357459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality detection is an important task in psychology, as different personality traits are linked to different behaviours and real-life outcomes. Traditionally it involves filling out lengthy questionnaires, which is time-consuming, and may also be unreliable if respondents do not fully understand the questions or are not willing to honestly answer them. In this article, we propose a framework for objective personality detection that leverages humans’ physiological responses to external stimuli. We exemplify and evaluate the framework in a case study, where we expose subjects to affective image and video stimuli, and capture their physiological responses using non-invasive commercial-grade eye-tracking and skin conductivity sensors. These responses are then processed and used to build a machine learning classifier capable of accurately predicting a wide range of personality traits. We investigate and discuss the performance of various machine learning methods, the most and least accurately predicted traits, and also assess the importance of the different stimuli, features, and physiological signals. Our work demonstrates that personality traits can be accurately detected, suggesting the applicability of the proposed framework for robust personality detection and use by psychology practitioners and researchers, as well as designers of personalised interactive systems.},
  archive      = {J_TIIS},
  doi          = {10.1145/3357459},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {10},
  number       = {3},
  pages        = {1-32},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Personality sensing: Detection of personality traits using physiological responses to image and video stimuli},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PolicyFlow: Interpreting policy diffusion in context.
<em>TIIS</em>, <em>10</em>(2), 1–23. (<a
href="https://doi.org/10.1145/3385729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stability in social, technical, and financial systems, as well as the capacity of organizations to work across borders, requires consistency in public policy across jurisdictions. The diffusion of laws and regulations across political boundaries can reduce the tension that arises between innovation and consistency. Policy diffusion has been a topic of focus across the social sciences for several decades, but due to limitations of data and computational capacity, researchers have not taken a comprehensive and data-intensive look at the aggregate, cross-policy patterns of diffusion. This work combines visual analytics and text and network analyses to help understand how policies, as represented in digitized text, spread across states. As a result, our approach can quickly guide analysts to progressively gain insights into policy adoption data. We evaluate the effectiveness of our system via case studies with a real-world policy dataset and qualitative interviews with domain experts.},
  archive      = {J_TIIS},
  doi          = {10.1145/3385729},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {6},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {PolicyFlow: Interpreting policy diffusion in context},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparing and combining interaction data and eye-tracking
data for the real-time prediction of user cognitive abilities in
visualization tasks. <em>TIIS</em>, <em>10</em>(2), 1–41. (<a
href="https://doi.org/10.1145/3301400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work has shown that some user cognitive abilities relevant for processing information visualizations can be predicted from eye-tracking data. Performing this type of user modeling is important for devising visualizations that can detect a user&#39;s abilities and adapt accordingly during the interaction. In this article, we extend previous user modeling work by investigating for the first time interaction data as an alternative source to predict cognitive abilities during visualization processing when it is not feasible to collect eye-tracking data. We present an extensive comparison of user models based solely on eye-tracking data, on interaction data, as well as on a combination of the two. Although we found that eye-tracking data generate the most accurate predictions, results show that interaction data can still outperform a majority-class baseline, meaning that adaptation for interactive visualizations could be enabled even when it is not feasible to perform eye tracking, using solely interaction data. Furthermore, we found that interaction data can predict several cognitive abilities with better accuracy at the very beginning of the task than eye-tracking data, which are valuable for delivering adaptation early in the task. We also extend previous work by examining the value of multimodal classifiers combining interaction data and eye-tracking data, with promising results for some of our target user cognitive abilities. Next, we contribute to previous work by extending the type of visualizations considered and the set of cognitive abilities that can be predicted from either eye-tracking data and interaction data. Finally, we evaluate how noise in gaze data impacts prediction accuracy and find that retaining rather noisy gaze datapoints can yield equal or even better predictions than discarding them, a novel and important contribution for devising adaptive visualizations in real settings where eye-tracking data are typically noisier than in laboratory settings.},
  archive      = {J_TIIS},
  doi          = {10.1145/3301400},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {5},
  number       = {2},
  pages        = {1-41},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Comparing and combining interaction data and eye-tracking data for the real-time prediction of user cognitive abilities in visualization tasks},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mental models of mere mortals with explanations of
reinforcement learning. <em>TIIS</em>, <em>10</em>(2), 1–37. (<a
href="https://doi.org/10.1145/3366485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How should reinforcement learning (RL) agents explain themselves to humans not trained in AI? To gain insights into this question, we conducted a 124-participant, four-treatment experiment to compare participants’ mental models of an RL agent in the context of a simple Real-Time Strategy (RTS) game. The four treatments isolated two types of explanations vs. neither vs. both together. The two types of explanations were as follows: (1) saliency maps (an “Input Intelligibility Type” that explains the AI’s focus of attention) and (2) reward-decomposition bars (an “Output Intelligibility Type” that explains the AI’s predictions of future types of rewards). Our results show that a combined explanation that included saliency and reward bars was needed to achieve a statistically significant difference in participants’ mental model scores over the no-explanation treatment. However, this combined explanation was far from a panacea: It exacted disproportionately high cognitive loads from the participants who received the combined explanation. Further, in some situations, participants who saw both explanations predicted the agent’s next action worse than all other treatments’ participants.},
  archive      = {J_TIIS},
  doi          = {10.1145/3366485},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {5},
  number       = {2},
  pages        = {1-37},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Mental models of mere mortals with explanations of reinforcement learning},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing an AI health coach and studying its utility in
promoting regular aerobic exercise. <em>TIIS</em>, <em>10</em>(2), 1–30.
(<a href="https://doi.org/10.1145/3366501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research aims to develop interactive, social agents that can coach people to learn new tasks, skills, and habits. In this article, we focus on coaching sedentary, overweight individuals (i.e., “trainees”) to exercise regularly. We employ adaptive goal setting in which the intelligent health coach generates, tracks, and revises personalized exercise goals for a trainee. The goals become incrementally more difficult as the trainee progresses through the training program. Our approach is model-based—the coach maintains a parameterized model of the trainee’s aerobic capability that drives its expectation of the trainee’s performance. The model is continually revised based on trainee-coach interactions. The coach is embodied in a smartphone application, N utri W alking , which serves as a medium for coach-trainee interaction. We adopt a task-centric evaluation approach for studying the utility of the proposed algorithm in promoting regular aerobic exercise. We show that our approach can adapt the trainee program not only to several trainees with different capabilities but also to how a trainee’s capability improves as they begin to exercise more. Experts rate the goals selected by the coach better than other plausible goals, demonstrating that our approach is consistent with clinical recommendations. Further, in a 6-week observational study with sedentary participants, we show that the proposed approach helps increase exercise volume performed each week.},
  archive      = {J_TIIS},
  doi          = {10.1145/3366501},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {5},
  number       = {2},
  pages        = {1-30},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Designing an AI health coach and studying its utility in promoting regular aerobic exercise},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic detection of usability problem encounters in
think-aloud sessions. <em>TIIS</em>, <em>10</em>(2), 1–24. (<a
href="https://doi.org/10.1145/3385732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Think-aloud protocols are a highly valued usability testing method for identifying usability problems. Despite the value of conducting think-aloud usability test sessions, analyzing think-aloud sessions is often time-consuming and labor-intensive. Consequently, previous research has urged the community to develop techniques to support fast-paced analysis. In this work, we took the first step to design and evaluate machine learning (ML) models to automatically detect usability problem encounters based on users’ verbalization and speech features in think-aloud sessions. Inspired by recent research that shows subtle patterns in users’ verbalizations and speech features tend to occur when they encounter problems, we examined whether these patterns can be utilized to improve the automatic detection of usability problems. We first conducted and recorded think-aloud sessions and then examined the effect of different input features, ML models, test products, and users on usability problem encounters detection. Our work uncovers several technical and user interface design challenges and sets a baseline for automating usability problem detection and integrating such automation into UX practitioners’ workflow.},
  archive      = {J_TIIS},
  doi          = {10.1145/3385732},
  journal      = {ACM Transactions on Interactive Intelligent Systems},
  month        = {5},
  number       = {2},
  pages        = {1-24},
  shortjournal = {ACM Trans. Interact. Intell. Syst.},
  title        = {Automatic detection of usability problem encounters in think-aloud sessions},
  volume       = {10},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
