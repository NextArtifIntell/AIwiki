<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmis---32">TMIS - 32</h2>
<ul>
<li><details>
<summary>
(2020). Extraction of information content exchange in financial
markets by an entropy analysis. <em>TMIS</em>, <em>12</em>(1), 9:1–16.
(<a href="https://doi.org/10.1145/3419372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there has been an explosive interest in the literature about modeling and forecasting volatility in financial markets. Many researches have focused on energy markets and oil volatility index (OVX). In this article, we aim first at showing if there is an exchange of information between two stock time series, and then at evaluating what is the direction of this information flow. In particular, we propose an entropy-based approach that exploits two objective metrics, namely Mutual Information (MI) and Transfer Entropy (TE), that does not require a parametric model and is directly applicable on the data. The experimental outcomes, applied on Brent and WTI crude oil prices and their volatility index for the period from May 10, 2007 till July 03, 2018, demonstrate the effectiveness of the proposed method.},
  archive      = {J_TMIS},
  author       = {Francesco Benedetto and Loretta Mastroeni and Pierluigi Vellucci},
  doi          = {10.1145/3419372},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {9:1–16},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Extraction of information content exchange in financial markets by an entropy analysis},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting high-engaging breaking news rumors in social
media. <em>TMIS</em>, <em>12</em>(1), 8:1–16. (<a
href="https://doi.org/10.1145/3416703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users from all over the world increasingly adopt social media for newsgathering, especially during breaking news. Breaking news is an unexpected event that is currently developing. Early stages of breaking news are usually associated with lots of unverified information, i.e., rumors. Efficiently detecting and acting upon rumors in a timely fashion is of high importance to minimize their harmful effects. Yet, not all rumors have the potential to spread in social media. High-engaging rumors are those written in a manner that ensures achievement of the highest prevalence among the recipients. They are difficult to detect, spread very fast, and can cause serious damage to society. In this article, we propose a new multi-task Convolutional Neural Network (CNN) attention-based neural network architecture to jointly learn the two tasks of breaking news rumors detection and breaking news rumors popularity prediction in social media. The proposed model learns the salient semantic similarities among important features for detecting high-engaging breaking news rumors and separates them from the rest of the input text. Extensive experiments on five real-life datasets of breaking news suggest that our proposed model outperforms all baselines and is capable of detecting breaking news rumors and predicting their future popularity with high accuracy.},
  archive      = {J_TMIS},
  author       = {Sarah A. Alkhodair and Benjamin C. M. Fung and Steven H. H. Ding and William K. Cheung and Shih-Chia Huang},
  doi          = {10.1145/3416703},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {8:1–16},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Detecting high-engaging breaking news rumors in social media},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of an inclusive financial privacy index (INF-PIE): A
financial privacy and digital financial inclusion perspective.
<em>TMIS</em>, <em>12</em>(1), 7:1–21. (<a
href="https://doi.org/10.1145/3403949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial privacy is an important part of an individual&#39;s privacy, but efforts to enhance financial privacy have often not been given enough prominence by some countries when advancing financial inclusion. This impedes under-served communities from utilizing financial services. This article adopts a design science approach to create an INclusive Financial Privacy IndEx (INF-PIE) from the two perspectives of financial privacy and digital financial inclusion to help ensure financial services for a wide range of populations. This article first examines the privacy policies of Mobile Wallet and Remittance (MWR) apps (a digital financial solution), uses an analytics approach for extracting semi-structured information components; and based on text categorization and topic modeling, creates privacy policy compliance scores. In particular, it analyses the privacy policies using natural language processing techniques such as Term Frequency-Inverse Document Frequency (tf-idf) and Latent Dirichlet Allocation (LDA). This article then develops a digital financial inclusion score through a multivariate analysis of indexes extracted from the global findex dataset using Principal Component Analysis (PCA). Finally, the INF-PIE framework is established to analyze various countries and assess their financial privacy and digital financial inclusion practices. This framework can show how countries’ relative data privacy compliance and digital financial inclusion practices underscore their inclusive financial privacy.},
  archive      = {J_TMIS},
  author       = {Oluwafemi Akanfe and Rohit Valecha and H. Raghav Rao},
  doi          = {10.1145/3403949},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {7:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Design of an inclusive financial privacy index (INF-PIE): A financial privacy and digital financial inclusion perspective},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical reconciliation of medical privacy policies.
<em>TMIS</em>, <em>12</em>(1), 5:1–18. (<a
href="https://doi.org/10.1145/3397520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare data are arguably the most private of personal data. This very private information in the wrong hands can lead to identity theft, prescription fraud, insurance fraud, and an array of other crimes. Electronic-health systems such as My Health Record in Australia holds great promise in sharing medical data and improving healthcare quality. But, a key privacy issue in these systems is the misuse of healthcare data by “authorities.” The recent General Data Protection Regulation (GDPR) introduced in the EU aims to reduce personal-data misuse. But, there are no tools currently available to accurately reconcile a domestic E-health policy against the GDPR to identify discrepancies. Reconciling privacy policies is also non-trivial, because policies are often written in free text, making them subject to human interpretation. In this article, we propose a tool that allows the description of E-health privacy policies, represents them using formal constructs making the policies precise and explicit. Using this formal framework, our tool can automatically reconcile a domestic E-health policy against the GDPR to identify violations and omissions. We use our prototype to illustrate several critical flaws in Australia’s My Health Record policy, including a non-compliance with GDPR that allows healthcare providers to access medical records by default.},
  archive      = {J_TMIS},
  author       = {Dinesha Ranathunga and Matthew Roughan and Hung Nguyen},
  doi          = {10.1145/3397520},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {5:1–18},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Mathematical reconciliation of medical privacy policies},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of complexity of insider attacks to databases.
<em>TMIS</em>, <em>12</em>(1), 4:1–18. (<a
href="https://doi.org/10.1145/3391231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insider attacks are one of the most dangerous threats to an organization. Unfortunately, they are very difficult to foresee, detect, and defend against due to the trust and responsibilities placed on the employees. In this article, we first define the notion of user intent and construct a model for a common scenario that poses a very high risk for sensitive data stored in the organization’s database. We show that the complexity of identifying pseudo-intents of a user in this scenario is coNP-Complete, and launching a harvester insider attack within the boundaries of the defined threat model takes linear time while a targeted threat model is an NP-Complete problem. We also discuss the general defense mechanisms against the modeled threats and show that countering the harvester insider attack takes quadratic time while countering the targeted insider attack can take linear to quadratic time, depending on the strategy chosen. We analyze the adversarial behavior and show that launching an attack with minimum risk is also an NP-Complete problem. Finally, we perform timing experiments with the defense mechanisms on SQL query workloads collected from a national bank to test the feasibility of using these systems in real time.},
  archive      = {J_TMIS},
  author       = {Gökhan Kul and Shambhu Upadhyaya and Andrew Hughes},
  doi          = {10.1145/3391231},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {4:1–18},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An analysis of complexity of insider attacks to databases},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning for multi-instance biometric privacy.
<em>TMIS</em>, <em>12</em>(1), 3:1–23. (<a
href="https://doi.org/10.1145/3389683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fundamental goal of a revocable biometric system is to defend a user’s biometrics from being compromised. This research explores the application of deep learning or Convolutional Neural Networks to multi-instance biometrics. Modality features are transformed into revocable templates through the application of random projection. During the user authentication phase, we employ Support Vector Machines, chosen over three other alternative classifiers after carrying out a comparative study. Comparison of the proposed method over other standard deep learning models and performance evaluation before and after revocability have also been discussed. Results demonstrate ability to improve identification accuracy and provide sound template security. The system was validated on three multi-instance iris and fingervein databases.},
  archive      = {J_TMIS},
  author       = {Tanuja Sudhakar and Marina Gavrilova},
  doi          = {10.1145/3389683},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {3:1–23},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Deep learning for multi-instance biometric privacy},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of the GDPR on privacy policies: Recent progress
and future promise. <em>TMIS</em>, <em>12</em>(1), 2:1–20. (<a
href="https://doi.org/10.1145/3389685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The General Data Protection Regulation (GDPR) is considered by some to be the most important change in data privacy regulation in 20 years. Effective May 2018, the European Union GDPR privacy law applies to any organization that collects and processes the personal information of EU citizens within or outside the EU. In this work, we seek to quantify the progress the GDPR has made in improving privacy policies around the globe. We leverage our data mining tool, PrivacyCheck, to automatically compare three corpora (totaling 550) of privacy policies, pre- and post-GDPR. In addition, to evaluate the current level of compliance with the GDPR around the globe, we manually studied the policies within two corpora (450 policies). We find that the GDPR has made progress in protecting user data, but more progress is necessary—particularly in the area of giving users the right to edit and delete their information—to entirely fulfill the GDPR’s promise. We also observe that the GDPR encourages sharing user data with law enforcement, and as a result, many policies have facilitated such sharing after the GDPR. Finally, we see that when there is non-compliance with the GDPR, it is often in the form of failing to explicitly indicate compliance, which in turn speaks to an organization’s lack of transparency and disclosure regarding their processing and protection of personal information. If Personally Identifiable Information (PII) is the “currency of the Internet,” these findings mark continued alarm regarding an individual’s agency to protect and secure their PII assets.},
  archive      = {J_TMIS},
  author       = {Razieh Nokhbeh Zaeem and K. Suzanne Barber},
  doi          = {10.1145/3389685},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {2:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {The effect of the GDPR on privacy policies: Recent progress and future promise},
  volume       = {12},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IP reputation scoring with geo-contextual feature
augmentation. <em>TMIS</em>, <em>11</em>(4), 26:1–29. (<a
href="https://doi.org/10.1145/3419373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this article is to present an effective anomaly detection model for an encrypted network session by developing a novel IP reputation scoring model that labels the incoming session IP address based on the most similar IP addresses in terms of both network and geo-contextual knowledge. We provide empirical evidence that considering not only traditional network information but also geo-contextual information provides better threat assessment. The reputation scores provide a means to quantitatively capture good and bad IP behavior, making our model ideal for detecting malicious network behavior. With network encryption being the most practical solution to data security and privacy today, our approach expands the network administrator&#39;s ability to make decisions about IP addresses’ trustworthiness in an encrypted session with limited network information.},
  archive      = {J_TMIS},
  author       = {Henanksha Sainani and Josephine M. Namayanja and Guneeti Sharma and Vasundhara Misal and Vandana P. Janeja},
  doi          = {10.1145/3419373},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {26:1–29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {IP reputation scoring with geo-contextual feature augmentation},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of cyber incident categories based on losses.
<em>TMIS</em>, <em>11</em>(4), 25:1–28. (<a
href="https://doi.org/10.1145/3418288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fact that “cyber risk” is indeed a collective term for various distinct risks creates great difficulty in communications. For example, policyholders of “cyber insurance” contracts often have a limited or inaccurate understanding about the coverage that they have. To address this issue, we propose a cyber risk categorization method using clustering techniques. This method classifies cyber incidents based on their consequential losses for insurance and risk management purposes. As a result, it also reveals the relationship between the causes and the outcomes of incidents. Our results show that similar cyber incidents, which are often not properly distinguished, can lead to very different losses. We hope that our work can clarify the differences between cyber risks and provide a set of risk categories that is feasible in practice and for future studies.},
  archive      = {J_TMIS},
  author       = {Jay P. Kesan and Linfeng Zhang},
  doi          = {10.1145/3418288},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {25:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Analysis of cyber incident categories based on losses},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ensemble of ensembles approach to author attribution for
internet relay chat forensics. <em>TMIS</em>, <em>11</em>(4), 24:1–25.
(<a href="https://doi.org/10.1145/3409455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advances in Internet technologies and services, social media has been gained extreme popularity, especially because these technologies provide potential anonymity, which in turn harbors hacker discussion forums, underground markets, dark web, and so on. Internet relay chat (IRC) is a real-time communication protocol actively used by cybercriminals for hacking, cracking, and carding. Hence, it is particularly urgent to identify the authors of threat messages and malicious activities in IRC. Unfortunately, author identification studies in IRC remain as an underexplored area. In this research, we perform novel IRC text feature extraction methods and propose the first author attribution version of the deep forest (DF) model that is an ensemble of ensembles that utilizes the fusion of ensemble learning techniques. Our approach is supported by autonomic IRC monitoring. Experiments show that our approach is highly effective for author attribution and attains high accuracy even when the number of candidates is large while training data is limited.},
  archive      = {J_TMIS},
  author       = {Sicong Shao and Cihan Tunc and Amany Al-Shawi and Salim Hariri},
  doi          = {10.1145/3409455},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {24:1–25},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {An ensemble of ensembles approach to author attribution for internet relay chat forensics},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PANDA: Partitioned data security on outsourced sensitive and
non-sensitive data. <em>TMIS</em>, <em>11</em>(4), 23:1–41. (<a
href="https://doi.org/10.1145/3397521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite extensive research on cryptography, secure and efficient query processing over outsourced data remains an open challenge. This article continues along with the emerging trend in secure data processing that recognizes that the entire dataset may not be sensitive and, hence, non-sensitivity of data can be exploited to overcome limitations of existing encryption-based approaches. We first provide a new security definition, entitled partitioned data security , for guaranteeing that the joint processing of non-sensitive data (in cleartext) and sensitive data (in encrypted form) does not lead to any leakage. Then, this article proposes a new secure approach, entitled query binning (QB), that allows secure execution of queries over non-sensitive and sensitive parts of the data. QB maps a query to a set of queries over the sensitive and non-sensitive data in a way that no leakage will occur due to the joint processing over sensitive and non-sensitive data. In particular, we propose secure algorithms for selection, range, and join queries to be executed over encrypted sensitive and cleartext non-sensitive datasets. Interestingly, in addition to improving performance, we show that QB actually strengthens the security of the underlying cryptographic technique by preventing size, frequency-count, and workload-skew attacks.},
  archive      = {J_TMIS},
  author       = {Sharad Mehrotra and Shantanu Sharma and Jeffrey D. Ullman and Dhrubajyoti Ghosh and Peeyush Gupta and Anurag Mishra},
  doi          = {10.1145/3397521},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {23:1–41},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {PANDA: Partitioned data security on outsourced sensitive and non-sensitive data},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the variety and veracity of cyber intrusion alerts
synthesized by generative adversarial networks. <em>TMIS</em>,
<em>11</em>(4), 22:1–21. (<a
href="https://doi.org/10.1145/3394503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many cyber attack actions can be observed, but the observables often exhibit intricate feature dependencies, non-homogeneity, and potentially rare yet critical samples. This work tests the ability to learn, model, and synthesize cyber intrusion alerts through Generative Adversarial Networks (GANs), which explore the feature space by reconciling between randomly generated samples and data that reflect a mixture of diverse attack behaviors without a priori knowledge. Through a comprehensive analysis using Jensen-Shannon Divergence, Conditional and Joint Entropy, and mode drops and additions, we show that the Wasserstein-GAN with Gradient Penalty and Mutual Information is more effective in learning to generate realistic alerts than models without Mutual Information constraints. We further show that the added Mutual Information constraint pushes the model to explore the feature space more thoroughly and increases the generation of low probability, yet critical, alert features. This research demonstrates the novel and promising application of unsupervised GANs to learn from limited yet diverse intrusion alerts to generate synthetic alerts that emulate critical dependencies, opening the door to proactive, data-driven cyber threat analyses.},
  archive      = {J_TMIS},
  author       = {Christopher Sweet and Stephen Moskal and Shanchieh Jay Yang},
  doi          = {10.1145/3394503},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {22:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {On the variety and veracity of cyber intrusion alerts synthesized by generative adversarial networks},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet-scale insecurity of consumer internet of things: An
empirical measurements perspective. <em>TMIS</em>, <em>11</em>(4),
21:1–24. (<a href="https://doi.org/10.1145/3394504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number of Internet-of-Things (IoT) devices actively communicating across the Internet is continually increasing, as these devices are deployed across a variety of sectors, constantly transferring private data across the Internet. Due to the extensive deployment of such devices, the continuous discovery and persistence of IoT-centric vulnerabilities in protocols, applications, hardware, and the improper management of such IoT devices has resulted in the rampant, uncontrolled spread of malware threatening consumer IoT devices. To this end, this work adopts a novel, macroscopic methodology for fingerprinting Internet-scale compromised IoT devices, revealing crucial cyber threat intelligence on the insecurity of consumer IoT devices. By developing data-driven techniques rooted in machine learning methods and analyzing 3.6 TB of network traffic data, we discover 855,916 compromised IP addresses, with 310,164 fingerprinted as IoT. Further analysis reveals China and Brazil to be hosting the most significant population of compromised IoT devices (100,000 and 55,000, respectively). Additionally, we provide a longitudinal analysis on data from one year ago against this work, revealing the evolving trends of IoT exploitation, such as the increased number of vendors targeted by malware, rising from 50 to 131. Moreover, countries such as China (420\% increased infected IoT count) and Indonesia (177\% increased infected IoT count) have seen notably high increases in infection rates. Last, we compare our geographic results against Global Cybersecurity Index (GCI) ratings, verifying that countries with high GCI ratings, such as the Netherlands and Germany, had relatively low infection rates. However, upon further inspection, we find that the GCI rate does not accurately represent the consumer IoT market, with countries such as China and Russia being rated with “high” CGI scores, yet hosting a large population of infected consumer IoT devices.},
  archive      = {J_TMIS},
  author       = {Antonio Mangino and Morteza Safaei Pour and Elias Bou-Harb},
  doi          = {10.1145/3394504},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {21:1–24},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Internet-scale insecurity of consumer internet of things: An empirical measurements perspective},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-based gap analysis of cybersecurity trends in academic
and digital media. <em>TMIS</em>, <em>11</em>(4), 20:1–20. (<a
href="https://doi.org/10.1145/3389684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study analyzes cybersecurity trends and proposes a conceptual framework to identify cybersecurity topics of social interest and emerging topics that need to be addressed by researchers in the field. The insights drawn from this framework allow for a more proactive approach to identifying cybersecurity patterns and emerging threats that will ultimately improve the collective cybersecurity posture of the modern society. To achieve this, cybersecurity-oriented content in both media and academic corpora, disseminated between 2008 and 2018, were morphologically analyzed via text mining. A total of 3,556 academic papers obtained from the top-10 highly reputable cybersecurity academic conferences, and 4,163 news articles collected from the New York Times were processed. The LDA topic modeling followed optimal perplexity and coherence scores resulted in 12 trendy topics. Next, the time-based gap between these trendy topics was analyzed to measure the correlation between media and trendy academic topics. Both convergences and divergences between the two cybersecurity corpora were identified, suggesting a strong time-based correlation between these resources. This framework demonstrates the effective use of automated techniques to provide insights about cybersecurity topics of social interest and emerging trends and informs the direction of future academic research in this field.},
  archive      = {J_TMIS},
  author       = {Mahdi R. Alagheband and Atefeh Mashatan and Morteza Zihayat},
  doi          = {10.1145/3389684},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {20:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Time-based gap analysis of cybersecurity trends in academic and digital media},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predictive cyber situational awareness and personalized
blacklisting: A sequential rule mining approach. <em>TMIS</em>,
<em>11</em>(4), 19:1–16. (<a
href="https://doi.org/10.1145/3386250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity adopts data mining for its ability to extract concealed and indistinct patterns in the data, such as for the needs of alert correlation. Inferring common attack patterns and rules from the alerts helps in understanding the threat landscape for the defenders and allows for the realization of cyber situational awareness, including the projection of ongoing attacks. In this article, we explore the use of data mining, namely sequential rule mining, in the analysis of intrusion detection alerts. We employed a dataset of 12 million alerts from 34 intrusion detection systems in 3 organizations gathered in an alert sharing platform, and processed it using our analytical framework. We execute the mining of sequential rules that we use to predict security events, which we utilize to create a predictive blacklist. Thus, the recipients of the data from the sharing platform will receive only a small number of alerts of events that are likely to occur instead of a large number of alerts of past events. The predictive blacklist has the size of only 3\% of the raw data, and more than 60\% of its entries are shown to be successful in performing accurate predictions in operational, real-world settings.},
  archive      = {J_TMIS},
  author       = {Martin Husák and Tomáš Bajtoš and Jaroslav Kašpar and Elias Bou-Harb and Pavel Čeleda},
  doi          = {10.1145/3386250},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {19:1–16},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Predictive cyber situational awareness and personalized blacklisting: A sequential rule mining approach},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge-based intrusion detection for IoT devices.
<em>TMIS</em>, <em>11</em>(4), 18:1–21. (<a
href="https://doi.org/10.1145/3382159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the Internet of Things (IoT) is estimated to grow to 25 billion by 2021, there is a need for an effective and efficient Intrusion Detection System (IDS) for IoT devices. Traditional network-based IDSs are unable to efficiently detect IoT malware and new evolving forms of attacks like file-less attacks. In this article, we present a system level Device-Edge split IDS for IoT devices. Our IDS profiles IoT devices according to their “behavior” using system-level information like running process parameters and their system calls in an autonomous, efficient, and scalable manner and then detects anomalous behavior indicative of intrusions. The modular design of our IDS along with a unique device-edge split architecture allows for effective attack detection with minimal overhead on the IoT devices. We have extensively evaluated our system using a dataset of 3,973 traditional IoT malware samples and 8 types of sophisticated file-less attacks recently observed against IoT devices in our testbed. We report the evaluation results in terms of detection efficiency and computational.},
  archive      = {J_TMIS},
  author       = {Anand Mudgerikar and Puneet Sharma and Elisa Bertino},
  doi          = {10.1145/3382159},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {4},
  pages        = {18:1–21},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Edge-based intrusion detection for IoT devices},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trajectory outlier detection: Algorithms, taxonomies,
evaluation, and open challenges. <em>TMIS</em>, <em>11</em>(3), 16:1–29.
(<a href="https://doi.org/10.1145/3399631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting abnormal trajectories is an important task in research and industrial applications, which has attracted considerable attention in recent decades. This work studies the existing trajectory outlier detection algorithms in different industrial domains and applications, including maritime, smart urban transportation, video surveillance, and climate change domains. First, we review several algorithms for trajectory outlier detection. Second, different taxonomies are proposed regarding application-, output-, and algorithm-based levels. Third, evaluation of 10 trajectory outlier detection algorithms is performed on small, large, and big trajectory databases. Finally, future challenges and open issues with regard to trajectory outliers are derived and discussed. This survey offers a general overview of existing trajectory outlier detection algorithms in industrial informatics applications. As a result, mature solutions may be further developed by data mining and machine learning communities.},
  archive      = {J_TMIS},
  author       = {Asma Belhadi and Youcef Djenouri and Jerry Chun-Wei Lin and Alberto Cano},
  doi          = {10.1145/3399631},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {16:1–29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Trajectory outlier detection: Algorithms, taxonomies, evaluation, and open challenges},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cashless payment policy and its effects on economic growth
of india: An exploratory study. <em>TMIS</em>, <em>11</em>(3), 15:1–10.
(<a href="https://doi.org/10.1145/3391402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present world has moved from cash transactions to cashless transactions. This article examines the impact of implementation of a cashless payment policy on economic development and gradual transition to a cashless economy in India. For this study, the focus is on the time period from 2010 to 2018. The data used for this study are tele transfer, through credit or debit card payment, check payment, and E-money on Indian economic growth. The study has employed the panel vector error correction model, Padroni residual cointegration, and the hypothetical prototypical method. The results show that customers and sellers accept a cashless system policy. In the short period, we have a causality model running from a card system to a check payment and telegraphic transfer system, and a causality model running from a telegraphic payment system to a card payment system. In the long period, there is a positive outcome in using a cashless policy on Indian economic growth. However, the use of a cashless policy on Indian economic development in the short term will be negative, whereas in the long term it will impact positively. Hence, any kind of economic strategy that endorses a cashless payment system cannot have positive impact on the economic development directly.},
  archive      = {J_TMIS},
  author       = {Nenavath Sreenu},
  doi          = {10.1145/3391402},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {15:1–10},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Cashless payment policy and its effects on economic growth of india: An exploratory study},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Utility-driven mining of trend information for intelligent
system. <em>TMIS</em>, <em>11</em>(3), 14:1–28. (<a
href="https://doi.org/10.1145/3391251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Useful knowledge, embedded in a database, is likely to change over time. Identifying the recent changes in temporal data can provide valuable up-to-date information to decision makers. Nevertheless, techniques for mining high-utility patterns (HUPs) seldom consider recency as a criterion to discover patterns. Thus, the traditional utility mining framework is inadequate for obtaining up-to-date insights about real-world data. In this article, we address this issue by introducing a novel framework, named utility-driven mining of recent/trend high-utility patterns (RUPs), in temporal databases for intelligent systems, based on user-specified minimum recency and minimum utility thresholds. The utility-driven RUP algorithm is based on novel global and conditional downward closure properties, and a recency-utility tree. Moreover, it adopts a vertical compact recency-utility list structure to store the information required by the mining process. The developed RUP algorithm recursively discovers recent high-utility patterns. It is also fast and consumes a small amount of memory due to its pattern discovery approach that does not generate candidates. Two improved versions of the algorithm with additional pruning strategies are also designed to speed up the discovery of patterns by reducing the search space. Results of a substantial experimental evaluation show that the proposed algorithm can efficiently identify all recent HUPs in large-scale databases, and that the improved algorithm performs best.},
  archive      = {J_TMIS},
  author       = {Wensheng Gan and Jerry Chun-Wei Lin and Han-Chieh Chao and Philippe Fournier-Viger and Xuan Wang and Philip S. Yu},
  doi          = {10.1145/3391251},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {14:1–28},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Utility-driven mining of trend information for intelligent system},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A weakly supervised WordNet-guided deep learning approach to
extracting aspect terms from online reviews. <em>TMIS</em>,
<em>11</em>(3), 13:1–22. (<a
href="https://doi.org/10.1145/3399630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unstructured nature of online reviews makes it inefficient and inconvenient for prospective consumers to research and use in support of purchase decision making. The aspects of products provide a fine-grained meaningful perspective for understanding and organizing review texts. Traditional aspect term extraction approaches rely on discrete language models that treat words in isolation. Despite that continuous-space language models have demonstrated promise in addressing a wide range of problems, their application in aspect term extraction faces significant challenges. For instance, existing continuous-space language models typically require large collections of labeled data, which remain difficult to obtain in many domains. More importantly, previous methods are largely data driven but overlook the role of human knowledge in guiding model development. To address these limitations, this study designs and develops weakly supervised WordNet-guided deep learning to aspect term extraction. The approach draws on deep-level semantic information from WordNet to guide not only the selection representative seed terms but also the pruning of aspect candidate terms. The weak supervision is provided by a very small set of labeled data. We conduct a comprehensive evaluation of the proposed method using both direct and indirect methods. The evaluation results with Yelp restaurant reviews demonstrate that our proposed method consistently outperforms all baseline methods including discrete models and the state-of-the-art continuous-space language models for aspect term extraction across both direct and indirect evaluations. The research findings have broad research, technical, and practical implications for various stakeholders of online reviews.},
  archive      = {J_TMIS},
  author       = {Jie Tao and Lina Zhou},
  doi          = {10.1145/3399630},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {13:1–22},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A weakly supervised WordNet-guided deep learning approach to extracting aspect terms from online reviews},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting user posting activities in online health
communities with deep learning. <em>TMIS</em>, <em>11</em>(3), 12:1–15.
(<a href="https://doi.org/10.1145/3383780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online health communities (OHCs) represent a great source of social support for patients and their caregivers. Better predictions of user activities in OHCs can help improve user engagement and retention, which are important to manage and sustain a successful OHC. This article proposes a general framework to predict OHC user posting activities. Deep learning methods are adopted to learn from users’ temporal trajectories in both the volumes and content of posts published over time. Experiments based on data from a popular OHC for cancer survivors demonstrate that the proposed approach can improve the performance of user activity predictions. In addition, several topics of users’ posts are found to have strong impact on predicting users’ activities in the OHC.},
  archive      = {J_TMIS},
  author       = {Xiangyu Wang and Kang Zhao and Xun Zhou and Nick Street},
  doi          = {10.1145/3383780},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {12:1–15},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Predicting user posting activities in online health communities with deep learning},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). E-commerce product categorization via machine translation.
<em>TMIS</em>, <em>11</em>(3), 11:1–14. (<a
href="https://doi.org/10.1145/3382189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce platforms categorize their products into a multi-level taxonomy tree with thousands of leaf categories. Conventional methods for product categorization are typically based on machine learning classification algorithms. These algorithms take product information as input (e.g., titles and descriptions) to classify a product into a leaf category. In this article, we propose a new paradigm based on machine translation . In our approach, we translate a product’s natural language description into a sequence of tokens representing a root-to-leaf path in a product taxonomy. In our experiments on two large real-world datasets, we show that our approach achieves better predictive accuracy than a state-of-the-art classification system for product categorization. In addition, we demonstrate that our machine translation models can propose meaningful new paths between previously unconnected nodes in a taxonomy tree, thereby transforming the taxonomy into a directed acyclic graph. We discuss how the resultant taxonomy directed acyclic graph promotes user-friendly navigation, and how it is more adaptable to new products.},
  archive      = {J_TMIS},
  author       = {Liling Tan and Maggie Yundi Li and Stanley Kok},
  doi          = {10.1145/3382189},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {11:1–14},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {E-commerce product categorization via machine translation},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real or not?: Identifying untrustworthy news websites using
third-party partnerships. <em>TMIS</em>, <em>11</em>(3), 10:1–20. (<a
href="https://doi.org/10.1145/3382188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untrustworthy content such as fake news and clickbait have become a pervasive problem on the Internet, causing significant socio-political problems around the world. Identifying untrustworthy content is a crucial step in countering them. The current best practices for identification involve content analysis and arduous fact-checking of the content. To complement content analysis, we propose examining websites’ third-parties to identify their trustworthiness. Websites utilize third-parties, also known as their digital supply chains, to create and present content and help the website function. Third-parties are an important indication of a website&#39;s business model. Similar websites exhibit similarities in the third-parties they use. Using this perspective, we use machine learning and heuristic methods to discern similarities and dissimilarities in third-party usage, which we use to predict trustworthiness of websites. We demonstrate the effectiveness and robustness of our approach in predicting trustworthiness of websites from a database of News, Fake News, and Clickbait websites. Our approach can be easily and cost-effectively implemented to reinforce current identification methods.},
  archive      = {J_TMIS},
  author       = {Ram D. Gopal and Hooman Hidaji and Sule Nur Kutlu and Raymond A. Patterson and Erik Rolland and Dmitry Zhdanov},
  doi          = {10.1145/3382188},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {10:1–20},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Real or not?: Identifying untrustworthy news websites using third-party partnerships},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introduction to WITS 2018 special issue in TMIS.
<em>TMIS</em>, <em>11</em>(3), 9:1–2. (<a
href="https://doi.org/10.1145/3404392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TMIS},
  author       = {Kaushik Dutta and Xiao Fang and Zhengrui (Jeffrey) Jiang},
  doi          = {10.1145/3404392},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {3},
  pages        = {9:1–2},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Introduction to WITS 2018 special issue in TMIS},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Context-aware recommendations based on deep learning
frameworks. <em>TMIS</em>, <em>11</em>(2), 8:1–15. (<a
href="https://doi.org/10.1145/3386243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we suggest a novel deep learning recommendation framework that incorporates contextual information into neural collaborative filtering recommendation approaches. Since context is often represented by dynamic and high-dimensional feature space in multiple applications and services, we suggest to model contextual information in various ways for multiple purposes, such as rating prediction, generating top-k recommendations, and classification of users’ feedback. Specifically, based on the suggested framework, we propose three deep context-aware recommendation models based on explicit, unstructured, and structured latent representations of contextual data derived from various contextual dimensions (e.g., time, location, user activity). Offline evaluation on three context-aware datasets confirms that our proposed deep context-aware models surpass state-of-the-art context-aware methods. We also show that utilizing structured latent contexts in the proposed deep recommendation framework achieves significantly better performance than the other context-aware models on all datasets.},
  archive      = {J_TMIS},
  author       = {Moshe Unger and Alexander Tuzhilin and Amit Livne},
  doi          = {10.1145/3386243},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {8:1–15},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Context-aware recommendations based on deep learning frameworks},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithms and applications to weighted rank-one binary
matrix factorization. <em>TMIS</em>, <em>11</em>(2), 7:1–33. (<a
href="https://doi.org/10.1145/3386599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many applications use data that are better represented in the binary matrix form, such as click-stream data, market basket data, document-term data, user-permission data in access control, and others. Matrix factorization methods have been widely used tools for the analysis of high-dimensional data, as they automatically extract sparse and meaningful features from data vectors. However, existing matrix factorization methods do not work well for the binary data. One crucial limitation is interpretability, as many matrix factorization methods decompose an input matrix into matrices with fractional or even negative components, which are hard to interpret in many real settings. Some matrix factorization methods, like binary matrix factorization, do limit decomposed matrices to binary values. However, these models are not flexible to accommodate some data analysis tasks, like trading off summary size with quality and discriminating different types of approximation errors. To address those issues, this article presents weighted rank-one binary matrix factorization, which is to approximate a binary matrix by the product of two binary vectors, with parameters controlling different types of approximation errors. By systematically running weighted rank-one binary matrix factorization, one can effectively perform various binary data analysis tasks, like compression, clustering, and pattern discovery. Theoretical properties on weighted rank-one binary matrix factorization are investigated and its connection to problems in other research domains are examined. As weighted rank-one binary matrix factorization in general is NP-hard, efficient and effective algorithms are presented. Extensive studies on applications of weighted rank-one binary matrix factorization are also conducted.},
  archive      = {J_TMIS},
  author       = {Haibing Lu and Xi Chen and Junmin Shi and Jaideep Vaidya and Vijayalakshmi Atluri and Yuan Hong and Wei Huang},
  doi          = {10.1145/3386599},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {7:1–33},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Algorithms and applications to weighted rank-one binary matrix factorization},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security and privacy requirements for cloud computing in
healthcare: Elicitation and prioritization from a patient perspective.
<em>TMIS</em>, <em>11</em>(2), 6:1–29. (<a
href="https://doi.org/10.1145/3386160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing promises essential improvements in healthcare delivery performance. However, its wide adoption in healthcare is yet to be seen, one main reason being patients’ concerns for security and privacy of their sensitive medical records. These concerns can be addressed through corresponding security and privacy requirements within the system engineering process. Despite a plethora of related research, security and privacy requirements for cloud systems and services have seldomly been investigated methodically so far, whereas their individual priorities to increase the system success probability have been neglected. Against this background, this study applies a systematic requirements engineering process: First, based on a systematic literature review, an extensive initial set of security and privacy requirements is elicited. Second, an online survey based on the best-worst scaling method is designed, conducted, and evaluated to determine priorities of security and privacy requirements. Our results show that confidentiality and integrity of medical data are ranked at the top of the hierarchy of prioritized requirements, followed by control of data use and modification, patients’ anonymity, and patients’ control of access rights. Availability, fine-grained access control, revocation of access rights, flexible access, clinicians’ anonymity, as well as usability, scalability, and efficiency of the system complete the ranking. The level of agreement among patients is rather small, but statistically significant at the 0.01 level. The main contribution of the present research comprises the study method and results highlighting the role of strong security and privacy and excluding any trade-offs with system usability. Enabling a richer understanding of patients’ security and privacy requirements for adopting cloud computing in healthcare, these are of particular importance to researchers and practitioners interested in supporting the process of security and privacy engineering for health-cloud solutions. It further represents a supplement that can support time-intensive negotiation meetings between the requirements engineers and patients.},
  archive      = {J_TMIS},
  author       = {Tatiana Ermakova and Benjamin Fabian and Marta Kornacka and Scott Thiebes and Ali Sunyaev},
  doi          = {10.1145/3386160},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {6:1–29},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Security and privacy requirements for cloud computing in healthcare: Elicitation and prioritization from a patient perspective},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When are cyber blackouts in modern service networks likely?:
A network oblivious theory on cyber (re)insurance feasibility.
<em>TMIS</em>, <em>11</em>(2), 5:1–38. (<a
href="https://doi.org/10.1145/3386159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service liability interconnections among globally networked IT- and IoT-driven service organizations create potential channels for cascading service disruptions worth billions of dollars, due to modern cyber-crimes such as DDoS, APT, and ransomware attacks. A natural question that arises in this context is: What is the likelihood of a cyber-blackout? , where the latter term is defined as the probability that all (or a major subset of) organizations in a service chain become dysfunctional in a certain manner due to a cyber-attack at some or all points in the chain. The answer to this question has major implications to risk management businesses such as cyber-insurance when it comes to designing policies by risk-averse insurers for providing coverage to clients in the aftermath of such catastrophic network events. In this article, we investigate this question in general as a function of service chain networks and different cyber-loss distribution types. We show somewhat surprisingly (and discuss the potential practical implications) that, following a cyber-attack, the effect of (a) a network interconnection topology and (b) a wide range of loss distributions on the probability of a cyber-blackout and the increase in total service-related monetary losses across all organizations are mostly very small. The primary rationale behind these results are attributed to degrees of heterogeneity in the revenue base among organizations and the Increasing Failure Rate property of popular (i.i.d/non-i.i.d) loss distributions, i.e., log-concave cyber-loss distributions. The result will enable risk-averse cyber-risk managers to safely infer the impact of cyber-attacks in a worst-case network and distribution oblivious setting.},
  archive      = {J_TMIS},
  author       = {Ranjan Pal and Konstantinos Psounis and Jon Crowcroft and Pan Hui and Sasu Tarkoma and Abhishek Kumar and John Kelly and Aritra Chatterjee and Leana Golubchik and Nishanth Sastry and Bodhibrata Nag},
  doi          = {10.1145/3386159},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {2},
  pages        = {5:1–38},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {When are cyber blackouts in modern service networks likely?: A network oblivious theory on cyber (Re)Insurance feasibility},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven characterization of modern android spyware.
<em>TMIS</em>, <em>11</em>(1), 4:1–38. (<a
href="https://doi.org/10.1145/3382158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to Nokia’s 2017 Threat Intelligence Report, 68.5\% of malware targets the Android platform; Windows is second with 28\%, followed by iOS and other platforms with 3.5\%. The Android spyware family U A P USH was responsible for the most infections, and several of the top 20 most common Android malware were spyware. Simply put, modern spyware steals the basic information needed to fuel more deadly attacks such as ransomware and banking fraud. Not surprisingly, some forms of spyware are also classified as banking trojans (e.g., A CE C ARD ). We present a data-driven characterization of the principal factors that distinguish modern Android spyware (July 2016–July 2017) both from goodware and other Android malware, using both traditional and deep ML. First, we propose an Ensemble Late Fusion (ELF) architecture that combines the results of multiple classifiers’ predicted probabilities to generate a final prediction. We show that ELF outperforms several of the best-known traditional and deep learning classifiers. Second, we automatically identify key features that distinguish spyware both from goodware and from other malware. Finally we present a detailed analysis of the factors distinguishing five important families of Android spyware: U A P USH , P INCER , H E H E , USBC LEAVER , and A CE C ARD (the last is a hybrid spyware-banking trojan).},
  archive      = {J_TMIS},
  author       = {Fabio Pierazzi and Ghita Mezzour and Qian Han and Michele Colajanni and V. S. Subrahmanian},
  doi          = {10.1145/3382158},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {4:1–38},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A data-driven characterization of modern android spyware},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining the local dependency itemset in a products network.
<em>TMIS</em>, <em>11</em>(1), 3:1–31. (<a
href="https://doi.org/10.1145/3384473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many studies have been conducted on market basket analysis such as association rules and dependent patterns. These studies mainly focus on mining all significant patterns or patterns directly associated with a given item in a dataset. The problem that has not been addressed is how to mine patterns associated with a given item from the local view. This problem becomes very meaningful when the market basket dataset is huge. To address this problem, in this study, first, a new idea called “local dependency itemset” is put forward, which refers to patterns associated with the given item. Second, a framework of mining the local dependency itemset is presented. The framework has two steps, which are executed iteratively. One is expanding the local dependency itemset that initially consists of only the given item; the other is updating the local products network. Third, this framework is implemented by three different dependence indicators and a typical local community detection algorithm. The experimental results confirm that the local dependency itemset is meaningful.},
  archive      = {J_TMIS},
  author       = {Li Ni and Wenjian Luo and Nannan Lu and Wenjie Zhu},
  doi          = {10.1145/3384473},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {3:1–31},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Mining the local dependency itemset in a products network},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A randomized reputation system in the presence of unfair
ratings. <em>TMIS</em>, <em>11</em>(1), 2:1–16. (<a
href="https://doi.org/10.1145/3384472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of online shopping markets, a significant number of consumers rely on these venues to meet their demands while choosing different products based on the ratings provided by others. Simultaneously, consumers feel confident in expressing their opinions through ratings. As a result, millions of ratings are generated on the web for different products, services, and dealers. Nonetheless, a noticeable number of users post unfair feedback. Recent studies have shown that reputation escalation is emerging as a new service, by which dealers pay to receive good feedback and escalate their ratings in online shopping markets. Therefore, finding robust and reliable ways to distinguish between fake and trustworthy ratings from users is a crucial task for every online shopping market. Moreover, with the dramatic increase in the number of ratings provided by consumers, scalability has arisen as another significant issue in the existing methods of reputation systems. To tackle these issues, we propose a randomized algorithm that calculates the reputation based on a random sample of the ratings. Since the randomly selected sample has a logarithmic size, it guarantees feasible scalability for large-scale online review systems. In addition, the randomness nature of the algorithm makes it robust against unfair ratings. We provide a thorough theoretical analysis of the proposed algorithm and validate its effectiveness through extensive empirical evaluation using real-world and synthetically generated datasets. Our experimental results show that the proposed method provides a high accuracy while running much faster than the existing iterative filtering approaches.},
  archive      = {J_TMIS},
  author       = {Mohsen Rezvani and Mojtaba Rezvani},
  doi          = {10.1145/3384472},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {2:1–16},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {A randomized reputation system in the presence of unfair ratings},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Invested or indebted: Ex-ante and ex-post reciprocity in
online knowledge sharing communities. <em>TMIS</em>, <em>11</em>(1),
1:1–26. (<a href="https://doi.org/10.1145/3371388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online communities that curate knowledge critically depend on high-quality contributions from anonymous expert users. Understanding users’ motivation to contribute knowledge helps practitioners design such websites for optimal user contribution and user benefits. Researchers have studied reciprocity as a motivation for users to share knowledge online. In this study, we focus on two different types of reciprocity as drivers of online contribution: ex-post and ex-ante reciprocity. Ex-post reciprocity refers to users who received help from others in the past and pay back by helping others at present. Using a quasi-experiment performed via the instrumental variable method as the identification strategy, we test whether users who received more answers last week answer more questions in the current week on StackOverflow.com. We find a significant positive relationship between ex-post reciprocity and knowledge contribution, and such a reciprocal motivation diminishes with time. Ex-ante reciprocity refers to people helping others in expectation of future help from others. Using data from StackOverflow.com, we take advantage of a natural experiment with a difference-in-differences analysis and find evidence supporting the existence of ex-ante reciprocity. This study offers a new taxonomy for reciprocity and new insights on how reciprocity drives online knowledge sharing.},
  archive      = {J_TMIS},
  author       = {Hongfei Li and Ramesh Shankar and Jan Stallaert},
  doi          = {10.1145/3371388},
  journal      = {ACM Transactions on Management Information Systems},
  number       = {1},
  pages        = {1:1–26},
  shortjournal = {ACM Trans. Manag. Inf. Sys.},
  title        = {Invested or indebted: Ex-ante and ex-post reciprocity in online knowledge sharing communities},
  volume       = {11},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
