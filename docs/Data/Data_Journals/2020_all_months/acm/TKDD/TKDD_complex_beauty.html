<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkdd---85">TKDD - 85</h2>
<ul>
<li><details>
<summary>
(2020). Dynamic graph mining for multi-weight multi-destination
route planning with deadlines constraints. <em>TKDD</em>,
<em>15</em>(1), 1–32. (<a
href="https://doi.org/10.1145/3412363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Route planning satisfied multiple requests is an emerging branch in the route planning field and has attracted significant attention from the research community in recent years. The prevailing studies focus only on seeking a route by minimizing a single kind of Travel Cost, such as trip time or distance, among others. In reality, most users would like to choose an appropriate route, neither fastest nor shortest route. Usually, a user may have multiple requirements, and an appropriate route would satisfy all requirements requested by the user. In fact, planning an appropriate route could be formulated as a problem of Multi-weight Multi-destination Route Planning with Deadlines Constraints (MWMDRP-DC). In this article, we propose a framework, namely, MWMD-Router, which addresses the MWMDRP-DC problem comprehensively. To consider the travel costs with time-variation, we propose not only four novel dynamic graph miner to extract travel costs that reveal users’ requirements but also two new algorithms, namely, Basic MWMD Route Planning and Advanced MWMD Route Planning , to plan a route that satisfies deadline requirements and optimizes another criterion like travel cost with time-variation efficiently. To the best of our knowledge, this is the first work on route planning that considers handling multiple deadlines for multi-destination planning as well as optimizing multiple travel costs with time-variation simultaneously. Experimental results demonstrate that our proposed algorithms deliver excellent performance with respect to efficiency and effectiveness.},
  archive      = {J_TKDD},
  doi          = {10.1145/3412363},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Dynamic graph mining for multi-weight multi-destination route planning with deadlines constraints},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Class imbalance and cost-sensitive decision trees: A unified
survey based on a core similarity. <em>TKDD</em>, <em>15</em>(1), 1–31.
(<a href="https://doi.org/10.1145/3415156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance treatment methods and cost-sensitive classification algorithms are typically treated as two independent research areas. However, many of these techniques have properties in common. After providing a background to the two fields of research, this article identifies the fundamental mechanism which is common to both. Using this mechanism, a taxonomy is created which encompasses approaches to both class imbalance treatment and cost-sensitive classification. Through this survey, we aim to bridge the gap between the two fields such that lessons from one field may be applied to the other. Many data mining tasks are naturally both class imbalanced and cost-sensitive. This survey is useful for researchers and practitioners approaching these tasks as it provides a detailed overview of approaches in both fields. Many of the surveyed techniques are classifier independent. However, we chose to focus on techniques which were either decision tree-based or compatible with decision trees. This choice was based on the popularity and novelty of their application to both fields.},
  archive      = {J_TKDD},
  doi          = {10.1145/3415156},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Class imbalance and cost-sensitive decision trees: A unified survey based on a core similarity},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-stage network embedding for exploring heterogeneous
edges. <em>TKDD</em>, <em>15</em>(1), 1–27. (<a
href="https://doi.org/10.1145/3415157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationships between objects in a network are typically diverse and complex, leading to the heterogeneous edges with different semantic information. In this article, we focus on exploring the heterogeneous edges for network representation learning. By considering each relationship as a view that depicts a specific type of proximity between nodes, we propose a multi-stage non-negative matrix factorization (MNMF) model, committed to utilizing abundant information in multiple views to learn robust network representations. In fact, most existing network embedding methods are closely related to implicitly factorizing the complex proximity matrix. However, the approximation error is usually quite large, since a single low-rank matrix is insufficient to capture the original information. Through a multi-stage matrix factorization process motivated by gradient boosting, our MNMF model achieves lower approximation error. Meanwhile, the multi-stage structure of MNMF gives the feasibility of designing two kinds of non-negative matrix factorization (NMF) manners to preserve network information better. The united NMF aims to preserve the consensus information between different views, and the independent NMF aims to preserve unique information of each view. Concrete experimental results on realistic datasets indicate that our model outperforms three types of baselines in practical applications.},
  archive      = {J_TKDD},
  doi          = {10.1145/3415157},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-stage network embedding for exploring heterogeneous edges},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust tensor recovery with fiber outliers for traffic
events. <em>TKDD</em>, <em>15</em>(1), 1–27. (<a
href="https://doi.org/10.1145/3417337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event detection is gaining increasing attention in smart cities research. Large-scale mobility data serves as an important tool to uncover the dynamics of urban transportation systems, and more often than not the dataset is incomplete. In this article, we develop a method to detect extreme events in large traffic datasets, and to impute missing data during regular conditions. Specifically, we propose a robust tensor recovery problem to recover low-rank tensors under fiber-sparse corruptions with partial observations, and use it to identify events, and impute missing data under typical conditions. Our approach is scalable to large urban areas, taking full advantage of the spatio-temporal correlations in traffic patterns. We develop an efficient algorithm to solve the tensor recovery problem based on the alternating direction method of multipliers (ADMM) framework. Compared with existing l 1 norm regularized tensor decomposition methods, our algorithm can exactly recover the values of uncorrupted fibers of a low-rank tensor and find the positions of corrupted fibers under mild conditions. Numerical experiments illustrate that our algorithm can achieve exact recovery and outlier detection even with missing data rates as high as 40% under 5% gross corruption, depending on the tensor size and the Tucker rank of the low rank tensor. Finally, we apply our method on a real traffic dataset corresponding to downtown Nashville, TN and successfully detect the events like severe car crashes, construction lane closures, and other large events that cause significant traffic disruptions.},
  archive      = {J_TKDD},
  doi          = {10.1145/3417337},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Robust tensor recovery with fiber outliers for traffic events},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Span-core decomposition for temporal networks: Algorithms
and applications. <em>TKDD</em>, <em>15</em>(1), 1–44. (<a
href="https://doi.org/10.1145/3418226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When analyzing temporal networks, a fundamental task is the identification of dense structures (i.e., groups of vertices that exhibit a large number of links), together with their temporal span (i.e., the period of time for which the high density holds). In this article, we tackle this task by introducing a notion of temporal core decomposition where each core is associated with two quantities, its coreness, which quantifies how densely it is connected, and its span, which is a temporal interval: we call such cores span-cores . For a temporal network defined on a discrete temporal domain T , the total number of time intervals included in T is quadratic in | T |, so that the total number of span-cores is potentially quadratic in | T | as well. Our first main contribution is an algorithm that, by exploiting containment properties among span-cores, computes all the span-cores efficiently. Then, we focus on the problem of finding only the maximal span-cores , i.e., span-cores that are not dominated by any other span-core by both their coreness property and their span. We devise a very efficient algorithm that exploits theoretical findings on the maximality condition to directly extract the maximal ones without computing all span-cores. Finally, as a third contribution, we introduce the problem of temporal community search , where a set of query vertices is given as input, and the goal is to find a set of densely-connected subgraphs containing the query vertices and covering the whole underlying temporal domain T . We derive a connection between this problem and the problem of finding (maximal) span-cores. Based on this connection, we show how temporal community search can be solved in polynomial-time via dynamic programming, and how the maximal span-cores can be profitably exploited to significantly speed-up the basic algorithm. We provide an extensive experimentation on several real-world temporal networks of widely different origins and characteristics. Our results confirm the efficiency and scalability of the proposed methods. Moreover, we showcase the practical relevance of our techniques in a number of applications on temporal networks, describing face-to-face contacts between individuals in schools. Our experiments highlight the relevance of the notion of (maximal) span-core in analyzing social dynamics, detecting/correcting anomalies in the data, and graph-embedding-based network classification.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418226},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-44},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Span-core decomposition for temporal networks: Algorithms and applications},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical physician recommendation via diversity-enhanced
matrix factorization. <em>TKDD</em>, <em>15</em>(1), 1–17. (<a
href="https://doi.org/10.1145/3418227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that there exhibits significantly imbalanced medical resource allocation across public hospitals. Patients, regardless of their diseases, tend to choose hospitals and physicians with a better reputation, which often overloads major hospitals while leaving others underutilized. Guiding patients to hospitals that can serve their treatment needs both timely and with good quality can make the best use of precious medical resources. Unfortunately, it remains one of the major challenges both for research and in practice. In this article, we propose a novel diversity-enhanced hierarchical physician recommendation approach to address this issue. We adopt matrix factorization to estimate physician competency and exploit implicit similarity relationships to improve the competency estimation of physicians that we are of little information of. We then balance the patient preference and physician diversity using two novel heuristic algorithms. We evaluate our proposed approach and compare it with the state of the art. Experiments show that our approach significantly improves both accuracy and recommendation diversity over existing approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418227},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Hierarchical physician recommendation via diversity-enhanced matrix factorization},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic recommendation of a distance measure for
clustering algorithms. <em>TKDD</em>, <em>15</em>(1), 1–22. (<a
href="https://doi.org/10.1145/3418228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a large number of distance measures, the appropriate choice for clustering a given data set with a specified clustering algorithm becomes an important problem. In this article, an automatic distance measure recommendation method for clustering algorithms is proposed. The recommendation method consists of the following steps: (1) metadata extraction, including meta-feature collection and meta-target identification; (2) recommendation model construction using metadata; and (3) distance measure recommendation for a new data set by the recommendation model. Two different types of meta-targets and meta-learning techniques are utilized considering the possible different requirements of users. To validate the necessity and effectiveness of the distance measure recommendation method, an empirical study is conducted with 199 publicly available data sets, 9 distance measures, and 2 widely used clustering algorithms. The experimental results indicate that distance measure significantly influences the performance of the clustering algorithm for a given data set. Furthermore, performance analysis of the proposed recommendation method proves its effectiveness.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418228},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Automatic recommendation of a distance measure for clustering algorithms},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combinatorial algorithms for string sanitization.
<em>TKDD</em>, <em>15</em>(1), 1–34. (<a
href="https://doi.org/10.1145/3418683">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {String data are often disseminated to support applications such as location-based service provision or DNA sequence analysis. This dissemination, however, may expose sensitive patterns that model confidential knowledge (e.g., trips to mental health clinics from a string representing a user’s location history). In this article, we consider the problem of sanitizing a string by concealing the occurrences of sensitive patterns, while maintaining data utility, in two settings that are relevant to many common string processing tasks. In the first setting, we aim to generate the minimal-length string that preserves the order of appearance and frequency of all non-sensitive patterns. Such a string allows accurately performing tasks based on the sequential nature and pattern frequencies of the string. To construct such a string, we propose a time-optimal algorithm, TFS-ALGO. We also propose another time-optimal algorithm, PFS-ALGO, which preserves a partial order of appearance of non-sensitive patterns but produces a much shorter string that can be analyzed more efficiently. The strings produced by either of these algorithms are constructed by concatenating non-sensitive parts of the input string. However, it is possible to detect the sensitive patterns by “reversing” the concatenation operations. In response, we propose a heuristic, MCSR-ALGO, which replaces letters in the strings output by the algorithms with carefully selected letters, so that sensitive patterns are not reinstated, implausible patterns are not introduced, and occurrences of spurious patterns are prevented. In the second setting, we aim to generate a string that is at minimal edit distance from the original string, in addition to preserving the order of appearance and frequency of all non-sensitive patterns. To construct such a string, we propose an algorithm, ETFS-ALGO, based on solving specific instances of approximate regular expression matching. We implemented our sanitization approach that applies TFS-ALGO, PFS-ALGO, and then MCSR-ALGO, and experimentally show that it is effective and efficient. We also show that TFS-ALGO is nearly as effective at minimizing the edit distance as ETFS-ALGO, while being substantially more efficient than ETFS-ALGO.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418683},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Combinatorial algorithms for string sanitization},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerating large-scale heterogeneous interaction graph
embedding learning via importance sampling. <em>TKDD</em>,
<em>15</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3418684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world problems, heterogeneous entities are often related to each other through multiple interactions, forming a Heterogeneous Interaction Graph (HIG). While modeling HIGs to deal with fundamental tasks, graph neural networks present an attractive opportunity that can make full use of the heterogeneity and rich semantic information by aggregating and propagating information from different types of neighborhoods. However, learning on such complex graphs, often with millions or billions of nodes, edges, and various attributes, could suffer from expensive time cost and high memory consumption. In this article, we attempt to accelerate representation learning on large-scale HIGs by adopting the importance sampling of heterogeneous neighborhoods in a batch-wise manner, which naturally fits with most batch-based optimizations. Distinct from traditional homogeneous strategies neglecting semantic types of nodes and edges, to handle the rich heterogeneous semantics within HIGs, we devise both type-dependent and type-fusion samplers where the former respectively samples neighborhoods of each type and the latter jointly samples from candidates of all types. Furthermore, to overcome the imbalance between the down-sampled and the original information, we respectively propose heterogeneous estimators including the self-normalized and the adaptive estimators to improve the robustness of our sampling strategies. Finally, we evaluate the performance of our models for node classification and link prediction on five real-world datasets, respectively. The empirical results demonstrate that our approach performs significantly better than other state-of-the-art alternatives, and is able to reduce the number of edges in computation by up to 93%, the memory cost by up to 92% and the time cost by up to 86%.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418684},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Accelerating large-scale heterogeneous interaction graph embedding learning via importance sampling},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous graphlets. <em>TKDD</em>, <em>15</em>(1),
1–43. (<a href="https://doi.org/10.1145/3418773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce a generalization of graphlets to heterogeneous networks called typed graphlets . Informally, typed graphlets are small typed induced subgraphs. Typed graphlets generalize graphlets to rich heterogeneous networks as they explicitly capture the higher-order typed connectivity patterns in such networks. To address this problem, we describe a general framework for counting the occurrences of such typed graphlets. The proposed algorithms leverage a number of combinatorial relationships for different typed graphlets. For each edge, we count a few typed graphlets, and with these counts along with the combinatorial relationships, we obtain the exact counts of the other typed graphlets in o (1) constant time. Notably, the worst-case time complexity of the proposed approach matches the time complexity of the best known untyped algorithm. In addition, the approach lends itself to an efficient lock-free and asynchronous parallel implementation. While there are no existing methods for typed graphlets, there has been some work that focused on computing a different and much simpler notion called colored graphlet. The experiments confirm that our proposed approach is orders of magnitude faster and more space-efficient than methods for computing the simpler notion of colored graphlet. Unlike these methods that take hours on small networks, the proposed approach takes only seconds on large networks with millions of edges. Notably, since typed graphlet is more general than colored graphlet (and untyped graphlets), the counts of various typed graphlets can be combined to obtain the counts of the much simpler notion of colored graphlets. The proposed methods give rise to new opportunities and applications for typed graphlets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3418773},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-43},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Heterogeneous graphlets},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CrowdWT: Crowdsourcing via joint modeling of workers and
tasks. <em>TKDD</em>, <em>15</em>(1), 1–24. (<a
href="https://doi.org/10.1145/3421712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is a relatively inexpensive and efficient mechanism to collect annotations of data from the open Internet. Crowdsourcing workers are paid for the provided annotations, but the task requester usually has a limited budget. It is desirable to wisely assign the appropriate task to the right workers, so the overall annotation quality is maximized while the cost is reduced. In this article, we propose a novel task assignment strategy (CrowdWT) to capture the complex interactions between tasks and workers, and properly assign tasks to workers. CrowdWT first develops a Worker Bias Model (WBM) to jointly model the worker’s bias, the ground truths of tasks, and the task features. WBM constructs a mapping between task features and worker annotations to dynamically assign the task to a group of workers, who are more likely to give correct annotations for the task. CrowdWT further introduces a Task Difficulty Model (TDM), which builds a Kernel ridge regressor based on task features to quantify the intrinsic difficulty of tasks and thus to assign the difficult tasks to more reliable workers. Finally, CrowdWT combines WBM and TDM into a unified model to dynamically assign tasks to a group of workers and recall more reliable and even expert workers to annotate the difficult tasks. Our experimental results on two real-world datasets and two semi-synthetic datasets show that CrowdWT achieves high-quality answers within a limited budget, and has the best performance against competitive methods.&lt;?vsp -1.5pt?&gt;},
  archive      = {J_TKDD},
  doi          = {10.1145/3421712},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CrowdWT: Crowdsourcing via joint modeling of workers and tasks},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MeSHProbeNet-p: Improving large-scale MeSH indexing with
personalizable MeSH probes. <em>TKDD</em>, <em>15</em>(1), 1–14. (<a
href="https://doi.org/10.1145/3421713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indexing biomedical research articles with Medical Subject Headings (MeSH) can greatly facilitate biomedical research and information retrieval. Currently MeSH indexing is performed by human experts. To alleviate the time consumption and monetary cost caused by manual indexing, many automatic MeSH indexing models have been developed, such as MeSHProbeNet, DeepMeSH, and NLM’s official model Medical Text Indexer. In this article, we propose an end-to-end framework, MeSHProbeNet-P, which extends MeSHProbeNet with personalizable MeSH probes. In MeSHProbeNet-P, each MeSH probe carries certain aspects of biomedical knowledge and extracts related information from input articles. MeSHProbeNet-P is able to automatically personalize its MeSH probes for different input articles to ensure that the current MeSH probes best fit the current input article and the most informative features can be extracted from the article. We demonstrate the effectiveness of MeSHProbeNet-P in a real-world large-scale MeSH indexing challenge. MeSHProbeNet-P won the first place in the first batch of Task A in the 2019 BioASQ challenge. The result on the first test set of the challenge is reported in this article. We also provide ablation studies to show the advantages of personalizable MeSH probes.},
  archive      = {J_TKDD},
  doi          = {10.1145/3421713},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-14},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MeSHProbeNet-P: Improving large-scale MeSH indexing with personalizable MeSH probes},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A reduced network traffic method for IoT data clustering.
<em>TKDD</em>, <em>15</em>(1), 1–23. (<a
href="https://doi.org/10.1145/3423139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) systems usually involve interconnected, low processing capacity, and low memory sensor nodes (devices) that collect data in several sorts of applications that interconnect people and things. In this scenario, mining tasks, such as clustering, have been commonly deployed to detect behavioral patterns from the collected data. The centralized clustering of IoT data demands high network traffic to transmit the data from the devices to a central node, where a clustering algorithm must be applied. This approach does not scale as the number of devices increases, and the amount of data grows. However, distributing the clustering process through the devices may not be a feasible approach as well, since the devices are usually simple and may not have the ability to execute complex procedures. This work proposes a centralized IoT data clustering method that demands reduced network traffic and low processing power in the devices. The proposed method uses a data grid to summarize the information at the devices before transmitting it to the central node, reducing network traffic. After the data transfer, the proposed method applies a clustering algorithm that was developed to process data in the summarized representation. Tests with seven datasets provided experimental evidence that the proposed method reduces network traffic and produces results comparable to the ones generated by DBSCAN and HDBSCAN, two robust centralized clustering algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3423139},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A reduced network traffic method for IoT data clustering},
  volume       = {15},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient outlier detection in text corpus using rare
frequency and ranking. <em>TKDD</em>, <em>14</em>(6), 1–30. (<a
href="https://doi.org/10.1145/3399712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection in text data collections has become significant due to the need of finding anomalies in the myriad of text data sources. High feature dimensionality, together with the larger size of these document collections, presents a need for developing accurate outlier detection methods with high efficiency. Traditional outlier detection methods face several challenges including data sparseness, distance concentration, and the presence of a larger number of sub-groups when dealing with text data. In this article, we propose to address these issues by developing novel concepts such as presenting documents with the rare document frequency, finding ranking-based neighborhood for similarity computation, and identifying sub-dense local neighborhoods in high dimensions. To improve the proposed primary method based on rare document frequency, we present several novel ensemble approaches using the ranking concept to reduce the false identifications while finding the higher number of true outliers. Extensive empirical analysis shows that the proposed method and its ensemble variations improve the quality of outlier detection in document repositories as well as they are found scalable compared to the relevant benchmarking methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3399712},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {10},
  number       = {6},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient outlier detection in text corpus using rare frequency and ranking},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable spatial scan statistics for trajectories.
<em>TKDD</em>, <em>14</em>(6), 1–24. (<a
href="https://doi.org/10.1145/3394046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define several new models for how to define anomalous regions among enormous sets of trajectories. These are based on spatial scan statistics, and identify a geometric region which captures a subset of trajectories which are significantly different in a measured characteristic from the background population. The model definition depends on how much a geometric region is contributed to by some overlapping trajectory. This contribution can be the full trajectory, proportional to the length within the spatial region, or dependent on the flux across the boundary of that spatial region. Our methods are based on and significantly extend a recent two-level sampling approach which provides high accuracy at enormous scales of data. We support these new models and algorithms with extensive experiments on millions of trajectories and also theoretical guarantees.},
  archive      = {J_TKDD},
  doi          = {10.1145/3394046},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Scalable spatial scan statistics for trajectories},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Influence maximization: Seeding based on community
structure. <em>TKDD</em>, <em>14</em>(6), 1–22. (<a
href="https://doi.org/10.1145/3399661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization problem attempts to find a small subset of nodes in a social network that makes the expected influence maximized, which has been researched intensively before. Most of the existing literature focus only on maximizing total influence, but it ignores whether the influential distribution is balanced through the network. Even though the total influence is maximized, but gathered in a certain area of social network. Sometimes, this is not advisable. In this article, we propose a novel seeding strategy based on community structure, and formulate the Influence Maximization with Community Budget (IMCB) problem. In this problem, the number of seed nodes in each community is under the cardinality constraint, which can be classified as the problem of monotone submodular maximization under the matroid constraint. To give a satisfactory solution for IMCB problem under the triggering model, we propose the IMCB-Framework, which is inspired by the idea of continuous greedy process and pipage rounding, and derive the best approximation ratio for this problem. In IMCB-Framework, we adopt sampling techniques to overcome the high complexity of continuous greedy. Then, we propose a simplified pipage rounding algorithm, which reduces the complexity of IMCB-Framework further. Finally, we conduct experiments on three real-world datasets to evaluate the correctness and effectiveness of our proposed algorithms, as well as the advantage of IMCB-Framework against classical greedy method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3399661},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Influence maximization: Seeding based on community structure},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NGUARD+: An attention-based game bot detection framework via
player behavior sequences. <em>TKDD</em>, <em>14</em>(6), 1–24. (<a
href="https://doi.org/10.1145/3399711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game bots are automated programs that assist cheating users, leading to an imbalance in the game ecosystem and the collapse of user interest. Online games provide immersive gaming experience and attract many loyal fans. However, game bots have proliferated in volume and method, evolving with the real-world detection methods and showing strong diversity, leaving game bot detection efforts extremely difficult. Existing game bot detection techniques mostly rely on handcrafted features or time-series based features instead of fully utilizing player behavior sequences. In this regard, a more reasonable way should be learning user patterns from player behavior sequences when facing the fast-changing nature of game bots. Here we propose a general game bot detection framework for massively multiplayer online role playing games termed NGUARD+ (denoting NetEase Games’ Guard), which captures user patterns in order to identify game bots from player behavior sequences. NGUARD+ mainly employs attention-based methods to automatically differentiate game bots from humans. We provide a combination of supervised and unsupervised methods for game bot detection to detect game bots and new type of game bots even when the labels of game bots are limited. Specifically, we propose the following two variants for attention-based sequence modeling: Attention based Bidirectional Long Short-Term Memory Networks (ABLSTM) and Hierarchical Self-Attention Network (HSAN) as our supervised models. ABLSTM is keen on inducing certain inductive biases which makes learning more reasonable as well as capturing local dependency and global information, while HSAN could handle much longer behavior sequences with less memory and higher computational efficiency. Experiments conducted on a real-world dataset show that NGUARD+ can achieve remarkable performance improvement compared to traditional methods. Moreover, NGUARD+ can reveal outstanding robustness for game bots in mutated patterns and even in completely unseen patterns.},
  archive      = {J_TKDD},
  doi          = {10.1145/3399711},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {NGUARD+: An attention-based game bot detection framework via player behavior sequences},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous univariate outlier ensembles in
multidimensional data. <em>TKDD</em>, <em>14</em>(6), 1–27. (<a
href="https://doi.org/10.1145/3403934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In outlier detection, recent major research has shifted from developing univariate methods to multivariate methods due to the rapid growth of multidimensional data. However, one typical issue of this paradigm shift is that many multidimensional data often mainly contains univariate outliers , in which many features are actually irrelevant. In such cases, multivariate methods are ineffective in identifying such outliers due to the potential biases and the curse of dimensionality brought by irrelevant features. Those univariate outliers might be well detected by applying univariate outlier detectors in individually relevant features. However, it is very challenging to choose a right univariate detector for each individual feature since different features may take very different probability distributions. To address this challenge, we introduce a novel Heterogeneous Univariate Outlier Ensembles (HUOE) framework and its instance ZDD to synthesize a set of heterogeneous univariate outlier detectors as base learners to build heterogeneous ensembles that are optimized for each individual feature. Extensive results on 19 real-world datasets and a collection of synthetic datasets show that ZDD obtains 5%–14% average AUC improvement over four state-of-the-art multivariate ensembles and performs substantially more robustly w.r.t. irrelevant features.},
  archive      = {J_TKDD},
  doi          = {10.1145/3403934},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Heterogeneous univariate outlier ensembles in multidimensional data},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting item-based collaborative filtering via nearly
uncoupled random walks. <em>TKDD</em>, <em>14</em>(6), 1–26. (<a
href="https://doi.org/10.1145/3406241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Item-based models are among the most popular collaborative filtering approaches for building recommender systems. Random walks can provide a powerful tool for harvesting the rich network of interactions captured within these models. They can exploit indirect relations between the items, mitigate the effects of sparsity, ensure wider itemspace coverage, as well as increase the diversity of recommendation lists. Their potential however, can be hindered by the tendency of the walks to rapidly concentrate towards the central nodes of the graph, thereby significantly restricting the range of K -step distributions that can be exploited for personalized recommendations. In this work, we introduce RecWalk ; a novel random walk-based method that leverages the spectral properties of nearly uncoupled Markov chains to provably lift this limitation and prolong the influence of users’ past preferences on the successive steps of the walk—thereby allowing the walker to explore the underlying network more fruitfully. A comprehensive set of experiments on real-world datasets verify the theoretically predicted properties of the proposed approach and indicate that they are directly linked to significant improvements in top- n recommendation accuracy. They also highlight RecWalk’s potential in providing a framework for boosting the performance of item-based models. RecWalk achieves state-of-the-art top- n recommendation quality outperforming several competing approaches, including recently proposed methods that rely on deep neural networks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3406241},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Boosting item-based collaborative filtering via nearly uncoupled random walks},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic modeling for frequency vectors using a
flexible shifted-scaled dirichlet distribution prior. <em>TKDD</em>,
<em>14</em>(6), 1–35. (<a
href="https://doi.org/10.1145/3406242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burstiness and overdispersion phenomena of count vectors pose significant challenges in modeling such data accurately. While the dependency assumption of the multinomial distribution causes its failure to model frequency vectors in several machine learning and data mining applications, researchers found that by extending the multinomial distribution to the Dirichlet Compound multinomial (DCM), both phenomena modeling can be addressed. However, Dirichlet distribution is not the best choice, as a prior, given its negative-correlation and equal-confidence requirements. Thus, we propose to use a flexible generalization of the Dirichlet distribution, namely, the shifted-scaled Dirichlet, as a prior to the multinomial, which grants the model a capability to better fit real data, and we call the new model the Multinomial Shifted-Scaled Dirichlet (MSSD). Given that the likelihood function plays a key role in statistical inference, e.g., in maximum likelihood estimation and Fisher information matrix investigation, we propose to improve the efficiency of computing the MSSD log-likelihood by approximating its function based on Bernoulli polynomials where the log-likelihood function is computed using the proposed mesh algorithm. Moreover, given the sparsity and high-dimensionality nature of count vectors, we propose to improve its computation efficiency by approximating the novel MSSD as a member of the exponential family of distribution, which we call EMSSD. The clustering is based on mixture models, and for learning a model, selection approach is seamlessly integrated with the estimation of the parameters. The merits of the proposed approach are validated via challenging real-world applications such as hate speech detection in Twitter, real-time recognition of criminal action, and anomaly detection in crowded scenes. Results reveal that the proposed clustering frameworks offer a good compromise between other state-of-the-art techniques and outperform other approaches previously used for frequency vectors modeling. Besides, comparing to the MSSD, the approximation EMSSD has reduced the computational complexity in high-dimensional feature spaces.},
  archive      = {J_TKDD},
  doi          = {10.1145/3406242},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-35},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Probabilistic modeling for frequency vectors using a flexible shifted-scaled dirichlet distribution prior},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach for concept drift detection in a graph stream
using discriminative subgraphs. <em>TKDD</em>, <em>14</em>(6), 1–25. (<a
href="https://doi.org/10.1145/3406243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of mining complex networks like social media, sensor networks, and the world-wide-web has attracted considerable research interest. In a streaming scenario, the concept to be learned can change over time. However, while there has been some research done for detecting concept drift in traditional data streams, little work has been done on addressing concept drift in data represented as a graph . We propose a novel unsupervised concept-drift detection method on graph streams called Discriminative Subgraph-based Drift Detector (DSDD). The methodology starts by discovering discriminative subgraphs for each graph in the stream. We then compute the entropy of the window based on the distribution of discriminative subgraphs with respect to the graphs and then use the direct density-ratio estimation approach for detecting concept drift in the series of entropy values obtained by moving one step forward in the sliding window. The effectiveness of the proposed method is demonstrated through experiments using artificial and real-world datasets and its performance is evaluated by comparing against related baseline methods. Similarly, the usefulness of the proposed concept drift detection approach is studied by incorporating it in a popular graph stream classification algorithm and studying the impact of drift detection in classification accuracy.},
  archive      = {J_TKDD},
  doi          = {10.1145/3406243},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {An approach for concept drift detection in a graph stream using discriminative subgraphs},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting user preference and mobile peer influence for
human mobility annotation. <em>TKDD</em>, <em>14</em>(6), 1–18. (<a
href="https://doi.org/10.1145/3406600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human mobility annotation aims to assign mobility records the corresponding visiting Point-of-Interests (POIs). It is one of the most fundamental problems for understanding human mobile behaviors. In literature, many efforts have been devoted to annotating mobility records in a pointwise or trajectory-wise manner. However, the user preference factor is not fully explored and, worse still, the mobile peer influence factor has never been integrated. To this end, in this article, we propose a novel framework, named JEPPI, to jointly exploit user preference and mobile peer influence to tackle the problem. In our JEPPI, we first unify the two distinct factors in a behavior-driven user-POI graph. This graph enables us to model user preference with user-POI visiting relationships, and model two types of mobile peer influence with co-location and co-visiting peer relationships, respectively. Moreover, we devise an equivalence-emphasizing metric to reduce redundancy in the second-order co-visiting peer influence. In addition, a mutual augmentation learning approach is proposed to preserve the latent structures of various factors exploited. Notably, our learning approach preserves all factors in a shared representation space such that user preference is learned with mobile peer influence being considered at the same time, and vice versa. In this way, the different factors are mutually augmented and semantically integrated to enhance human mobility annotation. Finally, using two large-scale real-world datasets, we conduct extensive experiments to demonstrate the superiority of our approach compared with the state-of-the-art annotation methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3406600},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-18},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Exploiting user preference and mobile peer influence for human mobility annotation},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-warped sparse non-negative factorization for functional
data analysis. <em>TKDD</em>, <em>14</em>(6), 1–23. (<a
href="https://doi.org/10.1145/3408313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel time-warped sparse non-negative factorization method for functional data analysis. The proposed method on the one hand guarantees the extracted basis functions and their coefficients to be positive and interpretable, and on the other hand is able to handle weakly correlated functions with different features. Furthermore, the method incorporates time warping into factorization and hence allows the extracted basis functions of different samples to have temporal deformations. An efficient framework of estimation algorithms is proposed based on a greedy variable selection approach. Numerical studies together with case studies on real-world data demonstrate the efficacy and applicability of the proposed methodology.},
  archive      = {J_TKDD},
  doi          = {10.1145/3408313},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Time-warped sparse non-negative factorization for functional data analysis},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust adaptive linear discriminant analysis with
bidirectional reconstruction constraint. <em>TKDD</em>, <em>14</em>(6),
1–20. (<a href="https://doi.org/10.1145/3409478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) is a well-known supervised method for dimensionality reduction in which the global structure of data can be preserved. The classical LDA is sensitive to the noises, and the projection direction of LDA cannot preserve the main energy. This article proposes a novel feature extraction model with l 2,1 norm constraint based on LDA, termed as RALDA. This model preserves within-class local structure in the latent subspace according to the label information. To reduce information loss, it learns a projection matrix and an inverse projection matrix simultaneously. By introducing an implicit variable and matrix norm transformation, the alternating direction multiple method with updating variables is designed to solve the RALDA model. Moreover, both computational complexity and weak convergence property of the proposed algorithm are investigated. The experimental results on several public databases have demonstrated the effectiveness of our proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3409478},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Robust adaptive linear discriminant analysis with bidirectional reconstruction constraint},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Large-scale data exploration using explanatory regression
functions. <em>TKDD</em>, <em>14</em>(6), 1–33. (<a
href="https://doi.org/10.1145/3410448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analysts wishing to explore multivariate data spaces, typically issue queries involving selection operators, i.e., range or equality predicates, which define data subspaces of potential interest. Then, they use aggregation functions, the results of which determine a subspace’s interestingness for further exploration and deeper analysis. However, Aggregate Query (AQ) results are scalars and convey limited information and explainability about the queried subspaces for enhanced exploratory analysis. Analysts have no way of identifying how these results are derived or how they change w.r.t query (input) parameter values. We address this shortcoming by aiding analysts to explore and understand data subspaces by contributing a novel explanation mechanism based on machine learning. We explain AQ results using functions obtained by a three-fold joint optimization problem which assume the form of explainable piecewise-linear regression functions. A key feature of the proposed solution is that the explanation functions are estimated using past executed queries. These queries provide a coarse grained overview of the underlying aggregate function (generating the AQ results) to be learned. Explanations for future, previously unseen AQs can be computed without accessing the underlying data and can be used to further explore the queried data subspaces, without issuing more queries to the backend analytics engine. We evaluate the explanation accuracy and efficiency through theoretically grounded metrics over real-world and synthetic datasets and query workloads.},
  archive      = {J_TKDD},
  doi          = {10.1145/3410448},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Large-scale data exploration using explanatory regression functions},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). REMIAN: Real-time and error-tolerant missing value
imputation. <em>TKDD</em>, <em>14</em>(6), 1–38. (<a
href="https://doi.org/10.1145/3412364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing value (MV) imputation is a critical preprocessing means for data mining. Nevertheless, existing MV imputation methods are mostly designed for batch processing, and thus are not applicable to streaming data, especially those with poor quality. In this article, we propose a framework, called Real-time and Error-tolerant Missing vAlue ImputatioN (REMAIN), to impute MVs in poor-quality streaming data. Instead of imputing MVs based on all the observed data, REMAIN first initializes the MV imputation model based on a-RANSAC which is capable of detecting and rejecting anomalies in an efficient manner, and then incrementally updates the model parameters upon the arrival of new data to support real-time MV imputation. As the correlations among attributes of the data may change over time in unforseenable ways, we devise a deterioration detection mechanism to capture the deterioration of the imputation model to further improve the imputation accuracy. Finally, we conduct an extensive evaluation on the proposed algorithms using real-world and synthetic datasets. Experimental results demonstrate that REMAIN achieves significantly higher imputation accuracy over existing solutions. Meanwhile, REMAIN improves up to one order of magnitude in time cost compared with existing approaches.},
  archive      = {J_TKDD},
  doi          = {10.1145/3412364},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-38},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {REMIAN: Real-time and error-tolerant missing value imputation},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-directional recurrent attentional topic model.
<em>TKDD</em>, <em>14</em>(6), 1–30. (<a
href="https://doi.org/10.1145/3412371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a document, the topic distribution of a sentence depends on both the topics of its neighbored sentences and its own content, and it is usually affected by the topics of the neighbored sentences with different weights. The neighbored sentences of a sentence include the preceding sentences and the subsequent sentences. Meanwhile, it is natural that a document can be treated as a sequence of sentences. Most existing works for Bayesian document modeling do not take these points into consideration. To fill this gap, we propose a bi-Directional Recurrent Attentional Topic Model (bi-RATM) for document embedding. The bi-RATM not only takes advantage of the sequential orders among sentences but also uses the attention mechanism to model the relations among successive sentences. To support to the bi-RATM, we propose a bi-Directional Recurrent Attentional Bayesian Process (bi-RABP) to handle the sequences. Based on the bi-RABP, bi-RATM fully utilizes the bi-directional sequential information of the sentences in a document. Online bi-RATM is proposed to handle large-scale corpus. Experiments on two corpora show that the proposed model outperforms state-of-the-art methods on document modeling and classification.},
  archive      = {J_TKDD},
  doi          = {10.1145/3412371},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {9},
  number       = {6},
  pages        = {1-30},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Bi-directional recurrent attentional topic model},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified framework for sparse online learning.
<em>TKDD</em>, <em>14</em>(5), 1–20. (<a
href="https://doi.org/10.1145/3361559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The amount of data in our society has been exploding in the era of big data. This article aims to address several open challenges in big data stream classification. Many existing studies in data mining literature follow the batch learning setting, which suffers from low efficiency and poor scalability. To tackle these challenges, we investigate a unified online learning framework for the big data stream classification task. Different from the existing online data stream classification techniques, we propose a unified Sparse Online Classification (SOC) framework. Based on SOC, we derive a second-order online learning algorithm and a cost-sensitive sparse online learning algorithm, which could successfully handle online anomaly detection tasks with the extremely unbalanced class distribution. As the performance evaluation, we analyze the theoretical bounds of the proposed algorithms and conduct an extensive set of experiments. The encouraging experimental results demonstrate the efficacy of the proposed algorithms over the state-of-the-art techniques on multiple data stream classification tasks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3361559},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A unified framework for sparse online learning},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On proximity and structural role-based embeddings in
networks: Misconceptions, techniques, and applications. <em>TKDD</em>,
<em>14</em>(5), 1–37. (<a
href="https://doi.org/10.1145/3397191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural roles define sets of structurally similar nodes that are more similar to nodes inside the set than outside, whereas communities define sets of nodes with more connections inside the set than outside. Roles based on structural similarity and communities based on proximity are fundamentally different but important complementary notions. Recently, the notion of structural roles has become increasingly important and has gained a lot of attention due to the proliferation of work on learning representations (node/edge embeddings) from graphs that preserve the notion of roles. Unfortunately, recent work has sometimes confused the notion of structural roles and communities (based on proximity) leading to misleading or incorrect claims about the capabilities of network embedding methods. As such, this article seeks to clarify the misconceptions and key differences between structural roles and communities, and formalize the general mechanisms (e.g., random walks and feature diffusion) that give rise to community- or role-based structural embeddings. We theoretically prove that embedding methods based on these mechanisms result in either community- or role-based structural embeddings. These mechanisms are typically easy to identify and can help researchers quickly determine whether a method preserves community- or role-based embeddings. Furthermore, they also serve as a basis for developing new and improved methods for community- or role-based structural embeddings. Finally, we analyze and discuss applications and data characteristics where community- or role-based embeddings are most appropriate.},
  archive      = {J_TKDD},
  doi          = {10.1145/3397191},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {On proximity and structural role-based embeddings in networks: Misconceptions, techniques, and applications},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). End-to-end continual rare-class recognition with emerging
novel subclasses. <em>TKDD</em>, <em>14</em>(5), 1–28. (<a
href="https://doi.org/10.1145/3399660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a labeled dataset that contains a rare (or minority) class containing of-interest instances, as well as a large class of instances that are not of interest, how can we learn to recognize future of-interest instances over a continuous stream? The setting is different from traditional classification in that instances from novel minority subclasses might continually emerge over time—and hence is often referred as continual, life-long, or open-world classification. We introduce RaRecognize, which ( i ) estimates a general decision boundary between the rare class and the majority class, ( ii ) learns to recognize the individual rare subclasses that exist within the training data, as well as ( iii ) flags instances from previously unseen rare subclasses as newly emerging (i.e., novel). The learner in (i) is general in the sense that by construction it is dissimilar to the specialized learners in (ii) , thus distinguishes minority from the majority without overly tuning to what is only seen in the training data. Thanks to this generality, RaRecognize ignores all future instances that it labels as majority and recognizes the recurring as well as emerging rare subclasses only. This saves effort at test time as well as ensures that the model size grows moderately over time as it only maintains specialized minority learners. Overall, we build an end-to-end system which consists of (1) a representation learning component that transforms data instances into suitable vector inputs; (2) a continual classifier that labels incoming instances as majority (not of interest), rare recurrent, or rare emerging; and (3) a clustering component that groups the rare emerging instances into novel subclasses for expert vetting and model re-training. Through extensive experiments, we show that RaRecognize outperforms state-of-the art baselines on three real-world datasets that contain documents related to corporate-risk and (natural and man-made) disasters as rare classes.},
  archive      = {J_TKDD},
  doi          = {10.1145/3399660},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {End-to-end continual rare-class recognition with emerging novel subclasses},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient mining of outlying sequence patterns for analyzing
outlierness of sequence data. <em>TKDD</em>, <em>14</em>(5), 1–26. (<a
href="https://doi.org/10.1145/3399671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a lot of research work has been proposed in different domains to detect outliers and analyze the outlierness of outliers for relational data. However, while sequence data is ubiquitous in real life, analyzing the outlierness for sequence data has not received enough attention. In this article, we study the problem of mining outlying sequence patterns in sequence data addressing the question: given a query sequence s in a sequence dataset D , the objective is to discover sequence patterns that will indicate the most unusualness (i.e., outlierness) of s compared against other sequences. Technically, we use the rank defined by the average probabilistic strength ( aps ) of a sequence pattern in a sequence to measure the outlierness of the sequence. Then a minimal sequence pattern where the query sequence is ranked the highest is defined as an outlying sequence pattern. To address the above problem, we present OSPMiner, a heuristic method that computes aps by incorporating several pruning techniques. Our empirical study using both real and synthetic data demonstrates that OSPMiner is effective and efficient.},
  archive      = {J_TKDD},
  doi          = {10.1145/3399671},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient mining of outlying sequence patterns for analyzing outlierness of sequence data},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general coreset-based approach to diversity maximization
under matroid constraints. <em>TKDD</em>, <em>14</em>(5), 1–27. (<a
href="https://doi.org/10.1145/3402448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diversity maximization is a fundamental problem in web search and data mining. For a given dataset S of n elements, the problem requires to determine a subset of S containing k ≪ n “representatives” which maximize some diversity function expressed in terms of pairwise distances, where distance models dissimilarity. An important variant of the problem prescribes that the solution satisfy an additional orthogonal requirement, which can be specified as a matroid constraint (i.e., a feasible solution must be an independent set of size k of a given matroid). While unconstrained diversity maximization admits efficient coreset-based strategies for several diversity functions, known approaches dealing with the additional matroid constraint apply only to one diversity function (sum of distances), and are based on an expensive, inherently sequential, local search over the entire input dataset. We devise the first coreset-based algorithms for diversity maximization under matroid constraints for various diversity functions, together with efficient sequential, MapReduce, and Streaming implementations. Technically, our algorithms rely on the construction of a small coreset, that is, a subset of S containing a feasible solution which is no more than a factor 1−ɛ away from the optimal solution for S . While our algorithms are fully general, for the partition and transversal matroids, if ɛ is a constant in (0,1) and S has bounded doubling dimension, the coreset size is independent of n and it is small enough to afford the execution of a slow sequential algorithm to extract a final, accurate, solution in reasonable time. Extensive experiments show that our algorithms are accurate, fast, and scalable, and therefore they are capable of dealing with the large input instances typical of the big data scenario.},
  archive      = {J_TKDD},
  doi          = {10.1145/3402448},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A general coreset-based approach to diversity maximization under matroid constraints},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introduction to the special issue on the best papers from
KDD 2018. <em>TKDD</em>, <em>14</em>(5), 1–2. (<a
href="https://doi.org/10.1145/3407901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TKDD},
  doi          = {10.1145/3407901},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {8},
  number       = {5},
  pages        = {1-2},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Introduction to the special issue on the best papers from KDD 2018},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards an optimal outdoor advertising placement: When a
budget constraint meets moving trajectories. <em>TKDD</em>,
<em>14</em>(5), 1–32. (<a
href="https://doi.org/10.1145/3350488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose and study the problem of trajectory-driven influential billboard placement: given a set of billboards U (each with a location and a cost), a database of trajectories T , and a budget L , we find a set of billboards within the budget to influence the largest number of trajectories. One core challenge is to identify and reduce the overlap of the influence from different billboards to the same trajectories, while keeping the budget constraint into consideration. We show that this problem is NP-hard and present an enumeration based algorithm with (1-1/e) approximation ratio. However, the enumeration would be very costly when | U | is large. By exploiting the locality property of billboards’ influence, we propose a partition-based framework PartSel. PartSel partitions U into a set of small clusters, computes the locally influential billboards for each cluster, and merges them to generate the global solution. Since the local solutions can be obtained much more efficiently than the global one, PartSel would reduce the computation cost greatly; meanwhile it achieves a non-trivial approximation ratio guarantee. Then we propose a LazyProbe method to further prune billboards with low marginal influence, while achieving the same approximation ratio as PartSel. Next, we propose a branch-and-bound method to eliminate unnecessary enumerations in both PartSel and LazyProbe, as well as an aggregated index to speed up the computation of marginal influence. Experiments on real datasets verify the efficiency and effectiveness of our methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3350488},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Towards an optimal outdoor advertising placement: When a budget constraint meets moving trajectories},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-user mobile sequential recommendation for route
optimization. <em>TKDD</em>, <em>14</em>(5), 1–28. (<a
href="https://doi.org/10.1145/3360048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We enhance the mobile sequential recommendation (MSR) model and address some critical issues in existing formulations by proposing three new forms of the MSR from a multi-user perspective. The multi-user MSR (MMSR) model searches optimal routes for multiple drivers at different locations while disallowing overlapping routes to be recommended. To enrich the properties of pick-up points in the problem formulation, we additionally consider the pick-up capacity as an important feature, leading to the following two modified forms of the MMSR: MMSR-m and MMSR-d. The MMSR-m sets a maximum pick-up capacity for all urban areas, while the MMSR-d allows the pick-up capacity to vary at different locations. We develop a parallel framework based on the simulated annealing to numerically solve the MMSR problem series. Also, a push-point method is introduced to improve our algorithms further for the MMSR-m and the MMSR-d, which can handle the route optimization in more practical ways. Our results on both real-world and synthetic data confirmed the superiority of our problem formulation and solutions under more demanding practical scenarios over several published benchmarks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3360048},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {5},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-user mobile sequential recommendation for route optimization},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning distance metrics from probabilistic information.
<em>TKDD</em>, <em>14</em>(5), 1–33. (<a
href="https://doi.org/10.1145/3364320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of metric learning is to learn a good distance metric that can capture the relationships among instances, and its importance has long been recognized in many fields. An implicit assumption in the traditional settings of metric learning is that the associated labels of the instances are deterministic. However, in many real-world applications, the associated labels come naturally with probabilities instead of deterministic values, which makes it difficult for the existing metric-learning methods to work well in these applications. To address this challenge, in this article, we study how to effectively learn the distance metric from datasets that contain probabilistic information, and then propose several novel metric-learning mechanisms for two types of probabilistic labels, i.e., the instance-wise probabilistic label and the group-wise probabilistic label. Compared with the existing metric-learning methods, our proposed mechanisms are capable of learning distance metrics directly from the probabilistic labels with high accuracy. We also theoretically analyze the proposed mechanisms and conduct extensive experiments on real-world datasets to verify the desirable properties of these mechanisms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3364320},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {5},
  pages        = {1-33},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning distance metrics from probabilistic information},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pop music generation: From melody to multi-style
arrangement. <em>TKDD</em>, <em>14</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3374915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music plays an important role in our daily life. With the development of deep learning and modern generation techniques, researchers have done plenty of works on automatic music generation. However, due to the special requirements of both melody and arrangement, most of these methods have limitations when applying to multi-track music generation. Some critical factors related to the quality of music are not well addressed, such as chord progression, rhythm pattern, and musical style. In order to tackle the problems and ensure the harmony of multi-track music, in this article, we propose an end-to-end melody and arrangement generation framework to generate a melody track with several accompany tracks played by some different instruments. To be specific, we first develop a novel Chord based Rhythm and Melody Cross-Generation Model to generate melody with a chord progression. Then, we propose a Multi-Instrument Co-Arrangement Model based on multi-task learning for multi-track music arrangement. Furthermore, to control the musical style of arrangement, we design a Multi-Style Multi-Instrument Co-Arrangement Model to learn the musical style with adversarial training. Therefore, we can not only maintain the harmony of the generated music but also control the musical style for better utilization. Extensive experiments on a real-world dataset demonstrate the superiority and effectiveness of our proposed models.},
  archive      = {J_TKDD},
  doi          = {10.1145/3374915},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Pop music generation: From melody to multi-style arrangement},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient approaches to k representative g-skyline queries.
<em>TKDD</em>, <em>14</em>(5), 1–27. (<a
href="https://doi.org/10.1145/3397503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The G-Skyline (GSky) query is a powerful tool to analyze optimal groups in decision support. Compared with other group skyline queries, it releases users from providing an aggregate function. Besides, it can get much comprehensive results without overlooking some important results containing non-skylines. However, it is hard for the users to make sensible choices when facing so many results the GSky query returns, especially over a large, high-dimensional dataset or with a large group size. In this article, we investigate k representative G-Skyline ( k GSky) queries to obtain a manageable size of optimal groups. The k GSky query can also inherit the advantage of the GSky query; its results are representative and diversified. Next, we propose three exact algorithms with novel techniques including an upper bound pruning, a grouping strategy, a layered optimum strategy, and a hybrid strategy to efficiently process the k GSky query. Consider these exact algorithms have high time complexity and the precise results are not necessary in many applications. We further develop two approximate algorithms to trade off some accuracy for efficiency. Extensive experiments on both real and synthetic datasets demonstrate the efficiency, scalability, and accuracy of the proposed algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3397503},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {7},
  number       = {5},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient approaches to k representative G-skyline queries},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-redundant subspace clusterings with nr-kmeans and
nr-DipMeans. <em>TKDD</em>, <em>14</em>(5), 1–24. (<a
href="https://doi.org/10.1145/3385652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A huge object collection in high-dimensional space can often be clustered in more than one way, for instance, objects could be clustered by their shape or alternatively by their color. Each grouping represents a different view of the dataset. The new research field of non-redundant clustering addresses this class of problems. In this article, we follow the approach that different, non-redundant k -means-like clusterings may exist in different, arbitrarily oriented subspaces of the high-dimensional space. We assume that these subspaces (and optionally a further noise space without any cluster structure) are orthogonal to each other. This assumption enables a particularly rigorous mathematical treatment of the non-redundant clustering problem and thus a particularly efficient algorithm, which we call N r -K means (for non-redundant k -means). The superiority of our algorithm is demonstrated both theoretically, as well as in extensive experiments. Further, we propose an extension of N r -K means that harnesses Hartigan’s dip test to identify the number of clusters for each subspace automatically.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385652},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Non-redundant subspace clusterings with nr-kmeans and nr-DipMeans},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MiSoSouP: Mining interesting subgroups with sampling and
pseudodimension. <em>TKDD</em>, <em>14</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3385653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MiSoSouP, a suite of algorithms for extracting high-quality approximations of the most interesting subgroups, according to different popular interestingness measures, from a random sample of a transactional dataset. We describe a new formulation of these measures as functions of averages, that makes it possible to approximate them using sampling. We then discuss how pseudodimension, a key concept from statistical learning theory, relates to the sample size needed to obtain an high-quality approximation of the most interesting subgroups. We prove an upper bound on the pseudodimension of the problem at hand, which depends on characteristic quantities of the dataset and of the language of patterns of interest. This upper bound then leads to small sample sizes. Our evaluation on real datasets shows that MiSoSouP outperforms state-of-the-art algorithms offering the same guarantees, and it vastly speeds up the discovery of subgroups w.r.t. analyzing the whole dataset.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385653},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MiSoSouP: Mining interesting subgroups with sampling and pseudodimension},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial attacks on graph neural networks: Perturbations
and their patterns. <em>TKDD</em>, <em>14</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3394520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, little is known about their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g., the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we present a study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model. We generate adversarial perturbations targeting the node’s features and the graph structure , thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain, we propose an efficient algorithm N ettack exploiting incremental computations. Our experimental study shows that accuracy of node classification significantly drops even when performing only few perturbations. Even more, our attacks are transferable: the learned attacks generalize to other state-of-the-art node classification models and unsupervised approaches, and likewise are successful even when only limited knowledge about the graph is given. For the first time, we successfully identify important patterns of adversarial attacks on graph neural networks (GNNs) — a first step towards being able to detect adversarial attacks on GNNs.},
  archive      = {J_TKDD},
  doi          = {10.1145/3394520},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adversarial attacks on graph neural networks: Perturbations and their patterns},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning bayesian networks with the saiyan algorithm.
<em>TKDD</em>, <em>14</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3385655">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some structure learning algorithms have proven to be effective in reconstructing hypothetical Bayesian Network graphs from synthetic data. However, in their mission to maximise a scoring function, many become conservative and minimise edges discovered. While simplicity is desired, the output is often a graph that consists of multiple independent subgraphs that do not enable full propagation of evidence. While this is not a problem in theory, it can be a problem in practice. This article examines a novel unconventional associational heuristic called Saiyan, which returns a directed acyclic graph that enables full propagation of evidence. Associational heuristics are not expected to perform well relative to sophisticated constraint-based and score-based learning approaches. Moreover, forcing the algorithm to connect all data variables implies that the forced edges will not be correct at the rate of those identified unrestrictedly. Still, synthetic and real-world experiments suggest that such a heuristic can be competitive relative to some of the well-established constraint-based, score-based and hybrid learning algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385655},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Learning bayesian networks with the saiyan algorithm},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internal evaluation of unsupervised outlier detection.
<em>TKDD</em>, <em>14</em>(4), 1–42. (<a
href="https://doi.org/10.1145/3394053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there is a large and growing literature that tackles the unsupervised outlier detection problem, the unsupervised evaluation of outlier detection results is still virtually untouched in the literature. The so-called internal evaluation, based solely on the data and the assessed solutions themselves, is required if one wants to statistically validate (in absolute terms) or just compare (in relative terms) the solutions provided by different algorithms or by different parameterizations of a given algorithm in the absence of labeled data. However, in contrast to unsupervised cluster analysis, where indexes for internal evaluation and validation of clustering solutions have been conceived and shown to be very useful, in the outlier detection domain, this problem has been notably overlooked. Here we discuss this problem and provide a solution for the internal evaluation of outlier detection results. Specifically, we describe an index called Internal, Relative Evaluation of Outlier Solutions (IREOS) that can evaluate and compare different candidate outlier detection solutions. Initially, the index is designed to evaluate binary solutions only, referred to as top - n outlier detection results. We then extend IREOS to the general case of non-binary solutions, consisting of outlier detection scorings. We also statistically adjust IREOS for chance and extensively evaluate it in several experiments involving different collections of synthetic and real datasets.},
  archive      = {J_TKDD},
  doi          = {10.1145/3394053},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-42},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Internal evaluation of unsupervised outlier detection},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-weighted multi-view fuzzy clustering. <em>TKDD</em>,
<em>14</em>(4), 1–17. (<a
href="https://doi.org/10.1145/3396238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the data in each view may contain distinct information different from other views as well as has common information for all views in multi-view learning, many multi-view clustering methods have been designed to use these information (including the distinct information for each view and the common information for all views) to improve the clustering performance. However, previous multi-view clustering methods cannot effectively detect these information so that difficultly outputting reliable clustering models. In this article, we propose a fuzzy, sparse, and robust multi-view clustering method to consider all kinds of relations among the data (such as view importance, view stability, and view diversity), which can effectively extract both distinct information and common information as well as balance these two kinds of information. Moreover, we devise an alternating optimization algorithm to solve the resulting objective function as well as prove that our proposed algorithm achieves fast convergence. It is noteworthy that existing multi-view clustering methods only consider a part of the relations, and thus are a special case of our proposed framework. Experimental results on synthetic datasets and real datasets show that our proposed method outperforms the state-of-the-art clustering methods in terms of evaluation metrics of clustering such as clustering accuracy, normalized mutual information, purity, and adjusted rand index.},
  archive      = {J_TKDD},
  doi          = {10.1145/3396238},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-17},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Self-weighted multi-view fuzzy clustering},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural serendipity recommendation: Exploring the balance
between accuracy and novelty with sparse explicit feedback.
<em>TKDD</em>, <em>14</em>(4), 1–25. (<a
href="https://doi.org/10.1145/3396607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have been playing an important role in providing personalized information to users. However, there is always a trade-off between accuracy and novelty in recommender systems. Usually, many users are suffering from redundant or inaccurate recommendation results. To this end, in this article, we put efforts into exploring the hidden knowledge of observed ratings to alleviate this recommendation dilemma. Specifically, we utilize some basic concepts to define a concept, Serendipity , which is characterized by high-satisfaction and low-initial-interest. Based on this concept, we propose a two-phase recommendation problem which aims to strike a balance between accuracy and novelty achieved by serendipity prediction and personalized recommendation. Along this line, a Neural Serendipity Recommendation (NSR) method is first developed by combining Muti-Layer Percetron and Matrix Factorization for serendipity prediction. Then, a weighted candidate filtering method is designed for personalized recommendation. Finally, extensive experiments on real-world data demonstrate that NSR can achieve a superior serendipity by a 12% improvement in average while maintaining stable accuracy compared with state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3396607},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Neural serendipity recommendation: Exploring the balance between accuracy and novelty with sparse explicit feedback},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discovering anomalies by incorporating feedback from an
expert. <em>TKDD</em>, <em>14</em>(4), 1–32. (<a
href="https://doi.org/10.1145/3396608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection algorithms search for outliers and then predict that these outliers are the anomalies. When deployed, however, these algorithms are often criticized for high false-positive and high false-negative rates. One main cause of poor performance is that not all outliers are anomalies and not all anomalies are outliers. In this article, we describe the Active Anomaly Discovery (AAD) algorithm, which incorporates feedback from an expert user that labels a queried data instance as an anomaly or nominal point. This feedback is intended to adjust the anomaly detector so that the outliers it discovers are more in tune with the expert user’s semantic understanding of the anomalies. The AAD algorithm is based on a weighted ensemble of anomaly detectors. When it receives a label from the user, it adjusts the weights on each individual ensemble member such that the anomalies rank higher in terms of their anomaly score than the outliers. The AAD approach is designed to operate in an interactive data exploration loop. In each iteration of this loop, our algorithm first selects a data instance to present to the expert as a potential anomaly and then the expert labels the instance as an anomaly or as a nominal data point. When it receives the instance label, the algorithm updates its internal model and the loop continues until a budget of B queries is spent. The goal of our approach is to maximize the total number of true anomalies in the B instances presented to the expert. We show that the AAD method performs well and in some cases doubles the number of true anomalies found compared to previous methods. In addition we present approximations that make the AAD algorithm much more computationally efficient while maintaining a desirable level of performance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3396608},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-32},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Discovering anomalies by incorporating feedback from an expert},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse graph connectivity for image segmentation.
<em>TKDD</em>, <em>14</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3397188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been demonstrated that the segmentation performance is highly dependent on both subspace preservation and graph connectivity. In the literature, the full connectivity method linearly represents each data point ( e.g., a pixel in one image) by all data points for achieving subspace preservation, while the sparse connectivity method was designed to linearly represent each data point by a set of data points for achieving graph connectivity. However, previous methods only focused on either subspace preservation or graph connectivity. In this article, we propose a Sparse Graph Connectivity (SGC) method for image segmentation to automatically learn the affinity matrix from the low-dimensional space of original data, which aims at simultaneously achieving subspace preservation and graph connectivity. To do this, the proposed SGC simultaneously learns a self-representation affinity matrix for subspace preservation and a sparse affinity matrix for graph connectivity, from the intrinsic low-dimensional feature space of high-dimensional original data. Meanwhile, the self-representation affinity matrix is pushed to be similar to the sparse affinity as well as be the final segmentation results. Experimental result on synthetic and real-image datasets showed that our SGC method achieved the best segmentation performance, compared to state-of-the-art segmentation methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3397188},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {6},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Sparse graph connectivity for image segmentation},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incomplete network alignment: Problem definitions and fast
solutions. <em>TKDD</em>, <em>14</em>(4), 1–26. (<a
href="https://doi.org/10.1145/3384203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are prevalent in many areas and are often collected from multiple sources. However, due to the veracity characteristics, more often than not, networks are incomplete. Network alignment and network completion have become two fundamental cornerstones behind a wealth of high-impact graph mining applications. The state-of-the-art have been addressing these two tasks in parallel . That is, most of the existing network alignment methods have implicitly assumed that the topology of the input networks for alignment are perfectly known a priori, whereas the existing network completion methods admit either a single network (i.e., matrix completion) or multiple aligned networks (e.g., tensor completion). In this article, we argue that network alignment and completion are inherently complementary with each other, and hence propose to jointly address them so that the two tasks can mutually benefit from each other. We formulate the problem from the optimization perspective, and propose an effective algorithm ( iNeAt ) to solve it. The proposed method offers two distinctive advantages. First ( Alignment accuracy ), our method benefits from the higher-quality input networks while mitigates the effect of the incorrectly inferred links introduced by the completion task itself. Second ( Alignment efficiency ), thanks to the low-rank structure of the complete networks and the alignment matrix, the alignment process can be significantly accelerated. We perform extensive experiments which show that (1) the network completion can significantly improve the alignment accuracy, i.e., up to 30% over the baseline methods; (2) the network alignment can in turn help recover more missing edges than the baseline methods; and (3) our method achieves a good balance between the running time and the accuracy, and scales with a provable linear complexity in both time and space.},
  archive      = {J_TKDD},
  doi          = {10.1145/3384203},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Incomplete network alignment: Problem definitions and fast solutions},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Citywide traffic flow prediction based on multiple gated
spatio-temporal convolutional neural networks. <em>TKDD</em>,
<em>14</em>(4), 1–23. (<a
href="https://doi.org/10.1145/3385414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is crucial for public safety and traffic management, and remains a big challenge because of many complicated factors, e.g., multiple spatio-temporal dependencies, holidays, and weather. Some work leveraged 2D convolutional neural networks (CNNs) and long short-term memory networks (LSTMs) to explore spatial relations and temporal relations, respectively, which outperformed the classical approaches. However, it is hard for these work to model spatio-temporal relations jointly. To tackle this, some studies utilized LSTMs to connect high-level layers of CNNs, but left the spatio-temporal correlations not fully exploited in low-level layers. In this work, we propose novel spatio-temporal CNNs to extract spatio-temporal features simultaneously from low-level to high-level layers, and propose a novel gated scheme to control the spatio-temporal features that should be propagated through the hierarchy of layers. Based on these, we propose an end-to-end framework, multiple gated spatio-temporal CNNs (MGSTC), for citywide traffic flow prediction. MGSTC can explore multiple spatio-temporal dependencies through multiple gated spatio-temporal CNN branches, and combine the spatio-temporal features with external factors dynamically. Extensive experiments on two real traffic datasets demonstrates that MGSTC outperforms other state-of-the-art baselines.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385414},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Citywide traffic flow prediction based on multiple gated spatio-temporal convolutional neural networks},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully dynamic approximate k-core decomposition in
hypergraphs. <em>TKDD</em>, <em>14</em>(4), 1–21. (<a
href="https://doi.org/10.1145/3385416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we design algorithms to maintain approximate core values in dynamic hypergraphs. This notion has been well studied for normal graphs in both static and dynamic setting. We generalize the problem to hypergraphs when edges can be inserted or deleted by an adversary. We consider two dynamic scenarios. In the first case, there are only insertions; and in the second case, there can be both insertions and deletions. In either case, the update time is poly-logarithmic in the number of nodes, with the insertion-only case boasting a better approximation ratio. We also perform extensive experiments on large real-world datasets, which demonstrate the accuracy and efficiency of our algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385416},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fully dynamic approximate k-core decomposition in hypergraphs},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The gene of scientific success. <em>TKDD</em>,
<em>14</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3385530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article elaborates how to identify and evaluate causal factors to improve scientific impact. Currently, analyzing scientific impact can be beneficial to various academic activities including funding application, mentor recommendation, discovering potential cooperators, and the like. It is universally acknowledged that high-impact scholars often have more opportunities to receive awards as an encouragement for their hard work. Therefore, scholars spend great efforts in making scientific achievements and improving scientific impact during their academic life. However, what are the determinate factors that control scholars’ academic success? The answer to this question can help scholars conduct their research more efficiently. Under this consideration, our article presents and analyzes the causal factors that are crucial for scholars’ academic success. We first propose five major factors including article-centered factors, author-centered factors, venue-centered factors, institution-centered factors, and temporal factors. Then, we apply recent advanced machine learning algorithms and jackknife method to assess the importance of each causal factor. Our empirical results show that author-centered and article-centered factors have the highest relevancy to scholars’ future success in the computer science area. Additionally, we discover an interesting phenomenon that the h -index of scholars within the same institution or university are actually very close to each other.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385530},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {The gene of scientific success},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient nonnegative tensor factorization via saturating
coordinate descent. <em>TKDD</em>, <em>14</em>(4), 1–28. (<a
href="https://doi.org/10.1145/3385654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancements in computing technology and web-based applications, data are increasingly generated in multi-dimensional form. These data are usually sparse due to the presence of a large number of users and fewer user interactions. To deal with this, the Nonnegative Tensor Factorization (NTF) based methods have been widely used. However existing factorization algorithms are not suitable to process in all three conditions of size, density, and rank of the tensor. Consequently, their applicability becomes limited. In this article, we propose a novel fast and efficient NTF algorithm using the element selection approach. We calculate the element importance using Lipschitz continuity and propose a saturation point-based element selection method that chooses a set of elements column-wise for updating to solve the optimization problem. Empirical analysis reveals that the proposed algorithm is scalable in terms of tensor size, density, and rank in comparison to the relevant state-of-the-art algorithms.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385654},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient nonnegative tensor factorization via saturating coordinate descent},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social collaborative mutual learning for item
recommendation. <em>TKDD</em>, <em>14</em>(4), 1–19. (<a
href="https://doi.org/10.1145/3387162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RSs) provide users with item choices based on their preferences reflected in past interactions and become important tools to alleviate the information overload problem for users. However, in real-world scenarios, the user–item interaction matrix is generally sparse, leading to the poor performance of recommendation methods. To cope with this problem, social information is introduced into these methods in several ways, such as regularization, ensemble, and sampling. However, these strategies to use social information have their limitations. The regularization and ensemble strategies may suffer from the over-smoothing problem, while the sampling-based strategy may be affected by the overfitting problem. To overcome the limitations of the previous efforts, a novel social recommendation model, namely, Social Collaborative Mutual Learning (SCML), is proposed in this article. SCML combines the item-based CF model with the social CF model by two well-designed mutual regularization strategies. The embedding-level mutual regularization forces the user representations in two models to be close, and the output-level mutual regularization matches the distributions of the predictions in two models. Extensive experiments on three public datasets show that SCML significantly outperforms the baseline methods and the proposed mutual regularization strategies can embrace the advantages of the item-based CF model and the social CF model to improve the recommendation performance.},
  archive      = {J_TKDD},
  doi          = {10.1145/3387162},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Social collaborative mutual learning for item recommendation},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge2vec: Edge-based social network embedding.
<em>TKDD</em>, <em>14</em>(4), 1–24. (<a
href="https://doi.org/10.1145/3391298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding, also known as network embedding and network representation learning, is a useful technique which helps researchers analyze information networks through embedding a network into a low-dimensional space. However, existing graph embedding methods are all node-based, which means they can just directly map the nodes of a network to low-dimensional vectors while the edges could only be mapped to vectors indirectly. One important reason is the computational cost, because the number of edges is always far greater than the number of nodes. In this article, considering an important property of social networks, i.e., the network is sparse, and hence the average degree of nodes is bounded, we propose an edge-based graph embedding ( edge2vec ) method to map the edges in social networks directly to low-dimensional vectors. Edge2vec takes both the local and the global structure information of edges into consideration to preserve structure information of embedded edges as much as possible. To achieve this goal, edge2vec first ingeniously combines the deep autoencoder and Skip-gram model through a well-designed deep neural network. The experimental results on different datasets show edge2vec benefits from the direct mapping in preserving the structure information of edges.},
  archive      = {J_TKDD},
  doi          = {10.1145/3391298},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {4},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Edge2vec: Edge-based social network embedding},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data sharing via differentially private coupled matrix
factorization. <em>TKDD</em>, <em>14</em>(3), 1–27. (<a
href="https://doi.org/10.1145/3372408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the privacy-preserving data-sharing problem in a distributed multiparty setting. In this setting, each data site owns a distinct part of a dataset and the aim is to estimate the parameters of a statistical model conditioned on the complete data without any site revealing any information about the individuals in their own parts. The sites want to maximize the utility of the collective data analysis while providing privacy guarantees for their own portion of the data as well as for each participating individual . Our first contribution is to classify these different privacy requirements as (i) site-level and (ii) user-level differential privacy and present formal privacy guarantees for these two cases under the model of differential privacy. To satisfy a stronger form of differential privacy, we use a variant of differential privacy which is local differential privacy where the sensitive data is perturbed with a randomized response mechanism prior to the estimation. In this study, we assume that the data instances that are partitioned between several parties are arranged as matrices. A natural statistical model for this distributed scenario is coupled matrix factorization. We present two generic frameworks for privatizing Bayesian inference for coupled matrix factorization models that are able to guarantee proposed differential privacy notions based on the privacy requirements of the model. To privatize Bayesian inference, we first exploit the connection between differential privacy and sampling from a Bayesian posterior via stochastic gradient Langevin dynamics and then derive an efficient coupled matrix factorization method. In the local privacy context, we propose two models that have an additional privatization mechanism to achieve a stronger measure of privacy and introduce a Gibbs sampling based algorithm. We demonstrate that the proposed methods are able to provide good prediction accuracy on synthetic and real datasets while adhering to the introduced privacy constraints.},
  archive      = {J_TKDD},
  doi          = {10.1145/3372408},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Data sharing via differentially private coupled matrix factorization},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Story forest: Extracting events and telling stories from
breaking news. <em>TKDD</em>, <em>14</em>(3), 1–28. (<a
href="https://doi.org/10.1145/3377939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting events accurately from vast news corpora and organize events logically is critical for news apps and search engines, which aim to organize news information collected from the Internet and present it to users in the most sensible forms. Intuitively speaking, an event is a group of news documents that report the same news incident possibly in different ways. In this article, we describe our experience of implementing a news content organization system at Tencent to discover events from vast streams of breaking news and to evolve news story structures in an online fashion. Our real-world system faces unique challenges in contrast to previous studies on topic detection and tracking (TDT) and event timeline or graph generation, in that we (1) need to accurately and quickly extract distinguishable events from massive streams of long text documents, and (2) must develop the structures of event stories in an online manner, in order to guarantee a consistent user viewing experience. In solving these challenges, we propose Story Forest , a set of online schemes that automatically clusters streaming documents into events, while connecting related events in growing trees to tell evolving stories. A core novelty of our Story Forest system is EventX , a semi-supervised scheme to extract events from massive Internet news corpora. EventX relies on a two-layered, graph-based clustering procedure to group documents into fine-grained events. We conducted extensive evaluations based on (1) 60 GB of real-world Chinese news data, (2) a large Chinese Internet news dataset that contains 11,748 news articles with truth event labels, and (3) the 20 News Groups English dataset, through detailed pilot user experience studies. The results demonstrate the superior capabilities of Story Forest to accurately identify events and organize news text into a logical structure that is appealing to human readers.},
  archive      = {J_TKDD},
  doi          = {10.1145/3377939},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Story forest: Extracting events and telling stories from breaking news},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining career paths from large resume databases: Evidence
from IT professionals. <em>TKDD</em>, <em>14</em>(3), 1–38. (<a
href="https://doi.org/10.1145/3379984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of online professional platforms, such as LinkedIn and Indeed, has led to unprecedented volumes of rich resume data that have revolutionized the study of careers. One of the most prevalent problems in this space is the extraction of prototype career paths from a workforce. Previous research has consistently relied on a two-step approach to tackle this problem. The first step computes the pairwise distances between all the career sequences in the database. The second step uses the distance matrix to create clusters, with each cluster representing a different prototype path. As we demonstrate in this work, this approach faces two significant challenges when applied on large resume databases. First, the overwhelming diversity of job titles in the modern workforce prevents the accurate evaluation of distance between career sequences. Second, the clustering step of the standard approach leads to highly heterogeneous clusters, due to its inability to handle categorical sequences and sensitivity to outliers. This leads to non-representative centroids and spurious prototype paths that do not accurately represent the actual groups in the workforce. Our work addresses these two challenges and has practical implications for the numerous researchers and practitioners working on the analysis of career data across domains.},
  archive      = {J_TKDD},
  doi          = {10.1145/3379984},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Mining career paths from large resume databases: Evidence from IT professionals},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep multi-task contextual attention framework for
multi-modal affect analysis. <em>TKDD</em>, <em>14</em>(3), 1–27. (<a
href="https://doi.org/10.1145/3380744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal affect analysis (e.g., sentiment and emotion analysis) is an interdisciplinary study and has been an emerging and prominent field in Natural Language Processing and Computer Vision. The effective fusion of multiple modalities (e.g., text , acoustic, or visual frames ) is a non-trivial task, as these modalities, often, carry distinct and diverse information, and do not contribute equally. The issue further escalates when these data contain noise. In this article, we study the concept of multi-task learning for multi-modal affect analysis and explore a contextual inter-modal attention framework that aims to leverage the association among the neighboring utterances and their multi-modal information. In general, sentiments and emotions have inter-dependence on each other (e.g., anger → negative or happy → positive ). In our current work, we exploit the relatedness among the participating tasks in the multi-task framework. We define three different multi-task setups, each having two tasks, i.e., sentiment 8 emotion classification, sentiment classification 8 sentiment intensity prediction, and emotion classificati on 8 emotion intensity prediction. Our evaluation of the proposed system on the CMU-Multi-modal Opinion Sentiment and Emotion Intensity benchmark dataset suggests that, in comparison with the single-task learning framework, our multi-task framework yields better performance for the inter-related participating tasks. Further, comparative studies show that our proposed approach attains state-of-the-art performance for most of the cases.},
  archive      = {J_TKDD},
  doi          = {10.1145/3380744},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A deep multi-task contextual attention framework for multi-modal affect analysis},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network embedding for community detection in attributed
networks. <em>TKDD</em>, <em>14</em>(3), 1–25. (<a
href="https://doi.org/10.1145/3385415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection aims to partition network nodes into a set of clusters, such that nodes are more densely connected to each other within the same cluster than other clusters. For attributed networks, apart from the denseness requirement of topology structure, the attributes of nodes in the same community should also be homogeneous. Network embedding has been proved extremely useful in a variety of tasks, such as node classification, link prediction, and graph visualization, but few works dedicated to unsupervised embedding of node features specified for clustering task, which is vital for community detection and graph clustering. By post-processing with clustering algorithms like k -means, most existing network embedding methods can be applied to clustering tasks. However, the learned embeddings are not designed for clustering task, they only learn topological and attributed information of networks, and no clustering-oriented information is explored. In this article, we propose an algorithm named Network Embedding for node Clustering (NEC) to learn network embedding for node clustering in attributed graphs. Specifically, the presented work introduces a framework that simultaneously learns graph structure-based representations and clustering-oriented representations together. The framework consists of the following three modules: graph convolutional autoencoder module, soft modularity maximization module, and self-clustering module. Graph convolutional autoencoder module learns node embeddings based on topological structure and node attributes. We introduce soft modularity, which can be easily optimized using gradient descent algorithms, to exploit the community structure of networks. By integrating clustering loss and embedding loss, NEC can jointly optimize node cluster labels assignment and learn representations that keep local structure of network. This model can be effectively optimized using stochastic gradient algorithm. Empirical experiments on real-world networks and synthetic networks validate the feasibility and effectiveness of our algorithm on community detection task compared with network embedding based methods and traditional community detection methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385415},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Network embedding for community detection in attributed networks},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Better classifier calibration for small datasets.
<em>TKDD</em>, <em>14</em>(3), 1–19. (<a
href="https://doi.org/10.1145/3385656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier calibration does not always go hand in hand with the classifier’s ability to separate the classes. There are applications where good classifier calibration, i.e., the ability to produce accurate probability estimates, is more important than class separation. When the amount of data for training is limited, the traditional approach to improve calibration starts to crumble. In this article, we show how generating more data for calibration is able to improve calibration algorithm performance in many cases where a classifier is not naturally producing well-calibrated outputs and the traditional approach fails. The proposed approach adds computational cost but considering that the main use case is with small datasets this extra computational cost stays insignificant and is comparable to other methods in prediction time. From the tested classifiers, the largest improvement was detected with the random forest and naive Bayes classifiers. Therefore, the proposed approach can be recommended at least for those classifiers when the amount of data available for training is limited and good calibration is essential.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385656},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Better classifier calibration for small datasets},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Framework for inferring following strategies from time
series of movement data. <em>TKDD</em>, <em>14</em>(3), 1–22. (<a
href="https://doi.org/10.1145/3385730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How do groups of individuals achieve consensus in movement decisions? Do individuals follow their friends, the one predetermined leader, or whomever just happens to be nearby? To address these questions computationally, we formalize C oordination S trategy I nference P roblem . In this setting, a group of multiple individuals moves in a coordinated manner toward a target path. Each individual uses a specific strategy to follow others (e.g., nearest neighbors, pre-defined leaders, and preferred friends). Given a set of time series that includes coordinated movement and a set of candidate strategies as inputs, we provide the first methodology (to the best of our knowledge) to infer whether each individual uses local-agreement system or dictatorship-like strategy to achieve movement coordination at the group level. We evaluate and demonstrate the performance of the proposed framework by predicting directions of movement of an individual in a group in both simulated datasets as well as in two real-world datasets: a school of fish and a troop of baboons. Moreover, since there is no prior methodology for inferring individual-level strategies, we compare our framework with the state-of-the-art approach for the task of classification of group-level-coordination models. Results show that our approach is highly accurate in inferring correct strategies in simulated datasets even in complicated mixed strategy settings, which no existing method can infer. In the task of classification of group-level-coordination models, our framework performs better than the state-of-the-art approach in all datasets. Animal data experiments show that fish, as expected, follow their neighbors, while baboons have a preference to follow specific individuals. Our methodology generalizes to arbitrary time series data of real numbers, beyond movement data.},
  archive      = {J_TKDD},
  doi          = {10.1145/3385730},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Framework for inferring following strategies from time series of movement data},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced data mining technique to measure satisfaction
degree of social media users of xeljanz drug. <em>TKDD</em>,
<em>14</em>(3), 1–13. (<a
href="https://doi.org/10.1145/3389433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent times, social media has become important in the field of health care as a major resource of valuable health information. Social media can provide massive amounts of data in real-time through user interaction, and this data can be analysed to reflect the harms and benefits of treatment by using the personal health experiences of users to improve health outcomes. In this study, we propose an enhanced data mining framework for analysing user opinions on Twitter and on a health-care forum. The proposed framework measures the degree of satisfaction of consumers regarding the drug Xeljanz, which is used to treat rheumatoid arthritis. The proposed framework is based on seven steps distributed in two phases. The first phase involves aggregating data related to the drug Xeljanz. This data is pre-processed to produce a list of words with a term frequency-inverse document frequency score. The word list is then classified into the following three categories: positive, negative and neutral. The second phase involves modelling social media posts using network analysis, identifying sub-graphs, calculating average opinions and detecting influential users. The results showed 77.3% user satisfaction with Xeljanz. Positive opinions were especially pronounced among users who switched to Xeljanz based on advice from a physician. Negative opinions of Xeljanz typically pertained to the high cost of the drug.},
  archive      = {J_TKDD},
  doi          = {10.1145/3389433},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {5},
  number       = {3},
  pages        = {1-13},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Enhanced data mining technique to measure satisfaction degree of social media users of xeljanz drug},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient ridesharing framework for ride-matching via
heterogeneous network embedding. <em>TKDD</em>, <em>14</em>(3), 1–24.
(<a href="https://doi.org/10.1145/3373839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ridesharing has attracted increasing attention in recent years, and combines the flexibility and speed of private cars with the reduced cost of fixed-line systems to benefit alleviating traffic pressure. A major issue in ridesharing is the accurate assignment of passengers to drivers, and how to maximize the number of rides shared between people being assigned to different drivers has become an increasingly popular research topic. There are two major challenges facing ride-matching: scalability and sparsity. Here, we show that network embedding drives the optimal matches between drivers and riders. Contrary to existing approaches that merely depend on the proximity between passengers and drivers, we employ a heterogeneous network to learn the latent semantics from different choices in two types of ridesharing, and extract features in terms of user trajectories and sentiment. A novel framework for ridesharing, RShareForm, which encodes not only the objects but also a variety of semantic relationships between them, is proposed. This article extends the existing skip-gram model to incorporate meta-paths over a proposed heterogeneous network. It allows diverse features to be used to search for similar participants and then ranks them to improve the quality of ride-matching. Extensive experiments on a large-scale dataset from DiDi in Chengdu, China show that by leveraging heterogeneous network embedding with meta paths, RShareForm can significantly improve the accuracy of identifying the participants for ridesharing over existing methods, including both meta-path guided similarity search methods and variants of embedding methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3373839},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-24},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Efficient ridesharing framework for ride-matching via heterogeneous network embedding},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MP2SDA: Multi-party parallelized sparse discriminant
learning. <em>TKDD</em>, <em>14</em>(3), 1–22. (<a
href="https://doi.org/10.1145/3374919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Discriminant Analysis (SDA) has been widely used to improve the performance of classical Fisher’s Linear Discriminant Analysis in supervised metric learning, feature selection, and classification. With the increasing needs of distributed data collection, storage, and processing, enabling the Sparse Discriminant Learning to embrace the multi-party distributed computing environments becomes an emerging research topic. This article proposes a novel multi-party SDA algorithm, which can learn SDA models effectively without sharing any raw data and basic statistics among machines. The proposed algorithm (1) leverages the direct estimation of SDA to derive a distributed loss function for the discriminant learning, (2) parameterizes the distributed loss function with local/global estimates through bootstrapping, and (3) approximates a global estimation of linear discriminant projection vector by optimizing the “distributed bootstrapping loss function” with gossip-based stochastic gradient descent. Experimental results on both synthetic and real-world benchmark datasets show that our algorithm can compete with the aggregated SDA with similar performance, and significantly outperforms the most recent distributed SDA in terms of accuracy and F1-score.},
  archive      = {J_TKDD},
  doi          = {10.1145/3374919},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-22},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {MP2SDA: Multi-party parallelized sparse discriminant learning},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust drift characterization from event streams of business
processes. <em>TKDD</em>, <em>14</em>(3), 1–57. (<a
href="https://doi.org/10.1145/3375398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process workers may vary the normal execution of a business process to adjust to changes in their operational environment, e.g., changes in workload, season, or regulations. Changes may be simple, such as skipping an individual activity, or complex, such as replacing an entire procedure with another. Over time, these changes may negatively affect process performance; hence, it is important to identify and understand them early on. As such, a number of techniques have been developed to detect process drifts , i.e., statistically significant changes in process behavior, from process event logs (offline) or event streams (online). However, detecting a drift without characterizing it, i.e., without providing explanations on its nature, is not enough to help analysts understand and rectify root causes for process performance issues. Existing approaches for drift characterization are limited to simple changes that affect individual activities. This article contributes an efficient, accurate, and noise-tolerant automated method for characterizing complex drifts affecting entire process fragments. The method, which works both offline and online, relies on two cornerstone techniques, one to automatically discover process trees from event streams (logs) and the other to transform process trees using a minimum number of change operations. The operations identified are then translated into natural language statements to explain the change behind a drift. The method has been extensively evaluated on artificial and real-life datasets, and against a state-of-the-art baseline method. The results from one of the real-life datasets have also been validated with a process stakeholder.},
  archive      = {J_TKDD},
  doi          = {10.1145/3375398},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-57},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Robust drift characterization from event streams of business processes},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linearization of dependency and sampling for
participation-based betweenness centrality in very large b-hypergraphs.
<em>TKDD</em>, <em>14</em>(3), 1–41. (<a
href="https://doi.org/10.1145/3375399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A B-hypergraph consisting of nodes and directed hyperedges is a generalization of the directed graph. A directed hyperedge in the B-hypergraph represents a relation from a set of source nodes to a single destination node. We suggest one possible definition of betweenness centrality (BC) in B-hypergraphs, called Participation-based BC (PBC). A PBC score of a node is computed based on the number of the shortest paths in which the node participates. This score can be expressed in terms of dependency on the set of its outgoing hyperedges. In this article, we focus on developing efficient computation algorithms for PBC. We first present an algorithm called ePBC for computing exact PBC scores of nodes, which has a cubic-time complexity. This algorithm, however, can be used for only small-sized B-hypergraphs because of its cubic-time complexity, so we propose linearized PBC ( ℓ PBC) that is an approximation method of ePBC. ℓ PBC that comes with a guaranteed upper bound on its error, uses a linearization of dependency on a set of hyperedges. ℓ PBC improves the computing time of ePBC by an order of magnitude (i.e., it requires a quadratic time) while maintaining a high accuracy. ℓ PBC works well on small to medium-sized B-hypergraphs, but is not scalable enough for a very large B-hypergraph with more than a million hyperedges. To cope with such a very large B-hypergraph, we propose a very fast heuristic sampling-based method called sampling-based ℓ PBC (s ℓ PBC). We show through extensive experiments that ℓ PBC and s ℓ PBC can efficiently estimate PBC scores in various real-world B-hypergraphs with a reasonably good precision@ k . The experimental results show that s ℓ PBC works efficiently even for a very large B-hypergraph.},
  archive      = {J_TKDD},
  doi          = {10.1145/3375399},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-41},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Linearization of dependency and sampling for participation-based betweenness centrality in very large B-hypergraphs},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Continuous influence maximization. <em>TKDD</em>,
<em>14</em>(3), 1–38. (<a
href="https://doi.org/10.1145/3380928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imagine we are introducing a new product through a social network, where we know for each user in the network the function of purchase probability with respect to discount. Then, what discounts should we offer to those social network users so that, under a predefined budget, the adoption of the product is maximized in expectation? Although influence maximization has been extensively explored, this appealing practical problem still cannot be answered by the existing influence maximization methods. In this article, we tackle the problem systematically. We formulate the general continuous influence maximization problem, investigate the essential properties, and develop a general coordinate descent algorithmic framework as well as the engineering techniques for practical implementation. Our investigation does not assume any specific influence model and thus is general and principled. At the same time, using the most popularly adopted triggering model as a concrete example, we demonstrate that more efficient methods are feasible under specific influence models. Our extensive empirical study on four benchmark real-world networks with synthesized purchase probability curves clearly illustrates that continuous influence maximization can improve influence spread significantly with very moderate extra running time comparing to the classical influence maximization methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3380928},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {3},
  pages        = {1-38},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Continuous influence maximization},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic topic modeling for comparative analysis of
document collections. <em>TKDD</em>, <em>14</em>(2), 1–27. (<a
href="https://doi.org/10.1145/3369873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic topic models, which can discover hidden patterns in documents, have been extensively studied. However, rather than learning from a single document collection, numerous real-world applications demand a comprehensive understanding of the relationships among various document sets. To address such needs, this article proposes a new model that can identify the common and discriminative aspects of multiple datasets. Specifically, our proposed method is a Bayesian approach that represents each document as a combination of common topics (shared across all document sets) and distinctive topics (distributions over words that are exclusive to a particular dataset). Through extensive experiments, we demonstrate the effectiveness of our method compared with state-of-the-art models. The proposed model can be useful for “comparative thinking” analysis in real-world document collections.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369873},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {3},
  number       = {2},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Probabilistic topic modeling for comparative analysis of document collections},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalizing long short-term memory network for deep
learning from generic data. <em>TKDD</em>, <em>14</em>(2), 1–28. (<a
href="https://doi.org/10.1145/3366022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long Short-Term Memory (LSTM) network, a popular deep-learning model, is particularly useful for data with temporal correlation, such as texts, sequences, or time series data, thanks to its well-sought after recurrent network structures designed to capture temporal correlation. In this article, we propose to generalize LSTM to generic machine-learning tasks where data used for training do not have explicit temporal or sequential correlation. Our theme is to explore feature correlation in the original data and convert each instance into a synthetic sentence format by using a two-gram probabilistic language model. More specifically, for each instance represented in the original feature space, our conversion first seeks to horizontally align original features into a sequentially correlated feature vector, resembling to the letter coherence within a word. In addition, a vertical alignment is also carried out to create multiple time points and simulate word sequential order in a sentence ( i.e., word correlation). The two dimensional horizontal-and-vertical alignments not only ensure feature correlations are maximally utilized, but also preserve the original feature values in the new representation. As a result, LSTM model can be utilized to achieve good classification accuracy, even if the underlying data do not have temporal or sequential dependency. Experiments on 20 generic datasets show that applying LSTM to generic data can improve the classification accuracy, compared to conventional machine-learning methods. This research opens a new opportunity for LSTM deep learning to be broadly applied to generic machine-learning tasks.},
  archive      = {J_TKDD},
  doi          = {10.1145/3366022},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Generalizing long short-term memory network for deep learning from generic data},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bradykinesia recognition in parkinson’s disease via single
RGB video. <em>TKDD</em>, <em>14</em>(2), 1–19. (<a
href="https://doi.org/10.1145/3369438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a progressive nervous system disorder afflicting millions of patients. Among its motor symptoms, bradykinesia is one of the cardinal manifestations. Experienced doctors are required for the clinical diagnosis of bradykinesia, but sometimes they also miss subtle changes, especially in early stages of such disease. Therefore, developing auxiliary diagnostic methods that can automatically detect bradykinesia has received more and more attention. In this article, we employ a two-stage framework for bradykinesia recognition based on the video of patient movement. First, convolution neural networks are trained to localize keypoints in each video frame. These time-varying coordinates form motion trajectories that represent the whole movement. From the trajectory, we then propose novel measurements, namely stability , completeness , and self-similarity , to quantify different motor behaviors. We also propose a periodic motion model called PMNet . An encoder--decoder structure is applied to learn a low dimensional representation of a motion process. The compressed motion process and quantified motor behaviors are combined as inputs to a fully-connected neural network. Different from the traditional means, our solution extends the application scenario outside the hospital and can be easily transplanted to conduct similar tasks. A commonly used clinical assessment is served as a case study. Experimental results based on real-world data validate the effectiveness of our approach for bradykinesia recognition.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369438},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Bradykinesia recognition in parkinson’s disease via single RGB video},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time transportation prediction correction using
reconstruction error in deep learning. <em>TKDD</em>, <em>14</em>(2),
1–20. (<a href="https://doi.org/10.1145/3369871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online complex systems such as transportation system, an important work is real-time traffic prediction. Due to the data shift, data model inconsistency, and sudden change of traffic patterns (like transportation accident), the prediction result derived from an offline-built model would be unreliable. Retraining the model is usually not time affordable for online prediction, especially when the prediction model is very complex and costs a lot of training time (for example, deep neural networks). A real-time prediction correction strategy would be of great value under this situation. Traditionally, the prediction correction usually relies on the prediction error in several previous time intervals. They assume that the error pattern is similar in the current time interval, so that it is time-delayed to some extent. In this article, we propose the prediction correction strategy using the reconstruction error in the deep neural network. The reconstruction error can reflect the model’s ability on feature representation and then determine the fitness of an input data to the model. We first build the relationship between reconstruction error and prediction error. From the perspective of the prediction interval, we demonstrate that the reconstruction error is in positive relation with the prediction interval. Thus the prediction result is more reliable when the reconstruction error is smaller. Then we propose two mechanisms of real-time prediction correction using the reconstruction error. The data driven prediction correction approach selects several training instances with similar reconstruction errors to the current instance and using their average prediction error in correcting the prediction result. The model-driven approach builds several component deep neural networks in training. The component training set for each network is selected according to the reconstruction error of training instances. For a predicting instance, it first computes the reconstruction error of the sample in each component network and then averages the results by the reconstruction error and prediction interval. The model-driven approach is actually a reconstruction error-based deep neural network ensemble approach. Finally, a series of experiments demonstrated that reconstruction error based prediction correction approaches are effective in several prediction problems in transportation including traffic flow prediction on road, traffic flow prediction in entrance and exit station and travel time prediction. Besides the high overall accuracy, our approach can also provide many observations of using the reconstruction error in transportation prediction.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369871},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Real-time transportation prediction correction using reconstruction error in deep learning},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CenEEGs: Valid EEG selection for classification.
<em>TKDD</em>, <em>14</em>(2), 1–25. (<a
href="https://doi.org/10.1145/3371153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores valid brain electroencephalography (EEG) selection for EEG classification with different classifiers, which has been rarely addressed in previous studies and is mostly ignored by existing EEG processing methods and applications. Importantly, traditional selection methods are not able to select valid EEG signals for different classifiers. This article focuses on a source control-based valid EEG selection to reduce the impact of invalid EEG signals and aims to improve EEG-based classification performance for different classifiers. We propose a novel centroid-based EEG selection approach named CenEEGs, which uses a scale-and-shift-invariance similarity metric to measure similarities of EEG signals and then applies a globally optimal centroid strategy to select valid EEG signals with respect to a similarity threshold. A detailed comparison with several state-of-the-art time series selection methods by using standard criteria on 8 EEG datasets demonstrates the efficacy and superiority of CenEEGs for different classifiers.},
  archive      = {J_TKDD},
  doi          = {10.1145/3371153},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-25},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CenEEGs: Valid EEG selection for classification},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AR2Net: An attentive neural approach for business location
selection with satellite data and urban data. <em>TKDD</em>,
<em>14</em>(2), 1–28. (<a
href="https://doi.org/10.1145/3372406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business location selection is crucial to the success of businesses. Traditional approaches like manual survey investigate multiple factors, such as foot traffic, neighborhood structure, and available workforce, which are typically hard to measure. In this article, we propose to explore both satellite data (e.g., satellite images and nighttime light data) and urban data for business location selection tasks of various businesses. We extract discriminative features from the two kinds of data and perform empirical analysis to evaluate the correlation between extracted features and the business popularity of locations. A novel neural network approach named R 2 Net is proposed to learn deep interactions among features and predict the business popularity of locations. The proposed approach is trained with a regression-and-ranking combined loss function to preserve accurate popularity estimation and the ranking order of locations simultaneously. To support the location selection for multiple businesses, we propose an approach named AR 2 Net with three attention modules, which enable the approach to focus on different latent features according to business types. Comprehensive experiments on a real-world dataset demonstrate that the satellite features are effective and our models outperform the state-of-the-art methods in terms of four metrics.},
  archive      = {J_TKDD},
  doi          = {10.1145/3372406},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-28},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {AR2Net: An attentive neural approach for business location selection with satellite data and urban data},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranking from crowdsourced pairwise comparisons via smoothed
riemannian optimization. <em>TKDD</em>, <em>14</em>(2), 1–26. (<a
href="https://doi.org/10.1145/3372407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Internet of Things has recently become a promising paradigm for augmenting the capability of humans and devices connected in the networks to provide services. In social Internet of Things network, crowdsourcing that collects the intelligence of the human crowd has served as a powerful tool for data acquisition and distributed computing. To support critical applications (e.g., a recommendation system and assessing the inequality of urban perception), in this article, we shall focus on the collaborative ranking problems for user preference prediction from crowdsourced pairwise comparisons. Based on the Bradley--Terry--Luce (BTL) model, a maximum likelihood estimation (MLE) is proposed via low-rank approach in order to estimate the underlying weight/score matrix, thereby predicting the ranking list for each user. A novel regularized formulation with the smoothed surrogate of elementwise infinity norm is proposed in order to address the unique challenge of the coupled the non-smooth elementwise infinity norm constraint and non-convex low-rank constraint in the MLE problem. We solve the resulting smoothed rank-constrained optimization problem via developing the Riemannian trust-region algorithm on quotient manifolds of fixed-rank matrices, which enjoys the superlinear convergence rate. The admirable performance and algorithmic advantages of the proposed method over the state-of-the-art algorithms are demonstrated via numerical results. Moreover, the proposed method outperforms state-of-the-art algorithms on large collaborative filtering datasets in both success rate of inferring preference and normalized discounted cumulative gain.},
  archive      = {J_TKDD},
  doi          = {10.1145/3372407},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-26},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Ranking from crowdsourced pairwise comparisons via smoothed riemannian optimization},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple set matching with bloom matrix and bloom vector.
<em>TKDD</em>, <em>14</em>(2), 1–21. (<a
href="https://doi.org/10.1145/3372409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bloom Filter is a space-efficient probabilistic data structure for checking the membership of elements in a set. Given multiple sets, a standard Bloom Filter is not sufficient when looking for the items to which an element or a set of input elements belong. An example case is searching for documents with keywords in a large text corpus, which is essentially a multiple set matching problem where the input is single or multiple keywords, and the result is a set of possible candidate documents. This article solves the multiple set matching problem by proposing two efficient Bloom Multifilters called Bloom Matrix and Bloom Vector, which generalize the standard Bloom Filter. Both structures are space-efficient and answer queries with a set of identifiers for multiple set matching problems. The space efficiency can be optimized according to the distribution of labels among multiple sets: Uniform and Zipf. Bloom Vector efficiently exploits the Zipf distribution of data for further space reduction. Indeed, both structures are much more space-efficient compared with the state-of-the-art, Bloofi. The results also highlight that a L ookup operation on Bloom Matrix is significantly faster than on Bloom Vector and Bloofi.},
  archive      = {J_TKDD},
  doi          = {10.1145/3372409},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-21},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multiple set matching with bloom matrix and bloom vector},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New algorithms of feature selection and big data assignment
for CBR system integrated by bayesian network. <em>TKDD</em>,
<em>14</em>(2), 1–20. (<a
href="https://doi.org/10.1145/3373086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under big data, the integrated system of case-based reasoning and Bayesian network has exhibited great advantage in implementing the intelligence of engineering application in many domains. To further improve the performance of the hybrid system, this article proposes Probability Change Measurement of Solution Parameters (PCMSP)–Half-Division-Cross (HDC) method, which includes two algorithms, namely PCMSP and HDC algorithm. PCMSP algorithm can select principal problem features according to their effects upon all solution features measured by calculating the weighted relative probability (RP) change of all solution features caused by each problem feature. PCMSP algorithm can perfectly work under big data no matter how complex the data types are and how huge the data size is. HDC algorithm is used to assign the computation task of big data to enhance the efficiency of the integrated system. HDC algorithm assigns big data by grouping all the problem parameters into many small sub-groups and then distributing the data which covers the same sub-group of problem parameters to a slave node. HDC algorithm can guarantee enough efficiency of the integrated system under big data no matter how large the number of problem parameters is. Finally, lots of experiments are executed to validate the proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3373086},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-20},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {New algorithms of feature selection and big data assignment for CBR system integrated by bayesian network},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast, accurate and provable triangle counting in fully
dynamic graph streams. <em>TKDD</em>, <em>14</em>(2), 1–39. (<a
href="https://doi.org/10.1145/3375392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a stream of edge additions and deletions, how can we estimate the count of triangles in it? If we can store only a subset of the edges, how can we obtain unbiased estimates with small variances? Counting triangles (i.e., cliques of size three) in a graph is a classical problem with applications in a wide range of research areas, including social network analysis, data mining, and databases. Recently, streaming algorithms for triangle counting have been extensively studied since they can naturally be used for large dynamic graphs. However, existing algorithms cannot handle edge deletions or suffer from low accuracy. Can we handle edge deletions while achieving high accuracy? We propose T hink D, which accurately estimates the counts of global triangles (i.e., all triangles) and local triangles associated with each node in a fully dynamic graph stream with additions and deletions of edges. Compared to its best competitors, T hink D is (a) Accurate: up to 4.3 × more accurate within the same memory budget, (b) Fast: up to 2.2 × faster for the same accuracy requirements, and (c) Theoretically sound: always maintaining estimates with zero bias (i.e., the difference between the true triangle count and the expected value of its estimate) and small variance. As an application, we use T hink D to detect suddenly emerging dense subgraphs, and we show its advantages over state-of-the-art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3375392},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-39},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Fast, accurate and provable triangle counting in fully dynamic graph streams},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Budget-constrained real-time bidding optimization: Multiple
predictors make it better. <em>TKDD</em>, <em>14</em>(2), 1–27. (<a
href="https://doi.org/10.1145/3375393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we pursue a better solution for the promising problem, i.e., the bidding strategy design, in the real-time bidding (RTB) advertising (AD) environment. Under the budget constraint, the design of an optimal strategy for bidding on each incoming impression opportunity targets at acquiring as many clicks as possible during an AD campaign. State-of-the-art bidding algorithms rely on a single predictor, the clickthrough rate predictor, to calculate the bidding value for each impression. This provides reasonable performance if the predictor has appropriate accuracy in predicting the probability of user clicking. However, the classical methods usually fail to capture optimal results since the predictor accuracy is limited. We improve the situation by accomplishing an additional winning price predictor in the bidding process. In this article, an algorithm combining powers of multiple prediction models is developed. It emerges from an analogy to the online stochastic knapsack problem, and the efficiency of the algorithm is also theoretically analyzed. Experiments conducted on real world RTB datasets show that the proposed solution performs better with regard to both number of clicks achieved and effective cost per click in many different settings of budget constraints.},
  archive      = {J_TKDD},
  doi          = {10.1145/3375393},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Budget-constrained real-time bidding optimization: Multiple predictors make it better},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-task information bottleneck co-clustering for
unsupervised cross-view human action categorization. <em>TKDD</em>,
<em>14</em>(2), 1–23. (<a
href="https://doi.org/10.1145/3375394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of low-cost cameras generates massive amounts of videos recorded from different viewpoints every day. To cope with this vast amount of unlabeled and heterogeneous data, a new multi-task information bottleneck co-clustering (MIBC) approach is proposed to automatically categorize human actions in collections of unlabeled cross-view videos. Our motivation is that, if a learning action category from each view is seen as a single task, it is reasonable to assume that the tasks of learning action patterns from the videos recorded by multiple cameras are dependent and inter-related, since the actions of the same subjects synchronously recorded from different camera viewpoints are complementary to each other. MIBC aims to transfer the shared view knowledge across multiple tasks (i.e., camera viewpoints) to boost the performance of each task. Specifically, MIBC involves the following two parts: (1) extracting action categories for each task by independently maintaining its own relevant information, and (2) allowing the feature representations of all tasks to be compressed into a common feature space, which is utilized to capture the relatedness of multiple tasks and transfer the shared knowledge across different camera viewpoints. These two parts of MIBC work simultaneously and can be solved in a novel co-clustering mechanism. Our experimental evaluation on several cross-view action collections shows that the MIBC algorithm outperforms the existing state-of-the-art baselines.},
  archive      = {J_TKDD},
  doi          = {10.1145/3375394},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-23},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Multi-task information bottleneck co-clustering for unsupervised cross-view human action categorization},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community detection by motif-aware label propagation.
<em>TKDD</em>, <em>14</em>(2), 1–19. (<a
href="https://doi.org/10.1145/3378537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection (or graph clustering) is crucial for unraveling the structural properties of complex networks. As an important technique in community detection, label propagation has shown the advantage of finding a good community structure with nearly linear time complexity. However, despite the progress that has been made, there are still several important issues that have not been properly addressed. First, the label propagation typically proceeds over the lower order structure of the network and only the direct one-hop connections between nodes are taken into consideration. Unfortunately, the higher order structure that may encode design principle of the network and be crucial for community detection is neglected under this regime. Second, the stability of the identified community structure may also be seriously affected by the inherent randomness in the label propagation process. To tackle the above issues, this article proposes a Motif-Aware Weighted Label Propagation method for community detection. We focus on triangles within the network, but our technique extends to other kinds of motifs as well. Specifically, the motif-based higher order structure mining is conducted to capture structural characteristics of the network. First, the motif of interest (locally meaningful pattern) is identified, and then, the motif-based hypergraph can be constructed to encode the higher order connections. To further utilize the structural information of the network, a re-weighted network is designed, which unifies both the higher order structure and the original lower order structure. Accordingly, a novel voting strategy termed NaS (considering both Number and Strength of connections) is proposed to update node labels during the label propagation process. In this way, the random label selection can be effectively eliminated, yielding more stable community structures. Experimental results on multiple real-world datasets have shown the superiority of the proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3378537},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {2},
  number       = {2},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Community detection by motif-aware label propagation},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CFOF: A concentration free measure for anomaly detection.
<em>TKDD</em>, <em>14</em>(1), 1–53. (<a
href="https://doi.org/10.1145/3362158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel notion of outlier, called the Concentration Free Outlier Factor, or CFOF. As a main contribution, we formalize the notion of concentration of outlier scores and theoretically prove that CFOF does not concentrate in the Euclidean space for any arbitrary large dimensionality. To the best of our knowledge, there are no other proposals of data analysis measures related to the Euclidean distance for which it has been provided theoretical evidence that they are immune to the concentration effect. We determine the closed form of the distribution of CFOF scores in arbitrarily large dimensionalities and show that the CFOF score of a point depends on its squared norm standard score and on the kurtosis of the data distribution, thus providing a clear and statistically founded characterization of this notion. Moreover, we leverage this closed form to provide evidence that the definition does not suffer of the hubness problem affecting other measures in high dimensions. We prove that the number of CFOF outliers coming from each cluster is proportional to cluster size and kurtosis, a property that we call semi-locality. We leverage theoretical findings to shed lights on properties of well-known outlier scores. Indeed, we determine that semi-locality characterizes existing reverse nearest neighbor-based outlier definitions, thus clarifying the exact nature of their observed local behavior. We also formally prove that classical distance-based and density-based outliers concentrate both for bounded and unbounded sample sizes and for fixed and variable values of the neighborhood parameter. We introduce the fast-CFOF algorithm for detecting outliers in large high-dimensional dataset. The algorithm has linear cost, supports multi-resolution analysis, and is embarrassingly parallel. Experiments highlight that the technique is able to efficiently process huge datasets and to deal even with large values of the neighborhood parameter, to avoid concentration, and to obtain excellent accuracy.},
  archive      = {J_TKDD},
  doi          = {10.1145/3362158},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-53},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {CFOF: A concentration free measure for anomaly detection},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified multi-view clustering algorithm using
multi-objective optimization coupled with generative model.
<em>TKDD</em>, <em>14</em>(1), 1–31. (<a
href="https://doi.org/10.1145/3365673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a large body of works on multi-view clustering that exploit multiple representations (or views) of the same input data for better convergence. These multiple views can come from multiple modalities (image, audio, text) or different feature subsets. Obtaining one consensus partitioning after considering different views is usually a non-trivial task. Recently, multi-objective based multi-view clustering methods have suppressed the performance of single objective based multi-view clustering techniques. One key problem is that it is difficult to select a single solution from a set of alternative partitionings generated by multi-objective techniques on the final Pareto optimal front. In this article, we propose a novel multi-objective based multi-view clustering framework that overcomes the problem of selecting a single solution in multi-objective based techniques. In particular, our proposed framework has three major components as follows: (i) multi-view based multi-objective algorithm, Multiview-AMOSA, for initial clustering of data points; (ii) a generative model for generating a combined solution having probabilistic labels; and (iii) K -means algorithm for obtaining the final labels. As the first component, we have adopted a recently developed multi-view based multi-objective clustering algorithm to generate different possible consensus partitionings of a given dataset taking into account different views. A generative model is coupled with the first component to generate a single consensus partitioning after considering multiple solutions. It exploits the latent subsets of the non-dominated solutions obtained from the multi-objective clustering algorithm and combines them to produce a single probabilistic labeled solution. Finally, a simple clustering algorithm, namely K -means, is applied on the generated probabilistic labels to obtain the final cluster labels. Experimental validation of our proposed framework is carried out over several benchmark datasets belonging to three different domains; UCI datasets, multi-view datasets, search result clustering datasets, and patient stratification datasets. Experimental results show that our proposed framework achieves an improvement of around 2%--4% over different evaluation metrics in all the four domains in comparison to state-of-the art methods.},
  archive      = {J_TKDD},
  doi          = {10.1145/3365673},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-31},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {A unified multi-view clustering algorithm using multi-objective optimization coupled with generative model},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferring lifetime status of point-of-interest: A multitask
multiclass approach. <em>TKDD</em>, <em>14</em>(1), 1–27. (<a
href="https://doi.org/10.1145/3369799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Point-of-Interest (POI) refers to a specific location that people may find useful or interesting. In modern cities, a large number of POIs emerge, grow, stabilize for a period, then finally disappear. The stages (e.g., emerge and grow) in this process are called lifetime statuses of a POI. While a large body of research has been devoted to identifying and recommending POIs, there are few studies on inferring the lifetime status of POIs. Indeed, the predictive analytics of POI lifetime status can be valuable for various tasks, such as urban planning, business site selection, and real estate appraisal. In this article, we propose a multitask learning approach, named inferring POI lifetime status, to inferring the POI lifetime status with multifaceted data sources. Specifically, we first define three types of POI lifetime status, i.e., booming, decaying, and stable. Then, we formulate a serial classification problem to predict the sequential/successive lifetime statuses of POIs over time. Leveraging geographical data and human mobility data, we examine and integrate three aspects of features related to the prosperity of POIs, i.e., region popularity, region demands, and peer competitiveness. Next, as the booming/decaying POIs are relatively rare in our data, we perform stable class decomposition to alleviate the imbalance between stable POIs and booming/decaying POIs. Finally, we develop a POI lifetime status classifier by exploiting the multitask learning framework as well as the multiclass kernel-based vector machines. We perform extensive experiments using large-scale and real-world datasets of New York City. The experimental results validate the effectiveness of our approach to automatically inferring POI lifetime status.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369799},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Inferring lifetime status of point-of-interest: A multitask multiclass approach},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive local linear discriminant analysis. <em>TKDD</em>,
<em>14</em>(1), 1–19. (<a
href="https://doi.org/10.1145/3369870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction plays a significant role in high-dimensional data processing, and Linear Discriminant Analysis (LDA) is a widely used supervised dimensionality reduction approach. However, a major drawback of LDA is that it is incapable of extracting the local structure information, which is crucial for handling multimodal data. In this article, we propose a novel supervised dimensionality reduction method named Adaptive Local Linear Discriminant Analysis (ALLDA), which adaptively learns a k -nearest neighbors graph from data themselves to extract the local connectivity of data. Furthermore, the original high-dimensional data usually contains noisy and redundant features, which has a negative impact on the evaluation of neighborships and degrades the subsequent classification performance. To address this issue, our method learns the similarity matrix and updates the subspace simultaneously so that the neighborships can be evaluated in the optimal subspaces where the noises have been removed. Through the optimal graph embedding, the underlying sub-manifolds of data in intra-class can be extracted precisely. Meanwhile, an efficient iterative optimization algorithm is proposed to solve the minimization problem. Promising experimental results on synthetic and real-world datasets are provided to evaluate the effectiveness of proposed method.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369870},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Adaptive local linear discriminant analysis},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Core decomposition in multilayer networks: Theory,
algorithms, and applications. <em>TKDD</em>, <em>14</em>(1), 1–40. (<a
href="https://doi.org/10.1145/3369872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilayer networks are a powerful paradigm to model complex systems, where multiple relations occur between the same entities. Despite the keen interest in a variety of tasks, algorithms, and analyses in this type of network, the problem of extracting dense subgraphs has remained largely unexplored so far. As a first step in this direction, in this work, we study the problem of core decomposition of a multilayer network . Unlike the single-layer counterpart in which cores are all nested into one another and can be computed in linear time, the multilayer context is much more challenging as no total order exists among multilayer cores; rather, they form a lattice whose size is exponential in the number of layers. In this setting, we devise three algorithms, which differ in the way they visit the core lattice and in their pruning techniques. We assess time and space efficiency of the three algorithms on a large variety of real-world multilayer networks. We then move a step forward and study the problem of extracting the inner-most (also known as maximal ) cores, i.e., the cores that are not dominated by any other core in terms of their core index in all the layers. inner-most cores are typically orders of magnitude less than all the cores. Motivated by this, we devise an algorithm that effectively exploits the maximality property and extracts inner-most cores directly, without first computing a complete decomposition. This allows for a consistent speed up over a naïve method that simply filters out non-inner-most ones from all the cores. Finally, we showcase the multilayer core-decomposition tool in a variety of scenarios and problems. We start by considering the problem of densest-subgraph extraction in multilayer networks . We introduce a definition of multilayer densest subgraph that tradesoff between high density and number of layers in which the high density holds, and exploit multilayer core decomposition to approximate this problem with quality guarantees. As further applications, we show how to utilize multilayer core decomposition to speed-up the extraction of frequent cross-graph quasi-cliques and to generalize the community-search problem to the multilayer setting.},
  archive      = {J_TKDD},
  doi          = {10.1145/3369872},
  journal      = {ACM Transactions on Knowledge Discovery from Data},
  month        = {1},
  number       = {1},
  pages        = {1-40},
  shortjournal = {ACM Trans. knowl. Discov. Data},
  title        = {Core decomposition in multilayer networks: Theory, algorithms, and applications},
  volume       = {14},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
