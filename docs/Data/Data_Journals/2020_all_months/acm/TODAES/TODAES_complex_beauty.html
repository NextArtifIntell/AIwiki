<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TODAES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="todaes---63">TODAES - 63</h2>
<ul>
<li><details>
<summary>
(2020). Approximate learning and fault-tolerant mapping for
energy-efficient neuromorphic systems. <em>TODAES</em>, <em>26</em>(3),
21:1–23. (<a href="https://doi.org/10.1145/3436491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired deep neural networks such as Convolutional Neural Network (CNN) have shown great potential in solving difficult cognitive problems such as object recognition and classification. However, such architectures have high computational energy demand and sensitivity to variation effects, making them inapplicable for energy-constrained embedded learning platforms. To address this issue, we propose a learning and mapping approach that utilizes approximate computing during early design phases for a layer-wise pruning and fault tolerant weight mapping scheme of reliable and energy-efficient CNNs. In the proposed approach, approximate CNN is prepared first by layer-wise pruning of approximable neurons, which have high error tolerance margins using a two-level approximate learning methodology. Then, the pruned network is retrained to improve its accuracy by fine-tuning the weight values. Finally, a fault-tolerant layer-wise neural weight mapping scheme is adopted to aggressively reduce memory operating voltage when loading the weights of error resilient layers for energy-efficiency. Thus, the combination of approximate learning and fault tolerance aware memory operating voltage downscaling techniques enable us to implement robust and energy-efficient approximate inference engine for CNN applications. Simulation results show that the proposed fault tolerant and approximate learning approach can improve the energy-efficiency of CNN inference engines by more than 50\% with less than 5\% reduction in classification accuracy. Additionally, more than 26\% energy-saving is achieved by using the proposed layer-wise mapping-based cache memory operating voltage down-scaling.},
  archive      = {J_TODAES},
  author       = {Anteneh Gebregirogis and Mehdi Tahoori},
  doi          = {10.1145/3436491},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {21:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Approximate learning and fault-tolerant mapping for energy-efficient neuromorphic systems},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic diagnosis with hybrid fail data. <em>TODAES</em>,
<em>26</em>(3), 19:1–13. (<a
href="https://doi.org/10.1145/3433929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Yield improvement requires information about the defects present in faulty units. This information is derived by applying a logic diagnosis procedure to the fail data collected by a tester from faulty units. It is typical in the early stages of yield learning to find faulty units that produce excessive volumes of fail data. The current practice is to terminate the fail data collection and possibly discard the fail data already collected for the unit. An earlier study shows that a faulty unit may produce excessive volumes of fail data for some tests but not for others. Based on this observation, a possible solution is to collect full fail data only for tests where this is feasible and pass/fail information for other tests. For this approach to be practical, it is necessary to be able to perform logic diagnosis with hybrid fail data that consists of full fail data for some tests and only pass/fail information for other tests. The main challenge in designing such a procedure is to balance the use of the two types of data to produce accurate logic diagnosis results. This article describes a logic diagnosis procedure, from the class of procedures used by commercial tools, that addresses this challenge. Experimental results for benchmark circuits demonstrate the importance of pass/fail information in this scenario.},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz and M. Enamul Amyeen},
  doi          = {10.1145/3433929},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {19:1–13},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Logic diagnosis with hybrid fail data},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimization of mapping dataflow
applications to MPSoCs using a hybrid evaluation combining analytic
models and measurements. <em>TODAES</em>, <em>26</em>(3), 18:1–33. (<a
href="https://doi.org/10.1145/3431814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataflow modeling is well suited for a large variety of applications for modern multi-core architectures, e.g., from the signal processing and the control domain. Furthermore, Design Space Exploration (DSE) can be used to explore mappings of tasks to hardware resources (cores of an MPSoC) and their scheduling to obtain optimized trade-off solutions between throughput and resource costs. However, the throughput evaluation of an implementation candidate via compilation-in-the-loop or simulation-based approaches can be extremely time-consuming. Such a deficiency is very detrimental, because a typical DSE run needs to evaluate thousands of implementation candidates. As a remedy, we propose a hybrid-adaptive DSE where a max-plus algebra-based analytic throughput calculation method is used in the initial DSE phase to enable a fast progress of the search space exploration. However, as this analysis may be inaccurate as neglecting some real-world effects like cache and scheduling overhead, throughput measurements are taken later in the DSE. Moreover, we explore the trade-off between scheduling efficiency of implementation candidates—in favor of reducing concurrency—and exploiting concurrency to a large extent for parallel execution of the application. To find solutions of highest achievable throughput, it is shown that not only highly scheduling efficient implementation candidates but also highly parallel implementation candidates are essential when determining the initial population. In this realm, we contribute a method for diversity-based population initialization. For a representative set of benchmarks, it is shown that the combination of the two major contributions allows us to find much higher throughput multi-core solutions within a given exploration time compared to a state-of-the-art DSE approach.},
  archive      = {J_TODAES},
  author       = {Martin Letras and Joachim Falk and Tobias Schwarzer and Jürgen Teich},
  doi          = {10.1145/3431814},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {18:1–33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Multi-objective optimization of mapping dataflow applications to MPSoCs using a hybrid evaluation combining analytic models and measurements},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). COPE: Reducing cache pollution and network contention by
inter-tile coordinated prefetching in NoC-based MPSoCs. <em>TODAES</em>,
<em>26</em>(3), 17:1–31. (<a
href="https://doi.org/10.1145/3428149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prefetching helps in reducing the memory access latency in multi-banked NUCA architecture, where the Last Level Cache (LLC) is shared. In such systems, an application running on core generates significant traffic on the shared resources, the underlying network and LLC. While prefetching helps to increase application performance, but an inaccurate prefetcher can cause harm by generating unwanted traffic that additionally increases network and LLC contention. Increased network contention results in untimely prefetching of cache blocks, thereby reducing the effectiveness of a prefetcher. Prefetch accuracy is extensively used to reduce unwanted prefetches that can mitigate the prefetcher caused contention. However, the conventional prefetch accuracy parameter has major limitations in NUCA architectures. The article exposes that prefetch accuracy can create two major false-positive cases of prefetching, Under-estimation and Over-estimation problems, and false feedback loop that can mislead a prefetcher in generating more unwanted traffic. We propose a novel technique, Coordinated Prefetching for Efficient (COPE), which addresses these issues by redefining prefetch accuracy for such architectures and identifies additional parameters that can avoid generating unwanted prefetch requests. Experiment conducted using PARSEC benchmark on a 64-core system shows that COPE achieve 3\% reduction in L1 cache miss rate, 12.64\% improvement in IPC, 23.2\% reduction in average packet latency and 18.56\% reduction in dynamic power consumption of the underlying network.},
  archive      = {J_TODAES},
  author       = {Dipika Deb and John Jose and Maurizio Palesi},
  doi          = {10.1145/3428149},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {17:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {COPE: Reducing cache pollution and network contention by inter-tile coordinated prefetching in NoC-based MPSoCs},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust modulus-based matrix splitting iteration method for
mixed-cell-height circuit legalization. <em>TODAES</em>, <em>26</em>(2),
15:1–28. (<a href="https://doi.org/10.1145/3423326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern circuits often contain standard cells of different row heights to meet various design requirements. Taller cells give larger drive strengths and higher speed at the cost of larger areas and power. Multi-row height standard cells incur challenging issues for layout designs, especially the mixed-cell-height legalization problem with heterogeneous cell structures. Honoring the good cell positions from global placement, we present in this article a robust modulus-based matrix splitting iteration method (RMMSIM) to solve the mixed-cell-height legalization problem. Fixing the cell ordering from global placement and relaxing the right-boundary constraints, our proposed method first converts the problem into an equivalent linear complementarity problem (LCP), and then properly splits the matrices in the LCP so that the RMMSIM can solve the LCP optimally. The RMMSIM effectively explores the sparse characteristic of a circuit, and takes only linear time per iteration; as a result, it can solve the QP very efficiently. Finally, an allocation scheme for illegal cells is used to align such cells to placement sites on rows and fix the placement of out-of-right-boundary cells, if any. Experimental results show the effectiveness and efficiency of our proposed algorithm. In addition, the RMMSIM convergence and optimality are theoretically proved and empirically validated. In particular, this article provides a new RMMSIM formulation for various optimization problems that require solving large-scale convex quadratic programming problems efficiently.},
  archive      = {J_TODAES},
  author       = {Jianli Chen and Ziran Zhu and Wenxing Zhu and Chang Yao-Wen},
  doi          = {10.1145/3423326},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {15:1–28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A robust modulus-based matrix splitting iteration method for mixed-cell-height circuit legalization},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Thermal management for FPGA nodes in HPC systems.
<em>TODAES</em>, <em>26</em>(2), 14:1–17. (<a
href="https://doi.org/10.1145/3423494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of FPGAs into large-scale computing systems is gaining attention. In these systems, real-time data handling for networking, tasks for scientific computing, and machine learning can be executed with customized datapaths on reconfigurable fabric within heterogeneous compute nodes. At the same time, thermal management, particularly battling the cooling cost and guaranteeing the reliability, is a continuing concern. The introduction of new heterogeneous components into HPC nodes only adds further complexities to thermal modeling and management. The thermal behavior of multi-FPGA systems deployed within large compute clusters is less explored. In this article, we first show that the thermal behaviors of different FPGAs of the same generation can vary due to their physical locations in a rack and process variation, even though they are running the same tasks. We present a machine learning–based model to capture the thermal behavior of each individual FPGA in the cluster. We then propose two thermal management strategies guided by our thermal model. First, we mitigate thermal variation and hotspots across the cluster by proactive thermal-aware task placement. Under the tested system and benchmarks, we achieve up to 26.4° C and on average 13.3° C system temperature reduction with no performance penalty. Second, we utilize this thermal model to guide HLS parameter tuning at the task design stage to achieve improved thermal response after deployment.},
  archive      = {J_TODAES},
  author       = {Yingyi Luo and Joshua C. Zhao and Arnav Aggarwal and Seda Ogrenci-Memik and Kazutomo Yoshii},
  doi          = {10.1145/3423494},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {14:1–17},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Thermal management for FPGA nodes in HPC systems},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance-driven post-processing of control loop execution
schedules. <em>TODAES</em>, <em>26</em>(2), 13:1–27. (<a
href="https://doi.org/10.1145/3421505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for mapping diverse embedded features onto shared electronic control units has brought about novel ways to co-design control tasks and their schedules. These techniques replace traditional implementations of control with new methods, such as pattern-based scheduling of control tasks and adaptive sharing of bandwidth among control loops through orchestration of their execution patterns. In the current practice of control design, once the static execution schedule is prepared for control tasks, no further control-related optimization is attempted for improving the control performance. We introduce, for the first time, an algorithmic mechanism that re-engineers a recurrent control task by enforcing switching between multiple control laws, which are designed for compensating the non-uniform gaps between successive executions of the control task. We establish that such post-processing of control task schedules may potentially help in improving the combined control performance of the co-scheduled control loops that are executing on a shared platform.},
  archive      = {J_TODAES},
  author       = {Sumana Ghosh and Soumyajit Dey and Pallab Dasgupta},
  doi          = {10.1145/3421505},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {13:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Performance-driven post-processing of control loop execution schedules},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leakage-aware dynamic thermal management of 3D memories.
<em>TODAES</em>, <em>26</em>(2), 12:1–31. (<a
href="https://doi.org/10.1145/3419468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D memory systems offer several advantages in terms of area, bandwidth, and energy efficiency. However, thermal issues arising out of higher power densities have limited their widespread use. While prior works have looked at reducing dynamic power through reduced memory accesses, in these memories, both leakage and dynamic power consumption are comparable. Furthermore, as the temperature rises, the leakage power increases, creating a thermal-leakage loop. We study the impact of leakage power on 3D memory temperature and propose turning OFF specific memory channels to meet thermal constraints. Data is migrated to a 2D memory before closing a 3D channel. We introduce an analytical model to assess the 2D memory delay and use the model to guide data migration decisions. The above strategy is referred to as FastCool and provides an improvement of 22\%, 19\%, and 32\% on average (up to 57\%, 72\%, and 82\%) in performance, memory energy, and energy-delay product (EDP), respectively, on different workloads consisting of SPEC CPU2006 benchmarks. We further propose a thermal management strategy named Energy-Efficient FastCool (EEFC) , which improves upon FastCool by selecting the channels to be closed by considering temperature, leakage, access rate, and position of various 3D memory channels at runtime. Our experiments demonstrate that EEFC leads to an additional improvement of up to 30\%, 30\%, and 51\% in performance, memory energy, and EDP compared to FastCool. Finally, we analyze the effects of process variations on the efficiency of the proposed FC and EEFC strategies. Variation in the manufacturing process causes changes in the leakage power and temperature profile. Since EEFC considers both while selecting channels for closure, it is more resilient to process variations and achieves a lower application execution time and memory energy compared to FastCool.},
  archive      = {J_TODAES},
  author       = {Lokesh Siddhu and Rajesh Kedia and Preeti Ranjan Panda},
  doi          = {10.1145/3419468},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {12:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Leakage-aware dynamic thermal management of 3D memories},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Core placement optimization for multi-chip many-core neural
network systems with reinforcement learning. <em>TODAES</em>,
<em>26</em>(2), 11:1–27. (<a
href="https://doi.org/10.1145/3418498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99× increase in throughput and 50.5\% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22× and reduces the latency by 18.6\%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.},
  archive      = {J_TODAES},
  author       = {Nan Wu and Lei Deng and Guoqi Li and Yuan Xie},
  doi          = {10.1145/3418498},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {11:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Core placement optimization for multi-chip many-core neural network systems with reinforcement learning},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient parasitic-aware gm/ID-based hybrid sizing
methodology for analog and RF integrated circuits. <em>TODAES</em>,
<em>26</em>(2), 10:1–31. (<a
href="https://doi.org/10.1145/3416946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the primary second-order effect, parasitic issues have to be seriously addressed when synthesizing high-performance analog and RF integrated circuits (ICs). In this article, a two-phase hybrid sizing methodology for analog and RF ICs is proposed to take into account parasitic effect in the early design stage. It involves symbolic modeling and mixed-integer nonlinear programming (MINLP) in the first phase, and a many-objective evolutionary algorithm (many-OEA)-based sizing refiner in the second phase. With the aid of our proposed current density factor and piecewise curve fitting technique, the g m / I D concept, which is typically utilized to solve the analog circuit design problem, can provide theoretical support to our accurate symbolic modeling. Thus, the intrinsic and interconnect parasitics can be accurately considered in our work with moderate modeling effort. A variety of electrical, geometric, and parasitic (including parasitic mismatch) constraints can be conveniently integrated into our MINLP problem formulation. Moreover, numerical simulations are embedded into the many-OEA-based sizing phase, which is able to tackle floorplan co-optimization. With such dynamic floorplan variation, the parasitics accuracy can be sustained along the evolution. The experimental results demonstrate high efficacy of our proposed parasitic-aware hybrid sizing methodology.},
  archive      = {J_TODAES},
  author       = {Tuotian Liao and Lihong Zhang},
  doi          = {10.1145/3416946},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {10:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Efficient parasitic-aware gm/ID-based hybrid sizing methodology for analog and RF integrated circuits},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SmartDR: Algorithms and techniques for fast detailed routing
with good design rule handling. <em>TODAES</em>, <em>26</em>(2), 9:1–38.
(<a href="https://doi.org/10.1145/3417133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detailed routing is one of the most time-consuming steps of physical synthesis of integrated circuits. Also, it is very challenging due to the complexity of the design rules that the router must obey. In this article, we present SmartDR, a detailed routing system that focuses on good design rule handling and fast runtime. To attend these objectives, we propose a novel pin access approach and a fast design rule aware A*-interval-based path search algorithm. The pin access method uses resource sharing ghost pin access paths with dynamic legalization check. We also propose a design rule check algorithm to detect thick metal shapes that are widely created using the proposed pin access method. The path search algorithm integrates design rule check on its core, handling many design rules that would not be possible to be solved by postprocessing. It is aware of the minimum area rule, the cut spacing of via cuts within the same path, and the via library. We also present a new technique to improve A*-based path search in detailed routing. The technique makes the path search algorithm aware of the global routing guides, accelerating the search. Using ISPD 2018 Contest benchmarks, our experiments show that our router is superior to the state-of-the-art routers that were also tested using the same benchmarks. Our router has presented, on average, 77.6\% less runtime, 73.5\% less design rule violations, with respect to Dr. CU 2.0, which is the better of the compared routers.},
  archive      = {J_TODAES},
  author       = {Stèphano M. M. Gonçalves and Leomar S. da Rosa Jr and Felipe S. Marques},
  doi          = {10.1145/3417133},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {9:1–38},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {SmartDR: Algorithms and techniques for fast detailed routing with good design rule handling},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deterministic-path routing algorithm for tolerating many
faults on very-large-scale network-on-chip. <em>TODAES</em>,
<em>26</em>(1), 8:1–26. (<a
href="https://doi.org/10.1145/3414060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Very-large-scale network-on-chip (VLS-NoC) has become a promising fabric for supercomputers, but this fabric may encounter the many-fault problem. This article proposes a deterministic routing algorithm to tolerate the effects of many faults in VLS-NoCs. This approach generates routing tables offline using a breadth-first traversal algorithm and stores a routing table locally in each switch for online packet transmission. The approach applies the Tarjan algorithm to degrade the faulty NoC and maximizes the number of available nodes in the reconfigured NoC. In 2D NoCs, the approach updates routing tables of some nodes using the deprecated channel/node rules and avoids deadlocks in the NoC. In 3D NoCs, the approach uses a forbidden-turn selection algorithm and detour rules to prevent faceted rings and ensures the NoC is deadlock-free. Experimental results demonstrate that the proposed approach provides fault-free communications of 2D and 3D NoCs after injecting 40 faulty links. Meanwhile, it maximizes the number of available nodes in the reconfigured NoC. The approach also outperforms existing algorithms in terms of average latency, throughput, and energy consumption.},
  archive      = {J_TODAES},
  author       = {Ying Zhang and Xinpeng Hong and Zhongsheng Chen and Zebo Peng and Jianhui Jiang},
  doi          = {10.1145/3414060},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {8:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A deterministic-path routing algorithm for tolerating many faults on very-large-scale network-on-chip},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust multi-target sample preparation on MEDA biochips
obviating waste production. <em>TODAES</em>, <em>26</em>(1), 7:1–29. (<a
href="https://doi.org/10.1145/3414061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital microfluidic biochips have fueled a paradigm shift in implementing bench-top laboratory experiments on a single tiny chip, thus replacing costly and bulky equipment. However, because of imprecise fluidic functions, several volumetric split errors may occur during the execution of bioassays. Earlier approaches to error-correcting sample preparation addressed this problem by using a cyberphysical system yielding several drawbacks such as increased sample preparation cost and time, and uncertainty in assay completion time. In addition, error correction for only a single-target sample has been considered so far, although many assays require the production of multi-target samples. In this work, we present an error-free dilution technique that guarantees the correctness of the resulting concentration factor of a sample without performing any additional roll-back or roll-forward action. To the best of our knowledge, we are the first to present a solution strategy for tackling dispensing errors during sample preparation. We use micro-electrode-dot-array biochips that offer the advantages of manipulating fractional volumes of droplets (aliquots) for navigation, as well as mix-split operations. Instead of performing traditional mix-and-split steps with integral-volume droplets, we execute only an aliquoting-and-mix sequence using differential-size aliquots. Thus, all split operations, which are the main source of errors in conventional digital microfluidic biochips, are completely eliminated, and hence neither sensing nor any correcting action is needed, and further, no management of intermediate waste droplets is needed. Additionally, the procedure can be fully parallelized for accurately producing multiple dilutions of a sample. Experimental results corroborate the superiority of the proposed method in terms of error management, as well as sample preparation cost and time.},
  archive      = {J_TODAES},
  author       = {Sudip Poddar and Tapalina Banerjee and Robert Wille and Bhargab B. Bhattacharya},
  doi          = {10.1145/3414061},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {7:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Robust multi-target sample preparation on MEDA biochips obviating waste production},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-level synthesis of key-obfuscated RTL IP with design
lockout and camouflaging. <em>TODAES</em>, <em>26</em>(1), 6:1–35. (<a
href="https://doi.org/10.1145/3410337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose three orthogonal techniques to secure Register-Transfer-Level (RTL) Intellectual Property (IP). In the first technique, the key-based RTL obfuscation scheme is proposed at an early design phase during High-Level Synthesis (HLS). Given a control-dataflow graph, we identify operations on non-critical paths and leverage synthesis information during and after HLS to insert obfuscation logic. In the second approach, we propose a robust design lockout mechanism for a key-obfuscated RTL IP when an incorrect key is applied more than the allowed number of attempts. We embed comparators on obfuscation logic output to check if the applied key is correct or not and a finite-state machine checker to enforce design lockout. Once locked out, only an authorized user (designer) can unlock the locked IP. In the third technique, we design four variants of the obfuscating module to camouflage the RTL design. We analyze the security properties of obfuscation, design lockout, and camouflaging. We demonstrate the feasibility on four datapath-intensive IPs and one crypto core for 32-, 64-, and 128-bit key lengths under three design corners (best, typical, and worst) with reasonable area, power, and delay overheads on both ASIC and FPGA platforms.},
  archive      = {J_TODAES},
  author       = {Sheikh Ariful Islam and Love Kumar Sah and Srinivas Katkoori},
  doi          = {10.1145/3410337},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {6:1–35},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {High-level synthesis of key-obfuscated RTL IP with design lockout and camouflaging},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TransNet: Minimally supervised deep transfer learning for
dynamic adaptation of wearable systems. <em>TODAES</em>, <em>26</em>(1),
5:1–31. (<a href="https://doi.org/10.1145/3414062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearables are poised to transform health and wellness through automation of cost-effective, objective, and real-time health monitoring. However, machine learning models for these systems are designed based on labeled data collected, and feature representations engineered, in controlled environments. This approach has limited scalability of wearables because (i) collecting and labeling sufficiently large amounts of sensor data is a labor-intensive and expensive process; and (ii) wearables are deployed in highly dynamic environments of the end-users whose context undergoes consistent changes. We introduce TransNet , a deep learning framework that minimizes the costly process of data labeling, feature engineering, and algorithm retraining by constructing a scalable computational approach. TransNet learns general and reusable features in lower layers of the framework and quickly reconfigures the underlying models from a small number of labeled instances in a new domain, such as when the system is adopted by a new user or when a previously unseen event is to be added to event vocabulary of the system. Utilizing TransNet on four activity datasets, TransNet achieves an average accuracy of 88.1\% in cross-subject learning scenarios using only one labeled instance for each activity class. This performance improves to an accuracy of 92.7\% with five labeled instances.},
  archive      = {J_TODAES},
  author       = {Seyed Ali Rokni and Marjan Nourollahi and Parastoo Alinia and Iman Mirzadeh and Mahdi Pedram and Hassan Ghasemzadeh},
  doi          = {10.1145/3414062},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {5:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {TransNet: Minimally supervised deep transfer learning for dynamic adaptation of wearable systems},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ising-FPGA: A spintronics-based reconfigurable ising model
solver. <em>TODAES</em>, <em>26</em>(1), 4:1–27. (<a
href="https://doi.org/10.1145/3411511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Ising model has been explored as a framework for modeling NP-hard problems, with several diverse systems proposed to solve it. The Magnetic Tunnel Junction– (MTJ) based Magnetic RAM is capable of replacing CMOS in memory chips. In this article, we propose the use of MTJs for representing the units of an Ising model and leveraging its intrinsic physics for finding the ground state of the system through annealing. We design the structure of a basic MTJ-based Ising cell capable of performing the functions essential to an Ising solver. The hardware overhead of the Ising model is analyzed, and a technique to use the basic Ising cell for scaling to large problems is described. We then go on to propose Ising-FPGA, a parallel and reconfigurable architecture that can be used to map a large class of NP-hard problems, and show how a standard Place and Route tool can be utilized to program the Ising-FPGA. The effects of this hardware platform on our proposed design are characterized and methods to overcome these effects are prescribed. We discuss how three representative NP-hard problems can be mapped to the Ising model. Further, we suggest ways to simplify these problems to reduce the use of hardware and analyze the impact of these simplifications on the quality of solutions. Simulation results show the effectiveness of MTJs as Ising units by producing solutions close/comparable to the optimum and demonstrate that our design methodology holds the capability to account for the effects of the hardware.},
  archive      = {J_TODAES},
  author       = {Ankit Mondal and Ankur Srivastava},
  doi          = {10.1145/3411511},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {4:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Ising-FPGA: A spintronics-based reconfigurable ising model solver},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mitigating negative impacts of read disturb in SSDs.
<em>TODAES</em>, <em>26</em>(1), 3:1–24. (<a
href="https://doi.org/10.1145/3410332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Read disturb is a circuit-level noise in solid-state drives (SSDs), which may corrupt existing data in SSD blocks and then cause high read error rate and longer read latency. The approach of read refresh is commonly used to avoid read disturb errors by periodically migrating the hot read data to other free blocks, but it places considerable negative impacts on I/O (Input/Output) responsiveness. This article proposes scheduling approaches on write data and read refresh operations, to mitigate the negative effects caused by read disturb. To be specific, we first construct a model to classify SSD blocks into two categories according to the estimated read error rate by referring to the factors of block’s P/E (Program/Erase) cycle and the accumulated read count to the block. Then, the data being intensively read will be redirected to the block having a small read error rate, as it is not sensitive to read disturb even though the data will be heavily requested. Moreover, we take advantage of reinforcement learning to predict the idle interval between two I/O requests for purposely conducting (partial) read refresh operations. As a result, it is able to minimize negative impacts toward subsequent incoming I/O requests and to ensure I/O responsiveness. Through a series of emulation tests on several realistic disk traces, we demonstrate that the proposed mechanisms can noticeably yield performance improvements on the metrics of read error rate and I/O latency.},
  archive      = {J_TODAES},
  author       = {Jun Li and Bowen Huang and Zhibing Sha and Zhigang Cai and Jianwei Liao and Balazs Gerofi and Yutaka Ishikawa},
  doi          = {10.1145/3410332},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {3:1–24},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Mitigating negative impacts of read disturb in SSDs},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FaultDroid: An algorithmic approach for fault-induced
information leakage analysis. <em>TODAES</em>, <em>26</em>(1), 2:1–27.
(<a href="https://doi.org/10.1145/3410336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault attacks belong to a potent class of implementation-based attacks that can compromise a crypto-device within a few milliseconds. Out of the large numbers of faults that can occur in the device, only a very few are exploitable in terms of leaking the secret key. Ignorance of this fact has resulted in countermeasures that have either significant overhead or inadequate protection. This article presents a framework, referred to as FaultDroid, for automated vulnerability analysis of fault attacks. It explores the entire fault attack space, identifies the single/multiple fault scenarios that can be exploited by a differential fault attack, rank-orders them in terms of criticality, and provides design guidance to mitigate the vulnerabilities at low cost. The framework enables a designer to automatically evaluate the fault attack vulnerabilities of a block cipher implementation and then incorporate efficient countermeasures. FaultDroid uses a formal model of fault attacks on a high-level specification of a block cipher and hence is equally applicable to both software and hardware implementation of the cipher. As case studies, we employ FaultDroid to comprehensively evaluate the fault scenarios in several common ciphers—AES, CLEFIA, CAMELLIA, SMS4, SIMON, PRESENT, and GIFT—and assess their vulnerability.},
  archive      = {J_TODAES},
  author       = {Indrani Roy and Chester Rebeiro and Aritra Hazra and Swarup Bhunia},
  doi          = {10.1145/3410336},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {2:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {FaultDroid: An algorithmic approach for fault-induced information leakage analysis},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modular neural networks for low-power image classification
on embedded devices. <em>TODAES</em>, <em>26</em>(1), 1:1–35. (<a
href="https://doi.org/10.1145/3408062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded devices are generally small, battery-powered computers with limited hardware resources. It is difficult to run deep neural networks (DNNs) on these devices, because DNNs perform millions of operations and consume significant amounts of energy. Prior research has shown that a considerable number of a DNN’s memory accesses and computation are redundant when performing tasks like image classification. To reduce this redundancy and thereby reduce the energy consumption of DNNs, we introduce the Modular Neural Network Tree architecture. Instead of using one large DNN for the classifier, this architecture uses multiple smaller DNNs (called modules ) to progressively classify images into groups of categories based on a novel visual similarity metric. Once a group of categories is selected by a module, another module then continues to distinguish among the similar categories within the selected group. This process is repeated over multiple modules until we are left with a single category. The computation needed to distinguish dissimilar groups is avoided, thus reducing redundant operations, memory accesses, and energy. Experimental results using several image datasets reveal the effectiveness of our proposed solution to reduce memory requirements by 50\% to 99\%, inference time by 55\% to 95\%, energy consumption by 52\% to 94\%, and the number of operations by 15\% to 99\% when compared with existing DNN architectures, running on two different embedded systems: Raspberry Pi 3 and Raspberry Pi Zero.},
  archive      = {J_TODAES},
  author       = {Abhinav Goel and Sara Aghajanzadeh and Caleb Tung and Shuo-Han Chen and George K. Thiruvathukal and Yung-Hsiang Lu},
  doi          = {10.1145/3408062},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {1:1–35},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Modular neural networks for low-power image classification on embedded devices},
  volume       = {26},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wire load oriented analog routing with matching constraints.
<em>TODAES</em>, <em>25</em>(6), 55:1–26. (<a
href="https://doi.org/10.1145/3403932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As design complexity is increased exponentially, electronic design automation (EDA) tools are essential to reduce design efforts. However, the analog layout design has still been done manually for decades because it is a sensitive and error-prone task. Tool-generated layouts are still not well-accepted by analog designers due to the performance loss under non-ideal effects. Most previous works focus on adding more layout constraints on the analog placement. Routing the nets is thus considered as a trivial step that can be done by typical digital routing methodology, which is to use vias to connect every horizontal and vertical lines. Those extra vias will significantly increase the wire loads and degrade the circuit performance. Therefore, in this article, a wire load oriented analog routing methodology is proposed to reduce the number of layer changing of each routing net. Wire load is considered in the optimization goal as well as the wire length to keep the circuit performance after layout, while the analog layout constraints like symmetry and length matching are still satisfied during routing. As shown in the experimental results, this approach significantly reduces the wire load and performance loss after layout with little overhead on wire length.},
  archive      = {J_TODAES},
  author       = {Hao Yu Chi and Chien Nan Jimmy Liu and Hung Ming Chen},
  doi          = {10.1145/3403932},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {55:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Wire load oriented analog routing with matching constraints},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval arithmetic and self-similarity based RTL input
vector control for datapath leakage minimization. <em>TODAES</em>,
<em>25</em>(6), 54:1–26. (<a
href="https://doi.org/10.1145/3408061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With technology scaling, subthreshold leakage has dominated the overall power consumption in a design. Input vector control is an effective technique to minimize subthreshold leakage. Low leakage input vector determination is not often possible due to large design space and simulation time. Similarly, applying an appropriate minimum leakage vector (MLV) to each Register Transfer Level (RTL) module instance in a design often results in a low leakage state with significant area overhead. In this work, we propose a top-down and bottom-up approach for propagating the input vector interval to identify low leakage input vector at primary inputs of an RTL datapath. For each module, via Monte Carlo simulation, we identify a set of MLV intervals such that maximum leakage is within (say) 10\% of the lowest leakage points. As the module bit width increases, exhaustive simulation to find the low leakage vector is not feasible. Further, we need to uniformly search the entire input space to obtain as many low leakage intervals as possible. Based on empirical observations, we observe self-similarity in the subthreshold leakage distribution of adder/multiplier modules with highly regular bit-slice architectures when input space is partitioned into smaller cells. This property enables the uniform search of low leakage vectors in the entire input space where the time taken for characterization increases linearly with the module size. We further process the reduced interval set with simulated annealing to arrive at the best low-leakage vector at the primary inputs. We also propose to reduce area overhead (in some cases to 0\%) by choosing Primary Input (PI) MLVs such that resultant inputs to internal nodes are also MLVs. Compared to existing work, experimental results for DSP filters simulated in 16nm technology demonstrated leakage savings of 93.6\% and 89.2\% for top-down and bottom-up approaches with no area overhead.},
  archive      = {J_TODAES},
  author       = {Shilpa Pendyala and Sheikh Ariful Islam and Srinivas Katkoori},
  doi          = {10.1145/3408061},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {54:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Interval arithmetic and self-similarity based RTL input vector control for datapath leakage minimization},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconfigurable network-on-chip security architecture.
<em>TODAES</em>, <em>25</em>(6), 53:1–25. (<a
href="https://doi.org/10.1145/3406661">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Growth of the Internet-of-things has led to complex system-on-chips (SoCs) being used in the edge devices in IoT applications. The increased complexity is demanding designers to consider several critical factors, such as dynamic requirement changes, long application life, mass production, and tight time-to-market deadlines. These requirements lead to more complex security concerns. SoC manufacturers outsource some of the intellectual property cores integrated on the SoC to untrusted third-party vendors. The untrusted intellectual properties can contain malicious implants, which can launch attacks using the resources provided by the on-chip interconnection network, commonly known as the network-on-chip (NoC). Existing efforts on securing NoC have considered lightweight encryption, authentication, and other attack detection mechanisms such as denial-of-service and buffer overflows. Unfortunately, these approaches focus on designing statically optimized security solutions. As a result, they are not suitable for many IoT systems with long application life and dynamic requirement changes. There is a critical need to design reconfigurable security architectures that can be dynamically tuned based on changing requirements. In this article, we propose a tier-based reconfigurable security architecture that can adapt to different use-case scenarios. We explore how to design an efficient reconfigurable architecture that can support three popular NoC security mechanisms (encryption, authentication, and denial-of-service attack detection and localization) and implement suitable dynamic reconfiguration techniques. We evaluate our proposed framework by running standard benchmarks enabling different tiers of security and provide a comprehensive analysis of how different levels of security can affect application performance, energy efficiency, and area overhead.},
  archive      = {J_TODAES},
  author       = {Subodha Charles and Prabhat Mishra},
  doi          = {10.1145/3406661},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {53:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Reconfigurable network-on-chip security architecture},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient GPU l2 cache design using instruction-level
data locality similarity. <em>TODAES</em>, <em>25</em>(6), 52:1–18. (<a
href="https://doi.org/10.1145/3408060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel energy-efficient cache design for massively parallel, throughput-oriented architectures like GPUs. Unlike L1 data cache on modern GPUs, L2 cache shared by all of the streaming multiprocessors is not the primary performance bottleneck, but it does consume a large amount of chip energy. We observe that L2 cache is significantly underutilized by spending 95.6\% of the time storing useless data. If such “dead time” on L2 is identified and reduced, L2’s energy efficiency can be drastically improved. Fortunately, we discover that the SIMT programming model of GPUs provides a unique feature among threads: instruction-level data locality similarity, which can be used to accurately predict the data re-reference counts at L2 cache block level. We propose a simple design that leverages this Lo cality S imilarity to build an energy-efficient GPU L2 Cache , named LoSCache . Specifically, LoSCache uses the data locality information from a small group of cooperative thread arrays to dynamically predict the L2-level data re-reference counts of the remaining cooperative thread arrays. After that, specific L2 cache lines can be powered off if they are predicted to be “dead” after certain accesses. Experimental results on a wide range of applications demonstrate that our proposed design can significantly reduce the L2 cache energy by an average of 64\% with only 0.5\% performance loss. In addition, LoSCache is cost effective, independent of the scheduling policies, and compatible with the state-of-the-art L1 cache designs for additional energy savings.},
  archive      = {J_TODAES},
  author       = {Jingweijia Tan and Kaige Yan and Shuaiwen Leon Song and Xin Fu},
  doi          = {10.1145/3408060},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {52:1–18},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Energy-efficient GPU l2 cache design using instruction-level data locality similarity},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A locality optimizer for loop-dominated applications based
on reuse distance analysis. <em>TODAES</em>, <em>25</em>(6), 51:1–26.
(<a href="https://doi.org/10.1145/3398189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source code optimization can heavily improve software code implementation quality while still being complementary to conventional compilers’ optimizations. Source code analysis tools are very useful in supporting source code optimization. This article discusses MemAssist, a source-level optimization environment for semi-automatic locality optimization of loop-dominated code. MemAssist applies reuse distance analysis and a relevant optimization algorithm to explore the design space. It generates a set of suggestions for locality optimizing loop transformations that reduce data cache miss rate and execution time. MemAssist has been used to optimize a number of applications. Experimental results show that MemAssist leads to cache miss rate reduction at all cache layers, memory accesses reduction by up to 42\%, and to a speedup of up to three times. Therefore, MemAssist can be used for efficient early-stage software optimization leading to development effort and time reduction.},
  archive      = {J_TODAES},
  author       = {Christakis Lezos and Grigoris Dimitroulakos and Ioannis Latifis and Konstantinos Masselos},
  doi          = {10.1145/3398189},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {51:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A locality optimizer for loop-dominated applications based on reuse distance analysis},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MNFTL: An efficient flash translation layer for MLC NAND
flash memory. <em>TODAES</em>, <em>25</em>(6), 50:1–19. (<a
href="https://doi.org/10.1145/3398037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The write constraints of Multi-Level Cell (MLC) NAND flash memory make most of the existing flash translation layer (FTL) schemes inefficient or inapplicable. In this article, we solve several fundamental problems in the design of MLC flash translation layer. The objective is to reduce the garbage collection overhead to reduce the average system response time. We make the key observation that the valid pages copy is the essential garbage collection overhead. Based on this observation, we propose two approaches, namely, concentrated mapping and postponed reclamation, to effectively reduce the valid pages copy. Besides, we propose a progressive garbage collection that can well utilize the system idle time to reclaim more spaces. We conduct a series of experiments on an embedded developing board with a set of benchmarks. The experimental results show that our scheme can achieve a significant reduction in the average system response time compared with the previous work.},
  archive      = {J_TODAES},
  author       = {Chenlin Ma and Yi Wang and Zhaoyan Shen and Renhai Chen and Zhu Wang and Zili Shao},
  doi          = {10.1145/3398037},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {50:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {MNFTL: An efficient flash translation layer for MLC NAND flash memory},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial: A message from the new editor-in-chief.
<em>TODAES</em>, <em>25</em>(6), 49e:1–2. (<a
href="https://doi.org/10.1145/3419376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TODAES},
  author       = {X. Sharon Hu},
  doi          = {10.1145/3419376},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {49e:1–2},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Editorial: A message from the new editor-in-chief},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LDE-aware analog layout migration with OPC-inclusive
routing. <em>TODAES</em>, <em>25</em>(6), 49:1–22. (<a
href="https://doi.org/10.1145/3398190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance degradation in analog circuits due to layout dependent effects (LDEs) has become increasingly challenging in advanced technologies. To address this issue, LDEs have to be seriously considered as performance constraints in the physical design process. In this article, we have proposed an innovative LDE-aware retargeting methodology for analog layout migration from old technologies to new ones with LDEs optimized for performance preservation. The LDE constraints, which are first identified with the aid of a specialized sensitivity analysis scheme, are satisfied during the layout migration process. Moreover, optical proximity correction (OPC), as one of the most popular resolution enhancement techniques for subwavelength lithography in modern nanometer technology manufacturing, is also included in this study. We have developed an OPC-inclusive ILP-based analog router to route electrical nets for improving image fidelity of the final layout while the routability and other analog constraints are respected in the meantime. The experimental results show our proposed layout migration methodology along with the routing scheme is able to retarget analog layouts with better circuit performance and finer image quality compared to the previous works.},
  archive      = {J_TODAES},
  author       = {Mohammad Torabi and Lihong Zhang},
  doi          = {10.1145/3398190},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {6},
  pages        = {49:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {LDE-aware analog layout migration with OPC-inclusive routing},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial perturbation attacks on ML-based CAD: A case
study on CNN-based lithographic hotspot detection. <em>TODAES</em>,
<em>25</em>(5), 48:1–31. (<a
href="https://doi.org/10.1145/3408288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is substantial interest in the use of machine learning (ML)-based techniques throughout the electronic computer-aided design (CAD) flow, particularly those based on deep learning. However, while deep learning methods have surpassed state-of-the-art performance in several applications, they have exhibited intrinsic susceptibility to adversarial perturbations—small but deliberate alterations to the input of a neural network, precipitating incorrect predictions. In this article, we seek to investigate whether adversarial perturbations pose risks to ML-based CAD tools, and if so, how these risks can be mitigated. To this end, we use a motivating case study of lithographic hotspot detection, for which convolutional neural networks (CNN) have shown great promise. In this context, we show the first adversarial perturbation attacks on state-of-the-art CNN-based hotspot detectors; specifically, we show that small (on average 0.5\% modified area), functionality preserving, and design-constraint-satisfying changes to a layout can nonetheless trick a CNN-based hotspot detector into predicting the modified layout as hotspot free (with up to 99.7\% success in finding perturbations that flip a detector’s output prediction, based on a given set of attack constraints). We propose an adversarial retraining strategy to improve the robustness of CNN-based hotspot detection and show that this strategy significantly improves robustness (by a factor of ~3) against adversarial attacks without compromising classification accuracy.},
  archive      = {J_TODAES},
  author       = {Kang Liu and Haoyu Yang and Yuzhe Ma and Benjamin Tan and Bei Yu and Evangeline F. Y. Young and Ramesh Karri and Siddharth Garg},
  doi          = {10.1145/3408288},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {48:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Adversarial perturbation attacks on ML-based CAD: A case study on CNN-based lithographic hotspot detection},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning-based defect coverage boosting of analog
circuits under measurement variations. <em>TODAES</em>, <em>25</em>(5),
47:1–27. (<a href="https://doi.org/10.1145/3408063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety-critical and mission-critical systems, such as airplanes or (semi-)autonomous cars, are relying on an ever-increasing number of embedded integrated circuits. Consequently, there is a need for complete defect coverage during the testing of these circuits to guarantee their functionality in the field. In this context, reducing the escape rate of defects during production testing is crucial, and significant progress has been made to this end. However, production testing using automatic test equipment is subject to various measurement parasitic variations, which may have a negative impact on the testing procedure and therefore limit the final defect coverage. To tackle this issue, this article proposes an improved test flow targeting increased analog defect coverage, both at the system and block levels, by analyzing and improving the coverage of typical functional and structural tests under these measurement variations. To illustrate the flow, the technique of inserting a pseudo-random signal at available circuit nodes and applying machine learning techniques to its response is presented. A DC-DC converter, derived from an industrial product, is used as a case study to validate the flow. In short, results show that system-level tests for the converter suffer strongly from the measurement variations and are limited to just under 80\% coverage, even when applying the proposed test flow. Block-level testing, however, can achieve only 70\% fault coverage without improvements but is able to consistently achieve 98\% of fault coverage at a cost of at most 2\% yield loss with the proposed machine learning–based boosting technique.},
  archive      = {J_TODAES},
  author       = {Nektar Xama and Martin Andraud and Jhon Gomez and Baris Esen and Wim Dobbelaere and Ronny Vanhooren and Anthony Coyette and Georges Gielen},
  doi          = {10.1145/3408063},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {47:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning-based defect coverage boosting of analog circuits under measurement variations},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving FPGA-based logic emulation systems through machine
learning. <em>TODAES</em>, <em>25</em>(5), 46:1–20. (<a
href="https://doi.org/10.1145/3399595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a machine learning (ML) framework to improve the use of computing resources in the FPGA compilation step of a commercial FPGA-based logic emulation flow. Our ML models enable highly accurate predictability of the final place and route design qualities, runtime, and optimal mapping parameters. We identify key compilation features that may require aggressive compilation efforts using our ML models. Experiments based on our large-scale database from an industry’s emulation system show that our ML models help reduce the total number of jobs required for a given netlist by 33\%. Moreover, our job scheduling algorithm based on our ML model reduces the overall time to completion of concurrent compilation runs by 24\%. In addition, we propose a new method to compute “recommendations” from our ML model to perform re-partitioning of difficult partitions. Tested on a large-scale industry system on chip design, our recommendation flow provides additional 15\% compile time savings for the entire system on chip. To exploit our ML model inside the time-critical multi-FPGA partitioning step, we implement it in an optimized multi-threaded representation.},
  archive      = {J_TODAES},
  author       = {Anthony Agnesina and Sung Kyu Lim and Etienne Lepercq and Jose Escobedo Del Cid},
  doi          = {10.1145/3399595},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {46:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Improving FPGA-based logic emulation systems through machine learning},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-fidelity surrogate-based optimization for
electromagnetic simulation acceleration. <em>TODAES</em>,
<em>25</em>(5), 45:1–21. (<a
href="https://doi.org/10.1145/3398268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As circuits’ speed and frequency increase, fast and accurate capture of the details of the parasitics in metal structures, such as inductors and clock trees, becomes more critical. However, conducting high-fidelity 3D electromagnetic (EM) simulations within the design loop is very time consuming and computationally expensive. To address this issue, we propose a surrogate-based optimization methodology flow, namely multi-fidelity surrogate-based optimization with candidate search (MFSBO-CS), which integrates the concept of multi-fidelity to reduce the full-wave EM simulation cost in analog/RF simulation-based optimization problems. To do so, a statistical co-kriging model is adapted as the surrogate to model the response surface, and a parallelizable perturbation-based adaptive sampling method is used to find the optima. Within the proposed method, low-fidelity fast RC parasitic extraction tools and high-fidelity full-wave EM solvers are used together to model the target design and then guide the proposed adaptive sample method to achieve the final optimal design parameters. The sampling method in this work not only delivers additional coverage of design space but also helps increase the accuracy of the surrogate model efficiently by updating multiple samples within one iteration. Moreover, a novel modeling technique is developed to further improve the multi-fidelity surrogate model at an acceptable additional computation cost. The effectiveness of the proposed technique is validated by mathematical proofs and numerical test function demonstration. In this article, MFSBO-CS has been applied to two design cases, and the result shows that the proposed methodology offers a cost-efficient solution for analog/RF design problems involving EM simulation. For the two design cases, MFSBO-CS either reaches comparably or outperforms the optimization result from various Bayesian optimization methods with only approximately one- to two-thirds of the computation cost.},
  archive      = {J_TODAES},
  author       = {Yi Wang and Paul D. Franzon and David Smart and Brian Swahn},
  doi          = {10.1145/3398268},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {45:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Multi-fidelity surrogate-based optimization for electromagnetic simulation acceleration},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning approaches for efficient design space
exploration of application-specific NoCs. <em>TODAES</em>,
<em>25</em>(5), 44:1–27. (<a
href="https://doi.org/10.1145/3403584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many Multi-Processor Systems-on-Chip (MPSoCs), traffic between cores is unbalanced. This motivates the use of an application-specific Network-on-Chip (NoC) that is customized and can provide a high performance at low cost in terms of power and area. However, finding an optimized application-specific NoC architecture is a challenging task due to the huge design space. This article proposes to apply machine learning approaches for this task. Using graph rewriting, the NoC Design Space Exploration (DSE) is modelled as a Markov Decision Process (MDP). Monte Carlo Tree Search (MCTS), a technique from reinforcement learning, is used as search heuristic. Our experimental results show that—with the same cost function and exploration budget—MCTS finds superior NoC architectures compared to Simulated Annealing (SA) and a Genetic Algorithm (GA). However, the NoC DSE process suffers from the high computation time due to expensive cycle-accurate SystemC simulations for latency estimation. This article therefore additionally proposes to replace latency simulation by fast latency estimation using a Recurrent Neural Network (RNN). The designed RNN is sufficiently general for latency estimation on arbitrary NoC architectures. Our experiments show that compared to SystemC simulation, the RNN-based latency estimation offers a similar speed-up as the widely used Queuing Theory (QT). Yet, in terms of estimation accuracy and fidelity, the RNN is superior to QT, especially for high-traffic scenarios. When replacing SystemC simulations with the RNN estimation, the obtained solution quality decreases only slightly, whereas it suffers significantly when QT is used.},
  archive      = {J_TODAES},
  author       = {Yong Hu and Marcel Mettler and Daniel Mueller-Gritschneder and Thomas Wild and Andreas Herkersdorf and Ulf Schlichtmann},
  doi          = {10.1145/3403584},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {44:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning approaches for efficient design space exploration of application-specific NoCs},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards smarter diagnosis: A learning-based diagnostic
outcome previewer. <em>TODAES</em>, <em>25</em>(5), 43:1–20. (<a
href="https://doi.org/10.1145/3398267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the inherent perturbations during the fabrication process of integrated circuits that lead to yield loss, diagnosis of failing chips is a mitigating method employed during both yield ramping and high-volume manufacturing for yield learning. However, various uncertainties in the fabrication process bring a number of challenges, resulting in diagnosis with undesirable outcomes or low efficiency, including, for example, diagnosis failure, bad resolution, and extremely long runtime. It would therefore be very beneficial to have a comprehensive preview of diagnostic outcomes beforehand, which allows fail logs to be prioritized in a more reasonable way for smarter allocation of diagnosis resources. In this work, we propose a learning-based previewer, which is able to predict five aspects of diagnostic outcomes for a failing IC, including diagnosis success, defect count, failure type, resolution, and runtime magnitude. The previewer consists of three classification models and one regression model, where Random Forest classification and regression are used. Experiments on a 28 nm test chip and a high-volume 90 nm part demonstrate that the predictors can provide accurate prediction results, and in a virtual application scenario the overall previewer can bring up to 9× speed-up for the test chip and 6× for the high-volume part.},
  archive      = {J_TODAES},
  author       = {Qicheng Huang and Chenlei Fang and Soumya Mittal and R. D. (Shawn) Blanton},
  doi          = {10.1145/3398267},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {43:1–20},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Towards smarter diagnosis: A learning-based diagnostic outcome previewer},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning approach for fast electromigration aware
aging prediction in incremental design of large scale on-chip power grid
network. <em>TODAES</em>, <em>25</em>(5), 42:1–29. (<a
href="https://doi.org/10.1145/3399677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of technology nodes, Electromigration (EM) signoff has become increasingly difficult, which requires a considerable amount of time for an incremental change in the power grid (PG) network design in a chip. The traditional Black’s empirical equation and Blech’s criterion are still used for EM assessment, which is a time-consuming process. In this article, for the first time, we propose a machine learning (ML) approach to obtain the EM-aware aging prediction of the PG network. We use neural network--based regression as our core ML technique to instantly predict the lifetime of a perturbed PG network. The performance and accuracy of the proposed model using neural network are compared with the well-known standard regression models. We also propose a new failure criterion based on which the EM-aging prediction is done. Potential EM-affected metal segments of the PG network is detected by using a logistic-regression--based classification ML technique. Experiments on different standard PG benchmarks show a significant speedup for our ML model compared to the state-of-the-art models. The predicted value of MTTF for different PG benchmarks using our approach is also better than some of the state-of-the-art MTTF prediction models and comparable to the other accurate models.},
  archive      = {J_TODAES},
  author       = {Sukanta Dey and Sukumar Nandi and Gaurav Trivedi},
  doi          = {10.1145/3399677},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {42:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning approach for fast electromigration aware aging prediction in incremental design of large scale on-chip power grid network},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NeuPow: A CAD methodology for high-level power estimation
based on machine learning. <em>TODAES</em>, <em>25</em>(5), 41:1–29. (<a
href="https://doi.org/10.1145/3388141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new, simple, accurate, and fast power estimation technique that can be used to explore the power consumption of digital system designs at an early design stage. We exploit the machine learning techniques to aid the designers in exploring the design space of possible architectural solutions, and more specifically, their dynamic power consumption, which is application-, technology-, frequency-, and data-stimuli dependent. To model the power and the behavior of digital components, we adopt the Artificial Neural Networks (ANNs), while the final target technology is Application Specific Integrated Circuit (ASIC). The main characteristic of the proposed method, called NeuPow, is that it relies on propagating the signals throughout connected ANN models to predict the power consumption of a composite system. Besides a baseline version of the NeuPow methodology that works for a given predefined operating frequency, we also derive an upgraded version that is frequency-aware, where the same operating frequency is taken as additional input by the ANN models. To prove the effectiveness of the proposed methodology, we perform different assessments at different levels. Moreover, technology and scalability studies have been conducted, proving the NeuPow robustness in terms of these design parameters. Results show a very good estimation accuracy with less than 9\% of relative error independently from the technology and the size/layers of the design. NeuPow is also delivering a speed-up factor of about 84× with respect to the classical power estimation flow.},
  archive      = {J_TODAES},
  author       = {Yehya Nasser and Carlo Sau and Jean-Christophe Prévotet and Tiziana Fanni and Francesca Palumbo and Maryline Hélard and Luigi Raffo},
  doi          = {10.1145/3388141},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {41:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {NeuPow: A CAD methodology for high-level power estimation based on machine learning},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PREASC: Automatic portion resilience evaluation for
approximating SystemC-based designs using regression analysis
techniques. <em>TODAES</em>, <em>25</em>(5), 40:1–28. (<a
href="https://doi.org/10.1145/3388140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing functionality of electronic systems due to the constant evolution of the market requirements makes the non-functional aspects of such systems (e.g., energy consumption, area overhead, or performance) a major concern in the design process. Approximate computing is a promising way to optimize these criteria by trading accuracy within acceptable limits. Since the cost of applying significant structural changes to a given design increases with the stage of development, the optimization solution needs to be incorporated into the design as early as possible. For the early design entry, modeling hardware at the Electronic System Level (ESL) using the SystemC language is nowadays widely used in the industry. To apply approximation techniques to optimize a given SystemC design, designers need to know which parts of the design can be approximated. However, identifying these parts is a crucial and non-trivial starting point of approximate computing, as the incorrect detection of even one critical part as resilient may result in an unacceptable output. This usually requires a significant programming effort by designers, especially when exploring the design space manually. In this article, we present PREASC, a fully automated framework to identify the resilience portions of a given SystemC design. PREASC is based on a combination of static and dynamic analysis methods along with regression analysis techniques (a fast machine learning method providing an accurate function estimation). Once the resilient portions are identified, an approximation degree analysis is performed to determine the maximum error rate that each resilient portion can tolerate. Subsequently, the maximum number of resilient portions that can be approximated at the same time are reported to designers at different granularity levels. The effectiveness of our approach is evaluated using several standard SystemC benchmarks from various domains.},
  archive      = {J_TODAES},
  author       = {Mehran Goli and Rolf Drechsler},
  doi          = {10.1145/3388140},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {40:1–28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {PREASC: Automatic portion resilience evaluation for approximating SystemC-based designs using regression analysis techniques},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting memory compiler performance outputs using
feed-forward neural networks. <em>TODAES</em>, <em>25</em>(5), 39:1–19.
(<a href="https://doi.org/10.1145/3385262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical semiconductor chips include thousands of mostly small memories. As memories contribute an estimated 25\% to 40\% to the overall power, performance, and area (PPA) of a product, memories must be designed carefully to meet the system’s requirements. Memory arrays are highly uniform and can be described by approximately 10 parameters depending mostly on the complexity of the periphery. Thus, to improve PPA utilization, memories are typically generated by memory compilers. A key task in the design flow of a chip is to find optimal memory compiler parametrizations that, on the one hand, fulfill system requirements while, on the other hand, they optimize PPA. Although most compiler vendors also provide optimizers for this task, these are often slow or inaccurate. To enable efficient optimization in spite of long compiler runtimes, we propose training fully connected feed-forward neural networks to predict PPA outputs given a memory compiler parametrization. Using an exhaustive search-based optimizer framework that obtains neural network predictions, PPA-optimal parametrizations are found within seconds after chip designers have specified their requirements. Average model prediction errors of less than 3\%, a decision reliability of over 99\%, and productive usage of the optimizer for successful, large volume chip design projects illustrate the effectiveness of the approach.},
  archive      = {J_TODAES},
  author       = {Felix Last and Max Haeberlein and Ulf Schlichtmann},
  doi          = {10.1145/3385262},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {39:1–19},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Predicting memory compiler performance outputs using feed-forward neural networks},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fine-grained adaptive testing based on quality prediction.
<em>TODAES</em>, <em>25</em>(5), 38:1–25. (<a
href="https://doi.org/10.1145/3385261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing complexity of integrated circuits inevitably leads to high test cost. Adaptive testing provides an effective solution for test-cost reduction; this testing framework selects the important test items for each set of chips. However, adaptive testing methods designed for digital circuits are coarse-grained, and they are targeted only at systematic defects. To incorporate fabrication variations and random defects in the testing framework, we propose a fine-grained adaptive testing method based on machine learning. We use the parametric test results from the previous stages of test to train a quality-prediction model for use in subsequent test stages. Next, we partition a given lot of chips into two groups based on their predicted quality. A test-selection method based on statistical learning is applied to the chips with high predicted quality. An ad hoc test-selection method is proposed and applied to the chips with low predicted quality. Experimental results using a large number of fabricated chips and the associated test data show that to achieve the same defect level as in prior work on adaptive testing, the fine-grained adaptive testing method reduces test cost by 90\% for low-quality chips and up to 7\% for all the chips in a lot.},
  archive      = {J_TODAES},
  author       = {Mengyun Liu and Renjian Pan and Fangming Ye and Xin Li and Krishnendu Chakrabarty and Xinli Gu},
  doi          = {10.1145/3385261},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {38:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Fine-grained adaptive testing based on quality prediction},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning for congestion management and routability
prediction within FPGA placement. <em>TODAES</em>, <em>25</em>(5),
37:1–25. (<a href="https://doi.org/10.1145/3373269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Placement for Field Programmable Gate Arrays (FPGAs) is one of the most important but time-consuming steps for achieving design closure. This article proposes the integration of three unique machine learning models into the state-of-the-art analytic placement tool GPlace3.0 with the aim of significantly reducing placement runtimes. The first model, MLCong, is based on linear regression and replaces the computationally expensive global router currently used in GPlace3.0 to estimate switch-level congestion. The second model, DLManage, is a convolutional encoder-decoder that uses heat maps based on the switch-level congestion estimates produced by MLCong to dynamically determine the amount of inflation to apply to each switch to resolve congestion. The third model, DLRoute, is a convolutional neural network that uses the previous heat maps to predict whether or not a placement solution is routable. Once a placement solution is determined to be routable, further optimization may be avoided, leading to improved runtimes. Experimental results obtained using 372 benchmarks provided by Xilinx Inc. show that when all three models are integrated into GPlace3.0, placement runtimes decrease by an average of 48\%.},
  archive      = {J_TODAES},
  author       = {Hannah Szentimrey and Abeer Al-Hyari and Jeremy Foxcroft and Timothy Martin and David Noel and Gary Grewal and Shawki Areibi},
  doi          = {10.1145/3373269},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {37:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning for congestion management and routability prediction within FPGA placement},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introduction to the special issue on machine learning for
CAD. <em>TODAES</em>, <em>25</em>(5), 36:1–2. (<a
href="https://doi.org/10.1145/3410864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_TODAES},
  author       = {Jörg Henkel and Hussam Amrouch and Marilyn Wolf},
  doi          = {10.1145/3410864},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {5},
  pages        = {36:1–2},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Introduction to the special issue on machine learning for CAD},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Soft-HaT: Software-based silicon reprogramming for hardware
trojan implementation. <em>TODAES</em>, <em>25</em>(4), 35:1–22. (<a
href="https://doi.org/10.1145/3396521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hardware Trojan is a malicious modification to an integrated circuit (IC) made by untrusted third-party vendors, fabrication facilities, or rogue designers. Although existing hardware Trojans are designed to be stealthy, they can, in theory, be detected by post-manufacturing and acceptance tests due to their physical connections to IC logic. Manufacturing tests can potentially trigger the Trojan and propagate its payload to an output. Even if the Trojan is not triggered, the physical connections to the IC can enable detection due to additional side-channel activity (e.g., power consumption). In this article, we propose a novel hardware Trojan design, called Soft-HaT , which only becomes physically connected to other IC logic after activation by a software program. Using an electrically programmable fuse (E-fuse), the hardware can be “re-programmed” remotely. We illustrate how Soft-HaT can be used for offensive applications in system-on-chips. Examples of Soft-HaT attacks are demonstrated on an open source system-on-chip (OrpSoC) and implemented in Virtex-7 FPGA to show their efficacy in terms of stealthiness.},
  archive      = {J_TODAES},
  author       = {Md Mahbub Alam and Adib Nahiyan and Mehdi Sadi and Domenic Forte and Mark Tehranipoor},
  doi          = {10.1145/3396521},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {35:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Soft-HaT: Software-based silicon reprogramming for hardware trojan implementation},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strong logic obfuscation with low overhead against IC
reverse engineering attacks. <em>TODAES</em>, <em>25</em>(4), 34:1–31.
(<a href="https://doi.org/10.1145/3398012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Untrusted foundries pose threats of integrated circuit (IC) piracy and counterfeiting, and this has motivated research into logic locking. Strong logic locking approaches potentially prevent piracy and counterfeiting by preventing unauthorized replication and use of ICs. Unfortunately, recent work has shown that most state-of-the-art logic locking techniques are vulnerable to attacks that utilize Boolean Satisfiability (SAT) solvers. In this article, we extend our prior work on using silicon nanowire (SiNW) field-effect transistors (FETs) to produce obfuscated ICs that are resistant to reverse engineering attacks, such as the sensitization attack, SAT and approximate SAT attacks, as well as tracked signal attacks. Our method is based on exchanging some logic gates in the original design with a set of polymorphic gates (PLGs), designed using SiNW FETs, and augmenting the circuit with a small block, whose output is untraceable, namely, URSAT. The URSAT may not offer very strong resilience against the combined AppSAT-removal attack. Strong URSAT is achieved using only CMOS-logic gates, namely, S-URSAT. The proposed technique, S-URSAT + PLG-based traditional encryption, designed using SiNW FETs, increases the security level of the design to robustly thwart all existing attacks, including combined AppSAT-removal attack, with small penalties. Then, we evaluate the effectiveness of our proposed methods and subject it to a thorough security analysis. We also evaluate the performance penalty of the technique and find that it results in very small overheads in comparison to other works. The average area, power, and delay overheads of implementing 64 baseline key-bits of S-URSAT for small benchmarks are 5.03\%, 2.60\%, and −2.26\%, respectively, while for large benchmarks they are 2.37\%, 1.18\%, and −1.93\%.},
  archive      = {J_TODAES},
  author       = {Qutaiba Alasad and Jiann-Shuin Yuan and Pramod Subramanyan},
  doi          = {10.1145/3398012},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {34:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Strong logic obfuscation with low overhead against IC reverse engineering attacks},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Runtime identification of hardware trojans by feature
analysis on gate-level unstructured data and anomaly detection.
<em>TODAES</em>, <em>25</em>(4), 33:1–23. (<a
href="https://doi.org/10.1145/3391890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the globalization of chip design and manufacturing process becomes popular, malicious hardware inclusions such as hardware Trojans pose a serious threat to the security of digital systems. Advanced Trojans can mask many architectural-level Trojan signatures and adapt against several detection mechanisms. Runtime Trojan detection techniques are considered as a last line of defense against Trojan inclusion and activation. In this article, we propose an offline analysis to select a subset of flip-flops as surrogates and build an anomaly detection model based on the activity profile of flip-flops. These flip-flops are monitored online, and the anomaly detection model implemented online analyzes the flip-flop data to detect any anomalous Trojan activity. The effectiveness of our approach has been tested on several Trojan-inserted designs of the Leon3 processor. Trojan activation is detected with an accuracy score of above 0.9 (ratio of the number of true predictions to total number of predictions) with no false positives by monitoring less than 0.5\% of the total number of flip-flops.},
  archive      = {J_TODAES},
  author       = {Arunkumar Vijayan and Mehdi B. Tahoori and Krishnendu Chakrabarty},
  doi          = {10.1145/3391890},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {33:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Runtime identification of hardware trojans by feature analysis on gate-level unstructured data and anomaly detection},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning assisted PUF calibration for trustworthy
proof of sensor data in IoT. <em>TODAES</em>, <em>25</em>(4), 32:1–21.
(<a href="https://doi.org/10.1145/3393628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote integrity verification plays a paramount role in resource-constraint devices owing to emerging applications such as Internet-of-Things (IoT), smart homes, e-health, and so on. The concept of Virtual Proof of Reality (VPoR) proposed by Rührmair et al. in 2015 has come up with a Sense-Prove-Validate framework for integrity checking of abundant data generated from billions of connected sensors. It leverages the unreliability factor of Physically Unclonable Functions (PUFs) with respect to ambient parameter variations such as temperature, supply voltages, and so on, and claims to prove the authenticity of the sensor data without using any explicit keys. The state-of-the-art authenticated sensing protocols majorly lack in limited authentications and huge storage overhead. These protocols also assume that the behaviour of the PUF instances varies unpredictably for different levels of ambient factors, which in turn makes them hard to go beyond the theoretical concept. We address these issues in this work 1 and propose a Machine Learning (ML) assisted PUF calibration scheme to predict the Challenge-Response Pair (CRP) behaviour of a PUF instance in a specific environment, given the CRP behaviour in a pivot environment. Here, we present a new class of authenticated sensing protocols where we leverage the beneficence of ML techniques to validate the authenticity and integrity of sensor data over ambient factor variations. The scheme also reduces the storage complexity of the verifier from O ( p * K * l * ( c + r )) to O ( p * l *( c + r )), where p is the number of PUF instances deployed in the framework, l is the number of challenge-response pairs used for authentication, c is the bit lengths of the challenge, r is the response bits of the PUF, and K is the number of levels of ambient factor variations. The scheme alleviates the issue of limited authentication as well, whereby every CRP is used only once for authentication and then deleted from the database. To validate the proposed protocol through actual experiments on FPGA, we propose 5-4 Double Arbiter PUF, which is an extension of Double Arbiter PUFs (DAPUFs) as this design is more suited for FPGA, and implement it on Xilinx Artix-7 FPGAs. We characterise the proposed PUF instance from −20° C to 80° C and use Random Forest --based ML technique to generate a soft model of the PUF instance. This model is further used by the verifier to authenticate the actual PUF circuit. According to the FPGA-based validation, the proposed protocol with DAPUF can be effectively used to authenticate sensor devices across wide variations of temperature values.},
  archive      = {J_TODAES},
  author       = {Urbi Chatterjee and Soumi Chatterjee and Debdeep Mukhopadhyay and Rajat Subhra Chakraborty},
  doi          = {10.1145/3393628},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {32:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Machine learning assisted PUF calibration for trustworthy proof of sensor data in IoT},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hierarchical HVAC control scheme for energy-aware smart
building automation. <em>TODAES</em>, <em>25</em>(4), 31:1–33. (<a
href="https://doi.org/10.1145/3393666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heating ventilation and air conditioning (HVAC) systems usually account for the highest percentage of overall energy usage in large-sized smart building infrastructures. The performance of HVAC control systems for large buildings strongly depend on the outside environment, building architecture, and (thermal) zone usage pattern of the building. In large buildings, HVAC system with multiple air handling units (AHUs) is required to fulfill the cooling/heating requirements. In the present work, we propose an energy-aware building resource allocation and economic model predictive control (eMPC) framework for multi-AHU-based HVAC system. The energy consumption of a multi-AHU-based HVAC system significantly depends on how long the AHUs are running, which again is governed by the zone usage demands. Our approach comprises a two-step hierarchical technique where we first minimize the running time of AHUs by suitably allocating building resources (thermal zones) to usage demands for zones. Next, we formulate a finite receding horizon control problem for trading off energy consumption against thermal comfort during HVAC operations. Given a high-level building specification and usage demand, our computer-aided design framework generates building thermal models, allocates usage demands, formulates the control scheme, and simulates it to generate power consumption statistics for the given building with usage demands. We believe that the proposed framework will help in early analysis during the design phase of energy-aware building architecture and HVAC control. The framework can also be useful from a building operator point of view for energy-aware HVAC control as well as for satisfying smart grid demand-response events by HVAC system peak power reduction through automated control actions.},
  archive      = {J_TODAES},
  author       = {Rajib Lochan Jana and Soumyajit Dey and Pallab Dasgupta},
  doi          = {10.1145/3393666},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {31:1–33},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A hierarchical HVAC control scheme for energy-aware smart building automation},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating representative test sequences from real workload
for minimizing DRAM verification overhead. <em>TODAES</em>,
<em>25</em>(4), 30:1–23. (<a
href="https://doi.org/10.1145/3391891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Random Access Memory (DRAM) standards have evolved for higher bandwidth, larger capacity, and lower power consumption, so their specifications have become complicated to satisfy the design goals. These complex implementations have significantly increased the test time overhead for design verification; thus, a tremendous amount of command sequences are used. However, since the sequences generated by real machines or memory simulators are the results of scheduling for high performance, they result in low test coverage with repetitive patterns. Eventually, various workloads should be applied to increase the coverage, but this approach incurs significant test time overhead. A few preliminary studies have been proposed to generate predefined or random sequences to cover various test cases or increase test coverage. However, they have limitations in representing various memory behaviors of real workloads. In this article, we define a performance metric for estimating the test coverage when using command sequences. Then, our experiment shows that the coverage of a real machine and a simulator is low and similar. Also, the coverage patterns are almost the same in all tested benchmarks. To alleviate the problem, we propose a test-oriented command scheduling algorithm that increases the test coverage while preserving the memory behaviors of workloads and reducing the test time overhead by extracting representative sequences based on the similarity between command sequences. For the sequence extraction and the coverage estimation, our test sequences are embedded into vectors using bag-of-Ngrams. Compared to the simulator, our algorithm achieves 2.94x higher coverage while reducing the test overhead to 7.57\%.},
  archive      = {J_TODAES},
  author       = {Yoonah Paik and Seon Wook Kim and Dongha Jung and Minseong Kim},
  doi          = {10.1145/3391891},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {4},
  pages        = {30:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Generating representative test sequences from real workload for minimizing DRAM verification overhead},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithmic fault detection for RRAM-based matrix
operations. <em>TODAES</em>, <em>25</em>(3), 29:1–31. (<a
href="https://doi.org/10.1145/3386360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An RRAM-based computing system (RCS) provides an energy-efficient hardware implementation of vector-matrix multiplication for machine-learning hardware. However, it is vulnerable to faults due to the immature RRAM fabrication process. We propose an efficient fault tolerance method for RCS; the proposed method, referred to as extended-ABFT (X-ABFT), is inspired by algorithm-based fault tolerance (ABFT). We utilize row checksums and test-input vectors to extract signatures for fault detection and error correction. We present a solution to alleviate the overflow problem caused by the limited number of voltage levels for the test-input signals. Simulation results show that for a Hopfield classifier with faults in 5\% of its RRAM cells, X-ABFT allows us to achieve nearly the same classification accuracy as in the fault-free case.},
  archive      = {J_TODAES},
  author       = {Mengyun Liu and Lixue Xia and Yu Wang and Krishnendu Chakrabarty},
  doi          = {10.1145/3386360},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {29:1–31},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Algorithmic fault detection for RRAM-based matrix operations},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An energy-aware online learning framework for resource
management in heterogeneous platforms. <em>TODAES</em>, <em>25</em>(3),
28:1–26. (<a href="https://doi.org/10.1145/3386359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile platforms must satisfy the contradictory requirements of fast response time and minimum energy consumption as a function of dynamically changing applications. To address this need, systems-on-chip (SoC) that are at the heart of these devices provide a variety of control knobs, such as the number of active cores and their voltage/frequency levels. Controlling these knobs optimally at runtime is challenging for two reasons. First, the large configuration space prohibits exhaustive solutions. Second, control policies designed offline are at best sub-optimal, since many potential new applications are unknown at design-time. We address these challenges by proposing an online imitation learning approach. Our key idea is to construct an offline policy and adapt it online to new applications to optimize a given metric (e.g., energy). The proposed methodology leverages the supervision enabled by power-performance models learned at runtime. We demonstrate its effectiveness on a commercial mobile platform with 16 diverse benchmarks. Our approach successfully adapts the control policy to an unknown application after executing less than 25\% of its instructions.},
  archive      = {J_TODAES},
  author       = {Sumit K. Mandal and Ganapati Bhat and Janardhan Rao Doppa and Partha Pratim Pande and Umit Y. Ogras},
  doi          = {10.1145/3386359},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {28:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {An energy-aware online learning framework for resource management in heterogeneous platforms},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security of microfluidic biochip: Practical attacks and
countermeasures. <em>TODAES</em>, <em>25</em>(3), 27:1–29. (<a
href="https://doi.org/10.1145/3382127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of system miniaturization and automation, Lab-on-a-Chip (LoC) technology has revolutionized traditional experimental procedures. Microfluidic Biochip (MFB) is an emerging branch of LoC with wide medical applications such as DNA sequencing, drug delivery, and point of care diagnostics. Due to the critical usage of MFBs, their security is of great importance. In this article, we exploit the vulnerabilities of two types of MFBs: Flow-based Microfluidic Biochip (FMFB) and Digital Microfluidic Biochip (DMFB). We propose a systematic framework for applying Reverse Engineering (RE) attacks and Hardware Trojan (HT) attacks on MFBs as well as for practical countermeasures against the proposed attacks. We evaluate the attacks and defense on various benchmarks where experimental results prove the effectiveness of our methods. Security metrics are defined to quantify the vulnerability of MFBs. The overhead and performance of the proposed attacks as well as countermeasures are also discussed.},
  archive      = {J_TODAES},
  author       = {Huili Chen and Seetal Potluri and Farinaz Koushanfar},
  doi          = {10.1145/3382127},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {27:1–29},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Security of microfluidic biochip: Practical attacks and countermeasures},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SCRIPT: A CAD framework for power side-channel vulnerability
assessment using information flow tracking and pattern generation.
<em>TODAES</em>, <em>25</em>(3), 26:1–27. (<a
href="https://doi.org/10.1145/3383445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power side-channel attacks (SCAs) have been proven to be effective at extracting secret keys from hardware implementations of cryptographic algorithms. Ideally, the power side-channel leakage (PSCL) of hardware designs of a cryptographic algorithm should be evaluated as early as the pre-silicon stage (e.g., gate level). However, there has been little effort in developing computer-aided design (CAD) tools to accomplish this. In this article, we propose an automated CAD framework called SCRIPT to evaluate information leakage through side-channel analysis. SCRIPT starts by defining the underlying properties of the hardware implementation that can be exploited by side-channel attacks. It then utilizes information flow tracking (IFT) to identify registers that exhibit those properties and, therefore, leak information through the side-channel. Here, we develop an IFT-based side-channel vulnerability metric ( SCV ) that is utilized by SCRIPT for PSCL assessment. SCV is conceptually similar to the traditionally used signal-to-noise ratio (SNR) metric. However, unlike SNR, which requires thousands of traces from silicon measurements, SCRIPT utilizes formal methods to generate SCV-guided patterns/plaintexts, allowing us to derive SCV using only a few patterns (ideally as low as two) at gate level. SCV estimates PSCL vulnerability at pre-silicon stage based on the number of plaintexts required to attain a specific SCA success rate. The integration of IFT and pattern generation makes SCRIPT efficient, accurate, and generic to be applied to any hardware design. We validate the efficacy of the SCRIPT framework by demonstrating that it can effectively and accurately determine SCA success rates for different AES designs at pre-silicon stage. SCRIPT is orders of magnitude more efficient than traditional pre-silicon PSCL assessment (SNR-based), with an average evaluation time of 15 minutes; whereas, traditional PSCL assessment at pre-silicon stage would require more than a month. We also analyze the PSCL characteristic of the multiplication unit of RISC processor using SCRIPT to demonstrate SCRIPT’s applicability.},
  archive      = {J_TODAES},
  author       = {Adib Nahiyan and Jungmin Park and Miao He and Yousef Iskander and Farimah Farahmandi and Domenic Forte and Mark Tehranipoor},
  doi          = {10.1145/3383445},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {26:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {SCRIPT: A CAD framework for power side-channel vulnerability assessment using information flow tracking and pattern generation},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Architectural design of flow-based microfluidic biochips for
multi-target dilution of biochemical fluids. <em>TODAES</em>,
<em>25</em>(3), 25:1–34. (<a
href="https://doi.org/10.1145/3357604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microfluidic technologies enable replacement of time-consuming and complex steps of biochemical laboratory protocols with a tiny chip. Sample preparation (i.e., dilution or mixing of fluids) is one of the primary tasks of any bioprotocol. In real-life applications where several assays need to be executed for different diagnostic purposes, the same sample fluid is often required with different target concentration factors ( CF s). Although several multi-target dilution algorithms have been developed for digital microfluidic biochips, they are not efficient for implementation with continuous-flow-based microfluidic chips, which are preferred in the laboratories. In this article, we present a multi-target dilution algorithm ( MTDA ) for continuous-flow-based microfluidic biochips, which to the best of our knowledge is the first of its kind. We design a flow-based rotary mixer with a suitable number of segments depending on the target- CF profile, error tolerance, and optimization criteria. To schedule several intermediate fluid-mixing tasks, we develop a multi-target scheduling algorithm ( MTSA ) aiming to minimize the usage of storage units while producing dilutions with multiple CF s. Furthermore, we propose a storage architecture for efficiently loading (storing) of intermediate fluids from (to) the storage units.},
  archive      = {J_TODAES},
  author       = {Nishant Kamal and Ankur Gupta and Ananya Singla and Shubham Tiwari and Parth Kohli and Sudip Roy and Bhargab B. Bhattacharya},
  doi          = {10.1145/3357604},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {25:1–34},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Architectural design of flow-based microfluidic biochips for multi-target dilution of biochemical fluids},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reuse distance-based victim cache for effective utilisation
of hybrid main memory system. <em>TODAES</em>, <em>25</em>(3), 24:1–32.
(<a href="https://doi.org/10.1145/3380732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid main memories comprising DRAM and Non-volatile memories (NVM) are projected as potential replacements of the traditional DRAM-based memories. However, traditional cache management policies designed for improving the hit rate lack awareness of the comparative latency of read-write for NVM blocks where the write latency is more than the read latency. Therefore, developing cache management techniques that reduce costly write-backs of the NVM blocks, yet maintain a fair hit rate in the cache, is of paramount importance. We propose two techniques based on the use of a small victim cache associated with the last-level cache that helps in retaining on the chip critical DRAM and NVM blocks. Victim cache being a scarce resource, we intend to keep only performance-critical blocks in the victim cache by exploiting the idea of reuse distance. The first technique, Victim Cache Replacement Policy, works on the replacement policy of the victim cache by preferential eviction of DRAM blocks over NVM blocks. However, the second technique, Prioritized Partitioning of victim cache, logically partitions the victim cache, giving a smaller share to the DRAM blocks and a relatively larger share to the NVM blocks. Experimental evaluation on full-system simulator shows significant improvement in system performance and reduction in the number of write-backs to the NVM partition of the main memory compared to the baseline and existing technique. Additionally, NVM reads and DRAM miss rate are also improved, leading to further performance enhancement.},
  archive      = {J_TODAES},
  author       = {Arijit Nath and Sukarn Agarwal and Hemangee K. Kapoor},
  doi          = {10.1145/3380732},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {3},
  pages        = {24:1–32},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Reuse distance-based victim cache for effective utilisation of hybrid main memory system},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On fundamental principles for thermal-aware design on
periodic real-time multi-core systems. <em>TODAES</em>, <em>25</em>(2),
23:1–23. (<a href="https://doi.org/10.1145/3378063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the exponential rise of the transistor count in one chip, the thermal problem has become a pressing issue in computing system design. While there have been extensive methods and techniques published for design optimization with thermal awareness, there is a need for more rigorous and formal thermal analysis in designing real-time systems and applications that demand a strong exception guarantee. In this article, we analytically prove a series of fundamental properties and principles concerning the RC thermal model, peak temperature identification, and peak temperature reduction for periodic real-time systems, which are general enough to be applied on 2D and 3D multi-core platforms. These findings enhance the worst-case temperature predictability in runtime scenarios, as well as help to develop more effective thermal management policy, which is key to thermal-constrained periodic real-time system design.},
  archive      = {J_TODAES},
  author       = {Shi Sha and Ajinkya S. Bankar and Xiaokun Yang and Wujie Wen and Gang Quan},
  doi          = {10.1145/3378063},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {23:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {On fundamental principles for thermal-aware design on periodic real-time multi-core systems},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single-layer obstacle-aware substrate routing via iterative
pin reassignment and wire assignment. <em>TODAES</em>, <em>25</em>(2),
22:1–21. (<a href="https://doi.org/10.1145/3378162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that single-layer obstacle-aware substrate routing is necessary for modern IC/Package designs. In this article, given a set of two-pin nets and a set of rectangular obstacles inside a single-layer routing plane, a two-phase routing algorithm including an iterative routing phase and a rip-up-and-reroute phase can be proposed to maximize the number of the routed nets in single-layer obstacle-aware substrate routing. In the iterative routing phase, based on the pin and path distribution of the routing nets and the locations of the obstacles inside a single-layer routing plane, the start or target pins on some routing nets inside dense obstacle regions may be firstly reassigned to complete the partial wiring paths on the nets. Based on the region extraction of two intersected nets in single-layer routing, the private regions of some routing nets inside sparse obstacle regions can be extracted and the nets inside the extracted regions can be further routed by using maze routing. In the rip-up-and-reroute phase, the routability of the routing nets can be improved by ripping up some routed nets and rerouting the unrouted nets. Compared with Liu&#39;s modified algorithm and Yan&#39;s flow-based algorithm in single-layer obstacle-aware substrate routing, the experimental results show that the proposed algorithm can use less CPU time to increase 3.4\% and 1.8\% of the routability on the routing nets for eight tested examples on the average. Additionally, the percentage of the tested examples with the 100\% routability of the routing nets on the eight tested examples has been improved from 25\% to 62.5\%.},
  archive      = {J_TODAES},
  author       = {Jin-Tai Yan},
  doi          = {10.1145/3378162},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {22:1–21},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Single-layer obstacle-aware substrate routing via iterative pin reassignment and wire assignment},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lagrangian relaxation-based time-division multiplexing
optimization for multi-FPGA systems. <em>TODAES</em>, <em>25</em>(2),
21:1–23. (<a href="https://doi.org/10.1145/3377551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To increase the resource utilization in multi-FPGA (field-programmable gate array) systems, time-division multiplexing (TDM) is a widely used technique to accommodate a large number of inter-FPGA signals. However, with this technique, the delay imposed by the inter-FPGA connections becomes significant. Previous research has shown that the TDM ratios of signals can greatly affect the performance of a system. In this article, to minimize the system clock period and support more practical constraints in modern multi-FPGA systems, we propose an analytical framework to optimize the TDM ratios of inter-FPGA nets. A Lagrangian relaxation-based method first gives a continuous result under relaxed constraints. A binary search--based discretization algorithm is then used to assign the TDM ratio of each net such that the resulting maximum displacement is optimal and all the constraints are satisfied. Finally, a swapping-based post refinement is performed to further optimize the TDM ratios. For comparison, we also solve the problem using linear programming (LP)--based methods, which have guaranteed error bounds to the optimal solutions. Experimental results show that our framework can achieve similar quality with much shorter runtime compared to the LP-based methods. Moreover, our framework scales for designs with over 45,000 inter-FPGA nets while the runtime and memory usage of the LP-based methods will increase dramatically as the design scale becomes larger.},
  archive      = {J_TODAES},
  author       = {Chak-Wa Pui and Evangeline F. Y. Young},
  doi          = {10.1145/3377551},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {21:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Lagrangian relaxation-based time-division multiplexing optimization for multi-FPGA systems},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How secure is split manufacturing in preventing hardware
trojan? <em>TODAES</em>, <em>25</em>(2), 20:1–23. (<a
href="https://doi.org/10.1145/3378163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the trend of outsourcing fabrication, split manufacturing is regarded as a promising way to both acquire the high-end nodes in untrusted external foundries and protect the design from potential attackers. However, in this article, we show that split manufacturing is not inherently secure, that a hardware Trojan attacker can still recover necessary information with a proximity-based or a simulated-annealing-based mapping approach together with a probability-based or net-based pruning method at the placement level. We further propose a defense approach by moving the insecure gates away from their easily attacked candidate locations. Results on benchmark circuits show the effectiveness of our proposed methods.},
  archive      = {J_TODAES},
  author       = {Yajun Yang and Zhang Chen and Yuan Liu and Tsung-Yi Ho and Yier Jin and Pingqiang Zhou},
  doi          = {10.1145/3378163},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {20:1–23},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {How secure is split manufacturing in preventing hardware trojan?},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tunable FPGA bitstream obfuscation with boolean
satisfiability attack countermeasure. <em>TODAES</em>, <em>25</em>(2),
19:1–22. (<a href="https://doi.org/10.1145/3373638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field Programmable Gate Arrays (FPGAs) are seeing a surge in usage in many emerging application domains, where the in-field reconfigurability is an attractive characteristic for diverse applications with dynamic design requirements, such as cloud computing, automotive, IoT, and aerospace. The security of the FPGA configuration file, or bitstream , is critical, especially for devices with long in-field lifetimes, where attackers may attempt to extract valuable Intellectual Property (IP) from within. In this article, we propose a tunable obfuscation approach that protects IP from typical bitstream attacks while enabling designers to trade off security with acceptable overhead. We also consider two potential attacks on this protection mechanism: Boolean SAT Attacks on the obfuscation and removal attacks on the protection circuitry. The obfuscation and SAT countermeasure are integrated in a custom CAD framework within a commercial FPGA toolflow and together provide mathematically strong protection against common bitstream attacks. Further, we quantify the difficulty of a removal attack on the protection circuitry through pattern matching and direct bitstream manipulation. The average area, power, and delay overhead for obfuscation with 95\% mismatch probability are 18\%, 16\%, and 8\%, respectively, for small combinational circuits, and 1\%, 2\%, and 5\% for larger arithmetic modules.},
  archive      = {J_TODAES},
  author       = {Brooks Olney and Robert Karam},
  doi          = {10.1145/3373638},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {19:1–22},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Tunable FPGA bitstream obfuscation with boolean satisfiability attack countermeasure},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Target faults for test compaction based on multicycle tests.
<em>TODAES</em>, <em>25</em>(2), 18:1–14. (<a
href="https://doi.org/10.1145/3375278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of multicycle tests, with several functional capture cycles between scan operations, contributes significantly to the ability to compact a test set. Multicycle tests have the added benefit that they can contribute to the detection of defects with complex behaviors that are not detected by single-cycle or two-cycle tests. To ensure that this benefit is materialized when test compaction is applied to transition faults, this article suggests to incorporate into the test compaction procedure an additional fault model whose fault coverage increases when multicycle tests are used. To ensure that the computational complexity of test compaction is not increased by a fault model with a large number of faults, or faults with complex behaviors, the added fault model is required to have the same characteristics as the transition fault model. A type of transition fault called unspecified transition fault satisfies these requirements. The article describes a test compaction procedure for transition faults that incorporates unspecified transition faults, and presents experimental results for benchmark circuits to demonstrate the levels of test compaction and fault coverage that can be achieved.},
  archive      = {J_TODAES},
  author       = {Irith Pomeranz},
  doi          = {10.1145/3375278},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {18:1–14},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Target faults for test compaction based on multicycle tests},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure assay execution on MEDA biochips to thwart attacks
using real-time sensing. <em>TODAES</em>, <em>25</em>(2), 17:1–25. (<a
href="https://doi.org/10.1145/3374213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital microfluidic biochips (DMFBs) have emerged as a promising platform for DNA sequencing, clinical chemistry, and point-of-care diagnostics. Recent research has shown that DMFBs are susceptible to various types of malicious attacks. Defenses proposed thus far only offer probabilistic guarantees of security due to the limitation of on-chip sensor resources. A micro-electrode-dot-array (MEDA) biochip is a next-generation DMFB that enables the real-time sensing of on-chip droplet locations, which are captured in the form of a droplet-location map. We propose a security mechanism that validates assay execution by reconstructing the sequencing graph (i.e., the assay specification) from the droplet-location maps and comparing it against the golden sequencing graph. We prove that there is a unique (one-to-one) mapping from the set of droplet-location maps (over the duration of the assay) to the set of possible sequencing graphs. Any deviation in the droplet-location maps due to an attack is detected by this countermeasure because the resulting derived sequencing graph is not isomorphic to the original sequencing graph. We highlight the strength of the security mechanism by simulating attacks on real-life bioassays. We also address the concern that the proposed mechanism may raise false alarms when some fluidic operations are executed on MEDA biochips. To avoid such false alarms, we propose an enhanced sensing technique that provides fine-grained sensing for the security mechanism.},
  archive      = {J_TODAES},
  author       = {Tung-Che Liang and Mohammed Shayan and Krishnendu Chakrabarty and Ramesh Karri},
  doi          = {10.1145/3374213},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {17:1–25},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Secure assay execution on MEDA biochips to thwart attacks using real-time sensing},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A theoretical foundation for timing synchronous systems
using asynchronous structures. <em>TODAES</em>, <em>25</em>(2), 16:1–28.
(<a href="https://doi.org/10.1145/3373355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Timing of synchronous systems is an everlasting stumbling block to the booming demands for lower power consumption and higher operation speeds in the electronics industry. This hardship is aggravated by the growing levels of variability in state-of-the-art silicon dimensions and in other beyond-CMOS technologies. Although some designers continue to strongly believe in the performance advantages of being fully synchronous, others have radically shifted toward extremely robust delay-insensitive domains. Targeting a different compromise of both performance and robustness, this article provides sufficient conditions for an asynchronous system to be able to generate the periodic signals necessary for the timing of a fully synchronous system and highlights a specific hierarchical clocking structure that with a single tunable delay satisfies these conditions. Using an asynchronous clock distribution network benefits from both the natural robustness of asynchronous structures and the advantageous performance of synchronous clocking.},
  archive      = {J_TODAES},
  author       = {Ramy N. Tadros and Peter A. Beerel},
  doi          = {10.1145/3373355},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {16:1–28},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {A theoretical foundation for timing synchronous systems using asynchronous structures},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Search-space decomposition for system-level design space
exploration of embedded systems. <em>TODAES</em>, <em>25</em>(2),
14:1–32. (<a href="https://doi.org/10.1145/3369388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of large-scale multi- and many-core platforms and the rising complexity of embedded applications have led to a significant increase in the number of implementation possibilities for a single application. Furthermore, rising demands on safe, energy-efficient, or real-time capable application execution make the problem of determining feasible implementations that are optimal with respect to such design objectives even more of a challenge. State-of-the-art Design Space Exploration (DSE) techniques for this problem demonstrably suffer from the vast and sparse search spaces posed by modern embedded systems, emphasizing the need for novel design methodologies in this field. Based on the idea of reducing problem complexity by a suitable decomposition of the system specification—in particular, by a reduction of target architecture or task mapping options—the work at hand proposes a portfolio of dynamic decomposition mechanisms that automatically decompose any system specification based on a short pre-exploration of the complete system. We present a two-phase approach consisting of (a) a set of novel data extraction and representation techniques combined with (b) a selection of filtering operations that automatically extract a decomposed system specification based on information gathered during pre-exploration. In particular, we employ heat map data structures and threshold as well as graph-partitioning filters to reduce problem complexity. The proposed decomposition procedure can seamlessly be integrated in any DSE flow, constituting a flexible extension for existing DSE approaches. Furthermore, it improves existing static decomposition techniques and other heuristics relying on information about the problem instance, since systems with irregular architectural topology or distribution of resource types can now be decomposed based on an automatic, problem-independent pre-exploration phase. We illustrate the efficiency of the proposed decomposition portfolio applied to state-of-the-art DSEs for many-core systems as well as networked embedded systems from the automotive domain. Experimental results show significant increases in optimization quality of up to 87\% within constant DSE time compared to existing approaches.},
  archive      = {J_TODAES},
  author       = {Valentina Richthammer and Fabian Fassnacht and Michael Glaß},
  doi          = {10.1145/3369388},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {2},
  pages        = {14:1–32},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Search-space decomposition for system-level design space exploration of embedded systems},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LBNoC: Design of low-latency router architecture with
lookahead bypass for network-on-chip using FPGA. <em>TODAES</em>,
<em>25</em>(1), 9:1–26. (<a
href="https://doi.org/10.1145/3365994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An FPGA-based Network-on-Chip (NoC) using a low-latency router with a look-ahead bypass (LBNoC) is discussed in this article. The proposed design targets the optimized area with improved network performance. The techniques such as single-cycle router bypass, adaptive routing module, parallel Virtual Channel (VC), and Switch allocation, combined virtual cut through and wormhole switching, have been employed in the design of the LBNoC router. The LBNoC router is parameterizable with the network topology, traffic patterns, routing algorithms, buffer depth, buffer width, number of VCs, and I/O ports being configurable. A table-based routing algorithm has been employed to support the design of custom topologies. The input buffer modules of NoC router have been mapped on the FPGA Block RAM hard blocks to utilize resources efficiently. The LBNoC architecture consumes 4.5\% and 27.1\% fewer hardware resources than the ProNoC and CONNECT NoC architectures. The average packet latency of the LBNoC NoC architecture is 30\% and 15\% lower than the CONNECT and ProNoC architectures. The LBNoC architecture is 1.15× and 1.18× faster than the ProNoC and CONNECT NoC frameworks.},
  archive      = {J_TODAES},
  author       = {Khyamling Parane and Prabhu Prasad B M and Basavaraj Talawar},
  doi          = {10.1145/3365994},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {9:1–26},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {LBNoC: Design of low-latency router architecture with lookahead bypass for network-on-chip using FPGA},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hardware trojan mitigation in pipelined MPSoCs.
<em>TODAES</em>, <em>25</em>(1), 6:1–27. (<a
href="https://doi.org/10.1145/3365578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiprocessor System-on-Chip (MPSoC) has become necessary due to the the billions of transistors available to the designer, the need for fast design turnaround times, and the power wall. Thus, present embedded systems are designed with MPSoCs, and one possible way MPSoCs can be realized is through Pipelined MPSoC (PMPSoC) architectures, which are used in applications from video surveillance to cryptosystems. Hardware Trojans (HTs) on PMPSoCs are a significant concern due to the damage caused by their stealth. An adversary could use HTs to extract secret information (data leakage) to modify functionality/data (functional modification) or make PMPSoCs deny service. In this article, we present PMPGuard, a mechanism that (1) detects the presence of hardware Trojans in Third Party Intellectual Property (3PIP) cores of PMPSoCs by continuous monitoring and testing and (2) recovers the system by switching the infected processor core with another one. We designed, implemented, and tested the system on a commercial cycle accurate multiprocessor simulation environment. Compared to the state-of-the-art system-level techniques that use Triple Modular Redundancy (TMR) and therefore incur at least 3× area and power overheads, our proposed system incurs about 2× area and 1.5× power overheads without any adverse impact on throughput.},
  archive      = {J_TODAES},
  author       = {Amin Malekpour and Roshan Ragel and Tuo Li and Haris Javaid and Aleksandar Ignjatovic and Sri Parameswaran},
  doi          = {10.1145/3365578},
  journal      = {ACM Transactions on Design Automation of Electronic Systems},
  number       = {1},
  pages        = {6:1–27},
  shortjournal = {ACM Trans. Des. Autom. Electron. Syst.},
  title        = {Hardware trojan mitigation in pipelined MPSoCs},
  volume       = {25},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
