<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---134">CSUR - 134</h2>
<ul>
<li><details>
<summary>
(2020). Design of algorithms and protocols for underwater acoustic
wireless sensor networks. <em>CSUR</em>, <em>53</em>(6), 134:1–34. (<a
href="https://doi.org/10.1145/3421763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the recent advances of wireless underwater communication and acoustic sensor devices technology, we are witnessing a surge in the exploration and exploitation of the ocean’s abundant natural resources. Accordingly, to fulfill the requirements of the exploration of the ocean, researchers have focused their work toward the design of methods and algorithms for the underwater acoustic sensor networks (UASNs). Although considerable research effort has been devoted to the development of a variety of UASN-based applications, very limited work has addressed the algorithmic design and analysis for UASN. To this end, we propose to provide a comprehensive design, development, and analysis of algorithms and protocols for UASNs. We discuss each of the fundamental UASN building blocks, such as (i) underwater acoustic communication channel modeling, (ii) sustainable coverage and target detection, (iii) Medium Access Control (MAC-layer design and time synchronization, (iv) localization algorithms design, and (v) underwater routing protocol. Then, we illustrate the different protocols from each category and compare their benefits and drawbacks. Finally, we discuss a few potential directions for future research related to the design of future generations of UASNs.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Peng Sun},
  doi          = {10.1145/3421763},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {134:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Design of algorithms and protocols for underwater acoustic wireless sensor networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDN controllers: A comprehensive analysis and performance
evaluation study. <em>CSUR</em>, <em>53</em>(6), 133:1–40. (<a
href="https://doi.org/10.1145/3421764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networks offer flexible and intelligent network operations by splitting a traditional network into a centralized control plane and a programmable data plane. The controller in the control plane is the fundamental element used to manage all operations of the data plane. Hence, the performance and capabilities of the controller itself are essential in achieving optimal performance. Furthermore, the tools used to benchmark their performance must be accurate and useful in measuring different evaluation parameters. There are dozens of controller proposals for general and specialized networks in the literature. However, there is a very limited comprehensive quantitative analysis for them. In this article, we present a comprehensive qualitative comparison of different SDN controllers, along with a quantitative analysis of their performance in different network scenarios. We categorize and classify 34 controllers and present a qualitative comparison. We also present a comparative analysis of controllers for specialized networks such as the Internet of Things, blockchain networks, vehicular networks, and wireless sensor networks. We also discuss in-depth capabilities of benchmarking tools and provide a comparative analysis of their capabilities. This work uses three benchmarking tools to compare 9 controllers and presents a detailed analysis of their performance, along with discussion on performance of specialized network controllers.},
  archive      = {J_CSUR},
  author       = {Liehuang Zhu and Md M. Karim and Kashif Sharif and Chang Xu and Fan Li and Xiaojiang Du and Mohsen Guizani},
  doi          = {10.1145/3421764},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {133:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {SDN controllers: A comprehensive analysis and performance evaluation study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementations in machine ethics: A survey. <em>CSUR</em>,
<em>53</em>(6), 132:1–38. (<a
href="https://doi.org/10.1145/3419633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasingly complex and autonomous systems require machine ethics to maximize the benefits and minimize the risks to society arising from the new technology. It is challenging to decide which type of ethical theory to employ and how to implement it effectively. This survey provides a threefold contribution. First, it introduces a trimorphic taxonomy to analyze machine ethics implementations with respect to their object (ethical theories), as well as their nontechnical and technical aspects. Second, an exhaustive selection and description of relevant works is presented. Third, applying the new taxonomy to the selected works, dominant research patterns, and lessons for the field are identified, and future directions for research are suggested.},
  archive      = {J_CSUR},
  author       = {Suzanne Tolmeijer and Markus Kneer and Cristina Sarasua and Markus Christen and Abraham Bernstein},
  doi          = {10.1145/3419633},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {132:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Implementations in machine ethics: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on IoT big data: Current status, 13 v’s challenges,
and future directions. <em>CSUR</em>, <em>53</em>(6), 131:1–59. (<a
href="https://doi.org/10.1145/3419634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.},
  archive      = {J_CSUR},
  author       = {Maggi Bansal and Inderveer Chana and Siobhán Clarke},
  doi          = {10.1145/3419634},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {131:1–59},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on IoT big data: Current status, 13 v’s challenges, and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using social media for mental health surveillance: A review.
<em>CSUR</em>, <em>53</em>(6), 129:1–31. (<a
href="https://doi.org/10.1145/3422824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data on social media contain a wealth of user information. Big data research of social media data may also support standard surveillance approaches and provide decision-makers with usable information. These data can be analyzed using Natural Language Processing (NLP) and Machine Learning (ML) techniques to detect signs of mental disorders that need attention, such as depression and suicide ideation. This article presents the recent trends and tools that are used in this field, the different means for data collection, and the current applications of ML and NLP in the surveillance of public mental health. We highlight the best practices and the challenges. Furthermore, we discuss the current gaps that need to be addressed and resolved.},
  archive      = {J_CSUR},
  author       = {Ruba Skaik and Diana Inkpen},
  doi          = {10.1145/3422824},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {129:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Using social media for mental health surveillance: A review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trust in FPGA-accelerated cloud computing. <em>CSUR</em>,
<em>53</em>(6), 128:1–28. (<a
href="https://doi.org/10.1145/3419100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Platforms combining Central Processing Systems (CPUs) with Field Programmable Gate Arrays (FPGAs) have become popular, as they promise high performance with energy efficiency. This is the result of the combination of FPGA accelerators tuned to the application, with the CPU providing the programming flexibility. Unfortunately, the security of these new platforms has received little attention: The classic software security assumption that hardware is immutable no longer holds. It is expected that attack surfaces will expand and threats will evolve, hence the trust models, and security solutions should be prepared. The attacker model should be enhanced and consider the following three basic entities as the source of threats: applications run by users, accelerators designed by third-party developers, and the cloud service providers enabling the computation on their platforms. In our work, we review current trust models and existing security assumptions and point out their shortcomings. We survey existing research that target secure remote FPGA configuration, the protection of intellectual property, and secure shared use of FPGAs. When combined, these are the foundations to build a solution for secure use of FPGAs in the cloud. In addition to analysing the existing research, we provide discussions on how to improve it and disclose various concerns that have not been addressed yet.},
  archive      = {J_CSUR},
  author       = {Furkan Turan and Ingrid Verbauwhede},
  doi          = {10.1145/3419100},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {128:1–28},
  shortjournal = {ACM Comput. Surv.},
  title        = {Trust in FPGA-accelerated cloud computing},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An overview of end-to-end entity resolution for big data.
<em>CSUR</em>, <em>53</em>(6), 127:1–42. (<a
href="https://doi.org/10.1145/3418896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most critical tasks for improving data quality and increasing the reliability of data analytics is Entity Resolution (ER), which aims to identify different descriptions that refer to the same real-world entity. Despite several decades of research, ER remains a challenging problem. In this survey, we highlight the novel aspects of resolving Big Data entities when we should satisfy more than one of the Big Data characteristics simultaneously (i.e., Volume and Velocity with Variety). We present the basic concepts, processing steps, and execution strategies that have been proposed by database, semantic Web, and machine learning communities in order to cope with the loose structuredness , extreme diversity , high speed, and large scale of entity descriptions used by real-world applications. We provide an end-to-end view of ER workflows for Big Data, critically review the pros and cons of existing methods, and conclude with the main open research directions.},
  archive      = {J_CSUR},
  author       = {Vassilis Christophides and Vasilis Efthymiou and Themis Palpanas and George Papadakis and Kostas Stefanidis},
  doi          = {10.1145/3418896},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {127:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of end-to-end entity resolution for big data},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of android malware detection with deep neural
models. <em>CSUR</em>, <em>53</em>(6), 126:1–36. (<a
href="https://doi.org/10.1145/3417978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) is a disruptive technology that has changed the landscape of cyber security research. Deep learning models have many advantages over traditional Machine Learning (ML) models, particularly when there is a large amount of data available. Android malware detection or classification qualifies as a big data problem because of the fast booming number of Android malware, the obfuscation of Android malware, and the potential protection of huge values of data assets stored on the Android devices. It seems a natural choice to apply DL on Android malware detection. However, there exist challenges for researchers and practitioners, such as choice of DL architecture, feature extraction and processing, performance evaluation, and even gathering adequate data of high quality. In this survey, we aim to address the challenges by systematically reviewing the latest progress in DL-based Android malware detection and classification. We organize the literature according to the DL architecture, including FCN, CNN, RNN, DBN, AE, and hybrid models. The goal is to reveal the research frontier, with the focus on representing code semantics for Android malware detection. We also discuss the challenges in this emerging field and provide our view of future research opportunities and directions.},
  archive      = {J_CSUR},
  author       = {Junyang Qiu and Jun Zhang and Wei Luo and Lei Pan and Surya Nepal and Yang Xiang},
  doi          = {10.1145/3417978},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {126:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of android malware detection with deep neural models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Techniques for inverted index compression. <em>CSUR</em>,
<em>53</em>(6), 125:1–36. (<a
href="https://doi.org/10.1145/3415148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data structure at the core of large-scale search engines is the inverted index , which is essentially a collection of sorted integer sequences called inverted lists . Because of the many documents indexed by such engines and stringent performance requirements imposed by the heavy load of queries, the inverted index stores billions of integers that must be searched efficiently. In this scenario, index compression is essential because it leads to a better exploitation of the computer memory hierarchy for faster query processing and, at the same time, allows reducing the number of storage machines. The aim of this article is twofold: first, surveying the encoding algorithms suitable for inverted index compression and, second, characterizing the performance of the inverted index through experimentation.},
  archive      = {J_CSUR},
  author       = {Giulio Ermanno Pibiri and Rossano Venturini},
  doi          = {10.1145/3415148},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {125:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Techniques for inverted index compression},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The node vector distance problem in complex networks.
<em>CSUR</em>, <em>53</em>(6), 124:1–27. (<a
href="https://doi.org/10.1145/3416509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a problem in complex networks we call the Node Vector Distance (NVD) problem, and we survey algorithms currently able to address it. Complex networks are a useful tool to map a non-trivial set of relationships among connected entities, or nodes. An agent—e.g., a disease—can occupy multiple nodes at the same time and can spread through the edges. The node vector distance problem is to estimate the distance traveled by the agent between two moments in time. This is closely related to the Optimal Transportation Problem (OTP), which has received attention in fields such as computer vision. OTP solutions can be used to solve the node vector distance problem, but they are not the only valid approaches. Here, we examine four classes of solutions, showing their differences and similarities both on synthetic networks and real world network data. The NVD problem has a much wider applicability than computer vision, being related to problems in economics, epidemiology, viral marketing, and sociology, to cite a few. We show how solutions to the NVD problem have a wide range of applications, and we provide a roadmap to general and computationally tractable solutions. We have implemented all methods presented in this article in a publicly available open source library, which can be used for result replication.},
  archive      = {J_CSUR},
  author       = {Michele Coscia and Andres Gomez-Lievano and James Mcnerney and Frank Neffke},
  doi          = {10.1145/3416509},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {124:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {The node vector distance problem in complex networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Languages of games and play: A systematic mapping study.
<em>CSUR</em>, <em>53</em>(6), 123:1–37. (<a
href="https://doi.org/10.1145/3412843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital games are a powerful means for creating enticing, beautiful, educational, and often highly addictive interactive experiences that impact the lives of billions of players worldwide. We explore what informs the design and construction of good games to learn how to speed-up game development. In particular, we study to what extent languages , notations , patterns, and tools , can offer experts theoretical foundations, systematic techniques, and practical solutions they need to raise their productivity and improve the quality of games and play. Despite the growing number of publications on this topic there is currently no overview describing the state-of-the-art that relates research areas, goals, and applications. As a result, efforts and successes are often one-off, lessons learned go overlooked, language reuse remains minimal, and opportunities for collaboration and synergy are lost. We present a systematic map that identifies relevant publications and gives an overview of research areas and publication venues. In addition, we categorize research perspectives along common objectives, techniques, and approaches, illustrated by summaries of selected languages. Finally, we distill challenges and opportunities for future research and development.},
  archive      = {J_CSUR},
  author       = {Riemer van Rozen},
  doi          = {10.1145/3412843},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {123:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Languages of games and play: A systematic mapping study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security and privacy in IoT using machine learning and
blockchain: Threats and countermeasures. <em>CSUR</em>, <em>53</em>(6),
122:1–37. (<a href="https://doi.org/10.1145/3417987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security and privacy of users have become significant concerns due to the involvement of the Internet of Things (IoT) devices in numerous applications. Cyber threats are growing at an explosive pace making the existing security and privacy measures inadequate. Hence, everyone on the Internet is a product for hackers. Consequently, Machine Learning (ML) algorithms are used to produce accurate outputs from large complex databases, where the generated outputs can be used to predict and detect vulnerabilities in IoT-based systems. Furthermore, Blockchain (BC) techniques are becoming popular in modern IoT applications to solve security and privacy issues. Several studies have been conducted on either ML algorithms or BC techniques. However, these studies target either security or privacy issues using ML algorithms or BC techniques, thus posing a need for a combined survey on efforts made in recent years addressing both security and privacy issues using ML algorithms and BC techniques. In this article, we provide a summary of research efforts made in the past few years, from 2008 to 2019, addressing security and privacy issues using ML algorithms and BC techniques in the IoT domain. First, we discuss and categorize various security and privacy threats reported in the past 12 years in the IoT domain. We then classify the literature on security and privacy efforts based on ML algorithms and BC techniques in the IoT domain. Finally, we identify and illuminate several challenges and future research directions using ML algorithms and BC techniques to address security and privacy issues in the IoT domain.},
  archive      = {J_CSUR},
  author       = {Nazar Waheed and Xiangjian He and Muhammad Ikram and Muhammad Usman and Saad Sajid Hashmi and Muhammad Usman},
  doi          = {10.1145/3417987},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {122:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security and privacy in IoT using machine learning and blockchain: Threats and countermeasures},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synchronous transmissions in low-power wireless: A survey of
communication protocols and network services. <em>CSUR</em>,
<em>53</em>(6), 121:1–39. (<a
href="https://doi.org/10.1145/3410159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-power wireless communication is a central building block of cyber-physical systems and the Internet of Things. Conventional low-power wireless protocols make avoiding packet collisions a cornerstone design choice. The concept of synchronous transmissions challenges this view. As collisions are not necessarily destructive, under specific circumstances, commodity low-power wireless radios are often able to receive useful information even in the presence of superimposed signals from different transmitters. We survey the growing number of protocols that exploit synchronous transmissions for higher robustness and efficiency as well as unprecedented functionality and versatility compared to conventional designs. The illustration of protocols based on synchronous transmissions is cast in a conceptional framework we establish, with the goal of highlighting differences and similarities among the proposed solutions. We conclude this article with a discussion on open questions and challenges in this research field.},
  archive      = {J_CSUR},
  author       = {Marco Zimmerling and Luca Mottola and Silvia Santini},
  doi          = {10.1145/3410159},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {121:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Synchronous transmissions in low-power wireless: A survey of communication protocols and network services},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Touch-dynamics based behavioural biometrics on mobile
devices – a review from a usability and performance perspective.
<em>CSUR</em>, <em>53</em>(6), 120:1–36. (<a
href="https://doi.org/10.1145/3394713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, there has been an exponential increase in the percentage of people owning and using a smart phone. These devices have sensor-rich touchscreens that can capture sensitive biometric features such as keystroke typing and finger-swiping patterns. Touch-dynamics based behavioural biometrics is a time-based assessment of how a user performs a particular touch task on a mobile device. Several performance-focused surveys already exist. In this article, building upon the existing reviews, we have examined studies on touch-dynamics based behavioural biometrics based on usability and its impact on authentication performance. We also emphasize the need for shifting the focus on usability during performance evaluations by presenting a consolidated list of usability and ergonomic-based factors that influence user interaction and cause performance variations. In this article, we report and review the usability evaluations: user acceptance studies and performance-based studies influencing the user interaction process on three specific touch-dynamics based modalities—signature, keystroke, and swipe. With regards to performance, we present a comparative analysis of error rates and accuracy of various research works undertaken. Additionally, we present a consolidated list of public datasets and discuss evolving vulnerabilities of touch-dynamics based behavioural biometrics, their adopted attack models, and their feasibility. Finally, we present our assessment of this domain&#39;s existing unresolved problems that could pave the way for future research.},
  archive      = {J_CSUR},
  author       = {Elakkiya Ellavarason and Richard Guest and Farzin Deravi and Raul Sanchez-Riello and Barbara Corsetti},
  doi          = {10.1145/3394713},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {120:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Touch-dynamics based behavioural biometrics on mobile devices – a review from a usability and performance perspective},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anomaly detection in road traffic using visual surveillance:
A survey. <em>CSUR</em>, <em>53</em>(6), 119:1–26. (<a
href="https://doi.org/10.1145/3417989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision has evolved in the last decade as a key technology for numerous applications replacing human supervision. Timely detection of traffic violations and abnormal behavior of pedestrians at public places through computer vision and visual surveillance can be highly effective for maintaining traffic order in cities. However, despite a handful of computer vision–based techniques proposed in recent times to understand the traffic violations or other types of on-road anomalies, no methodological survey is available that provides a detailed insight into the classification techniques, learning methods, datasets, and application contexts. Thus, this study aims to investigate the recent visual surveillance–related research on anomaly detection in public places, particularly on road. The study analyzes various vision-guided anomaly detection techniques using a generic framework such that the key technical components can be easily understood. Our survey includes definitions of related terminologies and concepts, judicious classifications of the vision-guided anomaly detection approaches, detailed analysis of anomaly detection methods including deep learning–based methods, descriptions of the relevant datasets with environmental conditions, and types of anomalies. The study also reveals vital gaps in the available datasets and anomaly detection capability in various contexts, and thus gives future directions to the computer vision–guided anomaly detection research. As anomaly detection is an important step in automatic road traffic surveillance, this survey can be a useful resource for interested researchers working on solving various issues of Intelligent Transportation Systems (ITS).},
  archive      = {J_CSUR},
  author       = {K. K. Santhosh and D. P. Dogra and P. P. Roy},
  doi          = {10.1145/3417989},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {119:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {Anomaly detection in road traffic using visual surveillance: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Patterns and interactions in network security.
<em>CSUR</em>, <em>53</em>(6), 118:1–37. (<a
href="https://doi.org/10.1145/3417988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks play a central role in cyber-security: networks deliver security attacks, suffer from them, defend against them, and sometimes even cause them. This article is a concise tutorial on the large subject of networks and security, written for all those interested in networking, whether their specialty is security or not. To achieve this goal, we derive our focus and organization from two perspectives. The first perspective is that, although mechanisms for network security are extremely diverse, they are all instances of a few patterns. Consequently, after a pragmatic classification of security attacks, the main sections of the tutorial cover the four patterns for providing network security, of which the familiar three are cryptographic protocols, packet filtering, and dynamic resource allocation. Although cryptographic protocols hide the data contents of packets, they cannot hide packet headers. When users need to hide packet headers from adversaries, which may include the network from which they are receiving service, they must resort to the pattern of compound sessions and overlays. The second perspective comes from the observation that security mechanisms interact in important ways, with each other and with other aspects of networking, so each pattern includes a discussion of its interactions.},
  archive      = {J_CSUR},
  author       = {Pamela Zave and Jennifer Rexford},
  doi          = {10.1145/3417988},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {118:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Patterns and interactions in network security},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy diagnosis of android applications: A thematic
taxonomy and survey. <em>CSUR</em>, <em>53</em>(6), 117:1–36. (<a
href="https://doi.org/10.1145/3417986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abnormal energy consumption of Android applications is a significant problem faced by developers and users. In recent years, researchers have invested their efforts to develop energy diagnosis tools that pinpoint and fix the energy bugs from source code automatically. These tools use traditional software engineering methods such as program analysis, refactoring, software repair, and bug localization to diagnose energy inefficiencies. Existing surveys focus only on energy measurement techniques and profiling tools and do not consider automated energy diagnosis tools. Therefore, this article organizes state of the art by surveying 25 relevant studies on Android applications’ automatic energy diagnosis. Further, this survey presents a systematic thematic taxonomy of existing approaches from a software engineering perspective. The taxonomy presented in this article would serve as a body of knowledge and help researchers and developers to understand the state of the field better. The future research directions discussed in this article might help prospective researchers to identify suitable topics to improve the current research work in this field.},
  archive      = {J_CSUR},
  author       = {Marimuthu C. and K. Chandrasekaran and Sridhar Chimalakonda},
  doi          = {10.1145/3417986},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {117:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Energy diagnosis of android applications: A thematic taxonomy and survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart home personal assistants: A security and privacy
review. <em>CSUR</em>, <em>53</em>(6), 116:1–36. (<a
href="https://doi.org/10.1145/3412383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart Home Personal Assistants (SPA) are an emerging innovation that is changing the means by which home users interact with technology. However, several elements expose these systems to various risks: (i) the open nature of the voice channel they use, (ii) the complexity of their architecture, (iii) the AI features they rely on, and (iv) their use of a wide range of underlying technologies. This article presents an in-depth review of SPA’s security and privacy issues, categorizing the most important attack vectors and their countermeasures. Based on this, we discuss open research challenges that can help steer the community to tackle and address current security and privacy issues in SPA. One of our key findings is that even though the attack surface of SPA is conspicuously broad and there has been a significant amount of recent research efforts in this area, research has so far focused on a small part of the attack surface, particularly on issues related to the interaction between the user and the SPA devices. To the best of our knowledge, this is the first article to conduct such a comprehensive review and characterization of the security and privacy issues and countermeasures of SPA.},
  archive      = {J_CSUR},
  author       = {Jide S. Edu and Jose M. Such and Guillermo Suarez-Tangil},
  doi          = {10.1145/3412383},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {116:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Smart home personal assistants: A security and privacy review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of cybersecurity certification for the internet of
things. <em>CSUR</em>, <em>53</em>(6), 115:1–36. (<a
href="https://doi.org/10.1145/3410160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cybersecurity certification is gaining momentum as the baseline to build a structured approach to mitigate cybersecurity risks in the Internet of Things (IoT). This initiative is driven by industry, governmental institutions, and research communities, which have the goal to make IoT more secure for the end-users. In this survey, we analyze the current cybersecurity certification schemes, as well as the potential challenges to make them applicable for the IoT ecosystem. We also examine current efforts related to risk assessment and testing processes, which are widely recognized as the processes to build a cybersecurity certification framework. Our work provides a multidisciplinary perspective of a possible IoT cybersecurity certification framework by integrating research and technical tools and processes with policies and governance structures, which are analyzed against a set of identified challenges. This survey is intended to give a comprehensive overview of cybersecurity certification to facilitate the definition of a framework that fits in emerging scenarios, such as the IoT paradigm.},
  archive      = {J_CSUR},
  author       = {Sara N. Matheu and José L. Hernández-Ramos and Antonio F. Skarmeta and Gianmarco Baldini},
  doi          = {10.1145/3410160},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {115:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of cybersecurity certification for the internet of things},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on heart biometrics. <em>CSUR</em>, <em>53</em>(6),
114:1–38. (<a href="https://doi.org/10.1145/3410158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, biometrics (e.g., fingerprint or face recognition) has replaced traditional passwords and PINs as a widely used method for user authentication, particularly in personal or mobile devices. Differing from state-of-the-art biometrics, heart biometrics offer the advantages of liveness detection, which provides strong tolerance to spoofing attacks. To date, several authentication methods primarily focusing on electrocardiogram (ECG) have demonstrated remarkable success; however, the degree of exploration with other cardiac signals is still limited. To this end, we discuss the challenges in various cardiac domains and propose future prospectives for developing effective heart biometrics systems in real-world applications.},
  archive      = {J_CSUR},
  author       = {Aditya Singh Rathore and Zhengxiong Li and Weijin Zhu and Zhanpeng Jin and Wenyao Xu},
  doi          = {10.1145/3410158},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {114:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on heart biometrics},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In memoriam sherif sakr (1979–2020). <em>CSUR</em>,
<em>53</em>(6), 113e:1. (<a
href="https://doi.org/10.1145/3436208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_CSUR},
  author       = {Albert Y. Zomaya},
  doi          = {10.1145/3436208},
  journal      = {ACM Computing Surveys},
  number       = {6},
  pages        = {113e:1},
  shortjournal = {ACM Comput. Surv.},
  title        = {In memoriam sherif sakr (1979–2020)},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparative analysis and framework evaluating web single
sign-on systems. <em>CSUR</em>, <em>53</em>(5), 112:1–34. (<a
href="https://doi.org/10.1145/3409452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We perform a comprehensive analysis and comparison of 14 web single sign-on (SSO) systems proposed and/or deployed over the past decade, including federated identity and credential/password management schemes. We identify common design properties and use them to develop a taxonomy for SSO schemes, highlighting the associated tradeoffs in benefits (positive attributes) offered. We develop a framework to evaluate the schemes, in which we identify 14 security, usability, deployability, and privacy benefits. We also discuss how differences in priorities between users, service providers, and identity providers impact the design and deployment of SSO schemes.},
  archive      = {J_CSUR},
  author       = {Furkan Alaca and Paul C. Van Oorschot},
  doi          = {10.1145/3409452},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {112:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Comparative analysis and framework evaluating web single sign-on systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causality-based feature selection: Methods and evaluations.
<em>CSUR</em>, <em>53</em>(5), 111:1–36. (<a
href="https://doi.org/10.1145/3409382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a crucial preprocessing step in data analytics and machine learning. Classical feature selection algorithms select features based on the correlations between predictive features and the class variable and do not attempt to capture causal relationships between them. It has been shown that the knowledge about the causal relationships between features and the class variable has potential benefits for building interpretable and robust prediction models, since causal relationships imply the underlying mechanism of a system. Consequently, causality-based feature selection has gradually attracted greater attentions and many algorithms have been proposed. In this article, we present a comprehensive review of recent advances in causality-based feature selection. To facilitate the development of new algorithms in the research area and make it easy for the comparisons between new methods and existing ones, we develop the first open-source package, called CausalFS, which consists of most of the representative causality-based feature selection algorithms (available at https://github.com/kuiy/CausalFS). Using CausalFS, we conduct extensive experiments to compare the representative algorithms with both synthetic and real-world datasets. Finally, we discuss some challenging problems to be tackled in future research.},
  archive      = {J_CSUR},
  author       = {Kui Yu and Xianjie Guo and Lin Liu and Jiuyong Li and Hao Wang and Zhaolong Ling and Xindong Wu},
  doi          = {10.1145/3409382},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {111:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Causality-based feature selection: Methods and evaluations},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Big data systems: A software engineering perspective.
<em>CSUR</em>, <em>53</em>(5), 110:1–39. (<a
href="https://doi.org/10.1145/3408314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big Data Systems (BDSs) are an emerging class of scalable software technologies whereby massive amounts of heterogeneous data are gathered from multiple sources, managed, analyzed (in batch, stream or hybrid fashion), and served to end-users and external applications. Such systems pose specific challenges in all phases of software development lifecycle and might become very complex by evolving data, technologies, and target value over time. Consequently, many organizations and enterprises have found it difficult to adopt BDSs. In this article, we provide insight into three major activities of software engineering in the context of BDSs as well as the choices made to tackle them regarding state-of-the-art research and industry efforts. These activities include the engineering of requirements, designing and constructing software to meet the specified requirements, and software/data quality assurance. We also disclose some open challenges of developing effective BDSs, which need attention from both researchers and practitioners.},
  archive      = {J_CSUR},
  author       = {Ali Davoudian and Mengchi Liu},
  doi          = {10.1145/3408314},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {110:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Big data systems: A software engineering perspective},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of fake news: Fundamental theories, detection
methods, and opportunities. <em>CSUR</em>, <em>53</em>(5), 109:1–40. (<a
href="https://doi.org/10.1145/3395046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style , its propagation patterns, and the credibility of its source . The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.},
  archive      = {J_CSUR},
  author       = {Xinyi Zhou and Reza Zafarani},
  doi          = {10.1145/3395046},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {109:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of fake news: Fundamental theories, detection methods, and opportunities},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on bayesian deep learning. <em>CSUR</em>,
<em>53</em>(5), 108:1–37. (<a
href="https://doi.org/10.1145/3409383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive artificial intelligence system needs to not only perceive the environment with different “senses” (e.g., seeing and hearing) but also infer the world’s conditional (or even causal) relations and corresponding uncertainty. The past decade has seen major advances in many perception tasks, such as visual object recognition and speech recognition, using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. In recent years, Bayesian deep learning has emerged as a unified probabilistic framework to tightly integrate deep learning and Bayesian models. 1 In this general framework, the perception of text or images using deep learning can boost the performance of higher-level inference and, in turn, the feedback from the inference process is able to enhance the perception of text or images. This survey provides a comprehensive introduction to Bayesian deep learning and reviews its recent applications on recommender systems, topic models, control, and so on. We also discuss the relationship and differences between Bayesian deep learning and other related topics, such as Bayesian treatment of neural networks.},
  archive      = {J_CSUR},
  author       = {Hao Wang and Dit-Yan Yeung},
  doi          = {10.1145/3409383},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {108:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on bayesian deep learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on trust evaluation based on machine learning.
<em>CSUR</em>, <em>53</em>(5), 107:1–36. (<a
href="https://doi.org/10.1145/3408292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trust evaluation is the process of quantifying trust with attributes that influence trust. It faces a number of severe issues such as lack of essential evaluation data, demand of big data process, request of simple trust relationship expression, and expectation of automation. In order to overcome these problems and intelligently and automatically evaluate trust, machine learning has been applied into trust evaluation. Researchers have proposed many methods to use machine learning for trust evaluation. However, the literature still lacks a comprehensive literature review on this topic. In this article, we perform a thorough survey on trust evaluation based on machine learning. First, we cover essential prerequisites of trust evaluation and machine learning. Then, we justify a number of requirements that a sound trust evaluation method should satisfy, and propose them as evaluation criteria to assess the performance of trust evaluation methods. Furthermore, we systematically organize existing methods according to application scenarios and provide a comprehensive literature review on trust evaluation from the perspective of machine learning’s function in trust evaluation and evaluation granularity. Finally, according to the completed review and evaluation, we explore some open research problems and suggest the directions that are worth our research effort in the future.},
  archive      = {J_CSUR},
  author       = {Jingwen Wang and Xuyang Jing and Zheng Yan and Yulong Fu and Witold Pedrycz and Laurence T. Yang},
  doi          = {10.1145/3408292},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {107:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on trust evaluation based on machine learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommender systems leveraging multimedia content.
<em>CSUR</em>, <em>53</em>(5), 106:1–38. (<a
href="https://doi.org/10.1145/3407190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become a popular and effective means to manage the ever-increasing amount of multimedia content available today and to help users discover interesting new items. Today’s recommender systems suggest items of various media types, including audio, text, visual (images), and videos. In fact, scientific research related to the analysis of multimedia content has made possible effective content-based recommender systems capable of suggesting items based on an analysis of the features extracted from the item itself. The aim of this survey is to present a thorough review of the state-of-the-art of recommender systems that leverage multimedia content, by classifying the reviewed papers with respect to their media type, the techniques employed to extract and represent their content features, and the recommendation algorithm. Moreover, for each media type, we discuss various domains in which multimedia content plays a key role in human decision-making and is therefore considered in the recommendation process. Examples of the identified domains include fashion, tourism, food, media streaming, and e-commerce.},
  archive      = {J_CSUR},
  author       = {Yashar Deldjoo and Markus Schedl and Paolo Cremonesi and Gabriella Pasi},
  doi          = {10.1145/3407190},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {106:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recommender systems leveraging multimedia content},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predecessor search. <em>CSUR</em>, <em>53</em>(5), 105:1–35.
(<a href="https://doi.org/10.1145/3409371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predecessor problem is a key component of the fundamental sorting-and-searching core of algorithmic problems. While binary search is the optimal solution in the comparison model, more realistic machine models on integer sets open the door to a rich universe of data structures, algorithms, and lower bounds. In this article, we review the evolution of the solutions to the predecessor problem, focusing on the important algorithmic ideas, from the famous data structure of van Emde Boas to the optimal results of Patrascu and Thorup. We also consider lower bounds, variants, and special cases, as well as the remaining open questions.},
  archive      = {J_CSUR},
  author       = {Gonzalo Navarro and Javiel Rojas-Ledesma},
  doi          = {10.1145/3409371},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {105:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Predecessor search},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unveiling the mystery of internet packet forwarding: A
survey of network path validation. <em>CSUR</em>, <em>53</em>(5),
104:1–34. (<a href="https://doi.org/10.1145/3409796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating the network paths taken by packets is critical in constructing a secure Internet architecture. Any feasible solution must both enforce packet forwarding along end-host specified paths and verify whether packets have taken those paths. However, the current Internet supports neither enforcement nor verification. Likely due to the radical changes to the Internet architecture and a long-standing confusion between routing and forwarding, only limited solutions for path validation exist in the literature. This survey article aims to reinvigorate research on the essential topic of path validation by crystallizing not only how path validation works but also where seemingly qualified solutions fall short. The analyses explore future research directions in path validation aimed at improving security, privacy, and efficiency.},
  archive      = {J_CSUR},
  author       = {Kai Bu and Avery Laird and Yutian Yang and Linfeng Cheng and Jiaqing Luo and Yingjiu Li and Kui Ren},
  doi          = {10.1145/3409796},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {104:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Unveiling the mystery of internet packet forwarding: A survey of network path validation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of ontologies for simultaneous localization and
mapping in mobile robots. <em>CSUR</em>, <em>53</em>(5), 103:1–26. (<a
href="https://doi.org/10.1145/3408316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous robots are playing important roles in academic, technological, and scientific activities. Thus, their behavior is getting more complex, particularly, in tasks related to mapping an environment and localizing themselves. These tasks comprise the Simultaneous Localization and Mapping (SLAM) problem. Representation of knowledge related to the SLAM problem with a standard, flexible, and well-defined model, provides the base to develop efficient and interoperable solutions. As many existing works demonstrate, Semantic Web seems to be a clear approach, since they have formulated ontologies, as the base data model to represent such knowledge. In this article, we survey the most popular and recent SLAM ontologies with our aim being threefold: (i) propose a classification of SLAM ontologies according to the main knowledge needed to model the SLAM problem; (ii) identify existing ontologies for classifying, comparing, and contrasting them, in order to conceptualize SLAM domain for mobile robots; and (iii) pin-down lessons to learn from existing solutions in order to design better solutions and identify new research directions and further improvements. We compare the identified SLAM ontologies according to the proposed classification and, finally, we explore new data fields to enrich existing ontologies and highlight new possibilities in terms of performance and efficiency for SLAM solutions.},
  archive      = {J_CSUR},
  author       = {María A. Cornejo-Lupa and Regina P. Ticona-Herrera and Yudith Cardinale and Dennis Barrios-Aranibar},
  doi          = {10.1145/3408316},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {103:1–26},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of ontologies for simultaneous localization and mapping in mobile robots},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic efficiency applications over downtown roads: A new
challenge for intelligent connected vehicles. <em>CSUR</em>,
<em>53</em>(5), 102:1–30. (<a
href="https://doi.org/10.1145/3403952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular network technology is frequently used to provide several services and applications for drivers on road networks. The proposed applications in the environment of road networks are classified into three main categories based on their functions: safety, traffic efficiency, and entertainment. The traffic efficiency services are designed to enhance the moving fluency and smoothness of traveling vehicles over the road network. The grid layout architecture of the downtown areas provides several routes toward any targeted destination. Moreover, since several conflicted traffic flows compete at the road intersections, many vehicles have to stop and wait for safe situations to pass the road intersection without coming into conflict with other vehicles. The traffic efficiency applications in this scenario are designed to select the most efficient path for vehicles traveling toward their targeted destination/destinations. Moreover, other applications aimed to decrease the queuing delay time for vehicles at road intersections. In this article, we review several recently proposed mechanisms that worked to enhance the fluency of traffic over downtown road networks and point to the expected future trends in this field.},
  archive      = {J_CSUR},
  author       = {Maram Bani Younes and Azzedine Boukerche},
  doi          = {10.1145/3403952},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {102:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Traffic efficiency applications over downtown roads: A new challenge for intelligent connected vehicles},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational sustainability: A socio-technical perspective.
<em>CSUR</em>, <em>53</em>(5), 101:1–29. (<a
href="https://doi.org/10.1145/3409797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a consolidated look at computational techniques for sustainability, and their limits and possibilities. Sustainability is already well established as a concern and a topic of study and practice, given the alarming increase of environmental degradation, pollution, and other adverse effects of industrialization and urbanization. Computational sustainability, which focuses on the use of effective computational models and computational approaches to help achieve the goal of sustainability, has attracted interest from computer science researchers worldwide. We review recent work on computational techniques applied to a range of domains related to sustainability, from bio-surveillance to poverty mapping, from renewable energy production forecasting to crop disease monitoring, and from agent-based modeling to stochastic network design. In sustainable computing, we discuss some directions that have recently been explored. Finally, we analyze research directions that could be explored in the future to achieve the goal of long-term environmental sustainability.},
  archive      = {J_CSUR},
  author       = {Deya Chatterjee and Shrisha Rao},
  doi          = {10.1145/3409797},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {101:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computational sustainability: A socio-technical perspective},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A taxonomy and survey of power models and power modeling for
cloud servers. <em>CSUR</em>, <em>53</em>(5), 100:1–41. (<a
href="https://doi.org/10.1145/3406208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing demand of cloud resources, the ever-increasing number and scale of cloud data centers make their massive power consumption a prominent issue today. Evidence reveals that the behaviors of cloud servers make the major impact on data centers’ power consumption. Although extensive research can be found in this context, a systematic review of the models and modeling methods for the entire hierarchy (from underlying hardware components to the upper-layer applications) of the cloud server is still missing, which is supposed to cover the relevant studies on physical and virtual cloud server instances, server components, and cloud applications. In this article, we summarize a broad range of relevant studies from three perspectives: power data acquisition, power models, and power modeling methods for cloud servers (including bare-metal, virtual machine (VM), and container instances). We present a comprehensive taxonomy on the collection methods of server-level power data, the existing mainstream power models at multiple levels from hardware to software and application, and commonly used methods for modeling power consumption including classical regression analysis and emerging methods like reinforcement learning. Throughout the work, we introduce a variety of models and methods, illustrating their implementation, usability, and applicability while discussing the limitations of existing approaches and possible ways of improvement. Apart from reviewing existing studies on server power models and modeling methods, we further figure out several open challenges and possible research directions, such as the study on modeling the power consumption of lightweight virtual units like unikernel and the necessity of further explorations toward empowering server power estimation/prediction with machine learning. As power monitoring is drawing increasing attention from cloud service providers (CSPs), this survey provides useful guidelines on server power modeling and can be inspiring for further research on energy-efficient data centers.},
  archive      = {J_CSUR},
  author       = {Weiwei Lin and Fang Shi and Wentai Wu and Keqin Li and Guangxin Wu and Al-Alas Mohammed},
  doi          = {10.1145/3406208},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {100:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy and survey of power models and power modeling for cloud servers},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of multilingual neural machine translation.
<em>CSUR</em>, <em>53</em>(5), 99:1–38. (<a
href="https://doi.org/10.1145/3406095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a survey on multilingual neural machine translation (MNMT), which has gained a lot of traction in recent years. MNMT has been useful in improving translation quality as a result of translation knowledge transfer (transfer learning). MNMT is more promising and interesting than its statistical machine translation counterpart, because end-to-end modeling and distributed representations open new avenues for research on machine translation. Many approaches have been proposed to exploit multilingual parallel corpora for improving translation quality. However, the lack of a comprehensive survey makes it difficult to determine which approaches are promising and, hence, deserve further exploration. In this article, we present an in-depth survey of existing literature on MNMT. We first categorize various approaches based on their central use-case and then further categorize them based on resource scenarios, underlying modeling principles, core-issues, and challenges. Wherever possible, we address the strengths and weaknesses of several techniques by comparing them with each other. We also discuss the future directions for MNMT. This article is aimed towards both beginners and experts in NMT. We hope this article will serve as a starting point as well as a source of new ideas for researchers and engineers interested in MNMT.},
  archive      = {J_CSUR},
  author       = {Raj Dabre and Chenhui Chu and Anoop Kunchukuttan},
  doi          = {10.1145/3406095},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {99:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of multilingual neural machine translation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of quantum theory inspired approaches to
information retrieval. <em>CSUR</em>, <em>53</em>(5), 98:1–39. (<a
href="https://doi.org/10.1145/3402179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 2004, researchers have been using the mathematical framework of quantum theory in information retrieval (IR). Quantum theory offers a generalized probability and logic framework. Such a framework has been shown to be capable of unifying the representation, ranking, and user cognitive aspects of IR, and helpful in developing more dynamic, adaptive, and context-aware IR systems. Although quantum-inspired IR is still a growing area, a wide array of work in different aspects of IR has been done and produced promising results. This article presents a survey of the research done in this area, aiming to show the landscape of the field and draw a road map of future directions.},
  archive      = {J_CSUR},
  author       = {Sagar Uprety and Dimitris Gkoumas and Dawei Song},
  doi          = {10.1145/3402179},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {98:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of quantum theory inspired approaches to information retrieval},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure hash algorithms and the corresponding FPGA
optimization techniques. <em>CSUR</em>, <em>53</em>(5), 97:1–36. (<a
href="https://doi.org/10.1145/3311724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptographic hash functions are widely used primitives with a purpose to ensure the integrity of data. Hash functions are also utilized in conjunction with digital signatures to provide authentication and non-repudiation services. The SHA has been developed over time by the National Institute of Standards and Technology for security, optimal performance, and robustness. The best-known hash standards are SHA-1, SHA-2, and SHA-3. Security is the most notable criterion for evaluating the hash functions. However, the hardware performance of an algorithm serves as a tiebreaker among the contestants when all other parameters (security, software performance, and flexibility) have equal strength. Field Programmable Gateway Array (FPGA) is a reconfigurable hardware that supports a variety of design options, making it the best choice for implementing the hash standards. In this survey, particular attention is devoted to the FPGA optimization techniques for the three hash standards. The study covers several types of optimization techniques and their contributions to the performance of FPGAs. Moreover, the article highlights the strengths and weaknesses of each of the optimization methods and their influence on performance. We are optimistic that the study will be a useful resource encompassing the efforts carried out on the SHAs and FPGA optimization techniques in a consolidated form.},
  archive      = {J_CSUR},
  author       = {Zeyad A. Al-Odat and Mazhar Ali and Assad Abbas and Samee U. Khan},
  doi          = {10.1145/3311724},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {97:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Secure hash algorithms and the corresponding FPGA optimization techniques},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum key distribution: A networking perspective.
<em>CSUR</em>, <em>53</em>(5), 96:1–41. (<a
href="https://doi.org/10.1145/3402192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convergence of quantum cryptography with applications used in everyday life is a topic drawing attention from the industrial and academic worlds. The development of quantum electronics has led to the practical achievement of quantum devices that are already available on the market and waiting for their first application on a broader scale. A major aspect of quantum cryptography is the methodology of Quantum Key Distribution (QKD), which is used to generate and distribute symmetric cryptographic keys between two geographically separate users using the principles of quantum physics. In previous years, several successful QKD networks have been created to test the implementation and interoperability of different practical solutions. This article surveys previously applied methods, showing techniques for deploying QKD networks and current challenges of QKD networking. Unlike studies focusing on optical channels and optical equipment, this survey focuses on the network aspect by considering network organization, routing and signaling protocols, simulation techniques, and a software-defined QKD networking approach.},
  archive      = {J_CSUR},
  author       = {Miralem Mehic and Marcin Niemiec and Stefan Rass and Jiajun Ma and Momtchil Peev and Alejandro Aguado and Vicente Martin and Stefan Schauer and Andreas Poppe and Christoph Pacher and Miroslav Voznak},
  doi          = {10.1145/3402192},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {96:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Quantum key distribution: A networking perspective},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predictive reliability and fault management in exascale
systems: State of the art and perspectives. <em>CSUR</em>,
<em>53</em>(5), 95:1–32. (<a
href="https://doi.org/10.1145/3403956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance and power constraints come together with Complementary Metal Oxide Semiconductor technology scaling in future Exascale systems. Technology scaling makes each individual transistor more prone to faults and, due to the exponential increase in the number of devices per chip, to higher system fault rates. Consequently, High-performance Computing (HPC) systems need to integrate prediction, detection, and recovery mechanisms to cope with faults efficiently. This article reviews fault detection, fault prediction, and recovery techniques in HPC systems, from electronics to system level. We analyze their strengths and limitations. Finally, we identify the promising paths to meet the reliability levels of Exascale systems.},
  archive      = {J_CSUR},
  author       = {Ramon Canal and Carles Hernandez and Rafa Tornero and Alessandro Cilardo and Giuseppe Massari and Federico Reghenzani and William Fornaciari and Marina Zapater and David Atienza and Ariel Oleksiak and Wojciech PiĄtek and Jaume Abella},
  doi          = {10.1145/3403956},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {95:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Predictive reliability and fault management in exascale systems: State of the art and perspectives},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vehicle trajectory similarity: Models, methods, and
applications. <em>CSUR</em>, <em>53</em>(5), 94:1–32. (<a
href="https://doi.org/10.1145/3406096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing availability of vehicular trajectory data is at the core of smart mobility solutions. Such data offer us unprecedented information for the development of trajectory data mining-based applications. An essential task of trajectory analysis is the employment of efficient and accurate methods to compare trajectories. This work presents a systematic survey of vehicular trajectory similarity measures and provides a panorama of the research field. First, we show an overview of vehicle trajectory data, including the models and some preprocessing techniques. Then, we give a comprehensive review of methods to compare trajectories and their intrinsic properties. We classify the methods according to the trajectory representation and features such as metricity, computational complexity, and robustness to noise and local time shift. Last, we discuss the applications of vehicular trajectory similarity measures and some open research problems.},
  archive      = {J_CSUR},
  author       = {Roniel S. De Sousa and Azzedine Boukerche and Antonio A. F. Loureiro},
  doi          = {10.1145/3406096},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {94:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Vehicle trajectory similarity: Models, methods, and applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Density-based algorithms for big data clustering using
MapReduce framework: A comprehensive study. <em>CSUR</em>,
<em>53</em>(5), 93:1–38. (<a
href="https://doi.org/10.1145/3403951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is used to extract hidden patterns and similar groups from data. Therefore, clustering as a method of unsupervised learning is a crucial technique for big data analysis owing to the massive number of unlabeled objects involved. Density-based algorithms have attracted research interest, because they help to better understand complex patterns in spatial datasets that contain information about data related to co-located objects. Big data clustering is a challenging task, because the volume of data increases exponentially. However, clustering using MapReduce can help answer this challenge. In this context, density-based algorithms in MapReduce have been largely investigated in the past decade to eliminate the problem of big data clustering. Despite the diversity of the algorithms proposed, the field lacks a structured review of the available algorithms and techniques for desirable partitioning, local clustering, and merging. This study formalizes the problem of density-based clustering using MapReduce, proposes a taxonomy to categorize the proposed algorithms, and provides a systematic and comprehensive comparison of these algorithms according to the partitioning technique, type of local clustering, merging technique, and exactness of their implementations. Finally, the study highlights outstanding challenges and opportunities to contribute to the field of density-based clustering using MapReduce.},
  archive      = {J_CSUR},
  author       = {Mariam Khader and Ghazi Al-Naymat},
  doi          = {10.1145/3403951},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {93:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Density-based algorithms for big data clustering using MapReduce framework: A comprehensive study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobility management in 5G-enabled vehicular networks:
Models, protocols, and classification. <em>CSUR</em>, <em>53</em>(5),
92:1–35. (<a href="https://doi.org/10.1145/3403953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past few years, the next generation of vehicular networks is envisioned to play an essential part in autonomous driving, traffic management, and infotainment applications. The next generation of intelligent vehicular networks enabled by 5G systems will integrate various heterogeneous wireless techniques to enable time-sensitive services with guaranteed quality of service and ultimate bandwidth usage. However, to allow the dense diversity of wireless technologies, seamless and reliable wireless communication protocols need to be thoroughly investigated in vehicular networks environment. Henceforth, efficient mobility management protocols that mitigate the challenges of vehicles’ mobility is essential to support massive data loads throughout various applications. In this article, we review different mobility management protocols and their ability to address issues related to 5G-enabled vehicular networks within the related works. First, we provide a broad view of existing models of vehicular networks and their applicability to the next generation of wireless networks. Next, we propose a classification of several vehicular network models that suit the 5G wireless network, followed by a thorough discussion of the mobility management challenges in each of these network models that need to be addressed and then discuss each of their benefits and drawbacks accordingly.},
  archive      = {J_CSUR},
  author       = {Noura Aljeri and Azzedine Boukerche},
  doi          = {10.1145/3403953},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {92:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mobility management in 5G-enabled vehicular networks: Models, protocols, and classification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on energy expenditure estimation using wearable
devices. <em>CSUR</em>, <em>53</em>(5), 91:1–35. (<a
href="https://doi.org/10.1145/3404482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Energy Expenditure (EE) is a valuable tool for measuring physical activity and its impact on our body in an objective way. To accurately measure the EE, there are methods such as doubly labeled water and direct and indirect calorimetry, but their cost and practical limitations make them suitable only for research and professional sports. This situation, combined with the proliferation of commercial activity monitors, has stimulated the research of EE estimation (EEE) using machine learning on multimodal data from wearable devices. The article provides an overview of existing work in this evolving field, categorizes it, and makes publicly available an EEE dataset. Such a dataset is one of the most valuable resources for the development of the field but is generally not provided by researchers due to the high cost of collection. Finally, the article highlights best practices and promising future direction for designing EEE methods.},
  archive      = {J_CSUR},
  author       = {Juan A. Álvarez-García and Božidara Cvetković and Mitja Luštrek},
  doi          = {10.1145/3404482},
  journal      = {ACM Computing Surveys},
  number       = {5},
  pages        = {91:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on energy expenditure estimation using wearable devices},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An overview of hardware implementation of membrane computing
models. <em>CSUR</em>, <em>53</em>(4), 90:1–38. (<a
href="https://doi.org/10.1145/3402456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The model of membrane computing, also known under the name of P systems, is a bio-inspired large-scale parallel computing paradigm having a good potential for the design of massively parallel algorithms. For its implementation it is very natural to choose hardware platforms that have important inherent parallelism, such as field-programmable gate arrays (FPGAs) or compute unified device architecture (CUDA)-enabled graphic processing units (GPUs). This article performs an overview of all existing approaches of hardware implementation in the area of P systems. The quantitative and qualitative attributes of FPGA-based implementations and CUDA-enabled GPU-based simulations are compared to evaluate the two methodologies.},
  archive      = {J_CSUR},
  author       = {Gexiang Zhang and Zeyi Shang and Sergey Verlan and Miguel Á. Martínez-del-Amor and Chengxun Yuan and Luis Valencia-Cabrera and Mario J. Pérez-Jiménez},
  doi          = {10.1145/3402456},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {90:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of hardware implementation of membrane computing models},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain technology for cloud storage: A systematic
literature review. <em>CSUR</em>, <em>53</em>(4), 89:1–32. (<a
href="https://doi.org/10.1145/3403954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for Blockchain innovation and the significance of its application has inspired ever-progressing exploration in various scientific and practical areas. Even though it is still in the initial testing stage, the blockchain is being viewed as a progressive solution to address present-day technology concerns, such as decentralization, identity, trust, character, ownership of data, and information-driven choices. Simultaneously, the world is facing an increase in the diversity and quantity of digital information produced by machines and users. While effectively looking for the ideal approach to storing and processing cloud data, the blockchain innovation provides significant inputs. This article reviews the application of blockchain technology for securing cloud storage.},
  archive      = {J_CSUR},
  author       = {Pratima Sharma and Rajni Jindal and Malaya Dutta Borah},
  doi          = {10.1145/3403954},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {89:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blockchain technology for cloud storage: A systematic literature review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application management in fog computing environments: A
taxonomy, review and future directions. <em>CSUR</em>, <em>53</em>(4),
88:1–43. (<a href="https://doi.org/10.1145/3403955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm is being rapidly adopted for the creation of smart environments in various domains. The IoT-enabled cyber-physical systems associated with smart city, healthcare, Industry 4.0 and Agtech handle a huge volume of data and require data processing services from different types of applications in real time. The Cloud-centric execution of IoT applications barely meets such requirements as the Cloud datacentres reside at a multi-hop distance from the IoT devices. Fog computing , an extension of Cloud at the edge network, can execute these applications closer to data sources. Thus, Fog computing can improve application service delivery time and resist network congestion. However, the Fog nodes are highly distributed and heterogeneous, and most of them are constrained in resources and spatial sharing. Therefore, efficient management of applications is necessary to fully exploit the capabilities of Fog nodes. In this work, we investigate the existing application management strategies in Fog computing and review them in terms of architecture, placement and maintenance. Additionally, we propose a comprehensive taxonomy and highlight the research gaps in Fog-based application management. We also discuss a perspective model and provide future research directions for further improvement of application management in Fog computing.},
  archive      = {J_CSUR},
  author       = {Redowan Mahmud and Kotagiri Ramamohanarao and Rajkumar Buyya},
  doi          = {10.1145/3403955},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {88:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {Application management in fog computing environments: A taxonomy, review and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application domain-based overview of IoT network traffic
characteristics. <em>CSUR</em>, <em>53</em>(4), 87:1–33. (<a
href="https://doi.org/10.1145/3399669">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, the Internet of Things (IoT) has advanced rapidly. New technologies have been proposed and existing approaches optimised to meet user, society and industry requirements. However, as the complexity and heterogeneity of the traffic that flows through the networks are continuously growing, the innovation becomes difficult to achieve in both IoT and legacy networks. This article provides an overview of IoT application domains from a traffic characteristics perspective. Specifically, it identifies several groups of major IoT application use cases and discusses the exhibited traffic characteristics, used network technologies for implementation, and their feasibility as well as challenges. We stress that a key factor in future IoT development is network technologies and the way they handle and forward network traffic. The traffic characteristics emerging from this work can serve as a basis for future design proposals to develop more efficient solutions and improve the network technologies.},
  archive      = {J_CSUR},
  author       = {Adrian Pekar and Jozef Mocnej and Winston K. G. Seah and Iveta Zolotova},
  doi          = {10.1145/3399669},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {87:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Application domain-based overview of IoT network traffic characteristics},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel genetic algorithms: A useful survey. <em>CSUR</em>,
<em>53</em>(4), 86:1–39. (<a
href="https://doi.org/10.1145/3400031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we encompass an analysis of the recent advances in parallel genetic algorithms (PGAs). We have selected these algorithms because of the deep interest in many research fields for techniques that can face complex applications where running times and other computational resources are greedily consumed by present solvers, and PGAs act then as efficient procedures that fully use modern computational platforms at the same time that allow the resolution of cutting-edge open problems. We have faced this survey on PGAs with the aim of helping newcomers or busy researchers who want to have a wide vision on the field. Then, we discuss the most well-known models and their implementations from a recent (last six years) and useful point of view: We discuss on highly cited articles, keywords, the venues where they can be found, a very comprehensive (and new) taxonomy covering different research domains involved in PGAs, and a set of recent applications. We also introduce a new vision on open challenges and try to give hints that guide practitioners and specialized researchers. Our conclusion is that there are many advantages to using these techniques and lots of potential interactions to other evolutionary algorithms; as well, we contribute to creating a body of knowledge in PGAs by summarizing them in a structured way, so the reader can find this article useful for practical research, graduate teaching, and as a pedagogical guide to this exciting domain.},
  archive      = {J_CSUR},
  author       = {Tomohiro Harada and Enrique Alba},
  doi          = {10.1145/3400031},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {86:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Parallel genetic algorithms: A useful survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biometric systems utilising health data from wearable
devices: Applications and future challenges in computer security.
<em>CSUR</em>, <em>53</em>(4), 85:1–29. (<a
href="https://doi.org/10.1145/3400030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health data are being increasingly sensed from the health-based wearable Internet of Things (IoT) devices, providing much-needed fitness and health tracking. However, data generated also present opportunities within computer security, specifically with biometric systems used for identification and authentication purposes. This article performs a systematic review of health-based IoT data collected from wearable IoT technology. This involved performing research in the underlying data sources, what they are collected for in terms of their health monitoring, and the underlying data characteristics. Furthermore, it explores existing work in computer security using these data sources, identifying key themes of work, key limitations, and challenges. Finally, key opportunities are provided as summaries to the potential of health-based IoT data, highlighting challenges that are yet to be addressed, which motivate areas of future work.},
  archive      = {J_CSUR},
  author       = {Saad Khan and Simon Parkinson and Liam Grant and Na Liu and Stephen Mcguire},
  doi          = {10.1145/3400030},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {85:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Biometric systems utilising health data from wearable devices: Applications and future challenges in computer security},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning on mobile and embedded devices:
State-of-the-art, challenges, and future directions. <em>CSUR</em>,
<em>53</em>(4), 84:1–37. (<a
href="https://doi.org/10.1145/3398209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed an exponential increase in the use of mobile and embedded devices. With the great success of deep learning in many fields, there is an emerging trend to deploy deep learning on mobile and embedded devices to better meet the requirement of real-time applications and user privacy protection. However, the limited resources of mobile and embedded devices make it challenging to fulfill the intensive computation and storage demand of deep learning models. In this survey, we conduct a comprehensive review on the related issues for deep learning on mobile and embedded devices. We start with a brief introduction of deep learning and discuss major challenges of implementing deep learning models on mobile and embedded devices. We then conduct an in-depth survey on important compression and acceleration techniques that help adapt deep learning models to mobile and embedded devices, which we specifically classify as pruning, quantization, model distillation, network design strategies, and low-rank factorization. We elaborate on the hardware-based solutions, including mobile GPU, FPGA, and ASIC, and describe software frameworks for mobile deep learning models, especially the development of frameworks based on OpenCL and RenderScript. After that, we present the application of mobile deep learning in a variety of areas, such as navigation, health, speech recognition, and information security. Finally, we discuss some future directions for deep learning on mobile and embedded devices to inspire further research in this area.},
  archive      = {J_CSUR},
  author       = {Yanjiao Chen and Baolin Zheng and Zihan Zhang and Qian Wang and Chao Shen and Qian Zhang},
  doi          = {10.1145/3398209},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {84:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning on mobile and embedded devices: State-of-the-art, challenges, and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute-based encryption for cloud computing access
control: A survey. <em>CSUR</em>, <em>53</em>(4), 83:1–41. (<a
href="https://doi.org/10.1145/3398036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute-based encryption (ABE) for cloud computing access control is reviewed in this article. A taxonomy and comprehensive assessment criteria of ABE are first proposed. In the taxonomy, ABE schemes are assorted into key-policy ABE (KP-ABE) schemes, ciphertext-policy ABE (CP-ABE) schemes, anti-quantum ABE schemes, and generic constructions. In accordance with cryptographically functional features, CP-ABE is further divided into nine subcategories with regard to basic functionality, revocation, accountability, policy hiding, policy updating, multi-authority, hierarchy, offline computation, and outsourced computation. In addition, a systematical methodology for discussing and comparing existing ABE schemes is proposed. For KP-ABE and each type of CP-ABE, the corresponding access control scenario is presented and explained by concrete examples. Specifically, the syntax of ABE is given followed by the adversarial model and security goals. ABE schemes are discussed according to the design strategies and special features and are compared in the light of the proposed assessment criteria with respect to security and performance. Compared to related state-of-the-art survey papers, this article not only provides a broader 12 categories of ABE schemes, but also makes a more comprehensive and holistic comparison. Finally, a number of open research challenges in ABE are pointed out.},
  archive      = {J_CSUR},
  author       = {Yinghui Zhang and Robert H. Deng and Shengmin Xu and Jianfei Sun and Qi Li and Dong Zheng},
  doi          = {10.1145/3398036},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {83:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Attribute-based encryption for cloud computing access control: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Orchestrating the development lifecycle of machine
learning-based IoT applications: A taxonomy and survey. <em>CSUR</em>,
<em>53</em>(4), 82:1–47. (<a
href="https://doi.org/10.1145/3398020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) and Internet of Things (IoT) are complementary advances: ML techniques unlock the potential of IoT with intelligence, and IoT applications increasingly feed data collected by sensors into ML models, thereby employing results to improve their business processes and services. Hence, orchestrating ML pipelines that encompass model training and implication involved in the holistic development lifecycle of an IoT application often leads to complex system integration. This article provides a comprehensive and systematic survey of the development lifecycle of ML-based IoT applications. We outline the core roadmap and taxonomy and subsequently assess and compare existing standard techniques used at individual stages.},
  archive      = {J_CSUR},
  author       = {Bin Qian and Jie Su and Zhenyu Wen and Devki Nandan Jha and Yinhao Li and Yu Guan and Deepak Puthal and Philip James and Renyu Yang and Albert Y. Zomaya and Omer Rana and Lizhe Wang and Maciej Koutny and Rajiv Ranjan},
  doi          = {10.1145/3398020},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {82:1–47},
  shortjournal = {ACM Comput. Surv.},
  title        = {Orchestrating the development lifecycle of machine learning-based IoT applications: A taxonomy and survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of multitier programming. <em>CSUR</em>,
<em>53</em>(4), 81:1–35. (<a
href="https://doi.org/10.1145/3397495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multitier programming deals with developing the components that pertain to different tiers in the system (e.g., client and server), mixing them in the same compilation unit. In this paradigm, the code for different tiers is then either generated at run time or it results from the compiler splitting the codebase into components that belong to different tiers based on user annotations, static analysis, types, or a combination of these. In the Web context, multitier languages aim at reducing the distinction between client and server code, by translating the code that is to be executed on the clients to JavaScript or by executing JavaScript on the server, too. Ultimately, the goal of the multitier approach is to improve program comprehension, simplify maintenance and enable formal reasoning about the properties of the whole distributed application. A number of multitier research languages have been proposed over the last decade, which support various degrees of multitier programming and explore different design tradeoffs. In this article, we provide an overview of the existing solutions, discuss their positioning in the design space, and outline open research problems.},
  archive      = {J_CSUR},
  author       = {Pascal Weisenburger and Johannes Wirth and Guido Salvaneschi},
  doi          = {10.1145/3397495},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {81:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of multitier programming},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computation offloading and retrieval for vehicular edge
computing: Algorithms, models, and classification. <em>CSUR</em>,
<em>53</em>(4), 80:1–35. (<a
href="https://doi.org/10.1145/3392064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of mobile devices, their applications, and the amount of data generated by them causes a significant increase in bandwidth consumption and congestions in the network core. Edge Computing offers a solution to these performance drawbacks by extending the cloud paradigm to the edge of the network using capable nodes of processing compute-intensive tasks. In the recent years, vehicular edge computing has emerged for supporting mobile applications. Such paradigm relies on vehicles as edge node devices for providing storage, computation, and bandwidth resources for resource-constrained mobile applications. In this article, we study the challenges of computation offloading for vehicular edge computing. We propose a new classification for the better understanding of the literature designing vehicular edge computing. We propose a taxonomy to classify partitioning solutions in filter-based and automatic techniques; scheduling is separated in adaptive, social-based, and deadline-sensitive methods, and finally data retrieval is organized in secure, distance, mobility prediction, and social-based procedures. By reviewing and analyzing literature, we found that vehicular edge computing is feasible and a viable option to address the increasing volume of data traffic. Moreover, we discuss the open challenges and future directions that must be addressed towards efficient and effective computation offloading and retrieval from mobile users to vehicular edge computing.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Victor Soto},
  doi          = {10.1145/3392064},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {80:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computation offloading and retrieval for vehicular edge computing: Algorithms, models, and classification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-core devices for safety-critical systems: A survey.
<em>CSUR</em>, <em>53</em>(4), 79:1–38. (<a
href="https://doi.org/10.1145/3398665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-core devices are envisioned to support the development of next-generation safety-critical systems, enabling the on-chip integration of functions of different criticality. This integration provides multiple system-level potential benefits such as cost, size, power, and weight reduction. However, safety certification becomes a challenge and several fundamental safety technical requirements must be addressed, such as temporal and spatial independence, reliability, and diagnostic coverage. This survey provides a categorization and overview at different device abstraction levels (nanoscale, component, and device) of selected key research contributions that support the compliance with these fundamental safety requirements.},
  archive      = {J_CSUR},
  author       = {Jon Perez Cerrolaza and Roman Obermaisser and Jaume Abella and Francisco J. Cazorla and Kim Grüttner and Irune Agirre and Hamidreza Ahmadian and Imanol Allende},
  doi          = {10.1145/3398665},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {79:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-core devices for safety-critical systems: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Context-sensitive rewriting. <em>CSUR</em>, <em>53</em>(4),
78:1–36. (<a href="https://doi.org/10.1145/3397677">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The appropriate selection of the arguments of functions that can be evaluated in function calls is often useful to improve efficiency, speed, termination behavior, and so on. This is essential, e.g., in the conditional if - then - else operator. We can specify this by associating a set μ(f) of indices of evaluable arguments to each function symbol f . With μ (if - then - else)={1}, only the Boolean argument b in calls if b , then e else e&#39; is evaluated. In the realm of term rewriting, this is called context-sensitive rewriting . It has been proven useful to improve the termination behavior of rewriting computations while it is still able to compute (or approximate) canonical forms like head-normal forms, (infinite) values, and (infinite) normal forms by requiring a few reasonable conditions. This article provides an overview of basic results to use context-sensitive rewriting in practice.},
  archive      = {J_CSUR},
  author       = {Salvador Lucas},
  doi          = {10.1145/3397677},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {78:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Context-sensitive rewriting},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding optical music recognition. <em>CSUR</em>,
<em>53</em>(4), 77:1–35. (<a
href="https://doi.org/10.1145/3397499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For over 50 years, researchers have been trying to teach computers to read music notation, referred to as Optical Music Recognition (OMR). However, this field is still difficult to access for new researchers, especially those without a significant musical background: Few introductory materials are available, and, furthermore, the field has struggled with defining itself and building a shared terminology. In this work, we address these shortcomings by (1) providing a robust definition of OMR and its relationship to related fields, (2) analyzing how OMR inverts the music encoding process to recover the musical notation and the musical semantics from documents, and (3) proposing a taxonomy of OMR, with most notably a novel taxonomy of applications. Additionally, we discuss how deep learning affects modern OMR research, as opposed to the traditional pipeline. Based on this work, the reader should be able to attain a basic understanding of OMR: its objectives, its inherent structure, its relationship to other fields, the state of the art, and the research opportunities it affords.},
  archive      = {J_CSUR},
  author       = {Jorge Calvo-Zaragoza and Jan Hajič Jr. and Alexander Pacha},
  doi          = {10.1145/3397499},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {77:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Understanding optical music recognition},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary tree classification of rigid error detection and
correction techniques. <em>CSUR</em>, <em>53</em>(4), 76:1–38. (<a
href="https://doi.org/10.1145/3397268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to technology scaling and harsh environments, a wide range of fault-tolerant techniques exists to deal with the error occurrences. Selecting a fault-tolerant technique is not trivial, whereas more than the necessary overhead is usually inserted during the system design. To avoid over-designing, it is necessary to have an in-depth understanding of the available design options. However, an exhaustive listing is neither possible to create nor efficient to use due to its prohibitive size. In this work, we present a top-down binary tree classification for error detection and correction techniques. At each split, the design space is clearly divided into two complementary parts using one single attribute, compared with existing classifications that use splits with multiple attributes. A leaf inherits all the attributes of its ancestors from the root to the leaf. A technique is decomposed into primitive components, each one belonging to a different leaf. The single attribute splits can be used to efficiently compare the techniques and to prune the incompatible parts of the design space during the design of a technique. This essential single attribute division of the design space is required for the improvement of the techniques and for novel contributions to the fault-tolerance domain.},
  archive      = {J_CSUR},
  author       = {Angeliki Kritikakou and Rafail Psiakis and Francky Catthoor and Olivier Sentieys},
  doi          = {10.1145/3397268},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {76:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Binary tree classification of rigid error detection and correction techniques},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of learning causality with data: Problems and
methods. <em>CSUR</em>, <em>53</em>(4), 75:1–37. (<a
href="https://doi.org/10.1145/3397269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from—or the same as—the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.},
  archive      = {J_CSUR},
  author       = {Ruocheng Guo and Lu Cheng and Jundong Li and P. Richard Hahn and Huan Liu},
  doi          = {10.1145/3397269},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {75:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of learning causality with data: Problems and methods},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Survey on algorithms for self-stabilizing overlay networks.
<em>CSUR</em>, <em>53</em>(4), 74:1–24. (<a
href="https://doi.org/10.1145/3397190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maintenance of efficient and robust overlay networks is one of the most fundamental and reoccurring themes in networking. This article presents a survey of state-of-the-art algorithms to design and repair overlay networks in a distributed manner. In particular, we discuss basic algorithmic primitives to preserve connectivity, review algorithms for the fundamental problem of graph linearization, and then survey self-stabilizing algorithms for metric and scalable topologies. We also identify open problems and avenues for future research.},
  archive      = {J_CSUR},
  author       = {Michael Feldmann and Christian Scheideler and Stefan Schmid},
  doi          = {10.1145/3397190},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {74:1–24},
  shortjournal = {ACM Comput. Surv.},
  title        = {Survey on algorithms for self-stabilizing overlay networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Paving the way for NFV acceleration: A taxonomy, survey and
future directions. <em>CSUR</em>, <em>53</em>(4), 73:1–42. (<a
href="https://doi.org/10.1145/3397022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a recent innovation, network functions virtualization (NFV)—with its core concept of replacing hardware middleboxes with software network functions (NFs) implemented in commodity servers—promises cost savings and flexibility benefits. However, transitioning NFs from special-purpose hardware to commodity servers has turned out to be more challenging than expected, as it inevitably incurs performance penalties due to bottlenecks in both software and hardware. To achieve performance comparable to hardware middleboxes, there is a strong demand for a speedup in NF processing, which plays a crucial role in the success of NFV. In this article, we study the performance challenges that exist in general-purpose servers and simultaneously summarize the typical performance bottlenecks in NFV. Through reviewing the progress in the field of NFV acceleration , we present a new taxonomy of the state-of-the-art efforts according to various acceleration approaches. We discuss the surveyed works and identify the respective advantages and disadvantages in each category. We then discuss the products, solutions, and projects emerged in industry. We also present a gap analysis to improve current solutions and highlight promising research trends that can be explored in the future.},
  archive      = {J_CSUR},
  author       = {Xincai Fei and Fangming Liu and Qixia Zhang and Hai Jin and Hongxin Hu},
  doi          = {10.1145/3397022},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {73:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Paving the way for NFV acceleration: A taxonomy, survey and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Foundations, properties, and security applications of
puzzles: A survey. <em>CSUR</em>, <em>53</em>(4), 72:1–38. (<a
href="https://doi.org/10.1145/3396374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptographic algorithms have been used not only to create robust ciphertexts but also to generate cryptograms that, contrary to the classic goal of cryptography, are meant to be broken. These cryptograms, generally called puzzles, require the use of a certain amount of resources to be solved, hence introducing a cost that is often regarded as a time delay—though it could involve other metrics as well, such as bandwidth. These powerful features have made puzzles the core of many security protocols, acquiring increasing importance in the IT security landscape. The concept of a puzzle has subsequently been extended to other types of schemes that do not use cryptographic functions, such as CAPTCHAs, which are used to discriminate humans from machines. Overall, puzzles have experienced a renewed interest with the advent of Bitcoin, which uses a CPU-intensive puzzle as proof of work. In this article, we provide a comprehensive study of the most important puzzle construction schemes available in the literature, categorizing them according to several attributes, such as resource type, verification type, and applications. We have redefined the term puzzle by collecting and integrating the scattered notions used in different works, to cover all the existing applications. Moreover, we provide an overview of the possible applications, identifying key requirements and different design approaches. Finally, we highlight the features and limitations of each approach, providing a useful guide for the future development of new puzzle schemes.},
  archive      = {J_CSUR},
  author       = {Isra Mohamed Ali and Maurantonio Caprolu and Roberto Di Pietro},
  doi          = {10.1145/3396374},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {72:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Foundations, properties, and security applications of puzzles: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on device-free indoor localization and tracking in
the multi-resident environment. <em>CSUR</em>, <em>53</em>(4), 71:1–29.
(<a href="https://doi.org/10.1145/3396302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor device-free localization and tracking can bring both convenience and privacy to users compared with traditional solutions such as camera-based surveillance and RFID tag-based tracking. Technologies such as Wi-Fi, wireless sensor, and infrared have been used to localize and track people living in care homes and office buildings. However, the presence of multiple residents introduces further challenges, such as the ambiguity in sensor measurements and target identity, to localization and tracking. In this article, we survey the latest development of device-free indoor localization and tracking in the multi-resident environment. We first present the fundamentals of device-free localization and tracking. Then, we discuss and compare the technologies used in device-free indoor localization and tracking. After discussing the steps involved in multi-resident localization and tracking including target detection, target counting, target identification, localization, and tracking, the techniques related to each step are classified and discussed in detail along with the performance metrics. Finally, we identify the research gap and point out future research directions. To the best of our knowledge, this survey is the most comprehensive work that covers a wide spectrum of the research area of device-free indoor localization and tracking.},
  archive      = {J_CSUR},
  author       = {Kan Ngamakeur and Sira Yongchareon and Jian Yu and Saeed Ur Rehman},
  doi          = {10.1145/3396302},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {71:1–29},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on device-free indoor localization and tracking in the multi-resident environment},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Homomorphic encryption for machine learning in medicine and
bioinformatics. <em>CSUR</em>, <em>53</em>(4), 70:1–35. (<a
href="https://doi.org/10.1145/3394658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning and statistical techniques are powerful tools for analyzing large amounts of medical and genomic data. On the other hand, ethical concerns and privacy regulations prevent free sharing of this data. Encryption techniques such as fully homomorphic encryption (FHE) enable evaluation over encrypted data. Using FHE, machine learning models such as deep learning, decision trees, and Naive Bayes have been implemented for privacy-preserving applications using medical data. These applications include classifying encrypted data and training models on encrypted data. FHE has also been shown to enable secure genomic algorithms, such as paternity and ancestry testing and privacy-preserving applications of genome-wide association studies. This survey provides an overview of fully homomorphic encryption and its applications in medicine and bioinformatics. The high-level concepts behind FHE and its history are introduced, and details on current open-source implementations are provided. The state of fully homomorphic encryption for privacy-preserving techniques in machine learning and bioinformatics is reviewed, along with descriptions of how these methods can be implemented in the encrypted domain.},
  archive      = {J_CSUR},
  author       = {Alexander Wood and Kayvan Najarian and Delaram Kahrobaei},
  doi          = {10.1145/3394658},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {70:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Homomorphic encryption for machine learning in medicine and bioinformatics},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning methods for data association in
multi-object tracking. <em>CSUR</em>, <em>53</em>(4), 69:1–34. (<a
href="https://doi.org/10.1145/3394659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data association is a key step within the multi-object tracking pipeline that is notoriously challenging due to its combinatorial nature. A popular and general way to formulate data association is as the NP-hard multi-dimensional assignment problem. Over the past few years, data-driven approaches to assignment have become increasingly prevalent as these techniques have started to mature. We focus this survey solely on learning algorithms for the assignment step of multi-object tracking, and we attempt to unify various methods by highlighting their connections to linear assignment and to the multi-dimensional assignment problem. First, we review probabilistic and end-to-end optimization approaches to data association, followed by methods that learn association affinities from data. We then compare the performance of the methods presented in this survey and conclude by discussing future research directions.},
  archive      = {J_CSUR},
  author       = {Patrick Emami and Panos M. Pardalos and Lily Elefteriadou and Sanjay Ranka},
  doi          = {10.1145/3394659},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {69:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Machine learning methods for data association in multi-object tracking},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The future of false information detection on social media:
New perspectives and trends. <em>CSUR</em>, <em>53</em>(4), 68:1–36. (<a
href="https://doi.org/10.1145/3393880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive spread of false information on social media has become a global risk, implicitly influencing public opinion and threatening social/political development. False information detection (FID) has thus become a surging research topic in recent years. As a promising and rapidly developing research field, we find that much effort has been paid to new research problems and approaches of FID. Therefore, it is necessary to give a comprehensive review of the new research trends of FID. We first give a brief review of the literature history of FID, based on which we present several new research challenges and techniques of it, including early detection, detection by multimodal data fusion, and explanatory detection. We further investigate the extraction and usage of various crowd intelligence in FID, which paves a promising way to tackle FID challenges. Finally, we give our views on the open issues and future research directions of FID, such as model adaptivity/generality to new events, embracing of novel machine learning models, aggregation of crowd wisdom, adversarial attack and defense in detection models, and so on.},
  archive      = {J_CSUR},
  author       = {Bin Guo and Yasan Ding and Lina Yao and Yunji Liang and Zhiwen Yu},
  doi          = {10.1145/3393880},
  journal      = {ACM Computing Surveys},
  number       = {4},
  pages        = {68:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {The future of false information detection on social media: New perspectives and trends},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on ethereum systems security: Vulnerabilities,
attacks, and defenses. <em>CSUR</em>, <em>53</em>(3), 67:1–43. (<a
href="https://doi.org/10.1145/3391195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology is believed by many to be a game changer in many application domains. While the first generation of blockchain technology (i.e., Blockchain 1.0) is almost exclusively used for cryptocurrency, the second generation (i.e., Blockchain 2.0), as represented by Ethereum, is an open and decentralized platform enabling a new paradigm of computing—Decentralized Applications (DApps) running on top of blockchains. The rich applications and semantics of DApps inevitably introduce many security vulnerabilities, which have no counterparts in pure cryptocurrency systems like Bitcoin. Since Ethereum is a new, yet complex, system, it is imperative to have a systematic and comprehensive understanding on its security from a holistic perspective, which was previously unavailable in the literature. To the best of our knowledge, the present survey, which can also be used as a tutorial, fills this void. We systematize three aspects of Ethereum systems security: vulnerabilities, attacks, and defenses. We draw insights into vulnerability root causes, attack consequences, and defense capabilities, which shed light on future research directions.},
  archive      = {J_CSUR},
  author       = {Huashan Chen and Marcus Pendleton and Laurent Njilla and Shouhuai Xu},
  doi          = {10.1145/3391195},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {67:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on ethereum systems security: Vulnerabilities, attacks, and defenses},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial examples on object recognition: A comprehensive
survey. <em>CSUR</em>, <em>53</em>(3), 66:1–38. (<a
href="https://doi.org/10.1145/3398394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are at the forefront of machine learning research. However, despite achieving impressive performance on complex tasks, they can be very sensitive: Small perturbations of inputs can be sufficient to induce incorrect behavior. Such perturbations, called adversarial examples, are intentionally designed to test the network’s sensitivity to distribution drifts. Given their surprisingly small size, a wide body of literature conjectures on their existence and how this phenomenon can be mitigated. In this article, we discuss the impact of adversarial examples on security, safety, and robustness of neural networks. We start by introducing the hypotheses behind their existence, the methods used to construct or protect against them, and the capacity to transfer adversarial examples between different machine learning models. Altogether, the goal is to provide a comprehensive and self-contained survey of this growing field of research.},
  archive      = {J_CSUR},
  author       = {Alex Serban and Erik Poll and Joost Visser},
  doi          = {10.1145/3398394},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {66:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial examples on object recognition: A comprehensive survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An overview of service placement problem in fog and edge
computing. <em>CSUR</em>, <em>53</em>(3), 65:1–35. (<a
href="https://doi.org/10.1145/3391196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support the large and various applications generated by the Internet of Things (IoT), Fog Computing was introduced to complement the Cloud Computing and offer Cloud-like services at the edge of the network with low latency and real-time responses. Large-scale, geographical distribution, and heterogeneity of edge computational nodes make service placement in such infrastructure a challenging issue. Diversity of user expectations and IoT devices characteristics also complicate the deployment problem. This article presents a survey of current research conducted on Service Placement Problem (SPP) in the Fog/Edge Computing. Based on a new classification scheme, a categorization of current proposals is given and identified issues and challenges are discussed.},
  archive      = {J_CSUR},
  author       = {Farah Aït Salaht and Frédéric Desprez and Adrien Lebre},
  doi          = {10.1145/3391196},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {65:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {An overview of service placement problem in fog and edge computing},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Driver emotion recognition for intelligent vehicles: A
survey. <em>CSUR</em>, <em>53</em>(3), 64:1–30. (<a
href="https://doi.org/10.1145/3388790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving can occupy a large portion of daily life and often can elicit negative emotional states like anger or stress, which can significantly impact road safety and long-term human health. In recent decades, the arrival of new tools to help recognize human affect has inspired increasing interest in how to develop emotion-aware systems for cars. To help researchers make needed advances in this area, this article provides a comprehensive literature survey of work addressing the problem of human emotion recognition in an automotive context. We systematically review the literature back to 2002 and identify 63 peer-review published articles on this topic. We overview each study’s methodology to measure and recognize emotions in the context of driving. Across the literature, we find a strong preference toward studying emotional states associated with high arousal and negative valence, monitoring the different states with cardiac, electrodermal activity, and speech signals, and using supervised machine learning to automatically infer the underlying human affective states. This article summarizes the existing work together with publicly available resources (e.g., datasets and tools) to help new researchers get started in this field. We also identify new research opportunities to help advance progress for improving driver emotion recognition.},
  archive      = {J_CSUR},
  author       = {Sebastian Zepf and Javier Hernandez and Alexander Schmitt and Wolfgang Minker and Rosalind W. Picard},
  doi          = {10.1145/3388790},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {64:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Driver emotion recognition for intelligent vehicles: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalizing from a few examples: A survey on few-shot
learning. <em>CSUR</em>, <em>53</em>(3), 63:1–34. (<a
href="https://doi.org/10.1145/3386252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research. 1},
  archive      = {J_CSUR},
  author       = {Yaqing Wang and Quanming Yao and James T. Kwok and Lionel M. Ni},
  doi          = {10.1145/3386252},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {63:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generalizing from a few examples: A survey on few-shot learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning for source code modeling and generation:
Models, applications, and challenges. <em>CSUR</em>, <em>53</em>(3),
62:1–38. (<a href="https://doi.org/10.1145/3383458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) techniques for Natural Language Processing have been evolving remarkably fast. Recently, the DL advances in language modeling, machine translation, and paragraph understanding are so prominent that the potential of DL in Software Engineering cannot be overlooked, especially in the field of program learning. To facilitate further research and applications of DL in this field, we provide a comprehensive review to categorize and investigate existing DL methods for source code modeling and generation. To address the limitations of the traditional source code models, we formulate common program learning tasks under an encoder-decoder framework. After that, we introduce recent DL mechanisms suitable to solve such problems. Then, we present the state-of-the-art practices and discuss their challenges with some recommendations for practitioners and researchers as well.},
  archive      = {J_CSUR},
  author       = {Triet H. M. Le and Hao Chen and Muhammad Ali Babar},
  doi          = {10.1145/3383458},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {62:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning for source code modeling and generation: Models, applications, and challenges},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchains: A systematic multivocal literature review.
<em>CSUR</em>, <em>53</em>(3), 61:1–37. (<a
href="https://doi.org/10.1145/3369052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has gained tremendous popularity both in practice and academia. The goal of this article is to develop a coherent overview of the state of the art in blockchain technology, using a systematic (i.e., protocol-based, replicable), multivocal (i.e., featuring both white and grey literature alike) literature review to (1) define blockchain technology, (2) elaborate on its architecture options and (3) tradeoffs, as well as to understand (4) the current applications and challenges, as evident from the state of the art. We derive a systematic definition of blockchain technology, based on a formal concept analysis. Further, we flesh out an overview of blockchain technology elaborated by means of Grounded-Theory.},
  archive      = {J_CSUR},
  author       = {Bert-Jan Butijn and Damian A. Tamburri and Willem-Jan van den Heuvel},
  doi          = {10.1145/3369052},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {61:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blockchains: A systematic multivocal literature review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep journey into super-resolution: A survey.
<em>CSUR</em>, <em>53</em>(3), 60:1–34. (<a
href="https://doi.org/10.1145/3390462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional networks–based super-resolution is a fast-growing field with numerous practical applications. In this exposition, we extensively compare more than 30 state-of-the-art super-resolution Convolutional Neural Networks (CNNs) over three classical and three recently introduced challenging datasets to benchmark single image super-resolution. We introduce a taxonomy for deep learning–based super-resolution networks that groups existing methods into nine categories including linear, residual, multi-branch, recursive, progressive, attention-based, and adversarial designs. We also provide comparisons between the models in terms of network complexity, memory footprint, model input and output, learning details, the type of network losses, and important architectural differences (e.g., depth, skip-connections, filters). The extensive evaluation performed shows the consistent and rapid growth in the accuracy in the past few years along with a corresponding boost in model complexity and the availability of large-scale datasets. It is also observed that the pioneering methods identified as the benchmarks have been significantly outperformed by the current contenders. Despite the progress in recent years, we identify several shortcomings of existing techniques and provide future research directions towards the solution of these open problems. Datasets and codes for evaluation are publicly available at https://github.com/saeed-anwar/SRsurvey.},
  archive      = {J_CSUR},
  author       = {Saeed Anwar and Salman Khan and Nick Barnes},
  doi          = {10.1145/3390462},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {60:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A deep journey into super-resolution: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On resilience in cloud computing: A survey of techniques
across the cloud domain. <em>CSUR</em>, <em>53</em>(3), 59:1–36. (<a
href="https://doi.org/10.1145/3388922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud infrastructures are highly favoured as a computing delivery model worldwide, creating a strong societal dependence. It is therefore vital to enhance their resilience, providing persistent service delivery under a variety of conditions. Cloud environments are highly complex and continuously evolving. Additionally, the plethora of use-cases ensures requirements for persistent service delivery vary. As a contribution to knowledge, this work surveys resilience techniques for cloud environments. We apply a novel perspective using a layered model of traditional and emerging cloud paradigms. Works are then classified according to the Resilinets model. For each layer, the most common techniques with limitations are derived including an actor’s strength in influencing resilience in the cloud with each technique. We conclude with some future challenges to the field of resilient cloud computing.},
  archive      = {J_CSUR},
  author       = {Thomas Welsh and Elhadj Benkhelifa},
  doi          = {10.1145/3388922},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {59:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {On resilience in cloud computing: A survey of techniques across the cloud domain},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing server power modeling in a data center: Survey,
taxonomy, and performance evaluation. <em>CSUR</em>, <em>53</em>(3),
58:1–34. (<a href="https://doi.org/10.1145/3390605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data centers are large-scale, energy-hungry infrastructure serving the increasing computational demands as the world is becoming more connected in smart cities. The emergence of advanced technologies such as cloud-based services, internet of things (IoT), and big data analytics has augmented the growth of global data centers, leading to high energy consumption. This upsurge in energy consumption of the data centers not only incurs the issue of surging high cost (operational and maintenance) but also has an adverse effect on the environment. Dynamic power management in a data center environment requires the cognizance of the correlation between the system and hardware-level performance counters and the power consumption. Power consumption modeling exhibits this correlation and is crucial in designing energy-efficient optimization strategies based on resource utilization. Several works in power modeling are proposed and used in the literature. However, these power models have been evaluated using different benchmarking applications, power-measurement techniques, and error-calculation formulas on different machines. In this work, we present a taxonomy and evaluation of 24 software-based power models using a unified environment, benchmarking applications, power-measurement techniques, and error formulas, with the aim of achieving an objective comparison. We use different server architectures to assess the impact of heterogeneity on the models’ comparison. The performance analysis of these models is elaborated in the article.},
  archive      = {J_CSUR},
  author       = {Leila Ismail and Huned Materwala},
  doi          = {10.1145/3390605},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {58:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computing server power modeling in a data center: Survey, taxonomy, and performance evaluation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of machine learning approaches for student dropout
prediction in online courses. <em>CSUR</em>, <em>53</em>(3), 57:1–34.
(<a href="https://doi.org/10.1145/3388792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent diffusion of online education (both MOOCs and e-courses) has led to an increased economic and scientific interest in e-learning environments. As widely documented, online students have a much higher chance of dropping out than those attending conventional classrooms. It is of paramount interest for institutions, students, and faculty members to find more efficient methodologies to mitigate withdrawals. Following the rise of attention on the Student Dropout Prediction (SDP) problem, the literature has witnessed a significant increase in contributions to this subject. In this survey, we present an in-depth analysis of the state-of-the-art literature in the field of SDP, under the central perspective, but not exclusive, of machine learning predictive algorithms. Our main contributions are the following: (i) we propose a comprehensive hierarchical classification of existing literature that follows the workflow of design choices in the SDP; (ii) to facilitate the comparative analysis, we introduce a formal notation to describe in a uniform way the alternative dropout models investigated by the researchers in the field; (iii) we analyse some other relevant aspects to which the literature has given less attention, such as evaluation metrics, gathered data, and privacy concerns; (iv) we pay specific attention to deep sequential machine learning methods—recently proposed by some contributors—which represent one of the most effective solutions in this area. Overall, our survey provides novice readers who address these topics with practical guidance on design choices, as well as directs researchers to the most promising approaches, highlighting current limitations and open challenges in the field.},
  archive      = {J_CSUR},
  author       = {Bardh Prenkaj and Paola Velardi and Giovanni Stilo and Damiano Distante and Stefano Faralli},
  doi          = {10.1145/3388792},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {57:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of machine learning approaches for student dropout prediction in online courses},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling on two types of resources: A survey.
<em>CSUR</em>, <em>53</em>(3), 56:1–36. (<a
href="https://doi.org/10.1145/3387110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution in the design of modern parallel platforms leads to revisit the scheduling jobs on distributed heterogeneous resources. The goal of this survey is to present the main existing algorithms, to classify them based on their underlying principles, and to propose unified implementations to enable their fair comparison, in terms of running time and quality of schedules, on a large set of common benchmarks that we made available for the community. Beyond this comparison, our goal is also to understand the main difficulties that heterogeneity conveys and the shared principles that guide the design of efficient algorithms.},
  archive      = {J_CSUR},
  author       = {Olivier Beaumont and Louis-Claude Canon and Lionel Eyraud-Dubois and Giorgio Lucarelli and Loris Marchal and Clément Mommessin and Bertrand Simon and Denis Trystram},
  doi          = {10.1145/3387110},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {56:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Scheduling on two types of resources: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Outlier detection: Methods, models, and classification.
<em>CSUR</em>, <em>53</em>(3), 55:1–37. (<a
href="https://doi.org/10.1145/3381028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, we have witnessed an enormous amount of research effort dedicated to the design of efficient outlier detection techniques while taking into consideration efficiency, accuracy, high-dimensional data, and distributed environments, among other factors. In this article, we present and examine these characteristics, current solutions, as well as open challenges and future research directions in identifying new outlier detection strategies. We propose a taxonomy of the recently designed outlier detection strategies while underlying their fundamental characteristics and properties. We also introduce several newly trending outlier detection methods designed for high-dimensional data, data streams, big data, and minimally labeled data. Last, we review their advantages and limitations and then discuss future and new challenging issues.},
  archive      = {J_CSUR},
  author       = {Azzedine Boukerche and Lining Zheng and Omar Alfandi},
  doi          = {10.1145/3381028},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {55:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Outlier detection: Methods, models, and classification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on fuzzy deep neural networks. <em>CSUR</em>,
<em>53</em>(3), 54:1–25. (<a
href="https://doi.org/10.1145/3369798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are a class of powerful machine learning model that uses successive layers of non-linear processing units to extract features from data. However, the training process of such networks is quite computationally intensive and uses commonly used optimization methods that do not guarantee optimum performance. Furthermore, deep learning methods are often sensitive to noise in data and do not operate well in areas where data are incomplete. An alternative, yet little explored, method in enhancing deep learning performance is the use of fuzzy systems. Fuzzy systems have been previously used in conjunction with neural networks. This survey explores the different ways in which deep learning is improved with fuzzy logic systems. The techniques are classified based on how the two paradigms are combined. Finally, the real-life applications of the models are also explored.},
  archive      = {J_CSUR},
  author       = {Rangan Das and Sagnik Sen and Ujjwal Maulik},
  doi          = {10.1145/3369798},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {54:1–25},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on fuzzy deep neural networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A calculational deductive system for linear temporal logic.
<em>CSUR</em>, <em>53</em>(3), 53:1–38. (<a
href="https://doi.org/10.1145/3387109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article surveys the linear temporal logic (LTL) literature and presents all the LTL theorems from the survey, plus many new ones, in a calculational deductive system. Calculational deductive systems, developed by Dijkstra and Scholten and extended by Gries and Schneider, are based on only four inference rules—Substitution, Leibniz, Equanimity, and Transitivity. Inference rules in the older Hilbert-style systems, notably modus ponens, appear as theorems in this calculational deductive system. This article extends the calculational deductive system of Gries and Schneider to LTL, using only the same four inference rules. Although space limitations preclude giving a proof of every theorem in this article, every theorem has been proved with calculational logic.},
  archive      = {J_CSUR},
  author       = {J. Stanley Warford and David Vega and Scott M. Staley},
  doi          = {10.1145/3387109},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {53:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A calculational deductive system for linear temporal logic},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of context on small screen and wearable device
users’ performance - a systematic review. <em>CSUR</em>, <em>53</em>(3),
52:1–44. (<a href="https://doi.org/10.1145/3386370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small screen and wearable devices play a key role in most of our daily tasks and activities. However, depending on the context, users can easily experience situationally induced impairments and disabilities (SIIDs). Previous studies have defined SIIDs as a new type of impairment in which an able-bodied user’s behaviour is impaired by the context including the characteristics of a device and the environment. This article systematically reviews the empirical studies on the effect of context on SIIDs. In particular, this review aims to answer the following two research questions: Which contextual factors have been examined in the literature that can cause SIIDs and how different contextual factors affect small screen and wearable device users’ performance. This article systematically reviews 187 publications under a framework that has five factors for context analysis: physical, temporal, social, task, and technical contexts. This review shows that a significant amount of empirical studies have been conducted focusing on some factors such as mobility but there still are some factors such as social factors that need to be further considered for SIIDs. Finally, some factors have shown to have significant impact on users’ performance such as multitasking but not all factors has been empirically demonstrated to have an effect on users’ performance.},
  archive      = {J_CSUR},
  author       = {Elgin Akpinar and Yeliz Yeşilada and Selim Temizer},
  doi          = {10.1145/3386370},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {52:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {The effect of context on small screen and wearable device users’ performance - a systematic review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting errors for efficiency: A survey from circuits to
applications. <em>CSUR</em>, <em>53</em>(3), 51:1–39. (<a
href="https://doi.org/10.1145/3394898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a computational task tolerates a relaxation of its specification or when an algorithm tolerates the effects of noise in its execution, hardware, system software, and programming language compilers or their runtime systems can trade deviations from correct behavior for lower resource usage. We present, for the first time, a synthesis of research results on computing systems that only make as many errors as their end-to-end applications can tolerate. The results span the disciplines of computer-aided design of circuits, digital system design, computer architecture, programming languages, operating systems, and information theory. Rather than over-provisioning the resources controlled by each of these layers of abstraction to avoid errors, it can be more efficient to exploit the masking of errors occurring at one layer and thereby prevent those errors from propagating to a higher layer. We demonstrate the potential benefits of end-to-end approaches using two illustrative examples. We introduce a formalization of terminology that allows us to present a coherent view across the techniques traditionally used by different research communities in their individual layer of focus. Using this formalization, we survey tradeoffs for individual layers of computing systems at the circuit, architecture, operating system, and programming language levels as well as fundamental information-theoretic limits to tradeoffs between resource usage and correctness.},
  archive      = {J_CSUR},
  author       = {Phillip Stanley-Marbell and Armin Alaghi and Michael Carbin and Eva Darulova and Lara Dolecek and Andreas Gerstlauer and Ghayoor Gillani and Djordje Jevdjic and Thierry Moreau and Mattia Cacciotti and Alexandros Daglis and Natalie Enright Jerger and Babak Falsafi and Sasa Misailovic and Adrian Sampson and Damien Zufferey},
  doi          = {10.1145/3394898},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {51:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Exploiting errors for efficiency: A survey from circuits to applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource management and scheduling in distributed stream
processing systems: A taxonomy, review, and future directions.
<em>CSUR</em>, <em>53</em>(3), 50:1–41. (<a
href="https://doi.org/10.1145/3355399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream processing is an emerging paradigm to handle data streams upon arrival, powering latency-critical application such as fraud detection, algorithmic trading, and health surveillance. Though there are a variety of Distributed Stream Processing Systems (DSPSs) that facilitate the development of streaming applications, resource management and task scheduling is not automatically handled by the DSPS middleware and requires a laborious process to tune toward specific deployment targets. As the advent of cloud computing has supported renting resources on-demand, it is of great interest to review the research progress of hosting streaming systems in clouds under certain Service Level Agreements (SLA) and cost constraints. In this article, we introduce the hierarchical structure of streaming systems, define the scope of the resource management problem, and present a comprehensive taxonomy in this context covering critical research topics such as resource provisioning, operator parallelisation, and task scheduling. The literature is then reviewed following the taxonomy structure, facilitating a deeper understanding of the research landscape through classification and comparison of existing works. Finally, we discuss the open issues and future research directions toward realising an automatic, SLA-aware resource management framework.},
  archive      = {J_CSUR},
  author       = {Xunyun Liu and Rajkumar Buyya},
  doi          = {10.1145/3355399},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {50:1–41},
  shortjournal = {ACM Comput. Surv.},
  title        = {Resource management and scheduling in distributed stream processing systems: A taxonomy, review, and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time illumination and visual coherence for
photorealistic augmented/mixed reality. <em>CSUR</em>, <em>53</em>(3),
49:1–34. (<a href="https://doi.org/10.1145/3386496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A realistically inserted virtual object in the real-time physical environment is a desirable feature in augmented reality (AR) applications and mixed reality (MR) in general. This problem is considered a vital research area in computer graphics, a field that is experiencing ongoing discovery. The algorithms and methods used to obtain dynamic and real-time illumination measurement, estimating, and rendering of augmented reality scenes are utilized in many applications to achieve a realistic perception by humans. We cannot deny the powerful impact of the continuous development of computer vision and machine learning techniques accompanied by the original computer graphics and image processing methods to provide a significant range of novel AR/MR techniques. These techniques include methods for light source acquisition through image-based lighting or sampling, registering and estimating the lighting conditions, and composition of global illumination. In this review, we discussed the pipeline stages with the details elaborated about the methods and techniques that contributed to the development of providing a photo-realistic rendering, visual coherence, and interactive real-time illumination results in AR/MR.},
  archive      = {J_CSUR},
  author       = {A’Aeshah Alhakamy and Mihran Tuceryan},
  doi          = {10.1145/3386496},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {49:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Real-time illumination and visual coherence for photorealistic Augmented/Mixed reality},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey and classification of software-defined storage
systems. <em>CSUR</em>, <em>53</em>(3), 48:1–38. (<a
href="https://doi.org/10.1145/3385896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of digital information is imposing increasing scale and efficiency demands on modern storage infrastructures. As infrastructure complexity increases, so does the difficulty in ensuring quality of service, maintainability, and resource fairness, raising unprecedented performance, scalability, and programmability challenges. Software-Defined Storage (SDS) addresses these challenges by cleanly disentangling control and data flows, easing management, and improving control functionality of conventional storage systems. Despite its momentum in the research community, many aspects of the paradigm are still unclear, undefined, and unexplored, leading to misunderstandings that hamper the research and development of novel SDS technologies. In this article, we present an in-depth study of SDS systems, providing a thorough description and categorization of each plane of functionality. Further, we propose a taxonomy and classification of existing SDS solutions according to different criteria. Finally, we provide key insights about the paradigm and discuss potential future research directions for the field.},
  archive      = {J_CSUR},
  author       = {Ricardo Macedo and João Paulo and José Pereira and Alysson Bessani},
  doi          = {10.1145/3385896},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {48:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey and classification of software-defined storage systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visual question generation: The state of the art.
<em>CSUR</em>, <em>53</em>(3), 47:1–22. (<a
href="https://doi.org/10.1145/3383465">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question generation (VQG) is an interesting problem that has recently received attention. The task of VQG involves generating meaningful questions based on the input image. It is a multi-modal problem involving image understanding and natural language generation, especially using deep learning methods. VQG can be considered as complementary task of visual question answering. In this article, we review the current state of VQG in terms of methods to understand the problem, existing datasets to train the VQG model, evaluation metrics, and algorithms to handle the problem. Finally, we discuss the challenges that need to be conquered and the possible future directions for an effective VQG.},
  archive      = {J_CSUR},
  author       = {Charulata Patil and Manasi Patwardhan},
  doi          = {10.1145/3383465},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {47:1–22},
  shortjournal = {ACM Comput. Surv.},
  title        = {Visual question generation: The state of the art},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SLA management for big data analytical applications in
clouds: A taxonomy study. <em>CSUR</em>, <em>53</em>(3), 46:1–40. (<a
href="https://doi.org/10.1145/3383464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the booming of big data analytical applications (BDAAs). This trend provides unrivaled opportunities to reveal the latent patterns and correlations embedded in the data, and thus productive decisions may be made. This was previously a grand challenge due to the notoriously high dimensionality and scale of big data, whereas the quality of service offered by providers is the first priority. As BDAAs are routinely deployed on Clouds with great complexities and uncertainties, it is a critical task to manage the service level agreements (SLAs) so that a high quality of service can then be guaranteed. This study performs a systematic literature review of the state of the art of SLA-specific management for Cloud-hosted BDAAs. The review surveys the challenges and contemporary approaches along this direction centering on SLA. A research taxonomy is proposed to formulate the results of the systematic literature review. A new conceptual SLA model is defined and a multi-dimensional categorization scheme is proposed on its basis to apply the SLA metrics for an in-depth understanding of managing SLAs and the motivation of trends for future research.},
  archive      = {J_CSUR},
  author       = {Xuezhi Zeng and Saurabh Garg and Mutaz Barika and Albert Y. Zomaya and Lizhe Wang and Massimo Villari and Dan Chen and Rajiv Ranjan},
  doi          = {10.1145/3383464},
  journal      = {ACM Computing Surveys},
  number       = {3},
  pages        = {46:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {SLA management for big data analytical applications in clouds: A taxonomy study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security issues and challenges for virtualization
technologies. <em>CSUR</em>, <em>53</em>(2), 45:1–37. (<a
href="https://doi.org/10.1145/3382190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtualization-based technologies have become ubiquitous in computing. While they provide an easy-to-implement platform for scalable, high-availability services, they also introduce new security issues. Traditionally, discussions on security vulnerabilities in server platforms have been focused on stand-alone (i.e., non-virtualized) environments. For cloud and virtualized platforms, the discussion focuses on the shared usage of resources and the lack of control over the infrastructure. However, the impact virtualization technologies can have on exploit mitigation mechanisms of host machines is often neglected. Therefore, this survey discusses the following issues: first, the security issues and challenges that are introduced by the migration from stand-alone solutions to virtualized environments—special attention is given to the Virtual Machine Monitor, since it is a core component in a virtualized solution; second, the impact (sometimes negative) that these new technologies have on existing security strategies for hosts; third, how virtualization technologies can be leveraged to provide new security mechanisms not previously available.; and, finally, how virtualization technologies can be used for malicious purposes.},
  archive      = {J_CSUR},
  author       = {Federico Sierra-Arriaga and Rodrigo Branco and Ben Lee},
  doi          = {10.1145/3382190},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {45:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Security issues and challenges for virtualization technologies},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of IIoT protocols: A measure of vulnerability risk
analysis based on CVSS. <em>CSUR</em>, <em>53</em>(2), 44:1–53. (<a
href="https://doi.org/10.1145/3381038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is present in many participants from the energy, health, manufacturing, transport, and public sectors. Many factors catalyze IIoT, such as robotics, artificial intelligence, and intelligent decentralized manufacturing. However, the convergence between IT, OT, and IoT environments involves the integration of heterogeneous technologies through protocols, standards, and buses. However, this integration brings with it security risks. To avoid the security risks, especially when systems in different environments interact, it is important and urgent to create an early consensus among the stakeholders on the IIoT security. The default Common Vulnerability Scoring System (CVSS) offers a mechanism to measure the severity of an asset&#39;s vulnerability and therefore a way to characterize the risk. However, CVSS by default has two drawbacks. On the one hand, to carry out a risk analysis, it is necessary to have additional metrics to the one established by CVSSv3.1. On the other hand, this index has been used mostly in IT environments and although there are numerous efforts to develop a model that suits industrial environments, there is no established proposal. Therefore, we first propose a survey of the main 33 protocols, standards, and buses used in an IIoT environment. This survey will focus on the security of each one. The second part of our study consists of the creation of a framework to characterize risk in industrial environments, i.e., to solve both problems of the CVSS index. To this end, we created the Vulnerability Analysis Framework (VAF), which is a methodology that allows the analysis of 1,363 vulnerabilities to establish a measure to describe the risk in IIoT environments.},
  archive      = {J_CSUR},
  author       = {Santiago Figueroa-Lorenzo and Javier Añorga and Saioa Arrizabalaga},
  doi          = {10.1145/3381038},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {44:1–53},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of IIoT protocols: A measure of vulnerability risk analysis based on CVSS},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on automatic parameter tuning for big data
processing systems. <em>CSUR</em>, <em>53</em>(2), 43:1–37. (<a
href="https://doi.org/10.1145/3381027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data processing systems (e.g., Hadoop, Spark, Storm) contain a vast number of configuration parameters controlling parallelism, I/O behavior, memory settings, and compression. Improper parameter settings can cause significant performance degradation and stability issues. However, regular users and even expert administrators grapple with understanding and tuning them to achieve good performance. We investigate existing approaches on parameter tuning for both batch and stream data processing systems and classify them into six categories: rule-based, cost modeling, simulation-based, experiment-driven, machine learning, and adaptive tuning. We summarize the pros and cons of each approach and raise some open research problems for automatic parameter tuning.},
  archive      = {J_CSUR},
  author       = {Herodotos Herodotou and Yuxing Chen and Jiaheng Lu},
  doi          = {10.1145/3381027},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {43:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on automatic parameter tuning for big data processing systems},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trade-offs between distributed ledger technology
characteristics. <em>CSUR</em>, <em>53</em>(2), 42:1–37. (<a
href="https://doi.org/10.1145/3379463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When developing peer-to-peer applications on distributed ledger technology (DLT), a crucial decision is the selection of a suitable DLT design (e.g., Ethereum), because it is hard to change the underlying DLT design post hoc. To facilitate the selection of suitable DLT designs, we review DLT characteristics and identify trade-offs between them. Furthermore, we assess how DLT designs account for these trade-offs and we develop archetypes for DLT designs that cater to specific requirements of applications on DLT. The main purpose of our article is to introduce scientific and practical audiences to the intricacies of DLT designs and to support development of viable applications on DLT.},
  archive      = {J_CSUR},
  author       = {Niclas Kannengießer and Sebastian Lins and Tobias Dehling and Ali Sunyaev},
  doi          = {10.1145/3379463},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {42:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Trade-offs between distributed ledger technology characteristics},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on renamings of software entities. <em>CSUR</em>,
<em>53</em>(2), 41:1–38. (<a
href="https://doi.org/10.1145/3379443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 70\% of characters in the source code are used to label identifiers. Consequently, identifiers are one of the most important source for program comprehension. Meaningful identifiers are crucial to understand and maintain programs. However, for reasons like constrained schedule, inexperience, and unplanned evolution, identifiers may fail to convey the semantics of the entities associated with them. As a result, such entities should be renamed to improve software quality. However, manual renaming and recommendation are fastidious, time consuming, and error prone, whereas automating the process of renamings is challenging: (1) It involves complex natural language processing to understand the meaning of identifers; (2) It also involves difficult semantic analysis to determine the role of software entities. Researchers proposed a number of approaches and tools to facilitate renamings. We present a survey on existing approaches and classify them into identification of renaming opportunities, execution of renamings, and detection of renamings. We find that there is an imbalance between the three type of approaches, and most of implementation of approaches and evaluation dataset are not publicly available. We also discuss the challenges and present potential research directions. To the best of our knowledge, this survey is the first comprehensive study on renamings of software entities.},
  archive      = {J_CSUR},
  author       = {Guangjie Li and Hui Liu and Ally S. Nyamawe},
  doi          = {10.1145/3379443},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {41:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on renamings of software entities},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A taxonomy of supervised learning for IDSs in SCADA
environments. <em>CSUR</em>, <em>53</em>(2), 40:1–37. (<a
href="https://doi.org/10.1145/3379499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervisory Control and Data Acquisition (SCADA) systems play an important role in monitoring industrial processes such as electric power distribution, transport systems, water distribution, and wastewater collection systems. Such systems require a particular attention with regards to security aspects, as they deal with critical infrastructures that are crucial to organizations and countries. Protecting SCADA systems from intrusion is a very challenging task because they do not only inherit traditional IT security threats but they also include additional vulnerabilities related to field components (e.g., cyber-physical attacks). Many of the existing intrusion detection techniques rely on supervised learning that consists of algorithms that are first trained with reference inputs to learn specific information, and then tested on unseen inputs for classification purposes. This article surveys supervised learning from a specific security angle, namely SCADA-based intrusion detection. Based on a systematic review process, existing literature is categorized and evaluated according to SCADA-specific requirements. Additionally, this survey reports on well-known SCADA datasets and testbeds used with machine learning methods. Finally, we present key challenges and our recommendations for using specific supervised methods for SCADA systems.},
  archive      = {J_CSUR},
  author       = {Jakapan Suaboot and Adil Fahad and Zahir Tari and John Grundy and Abdun Naser Mahmood and Abdulmohsen Almalawi and Albert Y. Zomaya and Khalil Drira},
  doi          = {10.1145/3379499},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {40:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A taxonomy of supervised learning for IDSs in SCADA environments},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A critical survey of the multilevel method in complex
networks. <em>CSUR</em>, <em>53</em>(2), 39:1–35. (<a
href="https://doi.org/10.1145/3379347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multilevel optimization aims at reducing the cost of executing a target network-based algorithm by exploiting coarsened, i.e., reduced or simplified, versions of the network. There is a growing interest in multilevel algorithms in networked systems, mostly motivated by the urge for solutions capable of handling large-scale networks. Notwithstanding the success of multilevel optimization in a multitude of application problems, we were unable to find a representative survey of the state-of-the-art, or consistent descriptions of the method as a general theoretical framework independent of a specific application domain. In this article, we strive to fill this gap, presenting an extensive survey of the literature that contemplates a systematic overview of the state-of-the-art, a panorama of the historical evolution and current challenges, and a formal theoretical framework of the multilevel optimization method in complex networks. We believe our survey provides a useful resource to individuals interested in learning about multilevel strategies, as well as to those engaged in advancing theoretical and practical aspects of the method or in developing solutions in novel application domains.},
  archive      = {J_CSUR},
  author       = {Alan Valejo and Vinícius Ferreira and Renato Fabbri and Maria Cristina Ferreira de Oliveira and Alneu de Andrade Lopes},
  doi          = {10.1145/3379347},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {39:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A critical survey of the multilevel method in complex networks},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of hierarchical energy optimization for mobile edge
computing: A perspective from end devices to the cloud. <em>CSUR</em>,
<em>53</em>(2), 38:1–44. (<a
href="https://doi.org/10.1145/3378935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of wireless technology, various emerging mobile applications are attracting significant attention and drastically changing our daily lives. Applications such as augmented reality and object recognition demand stringent delay and powerful processing capability, which exerts enormous pressure on mobile devices with limited resources and energy. In this article, a survey of techniques for mobile device energy optimization is presented in a hierarchy of device design and operation, computation offloading, wireless data transmission, and cloud execution of offloaded computation. Energy management strategies for mobile devices from hardware and software aspects are first discussed, followed by energy-efficient computation offloading frameworks for mobile applications that trade application response time for device energy consumption. Then, techniques for efficient wireless data communication to reduce transmission energy are summarized. Finally, the execution mechanisms of application components or tasks in various clouds are further described to provide energy-saving opportunities for mobile devices. We classify the research works based on key characteristics of devices and applications to emphasize their similarities and differences. We hope that this survey will give insights to researchers into energy management mechanisms on mobile devices, and emphasize the crucial importance of optimizing device energy consumption for more research efforts in this area.},
  archive      = {J_CSUR},
  author       = {Peijin Cong and Junlong Zhou and Liying Li and Kun Cao and Tongquan Wei and Keqin Li},
  doi          = {10.1145/3378935},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {38:1–44},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of hierarchical energy optimization for mobile edge computing: A perspective from end devices to the cloud},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge transfer in vision recognition: A survey.
<em>CSUR</em>, <em>53</em>(2), 37:1–35. (<a
href="https://doi.org/10.1145/3379344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, we propose to explore and discuss the common rules behind knowledge transfer works for vision recognition tasks. To achieve this, we firstly discuss the different kinds of reusable knowledge existing in a vision recognition task, and then we categorize different knowledge transfer approaches depending on where the knowledge comes from and where the knowledge goes. Compared to previous surveys on knowledge transfer that are from the problem-oriented perspective or from the technique-oriented perspective, our viewpoint is closer to the nature of knowledge transfer and reveals common rules behind different transfer learning settings and applications. Besides different knowledge transfer categories, we also show some research works that study the transferability between different vision recognition tasks. We further give a discussion about the introduced research works and show some potential research directions in this field.},
  archive      = {J_CSUR},
  author       = {Ying Lu and Lingkun Luo and Di Huang and Yunhong Wang and Liming Chen},
  doi          = {10.1145/3379344},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {37:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Knowledge transfer in vision recognition: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph generators: State of the art and open challenges.
<em>CSUR</em>, <em>53</em>(2), 36:1–30. (<a
href="https://doi.org/10.1145/3379445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The abundance of interconnected data has fueled the design and implementation of graph generators reproducing real-world linking properties or gauging the effectiveness of graph algorithms, techniques, and applications manipulating these data. We consider graph generation across multiple subfields, such as Semantic Web, graph databases, social networks, and community detection, along with general graphs. Despite the disparate requirements of modern graph generators throughout these communities, we analyze them under a common umbrella, reaching out the functionalities, the practical usage, and their supported operations. We argue that this classification is serving the need of providing scientists, researchers, and practitioners with the right data generator at hand for their work. This survey provides a comprehensive overview of the state-of-the-art graph generators by focusing on those that are pertinent and suitable for several data-intensive tasks. Finally, we discuss open challenges and missing requirements of current graph generators along with their future extensions to new emerging fields.},
  archive      = {J_CSUR},
  author       = {Angela Bonifati and Irena Holubová and Arnau Prat-Pérez and Sherif Sakr},
  doi          = {10.1145/3379445},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {36:1–30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Graph generators: State of the art and open challenges},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of network virtualization techniques for internet
of things using SDN and NFV. <em>CSUR</em>, <em>53</em>(2), 35:1–40. (<a
href="https://doi.org/10.1145/3379444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) and Network Softwarization are fast becoming core technologies of information systems and network management for the next-generation Internet. The deployment and applications of IoT range from smart cities to urban computing and from ubiquitous healthcare to tactile Internet. For this reason, the physical infrastructure of heterogeneous network systems has become more complicated and thus requires efficient and dynamic solutions for management, configuration, and flow scheduling. Network softwarization in the form of Software Defined Networks and Network Function Virtualization has been extensively researched for IoT in the recent past. In this article, we present a systematic and comprehensive review of virtualization techniques explicitly designed for IoT networks. We have classified the literature into software-defined networks designed for IoT, function virtualization for IoT networks, and software-defined IoT networks. These categories are further divided into works that present architectural, security, and management solutions. Besides, the article highlights several short-term and long-term research challenges and open issues related to the adoption of software-defined Internet of Things.},
  archive      = {J_CSUR},
  author       = {Iqbal Alam and Kashif Sharif and Fan Li and Zohaib Latif and M. M. Karim and Sujit Biswas and Boubakr Nour and Yu Wang},
  doi          = {10.1145/3379444},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {35:1–40},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of network virtualization techniques for internet of things using SDN and NFV},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Content delivery networks: State of the art, trends, and
future roadmap. <em>CSUR</em>, <em>53</em>(2), 34:1–34. (<a
href="https://doi.org/10.1145/3380613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Content Delivery Networks (CDN) have become more and more popular. The technology itself is ahead of academic research in this area. Several dimensions of the technology have not been adequately investigated by academia. These dimensions include outline management, security, and standardization. Discovering and highlighting aspects of this technology that may have or have not been covered by academic research is the first step toward helping academia bridge the gap with industry or even go one step further to lead industry in the right direction. This suggests a comprehensive survey on research works in this regard. The literature in this area has already come up with some surveys and taxonomies, but some of them are outdated or do not cover every aspect of CDN while others fail to detect existing trends or to develop a holistic roadmap for research on the technology. Furthermore, none of the existing surveys aim at enlightening the dark aspects of the technology that have not been subject to academic research. In this survey, we first extract the lifecycle of a CDN as suggested by the existing research. Then, we investigate previous relevant works on each phase of the lifecycle to clarify where the research is currently located and headed. We show how CDN technology tends to converge with emerging paradigms such as cloud computing, edge computing, and machine learning, which are more mature in terms of academic research. This helps us determine the right direction for further research by revealing the deficiencies in existing works.},
  archive      = {J_CSUR},
  author       = {Behrouz Zolfaghari and Gautam Srivastava and Swapnoneel Roy and Hamid R. Nemati and Fatemeh Afghah and Takeshi Koshiba and Abolfazl Razi and Khodakhast Bibak and Pinaki Mitra and Brijesh Kumar Rai},
  doi          = {10.1145/3380613},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {34:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Content delivery networks: State of the art, trends, and future roadmap},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tools for reduced precision computation: A survey.
<em>CSUR</em>, <em>53</em>(2), 33:1–35. (<a
href="https://doi.org/10.1145/3381039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of reduced precision to improve performance metrics such as computation latency and power consumption is a common practice in the embedded systems field. This practice is emerging as a new trend in High Performance Computing (HPC), especially when new error-tolerant applications are considered. However, standard compiler frameworks do not support automated precision customization, and manual tuning and code transformation is the approach usually adopted in most domains. In recent years, research have been studying ways to improve the automation of this process. This article surveys this body of work, identifying the critical steps of this process, the most advanced tools available, and the open challenges in this research area. We conclude that, while several mature tools exist, there is still a gap to close, especially for tools based on static analysis rather than profiling, as well as for integration within mainstream, industry-strength compiler frameworks.},
  archive      = {J_CSUR},
  author       = {Stefano Cherubin and Giovanni Agosta},
  doi          = {10.1145/3381039},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {33:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Tools for reduced precision computation: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computer-generated holograms for 3D imaging: A survey.
<em>CSUR</em>, <em>53</em>(2), 32:1–35. (<a
href="https://doi.org/10.1145/3378444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Holography is usually considered as the ultimate way to visually reproduce a three-dimensional scene. Computer-generated holography constitutes an important branch of holography, which enables visualization of artificially generated scenes as well as real three-dimensional scenes recorded under white-light illumination. In this article, we present a comprehensive survey of methods for synthesis of computer-generated holograms, classifying them into two broad categories: wavefront-based methods and ray-based methods. We examine their modern implementations in terms of the quality of reconstruction and computational efficiency. As it is an integral part of computer-generated holography, we devote a special section to speckle suppression, which is also discussed under two categories following the classification of underlying computer-generated hologram methods.},
  archive      = {J_CSUR},
  author       = {Erdem Sahin and Elena Stoykova and Jani Mäkinen and Atanas Gotchev},
  doi          = {10.1145/3378444},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {32:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Computer-generated holograms for 3D imaging: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blocking and filtering techniques for entity resolution: A
survey. <em>CSUR</em>, <em>53</em>(2), 31:1–42. (<a
href="https://doi.org/10.1145/3377455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity Resolution (ER), a core task of Data Integration, detects different entity profiles that correspond to the same real-world object. Due to its inherently quadratic complexity, a series of techniques accelerate it so that it scales to voluminous data. In this survey, we review a large number of relevant works under two different but related frameworks: Blocking and Filtering. The former restricts comparisons to entity pairs that are more likely to match, while the latter identifies quickly entity pairs that are likely to satisfy predetermined similarity thresholds. We also elaborate on hybrid approaches that combine different characteristics. For each framework we provide a comprehensive list of the relevant works, discussing them in the greater context. We conclude with the most promising directions for future work in the field.},
  archive      = {J_CSUR},
  author       = {George Papadakis and Dimitrios Skoutas and Emmanouil Thanos and Themis Palpanas},
  doi          = {10.1145/3377455},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {31:1–42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Blocking and filtering techniques for entity resolution: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on distributed machine learning. <em>CSUR</em>,
<em>53</em>(2), 30:1–33. (<a
href="https://doi.org/10.1145/3377454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.},
  archive      = {J_CSUR},
  author       = {Joost Verbraeken and Matthijs Wolting and Jonathan Katzy and Jeroen Kloppenburg and Tim Verbelen and Jan S. Rellermeyer},
  doi          = {10.1145/3377454},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {30:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on distributed machine learning},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indicator-based multi-objective evolutionary algorithms: A
comprehensive survey. <em>CSUR</em>, <em>53</em>(2), 29:1–35. (<a
href="https://doi.org/10.1145/3376916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For over 25 years, most multi-objective evolutionary algorithms (MOEAs) have adopted selection criteria based on Pareto dominance. However, the performance of Pareto-based MOEAs quickly degrades when solving multi-objective optimization problems (MOPs) having four or more objective functions (the so-called many-objective optimization problems), mainly because of the loss of selection pressure. Consequently, in recent years, MOEAs have been coupled with indicator-based selection mechanisms in furtherance of increasing the selection pressure so that they can properly solve many-objective optimization problems. Several research efforts have been conducted since 2003 regarding the design of the so-called indicator-based (IB) MOEAs. In this article, we present a comprehensive survey of IB-MOEAs for continuous search spaces since their origins up to the current state-of-the-art approaches. We propose a taxonomy that classifies IB-mechanisms into two main categories: (1) IB-Selection (which is divided into IB-Environmental Selection, IB-Density Estimation, and IB-Archiving) and (2) IB-Mating Selection. Each of these classes is discussed in detail in this article, emphasizing the advantages and drawbacks of the selection mechanisms. In the final part, we provide some possible paths for future research.},
  archive      = {J_CSUR},
  author       = {Jesús Guillermo Falcón-Cardona and Carlos A. Coello Coello},
  doi          = {10.1145/3376916},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {29:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Indicator-based multi-objective evolutionary algorithms: A comprehensive survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label active learning algorithms for image
classification: Overview and future promise. <em>CSUR</em>,
<em>53</em>(2), 28:1–35. (<a
href="https://doi.org/10.1145/3379504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification is a key task in image understanding, and multi-label image classification has become a popular topic in recent years. However, the success of multi-label image classification is closely related to the way of constructing a training set. As active learning aims to construct an effective training set through iteratively selecting the most informative examples to query labels from annotators, it was introduced into multi-label image classification. Accordingly, multi-label active learning is becoming an important research direction. In this work, we first review existing multi-label active learning algorithms for image classification. These algorithms can be categorized into two top groups from two aspects respectively: sampling and annotation. The most important component of multi-label active learning is to design an effective sampling strategy that actively selects the examples with the highest informativeness from an unlabeled data pool, according to various information measures. Thus, different informativeness measures are emphasized in this survey. Furthermore, this work also makes a deep investigation on existing challenging issues and future promises in multi-label active learning with a focus on four core aspects: example dimension, label dimension, annotation, and application extension.},
  archive      = {J_CSUR},
  author       = {Jian Wu and Victor S. Sheng and Jing Zhang and Hua Li and Tetiana Dadakova and Christine Leon Swisher and Zhiming Cui and Pengpeng Zhao},
  doi          = {10.1145/3379504},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {28:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multi-label active learning algorithms for image classification: Overview and future promise},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of blockchain-based strategies for healthcare.
<em>CSUR</em>, <em>53</em>(2), 27:1–27. (<a
href="https://doi.org/10.1145/3376915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has been gaining visibility owing to its ability to enhance the security, reliability, and robustness of distributed systems. Several areas have benefited from research based on this technology, such as finance, remote sensing, data analysis, and healthcare. Data immutability, privacy, transparency, decentralization, and distributed ledgers are the main features that make blockchain an attractive technology. However, healthcare records that contain confidential patient data make this system very complicated because there is a risk of a privacy breach. This study aims to address research into the applications of the blockchain healthcare area. It sets out by discussing the management of medical information, as well as the sharing of medical records, image sharing, and log management. We also discuss papers that intersect with other areas, such as the Internet of Things, the management of information, tracking of drugs along their supply chain, and aspects of security and privacy. As we are aware that there are other surveys of blockchain in healthcare, we analyze and compare both the positive and negative aspects of their papers. Finally, we seek to examine the concepts of blockchain in the medical area, by assessing their benefits and drawbacks and thus giving guidance to other researchers in the area. Additionally, we summarize the methods used in healthcare per application area and show their pros and cons.},
  archive      = {J_CSUR},
  author       = {Erikson Júlio De Aguiar and Bruno S. Faiçal and Bhaskar Krishnamachari and Jó Ueyama},
  doi          = {10.1145/3376915},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {27:1–27},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of blockchain-based strategies for healthcare},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of profit optimization techniques for cloud
providers. <em>CSUR</em>, <em>53</em>(2), 26:1–35. (<a
href="https://doi.org/10.1145/3376917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the demand for computing resources grows, cloud computing becomes more and more popular as a pay-as-you-go model, in which the computing resources and services are provided to cloud users efficiently. For cloud providers, the typical goal is to maximize their profits. However, maximizing profits in a highly competitive cloud market is a huge challenge for cloud providers. In this article, a survey of profit optimization techniques is proposed to increase cloud provider profitability through service quality improvement, service pricing, energy consumption reduction, and virtual network function (VNF) deployment. The strategy of improving user service quality is discussed first, followed by the pricing strategy for cloud resources to maximize revenue. Then, this article summarizes the techniques for cloud data centers to reduce server power consumption. Finally, various heuristic algorithms for VNF deployment in the cloud are further described to reduce the cost of cloud providers while maintaining performance. We classify research works based on components of profit and methods used to demonstrate similarities and differences in these studies. We hope this survey will provide researchers with insights into cloud profit optimization techniques.},
  archive      = {J_CSUR},
  author       = {Peijin Cong and Guo Xu and Tongquan Wei and Keqin Li},
  doi          = {10.1145/3376917},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {26:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of profit optimization techniques for cloud providers},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attack and system modeling applied to IoT, cloud, and mobile
ecosystems: Embedding security by design. <em>CSUR</em>, <em>53</em>(2),
25:1–32. (<a href="https://doi.org/10.1145/3376123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, pervasive computing and communication technologies have enabled the emergence of new computing paradigms that have gained importance across a wide spectrum of domains. The three most notable that have witnessed significant advancements and have a solid track record of exponential growth in diverse applications are the Internet of Things (IoT), Cloud, and Mobile Computing. The ubiquity of these paradigms, their expandability, and applicability in different problem spaces have made them invaluable in modern computing solutions. Security becomes a real concern, especially when it comes to the development of applications in these environments, as numerous security issues may arise from potential design flaws. Secure application development across these three technologies can only be achieved when applications and systems are designed and developed with security in mind. This will improve the quality of the solutions and ensure that vulnerabilities are identified. It will also help in defining countermeasures against cyberattacks or mitigate the effects of potential threats to the systems. This article surveys existing approaches, tools, and techniques for attack and system modeling applicable to IoT, Cloud computing, and Mobile Computing. It also evaluates the strengths and limitations of the reviewed approaches and tools, from which it highlights the main existing challenges and open issues in the area.},
  archive      = {J_CSUR},
  author       = {João B. F. Sequeiros and Francisco T. Chimuco and Musa G. Samaila and Mário M. Freire and Pedro R. M. Inácio},
  doi          = {10.1145/3376123},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {25:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Attack and system modeling applied to IoT, cloud, and mobile ecosystems: Embedding security by design},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on computational metaphor processing.
<em>CSUR</em>, <em>53</em>(2), 24:1–37. (<a
href="https://doi.org/10.1145/3373265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, the problem of computational metaphor processing has garnered immense attention from the domains of computational linguistics and cognition. A wide panorama of approaches, ranging from a hand-coded rule system to deep learning techniques, have been proposed to automate different aspects of metaphor processing. In this article, we systematically examine the major theoretical views on metaphor and present their classification. We discuss the existing literature to provide a concise yet representative picture of computational metaphor processing. We conclude the article with possible research directions.},
  archive      = {J_CSUR},
  author       = {Sunny Rai and Shampa Chakraverty},
  doi          = {10.1145/3373265},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {24:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on computational metaphor processing},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The landscape of exascale research: A data-driven literature
analysis. <em>CSUR</em>, <em>53</em>(2), 23:1–43. (<a
href="https://doi.org/10.1145/3372390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next generation of supercomputers will break the exascale barrier. Soon we will have systems capable of at least one quintillion (billion billion) floating-point operations per second (10 18 FLOPS). Tremendous amounts of work have been invested into identifying and overcoming the challenges of the exascale era. In this work, we present an overview of these efforts and provide insight into the important trends, developments, and exciting research opportunities in exascale computing. We use a three-stage approach in which we (1) discuss various exascale landmark studies, (2) use data-driven techniques to analyze the large collection of related literature, and (3) discuss eight research areas in depth based on influential articles. Overall, we observe that great advancements have been made in tackling the two primary exascale challenges: energy efficiency and fault tolerance. However, as we look forward, we still foresee two major concerns: the lack of suitable programming tools and the growing gap between processor performance and data bandwidth (i.e., memory, storage, networks). Although we will certainly reach exascale soon, without additional research, these issues could potentially limit the applicability of exascale computing.},
  archive      = {J_CSUR},
  author       = {Stijn Heldens and Pieter Hijma and Ben Van Werkhoven and Jason Maassen and Adam S. Z. Belloum and Rob V. Van Nieuwpoort},
  doi          = {10.1145/3372390},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {23:1–43},
  shortjournal = {ACM Comput. Surv.},
  title        = {The landscape of exascale research: A data-driven literature analysis},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). In memoriam eliezer dekel (1948-2020). <em>CSUR</em>,
<em>53</em>(2), 23:1–2. (<a
href="https://doi.org/10.1145/3389414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No abstract available.},
  archive      = {J_CSUR},
  author       = {Sartaj Sahni and Albert Y. Zomaya},
  doi          = {10.1145/3389414},
  journal      = {ACM Computing Surveys},
  number       = {2},
  pages        = {23:1–2},
  shortjournal = {ACM Comput. Surv.},
  title        = {In memoriam eliezer dekel (1948-2020)},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A methodology for comparing the reliability of GPU-based and
CPU-based HPCs. <em>CSUR</em>, <em>53</em>(1), 22:1–33. (<a
href="https://doi.org/10.1145/3372790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, GPUs are widely used as coprocessors/accelerators in High-Performance Heterogeneous Computing due to their many advantages. However, many researches emphasize that GPUs are not as reliable as desired yet. Despite the fact that GPUs are more vulnerable to hardware errors than CPUs, the use of GPUs in HPCs is increasing more and more. Moreover, due to native reliability problems of GPUs, combining a great number of GPUs with CPUs can significantly increase HPCs’ failure rates. For this reason, analyzing the reliability characteristics of GPU-based HPCs has become a very important issue. Therefore, in this study we evaluate the reliability of GPU-based HPCs. For this purpose, we first examined field data analysis studies for GPU-based and CPU-based HPCs and identified factors that could increase systems failure/error rates. We then compared GPU-based HPCs with CPU-based HPCs in terms of reliability with the help of these factors in order to point out reliability challenges of GPU-based HPCs. Our primary goal is to present a study that can guide the researchers in this field by indicating the current state of GPU-based heterogeneous HPCs and requirements for the future, in terms of reliability. Our second goal is to offer a methodology to compare the reliability of GPU-based HPCs and CPU-based HPCs. To the best of our knowledge, this is the first survey study to compare the reliability of GPU-based and CPU-based HPCs in a systematic manner.},
  archive      = {J_CSUR},
  author       = {Nevin Cini and Gulay Yalcin},
  doi          = {10.1145/3372790},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {22:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {A methodology for comparing the reliability of GPU-based and CPU-based HPCs},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of context simulation for testing mobile
context-aware applications. <em>CSUR</em>, <em>53</em>(1), 21:1–39. (<a
href="https://doi.org/10.1145/3372788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Equipped with an abundance of small-scale microelectromechanical sensors, modern mobile devices such as smartphones and smartwatches can now offer context-aware services to users in mobile environments. Although advances in mobile context-aware applications have made our everyday environments increasingly intelligent, these applications are prone to bugs that are highly difficult to reproduce and repair. Compared to conventional computer software, mobile context-aware applications often have more complex structures to process a wide variety of dynamic context data in specific scenarios. Accordingly, researchers have proposed diverse context simulation techniques to enable low-cost and effective tests instead of conducting costly and time-consuming real-world experiments. This article aims to give a comprehensive overview of the state-of-the-art context simulation methods for testing mobile context-aware applications. In particular, this article highlights the technical distinctions and commonalities in previous research conducted across multiple disciplines, particularly at the intersection of software testing, ubiquitous computing, and mobile computing. This article also discusses how each method can be implemented and deployed by testing tool developers and mobile application testers. Finally, this article identifies several unexplored issues and directions for further advancements in this field.},
  archive      = {J_CSUR},
  author       = {Chu Luo and Jorge Goncalves and Eduardo Velloso and Vassilis Kostakos},
  doi          = {10.1145/3372788},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {21:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of context simulation for testing mobile context-aware applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The AI-based cyber threat landscape: A survey.
<em>CSUR</em>, <em>53</em>(1), 20:1–34. (<a
href="https://doi.org/10.1145/3372823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in artificial intelligence (AI) technologies have induced tremendous growth in innovation and automation. Although these AI technologies offer significant benefits, they can be used maliciously. Highly targeted and evasive attacks in benign carrier applications, such as DeepLocker, have demonstrated the intentional use of AI for harmful purposes. Threat actors are constantly changing and improving their attack strategy with particular emphasis on the application of AI-driven techniques in the attack process, called AI-based cyber attack , which can be used in conjunction with conventional attack techniques to cause greater damage. Despite several studies on AI and security, researchers have not summarized AI-based cyber attacks enough to be able to understand the adversary’s actions and to develop proper defenses against such attacks. This study aims to explore existing studies of AI-based cyber attacks and to map them onto a proposed framework, providing insight into new threats. Our framework includes the classification of several aspects of malicious uses of AI during the cyber attack life cycle and provides a basis for their detection to predict future threats. We also explain how to apply this framework to analyze AI-based cyber attacks in a hypothetical scenario of a critical smart grid infrastructure.},
  archive      = {J_CSUR},
  author       = {Nektaria Kaloudi and Jingyue Li},
  doi          = {10.1145/3372823},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {20:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {The AI-based cyber threat landscape: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of cache simulators. <em>CSUR</em>, <em>53</em>(1),
19:1–32. (<a href="https://doi.org/10.1145/3372393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer architecture simulation tools are essential for implementing and evaluating new ideas in the domain and can be useful for understanding the behavior of programs and finding microarchitectural bottlenecks. One particularly important part of almost any processor is the cache hierarchy. While some simulators support simulating a whole processor, including the cache hierarchy, cores, and on-chip interconnect, others may only support simulating the cache hierarchy. This survey provides a detailed discussion on 28 CPU cache simulators, including popular or recent simulators. We compare between all of these simulators in four different ways: major design characteristics, support for specific cache design features, support for specific cache-related metrics, and validation methods and efforts. The strengths and shortcomings of each simulator and major issues that are common to all simulators are highlighted. The information presented in this survey was collected from many different sources, including research papers, documentations, source code bases, and others. This survey is potentially useful for both users and developers of cache simulators. To the best of our knowledge, this is the first comprehensive survey on cache simulation tools.},
  archive      = {J_CSUR},
  author       = {Hadi Brais and Rajshekar Kalayappan and Preeti Ranjan Panda},
  doi          = {10.1145/3372393},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {19:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of cache simulators},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of IoT applications in blockchain systems:
Architecture, consensus, and traffic modeling. <em>CSUR</em>,
<em>53</em>(1), 18:1–32. (<a
href="https://doi.org/10.1145/3372136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology can be extensively applied in diverse services, including online micro-payments, supply chain tracking, digital forensics, health-care record sharing, and insurance payments. Extending the technology to the Internet of things (IoT), we can obtain a verifiable and traceable IoT network. Emerging research in IoT applications exploits blockchain technology to record transaction data, optimize current system performance, or construct next-generation systems, which can provide additional security, automatic transaction management, decentralized platforms, offline-to-online data verification, and so on. In this article, we conduct a systematic survey of the key components of IoT blockchain and examine a number of popular blockchain applications. In particular, we first give an architecture overview of popular IoT-blockchain systems by analyzing their network structures and protocols. Then, we discuss variant consensus protocols for IoT blockchains, and make comparisons among different consensus algorithms. Finally, we analyze the traffic model for P2P and blockchain systems and provide several metrics. We also provide a suitable traffic model for IoT-blockchain systems to illustrate network traffic distribution.},
  archive      = {J_CSUR},
  author       = {Laphou Lao and Zecheng Li and Songlin Hou and Bin Xiao and Songtao Guo and Yuanyuan Yang},
  doi          = {10.1145/3372136},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {18:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of IoT applications in blockchain systems: Architecture, consensus, and traffic modeling},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mind your mind: EEG-based brain-computer interfaces and
their security in cyber space. <em>CSUR</em>, <em>53</em>(1), 17:1–38.
(<a href="https://doi.org/10.1145/3372043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) system is a system that leverages brainwave information acquired by a designated brain monitoring device to interact with a computerized system. Over the past 40 years, many BCI applications have been developed in a variety of domains, from entertainment to medical field and even to computer security mechanisms. Until now, the development of BCI systems has focused on improving their accuracy, functionality, and ease of use, and not enough effort and attention has been invested in securing these systems and the sensitive data they acquire. In this article, we present the principles of brain activity data acquisition, with a special focus on EEG, and we present a taxonomy of BCI applications and domains. We also provide a comprehensive survey that covers eight possible attacks aimed at BCI systems. For each BCI application, we created an ecosystem and data and attack flow-diagram, which comprehensively describes the roles and interactions of the players associated with the BCI application and presents the most vulnerable vectors and components within its ecosystem; we identified gaps between existing security solutions and the presented attacks and vulnerabilities. Finally, we provide several concrete suggestions for improving the security of BCI systems in cyber-space.},
  archive      = {J_CSUR},
  author       = {Ofir Landau and Rami Puzis and Nir Nissim},
  doi          = {10.1145/3372043},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {17:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Mind your mind: EEG-based brain-computer interfaces and their security in cyber space},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast packet processing with eBPF and XDP: Concepts, code,
challenges, and applications. <em>CSUR</em>, <em>53</em>(1), 16:1–36.
(<a href="https://doi.org/10.1145/3371038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extended Berkeley Packet Filter (eBPF) is an instruction set and an execution environment inside the Linux kernel. It enables modification, interaction, and kernel programmability at runtime. eBPF can be used to program the eXpress Data Path (XDP), a kernel network layer that processes packets closer to the NIC for fast packet processing. Developers can write programs in C or P4 languages and then compile to eBPF instructions, which can be processed by the kernel or by programmable devices (e.g., SmartNICs). Since its introduction in 2014, eBPF has been rapidly adopted by major companies such as Facebook, Cloudflare, and Netronome. Use cases include network monitoring, network traffic manipulation, load balancing, and system profiling. This work aims to present eBPF to an inexpert audience, covering the main theoretical and fundamental aspects of eBPF and XDP, as well as introducing the reader to simple examples to give insight into the general operation and use of both technologies.},
  archive      = {J_CSUR},
  author       = {Marcos A. M. Vieira and Matheus S. Castanho and Racyus D. G. Pacífico and Elerson R. S. Santos and Eduardo P. M. Câmara Júnior and Luiz F. M. Vieira},
  doi          = {10.1145/3371038},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {16:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Fast packet processing with eBPF and XDP: Concepts, code, challenges, and applications},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Change detection and notification of web pages: A survey.
<em>CSUR</em>, <em>53</em>(1), 15:1–35. (<a
href="https://doi.org/10.1145/3369876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of currently available webpages are dynamic in nature and are changing frequently. New content gets added to webpages, and existing content gets updated or deleted. Hence, people find it useful to be alert for changes in webpages that contain information that is of value to them. In the current context, keeping track of these webpages and getting alerts about different changes have become significantly challenging. Change Detection and Notification (CDN) systems were introduced to automate this monitoring process and to notify users when changes occur in webpages. This survey classifies and analyzes different aspects of CDN systems and different techniques used for each aspect. Furthermore, the survey highlights the current challenges and areas of improvement present within the field of research.},
  archive      = {J_CSUR},
  author       = {Vijini Mallawaarachchi and Lakmal Meegahapola and Roshan Madhushanka and Eranga Heshan and Dulani Meedeniya and Sampath Jayarathna},
  doi          = {10.1145/3369876},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {15:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Change detection and notification of web pages: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Frameworks for collective intelligence: A systematic
literature review. <em>CSUR</em>, <em>53</em>(1), 14:1–36. (<a
href="https://doi.org/10.1145/3368986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years, Collective Intelligence (CI) platforms have become a vital resource for learning, problem solving, decision-making, and predictions. This rising interest in the topic has to led to the development of several models and frameworks available in published literature. Unfortunately, most of these models are built around domain-specific requirements, i.e., they are often based on the intuitions of their domain experts and developers. This has created a gap in our knowledge in the theoretical foundations of CI systems and models, in general. In this article, we attempt to fill this gap by conducting a systematic review of CI models and frameworks, identified from a collection of 9,418 scholarly articles published since 2000. Eventually, we contribute by aggregating the available knowledge from 12 CI models into one novel framework and present a generic model that describes CI systems irrespective of their domains. We add to the previously available CI models by providing a more granular view of how different components of CI systems interact. We evaluate the proposed model by examining it with respect to six popular, ongoing CI initiatives available on the Web.},
  archive      = {J_CSUR},
  author       = {Shweta Suran and Vishwajeet Pattanaik and Dirk Draheim},
  doi          = {10.1145/3368986},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {14:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Frameworks for collective intelligence: A systematic literature review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Autonomous visual navigation for mobile robots: A systematic
literature review. <em>CSUR</em>, <em>53</em>(1), 13:1–34. (<a
href="https://doi.org/10.1145/3368961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous mobile robots are required to move throughout map the environment, locate themselves, and plan paths between positions. Vision stands out among the other senses for its richness and practicality. Even though there are well-established autonomous navigation solutions, as far as we can tell, no complete autonomous navigation system that is solely based on vision and that is suitable for dynamic indoor environments has fully succeeded. This article presents a systematic literature review of methods and techniques used to solve the complete autonomous navigation problem or its parts: localization, mapping, path planning, and locomotion. The focus of this review lays on vision-based methods for indoor environments and ground robots. A total of 121 studies were considered, comprising methods, conceptual models, and other literature reviews published between 2000 and 2017. To the best of our knowledge, this is the first systematic review about vision-based autonomous navigation suitable for dynamic indoor environments. It addresses navigation methods, autonomous navigation requirements, vision benefits, methods testing, and implementations validation. The results of this review show a deficiency in testing and validation of presented methods, poor requirements specification, and a lack of complete navigation systems in the literature. These results should encourage new works on computer vision techniques, requirements specification, development, integration, and systematic testing and validation of general navigation systems. In addition to these findings, we also present the complete methodology used for the systematic review, which provides a documentation of the process (allowing quality assessment and repeatability), the criteria for selecting and evaluating the studies, and a framework that can be used for future reviews in this research area.},
  archive      = {J_CSUR},
  author       = {Yuri D. V. Yasuda and Luiz Eduardo G. Martins and Fabio A. M. Cappabianco},
  doi          = {10.1145/3368961},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {13:1–34},
  shortjournal = {ACM Comput. Surv.},
  title        = {Autonomous visual navigation for mobile robots: A systematic literature review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stance detection: A survey. <em>CSUR</em>, <em>53</em>(1),
12:1–37. (<a href="https://doi.org/10.1145/3369026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic elicitation of semantic information from natural language texts is an important research problem with many practical application areas. Especially after the recent proliferation of online content through channels such as social media sites, news portals, and forums; solutions to problems such as sentiment analysis, sarcasm/controversy/veracity/rumour/fake news detection, and argument mining gained increasing impact and significance, revealed with large volumes of related scientific publications. In this article, we tackle an important problem from the same family and present a survey of stance detection in social media posts and (online) regular texts. Although stance detection is defined in different ways in different application settings, the most common definition is “automatic classification of the stance of the producer of a piece of text, towards a target, into one of these three classes: { Favor , Against , Neither }.” Our survey includes definitions of related problems and concepts, classifications of the proposed approaches so far, descriptions of the relevant datasets and tools, and related outstanding issues. Stance detection is a recent natural language processing topic with diverse application areas, and our survey article on this newly emerging topic will act as a significant resource for interested researchers and practitioners.},
  archive      = {J_CSUR},
  author       = {Dilek Küçük and Fazli Can},
  doi          = {10.1145/3369026},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {12:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Stance detection: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based video coding: A review and a case study.
<em>CSUR</em>, <em>53</em>(1), 11:1–35. (<a
href="https://doi.org/10.1145/3368405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has witnessed the great success of deep learning in many disciplines, especially in computer vision and image processing. However, deep learning-based video coding remains in its infancy. We review the representative works about using deep learning for image/video coding, an actively developing research area since 2015. We divide the related works into two categories: new coding schemes that are built primarily upon deep networks, and deep network-based coding tools that shall be used within traditional coding schemes. For deep schemes, pixel probability modeling and auto-encoder are the two approaches, that can be viewed as predictive coding and transform coding, respectively. For deep tools, there have been several techniques using deep learning to perform intra-picture prediction, inter-picture prediction, cross-channel prediction, probability distribution prediction, transform, post- or in-loop filtering, down- and up-sampling, as well as encoding optimizations. In the hope of advocating the research of deep learning-based video coding, we present a case study of our developed prototype video codec, Deep Learning Video Coding (DLVC). DLVC features two deep tools that are both based on convolutional neural network (CNN), namely CNN-based in-loop filter and CNN-based block adaptive resolution coding. The source code of DLVC has been released for future research.},
  archive      = {J_CSUR},
  author       = {Dong Liu and Yue Li and Jianping Lin and Houqiang Li and Feng Wu},
  doi          = {10.1145/3368405},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {11:1–35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Deep learning-based video coding: A review and a case study},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple workflows scheduling in multi-tenant distributed
systems: A taxonomy and future directions. <em>CSUR</em>,
<em>53</em>(1), 10:1–39. (<a
href="https://doi.org/10.1145/3368036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workflows are an application model that enables the automated execution of multiple interdependent and interconnected tasks. They are widely used by the scientific community to manage the distributed execution and dataflow of complex simulations and experiments. As the popularity of scientific workflows continue to rise, and their computational requirements continue to increase, the emergence and adoption of multi-tenant computing platforms that offer the execution of these workflows as a service becomes widespread. This article discusses the scheduling and resource provisioning problems particular to this type of platform. It presents a detailed taxonomy and a comprehensive survey of the current literature and identifies future directions to foster research in the field of multiple workflow scheduling in multi-tenant distributed computing systems.},
  archive      = {J_CSUR},
  author       = {Muhammad H. Hilman and Maria A. Rodriguez and Rajkumar Buyya},
  doi          = {10.1145/3368036},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {10:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Multiple workflows scheduling in multi-tenant distributed systems: A taxonomy and future directions},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Core concepts, challenges, and future directions in
blockchain: A centralized tutorial. <em>CSUR</em>, <em>53</em>(1),
9:1–39. (<a href="https://doi.org/10.1145/3366370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchains are a topic of immense interest in academia and industry, but their true nature is often obscured by marketing and hype. In this tutorial, we explain the fundamental elements of blockchains. We discuss their ability to achieve availability, consistency, and data integrity as well as their inherent limitations. Using Ethereum as a case study, we describe the inner workings of blockchains in detail before comparing blockchains to traditional distributed systems. In the second part of our tutorial, we discuss the major challenges facing blockchains and summarize ongoing research and commercial offerings that seek to address these challenges.},
  archive      = {J_CSUR},
  author       = {John Kolb and Moustafa AbdelBaky and Randy H. Katz and David E. Culler},
  doi          = {10.1145/3366370},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {9:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Core concepts, challenges, and future directions in blockchain: A centralized tutorial},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generic dynamic data outsourcing framework for integrity
verification. <em>CSUR</em>, <em>53</em>(1), 8:1–32. (<a
href="https://doi.org/10.1145/3365998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ateniese et al. proposed the Provable Data Possession (PDP) model in 2007. Following that, Erway et al. adapted the model for dynamically updatable data and called it the Dynamic Provable Data Possession (DPDP) model. The idea is that a client outsources her files to a cloud server and later challenges the server to obtain a proof of the integrity of her data. Many schemes have later been proposed for this purpose, all following a similar framework. We analyze dynamic data outsourcing schemes for the cloud regarding security and efficiency and show a general framework for constructing such schemes that encompasses existing DPDP-like schemes as different instantiations. This generalization shows that a dynamic outsourced data integrity verification scheme can be constructed given black-box access to an implicitly-ordered authenticated data structure. Moreover, for blockless verification efficiency, a homomorphic verifiable tag scheme is also needed. We investigate the requirements and conditions these building blocks should satisfy, using which one may easily check the applicability of a given building block for dynamic data outsourcing. Our framework serves as a guideline/tutorial/survey and enables us to provide a comparison among different building blocks that existing schemes employ.},
  archive      = {J_CSUR},
  author       = {Mohammad Etemad and Alptekin Küpçü},
  doi          = {10.1145/3365998},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {8:1–32},
  shortjournal = {ACM Comput. Surv.},
  title        = {Generic dynamic data outsourcing framework for integrity verification},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling influence with semantics in social networks: A
survey. <em>CSUR</em>, <em>53</em>(1), 7:1–38. (<a
href="https://doi.org/10.1145/3369780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discovery of influential entities in all kinds of networks (e.g., social, digital, or computer) has always been an important field of study. In recent years, Online Social Networks (OSNs) have been established as a basic means of communication and often influencers and opinion makers promote politics, events, brands, or products through viral content. In this work, we present a systematic review across (i) online social influence metrics, properties, and applications and (ii) the role of semantic in modeling OSNs information. We found that both areas can jointly provide useful insights towards the qualitative assessment of viral user-generated content, as well as for modeling the dynamic properties of influential content and its flow dynamics.},
  archive      = {J_CSUR},
  author       = {Gerasimos Razis and Ioannis Anagnostopoulos and Sherali Zeadally},
  doi          = {10.1145/3369780},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {7:1–38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Modeling influence with semantics in social networks: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving performance and energy consumption in embedded
systems via binary acceleration: A survey. <em>CSUR</em>,
<em>53</em>(1), 6:1–36. (<a
href="https://doi.org/10.1145/3369764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The breakdown of Dennard scaling has resulted in a decade-long stall of the maximum operating clock frequencies of processors. To mitigate this issue, computing shifted to multi-core devices. This introduced the need for programming flows and tools that facilitate the expression of workload parallelism at high abstraction levels. However, not all workloads are easily parallelizable, and the minor improvements to processor cores have not significantly increased single-threaded performance. Simultaneously, Instruction Level Parallelism in applications is considerably underexplored. This article reviews notable approaches that focus on exploiting this potential parallelism via automatic generation of specialized hardware from binary code. Although research on this topic spans over more than 20 years, automatic acceleration of software via translation to hardware has gained new importance with the recent trend toward reconfigurable heterogeneous platforms. We characterize this kind of binary acceleration approach and the accelerator architectures on which it relies. We summarize notable state-of-the-art approaches individually and present a taxonomy and comparison. Performance gains from 2.6× to 5.6× are reported, mostly considering bare-metal embedded applications, along with power consumption reductions between 1.3× and 3.9×. We believe the methodologies and results achievable by automatic hardware generation approaches are promising in the context of emergent reconfigurable devices.},
  archive      = {J_CSUR},
  author       = {Nuno Paulino and João Canas Ferreira and João M. P. Cardoso},
  doi          = {10.1145/3369764},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {6:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Improving performance and energy consumption in embedded systems via binary acceleration: A survey},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The ideal versus the real: Revisiting the history of virtual
machines and containers. <em>CSUR</em>, <em>53</em>(1), 5:1–31. (<a
href="https://doi.org/10.1145/3365199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The common perception in both academic literature and industry today is that virtual machines offer better security, whereas containers offer better performance. However, a detailed review of the history of these technologies and the current threats they face reveals a different story. This survey covers key developments in the evolution of virtual machines and containers from the 1950s to today, with an emphasis on countering modern misperceptions with accurate historical details and providing a solid foundation for ongoing research into the future of secure isolation for multitenant infrastructures, such as cloud and container deployments.},
  archive      = {J_CSUR},
  author       = {Allison Randal},
  doi          = {10.1145/3365199},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {5:1–31},
  shortjournal = {ACM Comput. Surv.},
  title        = {The ideal versus the real: Revisiting the history of virtual machines and containers},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of compiler testing. <em>CSUR</em>, <em>53</em>(1),
4:1–36. (<a href="https://doi.org/10.1145/3363562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtually any software running on a computer has been processed by a compiler or a compiler-like tool. Because compilers are such a crucial piece of infrastructure for building software, their correctness is of paramount importance. To validate and increase the correctness of compilers, significant research efforts have been devoted to testing compilers. This survey article provides a comprehensive summary of the current state-of-the-art of research on compiler testing. The survey covers different aspects of the compiler testing problem, including how to construct test programs, what test oracles to use for determining whether a compiler behaves correctly, how to execute compiler tests efficiently, and how to help compiler developers take action on bugs discovered by compiler testing. Moreover, we survey work that empirically studies the strengths and weaknesses of current compiler testing research and practice. Based on the discussion of existing work, we outline several open challenges that remain to be addressed in future work.},
  archive      = {J_CSUR},
  author       = {Junjie Chen and Jibesh Patra and Michael Pradel and Yingfei Xiong and Hongyu Zhang and Dan Hao and Lu Zhang},
  doi          = {10.1145/3363562},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {4:1–36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of compiler testing},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable deep learning on distributed infrastructures:
Challenges, techniques, and tools. <em>CSUR</em>, <em>53</em>(1),
3:1–37. (<a href="https://doi.org/10.1145/3363554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has had an immense success in the recent past, leading to state-of-the-art results in various domains, such as image recognition and natural language processing. One of the reasons for this success is the increasing size of DL models and the proliferation of vast amounts of training data being available. To keep on improving the performance of DL, increasing the scalability of DL systems is necessary. In this survey, we perform a broad and thorough investigation on challenges, techniques and tools for scalable DL on distributed infrastructures. This incorporates infrastructures for DL, methods for parallel DL training, multi-tenant resource scheduling, and the management of training and model data. Further, we analyze and compare 11 current open-source DL frameworks and tools and investigate which of the techniques are commonly implemented in practice. Finally, we highlight future research trends in DL systems that deserve further research.},
  archive      = {J_CSUR},
  author       = {Ruben Mayer and Hans-Arno Jacobsen},
  doi          = {10.1145/3363554},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {3:1–37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decentralized trust management: Risk analysis and trust
aggregation. <em>CSUR</em>, <em>53</em>(1), 2:1–33. (<a
href="https://doi.org/10.1145/3362168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized trust management is used as a referral benchmark for assisting decision making by human or intelligence machines in open collaborative systems. During any given period of time, each participant may only interact with a few other participants. Simply relying on direct trust may frequently resort to random team formation. Thus, trust aggregation becomes critical. It can leverage decentralized trust management to learn about indirect trust of every participant based on past transaction experiences. This article presents alternative designs of decentralized trust management and their efficiency and robustness from three perspectives. First, we study the risk factors and adverse effects of six common threat models. Second, we review the representative trust aggregation models and trust metrics. Third, we present an in-depth analysis and comparison of these reference trust aggregation methods with respect to effectiveness and robustness. We show our comparative study results through formal analysis and experimental evaluation. This comprehensive study advances the understanding of adverse effects of present and future threats and the robustness of different trust metrics. It may also serve as a guideline for research and development of next-generation trust aggregation algorithms and services in the anticipation of risk factors and mischievous threats.},
  archive      = {J_CSUR},
  author       = {Xinxin Fan and Ling Liu and Rui Zhang and Quanliang Jing and Jingping Bi},
  doi          = {10.1145/3362168},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {2:1–33},
  shortjournal = {ACM Comput. Surv.},
  title        = {Decentralized trust management: Risk analysis and trust aggregation},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactive clustering: A comprehensive review.
<em>CSUR</em>, <em>53</em>(1), 1:1–39. (<a
href="https://doi.org/10.1145/3340960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this survey, 105 papers related to interactive clustering were reviewed according to seven perspectives: (1) on what level is the interaction happening, (2) which interactive operations are involved, (3) how user feedback is incorporated, (4) how interactive clustering is evaluated, (5) which data and (6) which clustering methods have been used, and (7) what outlined challenges there are. This article serves as a comprehensive overview of the field and outlines the state of the art within the area as well as identifies challenges and future research needs.},
  archive      = {J_CSUR},
  author       = {Juhee Bae and Tove Helldin and Maria Riveiro and Sławomir Nowaczyk and Mohamed-Rafik Bouguelia and Göran Falkman},
  doi          = {10.1145/3340960},
  journal      = {ACM Computing Surveys},
  number       = {1},
  pages        = {1:1–39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Interactive clustering: A comprehensive review},
  volume       = {53},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
