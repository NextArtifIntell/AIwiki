<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOMP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jomp---76">JOMP - 76</h2>
<ul>
<li><details>
<summary>
(2020). Cognitive psychometrics: The scientific legacy of william h.
Batchelder (1940–2018). <em>JOMP</em>, <em>99</em>, 102468. (<a
href="https://doi.org/10.1016/j.jmp.2020.102468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOMP},
  author       = {Edgar Erdfelder and Xiangen Hu and Jeffrey N. Rouder and Eric-Jan Wagenmakers},
  doi          = {10.1016/j.jmp.2020.102468},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102468},
  shortjournal = {J. Math. Psychol.},
  title        = {Cognitive psychometrics: The scientific legacy of william h. batchelder (1940–2018)},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study of individual differences in categorization with
redundancy. <em>JOMP</em>, <em>99</em>, 102467. (<a
href="https://doi.org/10.1016/j.jmp.2020.102467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans and other animals are constantly learning new categories and making categorization decisions in their everyday life. However, different individuals may focus on different information when learning categories, which can impact the category representation and the information that is used when making categorization decisions. This article used computational modeling of behavioral data to take a closer look at this possibility in the context of a categorization task with redundancy. Iterative decision bound modeling and drift diffusion models were used to detect individual differences in human categorization performance. The results show that participants differ in terms of what stimulus features they learned and how they use the learned features. For example, while some participants only learn one stimulus dimension (which is sufficient for perfect accuracy), others learn both stimulus dimensions (which is not required for perfect accuracy). Among participants that learned both dimensions, some used both dimensions, while others show error and RT patterns suggesting the use of only one of the dimensions. The diversity of obtained results is problematic for existing categorization models and suggests that each categorization model may be able to account for the performance of some but not all participants.},
  archive      = {J_JOMP},
  author       = {Farzin Shamloo and Sébastien Hélie},
  doi          = {10.1016/j.jmp.2020.102467},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102467},
  shortjournal = {J. Math. Psychol.},
  title        = {A study of individual differences in categorization with redundancy},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tutorial: “With sufficient increases in x, more people will
engage in the target behavior.” <em>JOMP</em>, <em>99</em>, 102457. (<a
href="https://doi.org/10.1016/j.jmp.2020.102457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Psychological theory should guide the method. A method should not dictate theory. Extraneous assumptions entering psychological theories through the backdoor of a method may differentially affect the analysis of different data sets. This introduces noise and jeopardizes successful replication of valid theoretical claims. Auxiliary theoretical assumptions can also bias substantive conclusions (including across replications). It is therefore becoming ever more crucial that theoretical claims genuinely represent the given theory, no more, no less. Recent work has highlighted a disconnect between some theories and their ‘predictions,’ questioned the scope of theories in the presence of heterogeneity in hypothetical constructs, and developed methods to avoid extraneous assumptions. This tutorial merges these strands of research using a simple, illustrated case study on formulating and testing order-constrained theories. The tutorial applies to empirical paradigms in which scholars can state ordinal constraints on the outcome probabilities for several binary variables such as binary responses or the presence/absence of symptoms, and where the collection of binary variables is associated with a finite set of distinct conditions, such as group membership, treatment condition, or discrete levels of an independent variable. The goal is to let scholars spell out very precise hypotheses that (1) areunadulterated reflections of their theory, (2) provide exceptional theoretical nuance, (3) formally accommodate substantive heterogeneity and (4) offer rigorous and strong quantitative diagnosticity.},
  archive      = {J_JOMP},
  author       = {Michel Regenwetter},
  doi          = {10.1016/j.jmp.2020.102457},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102457},
  shortjournal = {J. Math. Psychol.},
  title        = {Tutorial: “With sufficient increases in x, more people will engage in the target behavior”},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A model of discrete choice based on reinforcement learning
under short-term memory. <em>JOMP</em>, <em>99</em>, 102455. (<a
href="https://doi.org/10.1016/j.jmp.2020.102455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A family of models of individual discrete choice are constructed by means of statistical averaging of choices made by a subject in a reinforcement learning process, where the subject has a short, k-term memory span. The choice probabilities in these models combine in a non-trivial, non-linear way the initial learning bias and the experience gained through learning. The properties of such models are discussed and, in particular, it is shown that probabilities deviate from Luce’s Choice Axiom. Moreover, it is shown that the latter property is recovered as the memory span increases. Two different applications in utility theory are considered. In the first, we use the discrete choice model to generate a binary preference (weak stochastic order) relation on simple lotteries. We show that the relation violate the transitivity and independence axioms of expected utility theory. Furthermore, we establish the dependence of the preferences on frames, with risk aversion for gains, and risk seeking for losses. Based on these findings, we consider a parametric model of choice based on the probability maximization principle, as a model for deviations from the expected utility principle. To illustrate the approach, we apply this model to the classical problem of demand for insurance.},
  archive      = {J_JOMP},
  author       = {Misha Perepelitsa},
  doi          = {10.1016/j.jmp.2020.102455},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102455},
  shortjournal = {J. Math. Psychol.},
  title        = {A model of discrete choice based on reinforcement learning under short-term memory},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geometric purity, kinematic scaling and dynamic optimality
in drawing movements beyond ellipses. <em>JOMP</em>, <em>99</em>,
102453. (<a href="https://doi.org/10.1016/j.jmp.2020.102453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drawing movements have been shown to comply with a power law constraining local curvature and instantaneous speed. In particular, ellipses have been extensively studied, enjoying a 2/3 exponent. While the origin of such a non-trivial relationship remains debated, it has been proposed to be an outcome of the least action principle whereby mechanical work is minimized along 2/3 power law trajectories. Here we demonstrate that this claim is flawed. We then study a wider range of curves beyond ellipses that can have 2/3 power law scaling. We show that all such geometries are quasi-pure and with the same spectral frequency. We then numerically estimate that their dynamics produce minimum jerk. Finally, using variational calculus and simulations, we discover that equi-affine displacement is invariant across different kinematics, power law or otherwise. In sum, we deepen and clarify the relationship between geometric purity, kinematic scaling and dynamic optimality for trajectories beyond ellipses. It is enticing to realize that we still do not fully understand why we move our pen on a piece of paper the way we do.},
  archive      = {J_JOMP},
  author       = {Adam Matic and Alex Gomez-Marin},
  doi          = {10.1016/j.jmp.2020.102453},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102453},
  shortjournal = {J. Math. Psychol.},
  title        = {Geometric purity, kinematic scaling and dynamic optimality in drawing movements beyond ellipses},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the necessary and sufficient conditions for delineating
forward- and backward-graded knowledge structures from skill maps.
<em>JOMP</em>, <em>99</em>, 102451. (<a
href="https://doi.org/10.1016/j.jmp.2020.102451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years two classes of knowledge structures received particular attention. They are, respectively, forward-graded and backward-graded knowledge structures. Their importance is related to the fact that the basic local independence model applied to such structures turns out to be locally unidentifiable. Spoto et al. (2012) established some sufficient conditions for a skill multimap to delineate forward- and/or backward graded knowledge structures. Drawing upon some of the theoretical results contained in that article, the present theoretical note aims at providing necessary and sufficient conditions for a skill map to delineate a forward- and/or backward graded knowledge structure.},
  archive      = {J_JOMP},
  author       = {Andrea Spoto and Luca Stefanutti},
  doi          = {10.1016/j.jmp.2020.102451},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102451},
  shortjournal = {J. Math. Psychol.},
  title        = {On the necessary and sufficient conditions for delineating forward- and backward-graded knowledge structures from skill maps},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revealing multisensory benefit with diffusion modeling.
<em>JOMP</em>, <em>99</em>, 102449. (<a
href="https://doi.org/10.1016/j.jmp.2020.102449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisensory information can benefit perceptual, memory, and decision-making processes. These benefits commonly manifest in superior detection and discrimination of multisensory stimuli, as well as improved perception and subsequent memory of unisensory representation of an object previously encoded in a multisensory context. However, the vast majority of studies to date analyze accuracy, sensitivity and/or reaction time data independently to compare multisensory and unisensory conditions. Considering the well-established speed-accuracy trade-off, we asked whether some multisensory benefits go unnoticed when measured using traditional methods that do not take both reaction time and accuracy into account simultaneously, and whether an approach combining them can more reliably characterize and quantify the broad extent of multisensory interactions across perception and cognition. While drift diffusion models have been previously shown to be effective in addressing the speed-accuracy trade-off and providing a reliable and accurate measure of multisensory benefits, one impediment of this approach is the requirement of a large number of trials to estimate model parameters and to characterize effects. This may be prohibitive in many experimental paradigms. Several model variants attempt to reduce the required number of trials, either by averaging across participants or limiting the search space for the parameters. Here, we employed a hierarchical drift diffusion model, that utilizes Bayesian priors, allowing parameter estimation with smaller sample sizes while still making subject-specific parameter estimates. We analyzed data in perceptual detection and discrimination tasks across multiple sensory combinations, to investigate if the diffusion model would provide a sensitive and reliable measure of multisensory benefits. Results indicate that across visual, auditory and tactile modality combinations, the diffusion model was either as or more sensitive than traditional accuracy, sensitivity, or reaction time measures, and was the only measure that consistently detected multisensory benefits in a statistically significant fashion. We recommend the use of diffusion modeling approaches when assessing the outcomes of multisensory experiments, especially as they become more computationally efficient.},
  archive      = {J_JOMP},
  author       = {Carolyn A. Murray and E. Sebastian Lelo de Larrea-Mancera and Arit Glicksohn and Ladan Shams and Aaron R. Seitz},
  doi          = {10.1016/j.jmp.2020.102449},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102449},
  shortjournal = {J. Math. Psychol.},
  title        = {Revealing multisensory benefit with diffusion modeling},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active inference on discrete state-spaces: A synthesis.
<em>JOMP</em>, <em>99</em>, 102447. (<a
href="https://doi.org/10.1016/j.jmp.2020.102447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.},
  archive      = {J_JOMP},
  author       = {Lancelot Da Costa and Thomas Parr and Noor Sajid and Sebastijan Veselic and Victorita Neacsu and Karl Friston},
  doi          = {10.1016/j.jmp.2020.102447},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102447},
  shortjournal = {J. Math. Psychol.},
  title        = {Active inference on discrete state-spaces: A synthesis},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision-time statistics of nonlinear diffusion models:
Characterizing long sequences of subsequent trials. <em>JOMP</em>,
<em>99</em>, 102445. (<a
href="https://doi.org/10.1016/j.jmp.2020.102445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive models of decision making are an important tool in studies of cognitive psychology and have been successfully used to fit experimental data and to relate them to neurophysiological mechanisms in the brain. One of the most important models for binary decision making is the diffusion-decision model (DDM) in which a diffusion process that models the accumulation of perceived evidence yields the decisions upon reaching one of two thresholds. Due to its simplicity, the model is analytically tractable and has been used to bridge the gap between implementations of decision making in neurobiologically plausible neural networks and experiments. However, biologically realistic network models exhibit nonlinear dynamics that yield via mean-field-reduction techniques a nonlinear DDM for which analytical solutions and proper numerical tools in general are not known. Furthermore, although often agents have to make a number of subsequent decisions, the statistics of such sequences of decisions (containing information on whether the decisions are correct or incorrect and on their timing) are so far poorly understood. Here we introduce the decision trains, sequences of negative or positive spikes at the decision times with the sign corresponding to the correctness of the decision. The decision trains enable a proper characterization of experiments in which many trials are performed consecutively. For the principal reference case of independent decisions (renewal statistics), we derive relations between the second-order statistics of the decision trains (i.e. their power spectra) and the response-time densities. Most importantly, we extend an efficient numerical procedure for spiking neuron models, the threshold-integration method, to determine the temporal statistics of nonlinear DDMs. The threshold-integration method provides the temporal statistics, i.e. decision rates, decision-time densities and the decision-train power spectra. Moreover, the procedure is used for the calculation of the linear response to a sinusoidal modulation. We compare all results with direct simulations of the stochastic model .},
  archive      = {J_JOMP},
  author       = {Sebastian Vellmer and Benjamin Lindner},
  doi          = {10.1016/j.jmp.2020.102445},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102445},
  shortjournal = {J. Math. Psychol.},
  title        = {Decision-time statistics of nonlinear diffusion models: Characterizing long sequences of subsequent trials},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Audiovisual integration in depth: Modeling the effect of
distance and stimulus effectiveness using the TWIN model. <em>JOMP</em>,
<em>99</em>, 102443. (<a
href="https://doi.org/10.1016/j.jmp.2020.102443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating information across our various sensory modalities results in striking behavioral benefits. This integration depends on a variety of factors, among which are the effectiveness of the stimuli and the relative timing between them. Both of these factors physically vary as a function of the distance between stimuli and the observer: intensity decreases as a function of distance for both auditory and visual stimuli, while the relative timing of energy arriving at the sensory organs differs due to differing transmission speeds. As a result, the depth at which multisensory stimuli are presented is likely to be an important factor in the gain that is derived from integrating them. Here, we use a computational approach – the Time-Window-of Integration (TWIN) framework – to examine differences in simultaneity judgments and reaction times to audiovisual stimuli presented at two depths. Using the TWIN model, we tested whether the observed behavior could be explained solely on the basis of differences in peripheral processing times, on the basis of changes in the temporal binding window (TBW), or by a combination of both factors. The results indicated that a model allowing for different TBWs for near and far space best accounts for the observed data in the majority of participants. However, the best overall model (regardless of the number of parameters) was a model containing both distance-dependent peripheral processing times and TBWs. Interestingly, TBWs were found not to expand from near to far space, but rather to get smaller. Taken together, the results indicate that distance is an additional factor in multisensory integration, above its impact on relative timing and intensity.},
  archive      = {J_JOMP},
  author       = {Nathan Van der Stoep and Hans Colonius and Jean-Paul Noel and Mark T. Wallace and Adele Diederich},
  doi          = {10.1016/j.jmp.2020.102443},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102443},
  shortjournal = {J. Math. Psychol.},
  title        = {Audiovisual integration in depth: Modeling the effect of distance and stimulus effectiveness using the TWIN model},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian hypothesis testing for gaussian graphical models:
Conditional independence and order constraints. <em>JOMP</em>,
<em>99</em>, 102441. (<a
href="https://doi.org/10.1016/j.jmp.2020.102441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian graphical models (GGM; partial correlation networks) have become increasingly popular in the social and behavioral sciences for studying conditional (in)dependencies between variables. In this work, we introduce exploratory and confirmatory Bayesian tests for partial correlations. For the former, we first extend the customary GGM formulation that focuses on conditional dependence to also consider the null hypothesis of conditional independence for each partial correlation. Here a novel testing strategy is introduced that can provide evidence for a null , negative, or positive effect. We then introduce a test for hypotheses with order constraints on partial correlations. This allows for testing theoretical and clinical expectations in GGMs. The novel matrix- F F prior distribution is described that provides increased flexibility in specification compared to the Wishart prior. The methods are applied to PTSD symptoms. In several applications, we demonstrate how the exploratory and confirmatory approaches can work in tandem: hypotheses are formulated from an initial analysis and then tested in an independent dataset. The methodology is implemented in the R package BGGM .},
  archive      = {J_JOMP},
  author       = {Donald R. Williams and Joris Mulder},
  doi          = {10.1016/j.jmp.2020.102441},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102441},
  shortjournal = {J. Math. Psychol.},
  title        = {Bayesian hypothesis testing for gaussian graphical models: Conditional independence and order constraints},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hyper-relation characterization of weak
pseudo-rationalizability. <em>JOMP</em>, <em>99</em>, 102439. (<a
href="https://doi.org/10.1016/j.jmp.2020.102439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I provide a characterization of weakly pseudo-rationalizable choice functions – that is, choice functions rationalizable by a set of acyclic relations – in terms of hyper-relations satisfying certain properties. For those hyper-relations Nehring calls extended preference relations , the central characterizing condition is weaker than (hyper-relation) transitivity but stronger than (hyper-relation) acyclicity. Furthermore, the relevant type of hyper-relation can be represented as the intersection of a certain class of its extensions. These results generalize known, analogous results for path independent choice functions.},
  archive      = {J_JOMP},
  author       = {Rush T. Stewart},
  doi          = {10.1016/j.jmp.2020.102439},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102439},
  shortjournal = {J. Math. Psychol.},
  title        = {A hyper-relation characterization of weak pseudo-rationalizability},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-sensory inhibition or unisensory facilitation: A
potential neural architecture of modality switch effects. <em>JOMP</em>,
<em>99</em>, 102438. (<a
href="https://doi.org/10.1016/j.jmp.2020.102438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a simple reaction time task in which auditory and visual stimuli are presented in random sequence alone (A or V) or together (AV), there is a so-called reaction time (RT) cost on trials in which sensory modality switches (A → → V) compared to when it repeats (A → → A). This is always true for unisensory trials, whereas RTs to AV stimuli preceded by unisensory stimuli are statistically comparable with the Repeat condition (AV → → AV). Neural facilitation for Repeat trials or neural inhibition for Switch trials could both account for these effects. Here we used a neural network model (Multisensory Integration with Crossed Inhibitory Dynamics (MICID) model) to test the ability of these two distinct mechanisms, inhibition and facilitation, to produce the specific patterns of behavior that we see experimentally, modeling switch and repeat trials as well as the influence of the interval between the present and the previous trial. The model results are consistent with an inhibitory account in which there is competition between the different sensory modalities, instead of a facilitation account in which the preceding stimulus sensitizes the neural system to its particular sensory modality. Moreover, the model shows that multisensory integration can explain the results in case of multisensory stimuli, where the preceding stimulus has little effect. This is due to faster dynamics for multisensory facilitation compared to cross-sensory inhibition. These findings link the cognitive framework delineated by the empirical results to a plausible neural implementation.},
  archive      = {J_JOMP},
  author       = {Cristiano Cuppini and Mauro Ursino and Elisa Magosso and Michael J. Crosse and John J. Foxe and Sophie Molholm},
  doi          = {10.1016/j.jmp.2020.102438},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102438},
  shortjournal = {J. Math. Psychol.},
  title        = {Cross-sensory inhibition or unisensory facilitation: A potential neural architecture of modality switch effects},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling misconceptions in knowledge space theory.
<em>JOMP</em>, <em>99</em>, 102435. (<a
href="https://doi.org/10.1016/j.jmp.2020.102435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building intelligent tutoring systems (ITSs) that are aware of the students’ misconceptions has been one of the ambitions for many of the approaches to computerized assessment of knowledge and learning. In the present article we extend knowledge space theory (KST) to mistakes and misconceptions. The proposed approach completes and extends the work initiated by J. Lukas (1997, Modellierung von Fehlkonzepten in einer algebraischen Wissensstruktur [Modeling misconceptions in an algebraic knowledge structure], Kognitionswissenschaft, 6(4), 196–204) on the application of information systems in KST for modeling misconceptions. The approach is divided into a deterministic and a probabilistic part. The notion of a “polytomous skill map” (PSM) represents the cornerstone of the deterministic part. Properties of the PSM are established that assure a consistent link between item responses on the one hand and the (correct or buggy) cognitive rules applied by an individual on the other hand. A weaker notion of information system (named a “cognitive rule system”) is proposed for representing two types of dependencies among cognitive rules: precedence and compatibility. The probabilistic part consists of an extension of the basic local independence model to more than two response alternatives. This model can be used for knowledge diagnoses, as well as for empirically testing the deterministic assumptions from a PSM. An empirical application of this probabilistic model to the responses of 331 university students is illustrated and discussed using two different PSMs.},
  archive      = {J_JOMP},
  author       = {Luca Stefanutti and Debora de Chiusole and Matthias Gondan and Alice Maurer},
  doi          = {10.1016/j.jmp.2020.102435},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102435},
  shortjournal = {J. Math. Psychol.},
  title        = {Modeling misconceptions in knowledge space theory},
  volume       = {99},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multinomial processing tree inferred from age-related
memory-error probabilities: Possibility of inferring more if response
times were available. <em>JOMP</em>, <em>98</em>, 102433. (<a
href="https://doi.org/10.1016/j.jmp.2020.102433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Use of Multinomial Processing Tree (MPT) models is illustrated by fitting one to data of Dhir (2017). Her experiment examined age and association type in a paired-associate recall task. Age and Pair-Type had interactive effects on probability of a correct response. A natural interpretation of the interaction would be that both factors impact the same mental process. However, fitting an MPT leads to the conclusion that Age and Pair-Type selectively influence two separate processes, one following the other. A possible interpretation of these is as attempts at specific (verbatim) retrieval and knowledge supported (gist) processing, selectively influenced by Age and Pair-Type, respectively. The order of these processes is not determined by the response probabilities . In a further section of the paper, we show that if response times or other measures had also been available, they could have resolved the process order, but might have left it undetermined. We give necessary and sufficient conditions for two factors to selectively influence two ordered vertices in an MPT, with either order of the vertices accounting for both response probability and response time. They do so if and only if the MPT is equivalent to a special processing tree, not necessarily an MPT itself.},
  archive      = {J_JOMP},
  author       = {Richard Schweickert and Pritha Dhir and Xiaofang Zheng and Marie Poirier},
  doi          = {10.1016/j.jmp.2020.102433},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102433},
  shortjournal = {J. Math. Psychol.},
  title        = {A multinomial processing tree inferred from age-related memory-error probabilities: Possibility of inferring more if response times were available},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on decomposition of sources of variability in
perceptual decision-making. <em>JOMP</em>, <em>98</em>, 102431. (<a
href="https://doi.org/10.1016/j.jmp.2020.102431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information processing underlying human perceptual decision-making is inherently noisy and identifying sources of this noise is important to understand processing. Ratcliff, Voskuilen, and McKoon (2018) examined results from five experiments using a double-pass procedure in which stimuli were repeated typically a hundred trials later. Greater than chance agreement between repeated tests provided evidence for trial-to-trial variability from external sources of noise. They applied the diffusion model to estimate the quality of evidence driving the decision process (drift rate) and the variability (standard deviation) in drift rate across trials. This variability can be decomposed into random (internal) and systematic (external) components by comparing the double-pass accuracy and agreement with the model predictions. In this note, we provide an additional analysis of the double-pass experiments using the linear ballistic accumulator (LBA) model. The LBA model does not have within-trial variability and thus it captures all variabilities in processing with its across-trial variability parameters. The LBA analysis of the double-pass data provides model-based evidence of external variability in a decision process, which is consistent with Ratcliff et al.’s result. This demonstrates that across-trial variability is required to model perceptual decision-making. The LBA model provides measures of systematic and random variability as the diffusion model did. But due to the lack of within-trial variability, the LBA model estimated the random component as a larger proportion of across-trial total variability than did the diffusion model.},
  archive      = {J_JOMP},
  author       = {Inhan Kang and Roger Ratcliff and Chelsea Voskuilen},
  doi          = {10.1016/j.jmp.2020.102431},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102431},
  shortjournal = {J. Math. Psychol.},
  title        = {A note on decomposition of sources of variability in perceptual decision-making},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical bayesian parameter estimation for cumulative
prospect theory. <em>JOMP</em>, <em>98</em>, 102429. (<a
href="https://doi.org/10.1016/j.jmp.2020.102429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nilsson, Rieskamp, and Wagenmakers (2011) implemented a hierarchical Bayesian estimation procedure for cumulative prospect theory (CPT; Tversky and Kahneman (1992)). Nilsson et al. used a simplified version of CPT that holds for choice options with mixed outcomes, that is, one positive and one negative payoff. However, for choice options with only gains or only losses, the model specification does not hold. Here we provide a corrected model specification of CPT, one that also holds for options with only gains or only losses. We show that the corrected version does not change the qualitative results reported in Nilsson et al.},
  archive      = {J_JOMP},
  author       = {Håkan Nilsson and Jörg Rieskamp and Eric-Jan Wagenmakers},
  doi          = {10.1016/j.jmp.2020.102429},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102429},
  shortjournal = {J. Math. Psychol.},
  title        = {Hierarchical bayesian parameter estimation for cumulative prospect theory},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on the separability of items in knowledge structures
delineated by skill multimaps. <em>JOMP</em>, <em>98</em>, 102427. (<a
href="https://doi.org/10.1016/j.jmp.2020.102427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the bi-separability of items in knowledge structures as a bidirectional separability of items. Let ( Q , K ) (Q,K) be the knowledge structure delineated by the skill multimap ( Q , S , μ ) (Q,S,μ) . This paper gives some necessary and sufficient conditions , expressed in terms of competencies of μ μ , ensuring that ( Q , K ) (Q,K) is discriminative (resp. bi-discriminative), which generalizes the discussion of the separability of items in the delineated knowledge structure from skill maps to skill multimaps. As applications of these results, the separability and the bi-separability are discussed around distributed skill functions and the meshing of the delineated knowledge structures.},
  archive      = {J_JOMP},
  author       = {Xun Ge and Jinjin Li},
  doi          = {10.1016/j.jmp.2020.102427},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102427},
  shortjournal = {J. Math. Psychol.},
  title        = {A note on the separability of items in knowledge structures delineated by skill multimaps},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When to stop — a cardinal secretary search experiment.
<em>JOMP</em>, <em>98</em>, 102425. (<a
href="https://doi.org/10.1016/j.jmp.2020.102425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cardinal secretary search problem confronts the decision maker with more or less candidates who have identically and independently distributed values and appear successively in a random order without recall of earlier candidates. Its benchmark solution implies monotonically decreasing sequences of optimal value aspirations (acceptance thresholds) for any number of remaining candidates. We compare experimentally observed aspirations with optimal ones for different numbers of (remaining) candidates and methods of experimental choice elicitation: “hot” collects play data, “warm” asks for an acceptance threshold before confronting the next candidate, and “cold” for a complete profile of trial-specific acceptance thresholds. The initially available number of candidates varies across elicitation methods to obtain more balanced data. We find that actual search differs from benchmark behavior, in average search length and success, but also in some puzzling qualitative aspects.},
  archive      = {J_JOMP},
  author       = {Andrej Angelovski and Werner Güth},
  doi          = {10.1016/j.jmp.2020.102425},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102425},
  shortjournal = {J. Math. Psychol.},
  title        = {When to stop — a cardinal secretary search experiment},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). “When a research problem is solved, others are
(re)introduced,” schurz g., hume’s problem solved: The optimality of
meta-induction, MIT press (2019), reviewed by konstantinos v.
katsikopoulos. <em>JOMP</em>, <em>98</em>, 102423. (<a
href="https://doi.org/10.1016/j.jmp.2020.102423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOMP},
  author       = {Konstantinos V. Katsikopoulos},
  doi          = {10.1016/j.jmp.2020.102423},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102423},
  shortjournal = {J. Math. Psychol.},
  title        = {“When a research problem is solved, others are (Re)Introduced”, schurz g., hume’s problem solved: The optimality of meta-induction, MIT press (2019), reviewed by konstantinos v. katsikopoulos},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the functional forms in a psychophysical law of
similarity under a subtractive representation. <em>JOMP</em>,
<em>98</em>, 102421. (<a
href="https://doi.org/10.1016/j.jmp.2020.102421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writing ξ s ( x ) ξs(x) for the stimulus intensity judged greater (louder, heavier, brighter) than stimulus intensity x x with criterion s s , Iverson (2006b) proposed a law of similarity ξ s ( λ x ) = γ ( λ , s ) ξ η ( λ , s ) ( x ) ξs(λx)=γ(λ,s)ξη(λ,s)(x) to model the dependence of ξ s ( x ) ξs(x) on x x . This model, which has η ( λ , s ) η(λ,s) and γ ( λ , s ) γ(λ,s) as parameters, is quite general and may be applied in a number of situations in psychophysics . Iverson (2006b) analyzed this model assuming the representation s = u ( ξ s ( x ) ) − u ( x ) s=u(ξs(x))−u(x) and derived the possible functional forms for the scale u u . In the present work, we extend the analysis to the more general s = u ( ξ s ( x ) ) − w ( x ) s=u(ξs(x))−w(x) and derive the forms for the scales u u and w w . We avoid the assumption of differentiability and replace it with an assumption either of nonconstancy or of dependence on only one input variable. We find that for some solutions, w w has the same form as u u , possibly with different parameters, while for other solutions, w w takes a different form than u u . Comparisons are made to Iverson (2006b) and to other work.},
  archive      = {J_JOMP},
  author       = {Christopher W. Doble and Yung-Fong Hsu},
  doi          = {10.1016/j.jmp.2020.102421},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102421},
  shortjournal = {J. Math. Psychol.},
  title        = {On the functional forms in a psychophysical law of similarity under a subtractive representation},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beating the average forecast: Regularization based on
forecaster attributes. <em>JOMP</em>, <em>98</em>, 102419. (<a
href="https://doi.org/10.1016/j.jmp.2020.102419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a variety of real-world forecasting contexts, researchers have demonstrated that the unweighted average forecast is reasonably accurate and difficult to improve upon with more complex, model-based aggregation methods. We investigate this phenomenon by systematically examining the relationship between individual forecaster characteristics (e.g., bias, consistency) and aspects of the criterion being forecast (e.g., “signal strength”). To this end, we develop a model inspired by Cultural Consensus Theory (Batchelder and Romney, 1988) that (i) allows us to jointly estimate both forecaster characteristics and environmental characteristics and (ii) contains the unweighted average as a special case. This allows us to use the model as a regularization method for forecast aggregation, where restrictions on forecaster parameters make the model similar to use of an unweighted average. Relatedly, the model allows us to apply existing results on optimal forecaster weighting to real data. We show how the model provides guidance for identifying prediction environments where the average forecast can potentially be beaten. We also conduct two simulation studies and illustrate the model’s practical application using forecasts of Australian Football League point spreads.},
  archive      = {J_JOMP},
  author       = {Edgar C. Merkle and Geoff Saw and Clintin Davis-Stober},
  doi          = {10.1016/j.jmp.2020.102419},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102419},
  shortjournal = {J. Math. Psychol.},
  title        = {Beating the average forecast: Regularization based on forecaster attributes},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of the bias–variance decomposition to human
forecasting. <em>JOMP</em>, <em>98</em>, 102417. (<a
href="https://doi.org/10.1016/j.jmp.2020.102417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasts are generated by both human experts and statistical models, and their forecast accuracy can be understood using error decompositions. However, the assumptions that underlie decompositions used in the analysis of human error differ substantially from those used in the analysis of models. The lens model, one of the most popular error decompositions for human errors, treats the beliefs of the human forecaster as fixed parameters to be estimated. Modern decompositions of model error treat the model as a random result from the process of fitting to noisy data. We highlight how these different approaches can be combined, expanding the application of the lens model to groups and opening up new perspectives on the study of human forecasting. We argue that treating human beliefs as the result of a process of learning from noisy data (even without specifying that process) can help to explain many documented phenomena in the world of forecasting such as: what kinds of environments human judgment will have difficulty with and what kinds they will be successful in; what conditions underlie the success of bootstrapping and aggregation of independent forecasts. Just as understanding statistical models as random variables has helped to improve the understanding of error in statistics and machines learning, we believe this framework will be able to help guide the literature on human judgment to a better understanding of error, its determinants and the mechanisms capable of improving forecasting accuracy.},
  archive      = {J_JOMP},
  author       = {Patrick Bodilly Kane and Stephen B. Broomell},
  doi          = {10.1016/j.jmp.2020.102417},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102417},
  shortjournal = {J. Math. Psychol.},
  title        = {Applications of the bias–variance decomposition to human forecasting},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Developing memory-based models of ACT-r within a statistical
framework. <em>JOMP</em>, <em>98</em>, 102416. (<a
href="https://doi.org/10.1016/j.jmp.2020.102416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ACT-R cognitive architecture is a computational framework for developing, simulating and testing comprehensive theories of cognition. By far, the most common method of evaluating ACT-R models involves generating predictions through Monte Carlo simulation and comparing those predictions to aggregated human data. This approach has several limitations, including computational inefficiency, the potential for averaging artifacts, and difficulty representing uncertainty in parameter estimates. In this paper, we demonstrate the fundamentals of developing models of ACT-R within a Bayesian framework. Instantiating ACT-R in a Bayesian framework has many advantages, including the ability to use modern parameter estimation and model comparison techniques, the ability to compare ACT-R to other closed-form models, increased computational efficiency, and the ability to perform a deeper mathematical analysis of model properties. We develop model variants of the classic fan experiment, beginning with a simple baseline model of ACT-R’s declarative memory system and progressing through increasingly complex variants until reaching a moderately complex general model. Our hope is that this will highlight connections between computational and mathematical approaches to formal modeling and facilitate new and exciting research.},
  archive      = {J_JOMP},
  author       = {Christopher R. Fisher and Joseph W. Houpt and Glenn Gunzelmann},
  doi          = {10.1016/j.jmp.2020.102416},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102416},
  shortjournal = {J. Math. Psychol.},
  title        = {Developing memory-based models of ACT-R within a statistical framework},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A one-line proof for complementary symmetry. <em>JOMP</em>,
<em>98</em>, 102406. (<a
href="https://doi.org/10.1016/j.jmp.2020.102406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary symmetry was derived before under particular theories, and used to test those. Progressively general results were published. This paper proves the condition in full generality, providing a one-line proof, and shedding new light on its empirical implications.},
  archive      = {J_JOMP},
  author       = {Peter P. Wakker},
  doi          = {10.1016/j.jmp.2020.102406},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102406},
  shortjournal = {J. Math. Psychol.},
  title        = {A one-line proof for complementary symmetry},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regularized models of audiovisual integration of speech with
predictive power for sparse behavioral data. <em>JOMP</em>, <em>98</em>,
102404. (<a href="https://doi.org/10.1016/j.jmp.2020.102404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audiovisual integration can facilitate speech comprehension by integrating information from lip-reading with auditory speech perception. When incongruent acoustic speech is dubbed onto a video of a talking face, this integration can lead to the McGurk illusion of hearing a different phoneme than that spoken by the voice. Several computational models of the information integration process underlying these phenomena exist. All are based on the assumption that the integration process is, in some sense, optimal. They differ, however, in assuming that it is based on either continuous or categorical internal representations. Here we develop models of audiovisual integration of the phonetic information represented on an internal representation that is continuous and cyclical. We compare these models to the Fuzzy Logical Model of Perception (FLMP), which is based on a categorical internal representation. Using cross-validation, we show that model evaluation criteria based on the goodness-of-fit are poor measures of the models’ generalization error even if they take the number of free parameters into account. We also show that the predictive power of all the models benefit from regularization that limits the precision of the internal representation. Finally, we show that, unlike the FLMP, models based on a continuous internal representation have good predictive power when properly regularized.},
  archive      = {J_JOMP},
  author       = {Tobias S. Andersen and Ole Winther},
  doi          = {10.1016/j.jmp.2020.102404},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102404},
  shortjournal = {J. Math. Psychol.},
  title        = {Regularized models of audiovisual integration of speech with predictive power for sparse behavioral data},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter estimation approaches for multinomial processing
tree models: A comparison for models of memory and judgment.
<em>JOMP</em>, <em>98</em>, 102402. (<a
href="https://doi.org/10.1016/j.jmp.2020.102402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multinomial processing tree (MPT) models are commonly used in cognitive psychology to disentangle and measure the psychological processes underlying behavior. Various estimation approaches have been developed to estimate the parameters of MPT models for a group of participants. These approaches are implemented in various programs (e.g., MPTinR, TreeBUGS) and differ with regard to how data are pooled across participants (no pooling, complete pooling, or partial pooling). The partial-pooling approaches differ with regard to whether correlations between individual-level parameters are explicitly modeled (latent-trait MPT) or not (beta-MPT). However, it is currently unclear whether the theoretical advantages of the partial-pooling approaches actually yield the best results in standard practice (i.e., with typical parameter values and amounts of data). We conducted parameter recovery analyses comparing the accuracy and precision of four estimation approaches for two MPT models: the source-monitoring model and the hindsight-bias model. For essential (“core”) parameters of the two models, the partial-pooling approaches yielded the best results overall. Importantly, there were also model-specific differences between the approaches. For the source-monitoring model, the latent-trait approach achieved the best results. For more complex hindsight-bias model, the latent-trait approach appeared to be overparameterized for typical amounts of data; here, the beta-MPT approach was better. We derive recommendations for applications of the two MPT models.},
  archive      = {J_JOMP},
  author       = {Julia Groß and Thorsten Pachur},
  doi          = {10.1016/j.jmp.2020.102402},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102402},
  shortjournal = {J. Math. Psychol.},
  title        = {Parameter estimation approaches for multinomial processing tree models: A comparison for models of memory and judgment},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparison of correlation and regression approaches for
multinomial processing tree models. <em>JOMP</em>, <em>98</em>, 102400.
(<a href="https://doi.org/10.1016/j.jmp.2020.102400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multinomial processing tree (MPT) models are a class of stochastic models for categorical data that have recently been extended to account for heterogeneity in individuals by assuming separate parameters per participant. These extensions enable the estimation of correlations among model parameters and correlations between model parameters and external covariates . The present study compares different approaches regarding their ability to estimate both types of correlations. For parameter–parameter correlations, we considered two Bayesian hierarchical MPT models – the beta-MPT approach and the latent-trait approach – and two frequentist approaches that fit the data of each participant separately, either involving a correction for attenuation or not (corrected and uncorrected individual-model approach). Regarding parameter-covariate correlations, we additionally considered the latent-trait regression. Recovery performance was determined via a Monte Carlo simulation varying sample size, number of items, extent of heterogeneity, and magnitude of the true correlation. The results indicate the smallest bias regarding parameter–parameter​ correlations for the latent-trait approach and the corrected individual-model approach and the smallest bias regarding parameter-covariate correlations for the latent-trait regression and the corrected individual-model approach. However, adequately recovering correlations of MPT parameters generally requires a sufficiently large number of observations and sufficient heterogeneity.},
  archive      = {J_JOMP},
  author       = {Lisa J. Jobst and Daniel W. Heck and Morten Moshagen},
  doi          = {10.1016/j.jmp.2020.102400},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102400},
  shortjournal = {J. Math. Psychol.},
  title        = {A comparison of correlation and regression approaches for multinomial processing tree models},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Do items order? The psychology in IRT models. <em>JOMP</em>,
<em>98</em>, 102398. (<a
href="https://doi.org/10.1016/j.jmp.2020.102398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invariant item ordering refers to the statement that if one item is harder than another for one person, then it is harder for all people. Whether item ordering holds is a psychological statement because it describes how people may qualitatively vary. Yet, modern item response theory (IRT) makes an a priori commitment to item ordering. The Rasch model , for example, posits that items must order. Conversely, the 2PL model posits that items never order. Needed is an IRT model where item ordering or its violation is a function of the data rather than an a priori commitment. We develop two-parameter shift-scale models for this purpose, and find that the two-parameter uniform offers many advantages. We show how item ordering may be assessed using Bayes factor model comparison, and discuss computational issues with shift-scale IRT models.},
  archive      = {J_JOMP},
  author       = {Julia M. Haaf and Edgar C. Merkle and Jeffrey N. Rouder},
  doi          = {10.1016/j.jmp.2020.102398},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102398},
  shortjournal = {J. Math. Psychol.},
  title        = {Do items order? the psychology in IRT models},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessing cross-modal interference in the detection response
task. <em>JOMP</em>, <em>98</em>, 102390. (<a
href="https://doi.org/10.1016/j.jmp.2020.102390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection response task (DRT) is a measure of workload that can assess the cognitive demands of real-world multitasking. It can be configured to present simple stimuli of several modalities, including auditory and visual signals. However, the concurrent presentation of the DRT stimuli alongside another task could cause dual-task interference, and the extent of this interference could be different based on the DRT’s configuration. It is necessary to consider the characteristics of the DRT stimulus, such as modality, to identify a minimally intrusive stimulus. Fifty participants completed a computer-based one-dimensional tracking task alongside a DRT. The DRT’s stimuli varied in their modality (visual/auditory), while the tracking task varied in its workload demand (low/high). DRT performance was modelled using a shifted-Wald model, while the tracking task was assessed using systems factorial technology (SFT), a non-parametric methodology capable of capturing a cognitive system’s workload capacity. To allow the latter’s use, we developed a method of transforming continuous tracking data into a discrete form akin to response times. Analysis of DRT data found little evidence that the DRT’s modality affected processing efficiency, while SFT analysis found limited-capacity processing on the tracking task across both DRT modalities. These findings suggest DRT modality had little effect on the level of interference between the two tasks.},
  archive      = {J_JOMP},
  author       = {Alexander Thorpe and Reilly Innes and James Townsend and Rachel Heath and Keith Nesbitt and Ami Eidels},
  doi          = {10.1016/j.jmp.2020.102390},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102390},
  shortjournal = {J. Math. Psychol.},
  title        = {Assessing cross-modal interference in the detection response task},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter validation in hierarchical MPT models by
functional dissociation with continuous covariates: An application to
contingency inference. <em>JOMP</em>, <em>98</em>, 102388. (<a
href="https://doi.org/10.1016/j.jmp.2020.102388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional multinomial processing tree (MPT) models for aggregate frequency data, parameters have usually been validated by means of experimental manipulations, thereby testing selective effects of discrete independent variables on specific model parameters. More recently, hierarchical MPT models which account for parameter heterogeneity between participants have been introduced. These models offer a new possibility of parameter validation by analyzing selective covariations of interindividual differences in MPT model parameters with continuous covariates . The new approach enables researchers to test parameter validity in terms of functional dissociations, including convergent validity and discriminant validity in a nomological network. Here, we apply the novel approach to a multidimensional source-monitoring model in the domain of stereotype formation based on pseudocontingency inference. Using hierarchical Bayesian MPT models, we test the validity of source-guessing parameters as indicators of specific source evaluations on the individual level. First, analyzing experimental data on stereotype formation ( N = 130 N=130 ), we replicated earlier findings of biased source-guessing parameters while taking parameter heterogeneity across participants into account. Second, we investigated the specificity of covariations between conditional guessing parameters and continuous direct measures of source evaluations. Interindividual differences in direct evaluations predicted interindividual differences in specific source-guessing parameters, thus validating their substantive interpretation. Third, in an exploratory analysis , we examined relations of memory parameters and guessing parameters with cognitive performance measures from a standardized cognitive assessment battery.},
  archive      = {J_JOMP},
  author       = {Franziska M. Bott and Daniel W. Heck and Thorsten Meiser},
  doi          = {10.1016/j.jmp.2020.102388},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102388},
  shortjournal = {J. Math. Psychol.},
  title        = {Parameter validation in hierarchical MPT models by functional dissociation with continuous covariates: An application to contingency inference},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A joint process model of consensus and longitudinal
dynamics. <em>JOMP</em>, <em>98</em>, 102386. (<a
href="https://doi.org/10.1016/j.jmp.2020.102386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extended Condorcet Model allows us to explore interindividual consensus concerning culturally held knowledge. Also, it enables a process-level description of interindividual differences in the knowledge a person has of the consensus, their willingness to guess in the absence of knowledge, and their bias in guessing. These person-specific characteristics might be tied to one’s everyday life experiences. Here, we develop a cognitive latent variable model in which dynamic process parameters from intensive longitudinal daily life data are systematically linked to parameters of the Extended Condorcet Model. We apply this joint model of consensus and longitudinal dynamics to study whether subjective beliefs on what makes people feel loved are linked to daily life experiences of love.},
  archive      = {J_JOMP},
  author       = {Zita Oravecz and Joachim Vandekerckhove},
  doi          = {10.1016/j.jmp.2020.102386},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102386},
  shortjournal = {J. Math. Psychol.},
  title        = {A joint process model of consensus and longitudinal dynamics},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the validity of perceived social structure.
<em>JOMP</em>, <em>98</em>, 102384. (<a
href="https://doi.org/10.1016/j.jmp.2020.102384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The validity of survey-based reports of social relationships is a critical assumption for much social network research. Research on informant accuracy has shown that observational data and recalled behavior by informants are imperfectly correlated, which calls into question whether complex relations like friendship and advice-seeking can be accurately measured from individual reports. A class of network inference models, the Bayesian Network Accuracy Models, growing out of the pioneering work of Batchelder and Romney on inference from informant reports, provides a principled basis for inferring network structure given such error-prone data. Using these models, we can gain insight into the accuracy of informants’ self and proxy reports of social ties, and more broadly, the reliability and validity of respondents’ reports of informal social relations. While existing data does not provide a criterion validity check for inferring most relationships, other notions of validity and/or reliability can still be applied. For instance, if friendship reports are generated from a common underlying network that is perceivable (albeit imperfectly) by all actors, then random subsets of actors should produce estimates that should agree (i.e., split-half reliability). Using informant reports on friendship and advice-seeking networks from four different organizations, we show substantially higher levels of split-half reliability than can be explained by chance, suggesting that models are indeed estimating a common underlying relation. We also show that informants’ errors appear to be structured in ways that are consistent with cognitive models of social perception, with greater accuracy on average for large-scale network features rather than fine details, for own versus others’ ties, and for core–periphery structures versus bipartitions. Evidence from construct validity checks further suggests the that common networks underlying informants’ reports have properties that would be expected of true social structures. Taken together, our findings support the view that informants’ mental models of social structure, while error-prone, nevertheless reflect an underlying social reality.},
  archive      = {J_JOMP},
  author       = {Francis Lee and Carter T. Butts},
  doi          = {10.1016/j.jmp.2020.102384},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102384},
  shortjournal = {J. Math. Psychol.},
  title        = {On the validity of perceived social structure},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cultural consensus theory for the evaluation of patients’
mental health scores in forensic psychiatric hospitals. <em>JOMP</em>,
<em>98</em>, 102383. (<a
href="https://doi.org/10.1016/j.jmp.2020.102383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many forensic psychiatric hospitals, patients’ mental health is monitored at regular intervals. Typically, clinicians score patients using a Likert scale on multiple criteria including hostility. Having an overview of patients’ scores benefits staff members in at least three ways. First, the scores may help adjust treatment to the individual patient; second, the change in scores over time allows an assessment of treatment effectiveness; third, the scores may warn staff that particular patients are at high risk of turning violent, either before or after release. Practical importance notwithstanding, current practices for the analysis of mental health scores are suboptimal: evaluations from different clinicians are averaged (as if the Likert scale were linear and the clinicians identical), and patients are analyzed in isolation (as if they were independent). Uncertainty estimates of the resulting score are often ignored. Here we outline a quantitative program for the analysis of mental health scores using cultural consensus theory (CCT; Anders and Batchelder, 2015). CCT models take into account the ordinal nature of the Likert scale, the individual differences among clinicians, and the possible commonalities between patients. In a simulation, we compare the predictive performance of the CCT model to the current practice of aggregating raw observations and, as an alternative, against often-used machine learning toolboxes. In addition, we outline the substantive conclusions afforded by the application of the CCT model. We end with recommendations for clinical practitioners who wish to apply CCT in their own work.},
  archive      = {J_JOMP},
  author       = {Don van den Bergh and Stefan Bogaerts and Marinus Spreen and Rob Flohr and Joachim Vandekerckhove and William H. Batchelder and Eric-Jan Wagenmakers},
  doi          = {10.1016/j.jmp.2020.102383},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102383},
  shortjournal = {J. Math. Psychol.},
  title        = {Cultural consensus theory for the evaluation of patients’ mental health scores in forensic psychiatric hospitals},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical multinomial modeling to explain individual
differences in children’s clustering in free recall. <em>JOMP</em>,
<em>98</em>, 102378. (<a
href="https://doi.org/10.1016/j.jmp.2020.102378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of individual differences in cognitive processes and the advancement of multinomial processing tree (MPT) models were two of William H. Batchelder’s major research interests. Inspired by his work, we investigated developmental differences between 7-year-old children, 10-year-old children, and young adults, in free recall with the pair-clustering model by Batchelder and Riefer (1980, 1986). Specifically, we examined individual differences (in initial levels and in change across multiple study–test trials) in cluster encoding, retrieval, and covariation with three basic cognitive abilities: semantic verbal understanding, short-term memory capacity, information-processing speed. Data from two developmental studies in which 228 participants freely recalled clusterable words in four study–test cycles were used for reanalysis. We combined two model extensions not linked so far (Klauer, 2010; Knapp &amp; Batchelder, 2004). This novel combination of modeling methods made it possible to analyze the relation between individual cognitive abilities and changes in cluster encoding and retrieval across study–test cycles. Inspired by William H. Batchelder, this work illustrates how MPT modeling can contribute to the understanding of cognitive development.},
  archive      = {J_JOMP},
  author       = {Martha Michalkiewicz and Sebastian S. Horn and Ute J. Bayen},
  doi          = {10.1016/j.jmp.2020.102378},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102378},
  shortjournal = {J. Math. Psychol.},
  title        = {Hierarchical multinomial modeling to explain individual differences in children’s clustering in free recall},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A transdisciplinary view of measurement error models and the
variations of x=t+e. <em>JOMP</em>, <em>98</em>, 102372. (<a
href="https://doi.org/10.1016/j.jmp.2020.102372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to formally outline a sequence of propositions that describe the connections between five linearly additive measurement error models commonly used in disciplines from psychometrics and test theory to economics to epidemiology, and one new model formerly proposed in Kroc &amp; Zumbo (2018). We show that although these models are deceptively similar in their general algebraic form, X = T + E X=T+E , they have different error structures that both connect and distinguish them.},
  archive      = {J_JOMP},
  author       = {Edward Kroc and Bruno D. Zumbo},
  doi          = {10.1016/j.jmp.2020.102372},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102372},
  shortjournal = {J. Math. Psychol.},
  title        = {A transdisciplinary view of measurement error models and the variations of X=T+E},
  volume       = {98},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mean field dynamics of stochastic cellular automata for
random and small-world graphs. <em>JOMP</em>, <em>97</em>, 102380. (<a
href="https://doi.org/10.1016/j.jmp.2020.102380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We aim to provide a theoretical framework to explain the discrete transitions of mood connecting ideas from network theory and dynamical systems theory. It was recently shown how networks (graphs) can be used to represent psychopathologies, where symptoms of, say, depression, affect each other and certain configurations determine whether someone could transition into a depression. To analyse changes over time and characterise possible future behaviour is in general rather difficult for large graphs. We describe the dynamics of graphs using one-dimensional discrete time dynamical systems theory obtained from a mean field approximation to stochastic cellular automata (SCA). Often the mean field approximation is used on a regular graph (a grid or torus) where each node has the same number of edges and the same probability of becoming active. We provide quantitative results on the accuracy of using the mean field approximation for the grid and random and small-world graph to describe the dynamics of the SCA. Bifurcation diagrams for the mean field of the different graphs indicate possible phase transitions for certain parameter settings of the mean field. Simulations confirm for different graph sizes (number of nodes) that the mean field approximation is accurate.},
  archive      = {J_JOMP},
  author       = {Lourens Waldorp and Jolanda Kossakowski},
  doi          = {10.1016/j.jmp.2020.102380},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102380},
  shortjournal = {J. Math. Psychol.},
  title        = {Mean field dynamics of stochastic cellular automata for random and small-world graphs},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical regularities of data from the property listing
task. <em>JOMP</em>, <em>97</em>, 102376. (<a
href="https://doi.org/10.1016/j.jmp.2020.102376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study linguistically coded concepts, researchers often resort to the Property Listing Task (PLT). In a PLT, participants are asked to list properties that describe a concept (e.g., for DOG, subjects may list “is a pet”, “has four legs”, etc.), which are then coded into property types (i.e., superficially dissimilar properties such as “has four legs” and “ is a quadruped” may be coded as “four legs”). When the PLT is done for many concepts, researchers obtain Conceptual Properties Norms (CPNs), which are used to study semantic content and as a source of control variables. Though the PLT and CPNs are widely used across psychology, there is a lack of a formal model of the PLT, which would provide better analysis tools. Particularly, nobody has attempted analyzing the PLT’s listing process. Thus, in the current work we develop a mathematical description of the PLT. Our analyses indicate that several regularities should be found in the observable data obtained from a PLT. Using data from three different CPNs (from 3 countries and 2 different languages), we show that these regularities do in fact exist and generalize well across different CPNs. Overall, our results suggest that the description of the regularities found in PLT data may be fruitfully used in the study of concepts.},
  archive      = {J_JOMP},
  author       = {Enrique Canessa and Sergio E. Chaigneau},
  doi          = {10.1016/j.jmp.2020.102376},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102376},
  shortjournal = {J. Math. Psychol.},
  title        = {Mathematical regularities of data from the property listing task},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consensus theory for multiple latent traits and consensus
groups. <em>JOMP</em>, <em>97</em>, 102374. (<a
href="https://doi.org/10.1016/j.jmp.2020.102374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a situation in which a group of respondents answers a set of questions and the aim is to identify any consensus among the respondents—that is, shared attitudes, beliefs, or knowledge. Consensus theory postulates that a latent trait determines the respondents’ probability to produce the consensus response. We propose a new version of the variable-response model, which implements consensus theory for numerical continuous responses, ordered categorical responses, unordered categorical responses, or a mixture thereof. The new model also accounts for multiple consensus groups and multiple latent traits underlying the response data. In a series of simulation studies, we identify procedures and conditions that permit an accurate estimation of the number of consensus groups and latent traits. In these simulations, we find that the model recovers the data-generating consensus responses well. We replicate these findings with the empirical data of a memory test.},
  archive      = {J_JOMP},
  author       = {André Aßfalg and Karl Christoph Klauer},
  doi          = {10.1016/j.jmp.2020.102374},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102374},
  shortjournal = {J. Math. Psychol.},
  title        = {Consensus theory for multiple latent traits and consensus groups},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dissecting EXIT. <em>JOMP</em>, <em>97</em>, 102371. (<a
href="https://doi.org/10.1016/j.jmp.2020.102371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kruschke’s EXIT model (Kruschke, 2001b) has been very successful in explaining a variety of learning phenomena by means of selective attention. In particular, EXIT produces learned predictiveness effects (Le Pelley and McLaren, 2003), the inverse base rate effect (Kruschke, 1996; Medin and Edelson, 1988), inattention after blocking (Beesley and Le Pelley, 2011; Kruschke and Blair, 2000), differential cue use across the stimulus space (Aha and Goldstone, 1992) and conditional learned predictiveness effects (Uengoer et al., 2013). We dissect EXIT into its component mechanisms (error-driven learning, selective attention, attentional competition, rapid attention shifts and exemplar mediation of attention) and test whether simplified versions of EXIT can explain the same experimental results as the full model. Most phenomena can be explained by either rapid attention shifts or attentional competition, without the need for combining them as in EXIT. There is little evidence for exemplar mediation of attention when people learn linearly separable category structures (e.g. Kruschke and Blair, 2000; Le Pelley and McLaren, 2003); whether or not it is needed for non-linear categories depends on stimulus representation (Aha and Goldstone, 1992; Uengoer et al., 2013). On the whole, we believe that attentional competition—embodied in a model which we dub CompAct—offers the simplest explanation for the experimental results we examine.},
  archive      = {J_JOMP},
  author       = {Samuel Paskewitz and Matt Jones},
  doi          = {10.1016/j.jmp.2020.102371},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102371},
  shortjournal = {J. Math. Psychol.},
  title        = {Dissecting EXIT},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting amongst multinomial models: An apologia for
normalized maximum likelihood. <em>JOMP</em>, <em>97</em>, 102367. (<a
href="https://doi.org/10.1016/j.jmp.2020.102367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The modeling of multinomial data has seen tremendous progress since Riefer and Batchelder’s (1988) seminal paper. One recurring challenge, however, concerns the availability of relative performance measures that strike an ideal balance between goodness of fit and functional flexibility. One approach to the problem of model selection is Normalized Maximum Likelihood (NML), a solution derived from the Minimum Description Length principle. In the present work we provide an R implementation of a Gibbs sampler that can be used to compute NML for models of joint multinomial data. We discuss the application of NML in different examples, compare NML with Bayes Factors, and show how it constitutes an important addition to researchers’ toolboxes.},
  archive      = {J_JOMP},
  author       = {David Kellen and Karl Christoph Klauer},
  doi          = {10.1016/j.jmp.2020.102367},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102367},
  shortjournal = {J. Math. Psychol.},
  title        = {Selecting amongst multinomial models: An apologia for normalized maximum likelihood},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How many decimals? Rounding descriptive and inferential
statistics based on measurement precision. <em>JOMP</em>, <em>97</em>,
102362. (<a href="https://doi.org/10.1016/j.jmp.2020.102362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reporting descriptive statistics requires rounding the results. Experienced researchers typically round the numbers to one or two decimals, following the APA manual. However, this general recommendation ignores the sample size and the instrument’s precision. Herein, expressions are derived that indicate how many decimals are reliable and so at what point the results should be rounded. The derivations are based on the measurement precision, that is, the precision of the raw data and uses propagation of error techniques. Two scenarios are considered, one in which systematic measurement error is possible and one in which only non-systematic measurement error is assumed. An example is provided showing how to round means, standard deviations and t values, among others, and an R library is available to automatize calculations.},
  archive      = {J_JOMP},
  author       = {Denis Cousineau},
  doi          = {10.1016/j.jmp.2020.102362},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102362},
  shortjournal = {J. Math. Psychol.},
  title        = {How many decimals? rounding descriptive and inferential statistics based on measurement precision},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can the wrong horse win: The ability of race models to
predict fast or slow errors. <em>JOMP</em>, <em>97</em>, 102360. (<a
href="https://doi.org/10.1016/j.jmp.2020.102360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This report continues our probe of the fundamental properties of elementary psychological processes. In the present instance, we first distinguish between descriptive and state–space based parallel race models. Then we show, engaging previous results on stochastic dominance in Theorem 1, that descriptive race models can be designed that predict either faster ‘right’ channels or faster ‘wrong’ channels. Moving to state–space based models and in particular, to inhomogeneous Poisson counter models, we use Theorem 1 to prove Theorem 2 which offers sufficient conditions for such models to elicit faster ‘rights’ than ‘wrongs’. Then, constraining ourselves to models possessing proportional processing rates, we revisit an important finding by Smith and Van Zandt (2000) to the effect that in such models, mean processing times conditional on ‘right’ decisions are faster than those conditional on ‘wrong’ decisions. Theorem 3 expands that property to the much stronger level of ordered conditional distribution functions. The penultimate section constructs an example of an inhomogeneous Poisson race model that predicts faster ‘wrongs’ for fast processing times but faster ‘rights’ for slower processing times. We leave as an open problem the question of whether there exist inhomogeneous Poisson race models where ‘wrongs’ are stochastically faster than ‘rights’ for all durations of processing.},
  archive      = {J_JOMP},
  author       = {James T. Townsend and Yanjun Liu},
  doi          = {10.1016/j.jmp.2020.102360},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102360},
  shortjournal = {J. Math. Psychol.},
  title        = {Can the wrong horse win: The ability of race models to predict fast or slow errors},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adding a bias to vector models of association memory
provides item memory for free. <em>JOMP</em>, <em>97</em>, 102358. (<a
href="https://doi.org/10.1016/j.jmp.2020.102358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anderson (1970) introduced two models that are at the core of artificial neural network models as well as cognitive mathematical models of memory. The first, a simple summation of items, represented as vectors, can support rudimentary item-recognition. The second, a heteroassociative model consisting of a summation of outer products between paired item vectors, can support cued recall of associations. Anderson recommended fixing the element-value mean to zero, for tractability, and with minimal loss of generality. However, in a neural network model, if element values are represented by firing rates, this mean-centering is violated, because firing rates cannot be negative. We show, analytically, that adding a bias to item representations produces interference from other studied list items. Although this worsens cued recall, it also tempts the model to make intrusion responses to other studied items, not unlike human participants. Moreover, an unexpected feature appears: when probed with a constant vector , containing no “information,” the model retrieves a weighted sum of studied items, formally equivalent to Anderson’s item-memory model. This speaks to Hockley and Cristi’s (1996) findings that associative study strategies led to high item-recognition, but not vice versa. We show that such a model can achieve high levels of performance (d ′ ′ ), when the bias is greater than zero but not too large relative to the standard deviation of element values. We demonstrate these effects in a two-layer spiking-neuron network model. Thus, when modelers have striven for realism and relaxed mean-centering, such models may not only still function at adequate levels, but acquire a spin-off functionality that can actually be used, without the need for additional encoding terms specific to item-memory.},
  archive      = {J_JOMP},
  author       = {Jeremy B. Caplan and Kaiyuan Xu and Sucheta Chakravarty and Kelvin E. Jones},
  doi          = {10.1016/j.jmp.2020.102358},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102358},
  shortjournal = {J. Math. Psychol.},
  title        = {Adding a bias to vector models of association memory provides item memory for free},
  volume       = {97},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New estimation approaches for the hierarchical linear
ballistic accumulator model. <em>JOMP</em>, <em>96</em>, 102368. (<a
href="https://doi.org/10.1016/j.jmp.2020.102368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Linear Ballistic Accumulator (LBA: Brown and Heathcote, 2008) model is used as a measurement tool to answer questions about applied psychology . The analyses based on this model depend upon the model selected and its estimated parameters. Modern approaches use hierarchical Bayesian models and Markov chain Monte-Carlo (MCMC) methods to estimate the posterior distribution of the parameters. Although there are several approaches available for model selection, they are all based on the posterior samples produced via MCMC , which means that the model selection inference inherits the properties of the MCMC sampler. To improve on current approaches to LBA inference we propose two methods that are based on recent advances in particle MCMC methodology; they are qualitatively different from existing approaches as well as from each other. The first approach is particle Metropolis-within-Gibbs; the second approach is density tempered sequential Monte Carlo . Both new approaches provide very efficient sampling and can be applied to estimate the marginal likelihood, which provides Bayes factors for model selection. The first approach is usually faster. The second approach provides a direct estimate of the marginal likelihood, uses the first approach in its Markov move step and is very efficient to parallelise on high performance computers. The new methods are illustrated by applying them to simulated and real data, and through pseudo code . The code implementing the methods is freely available.},
  archive      = {J_JOMP},
  author       = {D. Gunawan and G.E. Hawkins and M.-N. Tran and R. Kohn and S.D. Brown},
  doi          = {10.1016/j.jmp.2020.102368},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102368},
  shortjournal = {J. Math. Psychol.},
  title        = {New estimation approaches for the hierarchical linear ballistic accumulator model},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When your gain is also my gain. A class of strategic models
with other-regarding agents. <em>JOMP</em>, <em>96</em>, 102366. (<a
href="https://doi.org/10.1016/j.jmp.2020.102366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the role of social preferences in a competitive framework. More precisely, we study other-regarding strategic models where agents show Rawlsian preferences and, therefore, they care about the best interest of the worst-off agent. The representation of preferences proposed is the most appropriate when the utilities of the agents are vector-valued and their components are not compensable but complementary. In these cases, the improvement of the result for each agent has to be reached by simultaneously improving all the components of the vector-valued utility. Depending on the attitude exhibited by the agents with respect to the results of the others, we distinguish different types of agents and relate them with the parameters of the Rawlsian preference function. An analysis of the sets of equilibria in terms of these parameters is presented. Particularly, in the case of two agents, the equilibria for all the values of the parameters are completely described.},
  archive      = {J_JOMP},
  author       = {A.M. Mármol and A. Zapata and L. Monroy and M.A. Caraballo},
  doi          = {10.1016/j.jmp.2020.102366},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102366},
  shortjournal = {J. Math. Psychol.},
  title        = {When your gain is also my gain. a class of strategic models with other-regarding agents},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Category-based induction in conceptual spaces.
<em>JOMP</em>, <em>96</em>, 102357. (<a
href="https://doi.org/10.1016/j.jmp.2020.102357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Category-based induction is an inferential mechanism that uses knowledge of conceptual relations in order to estimate how likely is for a property to be projected from one category to another. During the last decades, psychologists have identified several features of this mechanism, and they have proposed different formal models of it. In this article; we propose a new mathematical model for category-based induction based on distances on conceptual spaces. We show how this model can predict most of the properties of this kind of reasoning while providing a solid theoretical foundation for it. We also show that it subsumes some of the previous models proposed in the literature and that it generates new predictions.},
  archive      = {J_JOMP},
  author       = {Matías Osta-Vélez and Peter Gärdenfors},
  doi          = {10.1016/j.jmp.2020.102357},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102357},
  shortjournal = {J. Math. Psychol.},
  title        = {Category-based induction in conceptual spaces},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bi-preference interplay between transitivity and
completeness: Reformulating and extending schmeidler’s theorem.
<em>JOMP</em>, <em>96</em>, 102354. (<a
href="https://doi.org/10.1016/j.jmp.2020.102354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers’ preferences and choices are traditionally described by appealing to two classical tenets of rationality: transitivity and completeness. In 1971, Schmeidler proved a striking result on the interplay between these properties: On a connected topological space, a nontrivial bi-semicontinuous preorder is complete . Here we reformulate and extend this well-known theorem. First, we show that the topology is not independent of the preorder, contrary to what the original statement suggests. In fact, Schmeidler’s theorem can be restated as follows: A nontrivial preorder with a connected order-section topology is complete. Successively, we extend it to comonotonic bi-preferences: these are pairs of relations such that the first is a preorder, and the second consistently enlarges the first. In particular, a NaP -preference (necessary and possible preference, Giarlotta and Greco, 2013) is a comonotonic bi-preference with a complete second component. We prove two complementary results of the following kind: Special comonotonic bi-preferences with a connected order-section topology are NaP -preferences . Schmeidler’s theorem is a particular case.},
  archive      = {J_JOMP},
  author       = {Alfio Giarlotta and Stephen Watson},
  doi          = {10.1016/j.jmp.2020.102354},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102354},
  shortjournal = {J. Math. Psychol.},
  title        = {A bi-preference interplay between transitivity and completeness: Reformulating and extending schmeidler’s theorem},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The role of context in experiments and models of
multisensory decision making. <em>JOMP</em>, <em>96</em>, 102352. (<a
href="https://doi.org/10.1016/j.jmp.2020.102352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of signals from multiple senses is often beneficial for perceptual decisions. To study such benefits, models of multisensory decision-making are typically fed with the behavioural performance as measured separately with unisensory component signals. Critically, by doing so, the approach implicitly makes the so-called context invariance assumption, which states that processing of a signal is independent of the experimental context in which it is embedded. However, context invariance is not necessarily true and is difficult to test directly. Here, we aim to assess context invariance indirectly in two testable scenarios. First, to consider the role of stimulus context, we compared unisensory performance in trials that either included a task-irrelevant signal in another modality, or not (unisensory vs. multisensory signal trials). We found that performance was faster but less sensitive in trials that contained a task-irrelevant signal. Hence, stimulus context invariance was violated. Second, to consider the role of instruction context, we compared unisensory performance when participants were asked to detect targets from either one or two modalities (unisensory vs. multisensory instructions). We found that performance was deteriorated in multi- compared to unisensory instructions, which was largely due to modality switch costs in multisensory instructions. Hence, instruction context invariance did not hold either. As performance was variant in both scenarios, context invariance cannot generally assumed to be true. We conclude that models of multisensory decision making should critically consider potential violations of the context invariance assumption as a potentially confounding factor.},
  archive      = {J_JOMP},
  author       = {Yue Liu and Thomas U. Otto},
  doi          = {10.1016/j.jmp.2020.102352},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102352},
  shortjournal = {J. Math. Psychol.},
  title        = {The role of context in experiments and models of multisensory decision making},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessing multisensory integration and estimating speed of
processing with the dual-presentation timing task: Model and data.
<em>JOMP</em>, <em>96</em>, 102351. (<a
href="https://doi.org/10.1016/j.jmp.2020.102351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our ability to detect temporal asynchrony is sometimes an obstacle to multisensory integration. A seamless multisensory experience occurs when the temporal misalignment of two signals is within the allowance for subjective synchrony, referred to as the temporal window of integration (TWI). The TWI is most commonly measured with the temporal-order judgment task or the synchrony judgment task, which are single-presentation methods that confound sensory and decisional determinants of performance. Thus, data collected with these tasks are unsuitable for elucidating whether changes in the TWI observed in studies on prior entry or temporal recalibration have a sensory or a decisional origin. The indeterminacy can be resolved with a dual-presentation timing (2PT) task in which observers report their judgment with a ternary response format: whether the first or the second presentation was more synchronous or else that they were equally synchronous. Yet, the analysis of 2PT data suffers from the lack of a process model that captures sensory, decisional, and response components of performance via separate parameters whose estimation can identify the cause of prior entry or recalibration effects. The main goal of this paper is to present and validate such a model. Simulation studies reveal that model parameters are identifiable and not confounded under the ternary response format. The empirical validity of the model is demonstrated by showing its capability to account for published data collected with the 2PT task under binary response formats and for new data collected with the ternary format. The new data relate to a study on differences in speed of processing between magnocellular and parvocellular visual pathways , and our analysis revealed that low-spatial-frequency information is processed 20–30 ms faster than high-spatial-frequency information. Measures of the TWI and the point of subjective synchrony are presented for their estimation from ternary 2PT data. Software in matlab and R to fit the model to ternary 2PT data is made available with this paper.},
  archive      = {J_JOMP},
  author       = {Miguel A. García-Pérez and Rocío Alcalá-Quintana},
  doi          = {10.1016/j.jmp.2020.102351},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102351},
  shortjournal = {J. Math. Psychol.},
  title        = {Assessing multisensory integration and estimating speed of processing with the dual-presentation timing task: Model and data},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep active inference as variational policy gradients.
<em>JOMP</em>, <em>96</em>, 102348. (<a
href="https://doi.org/10.1016/j.jmp.2020.102348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Inference is a theory arising from theoretical neuroscience which casts action and planning as Bayesian inference problems to be solved by minimizing a single quantity — the variational free energy. The theory promises a unifying account of action and perception coupled with a biologically plausible process theory. However, despite these potential advantages, current implementations of Active Inference can only handle small policy and state–spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm that approximates key densities using deep neural networks as flexible function approximators, which enables our approach to scale to significantly larger and more complex tasks than any before attempted in the literature. We demonstrate our method on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm evokes similarities with maximum-entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.},
  archive      = {J_JOMP},
  author       = {Beren Millidge},
  doi          = {10.1016/j.jmp.2020.102348},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102348},
  shortjournal = {J. Math. Psychol.},
  title        = {Deep active inference as variational policy gradients},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Retrospective surprise: A computational component for active
inference. <em>JOMP</em>, <em>96</em>, 102347. (<a
href="https://doi.org/10.1016/j.jmp.2020.102347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the free energy principle (FEP) proposed by Friston, it is supposed that agents seek to minimize the “surprise” – the negative log (marginal) likelihood of observations (i.e., sensory stimuli) – given the agents’ current belief. This is achieved by minimizing the free energy, which provides an upper bound on the surprise. The FEP has been applied to action selection in a framework called “active inference,” where agents are supposed to select an action so that they minimize the “expected free energy” (EFE). While EFE can be decomposed into interpretable components such as epistemic value and extrinsic value, it is difficult to understand intuitively how EFE itself is directly related to “surprise” and what psychological construct is related to EFE itself (as a single quantity). To facilitate the discussion and interpretation of psychological processes underlying active inference, we introduce a computational component termed the “retrospective surprise,” which is the surprise of an observation after updating the belief given the observation itself. The predicted retrospective surprise (PRS) is mathematically derived from a special case of EFE and provides a lower bound on EFE. We illustrate the properties of EFE and PRS using examples of inference for a binary hidden cause given a binary observation. We discuss how information-seeking behavior is accounted for by EFE and PRS. Our results highlight the role of prior distribution of future observation in EFE. By setting this prior distribution to be fixed irrespective of which action is selected, the epistemic value can exert an influence on EFE, leading to information-seeking behavior.},
  archive      = {J_JOMP},
  author       = {Kentaro Katahira and Yoshihiko Kunisato and Tsukasa Okimura and Yuichi Yamashita},
  doi          = {10.1016/j.jmp.2020.102347},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102347},
  shortjournal = {J. Math. Psychol.},
  title        = {Retrospective surprise: A computational component for active inference},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the structure of ordered latent trait models.
<em>JOMP</em>, <em>96</em>, 102346. (<a
href="https://doi.org/10.1016/j.jmp.2020.102346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordered item response models that are in common use can be divided into three groups, cumulative, sequential and adjacent categories model . The derivation and motivation of the models is typically based on the assumed presence of latent traits or underlying process models. In the construction frequently binary models play an important role. The objective of this paper is to give motivations for the models and to clarify the role of the binary models for the various types of ordinal models. It is investigated which binary models are included in an ordinal model but also how the models can be constructed from a sequence of binary models. In all the models one finds a Guttman space structure, which has previously been investigated in particular for the partial credit model. The consideration of the binary models adds to the interpretation of model parameters, which is helpful, in particular, in the case of the partial credit model, for which interpretation is less straightforward than for the other models. A specific topic that is addressed is the ordering of thresholds in the partial credit model because for some researchers reversed ordering is an anomaly, others disagree. It is argued that the ordering of thresholds is not a constitutive element of the partial credit model.},
  archive      = {J_JOMP},
  author       = {Gerhard Tutz},
  doi          = {10.1016/j.jmp.2020.102346},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102346},
  shortjournal = {J. Math. Psychol.},
  title        = {On the structure of ordered latent trait models},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State-trace analysis — misrepresented and misunderstood:
Reply to ashby (2019). <em>JOMP</em>, <em>96</em>, 102342. (<a
href="https://doi.org/10.1016/j.jmp.2020.102342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stephens, Matzke, and Hayes (SMH; 2019) used state-trace analysis to re-analyze databases of studies of reasoning and category learning. They found that many behavioral dissociations that had been viewed as support for distinct cognitive processes (or systems) were consistent with the operation of only one latent psychological variable. Ashby (2019) discussed several concerns about the application and interpretation of state-trace analysis in relation to the COVIS dual-systems model of category learning. The current reply addresses these concerns, showing that Ashby’s arguments reflect a misunderstanding of some aspects of state-trace analysis and a misrepresentation of claims made by SMH. We do not claim that state-trace analysis is the final arbiter of competing theories about cognitive systems, and do not assert that it directly assesses model parsimony. Nevertheless, we argue that state-trace analysis is an important advance over existing methods for evaluating claims about unobservable psychological processes based on ordinal data patterns, and is a useful tool as part of theory testing.},
  archive      = {J_JOMP},
  author       = {Rachel G. Stephens and Dora Matzke and Brett K. Hayes},
  doi          = {10.1016/j.jmp.2020.102342},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102342},
  shortjournal = {J. Math. Psychol.},
  title        = {State-trace analysis — misrepresented and misunderstood: Reply to ashby (2019)},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extending RT-MPTs to enable equal process times.
<em>JOMP</em>, <em>96</em>, 102340. (<a
href="https://doi.org/10.1016/j.jmp.2020.102340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The response-time extended multinomial processing tree (RT-MPT; Klauer and Kellen, 2018) model class and its implementation ( rtmpt ; Hartmann et al., in press) in the programming language R enable one to estimate process-completion times and encoding plus motor-execution times along with the process probabilities of traditional multinomial processing tree (MPT) models via an MCMC algorithm in a hierarchical Bayesian framework. This implementation is, however, restricted to RT-MPT models without process repetition in any of the model’s processing paths, implying that models such as the pair-clustering model (Batchelder and Riefer, 1980, 1986) cannot be fitted. Here, we develop a new MCMC algorithm that overcomes this restriction. Furthermore, we validate the algorithm, and demonstrate its usefulness on a dataset from recognition-memory research.},
  archive      = {J_JOMP},
  author       = {Raphael Hartmann and Karl Christoph Klauer},
  doi          = {10.1016/j.jmp.2020.102340},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102340},
  shortjournal = {J. Math. Psychol.},
  title        = {Extending RT-MPTs to enable equal process times},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Perfect prediction in normal form: Superrational thinking
extended to non-symmetric games. <em>JOMP</em>, <em>96</em>, 102332. (<a
href="https://doi.org/10.1016/j.jmp.2020.102332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new solution concept for non-cooperative games in normal form with no ties and pure strategies: the Perfectly Transparent Equilibrium. The players are rational in all possible worlds and know each other’s strategies in all possible worlds — which, together, we refer to as Perfect Prediction. The anticipation of a player’s decision by their opponents is counterfactually dependent on the decision, unlike in Nash Equilibria where the decisions are made independently. The equilibrium, when it exists, is unique and is Pareto optimal . This equilibrium is the normal-form counterpart of the Perfect Prediction Equilibrium; the prediction happens “in another room” rather than in the past. The equilibrium can also be seen as a natural extension of Hofstadter’s superrationality to non-symmetric games. Algorithmically, an iterated elimination of non-individually-rational strategy profiles is performed until at most one remains. An equilibrium is a strategy profile that is immune against knowledge of strategies in all possible worlds and rationality in all possible worlds, a stronger concept than common knowledge of rationality but also stronger than common counterfactual belief of rationality. We formalize and contrast the Non-Nashian Decision Theory paradigm, common to this and several other papers, with Causal Decision Theory and Evidential Decision Theory. We define the Perfectly Transparent Equilibrium algorithmically and prove (when it exists) that it is unique, that it is Pareto-optimal, and that it coincides with Hofstadter’s Superrationality on symmetric games. We relate the finding to concepts found in the literature such as Individual Rationality, Rationalizability, Minimax-Rationalizability, Second-Order Nash Equilibria , the Program Equilibrium, the Perfect Prediction Equilibrium, Shiffrin’s Joint-Selfish-Rational Equilibrium, the Stalnaker–Bonanno Equilibrium, the Perfect Cooperation Equilibrium, the Translucent Equilibrium, the Correlated Equilibrium, and Quantum Games. Finally, we specifically discuss inclusion relationships on the special case of symmetric games between Individual Rationality, Minimax-Rationalizability, Superrationality, and the Perfectly Transparent Equilibrium, and contrast them with asymmetric games.},
  archive      = {J_JOMP},
  author       = {Ghislain Fourny},
  doi          = {10.1016/j.jmp.2020.102332},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102332},
  shortjournal = {J. Math. Psychol.},
  title        = {Perfect prediction in normal form: Superrational thinking extended to non-symmetric games},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Correlated racing evidence accumulator models.
<em>JOMP</em>, <em>96</em>, 102331. (<a
href="https://doi.org/10.1016/j.jmp.2020.102331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many models of response time that base choices on the first evidence accumulator to win a race to threshold rely on statistical independence between accumulators to achieve mathematical tractability (e.g., Brown and Heathcote, 2008; Logan et al., 2014; Van Zandt et al., 2000). However, it is psychologically plausible that trial-to-trial fluctuations can cause both positive correlations (e.g., variability in arousal, attention or response caution that affect accumulators in the same way) and negative correlations (e.g., when evidence for each accumulator is computed relative to a criterion). We examine the effects of such correlations in a racing accumulator model that remains tractable when they are present, the log-normal race (LNR Heathcote and Love, 2012). We first show that correlations are hard to estimate in binary choice data, and that their presence does not noticeably improve model fit to lexical-decision data (Wagenmakers et al., 2008) that is well fit by an independent LNR model. Poor estimation is attributable to the fact that estimation of correlation requires information about the relationship between accumulator states but only the state of the winning accumulator is directly observed in binary choice. We then show that this problem is remedied when discrete confidence judgments are modeled by an extension of Vickers’s (1979) “balance-of-evidence” hypothesis proposed by Reynolds et al. (submitted). In this “multiple-threshold race” model confidence is based on the state of the losing accumulator judged relative to one or more extra thresholds. We show that not only is correlation well estimated in a multiple-threshold log-normal race (MTLNR) model with as few as two confidence levels, but that it also resulted in clearly better fits to Ratcliff et al.’s (1994) recognition memory data than an independent mode. We conclude that the MTLNR provides a mathematically tractable tool that is useful both for investigating correlations between accumulators and for modeling confidence judgments.},
  archive      = {J_JOMP},
  author       = {Angus Reynolds and Peter D. Kvam and Adam F. Osth and Andrew Heathcote},
  doi          = {10.1016/j.jmp.2020.102331},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102331},
  shortjournal = {J. Math. Psychol.},
  title        = {Correlated racing evidence accumulator models},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generalized framework for classical test theory.
<em>JOMP</em>, <em>96</em>, 102330. (<a
href="https://doi.org/10.1016/j.jmp.2020.102330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a generalized framework which allows for the use of parametric classical test theory inference with non-normal models. Using the theory of natural exponential families and Bayesian theory of their conjugate priors , theoretical properties of test scores under the framework are derived, including a formula for parallel-test reliability in terms of the test length and a parameter of the underlying population distribution of abilities. This framework is shown to satisfy the general properties of classical test theory several common classical test theory results are shown to reduce to parallel-test reliability in this framework. An empirical Bayes method for estimating reliability, both with point estimates and with intervals, is described using maximum likelihood. This method is applied to an example set of data and compared to classical test theory estimators of reliability, and a simulation study is performed to show the coverage of the interval estimates of reliability derived from the framework.},
  archive      = {J_JOMP},
  author       = {Robert C. Foster},
  doi          = {10.1016/j.jmp.2020.102330},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102330},
  shortjournal = {J. Math. Psychol.},
  title        = {A generalized framework for classical test theory},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representing probabilistic models of knowledge space theory
by multinomial processing tree models. <em>JOMP</em>, <em>96</em>,
102329. (<a href="https://doi.org/10.1016/j.jmp.2020.102329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Space Theory (KST) aims at modeling the hierarchical relations between items or skills in a learning process. For example, when studying mathematics in school, students first need to master the rules of summation before being able to learn multiplication. In KST, the knowledge states of individuals are represented by means of partially ordered latent classes. In probabilistic KST models, conditional probability parameters are introduced to model transitions from latent knowledge states to observed response patterns. Since these models account for discrete data by assuming a finite number of latent states, they can be represented by Multinomial Processing Tree (MPT) models (i.e., binary decision trees with parameters referring to the conditional probabilities of entering different states). We prove that standard probabilistic models of KST such as the Basic Local Independence Model (BLIM) and the Simple Learning Model (SLM) can be represented as specific instances of MPT models. Given this close link, MPT methods may be applied to address theoretical and practical issues in KST. By highlighting the MPT–KST link and its implications for modeling violations of local stochastic independence in Item Response Theory (IRT), we hope to facilitate an exchange of theoretical results, statistical methods, and software across these different domains of mathematical psychology and psychometrics .},
  archive      = {J_JOMP},
  author       = {Daniel W. Heck and Stefano Noventa},
  doi          = {10.1016/j.jmp.2020.102329},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102329},
  shortjournal = {J. Math. Psychol.},
  title        = {Representing probabilistic models of knowledge space theory by multinomial processing tree models},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An application of multinomial processing tree models and
bayesian methods to understanding memory impairment. <em>JOMP</em>,
<em>95</em>, 102328. (<a
href="https://doi.org/10.1016/j.jmp.2020.102328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model word-list learning over sequences of immediate and delayed free recall tasks to study the impact of memory impairment on episodic memory . We use a previously developed Multinomial Processing Tree (MPT) model of encoding, retrieval, and learning (Alexander et al., 2016), and apply it to behavioral data from thousands of patients tested tens of thousands of times in a cognitive disorders clinic. The patients were independently diagnosed, using the Functional Assessment Staging Test (FAST), into six stages of impairment. We apply hierarchical and latent-mixture versions of the MPT model to patients in each FAST stage, exploring individual differences among people and item-position effects across the word lists. Our results show clear and theoretically interpretable regularities in how model parameters change over item positions, corresponding to standard primacy and recency effects in free recall. Accordingly, we develop an extended model that directly incorporates theoretical assumptions about serial position. Inferences from this model allow us to reach conclusions about how learning, encoding, and retrieval processes change as memory impairment progresses.},
  archive      = {J_JOMP},
  author       = {Michael D. Lee and Jason R. Bock and Isaiah Cushman and William R. Shankle},
  doi          = {10.1016/j.jmp.2020.102328},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102328},
  shortjournal = {J. Math. Psychol.},
  title        = {An application of multinomial processing tree models and bayesian methods to understanding memory impairment},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An item response theory model of matching test performance.
<em>JOMP</em>, <em>95</em>, 102327. (<a
href="https://doi.org/10.1016/j.jmp.2020.102327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a matching test, a test taker is presented with a list of test items and a list of response alternatives and asked to match each response alternative with a test item. The response alternatives can be given as a response to at most one test item. As a result, the response a test taker offers to one test item depends on his or her responses to all of the other test items. This violates the “local independence” assumption underlying most existing item response theory (IRT) methods, such as the Rasch model . Here we develop a framework for extending dichotomous IRT models to account for test taking behavior on matching tests. This model separates an individual’s knowledge of the correct responses to the items of a matching test from his or her responses to those items. In addition to developing the matching framework, we derive a number of important properties, including its item response function and score distribution. Finally, we demonstrate through an empirical example that our matching test framework provides a good account of behavior on matching tests.},
  archive      = {J_JOMP},
  author       = {Matthew D. Zeigenfuse and William H. Batchelder and Mark Steyvers},
  doi          = {10.1016/j.jmp.2020.102327},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102327},
  shortjournal = {J. Math. Psychol.},
  title        = {An item response theory model of matching test performance},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequential hypothesis tests for multinomial processing tree
models. <em>JOMP</em>, <em>95</em>, 102326. (<a
href="https://doi.org/10.1016/j.jmp.2020.102326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stimulated by William H. Batchelder’s seminal contributions in the 1980s and 1990s, multinomial processing tree (MPT) modeling has become a powerful and frequently used method in various research fields, most prominently in cognitive psychology and social cognition research. MPT models allow for estimation of, and statistical tests on, parameters that represent psychological processes underlying responses to cognitive tasks. Therefore, their use has also been proposed repeatedly for purposes of psychological assessment, for example, in clinical settings to identify specific cognitive deficits in individuals. However, a considerable drawback of individual MPT analyses emerges from the limited number of data points per individual, resulting in estimation bias, large standard errors, and low power of statistical tests. Classical test procedures such as Neyman–Pearson tests often require very large sample sizes to ensure sufficiently low Type 1 and Type 2 error probabilities . Herein, we propose sequential probability ratio tests (SPRTs) as an efficient alternative. Unlike Neyman–Pearson tests, sequential tests continuously monitor the data and terminate when a predefined criterion is met. As a consequence, SPRTs typically require only about half of the Neyman–Pearson sample size without compromising error probability control. We illustrate the SPRT approach to statistical inference for simple hypotheses in single-parameter MPT models. Moreover, a large-sample approximation, based on ML theory , is presented for typical MPT models with more than one unknown parameter. We evaluate the properties of the proposed test procedures by means of simulations. Finally, we discuss benefits and limitations of sequential MPT analysis.},
  archive      = {J_JOMP},
  author       = {Martin Schnuerch and Edgar Erdfelder and Daniel W. Heck},
  doi          = {10.1016/j.jmp.2020.102326},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102326},
  shortjournal = {J. Math. Psychol.},
  title        = {Sequential hypothesis tests for multinomial processing tree models},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Testing the race model in a difficult redundant signals
task. <em>JOMP</em>, <em>95</em>, 102323. (<a
href="https://doi.org/10.1016/j.jmp.2020.102323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the redundant signals task, participants respond, in the same way, to stimuli of several sources, which are presented either alone or in combination (redundant signals). The responses to the redundant signals are typically much faster than to the single signals. Several models explain this effect, including race and coactivation models of information processing . Race models assume separate channels for the two components of a redundant signal, with the response time determined by the faster of the two channels. Because the slower processing times in one channel are canceled out by faster processing in the other channel, responses to redundant signals are, on average, faster than to single signals. In contrast, coactivation models relate the redundancy gain to some kind of integrated processing of the redundant information. The two models can be distinguished using the race model inequality (Miller, 1982) on the response time distribution functions. Miller’s prediction was derived for experiments with 100\% accuracy, and despite corrections for guesses and omitted responses, it is limited to easy tasks with negligible error rates. In this article we generalize Miller’s inequality to non-trivial experimental tasks in which incorrect responses may occur systematically. The method is illustrated using data from difficult discrimination tasks with Go/Nogo and choice responses.},
  archive      = {J_JOMP},
  author       = {Matthias Gondan and Dawa Dupont and Steven P. Blurton},
  doi          = {10.1016/j.jmp.2020.102323},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102323},
  shortjournal = {J. Math. Psychol.},
  title        = {Testing the race model in a difficult redundant signals task},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New handbook of mathematical psychology: Volume i:
Foundations and methodology; volume II: Modeling and measurement
(cambridge handbooks in psychology), batchelder william h., colonius
hans, dzhafarov ehtibar n., myung jay (eds.) (2016–2018). <em>JOMP</em>,
<em>95</em>, 102322. (<a
href="https://doi.org/10.1016/j.jmp.2020.102322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOMP},
  author       = {Reinhard Suck},
  doi          = {10.1016/j.jmp.2020.102322},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102322},
  shortjournal = {J. Math. Psychol.},
  title        = {New handbook of mathematical psychology: volume i: foundations and methodology; volume II: modeling and measurement (Cambridge handbooks in psychology), batchelder william h., colonius hans, dzhafarov ehtibar n., myung jay (Eds.) (2016–2018)},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BLIM’s identifiability and parameter invariance under
backward and forward transformations. <em>JOMP</em>, <em>95</em>,
102314. (<a href="https://doi.org/10.1016/j.jmp.2019.102314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The basic local independence model (BLIM) is one of the most widely applied probabilistic models in knowledge space theory. It is known that the BLIM is not identifiable in general and that its identifiability strictly depends on the properties of the knowledge structure to which it is applied. If the knowledge structure is either forward- or backward-graded in one or more items, then the BLIM is not identifiable. In such cases, there exist continuous transformations of the model’s parameters, named forward and backward transformations, that keep constant the value of the model’s prediction function. Under certain constraints on the model’s parameters, some of the transformations might lose this property. The type of constraints considered in this article consist of fixing the probability of a knowledge state to a constant value. The theoretical results contained in the article shed light on the role of the different state probabilities in reducing the collection of transformations and thus restoring the identifiability of the model’s parameters.},
  archive      = {J_JOMP},
  author       = {Luca Stefanutti and Andrea Spoto},
  doi          = {10.1016/j.jmp.2019.102314},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102314},
  shortjournal = {J. Math. Psychol.},
  title        = {BLIM’s identifiability and parameter invariance under backward and forward transformations},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian parameter estimation for the SWIFT model of
eye-movement control during reading. <em>JOMP</em>, <em>95</em>, 102313.
(<a href="https://doi.org/10.1016/j.jmp.2019.102313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process-oriented theories of cognition must be evaluated against time-ordered observations. Here we present a representative example for data assimilation of the SWIFT model, a dynamical model of the control of fixation positions and fixation durations during natural reading of single sentences. First, we develop and test an approximate likelihood function of the model, which is a combination of a spatial, pseudo-marginal likelihood and a temporal likelihood obtained by probability density approximation Second, we implement a Bayesian approach to parameter inference using an adaptive Markov chain Monte Carlo procedure. Our results indicate that model parameters can be estimated reliably for individual subjects. We conclude that approximative Bayesian inference represents a considerable step forward for computational models of eye-movement control, where modeling of individual data on the basis of process-based dynamic models has not been possible so far.},
  archive      = {J_JOMP},
  author       = {Stefan A. Seelig and Maximilian M. Rabe and Noa Malem-Shinitski and Sarah Risse and Sebastian Reich and Ralf Engbert},
  doi          = {10.1016/j.jmp.2019.102313},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102313},
  shortjournal = {J. Math. Psychol.},
  title        = {Bayesian parameter estimation for the SWIFT model of eye-movement control during reading},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On complementary symmetry under cumulative prospect theory.
<em>JOMP</em>, <em>95</em>, 102312. (<a
href="https://doi.org/10.1016/j.jmp.2019.102312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary symmetry has been proved to be fulfilled in Cumulative Prospect Theory with random reference, regardless of the form of the utility function. Furthermore an alternative model, in which complementary symmetry generally does not hold, is discussed.},
  archive      = {J_JOMP},
  author       = {J. Chudziak},
  doi          = {10.1016/j.jmp.2019.102312},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102312},
  shortjournal = {J. Math. Psychol.},
  title        = {On complementary symmetry under cumulative prospect theory},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixtures of peaked power batschelet distributions for
circular data with application to saccade directions. <em>JOMP</em>,
<em>95</em>, 102309. (<a
href="https://doi.org/10.1016/j.jmp.2019.102309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular data are encountered throughout a variety of scientific disciplines, such as in eye movement research as the direction of saccades. Motivated by such applications, mixtures of peaked circular distributions are developed. The peaked distributions are a novel family of Batschelet-type distributions, where the shape of the distribution is warped by means of a transformation function. Because the Inverse Batschelet distribution features an implicit inverse that is not computationally feasible for large or complex data, an alternative called the Power Batschelet distribution is introduced. This distribution is easy to compute and mimics the behavior of the Inverse Batschelet distribution. Inference is performed in both the frequentist framework, through Expectation–Maximization (EM) and the bootstrap , and the Bayesian framework, through MCMC. All parameters can be fixed, which may be done by assumption to reduce the number of parameters. Model comparison can be performed through information criteria or through bridge sampling in the Bayesian framework, which allows performing a wealth of hypothesis tests through the Bayes factor . An R package, flexcircmix , is available to perform these analyses.},
  archive      = {J_JOMP},
  author       = {Kees Mulder and Irene Klugkist and Daan van Renswoude and Ingmar Visser},
  doi          = {10.1016/j.jmp.2019.102309},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102309},
  shortjournal = {J. Math. Psychol.},
  title        = {Mixtures of peaked power batschelet distributions for circular data with application to saccade directions},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calibrating generative models: The probabilistic
chomsky–schützenberger hierarchy. <em>JOMP</em>, <em>95</em>, 102308.
(<a href="https://doi.org/10.1016/j.jmp.2019.102308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A probabilistic Chomsky–Schützenberger hierarchy of grammars is introduced and studied, with the aim of understanding the expressive power of generative models. We offer characterizations of the distributions definable at each level of the hierarchy, including probabilistic regular, context-free, (linear) indexed, context-sensitive, and unrestricted grammars, each corresponding to familiar probabilistic machine classes. Special attention is given to distributions on (unary notations for) positive integers. Unlike in the classical case where the ”semi-linear” languages all collapse into the regular languages, using analytic tools adapted from the classical setting we show there is no collapse in the probabilistic hierarchy: more distributions become definable at each level. We also address related issues such as closure under probabilistic conditioning.},
  archive      = {J_JOMP},
  author       = {Thomas F. Icard},
  doi          = {10.1016/j.jmp.2019.102308},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102308},
  shortjournal = {J. Math. Psychol.},
  title        = {Calibrating generative models: The probabilistic Chomsky–Schützenberger hierarchy},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic exploration of temporal bisection models across
sub- and supra-second duration ranges. <em>JOMP</em>, <em>94</em>,
102311. (<a href="https://doi.org/10.1016/j.jmp.2019.102311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An integral component to the validity of timing models is their ability to accurately fit behavioral data from detection and discrimination tasks such as the temporal bisection procedure. Two of the most prominent timing models are the Sample Known Exactly (SKE), based on scalar timing theory, and the pseudo-logistic model (PLM). Recently, evidence accumulation models based on drift–diffusionprocesses (DDM) have been utilized for modeling temporal bisection data. Currently, there is no standard by which timing behavioral data are fit, resulting in the implementation of both theoretical and atheoretical models, such as generalized logistic functions (L4P). As differences in timing behavior have been shown across sub- and supra-second durations, a comparative evaluation of these 4 different types of models (SKE, PLM, L4P, and DDM) was conducted to assess each model’s ability to capture these differences using timing data from the temporal bisection procedure. Psychometric functions from rats, trained on a bisection task using sub-sec (200 ms vs. 800 ms.) and supra-sec (2 s vs. 8 s) conditions, were fit with each of the four models. Using Akaike Information Criterion (AIC) we demonstrate that theoretical models vastly outperformed the L4P across both duration ranges, Furthermore, significant differences existed in key parameters between L4P and PLM. Three DDM models were analyzed with varying degrees of freedom, which showed that allowing for non-decision time, drift rate, and starting point to vary across signal durations outperform simpler models ( Δ i Δi ≥ ≥ 10) that only allowed for variation in drift rate or drift rate and starting point. These models explained variance in both choice and reaction time data. While we were unable to directly compare timing and temporal decision models the results from both demonstrate the need for a shift toward theoretically based models such as the SKE, PLM, or DDM which provide greater parsimony as well as provide for greater qualitative analysis and interpretation of the data.},
  archive      = {J_JOMP},
  author       = {Nicholas A. Lusk and Elijah A. Petter and Warren H. Meck},
  doi          = {10.1016/j.jmp.2019.102311},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102311},
  shortjournal = {J. Math. Psychol.},
  title        = {A systematic exploration of temporal bisection models across sub- and supra-second duration ranges},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inhibited elements model — implementation of an associative
learning theory. <em>JOMP</em>, <em>94</em>, 102310. (<a
href="https://doi.org/10.1016/j.jmp.2019.102310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Inhibited Elements Model (IEM) is an associative learning theory with an elemental stimulus representation and normalised amount of activation. At present, an evaluation of the model has been difficult as the IEM was originally described and specified only for one learning task (biconditional discriminations) and later discussions also concerned only selected learning problems and stimulus configurations. The main aim of the current paper is to derive a complete mathematical description of the IEM, including crucially a mathematical solution for the extrapolation of the stimulus representation of the IEM for any given stimulus configuration. Exemplary simulations support the adequateness of the implementation within the Associative Learning Simulator (ALTSim) both for replicating existing predictions of the model as well as for generating new ones.},
  archive      = {J_JOMP},
  author       = {Anna Thorwart and Harald Lachnit},
  doi          = {10.1016/j.jmp.2019.102310},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102310},
  shortjournal = {J. Math. Psychol.},
  title        = {Inhibited elements model — implementation of an associative learning theory},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The hitchhiker’s guide to nonlinear filtering.
<em>JOMP</em>, <em>94</em>, 102307. (<a
href="https://doi.org/10.1016/j.jmp.2019.102307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear filtering is used in online estimation of a dynamic hidden variable from incoming data and has vast applications in different fields, ranging from engineering, machine learning, economic science and natural sciences. We start our review of the theory on nonlinear filtering from the simplest ‘filtering’ task we can think of, namely static Bayesian inference . From there we continue our journey through discrete-time models, which are usually encountered in machine learning, and generalize to continuous-time filtering theory. The idea of changing the probability measure connects and elucidates several aspects of the theory, such as the parallels between the discrete- and continuous-time problems and between different observation models. Furthermore, it provides insight into the construction of particle filtering algorithms. This tutorial is targeted at scientists and engineers and should serve as an introduction to the main ideas of nonlinear filtering, and as a segway to more advanced and specialized literature.},
  archive      = {J_JOMP},
  author       = {Anna Kutschireiter and Simone Carlo Surace and Jean-Pascal Pfister},
  doi          = {10.1016/j.jmp.2019.102307},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102307},
  shortjournal = {J. Math. Psychol.},
  title        = {The hitchhiker’s guide to nonlinear filtering},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the polytomous generalization of knowledge space theory.
<em>JOMP</em>, <em>94</em>, 102306. (<a
href="https://doi.org/10.1016/j.jmp.2019.102306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the core assumptions of knowledge space theory (KST) is that the answer of a subject to an item can be dichotomously classified as correct or incorrect. Schrepp (1997) provided a very first attempt to generalize the main KST concepts to items with more than two response alternatives, but his work has not had a strong impact on the subsequent research on KST. The aim of the present article is to introduce a new formulation of the polytomous KST, starting from the work of Schrepp and broadening it to a wider extent. Schrepp’s generalization is revisited, and the fundamental closure conditions are reformulated and decomposed into a necessary and sufficient set of four independent properties of polytomous knowledge structures. Among them, two special properties emerge in the polytomous case that in the dichotomous one are neither testable nor immediately visible, since necessarily true. These properties allow for a straight generalization of Birkhoff’s Theorem with respect to quasi-ordinal knowledge spaces, and Doignon and Falmagne’s Theorem for knowledge spaces. Such findings open the field to a systematic generalization of many KST concepts to the polytomous case.},
  archive      = {J_JOMP},
  author       = {Luca Stefanutti and Pasquale Anselmi and Debora de Chiusole and Andrea Spoto},
  doi          = {10.1016/j.jmp.2019.102306},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102306},
  shortjournal = {J. Math. Psychol.},
  title        = {On the polytomous generalization of knowledge space theory},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of magnitude-sensitive sequential sampling models
in a simulation-based study. <em>JOMP</em>, <em>94</em>, 102298. (<a
href="https://doi.org/10.1016/j.jmp.2019.102298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling plays a key role in explaining data in psychology and neuroscience and helps elucidate neural computations . Recent observations of magnitude-sensitivity (i.e. sensitivity to overall magnitudes and magnitude differences) in both humans engaged in perceptual decision making and monkeys engaged in value-based decisions have shown that new assumptions (such as the inclusion of noise that is proportional to magnitudes of external stimuli) in routinely-used sequential sampling models need to be considered to fit this type of magnitude-sensitive data. In this paper, we studied different variants of diffusion-type models and a leaky-competing accumulator model, and compared their behaviour in response to varying input magnitudes as well as their ability to resemble each other. We evaluated the extent to which these models can give good fits to simulated reaction time distributions for choices between unequal and equal alternatives. As a result, in some cases we obtained good fits of model and data, even when the underlying model used for data generation was different compared to the model used to fit these data. Our results underpin the importance of both overall magnitude and magnitude difference effects in models describing the sequential integration of evidence, and contribute to the debate over possible model candidate explanations. We discuss how magnitude-dependent input noise and lateral inhibition may be used to regulate different magnitude-sensitive effects and the implications for quantitative analyses of experimental data .},
  archive      = {J_JOMP},
  author       = {Thomas Bose and Angelo Pirrone and Andreagiovanni Reina and James A.R. Marshall},
  doi          = {10.1016/j.jmp.2019.102298},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102298},
  shortjournal = {J. Math. Psychol.},
  title        = {Comparison of magnitude-sensitive sequential sampling models in a simulation-based study},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regression methods for metacognitive sensitivity.
<em>JOMP</em>, <em>94</em>, 102297. (<a
href="https://doi.org/10.1016/j.jmp.2019.102297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metacognition is an important component in basic science and clinical psychology , often studied through complex, cognitive experiments. While Signal Detection Theory (SDT) provides a popular and pervasive framework for modelling responses from such experiments, a shortfall remains that it cannot in a straightforward manner account for the often complex designs. Additionally, SDT does not provide direct estimates of metacognitive ability. This latter shortcoming has recently been sought remedied by introduction of a measure for metacognitive sensitivity dubbed meta- d ′ d′ . The new sensitivity measure , however, further accentuates the need for a flexible modelling framework. In the present paper, we argue that a straightforward extension of SDT is obtained by identifying the model with the proportional odds model, a widely implemented, ordinal regression technique. We go on to develop a formal statistical framework for metacognitive sensitivity by defining a model that combines standard SDT with meta- d ′ d′ in a latent variable model . We show how this agrees with the literature on meta- d ′ d′ and constitutes a practical framework for extending the model. We supply several theoretical considerations on the model, including closed-form approximate estimates of meta- d ′ d′ and optimal weighing of response-specific meta-sensitivities. We discuss regression analysis as an application of the obtained model and illustrate our points through simulations. Lastly, we discuss a software implementation of the model in R . Our methods and their implementation extend the computational possibilities of SDT and meta- d ′ d′ and are useful for theoretical and practical researchers of metacognition.},
  archive      = {J_JOMP},
  author       = {Simon Bang Kristensen and Kristian Sandberg and Bo Martin Bibby},
  doi          = {10.1016/j.jmp.2019.102297},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102297},
  shortjournal = {J. Math. Psychol.},
  title        = {Regression methods for metacognitive sensitivity},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algebraic aspects of bayesian modeling in psychology.
<em>JOMP</em>, <em>94</em>, 102296. (<a
href="https://doi.org/10.1016/j.jmp.2019.102296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several Bayesian models in perceptual and cognitive psychology show a complex organization that is only partly captured by referring to Bayes rule and the associated concepts of prior, likelihood, and posterior distributions . In this article, an algebraic framework is constructed that may serve as a guide for representing and analyzing the internal organization of these models. The construction begins by defining a comprehensive class of probabilistic structures, called probability kernels, and by focusing on three basic operations on them, called projection, conditioning, and promotion. The expressive power of these operations is then illustrated by showing how suitable combinations of them cover typical moves of Bayesian computations, such as mixing or inducing probability distributions, marginalizing likelihood functions, and Bayes rule itself. As a central finding, we show that a suitable combination of the basic operations gives rise to a binary relation that organizes any complete set of probability kernels as a lattice , and we highlight the peculiarities of this algebraic structure . Lastly, we illustrate the analytic use of the proposed framework by applying it to two Bayesian models from the literature, one concerning spatial vision and the other concerning category representation.},
  archive      = {J_JOMP},
  author       = {Luigi Burigana and Michele Vicovaro},
  doi          = {10.1016/j.jmp.2019.102296},
  journal      = {Journal of Mathematical Psychology},
  pages        = {102296},
  shortjournal = {J. Math. Psychol.},
  title        = {Algebraic aspects of bayesian modeling in psychology},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
