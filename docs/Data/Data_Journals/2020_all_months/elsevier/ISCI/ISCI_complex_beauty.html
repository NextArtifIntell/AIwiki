<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci---929">ISCI - 929</h2>
<ul>
<li><details>
<summary>
(2020a). Group decision making based on acceptable multiplicative
consistency and consensus of hesitant fuzzy linguistic preference
relations. <em>ISCI</em>, <em>541</em>, 531–550. (<a
href="https://doi.org/10.1016/j.ins.2020.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new group decision making (GDM) method based on the acceptable multiplicative consistency and consensus of hesitant fuzzy linguistic preference relations (HFLPRs). First, an approach for improving the consistency of HFLPRs is proposed to generate an acceptable multiplicative consistent HFLPR. Then, a consensus index of HFLPRs is defined and an optimization model is presented to meet an acceptable consensus requirement under the premise of the acceptable multiplicative consistency and the smallest information loss, where it yields adjusted HFLPRs with an acceptable consistency and consensus. Then, the weights of decision makers (DMs) are calculated based on the obtained adjusted HFLPRs. Moreover, we propose a new GDM method based on HFLPRs. Finally, the proposed GDM method is illustrated by an application example and comparative analyses are conducted to show the performance and the superiority of the proposed GDM method.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.07.024},
  journal      = {Information Sciences},
  pages        = {531-550},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on acceptable multiplicative consistency and consensus of hesitant fuzzy linguistic preference relations},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three completely independent spanning trees of crossed cubes
with application to secure-protection routing. <em>ISCI</em>,
<em>541</em>, 516–530. (<a
href="https://doi.org/10.1016/j.ins.2020.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kwong et al. (2011) proposed a reactive routing scheme using the multi-paths technique for integrating two mechanisms of route discovery and route maintenance in intra-domain IP networks. They further defined a route to be a protection routing if there is a loop-free alternate path for packet forwarding when a single failed component (including link or node) occurs. Later on, Tapolcai (2013) showed that a network possessing two completely independent spanning trees (CISTs for short) suffices to configure a protection routing. A set of k ( ⩾ 2 ) k(⩾2) spanning trees in a network is called CISTs if they are pairwise edge-disjoint and inner-node-disjoint. Particularly, if k = 2 k=2 , such a set of CISTs is called a dual-CIST. In the early stage, Hasunuma (2002) already pointed out that the problem of determining whether there exists a dual-CIST in a graph is NP-complete. In this paper, we investigate how to construct CISTs in a kind of hypercube-variant networks, called crossed cubes, and obtain the following results:},
  archive      = {J_ISCI},
  author       = {Kung-Jui Pai and Ruay-Shiung Chang and Ro-Yu Wu and Jou-Ming Chang},
  doi          = {10.1016/j.ins.2020.05.048},
  journal      = {Information Sciences},
  pages        = {516-530},
  shortjournal = {Inf. Sci.},
  title        = {Three completely independent spanning trees of crossed cubes with application to secure-protection routing},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-learning based medical image representation for rigid
real-time and multimodal slice-to-volume registration. <em>ISCI</em>,
<em>541</em>, 502–515. (<a
href="https://doi.org/10.1016/j.ins.2020.06.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the convolutional neural network (CNN) based real-time slice-to-volume registration methods show great potential in related clinical applications. Generally, these methods are mostly employed in monomodal scenarios because they essentially rely on image intensities. To extend this strategy in more general computer-aided surgery scenarios, we present a self-learning based multimodal image representation model for real-time and multimodal slice-to-volume registration. Different from usual approaches, which utilize structural descriptors or translate the image from one modality to another, the proposed method exploits the highly similar information embedded in multimodal images through the two-channel self-learning strategy based on the CNN. In this way, a universal image representation network for any modality can be achieved. Specifically, different multimodal image pairs can be simultaneously fed into two shared-weight channels in the training phase. The self-learning strategy is concretely implemented by making the paired outputs similar and retaining the edge information of the originals. Subsequently, the image representation of any modality can be realized through one channel. Experiments on different datasets have been conducted to evaluate the proposed method, demonstrating its significant advantage in providing multimodal representation for real-time and multimodal slice-to-volume registration; moreover, it is observed to be superior to the state-of-the-art representation methods.},
  archive      = {J_ISCI},
  author       = {Zixuan Chen and Zekai Xu and Qiuling Gui and Xin Yang and Qimin Cheng and Wenguang Hou and Mingyue Ding},
  doi          = {10.1016/j.ins.2020.06.072},
  journal      = {Information Sciences},
  pages        = {502-515},
  shortjournal = {Inf. Sci.},
  title        = {Self-learning based medical image representation for rigid real-time and multimodal slice-to-volume registration},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental approaches for heterogeneous feature selection
in dynamic ordered data. <em>ISCI</em>, <em>541</em>, 475–501. (<a
href="https://doi.org/10.1016/j.ins.2020.06.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection can identify essential features and reduce the dimensionality of features, improving the classification ability of a learning model. In this study, we consider data with a preference-order relation, i.e., ordered data. In the big data era, ordered data contain noise and exhibit heterogeneous features (including numerical and categorical features) and dynamic characteristics (i.e., new objects are added and obsolete objects are removed with evolving time). The dominance-based neighborhood rough set (DNRS) considers the preference order relation of heterogeneous features and demonstrates fault tolerance ; thus, it can be applied well to heterogeneous feature selection in ordered data. At present, DNRS-based heterogeneous feature selection methods are only used for static ordered data. For dynamic ordered data, existing heterogeneous feature selection approaches are highly time-consuming because they are required to recalculate knowledge from scratch when multiple objects vary. Motivated by this issue, we utilize a matrix-based method in this work to study incremental heterogeneous feature selection based on DNRS in dynamic ordered data. First, we define neighborhood dominance conditional entropy (NDCE) as the uncertainty measure and introduce a non-monotonic feature selection strategy based on this measure. Second, the neighborhood dominance relation matrix and its diagonal matrix are defined to calculate NDCE in matrix form. Third, the updating mechanisms of the diagonal matrix are studied when objects vary and used to update NDCE. Lastly, two incremental feature selection algorithms are proposed when multiple objects are added to or deleted from heterogeneous ordered data. Experiments are performed on public data sets. Experimental results verify that the proposed incremental algorithms are effective and efficient for updating feature subsets in dynamic heterogeneous ordered data.},
  archive      = {J_ISCI},
  author       = {Binbin Sang and Hongmei Chen and Tianrui Li and Weihua Xu and Hong Yu},
  doi          = {10.1016/j.ins.2020.06.051},
  journal      = {Information Sciences},
  pages        = {475-501},
  shortjournal = {Inf. Sci.},
  title        = {Incremental approaches for heterogeneous feature selection in dynamic ordered data},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-scale decomposition-based multifocus image fusion
framework combined with image morphology and fuzzy set theory.
<em>ISCI</em>, <em>541</em>, 442–474. (<a
href="https://doi.org/10.1016/j.ins.2020.06.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image fusion method can provide a high-quality image by merging the multiple features of different source images, and how to effectively evaluate the quality (informativeness) of image features is an important issue for image fusion. Because a considerable amount of imprecise and uncertain information exists in image fusion processes, this paper proposes a framework based on fuzzy set theory to handle the vague features, and a set of hybrid optimization methods is also designed to improve the performance. First, the two-scale decomposition method is utilized to decompose the source images and obtain a set of corresponding subimages . Second, fuzzy set theory and local spatial frequency are employed to generate preliminary decision maps by evaluating the pixel quality of the subimages . Third, a morphological method and consistency verification are utilized to optimize the decision maps to extract the focused and unfocused regions. Finally, three schemes are designed to generate the fused images according to the optimized decision maps. The experimental results show that the proposed method can achieve competitive performance compared with other methods.},
  archive      = {J_ISCI},
  author       = {Qian Jiang and Xin Jin and Gao Chen and Shin-Jye Lee and Xiaohui Cui and Shaowen Yao and Liwen Wu},
  doi          = {10.1016/j.ins.2020.06.053},
  journal      = {Information Sciences},
  pages        = {442-474},
  shortjournal = {Inf. Sci.},
  title        = {Two-scale decomposition-based multifocus image fusion framework combined with image morphology and fuzzy set theory},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial learning of sentiment word representations for
sentiment analysis. <em>ISCI</em>, <em>541</em>, 426–441. (<a
href="https://doi.org/10.1016/j.ins.2020.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word embeddings are used to represent words as distributed features, which can boost the performance on sentiment analysis tasks. However, most word embeddings consider only semantic and syntactic information and ignore sentiment information. Words with opposite sentiment polarities can have similar word embeddings (e.g., happy and sad or good and bad ) as they have similar contexts. For incorporating sentiment information into word vectors, some approaches to sentiment embeddings are proposed. Based on the end-to-end architectures, these methods typically take the sentiment labels of whole sentences as outputs and use them to propagate gradients that update the context word vectors. Therefore, if the polarities of context words are inconsistent, they will still share the same gradient for updating. To address this, we have proposed an adversarial learning method for training sentiment word embeddings, in which the discriminator is employed to force the generator to produce high-quality word embeddings by using semantic and sentiment information. Additionally, the generator applies the multi-head self-attention to re-weight the gradients so that sentiment and semantic information are efficiently captured. Comparative experiments have been conducted with the word- and sentence-level benchmarks. The results demonstrate that the proposed method has outperformed previous sentiment embedding training models.},
  archive      = {J_ISCI},
  author       = {Bo Peng and Jin Wang and Xuejie Zhang},
  doi          = {10.1016/j.ins.2020.06.044},
  journal      = {Information Sciences},
  pages        = {426-441},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial learning of sentiment word representations for sentiment analysis},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain-based public auditing and secure deduplication
with fair arbitration. <em>ISCI</em>, <em>541</em>, 409–425. (<a
href="https://doi.org/10.1016/j.ins.2020.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data auditing enables data owners to verify the integrity of their sensitive data stored at an untrusted cloud without retrieving them. This feature has been widely adopted by commercial cloud storage . However, the existing approaches still have some drawbacks. On the one hand, the existing schemes have a defect of fair arbitration, i.e., existing auditing schemes lack an effective method to punish the malicious cloud service provider (CSP) and compensate users whose data integrity is destroyed. On the other hand, a CSP may store redundant and repetitive data . These redundant data inevitably increase management overhead and computational cost during the whole data life cycle . To address these challenges, we propose a blockchain-based public auditing and secure deduplication scheme with fair arbitration. By using a smart contract , our scheme supports automatic penalization of the malicious CSP and compensates users whose data integrity is damaged. Moreover, our scheme introduces a message-locked encryption algorithm and removes the random masking in data auditing. Compared with the existing schemes, our scheme can effectively reduce the computational cost of tag verification and data storage costs. We give a comprehensive analysis to demonstrate the correctness of the proposed scheme in terms of storage, batch auditing, and data consistency. Also, extensive experiments conducted on the platform of Ethereum blockchain demonstrate the efficiency and effectiveness of our scheme.},
  archive      = {J_ISCI},
  author       = {Haoran Yuan and Xiaofeng Chen and Jianfeng Wang and Jiaming Yuan and Hongyang Yan and Willy Susilo},
  doi          = {10.1016/j.ins.2020.07.005},
  journal      = {Information Sciences},
  pages        = {409-425},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based public auditing and secure deduplication with fair arbitration},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new transfer learning-based method for label proportions
problem. <em>ISCI</em>, <em>541</em>, 391–408. (<a
href="https://doi.org/10.1016/j.ins.2020.05.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with label proportions (LLP), which only provides the unlabeled instances in the bag and the bag’s label proportion, has been widely studied recently. However, most of the existing LLP methods do not consider the knowledge transfer from the source task to the target task. In addition, in the process of the collecting data, the data may be corrupted by noise, and this always leads to the uncertain data in its representation. This paper proposes a new transfer learning-based approach for the problem of learning with label proportions, which is called TL-LLP in brief, to transfer knowledge from the source task to the target task where both the source and target tasks contain uncertain data. We first formulate the objective model to deal with transfer learning and uncertain data for the label proportions problem at the same time. We then propose an iterative framework to solve the proposed objective model and obtain the accurate classifier for the target task. Extensive experiments have shown that the proposed TL-LLP method can obtain better performance and is less sensitive to noise compared with the existing LLP methods.},
  archive      = {J_ISCI},
  author       = {Yanshan Xiao and HuaiPei Wang and Bo Liu},
  doi          = {10.1016/j.ins.2020.05.104},
  journal      = {Information Sciences},
  pages        = {391-408},
  shortjournal = {Inf. Sci.},
  title        = {A new transfer learning-based method for label proportions problem},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel decision-making approach based on three-way
decisions in fuzzy information systems. <em>ISCI</em>, <em>541</em>,
362–390. (<a href="https://doi.org/10.1016/j.ins.2020.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision-making theory with three-way decisions (3WD) improves the either-or decision results of the traditional multi-criteria decision-making (MCDM) methods and provides a more reasonable decision basis. This paper presents a novel 3WD method to solve MCDM problems in fuzzy information systems. Considering the usefulness of fuzzy neighborhood operators when dealing with fuzzy numerical data, we define a reflexive fuzzy α α -neighborhood operator for overcoming the weaknesses of the existing fuzzy β β -neighborhood operators in some applications. A probabilistic rough fuzzy set model and MCDM-based 3WD model are established by means of the constructed fuzzy ε ε -neighborhood classes. We give a determination method of the conditional probability according to data tables of MCDM problems. Particularly, the steps and algorithm of 3WD method are proposed. Then the feasibility and validity of the method are illustrated by the validity test and the comparative analysis on an example of project investments. Finally, we demonstrate the stability of the method through the experimental analysis on different data sets.},
  archive      = {J_ISCI},
  author       = {Jin Ye and Jianming Zhan and Zeshui Xu},
  doi          = {10.1016/j.ins.2020.06.050},
  journal      = {Information Sciences},
  pages        = {362-390},
  shortjournal = {Inf. Sci.},
  title        = {A novel decision-making approach based on three-way decisions in fuzzy information systems},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary algorithm with multiobjective optimization
technique for solving nonlinear equation systems. <em>ISCI</em>,
<em>541</em>, 345–361. (<a
href="https://doi.org/10.1016/j.ins.2020.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of solving nonlinear equation systems is how to locate multiple optimal solutions simultaneously in a single run. To address this issue, this paper proposes a novel algorithm by combining a diversity indicator, multi-objective optimization technique, and clustering technique . Firstly, a diversity indicator is designed to maintain the diversity of the population. Then, a K-means clustering-based selection strategy is introduced to locate the promising solutions. Finally, the local search is used to accelerate the convergence of population. The experimental results on 30 nonlinear equation systems show that the proposed algorithm is better than six state-of-the-art algorithms in terms of convergence rate and success rate.},
  archive      = {J_ISCI},
  author       = {Weifeng Gao and Yuting Luo and Jingwei Xu and Shengqi Zhu},
  doi          = {10.1016/j.ins.2020.06.042},
  journal      = {Information Sciences},
  pages        = {345-361},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary algorithm with multiobjective optimization technique for solving nonlinear equation systems},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). Evolutive preference analysis with online consumer ratings.
<em>ISCI</em>, <em>541</em>, 332–344. (<a
href="https://doi.org/10.1016/j.ins.2020.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of online rating information enables firms to learn and monitor consumer preferences over their products. Based on multidimensional rating information systems, we propose a novel class of Evolutive Preference Analysis (EPA) methods to handle the dynamic online ratings with arbitrary rating distribution, which takes all the historical ratings into consideration and delivers a comprehensive ranking evolution. As a new tool to analyze real-time consumer preferences, the EPA class includes the EPA that emphasizes the overall preferences of consumers, and the EPA t EPAt that emphasizes the recent preferences that generally provide up-to-date information. Both of them include four indices (the expected priority vector , expected rank, confidence factor , and index of rank probability) to reveal consumer preferences over rated attributes of products along time. The evolution trends of these indices help firms verify whether their advertised products match the preferences of target consumers to improve their products and marketing strategies. Finally, the practical applicability of EPA class is corroborated by several numerical examples and one real-world application on smartphone online ratings, which demonstrates the effectiveness of the proposed EPA class on streaming rating evolution.},
  archive      = {J_ISCI},
  author       = {Xue Li and Hongfu Liu and Bin Zhu},
  doi          = {10.1016/j.ins.2020.06.048},
  journal      = {Information Sciences},
  pages        = {332-344},
  shortjournal = {Inf. Sci.},
  title        = {Evolutive preference analysis with online consumer ratings},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sign prediction by motif naive bayes model in social
networks. <em>ISCI</em>, <em>541</em>, 316–331. (<a
href="https://doi.org/10.1016/j.ins.2020.05.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign prediction is a significant research content in signed social networks, so it has attracted increasing attention from the field of online social networks recently. Traditionally, the basic idea of motif-based predictive method is to calculate the motif number on the predicted edge (i.e., the single edge-dependent motif based method), and then use a machine learning predictor for sign prediction. Although this intuition-based method can achieve great performance for sign prediction, up to now its reasonability has not been proved theoretically. Furthermore, the method of counting the number of edge-dependent motif can not distinguish the distinct role of each node on the neighborhood of the predicted edge. In this study, firstly we propose a Single Motif Naive Bayes (SMNB) model for sign prediction, which can not only explain why the single edge-dependent motif based method is efficient, but also quantify the role of each neighbor node (for 3-node predictors) or neighbor edge (for 4-node predictors) which is connected by the predicted edge for the task of sign prediction. Then, we extend SMNB by merging two types of motifs, and propose a Two Motif Naive Bayes (TMNB) model. Experimental results on real-world networks indicate that the proposed algorithms outperform the state-of-the-art approaches. Finally, we explore the intrinsic relationship among different motifs according to the matrix of Maximal Information Coefficient (MIC). Our research not only extends the traditional motif theory by proving the rationality of the edge-dependent motif based method and distinguishing a node (or an edge) contribution for sign prediction, but also is helpful to further understand the evolution mechanism of signed social networks based on the correlation among different motifs.},
  archive      = {J_ISCI},
  author       = {Si-Yuan Liu and Jing Xiao and Xiao-Ke Xu},
  doi          = {10.1016/j.ins.2020.05.128},
  journal      = {Information Sciences},
  pages        = {316-331},
  shortjournal = {Inf. Sci.},
  title        = {Sign prediction by motif naive bayes model in social networks},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attention-based bidirectional GRU networks for efficient
HTTPS traffic classification. <em>ISCI</em>, <em>541</em>, 297–315. (<a
href="https://doi.org/10.1016/j.ins.2020.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed and pervasive web services have become a major platform for sharing information. However, the hypertext transfer protocol secure (HTTPS), which is a crucial web encryption technology for protecting the information security of users, creates a supervisory burden for network management (e.g., quality-of-service guarantees and traffic engineering). Identifying various types of encrypted traffic is crucial for cyber security and network management. In this paper, we propose a novel deep learning model called BGRUA to identify the web services running on HTTPS connections accurately. BGRUA utilizes a bidirectional gated recurrent unit (GRU) and attention mechanism to improve the accuracy of HTTPS traffic classification. The bidirectional GRU is used to extract the forward and backward features of the byte sequences in a session. The attention mechanism is adopted to assign weights to features according to their contributions to classification. Additionally, we investigate the effects of different hyperparameters on the performance of BGRUA and present a set of optimal values that can serve as a basis for future relevant studies. Comparisons to existing methods based on three typical datasets demonstrate that BGRUA outperforms state-of-the-art encrypted traffic classification approaches in terms of accuracy, precision, recall, and F1-score.},
  archive      = {J_ISCI},
  author       = {Xun Liu and Junling You and Yulei Wu and Tong Li and Liangxiong Li and Zheyuan Zhang and Jingguo Ge},
  doi          = {10.1016/j.ins.2020.05.035},
  journal      = {Information Sciences},
  pages        = {297-315},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based bidirectional GRU networks for efficient HTTPS traffic classification},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A memetic algorithm based on reformulation local search for
minimum sum-of-squares clustering in networks. <em>ISCI</em>,
<em>541</em>, 271–296. (<a
href="https://doi.org/10.1016/j.ins.2020.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The edge minimum sum-of-squares clustering problem (E-MSSC) aims at finding p prototypes such that the sum of squares of distances from a set of vertices to their closest prototype is minimized, where a prototype is either a vertex or an interior point of an edge. This paper proposes a highly effective memetic algorithm for E-MSSC that combines a dedicated crossover operator for solution generation with a reformulation local search for solution improvement. Reformulation local search is a recent algorithmic framework for continuous location problems that is based on an alternation between original (continuous) and discrete formulations of a given problem. Furthermore, the proposed algorithm uses a simple strategy for population updating, and a mutation operator to prevent from premature convergence. The computational results obtained on three sets of 132 benchmark instances show that the proposed algorithm competes very favorably with the existing state-of-the-art algorithms in terms of both solution quality and computational efficiency. We also analyze several essential components of the proposed algorithm to understand their contribution to the algorithm’s performance.},
  archive      = {J_ISCI},
  author       = {Qing Zhou and Una Benlic and Qinghua Wu},
  doi          = {10.1016/j.ins.2020.06.056},
  journal      = {Information Sciences},
  pages        = {271-296},
  shortjournal = {Inf. Sci.},
  title        = {A memetic algorithm based on reformulation local search for minimum sum-of-squares clustering in networks},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving polynomial interpolation and its
applications on predictive analysis. <em>ISCI</em>, <em>541</em>,
259–270. (<a href="https://doi.org/10.1016/j.ins.2020.05.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving polynomial interpolation refers to a process which requires two parties to jointly finding out a polynomial over their private coordinate pairs. Unfortunately, the existing general approach remains impractical. To date, no practical solution to privacy-preserving polynomial interpolation exists. In this paper, we aim to fill this gap by presenting an efficient solution to enable this process. To this end, we first transform the privacy-preserving polynomial interpolation into privacy-preserving calculation of function values, and design a succinct privacy-preserving scalar product protocol. Then, we tackle the original problem by employing Lagrange interpolation in combination with our privacy-preserving scalar product protocol. Finally, we offer some application examples of how our protocol can be used to conduct privacy-preserving predictive analysis .},
  archive      = {J_ISCI},
  author       = {Zhenhua Chen and Luqi Huang and Xiaonan Shi and Qiong Huang and Hao Wang and Xueqiao Liu},
  doi          = {10.1016/j.ins.2020.05.139},
  journal      = {Information Sciences},
  pages        = {259-270},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving polynomial interpolation and its applications on predictive analysis},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Linguistic group decision making: Axiomatic distance and
minimum cost consensus. <em>ISCI</em>, <em>541</em>, 242–258. (<a
href="https://doi.org/10.1016/j.ins.2020.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The axiomatic distance-based method is a powerful tool to aggregate individual preferences, and the extant axiomatic distance-based aggregation methods are with regard to individual numerical preferences. However, in some real-world decision problems with qualitative aspects, it is more convenient and natural for individuals to express their preferences through linguistic terms rather than through numerical values. Therefore, in this paper, we propose axiomatic distance in the linguistic context based on ordered linguistic term sets to aggregate individual linguistic preferences. Specifically, we provide some natural axioms on the distance measure among linguistic preferences. We then prove that there exists a unique distance function that satisfies all the proposed axioms. Based on the axiomatic distance function, we aggregate individual linguistic preferences into the group linguistic preference, which minimizes the total distance among individual linguistic preferences. Furthermore, we present a novel consensus measure based on the unique axiomatic distance and develop a minimum cost consensus model to obtain the optimal adjusted linguistic preference, which serves as a reference for the moderator to persuade individuals to modify their linguistic preferences.},
  archive      = {J_ISCI},
  author       = {Yao Li and Xia Chen and Yucheng Dong and Francisco Herrera},
  doi          = {10.1016/j.ins.2020.06.033},
  journal      = {Information Sciences},
  pages        = {242-258},
  shortjournal = {Inf. Sci.},
  title        = {Linguistic group decision making: Axiomatic distance and minimum cost consensus},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach to create synthetic biomedical signals
using BiRNN. <em>ISCI</em>, <em>541</em>, 218–241. (<a
href="https://doi.org/10.1016/j.ins.2020.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human health is threatened by several diseases for this reason automated medical diagnosis systems has been developed several years ago. These systems need databases, the creation of these databases is tedious, arduous and stops being done so the created database is incomplete or unbalanced. Sometimes the databases are private to protect the private information of the patients, among other problems. For this reason, the researchers have started to use synthetic data. The synthetic data have been applied by different hospitals in the USA. The creation of synthetic data has different problems like the synthetic data are generated using rules defined by the user, the proposed approaches only can create one kind of data, the proposals require input from domain experts, among others. To address these kinds of problems, we propose a novel approach, which consists of the Bidirectional Recurrent Neural Network and the statistical stage to generate synthetic biomedical signals. The approach is able to create 5 kinds of biomedical signals (ECG, EEG, BCG, PPG, and Respiratory Impedance). Our approach is able to create synthetic data for patients or for specific events. The performance of our approach is compared with other generative models (GAN’s) through evaluation metrics . The created synthetic data are used to construct models; these models are able to successfully differentiate between different signals with high accuracies.},
  archive      = {J_ISCI},
  author       = {Andres Hernandez-Matamoros and Hamido Fujita and Hector Perez-Meana},
  doi          = {10.1016/j.ins.2020.06.019},
  journal      = {Information Sciences},
  pages        = {218-241},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach to create synthetic biomedical signals using BiRNN},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computer aided detection of breathing disorder from
ballistocardiography signal using convolutional neural network.
<em>ISCI</em>, <em>541</em>, 207–217. (<a
href="https://doi.org/10.1016/j.ins.2020.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sleep-related breathing disorders are diseases related to pharyngeal airway collapse. It can lead to several health problems such as somnolence, poorer daytime cognitive performance, and cardiovascular morbidity and mortality. However, computer-aided diagnostic (CAD) tools play a very important role in the detection of breathing disorders. It is possible to measure breathing activity, but most approaches require some type of device placed on the human body. This paper proposes a novel methodology of an unobtrusive CAD system to the breathing disorder detection. Unobtrusive approach is ensured by ballistocardiography (BCG) sensors located on the measured bed. The significant pieces of information from the signals are extracted by Cartan curvatures. Thereafter, important features are separated from individual samples as an input to our 9-layer deep convolutional neural network . We achieved an average accuracy of 98.00\%, sensitivity of 94.26\%, and specificity of 99.22\% on 4009 regular and 1307 disordered breathing samples.},
  archive      = {J_ISCI},
  author       = {Dalibor Cimr and Filip Studnicka and Hamido Fujita and Hana Tomaskova and Richard Cimler and Jitka Kuhnova and Jan Slegr},
  doi          = {10.1016/j.ins.2020.05.051},
  journal      = {Information Sciences},
  pages        = {207-217},
  shortjournal = {Inf. Sci.},
  title        = {Computer aided detection of breathing disorder from ballistocardiography signal using convolutional neural network},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BSPR: Basket-sensitive personalized ranking for product
recommendation. <em>ISCI</em>, <em>541</em>, 185–206. (<a
href="https://doi.org/10.1016/j.ins.2020.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Product recommendation has played an important role in improving user experiences and obtaining more profits. To optimize recommendation models, pairwise learning has become a mainstream method for modeling user preferences from implicit feedback. Nevertheless, most existing pairwise methods optimize the relative order among products from only the user perspective. In fact, the purchase decision making of a given user depends on not only individual taste, but also the complementary relationships between the recommended products and the products in his/her historical basket. We argue that it is challenging to uncover meaningful user and product representations by only utilizing the user-side pairwise ranking. Towards this end, we propose a novel probabilistic pairwise method named BSPR, short for basket-sensitive personalized ranking , which solves both user- and product-side pairwise ranking problems in a unified manner. Specifically, BSPR discovers mutual correlations among users and products by exploiting co-pairwise ranking, alleviating the inherent flaw in existing pairwise methods. Considering that the negative sampler is one of the key components for pairwise learning, we devise a position-aware sampling strategy for the proposed method. To solve the optimization problem in BSPR, we further design an alternative optimization algorithm to efficiently learn the model parameters. Extensive experiments on multiple real-world datasets demonstrate significant improvements of our method over a series of state-of-the-art methods. Our implementation of BSPR is publicly available at: https://github.com/wubinzzu/BSPR .},
  archive      = {J_ISCI},
  author       = {Bin Wu and Yangdong Ye},
  doi          = {10.1016/j.ins.2020.06.046},
  journal      = {Information Sciences},
  pages        = {185-206},
  shortjournal = {Inf. Sci.},
  title        = {BSPR: Basket-sensitive personalized ranking for product recommendation},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimal distributed PID-like control for the output
containment and leader-following of heterogeneous high-order multi-agent
systems. <em>ISCI</em>, <em>541</em>, 166–184. (<a
href="https://doi.org/10.1016/j.ins.2020.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the leader-tracking and the containment control problems for heterogeneous high-order Multi-Agent Systems (MASs) sharing information through a directed communication topology. To solve both the control problems, a fully-distributed Proportional-Integral-Derivative (PID) control strategy is proposed, whose stability is analytically proven by exploiting the regulator equations and the Static Output Feedback (SOF) procedure adapted to the MASs framework. The application of SOF allows recasting the PID control design problem into a state-feedback control design one and, hence, finding the proper values of the proportional, integral and derivative actions via classical state-feedback approaches, such as the Linear-Quadratic-Regulator (LQR) strategy. Numerical simulations confirm the effectiveness of the proposed approach in guaranteeing that each follower tracks the leader behavior in the case of leader-tracking and that each follower converges to the convex hull spanned by the multiple leaders in the case of containment control.},
  archive      = {J_ISCI},
  author       = {Dario Giuseppe Lui and Alberto Petrillo and Stefania Santini},
  doi          = {10.1016/j.ins.2020.06.049},
  journal      = {Information Sciences},
  pages        = {166-184},
  shortjournal = {Inf. Sci.},
  title        = {An optimal distributed PID-like control for the output containment and leader-following of heterogeneous high-order multi-agent systems},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced kalman-filtering iterative learning control with
application to a wafer scanner. <em>ISCI</em>, <em>541</em>, 152–165.
(<a href="https://doi.org/10.1016/j.ins.2020.05.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an enhanced kalman-filtering iterative learning control (KF-ILC) algorithm is developed and applied to a wafer stage as a feedforward compensator of motion control. A novel learning gain is designed for the enhanced KF-ILC algorithm that consists of the inverse of the nominal model, a low-pass filter, a time-lead compensator and an iteration-varying parameter. The low-pass filter improves the robustness of the algorithm to high-frequency model uncertainties. The time-lead compensator is utilized to compensate the phase lag induced by the low-pass filter that enables the monotonic convergence condition to be satisfied in a wider frequency range. The iteration-varying parameter is able to reduce the accumulated effect of the noise during learning and results in a more accurate feedforward input for the motion control system. Deterministic convergence analysis is performed for the enhanced KF-ILC algorithm by the set-membership method in presence of bounded noises and bounded model uncertainties. And design guidelines are provided for the low-pass filter and the time-lead compensator. Experimental results on the wafer stage confirm the effectiveness and superiority of the enhanced KF-ILC algorithm.},
  archive      = {J_ISCI},
  author       = {Yang Liu and Li Li and Xiaofeng Yang and Jiubin Tan},
  doi          = {10.1016/j.ins.2020.05.125},
  journal      = {Information Sciences},
  pages        = {152-165},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced kalman-filtering iterative learning control with application to a wafer scanner},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable metric evolution strategies by mutation matrix
adaptation. <em>ISCI</em>, <em>541</em>, 136–151. (<a
href="https://doi.org/10.1016/j.ins.2020.05.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The covariance matrix adaptation evolution strategy (CMA-ES) is one of the most successful evolutionary algorithms . CMA-ES incrementally learns the variable metric by evolving a full covariance matrix . Yet, it suffers from high computational overload. In this paper, we propose two efficient variants of CMA-ES, termed mutation matrix adaptation (MMA-ES) and exponential MMA-ES (xMMA-ES). These variants are derived by taking the first order approximation of the update of the covariance matrix in CMA-ES. Both variants avoid the computational costly matrix decomposition while keeping the simplicity of the update scheme of CMA-ES. We analyze the properties and connections of MMA-ES and xMMA-ES to other variants of evolution strategies. We have experimentally studied the proposed algorithms’ behaviors and performances. xMMA-ES and MMA-ES generally outperform or perform competitively to CMA-ES. We have investigated the performance of MMA-ES with the BiPop restart strategy on the BBOB benchmarks. The experimental results validate the performance of the proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Zhenhua Li and Qingfu Zhang},
  doi          = {10.1016/j.ins.2020.05.091},
  journal      = {Information Sciences},
  pages        = {136-151},
  shortjournal = {Inf. Sci.},
  title        = {Variable metric evolution strategies by mutation matrix adaptation},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Paraphrase thought: Sentence embedding module imitating
human language recognition. <em>ISCI</em>, <em>541</em>, 123–135. (<a
href="https://doi.org/10.1016/j.ins.2020.05.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentence embedding is an important research topic in natural language processing . It is essential to generate a good embedding vector that fully reflects the semantic meaning of a sentence in order to achieve an enhanced performance for various natural language processing tasks, such as machine translation and document classification . Thus far, various sentence embedding models have been proposed, and their feasibility has been demonstrated through good performances on tasks following embedding, such as sentiment analysis and sentence classification. However, because the performances of sentence classification and sentiment analysis can be enhanced by using a simple sentence representation method, it is not sufficient to claim that these models fully reflect the meanings of sentences based on good performances for such tasks. In this paper, inspired by human language recognition, we propose the following concept of semantic coherence, which should be satisfied for a good sentence embedding method: similar sentences should be located close to each other in the embedding space. Then, we propose the Paraphrase-Thought (P-thought) model to pursue semantic coherence as much as possible. Experimental results on three paraphrase identification datasets (MS COCO, STS benchmark, SICK) show that the P-thought models outperform the benchmarked sentence embedding methods.},
  archive      = {J_ISCI},
  author       = {Myeongjun Jang and Pilsung Kang},
  doi          = {10.1016/j.ins.2020.05.129},
  journal      = {Information Sciences},
  pages        = {123-135},
  shortjournal = {Inf. Sci.},
  title        = {Paraphrase thought: Sentence embedding module imitating human language recognition},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental three-way neighborhood approach for dynamic
incomplete hybrid data. <em>ISCI</em>, <em>541</em>, 98–122. (<a
href="https://doi.org/10.1016/j.ins.2020.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, there generally exist incomplete hybrid data with heterogeneous and missing features. The complex structures and the fast update of incomplete hybrid data bring a series of challenges for decision making in dynamic data environments. Three-way decisions, as an important cognitive method for analyzing uncertain problems, have been extensively applied into various fields. However, the existing studies rarely focus on exploring three-way decisions with incomplete hybrid information. To tackle this issue, we propose a Three-Way Neighborhood Decision Model (TWNDM) based on the data-driven neighborhood relation in terms of two pseudo-distance functions only satisfying the reflexivity. Considering that the addition and deletion of objects will result in the variation of information granules and decision structures, this paper presents a matrix-based dynamic framework for updating three-way regions (positive, boundary and negative regions) in TWNDM. A novel relation matrix is first constructed by using a pair of values to replace single value in the classical relation matrix. Then, the matrix-based approach for computing the three-way regions is established in the light of the new relation matrix, the decision matrix and the related induced matrices. Moreover, the matrix-based incremental mechanisms and algorithms for the maintenance of the three-way regions are presented when adding and removing objects, respectively. The results of comparative experiments demonstrate that the proposed incremental algorithms can improve the computational performance for maintaining three-way regions in TWNDM compared with the static algorithm.},
  archive      = {J_ISCI},
  author       = {Qianqian Huang and Tianrui Li and Yanyong Huang and Xin Yang},
  doi          = {10.1016/j.ins.2020.06.029},
  journal      = {Information Sciences},
  pages        = {98-122},
  shortjournal = {Inf. Sci.},
  title        = {Incremental three-way neighborhood approach for dynamic incomplete hybrid data},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Local temporal-spatial multi-granularity learning for
sequential three-way granular computing. <em>ISCI</em>, <em>541</em>,
75–97. (<a href="https://doi.org/10.1016/j.ins.2020.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on multiple levels of granularity , the notion of sequential three-way granular computing focuses on a multiple stages of thinking, problem-solving, and information processing in threes. This paper interprets, represents, and implements sequential three-way granular computing by a framework of temporal-spatial multi-granularity learning, which is described with the temporality of data and the spatiality of parameters. In real-world decision-making, such a sequential approach is useful to make faster decisions for some objects with the lower cost of decision process and the acceptable accuracy when information is insufficient or unavailable. However, the cost of time-consuming computation for hierarchical multilevel granularity is our concern. To address this issue, we utilize a local strategy to accelerate a sequence of neighborhood-based granulation induced by Gaussian kernel function. Subsequently, local three-way decision rules are investigated based on the Bayesian minimum risk criterion. Moreover, by the construction of a novel local trisection model, we propose a local sequential approach of three-way granular computing under a temporal-spatial multilevel granular structure. Finally, a series of comparative experiments between global and local perspectives is carried out to verify the effectiveness of our proposed models.},
  archive      = {J_ISCI},
  author       = {Xin Yang and Yingying Zhang and Hamido Fujita and Dun Liu and Tianrui Li},
  doi          = {10.1016/j.ins.2020.06.020},
  journal      = {Information Sciences},
  pages        = {75-97},
  shortjournal = {Inf. Sci.},
  title        = {Local temporal-spatial multi-granularity learning for sequential three-way granular computing},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting textile micro-defects: A novel and efficient
method based on visual gain mechanism. <em>ISCI</em>, <em>541</em>,
60–74. (<a href="https://doi.org/10.1016/j.ins.2020.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern textile industrial processes, fast and efficient detection of textile defects plays a crucial role in textile quality control. Recently, as a critical machine-learning method, faster region-based convolutional neural network (Faster RCNN) have arisen as a promising framework, providing competitive performance for object detection. However, detecting small-scale objects, such as micro-defects on textile, is still a challenging task for Faster RCNN. To address the challenge, this paper aims to develop a new detection model to improve the ability of detecting small-scale objects. First, by analyzing the relationship between the attention mechanism and the visual gain mechanism, we find that the attention-related visual gain mechanism can modify response amplitude without changing selectivity and improve the acuity of visual perception. Then, the relevant mechanisms are further incorporated into the Faster RCNN model to build a new model called Faster VG-RCNN. To evaluate the proposed detection model, a unique textile micro-defect database is built as the benchmark for micro-defect detection. Furthermore, we conduct extensive experimental validations for various design choices. The experimental results show that the proposed Faster VG-RCNN outperforms the existing detection methods. In particular, compared to Faster RCNN, Faster VG-RCNN improves the detection precision from 90.1\% to 94.3\%.},
  archive      = {J_ISCI},
  author       = {Bing Wei and Kuangrong Hao and Lei Gao and Xue-song Tang},
  doi          = {10.1016/j.ins.2020.06.035},
  journal      = {Information Sciences},
  pages        = {60-74},
  shortjournal = {Inf. Sci.},
  title        = {Detecting textile micro-defects: A novel and efficient method based on visual gain mechanism},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal scale selection and attribute reduction in
multi-scale decision tables based on three-way decision. <em>ISCI</em>,
<em>541</em>, 36–59. (<a
href="https://doi.org/10.1016/j.ins.2020.05.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal scale selection and attribute reduction are two key issues related to knowledge discovery in multi-scale decision tables (MDTs). The former is mainly used to obtain optimal scale combinations by selecting a suitable scale for each attribute, while the latter attempts to obtain reducts of these optimal scale combinations (i.e., optimal scale reducts). However, a search for all optimal scale reducts of a given MDT may result in a combinatorial explosion and existing approaches typically incur excessive time consumption. In this paper, a novel scale combination is defined to perform optimal scale selection and attribute reduction synchronously. Accordingly, an effective approach integrating sequential three-way decision with simplified MDTs is proposed to search for all optimal scale reducts. The efficiency of searching can be significantly improved by reducing the number of consistency checks required for single-scale decision tables and accelerating each check. First, a sequential three-way decision model of the scale space is proposed to search for all optimal scale reducts. Based on the trisecting-and-acting concept and a multi-step strategy, a large number of non-optimal scale reducts can be progressively transferred from the boundary regions to the negative regions. Second, an extended stepwise optimal scale selection method is introduced to quickly search for a single optimal scale reduct in the boundary region. Finally, a simplified MDT is proposed to accelerate the consistency checks for single-scale decision tables. Accordingly, an optimal scale selection algorithm integrating sequential three-way decision with simplified MDTs is proposed to improve the efficiency of searching for all optimal scale reducts. Experimental results demonstrate that the proposed algorithm can significantly reduce overall computational time.},
  archive      = {J_ISCI},
  author       = {Yunlong Cheng and Qinghua Zhang and Guoyin Wang and Bao Qing Hu},
  doi          = {10.1016/j.ins.2020.05.109},
  journal      = {Information Sciences},
  pages        = {36-59},
  shortjournal = {Inf. Sci.},
  title        = {Optimal scale selection and attribute reduction in multi-scale decision tables based on three-way decision},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Deep joint neural model for single image haze removal and
color correction. <em>ISCI</em>, <em>541</em>, 16–35. (<a
href="https://doi.org/10.1016/j.ins.2020.05.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of an image affects the performance of computer vision applications. The presence of haze often greatly depreciates the visual effect of images. It is a traditional and critical vision challenge to remove haze from a single image. This paper proposes a trainable end-to-end de-hazing connectionist model with a special design. First, feature learning is conducted using hierarchical convolutional layers with nested structures. Cascaded haze-relevant tasks are then sequentially performed via a physics-driven sub-network. In particular, to break the assumption of a homogeneous atmosphere, a branch of the sub-network estimates the scattering factor in the form of a two-dimensional tensor. Finally, a chromatic adaptation layer is proposed for color adjustment, which is often neglected in existing de-hazing methods. In addition, we integrate different training criteria based on the characteristics of the haze-relevant variables in our model. For a fully actionable optimization, an asynchronous learning paradigm is designed for the fusion of different de-hazing tasks, and the joint model is further facilitated by a cyclic restoration. The effectiveness of the proposed de-hazing model was verified via extensive experiments, and most results of our method are remarkable.},
  archive      = {J_ISCI},
  author       = {Tianlun Zhang and Xi Yang and Xizhao Wang and Ran Wang},
  doi          = {10.1016/j.ins.2020.05.105},
  journal      = {Information Sciences},
  pages        = {16-35},
  shortjournal = {Inf. Sci.},
  title        = {Deep joint neural model for single image haze removal and color correction},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reformulating preferences into constraints for evolutionary
multi- and many-objective optimization. <em>ISCI</em>, <em>541</em>,
1–15. (<a href="https://doi.org/10.1016/j.ins.2020.05.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that the reference point based preference articulation plays a vital role in evolutionary multi- and many-objective optimization, three issues remain challenging. First, the performance of reference point based preference articulation largely depends on the location of the reference point. Second, the parameter settings for controlling the region of interest are not robust to the Pareto optimal fronts with different complicated shapes. Third, most existing methods have poor scalability to the number of objectives. To meet these challenges, we propose to reformulate preferences into constraints for evolutionary multi- and many-objective optimization. Extensive experiments on a variety of benchmark problems are conducted to demonstrate the effectiveness of our proposed method.},
  archive      = {J_ISCI},
  author       = {Zhanglu Hou and Cheng He and Ran Cheng},
  doi          = {10.1016/j.ins.2020.05.103},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Reformulating preferences into constraints for evolutionary multi- and many-objective optimization},
  volume       = {541},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An interactive knowledge-based recommender system for
fashion product design in the big data environment. <em>ISCI</em>,
<em>540</em>, 469–488. (<a
href="https://doi.org/10.1016/j.ins.2020.05.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we originally propose an interactive, knowledge-based design recommender system (IKDRS) for relevant personalised fashion product design schemes with their virtual demonstrations for a specific consumer. This system enables the iterative interaction between virtual product demonstration and the designer’s professional knowledge and perception in order to find the best existing design solution, i.e. combination of basic garment elements. To develop this system, the anthropometric data and designer’s perception of body shapes are first acquired by using a 3D body scanning system and a sensory evaluation procedure. Next, an instrumental experiment is realised for measuring the technical parameters of fabrics and five sensory experiments are carried out in order to acquire design knowledge. The acquired data are used to classify body shapes and model the relations between human bodies, fashion themes and design factors by using fuzzy techniques. From these models, we set up an ontology-based design knowledge base , including key data and relevant relation models. This knowledge base can be updated in a big data environment by progressively learning from new design cases. On this basis, we propose an interactive, personalised design recommender system . This system works through a newly proposed design process: consumers’ emotional requirement identification – design schemes generation – recommender – 3D virtual prototype display and evaluation – design factors adjustment . This process can be performed repeatedly until the designer is satisfied. The proposed system has been validated through a number of successful real design cases.},
  archive      = {J_ISCI},
  author       = {Min Dong and Xianyi Zeng and Ludovic Koehl and Junjie Zhang},
  doi          = {10.1016/j.ins.2020.05.094},
  journal      = {Information Sciences},
  pages        = {469-488},
  shortjournal = {Inf. Sci.},
  title        = {An interactive knowledge-based recommender system for fashion product design in the big data environment},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolution of social power over influence networks containing
antagonistic interactions. <em>ISCI</em>, <em>540</em>, 449–468. (<a
href="https://doi.org/10.1016/j.ins.2020.05.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual social power in the opinion formation process over social influence networks has been under intense scientific investigation. Most related works assume explicitly or implicitly that the interpersonal influence weights are always non-negative. In sharp comparison, we argue that such influence weights can be both positive and negative since there exist various contrasting relationships in real-world social networks. Hence, this article studies the evolution of opinion dynamics and social power on cooperative-competitive networks whose influence structure changes via a reflected appraisal mechanism along a sequence of issue discussions. Of particular focus is on identifying the pathways and effects of social power on shaping public opinions from a graph-theoretic perspective. Then, we propose a dynamic model for the reflected self-appraisal process, which enables us to discuss how the individual social power evolves over sequential issue discussions. By accommodating differential Lyapunov theory , we show the global exponential convergence of the self-appraisal model for almost all network topologies . Finally, we conclude that the self-appraisals and social powers are eventually dependent only on an interpersonal appraisal profile.},
  archive      = {J_ISCI},
  author       = {Dong Xue and Sandra Hirche and Ming Cao},
  doi          = {10.1016/j.ins.2020.05.142},
  journal      = {Information Sciences},
  pages        = {449-468},
  shortjournal = {Inf. Sci.},
  title        = {Evolution of social power over influence networks containing antagonistic interactions},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decomposition-based many-objective ant colony optimization
algorithm with adaptive reference points. <em>ISCI</em>, <em>540</em>,
435–448. (<a href="https://doi.org/10.1016/j.ins.2020.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The discrete many-objective problem (MaOP) is challenging in practice. Improving the convergence speed and making the nondominated solutions close to the Pareto front (PF) are vital issues in the optimization of the discrete MaOP. This pper proposed a modified decomposition-based many objective ant colony optimization (ACO) algorithm and employs an adaptive reference point mechanism that chooses the ideal point or nadir point as the reference point according to the distribution of the candidate solutions. This mechanism is utilized to improve the selection operator, accelerate the convergence speed and enhance the optimization ability. A comparative experiment is conducted on traveling salesman problems (TSPs) constrained by two, five, and ten objectives, which are built using test cases from the TSPLIB. The experimental results indicate that the inverted generational distance (IGD) indicator of the nondominated solution of the proposed algorithm has a rapid convergence speed and that the proposed algorithm achieves competitive performance regarding its optimization quality.},
  archive      = {J_ISCI},
  author       = {Haitong Zhao and Changsheng Zhang and Bin Zhang},
  doi          = {10.1016/j.ins.2020.06.028},
  journal      = {Information Sciences},
  pages        = {435-448},
  shortjournal = {Inf. Sci.},
  title        = {A decomposition-based many-objective ant colony optimization algorithm with adaptive reference points},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-based optimal output-feedback control of nonlinear
discrete-time systems. <em>ISCI</em>, <em>540</em>, 414–434. (<a
href="https://doi.org/10.1016/j.ins.2020.05.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an event-triggered strategy and an optimality scheme are presented to design an output-feedback controller for nonlinear discrete-time systems. Firstly, owing to the unavailability of the system states, a coordinate transformation is executed instead of state observers. Then, an action neural network and a specified critic neural network are presented to obtain the optimal controller and estimate the novel long-term cost function, respectively. The adaptation laws are designed on the basis of the gradient descent rule and event-triggered mechanism. The control signals are transmitted only when the event is triggered. Based on the Lyapunov analysis theory, the stability and the tracking performance of the closed-loop system are proven. The effectiveness of the proposed strategy is verified via simulation examples.},
  archive      = {J_ISCI},
  author       = {Wenqi Xu and Xiaoping Liu and Huanqing Wang and Yucheng Zhou},
  doi          = {10.1016/j.ins.2020.05.098},
  journal      = {Information Sciences},
  pages        = {414-434},
  shortjournal = {Inf. Sci.},
  title        = {Event-based optimal output-feedback control of nonlinear discrete-time systems},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ontology-based multi-domain model in social network
analysis: Experimental validation and case study. <em>ISCI</em>,
<em>540</em>, 390–413. (<a
href="https://doi.org/10.1016/j.ins.2020.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of social network theory and methods of analysis have been applied to different domains in recent years, including public health. The complete procedure for carrying out a social network analysis (SNA) is a time-consuming task that entails a series of steps in which the expert in social network analysis could make mistakes. This research presents a multi-domain knowledge model capable of automatically gathering data and carrying out different social network analyses in different domains, without errors and obtaining the same conclusions that an expert in SNA would obtain. The model is represented in an ontology called OntoSNAQA, which is made up of classes, properties and rules representing the domains of People, Questionnaires and Social Network Analysis . Besides the ontology itself, different rules are represented by SWRL and SPARQL queries. A Knowledge Based System was created using OntoSNAQA and applied to a real case study in order to show the advantages of the approach. Finally, the results of an SNA analysis obtained through the model were compared to those obtained from some of the most widely used SNA applications: UCINET, Pajek, Cytoscape and Gephi, to test and confirm the validity of the model.},
  archive      = {J_ISCI},
  author       = {José Alberto Benítez-Andrades and Isaías García-Rodríguez and Carmen Benavides and Héctor Alaiz-Moretón and José Emilio Labra Gayo},
  doi          = {10.1016/j.ins.2020.06.008},
  journal      = {Information Sciences},
  pages        = {390-413},
  shortjournal = {Inf. Sci.},
  title        = {An ontology-based multi-domain model in social network analysis: Experimental validation and case study},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed active disturbance rejection control for
ackermann steering of a four-in-wheel motor drive vehicle with deception
attacks on controller area networks. <em>ISCI</em>, <em>540</em>,
370–389. (<a href="https://doi.org/10.1016/j.ins.2020.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the network-based modeling and distributed active disturbance rejection control (ADRC) to address the Ackermann steering problem of a four-in-wheel motor drive electric vehicle with deception attacks on controller area networks (CAN). The distributed ADRC can achieve the independent steering, ensure a small steering radius and improve the stability and robustness of the vehicle under unknown tyre longitudinal forces and network attacks. Using an independent driving strategy and Ackermann steering geometry, a state-space model for rotational velocity tracking of each wheel is established, where a virtual external disturbance that consists of the tyre longitudinal force and the expected rotational velocity is imposed on the model. Considering the effect of deception attacks on measurement outputs, sampled-data-driven extended state observers are designed to estimate the tracking error and the external disturbance . To capture the interactions among four wheels, a distributed controller based on ADRC is proposed and the resulting system is formulated as a stochastic linear system with input delay and composite disturbance, where the composite disturbance is composed of false signals, a discretized disturbance error and the derivative of the longitudinal forces . A lemma is obtained to prove the discretized disturbance error to be energy-limited. Some stochastic stability conditions with H ∞ H∞ performance are derived by constructing a new discontinuous augmented Lyapunov–Krasovskii functional, and a design algorithm of the observer gain and the controller gain is presented. The effectiveness of the results is exemplified by two examples.},
  archive      = {J_ISCI},
  author       = {Zifan Gao and Dawei Zhang and Shuqian Zhu and Jun-e Feng},
  doi          = {10.1016/j.ins.2020.06.012},
  journal      = {Information Sciences},
  pages        = {370-389},
  shortjournal = {Inf. Sci.},
  title        = {Distributed active disturbance rejection control for ackermann steering of a four-in-wheel motor drive vehicle with deception attacks on controller area networks},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized hesitant multiplicative preference relations and
the analytic risk-network process. <em>ISCI</em>, <em>540</em>, 345–369.
(<a href="https://doi.org/10.1016/j.ins.2020.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hesitant fuzzy preference relation (HFPR) and the hesitant multiplicative preference relation (HMPR) are emerging techniques in decision-making research field. Clearly, an intuitionistic idea to improve the above preference relations is to synthesize the HFPR and the HMPR, which is also a primary contribution of this paper. Based on which, we propose the generalized HMPR (GHMPR) with full desired properties using transformation formulas that combine HFPR with HMPR and convert the HMPR into the GHMPR. Then, the GHMPR not only considers different risk appetites of a decision maker, but also preserves the advantages of both. Moreover, we design the corresponding consistency check algorithms, weight calculation methods and convergence algorithms for the GHMPR. Based on these new methods, we further propose a qualitative decision-making method under the GHMPR environment named as the analytic risk-network process (ARNP). Saaty’s well-known analytic network process case is then utilized as an illustrated example to verify the feasibility of the proposed methods via comparisons. The simulation results show our proposed methods are effective and useful.},
  archive      = {J_ISCI},
  author       = {Man Liu and Wei Zhou and Yunlong Duan},
  doi          = {10.1016/j.ins.2020.06.039},
  journal      = {Information Sciences},
  pages        = {345-369},
  shortjournal = {Inf. Sci.},
  title        = {Generalized hesitant multiplicative preference relations and the analytic risk-network process},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multifactorial optimization paradigm for linkage tree
genetic algorithm. <em>ISCI</em>, <em>540</em>, 325–344. (<a
href="https://doi.org/10.1016/j.ins.2020.05.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linkage Tree Genetic Algorithm (LTGA) is an effective Evolutionary Algorithm (EA) to solve complex problems using the linkage information between problem variables. LTGA performs well in various kinds of single-task optimization and yields promising results in comparison with the canonical genetic algorithm. However, LTGA is an unsuitable method for dealing with multi-task optimization problems. On the other hand, Multifactorial Optimization (MFO) can simultaneously solve independent optimization problems, which are encoded in a unified representation to take advantage of the process of knowledge transfer. In this paper, we introduce Genetic Algorithm (MF-LTGA) by combining the main features of both LTGA and MFO. MF-LTGA is able to tackle multiple optimization tasks at the same time, each task learns the dependency between problem variables from the shared representation. This knowledge serves to determine the high-quality partial solutions for supporting other tasks in exploring the search space. Moreover, MF-LTGA speeds up convergence because of knowledge transfer of relevant problems. We demonstrate the effectiveness of the proposed algorithm on two benchmark problems: Clustered Shortest-Path Tree Problem and Deceptive Trap Function. In comparison to LTGA and existing methods, MF-LTGA outperforms in quality of the solution or in computation time.},
  archive      = {J_ISCI},
  author       = {Thi Thanh Binh Huynh and Dinh Thanh Pham and Ba Trung Tran and Cong Thanh Le and Minh Hai Phong Le and Ananthram Swami and Thu Lam Bui},
  doi          = {10.1016/j.ins.2020.05.132},
  journal      = {Information Sciences},
  pages        = {325-344},
  shortjournal = {Inf. Sci.},
  title        = {A multifactorial optimization paradigm for linkage tree genetic algorithm},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient blockchain-based privacy preserving scheme for
vehicular social networks. <em>ISCI</em>, <em>540</em>, 308–324. (<a
href="https://doi.org/10.1016/j.ins.2020.05.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular social networks (VSNs), edge stations or cloud service provider can support the traffic services or location services to vehicles. Moreover, the information sharing among vehicles can assist vehicles to avoid traffic accidents and guarantee driving safety. However, it is easy to be threatened in the communication of vehicle-to-edge station, vehicle-to-cloud service provider and vehicle-to-vehicle in VSNs, which leads to the vehicle’s privacy leakage easily. Besides, some malicious users may provide untrustworthy information to mislead others just for its selfishness. Hence, in this paper, we propose an efficient, reliable and privacy-preserving scheme based on blockchain for VSNs. In our scheme, pseudonym mechanism is employed to achieve individual anonymization by concealing the vehicles’ identity. Moreover, to encourage vehicles to report trustworthy information, incentive-punishment mechanism is proposed. Meanwhile, we propose multi-factors and single-factor weight-based evaluation mechanism to evaluate the reliability of message. Additionally, Practical Byzantine Fault Tolerance (PBFT) and blockchain are also employed to achieve consensus and store the records respectively, which can prevent malicious entities from manipulating on vehicles’ reward scores and credit scores. Finally, we analyze the security of the proposed scheme in terms of external attacks, internal attacks, collusion attacks etc. The relevant experimental results are shown that our scheme is feasible and efficient.},
  archive      = {J_ISCI},
  author       = {Yuwen Pu and Tao Xiang and Chunqiang Hu and Arwa Alrawais and Hongyang Yan},
  doi          = {10.1016/j.ins.2020.05.087},
  journal      = {Information Sciences},
  pages        = {308-324},
  shortjournal = {Inf. Sci.},
  title        = {An efficient blockchain-based privacy preserving scheme for vehicular social networks},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A machine learning based golden-free detection method for
command-activated hardware trojan. <em>ISCI</em>, <em>540</em>, 292–307.
(<a href="https://doi.org/10.1016/j.ins.2020.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hardware Trojan detection has been becoming an attentive research subject since the first Trojan in real-world hardware was found. A common way to activate a hardware Trojan is to send a command, and detecting those command-activated Trojan is one of the significant dimensions in securing hardware. In this paper, we propose a novel chip-free detection method, called Pruning Bytes Command Search (PBCS), which is a machine learning-based approach and can efficiently find out command-activate hardware Trojans. The proposed PBCS has been evaluated in experimental environments (via micro-controller) and real-world validations (on smart cards). Our approach also combines with novelty detection and outlier detection methods and examines effects on One-Class Support Vector Machine , Local Outlier Factor , and Isolation Forest as distinguishers in five scenes, respectively. The findings of the evaluation show that our approach is competent for searching unknown commands. Accuracy performance can be enhanced when proper distinguishers are selected. The results demonstrate that PBCS can successfully find out all executable commands in an uncertain parsing path hardware, which implies our approach is applicable in the complicated context.},
  archive      = {J_ISCI},
  author       = {Ning Shang and An Wang and Yaoling Ding and Keke Gai and Liehuang Zhu and Guoshuang Zhang},
  doi          = {10.1016/j.ins.2020.05.053},
  journal      = {Information Sciences},
  pages        = {292-307},
  shortjournal = {Inf. Sci.},
  title        = {A machine learning based golden-free detection method for command-activated hardware trojan},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). H∞ control of uncertain linear systems with a triggering
threshold dependent approach. <em>ISCI</em>, <em>540</em>, 278–291. (<a
href="https://doi.org/10.1016/j.ins.2020.05.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the H ∞ H∞ control of uncertain linear systems under the event-triggered control framework. The uncertainty is a mismatched type without known upper bounds. To reduce the redundant transmission of control signals, three triggering strategies are developed, namely, the absolute threshold triggering manner is built firstly to deal with the small control input variation. By revisiting the first one, the large control input is monitored by the second triggering scheme. Lastly, a trade-off between the above two triggering measures is made to cover all possible inputs without sacrificing system performance largely. Based on the proposed triggering strategies, different adaptive controllers containing the triggering threshold bound are constructed to eliminate the unknown uncertainty and ensure uniformly bounded with the required H ∞ H∞ performance level, which is verified by simulation studies.},
  archive      = {J_ISCI},
  author       = {Mouquan Shen and Yang Gu and Ju H. Park and Qing-Guo Wang and Sing-Kiong Nguang},
  doi          = {10.1016/j.ins.2020.05.140},
  journal      = {Information Sciences},
  pages        = {278-291},
  shortjournal = {Inf. Sci.},
  title        = {H∞ control of uncertain linear systems with a triggering threshold dependent approach},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DKEN: Deep knowledge-enhanced network for recommender
systems. <em>ISCI</em>, <em>540</em>, 263–277. (<a
href="https://doi.org/10.1016/j.ins.2020.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that existing knowledge graphs embedding (KGE) based methods can achieve better recommendation performance compared with deep learning based ones, such improvement is limited due to lack of capturing the shared information between user-item interaction and item-item relation encoded in knowledge graph (KG) by fully leveraging the implicit and explicit relationship. To address this issue, in this paper, we propose a principled deep knowledge-enhanced network (DKEN) framework based on deep learning and KGE to model the semantics of entities and relations encoded in the KG. In particular, the DKEN utilizes deep neural networks (DNN) to learn higher-order feature interactions and ensembles KGE features with DNN features into an end-to-end learning process naturally to exploit implicit interaction and explicitt semantic features. Furthermore, a cross information sharing (CIS) layer is designed to facilitate information sharing between items and entities, and two aggregators are developed to improve the performance of the model. Extensive experiments on several public datasets, as well as online AB tests of an industrial recommendation scenario in the Ant Financial Service Group, demonstrate that DKEN achieves remarkably better performance than several state-of-the-art baselines.},
  archive      = {J_ISCI},
  author       = {Xiaobo Guo and Wenfang Lin and Youru Li and Zhongyi Liu and Lin Yang and Shuliang Zhao and Zhenfeng Zhu},
  doi          = {10.1016/j.ins.2020.06.041},
  journal      = {Information Sciences},
  pages        = {263-277},
  shortjournal = {Inf. Sci.},
  title        = {DKEN: Deep knowledge-enhanced network for recommender systems},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Federated learning with adaptive communication compression
under dynamic bandwidth and unreliable networks. <em>ISCI</em>,
<em>540</em>, 242–262. (<a
href="https://doi.org/10.1016/j.ins.2020.05.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging issues such as privacy protection and communication limitations make it not possible to collect all data into data centers, which has driven the paradigm of big data and artificial intelligence to sink to network edge. Because of having the ability to continuously learn newly generated data from the Internet of Things and mobile devices while protecting user privacy, federated learning has been recognized as a new parallel distributed technology for big data and artificial intelligence. However, traditional federated learning is too strict on network throughput and is susceptible to unreliable networks and dynamic bandwidth. To address these communication bottlenecks in federated learning, this study proposes a cloud-edge-clients federated learning architecture Cecilia and designs a new algorithm ACFL. ACFL employs an information sharing method different from the traditional federated learning, and can adaptively compress shared information according to network conditions. The convergence of ACFL is analyzed from a theoretical perspective. In addition, the performance of the ACFL is evaluated through typical machine learning tasks with real datasets, including image classification, sentiment analysis, and next character prediction. Both theoretical and experimental results show that Cecilia and ACFL can better adapt to dynamic bandwidth and unreliable networks when performing federated learning.},
  archive      = {J_ISCI},
  author       = {Xiongtao Zhang and Xiaomin Zhu and Ji Wang and Hui Yan and Huangke Chen and Weidong Bao},
  doi          = {10.1016/j.ins.2020.05.137},
  journal      = {Information Sciences},
  pages        = {242-262},
  shortjournal = {Inf. Sci.},
  title        = {Federated learning with adaptive communication compression under dynamic bandwidth and unreliable networks},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LoRMIkA: Local rule-based model interpretability with
k-optimal associations. <em>ISCI</em>, <em>540</em>, 221–241. (<a
href="https://doi.org/10.1016/j.ins.2020.05.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As we rely more and more on machine learning models for real-life decision-making, being able to understand and trust the predictions becomes ever more important. Local explainer models have recently been introduced to explain the predictions of complex machine learning models at the instance level. In this paper, we propose Local Rule-based Model Interpretability with k-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains k-optimal association rules from a neighbourhood of the instance to be explained. Compared with other rule-based approaches in the literature, we argue that the most predictive rules are not necessarily the rules that provide the best explanations. Consequently, the LoRMIkA framework provides a flexible way to obtain predictive and interesting rules. It uses an efficient search algorithm guaranteed to find the k-optimal rules with respect to objectives such as confidence, lift, leverage, coverage, and support. It also provides multiple rules which explain the decision and counterfactual rules, which give indications for potential changes to obtain different outputs for given instances. We compare our approach to other state-of-the-art approaches in local model interpretability on three different datasets and achieve competitive results in terms of local accuracy and interpretability.},
  archive      = {J_ISCI},
  author       = {Dilini Rajapaksha and Christoph Bergmeir and Wray Buntine},
  doi          = {10.1016/j.ins.2020.05.126},
  journal      = {Information Sciences},
  pages        = {221-241},
  shortjournal = {Inf. Sci.},
  title        = {LoRMIkA: Local rule-based model interpretability with k-optimal associations},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive fuzzy control of state-feedback time-delay systems
with uncertain parameters. <em>ISCI</em>, <em>540</em>, 202–220. (<a
href="https://doi.org/10.1016/j.ins.2020.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes an effective and relatively simple design method for an adaptive multi-input single-output (MISO) fuzzy controller for a linear plant with partially known parameters including transport delay. The model reference adaptive control idea was applied, incorporating a reference model that defines the desired closed-loop performance. The reference model containing the fuzzy controller and the plant provides control system performances that are not inferior to those attainable with linear state feedback. The frequency-domain stability conditions for nonlinear state feedback are formulated. They are crucial for the proposed approach and guarantee stability and convergence of the adaptation process. Unlike in other works, the number of MISO fuzzy controller inputs has no restrictions. In this way, the design procedure generalizes the results reported thus far. The idea of automatic fuzzy controller tuning to obtain quasi-optimal system behavior is proposed. The adaptive fuzzy controller design procedure is exemplified for third- and fourth-order systems with delayed feedback.},
  archive      = {J_ISCI},
  author       = {Jacek Kluska},
  doi          = {10.1016/j.ins.2020.06.015},
  journal      = {Information Sciences},
  pages        = {202-220},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy control of state-feedback time-delay systems with uncertain parameters},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Heterogeneous comprehensive learning and dynamic
multi-swarm particle swarm optimizer with two mutation operators.
<em>ISCI</em>, <em>540</em>, 175–201. (<a
href="https://doi.org/10.1016/j.ins.2020.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a heterogeneous comprehensive learning and dynamic multi-swarm particle swarm optimizer with two mutation operators (HCLDMS-PSO) is presented. In addition, a comprehensive learning (CL) strategy with the global optimal experience of the whole population is conducted to generate an exploitation subpopulation exemplar. However, a modified dynamic multi-swarm (DMS) strategy is specially designed to construct the exploration subpopulation exemplar. In the canonical DMS strategy, it is unfavorable for different sub-swarms to use the same linear decreasing inertia weight parameter. We first propose classifying the DMS sub-swarms at the search level and then constructing a novel nonlinear adaptive decreasing inertia weight for different sub-swarms, introducing a non-uniform mutation operator to enhance its exploration capability. Finally, the gbest of the whole population also adopts a Gaussian mutation operator to avoid falling into the local optimum. The particles of the two subpopulations will update their velocity independently without crippling one another to prevent a loss of diversity. The performance of HCLDMS-PSO is compared with those of 8 other PSO variants and 11 evolutionary algorithms on two classical benchmark optimization problems and a real-world engineering problem. Experimental results demonstrate that the HCLDMS-PSO improves the convergence speed, accuracy, and reliability on most optimization problems.},
  archive      = {J_ISCI},
  author       = {Shengliang Wang and Genyou Liu and Ming Gao and Shilong Cao and Aizhi Guo and Jiachen Wang},
  doi          = {10.1016/j.ins.2020.06.027},
  journal      = {Information Sciences},
  pages        = {175-201},
  shortjournal = {Inf. Sci.},
  title        = {Heterogeneous comprehensive learning and dynamic multi-swarm particle swarm optimizer with two mutation operators},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Big data time series forecasting based on pattern sequence
similarity and its application to the electricity demand. <em>ISCI</em>,
<em>540</em>, 160–174. (<a
href="https://doi.org/10.1016/j.ins.2020.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel algorithm to forecast big data time series . Based on the well-established Pattern Sequence-based Forecasting algorithm, this new approach has two major contributions to the literature. First, the improvement of the original algorithm with respect to the accuracy of predictions, and second, its transformation into the big data context, having reached meaningful results in terms of scalability. The algorithm uses the Apache Spark distributed computation framework and it is a ready-to-use application with few parameters to adjust. Physical and cloud clusters have been used to carry out the experimentation, which consisted in applying the algorithm to real-world data from Uruguay electricity demand.},
  archive      = {J_ISCI},
  author       = {R. Pérez-Chacón and G. Asencio-Cortés and F. Martínez-Álvarez and A. Troncoso},
  doi          = {10.1016/j.ins.2020.06.014},
  journal      = {Information Sciences},
  pages        = {160-174},
  shortjournal = {Inf. Sci.},
  title        = {Big data time series forecasting based on pattern sequence similarity and its application to the electricity demand},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gradient-based optimizer: A new metaheuristic optimization
algorithm. <em>ISCI</em>, <em>540</em>, 131–159. (<a
href="https://doi.org/10.1016/j.ins.2020.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel metaheuristic optimization algorithm, gradient-based optimizer (GBO) is proposed. The GBO, inspired by the gradient-based Newton’s method, uses two main operators: gradient search rule (GSR) and local escaping operator (LEO) and a set of vectors to explore the search space. The GSR employs the gradient-based method to enhance the exploration tendency and accelerate the convergence rate to achieve better positions in the search space. The LEO enables the proposed GBO to escape from local optima. The performance of the new algorithm was evaluated in two phases. 28 mathematical test functions were first used to evaluate various characteristics of the GBO, and then six engineering problems were optimized by the GBO. In the first phase, the GBO was compared with five existing optimization algorithms, indicating that the GBO yielded very promising results due to its enhanced capabilities of exploration, exploitation, convergence, and effective avoidance of local optima. The second phase also demonstrated the superior performance of the GBO in solving complex real-world engineering problems. Source codes of the GBO algorithm are publicly available at http://imanahmadianfar.com/codes/ .},
  archive      = {J_ISCI},
  author       = {Iman Ahmadianfar and Omid Bozorg-Haddad and Xuefeng Chu},
  doi          = {10.1016/j.ins.2020.06.037},
  journal      = {Information Sciences},
  pages        = {131-159},
  shortjournal = {Inf. Sci.},
  title        = {Gradient-based optimizer: A new metaheuristic optimization algorithm},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hierarchical deep convolutional neural network and gated
recurrent unit framework for structural damage detection. <em>ISCI</em>,
<em>540</em>, 117–130. (<a
href="https://doi.org/10.1016/j.ins.2020.05.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural damage detection has become an interdisciplinary area of interest for various engineering fields, while the available damage detection methods are being in the process of adapting machine learning concepts. Most machine learning based methods heavily depend on extracted “hand-crafted” features that are manually selected in advance by domain experts and then, fixed. Recently, deep learning has demonstrated remarkable performance on traditional challenging tasks, such as image classification , object detection, etc., due to the powerful feature learning capabilities. This breakthrough has inspired researchers to explore deep learning techniques for structural damage detection problems. However, existing methods have considered either spatial relation (e.g., using convolutional neural network (CNN)) or temporal relation (e.g., using long short term memory network (LSTM)) only. In this work, we propose a novel Hierarchical CNN and Gated recurrent unit (GRU) framework to model both spatial and temporal relations, termed as HCG, for structural damage detection. Specifically, CNN is utilized to model the spatial relations and the short-term temporal dependencies among sensors, while the output features of CNN are fed into the GRU to learn the long-term temporal dependencies jointly. Extensive experiments on IASC-ASCE structural health monitoring benchmark and scale model of three-span continuous rigid frame bridge structure datasets have shown that our proposed HCG outperforms other existing methods for structural damage detection significantly.},
  archive      = {J_ISCI},
  author       = {Jianxi Yang and Likai Zhang and Cen Chen and Yangfan Li and Ren Li and Guiping Wang and Shixin Jiang and Zeng Zeng},
  doi          = {10.1016/j.ins.2020.05.090},
  journal      = {Information Sciences},
  pages        = {117-130},
  shortjournal = {Inf. Sci.},
  title        = {A hierarchical deep convolutional neural network and gated recurrent unit framework for structural damage detection},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensembles of feature selectors for dealing with
class-imbalanced datasets: A proposal and comparative study.
<em>ISCI</em>, <em>540</em>, 89–116. (<a
href="https://doi.org/10.1016/j.ins.2020.05.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important task in many machine learning and data mining problems. Due to the increasing size of datasets, the removal of redundant, erroneous or noisy features is frequently an initial step. In many common applications, datasets have imbalanced class distribution. Although feature selection suffers in the presence of an uneven distribution of samples among the classes, there are few methods specifically designed for this situation. We propose a new approach based on the use of feature selection boosting to address this problem. Ensembles of feature selectors using both, standard and specifically designed for class-imbalanced datasets methods, are constructed using boosting algorithms,. These ensembles are used to perform feature selection in class-imbalanced datasets. The combination of different rounds of feature selectors over different samples with an adaptive distribution of the instances achieves an improved performance when compared with standard feature selection methods in class-imbalanced datasets. A comprehensive set of experiments that employ 18 different ensemble methods , 7 different feature selection methods and 140 class-imbalanced datasets demonstrates the efficiency of the ensemble approach in terms of reduction ability and classification performance. Further study of the proposed method shows its robustness in the presence of class label noise.},
  archive      = {J_ISCI},
  author       = {Aida de Haro-García and Gonzalo Cerruela-García and Nicolás García-Pedrajas},
  doi          = {10.1016/j.ins.2020.05.077},
  journal      = {Information Sciences},
  pages        = {89-116},
  shortjournal = {Inf. Sci.},
  title        = {Ensembles of feature selectors for dealing with class-imbalanced datasets: A proposal and comparative study},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incorporating a multiobjective knowledge-based energy
function into differential evolution for protein structure prediction.
<em>ISCI</em>, <em>540</em>, 69–88. (<a
href="https://doi.org/10.1016/j.ins.2020.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid development of computer techniques and the unremitting efforts of researchers, the protein structure prediction (PSP) problem remains challenging in computational biology and bioinformatics. In this study, we model the PSP problem as a multiobjective optimization problem and propose a free modeling approach called MODE-K to solve this problem. Our efforts center on two aspects. First, we use a knowledge-based energy function called RWplus as the evaluation criterion. This function is decomposed into two terms: a distance-dependent energy term and an orientation-dependent energy term. Second, we employ a multiobjective differential evolution coupled with an external archive to perform conformation space searching. After conformation space searching, a cluster method is introduced to select the final predicted structure from a set of decoy structures. We use eighteen test proteins to verify the performance of the proposed approach. The experimental results demonstrate the effectiveness of the proposed approach and indicate that incorporating knowledge-based energy functions into multiobjective approaches to solve the PSP problem is promising.},
  archive      = {J_ISCI},
  author       = {Xingqian Chen and Shuangbao Song and Junkai Ji and Zheng Tang and Yuki Todo},
  doi          = {10.1016/j.ins.2020.06.003},
  journal      = {Information Sciences},
  pages        = {69-88},
  shortjournal = {Inf. Sci.},
  title        = {Incorporating a multiobjective knowledge-based energy function into differential evolution for protein structure prediction},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Task offloading for directed acyclic graph applications
based on edge computing in industrial internet. <em>ISCI</em>,
<em>540</em>, 51–68. (<a
href="https://doi.org/10.1016/j.ins.2020.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an increase in the number of devices involved in the Industrial Internet, effectively combining the characteristics of industrial scenarios with an edge computing methodology for computation-intensive applications poses a critical challenge. This paper proposes an integrated architecture that allows industrial devices to offload tasks to cloud or edge servers. An offloading problem is also formulated into an energy-cost (EC) minimization problem while satisfying the deadline constraint. To solve the optimization problem , two types of offloading algorithms, namely ASO and Pro-ITGO, are proposed based on the integrated architecture. The ASO algorithm is a lightweight linear programming algorithm that includes subdeadline allocation, topology sorting, and task offloading sub-algorithms. The Pro-ITGO algorithm is a group intelligence heuristic algorithm that is derived from the original ITGO algorithm adapting the offloading scenarios of the Industrial Internet. Experimental results demonstrate that compared with state-of-the-art heuristic algorithms, the proposed algorithms can effectively reduce the energy consumption of industrial devices and cloud computing costs.},
  archive      = {J_ISCI},
  author       = {Lei Yang and Changyi Zhong and Qiuhui Yang and Wanrong Zou and Ahmed Fathalla},
  doi          = {10.1016/j.ins.2020.06.001},
  journal      = {Information Sciences},
  pages        = {51-68},
  shortjournal = {Inf. Sci.},
  title        = {Task offloading for directed acyclic graph applications based on edge computing in industrial internet},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Addressing time bias in bipartite graph ranking for
important node identification. <em>ISCI</em>, <em>540</em>, 38–50. (<a
href="https://doi.org/10.1016/j.ins.2020.05.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For online service platforms such as Netflix, it is important to propose a list of high quality movies to their users. This type of problem can be regarded as a ranking problem in a bipartite network. This is a well-known problem, that can be solved by a ranking algorithm. However, many classical ranking algorithms share a common drawback: they tend to rank higher older movies rather than newer ones, though some new movies may be of higher quality. In the study, we develop a ranking method using a rebalance approach to decrease the time bias of the rankings in bipartite graphs . We then conduct experiments on three real datasets with ground truth benchmark. The results show that our proposed method not only reduces the time bias of the ranking scores, but also improves the prediction accuracy by at least 20\%, and up to 80\%.},
  archive      = {J_ISCI},
  author       = {Hao Liao and Jiao Wu and Yifan Mao and Mingyang Zhou and Alexandre Vidmer and Kezhong Lu},
  doi          = {10.1016/j.ins.2020.05.120},
  journal      = {Information Sciences},
  pages        = {38-50},
  shortjournal = {Inf. Sci.},
  title        = {Addressing time bias in bipartite graph ranking for important node identification},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SPAMI: A cognitive spam protector for advertisement
malicious images. <em>ISCI</em>, <em>540</em>, 17–37. (<a
href="https://doi.org/10.1016/j.ins.2020.05.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern era, the graphical information is presented in the form of web images. As the dependency of human beings on web information is increasing day-by-day, so the spammers are injecting spam by adopting new spamming techniques. Image spam is a spamming technique that integrates spam text contents into graphical images in order to bypass conventional text-based spam filters . The spam images are of various categories, such as redirection spam, advertisement spam, fake review, and content spam. In order to detect image spam efficiently, it is important to analyze the features of the image data. However, the existing image spam detection techniques in literature focused on textual or graphic features of the image. Moreover, to extract the relevant features from the images is also a challenging task. So, to fill these gaps, in this paper, we propose a Spam Protector for Advertisement of Malicious Images (SPAMI) framework using features extraction by browsing different websites and webpages. SPAMI is a cognitive spam protector which labels the spam advertisement images by using deep learning models. Three deep learning models are used for the same, i.e., CNN , RNN , and LSTM . The regress analysis of output from these models is done in the proposed SPAMI framework. Finally, we analysed the labels (Advertisement, Suspicious, Normal) for all the 600 images collected. The accuracy obtained from these models is 95\% with real-time collected images, which improved up to 97\% when tested with ”Image Spam Hunter” dataset.},
  archive      = {J_ISCI},
  author       = {Aaisha Makkar and Neeraj Kumar and Albert Y Zomaya and Shalini Dhiman},
  doi          = {10.1016/j.ins.2020.05.113},
  journal      = {Information Sciences},
  pages        = {17-37},
  shortjournal = {Inf. Sci.},
  title        = {SPAMI: A cognitive spam protector for advertisement malicious images},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed stochastic configuration networks with
cooperative learning paradigm. <em>ISCI</em>, <em>540</em>, 1–16. (<a
href="https://doi.org/10.1016/j.ins.2020.05.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new category of randomized neural networks (RNNs), stochastic configuration networks (SCNs) have demonstrated great potential for data analytics. Unlike conventional randomized learning techniques, e.g., random vector functional-link (RVFL) networks, SCNs provide a stochastic configuration mechanism on the assignment of input parameters which guarantees the universal approximation capability of a resulting learner model. In this paper, a distributed version of SCN is developed for decentralized datasets in cooperative learning paradigm. This paper proposes an approach to deal with datasets stored across a network of multiple learning agents without any fusion center. Specifically, we formulate the centralized learning problem as an equivalent form with the decomposition of subproblems coupled in a network and a consensus restriction. Then, a cooperative configuration scheme is proposed for randomly assigning the input weights and bias. Finally, based on the well-known parallel alternating direction method of multipliers (ADMM), the output weights are evaluated iteratively. Simulation studies with comparisons on three benchmark datasets are carried out. The experimental results indicate that our proposed learning scheme performs well and outperforms distributed RVFL networks.},
  archive      = {J_ISCI},
  author       = {Wu Ai and Dianhui Wang},
  doi          = {10.1016/j.ins.2020.05.112},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {Distributed stochastic configuration networks with cooperative learning paradigm},
  volume       = {540},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LGSLRR: Towards fusing discriminative ordinal local and
global structured low-rank representation for image recognition.
<em>ISCI</em>, <em>539</em>, 522–535. (<a
href="https://doi.org/10.1016/j.ins.2020.05.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural information extraction has been a focal technique in many classification applications, such as image recognition and biometrics . However, it remains a challenge to simultaneously utilize local and global structural information in a classification model . In addition, in terms of the local information, the existing methods mainly seek to extract or preserve the first-order structure while ignoring the useful ordinal structural information for classification. To this end, this paper presents a discriminative ordinal local and global structured low-rank representation (LGSLRR) model that jointly preserves the local ordinal structure and global structure for image recognition. A discriminative block-diagonal low-rank representation is employed to obtain global information while the first-order and second-order local information is preserved by a joint graph based manifold embedding with two different Laplacian matrices . Some extensive comparison experiments on ten public image datasets are performed, and the results demonstrate the effectiveness and significant performance of the proposed method over some state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Qi Zhu and Rui Zhang and Sheng-Jun Huang and Zheng Zhang and Daoqiang Zhang},
  doi          = {10.1016/j.ins.2020.05.117},
  journal      = {Information Sciences},
  pages        = {522-535},
  shortjournal = {Inf. Sci.},
  title        = {LGSLRR: Towards fusing discriminative ordinal local and global structured low-rank representation for image recognition},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure bipartite tracking control of a class of nonlinear
multi-agent systems with nonsymmetric input constraint against sensor
attacks. <em>ISCI</em>, <em>539</em>, 504–521. (<a
href="https://doi.org/10.1016/j.ins.2020.05.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a secure bipartite tracking control problem for a class of nonlinear multi-agents (MASs) with nonsymmetric input constraints. In the presence of adversarial sensor attacks, a secure measurement preselector , along with an explicit sufficient condition, and a neural network (NN) secure state observer are introduced for achieving secure state estimation. Then, a secure bipartite tracking control strategy is proposed, where observation predictors are designed to reconstruct prediction errors in such a way as to improve control performance. Furthermore, an auxiliary system is presented to eliminate influence from nonsymmetric input saturations. It is theoretically proved that the proposed control strategy not only guarantees bipartite tracking of the MAS but also preserves the stability of the resulting closed-loop system in spite of senor attacks. Finally, two illustrative examples are presented to verify the effectiveness of the obtained results.},
  archive      = {J_ISCI},
  author       = {Yang Yang and Qidong Liu and Yue Qian and Dong Yue and Xiaohua Ding},
  doi          = {10.1016/j.ins.2020.05.086},
  journal      = {Information Sciences},
  pages        = {504-521},
  shortjournal = {Inf. Sci.},
  title        = {Secure bipartite tracking control of a class of nonlinear multi-agent systems with nonsymmetric input constraint against sensor attacks},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy PID controller with nonlinear compensation term for
mold level of continuous casting process. <em>ISCI</em>, <em>539</em>,
487–503. (<a href="https://doi.org/10.1016/j.ins.2020.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mold level is the key to stable continuous casting production process, and its fluctuation determines the quality of the slab. It is of great economic and scientific value to stabilize the mold level in numerous disturbances and complicated operating modes. To achieve high-precision and fast-response control of mold level control in engineering applications , a fuzzy PID controller with nonlinear compensation term is designed in this paper. By analyze the dynamic characteristics of the mold level, a fuzzy PID controller is designed. The parameters of fuzzy controller is optimized by using PSO algorithm, which achieves a better control effect in abnormal operating conditions. More importantly, a nonlinear compensation term is introduced to compensate the output of the fuzzy PID controller, thus further improving the anti-interference ability of the system. To verify the superiority of our method, a series of simulation studies are carried out. Finally, the method is applied to industrial sites. The running results show that, compared with the traditional control method , our method effectively improves the anti-interference ability under normal operating conditions and better suppresses the fluctuation of casting opening.},
  archive      = {J_ISCI},
  author       = {Ying Feng and Min Wu and Xin Chen and Luefeng Chen and Sheng Du},
  doi          = {10.1016/j.ins.2020.06.024},
  journal      = {Information Sciences},
  pages        = {487-503},
  shortjournal = {Inf. Sci.},
  title        = {A fuzzy PID controller with nonlinear compensation term for mold level of continuous casting process},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DE-ada*: A novel model for breast mass classification using
cross-modal pathological semantic mining and organic integration of
multi-feature fusions. <em>ISCI</em>, <em>539</em>, 461–486. (<a
href="https://doi.org/10.1016/j.ins.2020.05.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided breast mass classification is an effective and widely used technology to assist pathologists in formulating clinical diagnoses and improving working efficiencies. Existing studies usually use a single image feature to perform breast mass classification. Herein, we propose a simple, yet effective, model called the DE-Ada*, which is an organic integration of multi-feature fusions, for breast mass classification. Firstly, we extract a set of complementary features, namely, scale-invariant feature transform (SIFT), GIST, histogram of oriented gradient (HOG), local binary pattern (LBP), residual network (ResNet), densely connected convolutional networks (DenseNet), and visual geometry group (VGG), to characterize mammograms from diverse perspectives. We attempt to mine the cross-modal pathological semantics among these features and complete their early fusion. The dynamic weight of any feature or cross-modal pathological semantics is computed and utilized to complete mid-level feature fusion. Finally, we design two voting-based ensemble learning strategies to implement late feature fusion. Our experiments demonstrate that the DE-Ada* model outperforms baselines on two well-known mammographic datasets. Our model encourages the use of cross-modal pathological semantics to deal with the overfitting problem.},
  archive      = {J_ISCI},
  author       = {Hongbin Zhang and Renzhong Wu and Tian Yuan and Ziliang Jiang and Song Huang and Jinpeng Wu and Jin Hua and Zhengyu Niu and Donghong Ji},
  doi          = {10.1016/j.ins.2020.05.080},
  journal      = {Information Sciences},
  pages        = {461-486},
  shortjournal = {Inf. Sci.},
  title        = {DE-ada*: A novel model for breast mass classification using cross-modal pathological semantic mining and organic integration of multi-feature fusions},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gradient descent evolved imbalanced data gravitation
classification with an application on internet video traffic
identification. <em>ISCI</em>, <em>539</em>, 447–460. (<a
href="https://doi.org/10.1016/j.ins.2020.05.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, the increasing video traffic, especially illegal videos brought big challenges for Internet management. Generally, abnormal videos, such as illegal videos only account for a small percentage which makes the detection of such videos to be a typical imbalanced classification problem. In this study, we propose a new imbalanced learning method, namely, the imbalanced data gravitation classification model based the gradient descent (IDGC-GD), to handle imbalanced problems. In IDGC-GD model, we use the gradient descent algorithm to optimize feature weights of the imbalanced data gravitation classification (IDGC) model. Then, we try to build an accurate video traffic identification solution using IDGC-GD. We conduct a set of comparing experiments between IDGC-GD and seven imbalanced learning algorithms using 21 open data sets and four video traffic data sets collected from the real application. Experimental results show that our method is promising for solving imbalanced problems, including Internet video traffic identification.},
  archive      = {J_ISCI},
  author       = {Anqi Teng and Lizhi Peng and Yuxi Xie and Haibo Zhang and Zhenxiang Chen},
  doi          = {10.1016/j.ins.2020.05.141},
  journal      = {Information Sciences},
  pages        = {447-460},
  shortjournal = {Inf. Sci.},
  title        = {Gradient descent evolved imbalanced data gravitation classification with an application on internet video traffic identification},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). H∞ state estimation for multi-rate artificial neural
networks with integral measurements: A switched system approach.
<em>ISCI</em>, <em>539</em>, 434–446. (<a
href="https://doi.org/10.1016/j.ins.2020.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the H ∞ H∞ state estimation problem is studied for a class of multi-rate artificial neural networks with integral measurements. A novel method, rather than the widely used lifting technique, is proposed to transform the multi-rate artificial neural networks to single-rate switched ones. The purpose of the addressed H ∞ H∞ state estimation problem is to design an estimator such that the estimation error dynamics is exponentially stable and the H ∞ H∞ performance requirement is satisfied. First, with the help of the Lyapunov–Krasovskii functional and the switched system approach, sufficient conditions are derived under which the existence of the desired estimator is ensured. Then, the characterization of the estimator gains is realized by solving certain linear matrix inequalities. Finally, two illustrative examples are given that confirm the usefulness of the developed H ∞ H∞ state estimation scheme and reveal the influence of the multi-rate sampling on the state estimation performance.},
  archive      = {J_ISCI},
  author       = {Yuxuan Shen and Zidong Wang and Bo Shen and Fuad E. Alsaadi},
  doi          = {10.1016/j.ins.2020.06.021},
  journal      = {Information Sciences},
  pages        = {434-446},
  shortjournal = {Inf. Sci.},
  title        = {H∞ state estimation for multi-rate artificial neural networks with integral measurements: A switched system approach},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Transferable attention networks for adversarial domain
adaptation. <em>ISCI</em>, <em>539</em>, 422–433. (<a
href="https://doi.org/10.1016/j.ins.2020.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation is one of the fundamental challenges in transfer learning . How to effectively transfer knowledge from labeled source domain to unlabeled target domain is critical for domain adaptation, as it benefits to reduce the considerable performance gap due to domain shift. Existing methods of domain adaptation address this issue via matching the global features across domains. However, not all features are transferable for domain adaptation, while forcefully matching the untransferable features may lead to negative transfer. In this paper, we propose a novel method dubbed transferable attention networks (TAN) to address this issue. The proposed TAN focuses on the feature alignment by utilizing adversarial optimization. Specifically, we utilize the self-attention mechanism to weight extracted features, such that the influence of untransferable features can be effectively eliminated. Meanwhile, to exploit the complex multi-modal structures of domain adaptation, we use learned features and classifier predictions as the condition to train the adversarial networks. Furthermore, we further propose that the accurately transferable features should enable domain discrepancy to minimum. Three loss functions are introduced into the adversarial networks: classification loss, attention transfer loss, and condition transfer loss. Extensive experiments on Office-31, ImageCLEF-DA, Office-Home, and VisDA-2017 datasets testify that the proposed approach yields state-of-the-art results.},
  archive      = {J_ISCI},
  author       = {Changchun Zhang and Qingjie Zhao and Yu Wang},
  doi          = {10.1016/j.ins.2020.06.016},
  journal      = {Information Sciences},
  pages        = {422-433},
  shortjournal = {Inf. Sci.},
  title        = {Transferable attention networks for adversarial domain adaptation},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). TOPSIS-WAA method based on a covering-based fuzzy rough
set: An application to rating problem. <em>ISCI</em>, <em>539</em>,
397–421. (<a href="https://doi.org/10.1016/j.ins.2020.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we firstly study two pairs of covering-based fuzzy rough set models and propose the TOPSIS-WAA method based on a covering-based fuzzy rough set . Subsequently, we design a rating scheme based on a multi-criteria decision-making method in a finite fuzzy covering approximation space. The rating scheme is implemented based on the preset subjective ratio and the calculated objective ranking of all alternatives. Furthermore, we use the relevant data of some customers of Industrial and Commercial Bank of China (ICBC) to illustrate the feasibility of our method. At the same time, two test rules are used to verify the validity of the proposed method. Moreover, we compare five different decision-making methods with our method to demonstrate the superiority of our method. Finally, the performance of our method is verified from the perspectives of the best alternative and the optimal ranking.},
  archive      = {J_ISCI},
  author       = {Kai Zhang and Jianming Zhan and Xizhao Wang},
  doi          = {10.1016/j.ins.2020.06.009},
  journal      = {Information Sciences},
  pages        = {397-421},
  shortjournal = {Inf. Sci.},
  title        = {TOPSIS-WAA method based on a covering-based fuzzy rough set: An application to rating problem},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). And-like-uninorm-based transitivity and analytic hierarchy
process with interval-valued fuzzy preference relations. <em>ISCI</em>,
<em>539</em>, 375–396. (<a
href="https://doi.org/10.1016/j.ins.2020.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The framework of interval-valued fuzzy preference relations (IVFPRs) is adequate and effective to model human preference evaluations under indeterminacy. This paper analyzes three recently presented multiplicative transitivity models of IVFPRs and exposes their drawbacks. An and-like-uninorm-based functional transitivity equation is developed to introduce a multiplicative consistency notion for IVFPRs. Based on the transitivity logarithmic equation, a geometric-consistency index is further proposed to compute the inconsistency level of an IVFPR. The paper builds a logarithmic least squares model with row indeterminacy constraints and equivalently transforms it into a quadratic programming model for finding a closed-form solution of the normalized interval-valued fuzzy weights of IVFPRs. A novel method is subsequently presented to check the acceptability of an IVFPR by examining its acceptable consistency and acceptable indeterminacy. An approach including an and-like-uninorm-based maximization model is introduced to aggregate local interval-valued fuzzy weights and an interval fuzzy analytic hierarchy process is designed step-by-step. An illustrative example and a comparison study are utilized to demonstrate the performance and merits of the presented models. Meanwhile, an outstanding undergraduate student selection problem in international exchange is provided to show the application of the proposed decision method.},
  archive      = {J_ISCI},
  author       = {Zhou-Jing Wang and Xuan Yang and Xiao-Tong Jin},
  doi          = {10.1016/j.ins.2020.05.052},
  journal      = {Information Sciences},
  pages        = {375-396},
  shortjournal = {Inf. Sci.},
  title        = {And-like-uninorm-based transitivity and analytic hierarchy process with interval-valued fuzzy preference relations},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A hybrid method integrating an elite genetic algorithm with
tabu search for the quadratic assignment problem. <em>ISCI</em>,
<em>539</em>, 347–374. (<a
href="https://doi.org/10.1016/j.ins.2020.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quadratic Assignment Problem (QAP) is one of the most studied classical combinatorial optimization problems . QAP has many practical applications. Designing enhanced meta-heuristic approaches for the QAP is an active research area. In this work, we propose a hybrid algorithm (EGATS) that combines an elite genetic algorithm and tabu search to solve the QAP. In the optimization process, EGATS employs two kinds of elite crossovers, repeated 2-exchange mutation, and tabu search to strike a balance between exploitation and exploration. We evaluated the performance of EGATS through computational experiments on 135 well-known benchmark instances from the quadratic assignment problem library, QAPLIB. EGATS obtained the best-known solution for 131 instances. Compared to other popular meta-heuristic algorithms in the literature, EGATS is a competitive method for the QAP.},
  archive      = {J_ISCI},
  author       = {Huizhen Zhang and Fan Liu and Yuyang Zhou and Ziying Zhang},
  doi          = {10.1016/j.ins.2020.06.036},
  journal      = {Information Sciences},
  pages        = {347-374},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid method integrating an elite genetic algorithm with tabu search for the quadratic assignment problem},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A guidance framework for synthesis of multi-core
reconfigurable real-time systems. <em>ISCI</em>, <em>539</em>, 327–346.
(<a href="https://doi.org/10.1016/j.ins.2020.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multi-core architectures are being more and more used in the design of real-time systems. Those systems react usually to their environment that requires to amend their behaviors by applying reconfiguration scenarios. This paper deals with multi-core reconfigurable real-time systems that should be adapted to their environment under real-time constraints. Meanwhile, their synthesis induces a heavy system code and time overhead due to a huge number of threads. The setting up of those systems involves many stages: i) definition of system functionalities, ii) generating of tasks, iii) placement and scheduling of tasks, and iv) generating system code. Correct transition among these steps has an impact on the final system implementation. Thus the need of a designer’s experience is definitely required. However, many problems related to design decisions can be caused due to the complexity of real-time analysis, scheduling, and placement. Those problems may conduct to infeasible implementations. The proposed approach presents a guidance framework to avoid these problems from specification to code generation. This framework is performed by mixed-integer linear programming. It aims to resolve a task partitioning/scheduling problem while optimizing some metrics. The viability of the proposed framework is illustrated by a case study and performance evaluation.},
  archive      = {J_ISCI},
  author       = {Wafa Lakhdhar and Rania Mzid and Mohamed Khalgui and Georg Frey and Zhiwu Li and MengChu Zhou},
  doi          = {10.1016/j.ins.2020.06.005},
  journal      = {Information Sciences},
  pages        = {327-346},
  shortjournal = {Inf. Sci.},
  title        = {A guidance framework for synthesis of multi-core reconfigurable real-time systems},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel matrix-based approaches to computing minimal and
maximal descriptions in covering-based rough sets. <em>ISCI</em>,
<em>539</em>, 312–326. (<a
href="https://doi.org/10.1016/j.ins.2020.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimal and maximal descriptions of concepts are two important notions in covering-based rough sets. Many issues in covering-based rough sets (e.g., reducts, approximations , etc.) are related to them. It is well known that, it is time-consuming and error-prone when set representations are used to compute minimal and maximal descriptions in a large scale covering approximation space. To address this problem, matrix-based methods have been proposed in which calculations can be conveniently implemented by computers. In this paper, motivated by the need for knowledge discovery from large scale covering information systems and inspired by the previous research work, we present two novel matrix-based approaches to compute minimal and maximal descriptions in covering-based rough sets, which can reduce the computational complexity of traditional methods. First, by introducing the operation “sum” into the calculation of matrix instead of the operation “ ⊕ ⊕ ”, we propose a new matrix-based approach, called approach-1, to compute minimal and maximal descriptions, which does not need to compare the elements in two matrices. Second, by using the binary relation of inclusion between elements in a covering, we propose another approach to compute minimal and maximal descriptions. Finally, we present experimental comparisons showing the computational efficiency of the proposed approaches on six UCI datasets. Experimental results show that the proposed approaches are promising and comparable with other tested methods.},
  archive      = {J_ISCI},
  author       = {Caihui Liu and Kecan Cai and Duoqian Miao and Jin Qian},
  doi          = {10.1016/j.ins.2020.06.022},
  journal      = {Information Sciences},
  pages        = {312-326},
  shortjournal = {Inf. Sci.},
  title        = {Novel matrix-based approaches to computing minimal and maximal descriptions in covering-based rough sets},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Verifiable inner product computation on outsourced database
for authenticated multi-user data sharing. <em>ISCI</em>, <em>539</em>,
295–311. (<a href="https://doi.org/10.1016/j.ins.2020.05.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of cloud computing , the practical applications such as the machine learning based on the outsourced data have been investigated in the data sharing setting. In machine learning , the inner product is a necessary primitive to analyze the description statistics . However, the inner product computation in selective data sharing setting has not been fully considered. For this fact, we propose a verifiable inner product computation scheme based on Inner Product Functional Encryption (IPFE). IPFE is employed to preserve the outsourced data privacy and restrict the computation on the outsourced data to be inner product. To achieve the key privacy and result privacy, we transform the secret key into blinded form, which in turn results in a blinded result. With the aim of implementing access control over the data user and outsourced data, we design to let cloud server perform the authentication procedures before computing inner product. This can also eliminate most computational overhead resulting from the unauthorized data user and undesired data. As a result, only the authorized data user can obtain the inner product computed on the designated outsourced data. The proposed scheme is proved to be secure under the authentication model and the result unforgeability model. The performance evaluation shows that the proposed scheme is feasible. To achieve a better security level , the proposed scheme is extended to be secure against the corrupted cloud server.},
  archive      = {J_ISCI},
  author       = {Haining Yang and Ye Su and Jing Qin and Huaxiong Wang and Yongcheng Song},
  doi          = {10.1016/j.ins.2020.05.118},
  journal      = {Information Sciences},
  pages        = {295-311},
  shortjournal = {Inf. Sci.},
  title        = {Verifiable inner product computation on outsourced database for authenticated multi-user data sharing},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-attentional bracket-shaped convolutional network for
semantic image segmentation. <em>ISCI</em>, <em>539</em>, 277–294. (<a
href="https://doi.org/10.1016/j.ins.2020.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As perception-related applications are of great importance in industrial production and daily life nowadays, solutions for understanding given images semantically receive numerous attention from the literature. To this end, significant accomplishments have been reached for such pixel-wise segmentation problem thanks to novel manipulations of integrating global context into local details in convolutional neural networks. However, this strategy in the existing work did not exhaustively exploit middle-level features, which carry reasonable balance between fine-grained and semantic information. Therefore, this paper introduces a Cross-Attentional Bracket-shaped Convolutional Network (CAB-Net) to leverage their contribution to the tournament of constructing pixel-wise labeled map. In concrete, fine-to-coarse feature maps of interest from the backbone network are densely combined by an efficient fusion of channel-wisely and spatially attentional schemes in crossing manner, namely Cross-Attentional Fusion, to embed semantically rich features into finer patterns. Continuously, these newly decoded outputs repeat the same procedure round-by-round until shaping a final feature map having finest resolution for complete scene understanding. Consequently, the proposed CAB-Net achieves competitive mean Intersection of Union performance on PASCAL VOC 2012 (83.6\% without MS-COCO pretraining), CamVid (76.4\%) and Cityscapes (78.3\%) datasets.},
  archive      = {J_ISCI},
  author       = {Cam-Hao Hua and Thien Huynh-The and Sung-Ho Bae and Sungyoung Lee},
  doi          = {10.1016/j.ins.2020.06.023},
  journal      = {Information Sciences},
  pages        = {277-294},
  shortjournal = {Inf. Sci.},
  title        = {Cross-attentional bracket-shaped convolutional network for semantic image segmentation},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representation of nullnorms on bounded lattices.
<em>ISCI</em>, <em>539</em>, 269–276. (<a
href="https://doi.org/10.1016/j.ins.2020.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently nullnorms on bounded lattices have been frequently investigated by many researchers. In this paper, we give the full characterization for quite a general class of nullnorms on bounded lattices and represent them by their underlying t-norms and t-conorms. An example is given to show the relationship between each block of the nullnorms. We also fully determine the values of arbitrary nullnorms when only one of the two variables is comparable with the absorbing elements. For the rest cases, we give some necessary conditions.},
  archive      = {J_ISCI},
  author       = {Xiang-Rong Sun and Hua-Wen Liu},
  doi          = {10.1016/j.ins.2020.06.013},
  journal      = {Information Sciences},
  pages        = {269-276},
  shortjournal = {Inf. Sci.},
  title        = {Representation of nullnorms on bounded lattices},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-stream feature aggregation deep neural network for scene
classification of remote sensing images. <em>ISCI</em>, <em>539</em>,
250–268. (<a href="https://doi.org/10.1016/j.ins.2020.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene classification of high-spatial resolution (HSR) images has a wide range of potential applications in various fields, and it has become a research hotspot in remote sensing community. Recently, deep transfer learning-based methods have attracted tremendous attention due to powerful ability of feature extraction. In this paper, a novel architecture termed two-stream feature aggregation deep neural network (TFADNN) is developed for HSR scene classification. The TFADNN method contains two parallel parts, including the stream of discriminative features and the stream of general features. In the first stream, the fully connected layers of pre-trained CNNs are replaced by a global average pooling layer to remove the limitation on the size of input images. As for the second stream, the multi-scale nonlinear encoding based bag-of-visual-words (MNBoVW) model is proposed to process convolutional features, and the global representations can be obtained. Then, weighted fusion is adopted to integrate two-stream features. As a result, the TFADNN method can learn the discriminative features from HSR images with arbitrary sizes, and the experimental results on two challenging datasets indicate that the TFADNN method achieves satisfactory classification performance compared with some state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Kejie Xu and Hong Huang and Peifang Deng and Guangyao Shi},
  doi          = {10.1016/j.ins.2020.06.011},
  journal      = {Information Sciences},
  pages        = {250-268},
  shortjournal = {Inf. Sci.},
  title        = {Two-stream feature aggregation deep neural network for scene classification of remote sensing images},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). WOTS-s: A quantum secure compact signature scheme for
distributed ledger. <em>ISCI</em>, <em>539</em>, 229–249. (<a
href="https://doi.org/10.1016/j.ins.2020.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital signature scheme, which underpins most of the existing distributed ledgers, is generally based on non-quantum-resilient algorithms (e.g. elliptic curve digital signature algorithm). This highlights the need for quantum-secure signature schemes in future distributed ledgers (and other products). Therefore, in this paper, we propose a novel quantum-secure digital signature scheme designed specifically for cryptocurrencies . Our proposed scheme is a hash-based signature scheme, which is a variant of Winternitz-one time signature scheme. A comparison of the proposed scheme and two other competing quantum-secure cryptocurrencies (IoTA and QRL) reveals that our scheme respectively achieves 59\% and 24\% reductions in signature lengths without compromising the level of security. A salient feature of the proposed approach is that, unlike the previously proposed variants of Winternitz scheme, we avoid the need for any expensive computation. In addition, we formally model the classical cryptocurrency and the proposed quantum-secure cryptocurrency using high-level Petri-nets, which allows the implementer to understand their workings in the presence of a quantum attacker. Furthermore, we also provide formal security proof in the random oracle model .},
  archive      = {J_ISCI},
  author       = {Furqan Shahid and Abid Khan and Saif Ur Rehman Malik and Kim-Kwang Raymond Choo},
  doi          = {10.1016/j.ins.2020.05.024},
  journal      = {Information Sciences},
  pages        = {229-249},
  shortjournal = {Inf. Sci.},
  title        = {WOTS-S: A quantum secure compact signature scheme for distributed ledger},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Similarity and diversity induced paired projection for
cross-modal retrieval. <em>ISCI</em>, <em>539</em>, 215–228. (<a
href="https://doi.org/10.1016/j.ins.2020.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneous gap among cross modalities is a critical problem in many applications (e.g., retrieval). Considering that the main purpose of cross-modal learning is to learn a common representation while there also exist specific components across different modalities, a similarity and diversity induced paired projection (SDPP) method is proposed in this paper. SDPP not only extracts the correlation in a common subspace, but also removes the view-specific information which does not contribute to our task. In order to model the specific components, the Hilbert Schmidt Independence Criterion (HSIC) is introduced as a co-regularization to explicitly enforce the diversity. Additionally, different from some existing subspace learning methods which are time consuming in the testing phase, a paired projection strategy is exploited, being capable of obtaining the similar information in a simple but effective way. To optimize the presented approach, an efficient algorithm is designed to update different variables alternatively. Finally, we apply our strategy to the cross-modal retrieval, and experimental results on several real-world datasets substantiate the effectiveness and superiority of our model compared with other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jinxing Li and Mu Li and Guangming Lu and Bob Zhang and Hongpeng Yin and David Zhang},
  doi          = {10.1016/j.ins.2020.06.032},
  journal      = {Information Sciences},
  pages        = {215-228},
  shortjournal = {Inf. Sci.},
  title        = {Similarity and diversity induced paired projection for cross-modal retrieval},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image encryption algorithm based on the matrix semi-tensor
product with a compound secret key produced by a boolean network.
<em>ISCI</em>, <em>539</em>, 195–214. (<a
href="https://doi.org/10.1016/j.ins.2020.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a chaotic image encryption algorithm based on the matrix semi-tensor product (STP) with a compound secret key is designed. First, a new scrambling method is designed. The pixels of the initial plaintext image are randomly divided into four blocks. The pixels in each block are then subjected to different numbers of rounds of Arnold transformation, and the four blocks are combined to generate a scrambled image. Then, a compound secret key is designed. A set of pseudosecret keys is given and filtered through a synchronously updating Boolean network to generate the real secret key. This secret key is used as the initial value of the mixed linear-nonlinear coupled map lattice (MLNCML) system to generate a chaotic sequence . Finally, the STP operation is applied to the chaotic sequences and the scrambled image to generate an encrypted image. Compared with other encryption algorithms, the algorithm proposed in this paper is more secure and effective, and it is also suitable for color image encryption .},
  archive      = {J_ISCI},
  author       = {Xingyuan Wang and Suo Gao},
  doi          = {10.1016/j.ins.2020.06.030},
  journal      = {Information Sciences},
  pages        = {195-214},
  shortjournal = {Inf. Sci.},
  title        = {Image encryption algorithm based on the matrix semi-tensor product with a compound secret key produced by a boolean network},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sample generation based on a supervised wasserstein
generative adversarial network for high-resolution remote-sensing scene
classification. <em>ISCI</em>, <em>539</em>, 177–194. (<a
href="https://doi.org/10.1016/j.ins.2020.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As high-resolution remote-sensing (HRRS) images have become increasingly widely available, scene classification focusing on the smart classification of land cover and land use has also attracted more attention. However, mainstream methods encounter a severe problem in that many annotation samples are required to obtain an ideal model for scene classification. In the remote sensing community, there is no dataset with a comparative scale to ImageNet (which contains over 14 million images) to meet the sample requirements of the convolutional neural network (CNN)-based methods. In addition, labeling new images is both labor intensive and time consuming. To address these problems, we present a new generative adversarial network (GAN)-based remote-sensing image generation method (GAN-RSIGM) that can be applied to create high-resolution annotated samples for scene classification. In GAN-RSIGM, the Wasserstein distance is used to measure the difference between the generator distribution and the real data distribution. This addresses the problem of the gradient disappearing during sample generation, and distinctly promotes a generator distribution close to the real data distribution. An auxiliary classifier is added to the discriminator , guiding the generator to produce consistent and distinct images. With regard to the network structure, the discriminator and the generator are implemented by stacking residual blocks, which further stabilize the training process of the GAN-RSIGM. Extensive experiments were conducted to evaluate the proposed method with two public HRRS datasets. The experimental results demonstrated that the proposed method could achieve satisfactory performance for high-quality annotation sample generation, scene classification, and data augmentation .},
  archive      = {J_ISCI},
  author       = {Wei Han and Lizhe Wang and Ruyi Feng and Lang Gao and Xiaodao Chen and Ze Deng and Jia Chen and Peng Liu},
  doi          = {10.1016/j.ins.2020.06.018},
  journal      = {Information Sciences},
  pages        = {177-194},
  shortjournal = {Inf. Sci.},
  title        = {Sample generation based on a supervised wasserstein generative adversarial network for high-resolution remote-sensing scene classification},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PassDB: A password database with strict privacy protocol
using 3D bloom filter. <em>ISCI</em>, <em>539</em>, 157–176. (<a
href="https://doi.org/10.1016/j.ins.2020.05.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Bloom filter is a probabilistic data structure for approximate membership filtering. It is applied in diverse Network systems to enhance a system’s performance and reduce the memory consumption, for instance, Named-Data Networking, Software-Defined Networks, and Wireless Sensor Networking. Bloom filter consumes a tiny amount of RAM space to store information of large sets of data. On the contrary, the Bloom filter is unexplored in the password database. In this article, we present a novel password management system using the 3-Dimensional Bloom filter (3DBF), called PassDB which features a) low space consumption, b) irrecoverable, c) irreversible, and d) high security and strict privacy. PassDB uses twelve 3DBFs to avoid false positives . In addition, we present extremely high accuracy Bloom filter and the accuracy is 99.99\% with false positives of 0.000001882. Moreover, PassDB gives utmost importance to the privacy of a user. Why should anyone be allowed to see the password (e.g., encrypted or raw password) with raw user information? This research question poses a new challenge towards the privacy of a user. This practice exploits the privacy of the users in identity management system . Therefore, PassDB imposes strict privacy for password database, i.e., no one is able to map password with a user ID.},
  archive      = {J_ISCI},
  author       = {Ripon Patgiri and Sabuzima Nayak and Samir Kumar Borgohain},
  doi          = {10.1016/j.ins.2020.05.135},
  journal      = {Information Sciences},
  pages        = {157-176},
  shortjournal = {Inf. Sci.},
  title        = {PassDB: A password database with strict privacy protocol using 3D bloom filter},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DSRPH: Deep semantic-aware ranking preserving hashing for
efficient multi-label image retrieval. <em>ISCI</em>, <em>539</em>,
145–156. (<a href="https://doi.org/10.1016/j.ins.2020.05.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, several hashing methods have been proposed for multi-label image retrieval . However, general methods quantify the similarities of image pairs roughly, which only consider the similarities based on category labels. In addition, general pairwise loss functions are not sensitive to the relative order of similar images. To address above problems, we present a deep semantic-aware ranking preserving hashing (DSRPH) method. First, we design a semantic-aware similarity quantization method which can measure fine-grained semantic-level similarity beyond the category based on the cosine similarity of image captions that contain high-level semantic description. Second, we propose a novel weighted pairwise loss function by adding adaptive upper and lower bounds , which can construct a compact zero-loss interval to directly constrain the relative order of similar images. Extensive experiments show that our method can generate high-quality hash codes and yield the state-of-the-art performance.},
  archive      = {J_ISCI},
  author       = {Yiming Shen and Yong Feng and Bin Fang and Mingliang Zhou and Sam Kwong and Bao-hua Qiang},
  doi          = {10.1016/j.ins.2020.05.114},
  journal      = {Information Sciences},
  pages        = {145-156},
  shortjournal = {Inf. Sci.},
  title        = {DSRPH: Deep semantic-aware ranking preserving hashing for efficient multi-label image retrieval},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Chaos and ergodicity are decidable for linear cellular
automata over (z/mZ)n. <em>ISCI</em>, <em>539</em>, 136–144. (<a
href="https://doi.org/10.1016/j.ins.2020.05.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that important properties describing complex behaviours as ergodicity , chaos, topological transitivity , and topological mixing, are decidable for one-dimensional linear cellular automata (LCA) over ( Z / m Z ) n (Z/mZ)n ( Theorem 6 and Corollary 7) , a large and important class of cellular automata (CA) which are able to exhibit the complex behaviours of general CA and are used in applications. In particular, we provide a decidable characterization of ergodicity , which is known to be equivalent to all the above mentioned properties, in terms of the characteristic polynomial of the matrix associated with LCA. We stress that the setting of LCA over ( Z / m Z ) n (Z/mZ)n with n &gt; 1 n&amp;gt;1 is more expressive, gives rise to much more complex dynamics, and is more difficult to deal with than the already investigated case n = 1 n=1 . The proof techniques from [23] , [25] used when n = 1 n=1 for obtaining decidable characterizations of dynamical and ergodic properties can no longer be exploited when n &gt; 1 n&amp;gt;1 for achieving the same goal. Indeed, in order to get the decision algorithm (Algorithm 1) we need to prove a non trivial result of abstract algebra ( Theorem 5 ) which is also of interest in its own. We also illustrate the impact of our results in real-world applications concerning the important and growing domain of cryptosystems which are often based on one-dimensional LCA over ( Z / m Z ) n (Z/mZ)n with n &gt; 1 n&amp;gt;1 . As a matter of facts, since cryptosystems have to satisfy the so-called confusion and diffusion properties (ensured by ergodicity and chaos, respectively, of the involved LCA) Algorithm *1 turns out to be an important tool for building chaotic/ergodic one-dimensional linear CA over ( Z / m Z ) n (Z/mZ)n and, hence, for improving the existing methods based on them.},
  archive      = {J_ISCI},
  author       = {Alberto Dennunzio and Enrico Formenti and Darij Grinberg and Luciano Margara},
  doi          = {10.1016/j.ins.2020.05.123},
  journal      = {Information Sciences},
  pages        = {136-144},
  shortjournal = {Inf. Sci.},
  title        = {Chaos and ergodicity are decidable for linear cellular automata over (Z/mZ)n},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Object similarity measures and pawlak’s indiscernibility on
decision tables. <em>ISCI</em>, <em>539</em>, 104–135. (<a
href="https://doi.org/10.1016/j.ins.2020.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the mathematical foundations of the notion of similarity between objects in relation to the granulations on a decision table D D . First of all, we compare the endogenous granulation induced by Pawlak’s indiscernibility with the exogenous granulation induced by a similarity measure ζ ζ defined on pairs of objects and assuming values in the unit interval. To this aim, the starting point of our analysis is the introduction of the notion of refinement of the granulation induced by an attribute subset A through the object similarity measure ζ ζ . More in detail, we say that ζ ζ refines the granulation induced by A if ζ ζ assumes value 1 on a pair of objects if and only if they are A -indiscernible. Next, starting from two given families ρ ρ and ν ν of numerical maps defined on pairs of admissible values of D D , we determine a broad class of potential similarity measures on the objects of D D refining, sometimes under some specific additional hypotheses, the A -granulation on the object set of D D . With regard to a such class of similarity measures, we establish several mathematical properties. Finally, we focus our attention to the analysis of specific pairs of numerical maps ρ ρ and ν ν that have been classically studied in literature and, for each of them, we exhibit the main properties with respect to the aforementioned refinement of granulation.},
  archive      = {J_ISCI},
  author       = {Francesca Catanzariti and Giampiero Chiaselotti and Federico G. Infusino and Giuseppe Marino},
  doi          = {10.1016/j.ins.2020.05.030},
  journal      = {Information Sciences},
  pages        = {104-135},
  shortjournal = {Inf. Sci.},
  title        = {Object similarity measures and pawlak’s indiscernibility on decision tables},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ERG-DE: An elites regeneration framework for differential
evolution. <em>ISCI</em>, <em>539</em>, 81–103. (<a
href="https://doi.org/10.1016/j.ins.2020.05.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is one of the most popular paradigms of evolutionary algorithms. Numerous variants of basic DE have been developed in the past two decades after it was first proposed. However, very few works focused on re-exploring the neighborhood area of the elite solutions, which is definitely a promising area according to the proximate optimality principle. Here, a simple yet efficient elites regeneration (ERG) framework was designed to fill this gap. The elite population in this framework is defined as a group of individuals with better fitness values and they are regenerated after the selection procedure in DE. Specifically, a new individual is produced from the search space around each elite individual (i.e. the parent individual) by sampling Gaussian or Cauchy probability models and replaces the parent if it has better fitness value. The implementation of this procedure only introduces two parameters that need to be tuned, i.e. the standard deviation for Gaussian distribution and the scale parameter for the Cauchy distribution . In the proposed framework, the elite individuals serve as the mean or location parameters of the probability models and the standard deviation and scale parameters are tuned by experiments as a small constant value. Thus, offspring individuals are generated in areas close to their corresponding elite parents. The framework allows thorough exploitation of search neighborhoods around elite individuals and ultimately helps the elite individuals escaping from local optima. Experiments results on CEC2014 benchmark revealed that ERG framework significantly increased the optimization capacity for four original DE algorithms, four classical DE variants, and two state-of-the-art DE variants. In addition, it also demonstrated competitive performance when compared with another DE framework.},
  archive      = {J_ISCI},
  author       = {Li-Bao Deng and Li-Li Zhang and Ning Fu and Hai-li Sun and Li-Yan Qiao},
  doi          = {10.1016/j.ins.2020.05.108},
  journal      = {Information Sciences},
  pages        = {81-103},
  shortjournal = {Inf. Sci.},
  title        = {ERG-DE: An elites regeneration framework for differential evolution},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single-parameter decision-theoretic rough set.
<em>ISCI</em>, <em>539</em>, 49–80. (<a
href="https://doi.org/10.1016/j.ins.2020.05.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-theoretic rough sets (DTRSs), which can be considered as generalized rough set models produced by Bayesian risk minimum and three-way decisions (3WD) theories, have achieved fruitful results in risk decision-making problems. Nevertheless, the parameter determination of decision-theoretic rough sets is a challenging problem in practical applications, which narrows the generalization and development of these models. In this paper, a methodology to determine the parameters for DTRS and 3WD is proposed to improve their practicability. First, a data-driven loss function matrix is introduced based on the significance and the probability of the sample. Subsequently, a generalized rough set model named single-parameter decision-theoretic rough set (SPDTRS) is put forward based on the proposed loss function matrix. The main feature of the proposed model is that there is only one parameter that should be preset rather than the two or six parameters in the traditional DTRS models. Finally, some experiments on the University of California Irvine (UCI) and Knowledge Extraction based on Evolutionary Learning (KEEL) data sets are conducted to illustrate the effectiveness of the proposed methodology.},
  archive      = {J_ISCI},
  author       = {Mingliang Suo and Laifa Tao and Baolong Zhu and Xuewen Miao and Zhichao Liang and Yu Ding and Xingliu Zhang and Tong Zhang},
  doi          = {10.1016/j.ins.2020.05.124},
  journal      = {Information Sciences},
  pages        = {49-80},
  shortjournal = {Inf. Sci.},
  title        = {Single-parameter decision-theoretic rough set},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Finding dense subgraphs with maximum weighted triangle
density. <em>ISCI</em>, <em>539</em>, 36–48. (<a
href="https://doi.org/10.1016/j.ins.2020.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding dense subgraphs from sparse graphs is a fundamental graph mining task that has been applied in various domains, such as social networks, biology, and spam detection . Because the standard formulation of this problem is difficult to solve owing to connections with the Maximum Clique Problem , some tractable formulations have been proposed. These formulations find a dense subgraph by optimizing some density function, such as the degree density or triangle density. In this paper, we introduce the weighted k-clique density , a novel formulation for dense subgraph extraction. We show that the problem of maximizing weighted k-clique density can be solved optimally in polynomial time by solving a series of minimum cut problems. For scalability, we also propose a more efficient greedy algorithm with performance guarantee. The experimental results on real-world network datasets show that, compared with established state-of-the-art algorithms, the proposed algorithm can find a much denser subgraph in terms of edge density and triangle density.},
  archive      = {J_ISCI},
  author       = {Jiabing Wang and Rongjie Wang and Jia Wei and Qianli Ma and Guihua Wen},
  doi          = {10.1016/j.ins.2020.06.004},
  journal      = {Information Sciences},
  pages        = {36-48},
  shortjournal = {Inf. Sci.},
  title        = {Finding dense subgraphs with maximum weighted triangle density},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-objective memetic GP with dispersion-keeping pareto
evaluation for real-world regression. <em>ISCI</em>, <em>539</em>,
16–35. (<a href="https://doi.org/10.1016/j.ins.2020.05.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression tasks aim to determine accurate and simple relationship expressions between variables, which can be regarded as bi-objective optimization problems. As GP (genetic programming) can use expression trees as representation, it is popularly-used for regression. Introducing multi-objective techniques into GP enables it to solve bi-objective tasks, and the success of memetic algorithms show the importance of local search in improving GP. However, existing memetic GP methods are mainly single-objective, in which the local search operators cannot be applied in multi-objective optimization. Moreover, the popularly-used solution evaluation mechanism (Pareto local search) in existing multi-objective memetic methods cannot assure solution dispersion. To handle these problems, a dispersion-keeping Pareto evaluation (DkPE) mechanism is proposed, based on which new crossover and mutation operators adaptive to bi-objective GP are designed. In addition, two base bi-objective GP methods (NSGP (non-dominated sorting GP) and SPGP (strength Pareto GP)) are developed. Applying the new operators in them respectively forms two bi-objective memetic GP methods (MNSGP (memetic NSGP) and MSPGP (memetic SPGP)). Results show that MNSGP and MSPGP outperform NSGP and SPGP respectively, which reflects that DkPE based crossover/mutation increase the performance of NSGP and SPGP. Moreover, solutions evolved by MNSGP outperform reference GP and non-GP based methods.},
  archive      = {J_ISCI},
  author       = {Jiayu Liang and Yu Xue and Jianming Wang},
  doi          = {10.1016/j.ins.2020.05.136},
  journal      = {Information Sciences},
  pages        = {16-35},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective memetic GP with dispersion-keeping pareto evaluation for real-world regression},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved MOEA/d algorithm with an adaptive evolutionary
strategy. <em>ISCI</em>, <em>539</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2020.05.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-objective Evolutionary Algorithm Based on Decomposition (MOEA/D) overcomes the limitation of evolutionary algorithm based on a Pareto dominant relationship in dealing with the problem of super multi-objective optimization and has wide application prospects, but there are also some problems, such as the lack of diversity and slow convergence speed in the later-stage evolution species. This article specifically conducts a systematic study on the population diversity of the MOEA/D algorithm and proposes three improvements: firstly, the evolutionary strategy of competition between SBX and DE operator is adopted to overcome the problem of the species diversity degradation of a single operator; secondly, an adaptive adjusting strategy of modulation probability is introduced to promote the variability of later-stage evolution species; finally, a method of double-faced mirror theory boundary optimization is used to prevent species aggregating at the boundary. The research shows that the above three improvement measures can effectively improve the population diversity of the MOEA/D algorithm. On the basis of this research, an improved MOEA/D algorithm with adaptive evolution strategy (AES-MOEA/D) is proposed. Simulation experiment indicators show that the convergence and comprehensive performance of the AES-MOEA/D algorithm are better than that of the basic MOEA/D algorithm and the other four comparison algorithms, which shows that the research on the maintenance of the diversity of the MOEA/D algorithm population helps improve the comprehensive performance of the MOEA/D algorithm.},
  archive      = {J_ISCI},
  author       = {Wen-xiang Wang and Kang-shun Li and Xing-zhen Tao and Fa-hui Gu},
  doi          = {10.1016/j.ins.2020.05.082},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {An improved MOEA/D algorithm with an adaptive evolutionary strategy},
  volume       = {539},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Publisher’s note. <em>ISCI</em>, <em>538</em>, iii. (<a
href="https://doi.org/10.1016/S0020-0255(20)31167-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  doi          = {10.1016/S0020-0255(20)31167-1},
  journal      = {Information Sciences},
  pages        = {iii},
  shortjournal = {Inf. Sci.},
  title        = {Publisher’s note},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An accurate and dynamic predictive model for a smart
m-health system using machine learning. <em>ISCI</em>, <em>538</em>,
486–502. (<a href="https://doi.org/10.1016/j.ins.2020.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, new highly-developed technologies are changing traditional processes related to medical and healthcare systems. Emerging Mobile Health (M-Health) systems are examples of novel technologies based on advanced data communication, deep learning, artificial intelligence, cloud computing, big data, and other machine learning methods. Data are collected from sensor nodes and forwarded to local databases through new technologies that enable cellular networks and then store the information in cloud storage systems. From cloud computing services or medical centres, the data are collected for further analysis. Furthermore, machine learning techniques are being used for accurate prediction of disease analysis and for purposes of classification. This paper presents a detailed overview of M-Health systems, their model and architecture, technologies and applications and also discusses statistical and machine learning approaches. We also propose a secure Android-based architecture to collect patient data, a reliable cloud-based model for data storage. Finally, a predictive model able to classify cardiovascular diseases according to their seriousness will be discussed. Moreover, the proposed prediction model has been compared with existing models in terms of accuracy, sensitivity, and specificity. The experimental results show encouraging results in terms of the proposed predictive model for an M-Health system. Keywords: Machine Learning, Predictive, Models, M-Health, Classification, SVM, Decision Tree, Accuracy},
  archive      = {J_ISCI},
  author       = {Kashif Naseer Qureshi and Sadia Din and Gwanggil Jeon and Francesco Piccialli},
  doi          = {10.1016/j.ins.2020.06.025},
  journal      = {Information Sciences},
  pages        = {486-502},
  shortjournal = {Inf. Sci.},
  title        = {An accurate and dynamic predictive model for a smart M-health system using machine learning},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resilient decentralized sampled-data h∞ filter design for
linear interconnected systems subject to denial-of-service attacks.
<em>ISCI</em>, <em>538</em>, 467–485. (<a
href="https://doi.org/10.1016/j.ins.2020.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the design problem of the resilient decentralized sampled-data H ∞ H∞ filter for linear interconnected systems subject to the denial-of-service attacks. A piecewise Lyapunov function-based method is first developed to determine the filter parameters and the sampled-data communication schemes. Then the obtained results are utilized to facilitate the design of the resilient decentralized sampled-data H ∞ H∞ filter against the denial-of-service attacks. Compared with the existing results, the communication channels from the subsystems of interconnected systems to the filters are allowed to be independent and be compromised by different adversaries. Finally, numerical simulations on the double-inverted pendulums system and the three-machine power system are provided to illustrate the efficacy of the proposed method.},
  archive      = {J_ISCI},
  author       = {Rui Gao and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2020.06.038},
  journal      = {Information Sciences},
  pages        = {467-485},
  shortjournal = {Inf. Sci.},
  title        = {Resilient decentralized sampled-data h∞ filter design for linear interconnected systems subject to denial-of-service attacks},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-objective optimization of biclustering with binary data.
<em>ISCI</em>, <em>538</em>, 444–466. (<a
href="https://doi.org/10.1016/j.ins.2020.05.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering consists of partitioning data objects into subsets called clusters according to some similarity criteria. This paper addresses a structure for generating overlapping clusters, where data objects can belong to more than one subset, which we join with bi-objective optimization and link to biclustering for problems with binary data. Biclustering simultaneously groups the objects and features so that a specific group of objects has a special group of features. In recent years, biclustering has received a lot of attention in several practical applications. First we present an integer programing formulations for the bi-objective optimization of biclustering. Next we propose a constructive heuristic based on the set intersection operation and its efficient implementation for solving a series of mono-objective problems used inside the ε-constraint method (obtained by keeping only one objective function and the other objective function is integrated into constraints). Finally, our experimental results show that our proposed heuristic provides very good results and significantly reduces the computational expense compared to using the CPLEX solver as an exact algorithm for finding an optimal solution, which drastically increases the computational cost for large instances.},
  archive      = {J_ISCI},
  author       = {Saïd Hanafi and Gintaras Palubeckis and Fred Glover},
  doi          = {10.1016/j.ins.2020.05.078},
  journal      = {Information Sciences},
  pages        = {444-466},
  shortjournal = {Inf. Sci.},
  title        = {Bi-objective optimization of biclustering with binary data},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved recurrent generative adversarial networks with
regularization techniques and a controllable framework. <em>ISCI</em>,
<em>538</em>, 428–443. (<a
href="https://doi.org/10.1016/j.ins.2020.05.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Network (GAN), a deep learning framework to generate synthetic but realistic samples, has produced astonishing results for image synthesis. However, because GAN is routinely used for image datasets, regularization methods for GAN have been developed for convolutional layers. In this study, to expand these methods for time-series data, which are one of the most common data types in various real datasets, modified regularization methods are proposed for Long Short-Term Memory (LSTM)-based GANs. Specifically, the spectral normalization, hinge loss, orthogonal regularization, and the truncation trick are modified and assessed for LSTM-based GANs. Furthermore, a conditional GAN architecture called Controllable GAN (ControlGAN) is applied to LSTM-based GANs to produce the desired samples. The evaluations are conducted with sine wave data, air pollution datasets, and a medical time-series dataset obtained from intensive care units. As a result, ControlGAN with the spectral normalization on gates and cell states consistently outperforms the others, including the conventional model, called Recurrent Conditional GAN (RCGAN).},
  archive      = {J_ISCI},
  author       = {Minhyeok Lee and Donghyun Tae and Jae Hun Choi and Ho-Youl Jung and Junhee Seok},
  doi          = {10.1016/j.ins.2020.05.116},
  journal      = {Information Sciences},
  pages        = {428-443},
  shortjournal = {Inf. Sci.},
  title        = {Improved recurrent generative adversarial networks with regularization techniques and a controllable framework},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized decomposition integral. <em>ISCI</em>,
<em>538</em>, 415–427. (<a
href="https://doi.org/10.1016/j.ins.2020.05.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose two different generalizations of the decomposition integral introduced by Even and Lehrer. We modify the product operator merging a given capacity and the decomposition coefficients by some more general functions F and G and compare properties of the obtained functionals with properties of the original decomposition integral. Generalized decomposition integrals corresponding to the particular decomposition systems, being generalizations of Shilkret, Choquet and concave integrals, are studied and exemplified.},
  archive      = {J_ISCI},
  author       = {L&#39;ubomíra Horanská and Humberto Bustince and Javier Fernandez and Radko Mesiar},
  doi          = {10.1016/j.ins.2020.05.081},
  journal      = {Information Sciences},
  pages        = {415-427},
  shortjournal = {Inf. Sci.},
  title        = {Generalized decomposition integral},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On relationship between three-way concept lattices.
<em>ISCI</em>, <em>538</em>, 396–414. (<a
href="https://doi.org/10.1016/j.ins.2020.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By reformulating and extending the properties of three-way operators, this paper investigates the relationship between different kinds of three-way concept lattices . Three-way operators are defined through eight kinds of two-way operators which are connected by the complement operation. To examine the interrelations systematically, we study (a) the relationship between two-way operators, (b) the relationship between two-way concepts, (c) the relationship between three-way operators, and (d) the relationship between three-way concepts. The results show that the four kinds of object-induced three-way concept lattices are order isomorphic to each other and the four kinds of attribute-induced three-way concept lattices are also order isomorphic to each other.},
  archive      = {J_ISCI},
  author       = {Xuerong Zhao and Duoqian Miao and Bao Qing Hu},
  doi          = {10.1016/j.ins.2020.06.007},
  journal      = {Information Sciences},
  pages        = {396-414},
  shortjournal = {Inf. Sci.},
  title        = {On relationship between three-way concept lattices},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Error-tolerant label prior for interactive image
segmentation. <em>ISCI</em>, <em>538</em>, 384–395. (<a
href="https://doi.org/10.1016/j.ins.2020.05.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User interactions are generally utilized to impose the hard constraint and estimate the label prior probability in the interactive image segmentation methods. The conventional interactive approaches cannot work well when the user inputs contain incorrect marks. The existing error tolerance methods mainly focus on the interaction itself and try to eliminate the influence of incorrect hard constraint, which however ignore the label prior estimation. This paper mainly focuses on solving the label prior estimation problem when error marks appear. The prior probability is generally defined as the matching degree between pixels and the cluster centers of marked pixels. Incorrect interaction leads to the formation of incorrect clusters. Therefore, a reliability learning model is constructed in this paper by 1) assigning smaller weighting factors to incorrect clusters, 2) assigning larger weighting factors to correct clusters with higher matching degree. Accurate label prior probability can be obtained by the weighted averaging. Then referring to the existing methods, an error-tolerant segmentation model is designed as a ratio energy function, which can both overcome the hard constraint and the label prior limitation with error marks. Experiments on the challenging Berkeley segmentation data set and Microsoft GrabCut database demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Tao Wang and Shengzhe Qi and Zexuan Ji and Quansen Sun and Peng Fu and Qi Ge},
  doi          = {10.1016/j.ins.2020.05.122},
  journal      = {Information Sciences},
  pages        = {384-395},
  shortjournal = {Inf. Sci.},
  title        = {Error-tolerant label prior for interactive image segmentation},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Posterior concentration and fast convergence rates for
generalized bayesian learning. <em>ISCI</em>, <em>538</em>, 372–383. (<a
href="https://doi.org/10.1016/j.ins.2020.05.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the learning rate of generalized Bayes estimators in a general setting where the hypothesis class can be uncountable and have an irregular shape, the loss function can have heavy tails, and the optimal hypothesis may not be unique. We prove that under the multi-scale Bernstein’s condition, the generalized posterior distribution concentrates around the set of optimal hypotheses and the generalized Bayes estimator can achieve fast learning rate . Our results are applied to show that the standard Bayesian linear regression is robust to heavy-tailed distributions.},
  archive      = {J_ISCI},
  author       = {Lam Si Tung Ho and Binh T. Nguyen and Vu Dinh and Duy Nguyen},
  doi          = {10.1016/j.ins.2020.05.138},
  journal      = {Information Sciences},
  pages        = {372-383},
  shortjournal = {Inf. Sci.},
  title        = {Posterior concentration and fast convergence rates for generalized bayesian learning},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranking via partial ordering for answer selection.
<em>ISCI</em>, <em>538</em>, 358–371. (<a
href="https://doi.org/10.1016/j.ins.2020.05.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer selection with deep neural networks has been studied extensively owing to its strong capability of encoding semantic features . Most previous work has treated the candidates as independent individuals for ranking but ignored the relations between these. In this study, we propose a ranking method via partial ordering for answer selection, which is applicable to various tasks, such as question answering and reading comprehension. First, we propose a comparative network, namely Candidate vs. Candidate, which aims to discover the possible partial order relations between (candidate, candidate) pairs. Thereafter, a multi-task learning framework is constructed for the answer selection problem, in which the main task is representing the relevance between (question, answer) pairs, while the auxiliary sub-task is learning the partial order relations between (answer, answer) pairs. By jointly training the networks with abundant supervision information, a reasonable relevance function and a comparison function can be approximated for these tasks. The experimental results on four benchmarks indicate that ranking candidate answers via partial ordering can significantly improve the answer selection performance.},
  archive      = {J_ISCI},
  author       = {Zan-Xia Jin and Bo-Wen Zhang and Fang Zhou and Jingyan Qin and Xu-Cheng Yin},
  doi          = {10.1016/j.ins.2020.05.110},
  journal      = {Information Sciences},
  pages        = {358-371},
  shortjournal = {Inf. Sci.},
  title        = {Ranking via partial ordering for answer selection},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measures associated with granularity and rough
approximations in interval-valued information tables based on kernel
similarity relations. <em>ISCI</em>, <em>538</em>, 337–357. (<a
href="https://doi.org/10.1016/j.ins.2020.05.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granularity measures and rough approximation measures are two basic methods for dealing with uncertainty in rough set theory . Interval-valued information tables are a generalization of single-valued information tables. In this paper, we study granularity measures and rough approximation measures in interval-valued information tables based on kernel similarity relations. More specifically, we propose a new type of similarity relations called kernel similarity relations by employing kernel functions to compute the similarity between objects in interval-valued information tables. Based on the kernel similarity relations, we introduce a class of average granularity measures, from which we can obtain some specific granularity measures in interval-valued information tables. We develop three rough approximation measures in interval-valued information tables based on the kernel similarity relations, including kernel accuracy measure, kernel roughness measure, and kernel approximation accuracy measure. By using the class of average granularity measures, we further examine three granularity-based rough approximation measures in interval-valued information tables. The results of the experimental analysis provide an insightful understanding of the essence of the proposed granularity measures and rough approximation measures in interval-valued information tables.},
  archive      = {J_ISCI},
  author       = {Xi-Ao Ma},
  doi          = {10.1016/j.ins.2020.05.076},
  journal      = {Information Sciences},
  pages        = {337-357},
  shortjournal = {Inf. Sci.},
  title        = {Measures associated with granularity and rough approximations in interval-valued information tables based on kernel similarity relations},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering-based variable precision fuzzy rough sets with
PROMETHEE-EDAS methods. <em>ISCI</em>, <em>538</em>, 314–336. (<a
href="https://doi.org/10.1016/j.ins.2020.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a reflexive fuzzy β β -neighborhood operator by modifying Ma’s fuzzy β β -neighborhood operators. Then, we use such an operator to build a covering-based variable precision fuzzy rough set (CVPFRS) model that can deal with the issue of misclassifications and perturbations in decision-making problems. By combining the CVPFRS model with two traditional decision-making methods (the PROMETHE method and the DEAS method), we introduce a novel method for addressing multi-attribute decision-making (MADM) problems. An illustrative example is utilized to demonstrate the practicality of the proposed method. The effectiveness of the proposed method is validated by comparing it with existing methods. By virtue of the cross-validation and hypothesis testing , we give an experimental analysis to interpret the validity and stability of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jianming Zhan and Haibo Jiang and Yiyu Yao},
  doi          = {10.1016/j.ins.2020.06.006},
  journal      = {Information Sciences},
  pages        = {314-336},
  shortjournal = {Inf. Sci.},
  title        = {Covering-based variable precision fuzzy rough sets with PROMETHEE-EDAS methods},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ordered pair of normalized real numbers. <em>ISCI</em>,
<em>538</em>, 290–313. (<a
href="https://doi.org/10.1016/j.ins.2020.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For an ordered pair of real numbers, if both of its two entries are contained in the open interval (0,1) , it is called an Ordered Pair of Normalized real numbers (OPN). In this paper, a comprehensive theory is presented, which provides a novel mathematical tool for dealing with OPNs. Specifically, the eight arithmetic operations and trigonometric functions of OPNs are given. The set of OPNs is closed under these operations. Later, a total order defined on the set of OPNs is shown, and Cauchy–Schwarz inequality of OPNs’ version is proved to be true. Finally, a decision making example is given to demonstrate the feasibility and rationality of the OPNs theory proposed.},
  archive      = {J_ISCI},
  author       = {Lei Zhou},
  doi          = {10.1016/j.ins.2020.05.036},
  journal      = {Information Sciences},
  pages        = {290-313},
  shortjournal = {Inf. Sci.},
  title        = {Ordered pair of normalized real numbers},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Adaptively secure certificate-based broadcast encryption
and its application to cloud storage service. <em>ISCI</em>,
<em>538</em>, 273–289. (<a
href="https://doi.org/10.1016/j.ins.2020.05.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing public key broadcast encryption schemes are mainly constructed in identity-based cryptosystem , which bears the inherent problems of key escrow and key distribution. The certificate-based encryption mechanism can effectively address the problems in identity-based cryptosystem . Meanwhile, it simplifies the certificate revocation issue for traditional public key cryptosystem. Inspired by the idea of certificate-based encryption, we put forward the new primitive certificate-based broadcast encryption as well as its formal definition and security model. In virtue of prime order bilinear groups, we present an instantiation scheme of certificate-based broadcast encryption. To our best knowledge, the proposed scheme is the first adaptively secure scheme for certificate-based broadcast encryption in the standard model against chosen-ciphertext attack. Compared with the previous work, our scheme has advantages in the respects of computation cost as well as security properties. Furthermore, we present an application scenario of the proposed scheme for data access control in cloud storage service.},
  archive      = {J_ISCI},
  author       = {Liqing Chen and Jiguo Li and Yang Lu and Yichen Zhang},
  doi          = {10.1016/j.ins.2020.05.092},
  journal      = {Information Sciences},
  pages        = {273-289},
  shortjournal = {Inf. Sci.},
  title        = {Adaptively secure certificate-based broadcast encryption and its application to cloud storage service},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exponential operational laws and new aggregation operators
for intuitionistic multiplicative set in multiple-attribute group
decision making process. <em>ISCI</em>, <em>538</em>, 245–272. (<a
href="https://doi.org/10.1016/j.ins.2020.05.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intuitionistic multiplicative preference set is one of the replacements to the intuitionistic fuzzy preference set, where the preferences related to the object is asymmetrical distribution about 1. In it, Saaty’s 1–9 scale has been used to represent the uncertain and imprecise information. Meanwhile, an aggregation operator by using general operational laws for some fuzzy sets is an important task to aggregate the different numbers. Motivated by these primary characteristics, it is interesting to present the concept of exponential operational laws, which differs from the traditional laws by the way, in which bases are real numbers while exponents are the intuitionistic multiplicative numbers. In this paper, we develop a methodto solve the Multiple Attribute Group Decision Making (MAGDM) problem under the Intuitionistic Multiplicative Sets (IMS) environment. To do it, firstly, we define some new exponential operational laws and a score function for IMS and studied their properties. Secondly, based on this, we develop some averaging and geometric aggregation operators and characterize their various properties. Thirdly, a novel approach is promoted to solve MAGDM problems with IMS information. Finally, some numerical illustrations are given with a comparative study to verify the approach.},
  archive      = {J_ISCI},
  author       = {Harish Garg},
  doi          = {10.1016/j.ins.2020.05.095},
  journal      = {Information Sciences},
  pages        = {245-272},
  shortjournal = {Inf. Sci.},
  title        = {Exponential operational laws and new aggregation operators for intuitionistic multiplicative set in multiple-attribute group decision making process},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiattribute decision method for comprehensive logistics
distribution center location selection based on 2-dimensional linguistic
information. <em>ISCI</em>, <em>538</em>, 209–244. (<a
href="https://doi.org/10.1016/j.ins.2020.05.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The comprehensive logistics distribution center location selection (CLDCLS) problem is a multiattribute group decision-making (MAGDM) problem in which multiple commodity preference weights are considered. To better describe the preference information and expert evaluation information, this paper utilizes 2-dimensional linguistic (2DL) information to express the preference information of various commodities and the expert evaluation, which can represent not only the evaluation information of experts but also the reliability of the evaluation information. Additionally, for solving the CLDCLS problem, this paper puts forward improved operational rules a score function , a distance formula and a correlation coefficient measure. Based on the 2DL information and the improved operational rules, we propose a 2-dimensional linguistic similarity-degree-based clustering analysis method, the 2-dimensional linguistic partitioned Maclaurin symmetric mean (2DLPMSM) operator, and the 2-dimensional linguistic weighted partitioned Maclaurin symmetric mean (2DLWPMSM) operator. The corresponding properties and special cases are demonstrated. By using these proposed methods, this paper constructs a MAGDM solution framework for the CLDCLS problem. A practical case of the CLDCLS problem is presented to demonstrate the effectiveness, rationality, robustness and superior performance of the proposed method.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Ying Li},
  doi          = {10.1016/j.ins.2020.05.131},
  journal      = {Information Sciences},
  pages        = {209-244},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision method for comprehensive logistics distribution center location selection based on 2-dimensional linguistic information},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum generative adversarial network for generating
discrete distribution. <em>ISCI</em>, <em>538</em>, 193–208. (<a
href="https://doi.org/10.1016/j.ins.2020.05.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning has recently attracted much attention from the community of quantum computing . In this paper, we explore the ability of generative adversarial networks (GANs) based on quantum computing . More specifically, we propose a quantum GAN for generating classical discrete distribution, which has a classical-quantum hybrid architecture and is composed of a parameterized quantum circuit as the generator and a classical neural network as the discriminator . The parameterized quantum circuit only consists of simple one-qubit rotation gates and two-qubit controlled-phase gates that are available in current quantum devices . Our scheme has the following characteristics and potential advantages: (i) It is intrinsically capable of generating discrete data (e.g., text data), while classical GANs are clumsy for this task due to the vanishing gradient problem. (ii) Our scheme avoids the input/output bottlenecks embarrassing most of the existing quantum learning algorithms that either require to encode the classical input data into quantum states , or output a quantum state corresponding to the solution instead of giving the solution itself, which inevitably compromises the speedup of the quantum algorithm . (iii) The probability distribution implicitly given by data samples can be loaded into a quantum state, which may be useful for some further applications.},
  archive      = {J_ISCI},
  author       = {Haozhen Situ and Zhimin He and Yuyi Wang and Lvzhou Li and Shenggen Zheng},
  doi          = {10.1016/j.ins.2020.05.127},
  journal      = {Information Sciences},
  pages        = {193-208},
  shortjournal = {Inf. Sci.},
  title        = {Quantum generative adversarial network for generating discrete distribution},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic trajectory representation and retrieval via
hierarchical embedding. <em>ISCI</em>, <em>538</em>, 176–192. (<a
href="https://doi.org/10.1016/j.ins.2020.05.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory mining has gained growing attention due to its emerging applications, such as location-based services, urban computing, and movement behavior analyses. One critical and fundamental mining task is to retrieve specific locations or trajectories that satisfy particular patterns. However, existing approaches mainly represent the trajectory as a collection of geographic and temporal features, so the latent semantic properties are barely considered. In this paper, we introduce a new semantic trajectory representation method, which considers trajectory structures, temporal information, and domain knowledge to make efficient semantic retrieval possible. Specifically, we first introduce a synchronization-based model to identify multi-resolution regions of interest (ROIs) to extract structures from disordered raw trajectories. Afterward, we proposed a hierarchical embedding model to embed ROIs as well as trajectories on the hierarchical ROI network as continuous vectors by considering multiple kinds of semantic similarity . As a result, users can easily retrieve desirable ROIs or trajectories by computing the similarity among embedded vectors. Experiments show that our approach excels both classical trajectory metric-based models and state-of-the-art deep network embedding models in terms of retrieving interpretable ROIs and trajectories.},
  archive      = {J_ISCI},
  author       = {Chongming Gao and Zhong Zhang and Chen Huang and Hongzhi Yin and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2020.05.107},
  journal      = {Information Sciences},
  pages        = {176-192},
  shortjournal = {Inf. Sci.},
  title        = {Semantic trajectory representation and retrieval via hierarchical embedding},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differentially private publication of streaming trajectory
data. <em>ISCI</em>, <em>538</em>, 159–175. (<a
href="https://doi.org/10.1016/j.ins.2020.05.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated trajectories (e.g. during traveling) can be leveraged to offer value-added services (e.g. smart city policy formulation), but there are also privacy implications. For example, information about the routes or destinations obtained from such published trajectories can be used to profile and identify users, including during contact tracing in pandemics (e.g., COVID-19) or the monitoring of demonstrations (e.g., surveillance). However, existing trajectory publishing algorithms generally rely on batch processing platforms, and rarely pay attention to real-time privacy protection processing in streaming scenarios. Therefore, we propose a stream processing framework containing two modules for spatio-temporal data. This framework is designed to achieve high data utility, while effectively ensuring the preservation of privacy in the published results. The first module is TSP, which concurrently receives real-time queries from individuals and releases new sanitizing trajectories. The second module is VCR comprising three algorithms based on differential privacy to facilitate the publication of the distribution of position statistics . Our experiments on real-world datasets demonstrate that our framework can effectively guarantee privacy with high data utility, when the appropriate parameter configuration is chosen. In addition, compared with the baseline algorithm H t Ht - publication , our group-based algorithm AG n AGn - publication achieves better data accuracy in terms of visitor counts at the same level of privacy protection.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Ding and Wenxiang Zhou and Shujun Sheng and Zhifeng Bao and Kim-Kwang Raymond Choo and Hai Jin},
  doi          = {10.1016/j.ins.2020.05.058},
  journal      = {Information Sciences},
  pages        = {159-175},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private publication of streaming trajectory data},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive stock trading strategies with deep reinforcement
learning methods. <em>ISCI</em>, <em>538</em>, 142–158. (<a
href="https://doi.org/10.1016/j.ins.2020.05.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing complexity and dynamical property in stock markets are key challenges of the financial industry, in which inflexible trading strategies designed by experienced financial practitioners fail to achieve satisfactory performance in all market conditions. To meet this challenge, adaptive stock trading strategies with deep reinforcement learning methods are proposed. For the time-series nature of stock market data, the Gated Recurrent Unit (GRU) is applied to extract informative financial features, which can represent the intrinsic characteristics of the stock market for adaptive trading decisions. Furthermore, with the tailored design of state and action spaces, two trading strategies with reinforcement learning methods are proposed as GDQN (Gated Deep Q-learning trading strategy) and GDPG (Gated Deterministic Policy Gradient trading strategy). To verify the robustness and effectiveness of GDQN and GDPG, they are tested both in the trending and in the volatile stock market from different countries. Experimental results show that the proposed GDQN and GDPG not only outperform the Turtle trading strategy but also achieve more stable returns than a state-of-the-art direct reinforcement learning method, DRL trading strategy, in the volatile stock market. As far as the GDQN and the GDPG are compared, experimental results demonstrate that the GDPG with an actor-critic framework is more stable than the GDQN with a critic-only framework in the ever-evolving stock market.},
  archive      = {J_ISCI},
  author       = {Xing Wu and Haolei Chen and Jianjia Wang and Luigi Troiano and Vincenzo Loia and Hamido Fujita},
  doi          = {10.1016/j.ins.2020.05.066},
  journal      = {Information Sciences},
  pages        = {142-158},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive stock trading strategies with deep reinforcement learning methods},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A multilevel neighborhood sequential decision approach of
three-way granular computing. <em>ISCI</em>, <em>538</em>, 119–141. (<a
href="https://doi.org/10.1016/j.ins.2020.05.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fusion of three-way decision and granular computing provides powerful ideas and methods to understand and solve the problems of cognitive science by thinking and information processing in threes. As a typical representation of three-way granular computing , sequential three-way decision focuses on making a multiple stages of decisions by a sequence of trisecting-acting-outcome (TAO) models. To construct more general granules, levels, and hierarchies, we investigate an integrative multi-granularity approach to sequential three-way decision in a neighborhood system by the evolution mechanism of data and parameters. We employ the γ γ -cut similarity neighborhood relation based on Gaussian kernel function to the hierarchical granulation of universe. Subsequently, we propose the multilevel neighborhood granular structures by the combinations of horizontal granularity and vertical granularity , and discuss the monotonicity of level measurements associated with the uncertainty of decision. Based on such a neighborhood structured approach, a multilevel framework of sequential three-way decision is examined from coarser to finer concerning the granularity of neighborhood information. Finally, we report a series of experiments to demonstrate the performance of proposed models and algorithms.},
  archive      = {J_ISCI},
  author       = {Xin Yang and Tianrui Li and Dun Liu and Hamido Fujita},
  doi          = {10.1016/j.ins.2020.05.060},
  journal      = {Information Sciences},
  pages        = {119-141},
  shortjournal = {Inf. Sci.},
  title        = {A multilevel neighborhood sequential decision approach of three-way granular computing},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pareto dominance based multiobjective cohort intelligence
algorithm. <em>ISCI</em>, <em>538</em>, 69–118. (<a
href="https://doi.org/10.1016/j.ins.2020.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent days, several novel and specialized algorithms are coming up for solving particular class of problems. However, their performance on new benchmark or real-world problem remains unsure. This paper proposes a novel Multiobjective Cohort Intelligence (MOCI) algorithm. It is based on Pareto dominance and coevolutionary design principles to achieve efficient, effective, productive and robust performance. The capability of MOCI algorithm is enhanced through use of multiple features for balance of exploration versus exploitation, search towards promising region and avoidance of search stagnation. The performance of MOCI is assessed against the state-of-the-art algorithms, such as: ARMOEA, CMOPSO, hpaEA, LMOCSO, LSMOF, NMPSO and WOFSMPSO across multiple test suites including Classical, ZDT, DTLZ, WFG and UF. The performance assessment is conducted with truly uncorrelated performance metrics. In this regard, an exploratory approach of multiple correlation analysis is proposed. Performance of MOCI algorithm is statistically verified and validated using PROMETHEE-II and nonparametric statistical tests. MOCI is capable of achieving well converged and diversified solutions on most of the test as well as real world problems. The success of MOCI is attributed to multiple features incorporated in the algorithm. In the future, MOCI could be applied to challenging problems in engineering and management.},
  archive      = {J_ISCI},
  author       = {Mukundraj V. Patil and Anand J. Kulkarni},
  doi          = {10.1016/j.ins.2020.05.019},
  journal      = {Information Sciences},
  pages        = {69-118},
  shortjournal = {Inf. Sci.},
  title        = {Pareto dominance based multiobjective cohort intelligence algorithm},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Remarks on the cryptanalysis of common prime RSA for IoT
constrained low power devices. <em>ISCI</em>, <em>538</em>, 54–68. (<a
href="https://doi.org/10.1016/j.ins.2020.05.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard RSA cryptosystem becomes vulnerable, when private key d&amp;lt;N0.292 is used inside CryptoChips of constrained devices, thus an alternate scheme is the Common Prime RSA (CP-RSA) variant, which provides cryptographic (decryption/signing) operations. In this paper, we perform a cryptanalytic attack on CP-RSA using lattice basis reduction method that is used to exploit possible vulnerabilities of RSA small private key attacks. In addition, we performed detail experiments on CP-RSA weak or overestimated bounds and compare results to the past studies. Our implemented cryptanalytic attack implicates more precise and direct method to exploit the CP-RSA existing theoretical and experimental bounds. Also, our results prove that CP-RSA is an effective approach that provides resistance against standard RSA small private key attacks.},
  archive      = {J_ISCI},
  author       = {Majid Mumtaz and Luo Ping},
  doi          = {10.1016/j.ins.2020.05.075},
  journal      = {Information Sciences},
  pages        = {54-68},
  shortjournal = {Inf. Sci.},
  title        = {Remarks on the cryptanalysis of common prime RSA for IoT constrained low power devices},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differentially private distributed optimization for
multi-agent systems via the augmented lagrangian algorithm.
<em>ISCI</em>, <em>538</em>, 39–53. (<a
href="https://doi.org/10.1016/j.ins.2020.05.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the private distributed optimization problem for multi-agent systems, where all agents cooperatively minimize the sum of individual convex objective functions with the additional requirement that the functions remain differential privacy . Based on the augmented Lagrangian algorithm, an effective distributed algorithm is presented to ensure the privacy by perturbing primal estimates with additive Laplace noises. The proposed algorithm is more likely to have a faster convergence rate compared to the primal-based algorithms, and has less computational burden contrast with the ADMM-based private algorithms. By means of an important factorization of weighted Laplacian matrix , it is proven that the error between optimal solution and ergodic average estimates is bounded, which is related to the privacy level. Within this framework, trade-offs between privacy level and convergence accuracy are analyzed. Finally the effectiveness of the proposed algorithm is illustrated by numerical examples.},
  archive      = {J_ISCI},
  author       = {Yuan-Wei Lv and Guang-Hong Yang and Chong-Xiao Shi},
  doi          = {10.1016/j.ins.2020.05.119},
  journal      = {Information Sciences},
  pages        = {39-53},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private distributed optimization for multi-agent systems via the augmented lagrangian algorithm},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient ciphertext-policy attribute-based encryption with
blackbox traceability. <em>ISCI</em>, <em>538</em>, 19–38. (<a
href="https://doi.org/10.1016/j.ins.2020.05.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traitor tracing scheme is a paradigm to classify the users who illegal use of their decryption keys in cryptosystems . In the ciphertext-policy attribute-based cryptosystem, the decryption key usually contains the users’ attributes, while the real identities are hidden. The decryption key with hidden identities enables malicious users to intentionally leak decryption keys or embed the decryption keys in the decryption device to gain illegal profits with a little risk of being discovered. To mitigate this problem, the concept of blackbox traceability in the ciphertext-policy attribute-based scheme was proposed to identify the malicious user via observing the I/O streams of the decryption device. However, current solutions with blackbox traceability are impractical since either the composite-order group or the linear complexity of system users is required. In this article, we proposed a secure ciphertext-policy attribute-based set encryption scheme with the short decryption key. The proposed scheme bases on the prime-order group to improve computational performances and aggregates multiple attributes into a constant-size attribute set to reduce the costs of communication overheads . By applying our proposed scheme with fingerprint codes, we then give an instantiation of the ciphertext-policy attribute-based scheme with blackbox traceability. Our scheme is provably secure under various q -type assumptions.},
  archive      = {J_ISCI},
  author       = {Shengmin Xu and Jiaming Yuan and Guowen Xu and Yingjiu Li and Ximeng Liu and Yinghui Zhang and Zuobin Ying},
  doi          = {10.1016/j.ins.2020.05.115},
  journal      = {Information Sciences},
  pages        = {19-38},
  shortjournal = {Inf. Sci.},
  title        = {Efficient ciphertext-policy attribute-based encryption with blackbox traceability},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intent-based resource matching strategy in cloud.
<em>ISCI</em>, <em>538</em>, 1–18. (<a
href="https://doi.org/10.1016/j.ins.2020.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient resource allocation based on user intent is an important issue in a large-scale, distributed environment, such as cloud computing . Although a large number of cloud resource matching models he been proposed, these models do not consider the interests of user and cloud service provider objectively and fairly. Thus, a novel resource matching strategy that regulates multiattribute matching between cloud resources and tasks is proposed in this study. Tasks and resources are initially clustered on the basis of the attribute characteristics to reduce the scope of resource retrieval. Then, the tasks are matched to the appropriate resources in terms of the strict bilateral matching algorithm to improve the satisfaction of both parties. Finally, a series of experiments are reported to show the effectiveness of the algorithm. Experimental results conclusively demonstrate that our proposed methods can availably decrease the scheduling overhead and improve the overall satisfaction of both parties simultaneously.},
  archive      = {J_ISCI},
  author       = {Li He and Zhicheng Qian},
  doi          = {10.1016/j.ins.2020.05.045},
  journal      = {Information Sciences},
  pages        = {1-18},
  shortjournal = {Inf. Sci.},
  title        = {Intent-based resource matching strategy in cloud},
  volume       = {538},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A ternary bitwise calculator based genetic algorithm for
improving error correcting output codes. <em>ISCI</em>, <em>537</em>,
485–510. (<a href="https://doi.org/10.1016/j.ins.2020.05.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel genetic algorithm (GA) for the error correction output coding (ECOC) framework. Different from other GA algorithms, a new individual structure is designed by setting a gene as the combination of three types of operators: (1) the column selector; (2) the ternary bitwise calculator; (3) the feature selector. In our GA algorithm, two column selectors first extract two columns to from a codematrix pool, then a Ternary bitwise Calculator (TC) transfers them to a new column through a ternary number calculation process. The feature selector selects a feature subset for training the associated dichotomizer. By doing so, an individual contains a set of genes to form an ECOC ensemble. The TCs deployed in our algorithm include both the traditional TCs and some newly proposed TCs, which aid to generate diverse codematrices. When the evolutionary process terminates, the best individual in the last generation is regarded as the final solution. The performance of our algorithm is verified on both the UCI and microarray data sets. Experiment results demonstrate that our GA based ECOC achieves promising performance comparing to other ECOC algorithms. Furthermore, results also confirm that various TCs contribute to the generation of discriminative individuals.},
  archive      = {J_ISCI},
  author       = {Xiao-Na Ye and Kun-Hong Liu and Sze-Teng Liong},
  doi          = {10.1016/j.ins.2020.05.088},
  journal      = {Information Sciences},
  pages        = {485-510},
  shortjournal = {Inf. Sci.},
  title        = {A ternary bitwise calculator based genetic algorithm for improving error correcting output codes},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards safe reinforcement-learning in industrial
grid-warehousing. <em>ISCI</em>, <em>537</em>, 467–484. (<a
href="https://doi.org/10.1016/j.ins.2020.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning has shown to be profoundly successful at learning optimal policies for simulated environments using distributed training with extensive compute capacity. Model-free reinforcement learning uses the notion of trial and error , where the error is a vital part of learning the agent to behave optimally. In mission-critical, real-world environments, there is little tolerance for failure and can cause damaging effects on humans and equipment. In these environments, current state-of-the-art reinforcement learning approaches are not sufficient to learn optimal control policies safely. On the other hand, model-based reinforcement learning tries to encode environment transition dynamics into a predictive model . The transition dynamics describes the mapping from one state to another, conditioned on an action. If this model is accurate enough, the predictive model is sufficient to train agents for optimal behavior in real environments. This paper presents the Dreaming Variational Autoencoder (DVAE) for safely learning good policies with a significantly lower risk of catastrophes occurring during training. The algorithm combines variational autoencoders, risk-directed exploration, and curiosity to train deep-q networks inside ”dream” states. We introduce a novel environment, ASRS-Lab, for research in the safe learning of autonomous vehicles in grid-based warehousing. The work shows that the proposed algorithm has better sample efficiency with similar performance to novel model-free deep reinforcement learning algorithms while maintaining safety during training.},
  archive      = {J_ISCI},
  author       = {Per-Arne Andersen and Morten Goodwin and Ole-Christoffer Granmo},
  doi          = {10.1016/j.ins.2020.06.010},
  journal      = {Information Sciences},
  pages        = {467-484},
  shortjournal = {Inf. Sci.},
  title        = {Towards safe reinforcement-learning in industrial grid-warehousing},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 5′→3′ watson-crick pushdown automata. <em>ISCI</em>,
<em>537</em>, 452–466. (<a
href="https://doi.org/10.1016/j.ins.2020.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Watson-Crick automata work on two-stranded tape, and, consequently, they have two reading heads. In the case of sensing 5 ′ → 3 ′ 5′→3′ Watson-Crick automata , the two heads start from different ends of the input and they move in opposite directions until they meet. In this paper, an extension of these automata is presented by adding a pushdown stack. This model can also be seen as a 2-head extension of the pushdown automata . Acceptance by empty stack and acceptance by final states are proven to have the same recognition power in this new model. The language family recognized by this model contains only semi-linear context-sensitive languages and it includes the class of context-free languages. Some well-known non-context-free languages are shown as examples. Normal form like results, a pumping lemma and various closure properties are also proven.},
  archive      = {J_ISCI},
  author       = {Benedek Nagy},
  doi          = {10.1016/j.ins.2020.06.031},
  journal      = {Information Sciences},
  pages        = {452-466},
  shortjournal = {Inf. Sci.},
  title        = {5′→3′ watson-crick pushdown automata},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On-line anomaly detection with advanced independent
component analysis of multi-variate residual signals from causal
relation networks. <em>ISCI</em>, <em>537</em>, 425–451. (<a
href="https://doi.org/10.1016/j.ins.2020.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in todays industrial environments is an ambitious challenge to detect possible faults/problems which may turn into severe waste during production, defects, or systems components damage, at an early stage. Data-driven anomaly detection in multi-sensor networks rely on models which are extracted from multi-sensor measurements and which characterize the anomaly-free reference situation. Therefore, significant deviations to these models indicate potential anomalies . In this paper, we propose a new approach which is based on causal relation networks (CRNs) that represent the inner causes and effects between sensor channels (or sensor nodes) in form of partial sub-relations, and evaluate its functionality and performance on two distinct production phases within a micro-fluidic chip manufacturing scenario. The partial relations are modeled by non-linear (fuzzy) regression models for characterizing the (local) degree of influences of the single causes on the effects. An advanced analysis of the multi-variate residual signals , obtained from the partial relations in the CRNs, is conducted. It employs independent component analysis (ICA) to characterize hidden structures in the fused residuals through independent components (latent variables) as obtained through the demixing matrix. A significant change in the energy content of latent variables, detected through automated control limits, indicates an anomaly. Suppression of possible noise content in residuals—to decrease the likelihood of false alarms—is achieved by performing the residual analysis solely on the dominant parts of the demixing matrix. Our approach could detect anomalies in the process which caused bad quality chips (with the occurrence of malfunctions) with negligible delay based on the process data recorded by multiple sensors in two production phases: injection molding and bonding, which are independently carried out with completely different process parameter settings and on different machines (hence, can be seen as two distinct use cases). Our approach furthermore i.) produced lower false alarm rates than several related and well-known state-of-the-art methods for (unsupervised) anomaly detection, and ii.) also caused much lower parametrization efforts (in fact, none at all). Both aspects are essential for the useability of an anomaly detection approach.},
  archive      = {J_ISCI},
  author       = {Edwin Lughofer and Alexandru-Ciprian Zavoianu and Robert Pollak and Mahardhika Pratama and Pauline Meyer-Heye and Helmut Zörrer and Christian Eitzinger and Thomas Radauer},
  doi          = {10.1016/j.ins.2020.06.034},
  journal      = {Information Sciences},
  pages        = {425-451},
  shortjournal = {Inf. Sci.},
  title        = {On-line anomaly detection with advanced independent component analysis of multi-variate residual signals from causal relation networks},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multilabel feature selection using ML-ReliefF and
neighborhood mutual information for multilabel neighborhood decision
systems. <em>ISCI</em>, <em>537</em>, 401–424. (<a
href="https://doi.org/10.1016/j.ins.2020.05.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection as an essential preprocessing step in multilabel classification has been widely researched. Due to the diversity and complexity of multilabel datasets, some feature selection methods are unstable and yield low predictive accuracy . To address these issues, this paper presents a novel multilabel feature selection method using multilabel ReliefF (ML-ReliefF) and neighborhood mutual information in multilabel neighborhood decision systems. First, to solve the problem of the few available randomly selected samples when searching the nearest samples in ReliefF, the coefficient of difference and the average distance among the nearest similar and heterogeneous samples are introduced to evaluate the differences among the samples, and then the average differences among the similar or heterogeneous samples are defined. Using the Jaccard correlation coefficient , a new formula for updating feature weights is presented. Second, the margin of the sample is studied to granulate all samples under each label, and the concept of the neighborhood is given. By combining algebra with information views, some neighborhood entropy-based uncertainty measures for multilabel classification are investigated, and new neighborhood mutual information is proposed. Furthermore, an optimization objective function is constructed to evaluate the candidate features in multilabel neighborhood decision systems, all the properties are discussed, and the relationships of these measures are established. Finally, an improved ML-ReliefF algorithm is designed for preliminarily eliminating unrelated features to decrease the computational complexity for multilabel classification, and a heuristic forward multilabel feature selection algorithm is developed to remove redundant features and improve classification performance. Experimental results conducted on thirteen multilabel datasets to verify the effectiveness of the proposed algorithms in multilabel neighborhood decision systems are compared with representative methods.},
  archive      = {J_ISCI},
  author       = {Lin Sun and Tengyu Yin and Weiping Ding and Yuhua Qian and Jiucheng Xu},
  doi          = {10.1016/j.ins.2020.05.102},
  journal      = {Information Sciences},
  pages        = {401-424},
  shortjournal = {Inf. Sci.},
  title        = {Multilabel feature selection using ML-ReliefF and neighborhood mutual information for multilabel neighborhood decision systems},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on the coincidence of decomposition integrals and
superdecomposition integrals. <em>ISCI</em>, <em>537</em>, 394–400. (<a
href="https://doi.org/10.1016/j.ins.2020.05.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the decomposition integral I H IH and the superdecomposition integral I H IH related to the system H H of all finite chains from A ⧹ { ∅ } A⧹{∅} , where A A is a σ σ -algebra of the subsets of a nonvoid set X , coincide with each other for each monotone measure and for each nonnegative measurable function , and they are equal to the Choquet integral . In this note, we show that the converse is also true. That is, for a complete system H H of finite set systems from A ⧹ { ∅ } A⧹{∅} , if I H = I H IH=IH holds for each monotone measure and for each nonnegative measurable function , then the system H H and the system of all finite chains from A ⧹ { ∅ } A⧹{∅} are equivalent in some sense and the integrals involved are the Choquet integral .},
  archive      = {J_ISCI},
  author       = {Jun Li and Tingsu Yan and Yao Ouyang},
  doi          = {10.1016/j.ins.2020.05.133},
  journal      = {Information Sciences},
  pages        = {394-400},
  shortjournal = {Inf. Sci.},
  title        = {A note on the coincidence of decomposition integrals and superdecomposition integrals},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-attributed heterogeneous graph convolutional network
for bot detection. <em>ISCI</em>, <em>537</em>, 380–393. (<a
href="https://doi.org/10.1016/j.ins.2020.03.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bot detection is a fundamental and crucial task for tracing and mitigating cyber threats in the Internet. This paper aims to address two major limitations of current bot detection systems. First, existing flow-based bot detection approaches ignore structural information of botnets , which lead to false detection. Second, they cannot identify the interactive behavioral patterns among heterogeneous botnet objects. In this paper, we propose a novel bot detection framework, namely Bot-AHGCN, which models fine-grained network flow objects (e.g., IP, response) as a multi-attributed heterogeneous graph and transforms bot detection problem into a semi-supervised node classification task on the graph. Particularly, we first build a multi-attributed heterogeneous information network (AHIN) to model the interdependent relationships among botnet objects. Second, we present a weight-learning based node embedding method, which learns the interactive behavioral patterns among bots and integrates them into weighted similarity graphs . Finally, we perform graph convolution on the learned similarity graphs to characterize more comprehensive and discriminative features of bots, and feed them into a forward neural network to identify bots. The overall experimental results on two real-world datasets confirm that Bot-AHGCN outperforms the existing state-of-the-art approaches, and presents better interpretability by introducing meaningful meta-paths and meta-graphs.},
  archive      = {J_ISCI},
  author       = {Jun Zhao and Xudong Liu and Qiben Yan and Bo Li and Minglai Shao and Hao Peng},
  doi          = {10.1016/j.ins.2020.03.113},
  journal      = {Information Sciences},
  pages        = {380-393},
  shortjournal = {Inf. Sci.},
  title        = {Multi-attributed heterogeneous graph convolutional network for bot detection},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust fault detection of singular markov jump systems with
partially unknown information. <em>ISCI</em>, <em>537</em>, 368–379. (<a
href="https://doi.org/10.1016/j.ins.2020.05.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of robust fault detection for singular Markov jump systems with partially unknown transition probabilities is investigated in the paper. A fault detection observer is designed such that the residual signal is sensitive to fault signals and robust to unknown disturbances. By using Lyapunov function approach, sufficient conditions under which the system is stochastic stable with robustness and sensitiveness are given. Furthermore, an optimization problem is also derived. A simulation example is given to show the effectiveness.},
  archive      = {J_ISCI},
  author       = {Yanyan Yin and Jiangbin Shi and Fei Liu and Yanqing Liu},
  doi          = {10.1016/j.ins.2020.05.069},
  journal      = {Information Sciences},
  pages        = {368-379},
  shortjournal = {Inf. Sci.},
  title        = {Robust fault detection of singular markov jump systems with partially unknown information},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain probabilistic range queries on multidimensional
data. <em>ISCI</em>, <em>537</em>, 334–367. (<a
href="https://doi.org/10.1016/j.ins.2020.05.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Range Queries (PRQ) retrieve objects which, according to imprecise object properties, are (with a given probability) inside a precise range. When the query range is based on some imprecise object properties, which makes the query range imprecise as well, then Uncertain Probabilistic Range Queries (UPRQ) arise. Unfortunately, in the literature UPRQs ranges are constrained to be balls, i.e., the range is defined by providing a certain radius around an imprecise object property. Moreover, another important issue is the efficiency of answering UPRQs due to the necessary numerical operations to calculate probabilities. In this work we give a novel definition for UPRQs with query ranges of any shape; in addition we prove that any UPRQ can be reduced to a PRQ. Concerning the efficiency of UPRQs, we adopt and improve the usual way to address this family of queries (i.e., constructing indexes to prune/validate which objects belong to the answer, avoiding unnecessary numerical calculations) presenting: (1) a method to improve the filtering capabilities of the indexes when dealing with uniform distributions over rectangles or balls; and (2) a new index (eUD-Index), which enhances the state of the art, for any type of probability distribution. Our experiments show the feasibility of the proposals.},
  archive      = {J_ISCI},
  author       = {Jorge Bernad and Carlos Bobed and Eduardo Mena},
  doi          = {10.1016/j.ins.2020.05.068},
  journal      = {Information Sciences},
  pages        = {334-367},
  shortjournal = {Inf. Sci.},
  title        = {Uncertain probabilistic range queries on multidimensional data},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive neural quantized control for a class of switched
nonlinear systems. <em>ISCI</em>, <em>537</em>, 313–333. (<a
href="https://doi.org/10.1016/j.ins.2020.05.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses neural adaptive quantized control for switched nonlinear non-strict feedback systems. The systems under consideration have unknown virtual control coefficients , and the system states are unmeasurable. Another feature of the systems is that they have quantized input and output signals. The control objective is first to set up a robust switched observer, and then an adaptive neural tracking control strategy is proposed via estimated state feedback. By Lyapunov stability theory , we show that the constructed adaptive neural controller guarantees a small tracking error and the boundedness of all the closed-loop signals, despite the fact that the systems contain unknown virtual control coefficients , and quantized input and output signals. Eventually, two examples are employed to demonstrate the validity of our results.},
  archive      = {J_ISCI},
  author       = {Zhiliang Liu and Bing Chen and Chong Lin},
  doi          = {10.1016/j.ins.2020.05.096},
  journal      = {Information Sciences},
  pages        = {313-333},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive neural quantized control for a class of switched nonlinear systems},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Generating universal adversarial perturbation with ResNet.
<em>ISCI</em>, <em>537</em>, 302–312. (<a
href="https://doi.org/10.1016/j.ins.2020.05.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial machine learning , as a research area, has received a great deal of attention in recent years. Much of this attention has been devoted to a phenomenon called adversarial perturbation, which is human-imperceptible and can be used to craft adversarial examples . The deep neural networks are vulnerable to adversarial examples , which raises security concerns on learning algorithms due to the potentially severe consequences. It was shown there exist universal perturbations that are image-agnostic can fool the network when added to the majority of images. Since different attack strategies proposed for generating universal perturbation are still suffering from attack success rate, attack efficiency, and transferability. In this paper, we design an attack framework that uses a residual network (ResNet) to create universal perturbation. We introduce a trainable residual network generator that converts random noise into universal adversarial perturbation, which can be used to efficiently generate perturbations for any instance after being trained. Unlike traditional methods, moreover, we use a loss network to guarantee the similarity of images in content. The new generator structure and objective function make our method achieve better attack results than the existing methods. A variety of experiments conducted on the CIFAR-10 dataset reveal that our proposed attack framework constitutes an advance in the creation of universal adversarial perturbation, as it can achieve a success rate of 89\%, which outperforms the similar methods, along with low perturbation norms.},
  archive      = {J_ISCI},
  author       = {Jian Xu and Heng Liu and Dexin Wu and Fucai Zhou and Chong-zhi Gao and Linzhi Jiang},
  doi          = {10.1016/j.ins.2020.05.099},
  journal      = {Information Sciences},
  pages        = {302-312},
  shortjournal = {Inf. Sci.},
  title        = {Generating universal adversarial perturbation with ResNet},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Perceiving heavily occluded human poses by assigning
unbiased score. <em>ISCI</em>, <em>537</em>, 284–301. (<a
href="https://doi.org/10.1016/j.ins.2020.05.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of human pose estimation has been largely solved by the prevailing Deep Convolutional Neural Networks (DCNNs). However, heavily occluded human poses still represent great challenges. In this paper, we propose a new scoring method to perceive the detection of heavily occluded poses unbiasedly. The typical way of assigning scores to detected poses is to use the mean confidence of each joint . This makes poses with occlusion suppressed durng evaluation since invisible joints may have a much lower confidence than visible joints. We address this by identifying the visibility of each joint , an occlusion aware network is designed to predict both heatmaps and visible values of joints simultaneously. Thus, the degree of occlusion of a pose can be grasped, and a much fairer score is able to be set. Furthermore, a KS -net is proposed to predict the KS ( Keypoint Similarity ) between each estimated joint location and its matched ground-truth. The predicted KS calibrates localization accuracy better than the maximum heat value in heatmap. Pose score is calculated using the predicted visibility and KS value of each joint. The efficacy of our method is demonstrated on the most widely used MS-COCO pose dataset. Extensive experiments show that using our scoring approach can significantly improve the average precision of heavily occluded poses for the provided detections.},
  archive      = {J_ISCI},
  author       = {Lin Zhao and Jie Xu and Shanshan Zhang and Chen Gong and Jian Yang and Xinbo Gao},
  doi          = {10.1016/j.ins.2020.05.083},
  journal      = {Information Sciences},
  pages        = {284-301},
  shortjournal = {Inf. Sci.},
  title        = {Perceiving heavily occluded human poses by assigning unbiased score},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive clustering-based evolutionary algorithm for
many-objective optimization problems. <em>ISCI</em>, <em>537</em>,
261–283. (<a href="https://doi.org/10.1016/j.ins.2020.03.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive clustering-based evolutionary algorithm for many-objective optimization problems (MaOPs), called MaOEA/AC. In this algorithm, an adaptive clustering strategy (ACS) is first introduced to divide the population into multiple clusters, which can properly fit various Pareto fronts (PFs) of the target MaOPs. Then, the environmental selection of MaOEA/AC is designed based on these clusters to collect the solutions with balanceable convergence and diversity. To be more detail, the similarity between solutions in ACS is appropriately measured by computing the Euclidean distance between their projections on an adaptive unit hyper-surface, whose curving rate is controlled by a parameter p . A simple yet effective estimation method is proposed to get a suitable value of p based on the distribution of the current non-dominated solution set, so that the estimated unit hyper-surface can roughly reflect the characteristics of PFs in the target MaOPs. The effectiveness of MaOEA/AC is validated by numerous experimental studies on solving test MaOPs with various PFs, which have the characteristics with convex, concave, inverted, disconnected, degenerated, and other mixed or irregular PFs. The experiments also show that MaOEA/AC has the superior performance over several recent many-objective evolutionary algorithms, when solving most of these test MaOPs.},
  archive      = {J_ISCI},
  author       = {Songbai Liu and Qiyuan Yu and Qiuzhen Lin and Kay Chen Tan},
  doi          = {10.1016/j.ins.2020.03.104},
  journal      = {Information Sciences},
  pages        = {261-283},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive clustering-based evolutionary algorithm for many-objective optimization problems},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granular regression with a gradient descent method.
<em>ISCI</em>, <em>537</em>, 246–260. (<a
href="https://doi.org/10.1016/j.ins.2020.05.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regression is one of classical models in machine learning . Traditional regression algorithms involve operations of real values, which are difficult to handle the discrete or set data in information systems. Granules are structural objects on which agents perform complex computations. The structural objects are forms of sets that can measure the uncertainty of data. In order to deal with uncertain and vague data in the real world, we propose a set-based regression model: granular regression. Granules are constructed by introducing a distance metric on single-atom features. Meanwhile, we establish conditional granular vectors, weight granular vectors and decision granules. The operations among them induce a granular regression model. Furthermore, we propose a gradient descent method for the granular regression model, and the optimal solution of granular regression is achieved. We prove the convergence of granular regression and design a gradient descent algorithm. Finally, several UCI data sets are used to test and verify the granular regression model. We compare our proposed model with popular regression models from three aspects of convergence, fitting and prediction. The results show that the granular regression model is valid and effective.},
  archive      = {J_ISCI},
  author       = {Yumin Chen and Duoqian Miao},
  doi          = {10.1016/j.ins.2020.05.101},
  journal      = {Information Sciences},
  pages        = {246-260},
  shortjournal = {Inf. Sci.},
  title        = {Granular regression with a gradient descent method},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated retrieval framework for similar questions:
Word-semantic embedded label clustering – LDA with question life cycle.
<em>ISCI</em>, <em>537</em>, 227–245. (<a
href="https://doi.org/10.1016/j.ins.2020.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question retrieval is an extremely important research field in Community Question Answering (CQA). Most existing question retrieval methods depend on semantic analysis of questions, whose effectiveness suffers from the short texts of the noise words in the question corpus. In order to recommend the questions with more advanced knowledge to users, the influence of the questions’ popularity should be considered during retrieving questions. To make retrieved questions with both similar semantics and high popularity, we propose an Integrated Retrieval Framework for Similar Questions named Word-semantic Embedded Label Clustering – LDA with Question Life Cycle (WELQLC-QR), consisting of Word-semantic Embedded Label Clustering – LDA (WEL) and Question Life Cycle Optimization Similar Question List Strategy (QLC). Firstly, WEL is proposed for question retrieval from the perspective of semantic matching. It not only overcomes the problem of over-generalization of the semantic information extracted by topic models when facing short questions with multi-levels labels, but also avoids the influence of noise vocabularies during semantic extracting of the questions. Then, based on the internal factors (i.e., the number of comments and answers to the question) and external factors (i.e., programming language ranking information) of questions, QLC constructs a popularity-predicted model to optimize the similar question set searched by WEL, making the final retrieval results both semantically similar and popular. Finally, experiments are conducted on CQADupStack dataset, and results show that the MRR@N of WELQLC-QR model has an average increase of 8.99\%, 8.3\%, 4.74\% and 3.56\% compared with that of L-LDA, LC-LDA, BM25 and Word2vec, respectively.},
  archive      = {J_ISCI},
  author       = {Yue Liu and Aihua Tang and Zhibin Sun and Weize Tang and Fei Cai and Chengjin Wang},
  doi          = {10.1016/j.ins.2020.05.014},
  journal      = {Information Sciences},
  pages        = {227-245},
  shortjournal = {Inf. Sci.},
  title        = {An integrated retrieval framework for similar questions: Word-semantic embedded label clustering – LDA with question life cycle},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DMaOEA-εC: Decomposition-based many-objective evolutionary
algorithm with the ε-constraint framework. <em>ISCI</em>, <em>537</em>,
203–226. (<a href="https://doi.org/10.1016/j.ins.2020.05.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world problems which involve the optimization of multiple conflicting objectives are named as multi-objective optimization problems (MOPs). This paper mainly deals with the widespread and especially challenging many-objective optimization problem (MaOP) which is a category of the MOP with more than three objectives. Given the inefficiency of DMOEA- ε C which is a state-of-the-art decomposition-based multi-objective evolutionary algorithm with the ε -constraint framework when dealing with MaOPs, a number of strategies are proposed and embedded in DMOEA- ε C. To be specific, in order to overcome the ineffectiveness induced by exponential number of upper bound vectors, a two-stage upper bound vectors generation procedure is put forward to generate widely spread upper bound vectors in a high-dimensional space. Besides, a boundary points maintenance mechanism and a distance-based global replacement strategy are presented to remedy the diversity loss of a population. What’s more, given the feasibility rule adopted in DMOEA- ε C is simple but less effective, a two-side update rule which maintains both feasible and infeasible solutions for each subproblem is proposed to speed the convergence of a population. DMOEA- ε C with the above-mentioned strategies, denoted as DMaOEA- ε C, is designed for both multi- and many-objective optimization problems in this paper. DMaOEA- ε C is compared with five classical and state-of-the-art multi-objective evolutionary algorithms on 29 test instances to exhibit its performance on MOPs . Furthermore, DMaOEA- ε C is compared with five state-of-the-art many-objective evolutionary algorithms on 52 test problems to demonstrate its performance when dealing with MaOPs. Experimental studies show that DMaOEA- ε C outperforms or performs competitively against several competitors on the majority of MOPs and MaOPs with up to ten objectives.},
  archive      = {J_ISCI},
  author       = {Juan Li and Jie Li and Panos M. Pardalos and Chengwei Yang},
  doi          = {10.1016/j.ins.2020.05.097},
  journal      = {Information Sciences},
  pages        = {203-226},
  shortjournal = {Inf. Sci.},
  title        = {DMaOEA-εC: Decomposition-based many-objective evolutionary algorithm with the ε-constraint framework},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dense moment feature index and best match algorithms for
video copy-move forgery detection. <em>ISCI</em>, <em>537</em>, 184–202.
(<a href="https://doi.org/10.1016/j.ins.2020.05.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a video copy-move forgery detection method to effectively address inter/intra-frame forgeries both at the frame and pixel level . First, a unified moment framework is proposed to extract multi-dimensional dense moment features from the video effectively. Second, a novel feature representation method takes each feature sub-map index to represent its every dimensional feature and then concatenates to a 9-digit dense moment feature index. Third, an inter-frame best match algorithm is proposed to search the 9-digit dense moment feature index of each pixel to find its best matches. All the best matches construct the best match map. Fourth, an inter-frame post-processing algorithm identifies the inter-frame forgery video in the best match map firstly and then indicates the corresponding inter-frame forgery regions. Otherwise, the intra-frame post-processing algorithm re-searches the best match of every pixel in each independent frame and then indicates the intra-frame forgery regions. If the video does not belong to the intra-frame forgeries, the video is determined as a genuine one. The experimental results show that the proposed method is effective at addressing the forensics of the genuine/forgery video and locating the inter/intra-frame copy-move forgeries both at the frame and pixel level .},
  archive      = {J_ISCI},
  author       = {Jun-Liu Zhong and Chi-Man Pun and Yan-Fen Gan},
  doi          = {10.1016/j.ins.2020.05.134},
  journal      = {Information Sciences},
  pages        = {184-202},
  shortjournal = {Inf. Sci.},
  title        = {Dense moment feature index and best match algorithms for video copy-move forgery detection},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-band weighted lp norm minimization for image
denoising. <em>ISCI</em>, <em>537</em>, 162–183. (<a
href="https://doi.org/10.1016/j.ins.2020.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank matrix approximation (LRMA) has a wide range of applications in computer vision and has drawn much attention in recent years. A typical nuclear norm minimization (NNM) is often used to solve a LRMA, but this is likely to overshrink the rank components due to having the same threshold. To address this problem, we propose a flexible and precise model named multi-band weighted l p lp norm minimization (MBWPNM). We have reformulated it into nonconvex l p lp norm subproblems under certain weight conditions, and we solve these subproblems via a generalized soft-thresholding algorithm. We then adopt MBWPNM for image (grayscale, color and multispectral) denoising . The proposed MBWPNM not only guarantees a more accurate approximation with a Schatten p -norm in case of a change of noise levels, but it also considers prior knowledge, for which different rank components have varying importance. Extensive experiments on additive white Gaussian noise removal and realistic noise removal demonstrate that the proposed MBWPNM achieves better performance than several state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Yanchi Su and Zhanshan Li and Haihong Yu and Zeyu Wang},
  doi          = {10.1016/j.ins.2020.05.049},
  journal      = {Information Sciences},
  pages        = {162-183},
  shortjournal = {Inf. Sci.},
  title        = {Multi-band weighted lp norm minimization for image denoising},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A many-objective optimization recommendation algorithm based
on knowledge mining. <em>ISCI</em>, <em>537</em>, 148–161. (<a
href="https://doi.org/10.1016/j.ins.2020.05.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system (RS) is a technology that provides accurate recommendation for users. In order to make the recommendation results more accurate and diverse, we proposed a rating-based many-objective hybrid recommendation model that can optimize the accuracy, recall, diversity, novelty and coverage of the recommendation simultaneously. Additionally, a new generation-based fitness evaluation strategy and a partition-based knowledge mining strategy are proposed to improve the many-objective evolutionary algorithms (MaOEAs) to enhance the performance of the recommendations generated by the model. Finally, comparing the proposed many-objective optimization recommendation algorithm with the existing standard MaOEAs, experimental results demonstrate that the proposed algorithm can provide recommendations with the more and novel items on the basis of accuracy and diversity for users.},
  archive      = {J_ISCI},
  author       = {Xingjuan Cai and Zhaoming Hu and Jinjun Chen},
  doi          = {10.1016/j.ins.2020.05.067},
  journal      = {Information Sciences},
  pages        = {148-161},
  shortjournal = {Inf. Sci.},
  title        = {A many-objective optimization recommendation algorithm based on knowledge mining},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fall detection in older adults with mobile IoT devices and
machine learning in the cloud and on the edge. <em>ISCI</em>,
<em>537</em>, 132–147. (<a
href="https://doi.org/10.1016/j.ins.2020.05.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote monitoring of older adults and detecting dangers in the state of human health have become essential elements of modern telemedicine. Falls are a frequent reason for deaths or post-traumatic complications in the elderly. Therefore, the early detection of falls can be crucial for the survival of a person or for providing necessary support. However, telemedicine data centers require scalable computing and storage resources for the growing number of monitored people. Dedicated approaches that allow for minimal data transmission of strictly interesting cases are also required. In this paper, we show a scalable architecture of a system that can monitor thousands of older adults, detect falls, and notify caregivers. Scalability tests that disclose requirements to enable large scale system operations were also performed. Moreover, we validated several Machine Learning models to evaluate their suitability in the detection process. Among the tested models, Boosted Decisions Trees resulted in the best classification performance. We also experimentally tested the detection of falls inside a Cloud-based data center and on an Edge IoT device. Results of tests on the device-to-cloud data transmission confirmed that significant reduction in the size of stored and transmitted data can be achieved while performing fall detection on the Edge.},
  archive      = {J_ISCI},
  author       = {Dariusz Mrozek and Anna Koczur and Bożena Małysiak-Mrozek},
  doi          = {10.1016/j.ins.2020.05.070},
  journal      = {Information Sciences},
  pages        = {132-147},
  shortjournal = {Inf. Sci.},
  title        = {Fall detection in older adults with mobile IoT devices and machine learning in the cloud and on the edge},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive computation offloading and resource allocation
strategy in a mobile edge computing environment. <em>ISCI</em>,
<em>537</em>, 116–131. (<a
href="https://doi.org/10.1016/j.ins.2020.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of smart mobile equipment, the amount of data requested by users is growing rapidly. The traditional centralized processing method represented by the cloud computing model can no longer satisfy the effective processing of large amounts of data. Therefore, the mobile edge computing (MEC) is used as a new computing model to process the big growing data, which can better meet the service requirements. Similar to the task scheduling problem in cloud computing , an important issue in the MEC environment is task offloading and resource allocation. In this paper, we propose an adaptive task offloading and resource allocation algorithm in the MEC environment. The proposed algorithm uses the deep reinforcement learning (DRL) method to determine whether the task needs to be offloaded and allocates computing resources for the task. We simulate the generation of tasks in the form of Poisson distribution , and all tasks are submitted to be processed in the form of task flow. Besides, we consider the mobility of mobile user equipment (UE) between base stations (BSs), which is closer to the actual application environment. The DRL method is used to select the suitable computing node for each task according to the optimization objective , and the optimal strategy for solving the objective problem is learned in the algorithm training process. Compared with other comparison algorithms in different MEC environments, our proposed algorithm has the best performance in reducing the task average response time and the total system energy consumption, improving the system utility, which meets the profits of users and service providers.},
  archive      = {J_ISCI},
  author       = {Zhao Tong and Xiaomei Deng and Feng Ye and Sunitha Basodi and Xueli Xiao and Yi Pan},
  doi          = {10.1016/j.ins.2020.05.057},
  journal      = {Information Sciences},
  pages        = {116-131},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive computation offloading and resource allocation strategy in a mobile edge computing environment},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multigranulation behavioral three-way group decisions under
hesitant fuzzy linguistic environment. <em>ISCI</em>, <em>537</em>,
91–115. (<a href="https://doi.org/10.1016/j.ins.2020.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bounded rationality of decision-makers and interaction among criteria plays a key role in the actual multi-criteria group decision-making (MCGDM) process. This paper aims to offer a decision approach to a MCGDM problem under hesitant fuzzy linguistic (HFL) uncertainty, by means of behavioral multigranulation decision-theoretic rough set (DTRS), where criteria interaction is handled by Choquet integral , and decision-makers’ psychological preferences are considered by prospect theory. In specific, we firstly define the behavioral DTRS over two universes, where the threshold parameters are obtained by maximizing expected utility, rather than minimizing expected risk. Then, from the perspective of the difference of alternatives, we develop the calculation methods of loss and benefit functions, and provide the determination of the overall threshold parameters by Choquet integral , in consideration of criteria interaction. With these discussions, the behavioral multigranulation DTRS over two universes in the HFL context is proposed, and the two special cases, i.e., optimistic and pessimistic versions are also discussed. Thus, solutions to a MCGDM issue, green supplier selection, by utilizing the proposed behavioral multigranulation HFL DTRS over two universes, are designed, along with key steps and algorithm. Ultimately, an illustrative example is given to elaborate the practicability and feasibility of our presented model.},
  archive      = {J_ISCI},
  author       = {Wenjing Lei and Weimin Ma and Bingzhen Sun},
  doi          = {10.1016/j.ins.2020.05.025},
  journal      = {Information Sciences},
  pages        = {91-115},
  shortjournal = {Inf. Sci.},
  title        = {Multigranulation behavioral three-way group decisions under hesitant fuzzy linguistic environment},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three sequential multi-class three-way decision models.
<em>ISCI</em>, <em>537</em>, 62–90. (<a
href="https://doi.org/10.1016/j.ins.2020.05.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision conflict is a crucial issue of three-way decisions of multi-class. To overcome this limitation, there are mainly two ways. One is conflict resolution after decision-making, and the other is conflict resolution before decision-making. Considering insufficient information is a main cause of decision conflict, we propose a sequential approach to solve this problem by adding more detailed information step by step, which is conflict resolution during decision-making. Combining sequential approach with three methods to handle multi-class decision, which are converting m -class decision to m two-class decisions, based on pair-wise comparisons of m decision classes and directly making three-way decisions for each decision class of m -class simultaneously, we propose three sequential multi-class three-way decision models. At each level of three models, we define conflict region. In the sequential process of decision-making, for each model, only the objects belonging to one positive region with certain decision are assigned into corresponding decision classes, the objects in conflict region will be processed at the next level by adding more information sequentially. Finally, we compare the performance of three conflict resolutions and the performance of the proposed three models. Experimental results validate the effectiveness of the proposed three sequential multi-class three-way decision models.},
  archive      = {J_ISCI},
  author       = {Yi Xu and Jingxin Tang and Xusheng Wang},
  doi          = {10.1016/j.ins.2020.05.079},
  journal      = {Information Sciences},
  pages        = {62-90},
  shortjournal = {Inf. Sci.},
  title        = {Three sequential multi-class three-way decision models},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integration of genetic algorithms and neural networks for
the formation of the classifier of the hierarchical choquet integral.
<em>ISCI</em>, <em>537</em>, 46–61. (<a
href="https://doi.org/10.1016/j.ins.2020.05.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Choquet integral model is mainly applied to describe non-additive multi-criteria decision-making (MCDM) problems. This paper considers the Choquet integral as a classifier which deals with complicated high-dimensional data. Although previously conducted studies have investigated the problem of classification using the Choquet integral and provided corresponding models, these models usually need to estimate a large number of fuzzy measure coefficients, which are not suitable when considering real situations. Sugeno et al. proposed the hierarchical Choquet integral (HCI) model to overcome this problem. However, the HCI model requires partition information of the criteria, which often cannot be obtained practically. This paper proposes two HCI models—shallow and deep models—by employing genetic algorithms (GAs) and neural networks (NNs) to automatically construct the structure of the HCI. The results of numerical experiments show that the proposed model outperforms the existing Naïve Bayes, decision tree, and NN models.},
  archive      = {J_ISCI},
  author       = {Chin-Yi Chen and Jih-Jeng Huang},
  doi          = {10.1016/j.ins.2020.05.063},
  journal      = {Information Sciences},
  pages        = {46-61},
  shortjournal = {Inf. Sci.},
  title        = {Integration of genetic algorithms and neural networks for the formation of the classifier of the hierarchical choquet integral},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiattribute decision making based on u-quadratic
distribution of intervals and the transformed matrix in interval-valued
intuitionistic fuzzy environments. <em>ISCI</em>, <em>537</em>, 30–45.
(<a href="https://doi.org/10.1016/j.ins.2020.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiattribute decision making (MADM) method based on the U -quadratic distribution of intervals and the transformed matrix of the decision matrix given by the decision maker in interval-valued intuitionistic fuzzy (IVIF) environments. First, it gets the transformed matrix of the decision matrix . Then, it calculates the variances of the intervals appearing at each element of the obtained transformed matrix, respectively. Then, it calculates the standard deviations of the intervals appearing in the elements of each column of the obtained transformed matrix, respectively. Then, it calculates the middle points of the intervals appearing in the elements of each column of the obtained transformed matrix, respectively. Then, it calculates the average values of the intervals appearing in the elements of each column of the obtained transformed matrix, respectively. Then, it builds the z -score matrix. Then, it calculates the transformed weight of the IVIF weight of each attribute. Finally, according to the obtained z -score matrix and the obtained transformed weight of the IVIF weight of each attribute, it computes the weighted score of each alternative for ranking alternatives. The proposed MADM method can overcome the shortcomings of the existing MADM methods.},
  archive      = {J_ISCI},
  author       = {Shyi-Ming Chen and Yun-Chen Chu},
  doi          = {10.1016/j.ins.2020.04.032},
  journal      = {Information Sciences},
  pages        = {30-45},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on U-quadratic distribution of intervals and the transformed matrix in interval-valued intuitionistic fuzzy environments},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the negation of discrete z-numbers. <em>ISCI</em>,
<em>537</em>, 18–29. (<a
href="https://doi.org/10.1016/j.ins.2020.05.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The negation of a problem provides a new perspective for information representation. However, existing negation method has limitations since it can only be applied to the accurately expressed knowledge. Real-world information is imperfect and imprecise. It usually describes in natural language. In view of this, Prof. Zadeh suggested the concept of Z-number as a more adequate way for description of real world information. As Z-number involves both fuzzy and probabilistic uncertainty, a novel method for the negation of Z-number in combination of probability and fuzziness is proposed from the reliability of probability transmission in this paper. Moreover, several examples are used to describe the negation process and result. As far as our latest knowledge is concerned, the negation of Z-number has not been covered by researchers, so this may be another door for us to process Z-number-based information.},
  archive      = {J_ISCI},
  author       = {Qing Liu and Huizi Cui and Ye Tian and Bingyi Kang},
  doi          = {10.1016/j.ins.2020.05.106},
  journal      = {Information Sciences},
  pages        = {18-29},
  shortjournal = {Inf. Sci.},
  title        = {On the negation of discrete Z-numbers},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Input selection methods for data-driven soft sensors design:
Application to an industrial process. <em>ISCI</em>, <em>537</em>, 1–17.
(<a href="https://doi.org/10.1016/j.ins.2020.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft Sensors (SSs) are inferential models which are widely used in industry. They are generally built through data-driven approaches that exploit industry historical databases. Selection of input variables is one of the most critical issues in SSs design. This paper aims at highlighting difficulties arising from the implementation of data-driven input selection methods when solving real-world case studies. A procedure is, therefore, proposed for input selection, based on both data-driven and expert-driven input selection methods. The procedure allows designing SSs with good prediction accuracy and a low number of inputs. The design of an SS for a real-world industrial process is used. The results reported show that the selection methods proposed in literature do not give consistent results when applied to the considered case study. The key role for plant expert knowledge emerges, outlining the opportunity of judicious use of automatic data-driven procedures.},
  archive      = {J_ISCI},
  author       = {Francesco Curreri and Salvatore Graziani and Maria Gabriella Xibilia},
  doi          = {10.1016/j.ins.2020.05.028},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Input selection methods for data-driven soft sensors design: Application to an industrial process},
  volume       = {537},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A burst-based unsupervised method for detecting review
spammer groups. <em>ISCI</em>, <em>536</em>, 454–469. (<a
href="https://doi.org/10.1016/j.ins.2020.05.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of e-commerce, online shopping has become a part of people&#39;s life. As customers often refer to online product reviews for shopping, sellers often collude with review spammers in writing fake reviews to promote or demote target products. In particular, spammers working in groups are more harmful than individual attacks. To detect such spammer groups, previous researchers proposed some frequent item mining based algorithms and graph-based algorithms. In this paper, we propose a method called GSDB ( Group Spam Detection algorithm based on review Burst ). Our algorithm first locates target products attacked by spammers by detecting the abnormality of product rating distribution. As group spammers usually post many fake reviews within a short period, we design a burst-based algorithm that discovers candidate spammer groups in reviewbursts using the Kernel Density Estimation algorithm. As some innocent reviewers may coincidently review during the burst period, we formulate a variety of individual spam indicators to measure the spamicity of the reviewers to isolate the candidate spammer groups. Finally, we design a series of group spam indicators to measure and classify the spamicity of spammer groups. Experimental results show that our proposed GSDB algorithm outperforms state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Shu-juan Ji and Qi Zhang and Jinpeng Li and Dickson K.W. Chiu and Shaohua Xu and Lei Yi and Maoguo Gong},
  doi          = {10.1016/j.ins.2020.05.084},
  journal      = {Information Sciences},
  pages        = {454-469},
  shortjournal = {Inf. Sci.},
  title        = {A burst-based unsupervised method for detecting review spammer groups},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NEC: A nested equivalence class-based dependency calculation
approach for fast feature selection using rough set theory.
<em>ISCI</em>, <em>536</em>, 431–453. (<a
href="https://doi.org/10.1016/j.ins.2020.03.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an important role in data mining and machine learning tasks. As one of the most effective methods for feature selection, rough set theory provides a systematic theoretical framework for consistency-based feature selection, in which positive region-based dependency calculation is the most important step. However, it is time-consuming, and although many improved algorithms have been proposed, they are still computationally time-consuming. Therefore, to overcome this shortcoming, in this study, a nested equivalence class (NEC) approach is introduced to calculate dependency. The proposed method starts from the finest partition of the universe, and then extracts and uses the known knowledge of reducts in a decision table to construct an NEC. The proposed method not only simplifies dependency calculation but also reduces the universe correspondingly, in most cases. Using the proposed NEC-based approach, a number of representative heuristic- and swarm intelligence-based feature selection algorithms that apply rough set theory were enhanced. Note that the feature subset selected by each modified algorithm and that selected by the original algorithm were the same. Experiments conducted using 33 datasets from the UCI repository and KDD Cup competition, which included large-scale and high-dimensional datasets, demonstrated the efficiency and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jie Zhao and Jia-ming Liang and Zhen-ning Dong and De-yu Tang and Zhen Liu},
  doi          = {10.1016/j.ins.2020.03.092},
  journal      = {Information Sciences},
  pages        = {431-453},
  shortjournal = {Inf. Sci.},
  title        = {NEC: A nested equivalence class-based dependency calculation approach for fast feature selection using rough set theory},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated data and knowledge driven methodology for human
activity recognition. <em>ISCI</em>, <em>536</em>, 409–430. (<a
href="https://doi.org/10.1016/j.ins.2020.03.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition has been a popular research area concerned with identifying the specific movement or action of a person based on variety of sensor data. Conventional human activity recognition approaches are mainly data driven, which are not working well for composite activity recognition due to the complexity and uncertainty of real scenarios. We propose in this paper a hierarchical structure-based framework and methodology for human activity recognition by an integration of data-driven approach and knowledge-based approach, which provides an interesting framework capable of bridging lower-level pattern recognition and higher-level knowledge for reasoning and explanation. More specifically, this approach constructs a hierarchical structure for representing the composite activity by a composition of lower-level actions and gestures according to its semantic meaning. This hierarchical structure is then transformed into formal syntactical logical formulas and rules, based on which the resolution based automated reasoning is applied to recognize the composite activity given the recognized lower-level actions by using data driven machine learning methods. The work is the validated using some open-source data about video based human activity recognition. The present work provides a promising framework and application illustration of integration of machine learning and symbolic reasoning.},
  archive      = {J_ISCI},
  author       = {Hairui Jia and Shuwei Chen},
  doi          = {10.1016/j.ins.2020.03.081},
  journal      = {Information Sciences},
  pages        = {409-430},
  shortjournal = {Inf. Sci.},
  title        = {Integrated data and knowledge driven methodology for human activity recognition},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamical analysis of rumor spreading model in multi-lingual
environment and heterogeneous complex networks. <em>ISCI</em>,
<em>536</em>, 391–408. (<a
href="https://doi.org/10.1016/j.ins.2020.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel rumor propagation model with education mechanism is firstly proposed in multi-lingual environment and heterogeneous networks . Firstly, the threshold behaviour and dynamics of model are examined through analyzing the acquired differential equations. Next, based on Routh-Hurwitz judgment, Lyapunov method and LaSalle’s invariance principle , the existence and stability of rumor-free/spreading equilibrium points (RFEP/RSEP) are carried out. Furthermore, we found that the educational mechanism has significance influence on rumor spreading through sensitivity analysis. Therefore, the optimal control is presented to optimize the educational mechanism. Additionally, numerical simulations is given to show the correctness of theoretical results. Finally, combine with practice, a model application is presented to verify the effectiveness of the established model and the proposed optimal control .},
  archive      = {J_ISCI},
  author       = {Jiarong Li and Haijun Jiang and Xuehui Mei and Cheng Hu and Guoliang Zhang},
  doi          = {10.1016/j.ins.2020.05.037},
  journal      = {Information Sciences},
  pages        = {391-408},
  shortjournal = {Inf. Sci.},
  title        = {Dynamical analysis of rumor spreading model in multi-lingual environment and heterogeneous complex networks},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A coalition-structure’s generation method for solving
cooperative computing problems in edge computing environments.
<em>ISCI</em>, <em>536</em>, 372–390. (<a
href="https://doi.org/10.1016/j.ins.2020.05.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coalition-structure’s generation methods are usually employed to solve team allocation optimization problems or cooperative computing scheduling problems in the case of multitasking concurrency. In edge computing environments, affected by such factors as a large number of edge nodes, weak computing power, multiple optimization objectives and multiple constraints, the traditional methods can hardly guarantee the optimization speed and the optimal solution’s quality when solving similar problems. Based on the advantages of cooperative game algorithms and heuristic algorithms , we propose a coalition-structure’s generation method suitable for edge computing environments in this paper. Firstly, we introduce the concept of bargaining set and remove the impossible coalition-structures by judging the no-bargain coalition to narrow the strategic space. Secondly, for increasing the optimization speed and the optimal solution’s quality, we improve the inertia weight computing method and the particle state determination method of the primary discrete particle swarm , propose M-ary discrete particle swarm optimization (MDPSO). Finally, we design a series of contrast experiments and verify that this method boasts obvious advantages in optimization speed, the optimal solution’s quality, stability, and other aspects.},
  archive      = {J_ISCI},
  author       = {Kejia Zhang and Yanan Hu and Feng Tian and Chunsheng Li},
  doi          = {10.1016/j.ins.2020.05.061},
  journal      = {Information Sciences},
  pages        = {372-390},
  shortjournal = {Inf. Sci.},
  title        = {A coalition-structure’s generation method for solving cooperative computing problems in edge computing environments},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge instability: A critical parameter for the propagation
and robustness analysis of large networks. <em>ISCI</em>, <em>536</em>,
358–371. (<a href="https://doi.org/10.1016/j.ins.2020.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many large networks, such as social networks and web graphs, have been found to exhibit a variety of different interesting features. The dynamic properties of large networks, such as the propagation and robustness feature, have been actively investigated over the past years. In our research, we attempted to understand the propagation and robustness feature of large networks quantitatively. Specifically, we employed a critical parameter based on network topology , Edge Instability ( EI ), to study the propagation feature. Our experimental results indicate that, compared with the existing propagation strategies, the EI -based strategy has a more serious impact on information propagation in large networks. Furthermore, we investigated the robustness performance of large networks by evaluating their connectivity in the scenario that some edges are removed gradually. The experimental results show that, among the existing edge removing strategies, removing edges with high EI hurts network robustness most. Finally, in order to understand the influence of the average EI of a network, we devised an evolution model to generate large networks with varied average EI . We found that the average EI has a significant impact on information propagation. However, it has an unnoticeable influence on network robustness when EI -based strategies are adopted.},
  archive      = {J_ISCI},
  author       = {Lei Wang and Liang Li and Guoxiong Chen and Qiang Ye},
  doi          = {10.1016/j.ins.2020.05.027},
  journal      = {Information Sciences},
  pages        = {358-371},
  shortjournal = {Inf. Sci.},
  title        = {Edge instability: A critical parameter for the propagation and robustness analysis of large networks},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Necessary and sufficient conditions for the existence of
solution of generalized fuzzy relation equations a ⇔x = b.
<em>ISCI</em>, <em>536</em>, 351–357. (<a
href="https://doi.org/10.1016/j.ins.2020.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2013 Li and Jin studied a particular type of fuzzy relational equations on finite sets, where the introduced min-bi-implication composition is based on Łukasiewicz equivalence. In this paper such fuzzy relation equations are studied on a more general level, namely complete residuated lattice valued fuzzy relation equations of type ⋀ y ∈ Y ( A ( x , y ) ↔ X ( y ) = B ( x ) ⋀y∈Y(A(x,y)↔X(y)=B(x) are analyzed, and the existence of solutions S S is studied. First a necessary condition for the existence of solution is established, then conditions for lower and upper limits of solutions are given, and finally sufficient conditions for the existence of the smallest and largest solutions, respectively, are characterized. If such general or global solutions do not exist, there might still be partial or point wise solutions; this is a novel way to study fuzzy relation equations. Such point wise solutions are studied on Łukasiewicz , Product and Gödel t-norm based residuated lattices on the real unit interval.},
  archive      = {J_ISCI},
  author       = {Esko Turunen},
  doi          = {10.1016/j.ins.2020.05.015},
  journal      = {Information Sciences},
  pages        = {351-357},
  shortjournal = {Inf. Sci.},
  title        = {Necessary and sufficient conditions for the existence of solution of generalized fuzzy relation equations a ⇔X = b},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Almost periodic dynamics of memristive inertial neural
networks with mixed delays. <em>ISCI</em>, <em>536</em>, 332–350. (<a
href="https://doi.org/10.1016/j.ins.2020.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the physical properties (switching behavior) of the memristor, the resistors in the VLSI circuit of inertial neural networks is exchanged by the memristors then the VLSI circuit is known as memristive inertial neural networks (MINNs). In this manuscript, the authors concentrate on examining the almost periodic dynamics of memristive inertial neural networks with mixed time delays . First, the considered MINNs model is converted into two first-order system with the support of an appropriate variable transformation. Then, by means of a matrix measure scheme and Halanay inequality, some sufficient criteria are achieved to guarantee the global exponential stability of the periodic solutions of MINNs with mixed time delays . Furthermore, our theoretical results on the almost periodicity of MINNs with mixed time delays is a newfangled. Finally, simulation examples are elucidated to spectacle the value of the attaining main results of this manuscript.},
  archive      = {J_ISCI},
  author       = {Rakkiyappan Rajan and Velmurugan Gandhi and Premalatha Soundharajan and Young Hoon Joo},
  doi          = {10.1016/j.ins.2020.05.055},
  journal      = {Information Sciences},
  pages        = {332-350},
  shortjournal = {Inf. Sci.},
  title        = {Almost periodic dynamics of memristive inertial neural networks with mixed delays},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Dynamic imaging inversion with double deep learning
networks for cameras. <em>ISCI</em>, <em>536</em>, 317–331. (<a
href="https://doi.org/10.1016/j.ins.2020.05.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve high-quality imaging in low-light conditions, a remote sensing camera usually adopts a dynamic time-delay-integration imaging approach, which requires an accurate matching relationship between the optical image field motion and the photo-induced charge transfer. High-frequency motion aberrations still exist due to the measurement frequency limitation of physical attitude and position measurement sensors. However, conventional inversion imaging methods, such as blind deconvolution , can only measure and remove low-frequency motion aberrations. Here, an efficient dynamic inversion imaging algorithm based on double deep learning networks is proposed, which is able to measure and remove high-frequency motion aberrations. To measure high-frequency motion aberrations, we constructed two supervised online deep learning networks, a high-frequency motion aberration inversion learning network (HMAILN) and an optical flow inversion learning network (OFILN). The OFILN can measure the accurate optical flow information, which forms the input training set of the HMAILN. The HMAILN completes the measurement of high-frequency motion aberrations. Finally, the measured high-frequency motion aberrations from the HMAILN were used to construct the motion point spread function for imaging compensation to remove high-frequency motion aberrations. The proposed method was experimentally confirmed, opening the door for the successful implementation of dynamic high-resolution imaging without high-frequency motion aberrations.},
  archive      = {J_ISCI},
  author       = {Jin Li and Yanyan Liu and Zilong Liu},
  doi          = {10.1016/j.ins.2020.05.072},
  journal      = {Information Sciences},
  pages        = {317-331},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic imaging inversion with double deep learning networks for cameras},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved general attribute reduction algorithms.
<em>ISCI</em>, <em>536</em>, 298–316. (<a
href="https://doi.org/10.1016/j.ins.2020.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is a critical issue in rough sets theory . In recent years, there are many kinds of attribute reduction proposed, such as positive region preservation reduction, generalized decision preservation reduction, distribution preservation reduction, maximum distribution preservation reduction, and relative discernibility relation preservation reduction. General reduction approaches to obtaining various types of reducts also have been explored, but they are computationally time-consuming in the condition of large-scale data processing. In this study, we focus on the efficient general reduction algorithm to obtain five typical reducts mentioned above. At first, we introduce a concept called granularity space to establish a unified representation of five typical reducts. Based on the unified representation, we construct two quick general reduction algorithms by extending the positive region approximation to the granularity space. Then, we conduct a series of comparisons with existing reduction algorithms in aspects of theoretical analysis and experiments to evaluate the performance of the proposed algorithms. The results of analysis and experiments indicate that the proposed algorithms are effective and efficient.},
  archive      = {J_ISCI},
  author       = {Baizhen Li and Zhihua Wei and Duoqian Miao and Nan Zhang and Wen Shen and Chang Gong and Hongyun Zhang and Lijun Sun},
  doi          = {10.1016/j.ins.2020.05.043},
  journal      = {Information Sciences},
  pages        = {298-316},
  shortjournal = {Inf. Sci.},
  title        = {Improved general attribute reduction algorithms},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiscale fusion and aggregation PCNN for 3D shape
recovery. <em>ISCI</em>, <em>536</em>, 277–297. (<a
href="https://doi.org/10.1016/j.ins.2020.05.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape from focus (SFF) is a widely used method for recovering the three-dimensional (3D) shape of an object from an image sequence with various focus measure operators. However, most previous studies have focused on evaluating the depth map using a specified focus measure operator based on a single perspective. These methods severely limit the accuracy of the reconstruction results for a complex real scene. In this study, a novel SFF method based on a multiscale fusion perspective is proposed. First, the feasibility of obtaining a mapping relationship between high-frequency coefficients and the depth maps by the stationary wavelet transform (SWT) is discussed. Next, level reduction is introduced to approximate the target depth map using multilevel high-frequency coefficients. Then, an aggregation pulse coupled neural network (a-PCNN) model with variable-size cross sum modified Laplacian (CSML) operators is used as the mapping functions from selected high-frequency coefficients to various window size depth maps. Finally, a hierarchical screening method (HSM) is proposed to yield a more accurate reconstruction result by fusing depth maps with various window sizes. The experimental results demonstrate that the proposed method realizes a more accurate depth map estimation and better surface consistency of the reconstruction results than the compared SFF methods and several advanced multifocus image fusion methods.},
  archive      = {J_ISCI},
  author       = {Tao Yan and Peng Wu and Yuhua Qian and Zhiguo Hu and Fengxian Liu},
  doi          = {10.1016/j.ins.2020.05.100},
  journal      = {Information Sciences},
  pages        = {277-297},
  shortjournal = {Inf. Sci.},
  title        = {Multiscale fusion and aggregation PCNN for 3D shape recovery},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An information-theoretic instance-based classifier.
<em>ISCI</em>, <em>536</em>, 263–276. (<a
href="https://doi.org/10.1016/j.ins.2020.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification algorithms are used in many areas to determine new class labels given a training set. Many classification algorithms, linear or not, require a training phase to determine model parameters by using an iterative optimization of the cost function for that particular model or algorithm. The training phase can adjust and fine-tune the boundary line between classes. However, the process may get stuck in a local optimum, which may or may not be close to the desired solution. Another disadvantage of training processes is that upon arrival of a new sample, a retraining of the model is necessary. This work presents a new information-theoretic approach to an instance-based supervised classification. The boundary line between classes is calculated only by the data points without any external parameters or weights, and it is given in closed-form. The separation between classes is nonlinear and smooth, which reduces memorization problems. Since the method does not require a training phase, classified samples can be incorporated in the training set directly, simplifying a streaming classification operation. The boundary line can be replaced with an approximation or regression model for parametric calculations. Features and performance of the proposed method are discussed and compared with similar algorithms.},
  archive      = {J_ISCI},
  author       = {Erhan Gokcay},
  doi          = {10.1016/j.ins.2020.05.031},
  journal      = {Information Sciences},
  pages        = {263-276},
  shortjournal = {Inf. Sci.},
  title        = {An information-theoretic instance-based classifier},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving krawtchouk moment feature extraction over
encrypted image data. <em>ISCI</em>, <em>536</em>, 244–262. (<a
href="https://doi.org/10.1016/j.ins.2020.05.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource-constrained users outsource the massive image data to the cloud to reduce storage and computation overhead locally, but security and privacy concerns seriously hinder the applications of outsourced image processing services. Besides, existing image processing solutions in the encrypted domain still bring high computation overhead, and even lead to characteristic loss. To this end, we propose a Privacy-Preserving Krawtchouk Moment (PPKM) feature extraction framework over encrypted image data by utilizing the Paillier cryptosystem. First, a mathematical framework for PPKM implementation and image reconstruction is presented in the encrypted domain. Then, the detailed expanding factor and upper bound analysis shows that plaintext Krawtchouk moment and plaintext image reconstruction can be realized over encrypted image with PPKM. Furthermore, the computation complexity of PPKM can be significantly reduced with the block-based parallel algorithm . Experimental results verify that the PPKM is feasible and acceptable in practice in terms of image reconstruction capability and image recognition accuracy.},
  archive      = {J_ISCI},
  author       = {Tengfei Yang and Jianfeng Ma and Yinbin Miao and Ximeng Liu and Xuan Wang and Bin Xiao and Qian Meng},
  doi          = {10.1016/j.ins.2020.05.093},
  journal      = {Information Sciences},
  pages        = {244-262},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving krawtchouk moment feature extraction over encrypted image data},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute-based fine-grained access control for outscored
private set intersection computation. <em>ISCI</em>, <em>536</em>,
222–243. (<a href="https://doi.org/10.1016/j.ins.2020.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private set intersection (PSI) is a fundamental cryptographic protocol which has a wide range of applications. It enables two clients to compute the intersection of their private datasets without revealing non-matching elements. The advent of cloud computing drives the ambition to reduce computation and data management overhead by outsourcing such computations. However, since the cloud is not trustworthy, some cryptographic methods should be applied to maintain the confidentiality of datasets. But, in doing so, data owners may be excluded from access control on their outsourced datasets. Therefore, to control access rights and to interact with authorized users, they have to be online during the protocol. On the other hand, none of the existing cloud-based PSI schemes support fine-grained access control over outsourced datasets. This paper, for the first time, proposes an attribute-based private set intersection (AB-PSI) scheme providing fine-grained access control. AB-PSI allows a data owner to control intersection computations on its outsourced dataset by defining an access control policy. We also provide security definitions for an AB-PSI scheme and prove the security of our scheme in the standard model. We implement our scheme and report performance evaluation results.},
  archive      = {J_ISCI},
  author       = {Mohammad Ali and Javad Mohajeri and Mohammad-Reza Sadeghi and Ximeng Liu},
  doi          = {10.1016/j.ins.2020.05.041},
  journal      = {Information Sciences},
  pages        = {222-243},
  shortjournal = {Inf. Sci.},
  title        = {Attribute-based fine-grained access control for outscored private set intersection computation},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Negation scope detection for sentiment analysis: A
reinforcement learning framework for replicating human interpretations.
<em>ISCI</em>, <em>536</em>, 205–221. (<a
href="https://doi.org/10.1016/j.ins.2020.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Textual materials represent a rich source of information for improving the decision-making of people, businesses and organizations. However, for natural language processing (NLP), it is difficult to correctly infer the meaning of narrative content in the presence of negations. The reason is that negations can be formulated both explicitly (e.g., by negation words such as “not”) or implicitly (e.g., by expressions that invert meanings such as “forbid”) and that their use is further domain-specific. Hence, NLP requires a dynamic learning framework for detecting negations and, to this end, we develop a reinforcement learning framework for this task. Formally, our approach takes document-level labels (e.g., sentiment scores) as input and then learns a negation policy based on the document-level labels. In this sense, our approach replicates human perceptions as provided by the document-level labels and achieves a superior prediction performance. Furthermore, it benefits from weak supervision; meaning that the need for granular and thus expensive word-level annotations, as in prior literature, is replaced by document-level annotations. In addition, we propose an approach to interpretability: by evaluating the state-action table, we yield a novel form of statistical inference that allows us to test which linguistic cues act as negations.},
  archive      = {J_ISCI},
  author       = {Nicolas Pröllochs and Stefan Feuerriegel and Bernhard Lutz and Dirk Neumann},
  doi          = {10.1016/j.ins.2020.05.022},
  journal      = {Information Sciences},
  pages        = {205-221},
  shortjournal = {Inf. Sci.},
  title        = {Negation scope detection for sentiment analysis: A reinforcement learning framework for replicating human interpretations},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental feature selection based on fuzzy rough sets.
<em>ISCI</em>, <em>536</em>, 185–204. (<a
href="https://doi.org/10.1016/j.ins.2020.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incremental feature selection can improve learning of accumulated data. We focus on incremental feature selection based on rough sets, which along with their generalizations (e.g., fuzzy rough sets), reduce dimensionality without requiring domain knowledge, such as data distributions. By analyzing the basic concepts of fuzzy rough sets on incremental datasets, we propose incremental mechanisms of information measure. Moreover, we introduce a key instance set containing representative instances to select supplementary features when new instances arrive. As the key instance set is much smaller than the whole dataset, the proposed incremental feature selection mostly suppresses redundant computations. We experimentally compare the proposed method with various non-incremental and two state-of-the-art incremental methods on a variety of datasets. The comparison results demonstrate that the proposed method achieves compact results with reduced computation time, especially on high-dimensional datasets.},
  archive      = {J_ISCI},
  author       = {Peng Ni and Suyun Zhao and Xizhao Wang and Hong Chen and Cuiping Li and Eric C.C. Tsang},
  doi          = {10.1016/j.ins.2020.04.038},
  journal      = {Information Sciences},
  pages        = {185-204},
  shortjournal = {Inf. Sci.},
  title        = {Incremental feature selection based on fuzzy rough sets},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semi-supervised multi-view clustering based on
orthonormality-constrained nonnegative matrix factorization.
<em>ISCI</em>, <em>536</em>, 171–184. (<a
href="https://doi.org/10.1016/j.ins.2020.05.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering aims at integrating the complementary information between different views so as to obtain an accurate clustering result . In addition, the traditional clustering is a kind of unsupervised learning method, which does not take the label information into learning. In this paper, we propose a novel model, called semi-supervised multi-view clustering based on orthonormality-constrained nonnegative matrix factorization (MVOCNMF), to cluster the multi-view data into a number of categories. In the proposed model, based on the label information, we first learn the low-dimensional representations of data by the constrained NMF technique, and simultaneously cluster the samples with the same label into the clustering prototypes for each view. After that, we put forward a novel orthonormality constraint term to obtain the desirable representations for each view, and use the co-regularization to integrate the complementary information from different views. We further develop an alternating minimization algorithm to solve the proposed model, and present the convergence analysis and computational complexity of the proposed method. Extensive experimental results on several multi-view datasets have shown that the proposed MVOCNMF method outperforms the existing multi-view clustering methods .},
  archive      = {J_ISCI},
  author       = {Hao Cai and Bo Liu and Yanshan Xiao and LuYue Lin},
  doi          = {10.1016/j.ins.2020.05.073},
  journal      = {Information Sciences},
  pages        = {171-184},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised multi-view clustering based on orthonormality-constrained nonnegative matrix factorization},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New technique to alleviate the cold start problem in
recommender systems using information from social media and random
decision forests. <em>ISCI</em>, <em>536</em>, 156–170. (<a
href="https://doi.org/10.1016/j.ins.2020.05.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of recommender systems is to provide users with items that could be of their interest. However one of the biggest drawbacks from recommender systems is the so called cold start problem, which occurs when new users or products are added to the system and therefore there is no previous information about them. There are many proposals in the literature that aim to deal with this issue. In some cases the user is required to provide some explicit information about them, which demands some effort on their part. Because of that and due to the great boom of social networks, we will focus on extracting implicit information from user’s social stream. In this paper we will present an approach on which social media data will be used to create a behavioural profile to classify the users and based on this classification will create predictions making use of machine learning techniques such as classification trees and random forests . Thus the user will not have to provide actively any kind of data explicitly but their social media source, alleviating in this way the cold start problem since the system would use this data in order to create user profiles, which will be the input for the engine of the recommender systems. We have carried out numerous experiments, as well as a comparison with some other state-of-the-art new user cold-start algorithms, obtaining very satisfactory results.},
  archive      = {J_ISCI},
  author       = {J. Herce-Zelaya and C. Porcel and J. Bernabé-Moreno and A. Tejeda-Lorente and E. Herrera-Viedma},
  doi          = {10.1016/j.ins.2020.05.071},
  journal      = {Information Sciences},
  pages        = {156-170},
  shortjournal = {Inf. Sci.},
  title        = {New technique to alleviate the cold start problem in recommender systems using information from social media and random decision forests},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A likelihood-based multi-criteria sustainable supplier
selection approach with complex preference information. <em>ISCI</em>,
<em>536</em>, 135–155. (<a
href="https://doi.org/10.1016/j.ins.2020.05.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval type-2 fuzzy sets are more valuable than conventional type-1 fuzzy sets in terms of covering more uncertain and complex preference information. Interval type-2 trapezoidal fuzzy sets, as a particular form of interval type-2 fuzzy sets, can precisely express subjective evaluations and qualitative assessments. In this paper, the concept of the likelihoods of interval type-2 fuzzy preference relations are utilized to propose a novel multi-criteria decision-making model for the sustainable supplier selection problems in which the weights of criteria and performance ratings are expressed as interval type-2 trapezoidal fuzzy sets. A new likelihood-based multi-criteria sustainable supplier selection model is proposed by encapsulating assorted sustainability triple bottom line criteria, collected from the state-of-the-art literature, which turns this framework into a benchmark approach for the evaluations of sustainable suppliers. The practical effectiveness of the proposed likelihood-based method is illustrated by the applications to four real cases and the comparative analysis demonstrates the validation and advantages of the proposed method over conventional multi-criteria sustainable supplier selection methods.},
  archive      = {J_ISCI},
  author       = {Sepehr Hendiani and Huchang Liao and Ruxue Ren and Benjamin Lev},
  doi          = {10.1016/j.ins.2020.05.065},
  journal      = {Information Sciences},
  pages        = {135-155},
  shortjournal = {Inf. Sci.},
  title        = {A likelihood-based multi-criteria sustainable supplier selection approach with complex preference information},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resampling ensemble model based on data distribution for
imbalanced credit risk evaluation in P2P lending. <em>ISCI</em>,
<em>536</em>, 120–134. (<a
href="https://doi.org/10.1016/j.ins.2020.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The misclassification of loan applicants by credit scoring model is one of the main factors causing the loss of investors’ profits in P2P lending. Class imbalance of credit data is a main factor that affects classification performance of the model. Most existing methods of addressing class imbalance in credit scoring worked on improving the prediction accuracy for minority class samples (bad credit), which usually led to decreasing the prediction performance for majority class samples (good credit) significantly. In this paper, we propose a novel resampling ensemble model based on data distribution (REMDD) for imbalanced credit risk evaluation in P2P lending. REMMD solves class imbalance problem by using proposed undersampling method based on majority class data distribution (UMCDD). To further improve classification performance of REMMD, base classifiers with better comprehensive performance on the validation set are used to conduct class prediction. We validate the classification performance of REMDD on the three real and representative P2P lending credit datasets. The experimental results demonstrate that REMDD not only has good prediction performance for both majority class and minority class, but also effectively improves the comprehensive classification performance for imbalanced credit risk evaluation in P2P lending, compared with existing models.},
  archive      = {J_ISCI},
  author       = {Kun Niu and Zaimei Zhang and Yan Liu and Renfa Li},
  doi          = {10.1016/j.ins.2020.05.040},
  journal      = {Information Sciences},
  pages        = {120-134},
  shortjournal = {Inf. Sci.},
  title        = {Resampling ensemble model based on data distribution for imbalanced credit risk evaluation in P2P lending},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Enhanced pairwise IPVO-based reversible data hiding scheme
using rhombus context. <em>ISCI</em>, <em>536</em>, 101–119. (<a
href="https://doi.org/10.1016/j.ins.2020.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pixel-Value-Ordering (PVO) based reversible data hiding schemes provide high-fidelity stego-images with moderate embedding capacity. In this paper, a novel reversible data hiding scheme based on enhanced pairwise pixel value ordering is proposed to increase embedding capacity. The proposed scheme divides a host image into non-overlapping blocks of three pixels in zig-zag order and categorizes the blocks into two categories namely absolute smooth and probably complex based on the rhombus mean for each pixel of the block. In the case of absolute smooth, the pairwise embedding is done in two-pass using two different predictors. In the pass-1, enhanced pairwise improved PVO method is used to embed the secret data in the block. The proposed method decreases the minimum valued pixels and increases the maximum valued pixels for embedding the secret data . In the pass-2, secret data is hidden using a novel recovery based pairwise embedding strategy, where the value of the first pixel according to the sorted mean sequence will be either increased or remains unchanged while the value of the last pixel will be either decreased or remains unchanged. Additionally, the medium pixel is also used to embed the secret data by modifying its value in any direction using prediction error expansion . Therefore, the pass-2 embedding is done in such a way that it becomes the complement of pass-1 embedding so that stego-image quality can be maintained with additional embedded data. In case of probable complex blocks, the secret data is embedded in pixel wise manner to local complexity of each pixel. The use of rhombus mean in block categorization allows embedding in each and every pixel of the host image while ensuring its reversibility . Thus, the proposed scheme significantly increases the embedding capacity. The experimental results show that the proposed scheme has almost doubled on the embedding capacity than the previous PVO-based reversible data hiding schemes . Further, it has higher PSNR at high embedding capacity.},
  archive      = {J_ISCI},
  author       = {Rajeev Kumar and Ki-Hyun Jung},
  doi          = {10.1016/j.ins.2020.05.047},
  journal      = {Information Sciences},
  pages        = {101-119},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced pairwise IPVO-based reversible data hiding scheme using rhombus context},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A GPU-based residual network for medical image
classification in smart medicine. <em>ISCI</em>, <em>536</em>, 91–100.
(<a href="https://doi.org/10.1016/j.ins.2020.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advance of high-performance computing techniques like graphics processing unit (GPU) enables large-scale deep learning models for medical image analytics in smart medicine. Smart medicine has made great progress by applying convolutional neural networks (CNNs) like ResNet and VGG-16 to medical image classification. However, various CNN models achieve very limited accuracy in some cases where multiple diseases are revealed in an X-ray image. This paper presents a variant ResNet model by replacing the global average pooling with the adaptive dropout for medical image classification. In order for the presented model to recognize multiple diseases (i.e., multi-label classification), we convert the multi-label classification to N binary classification by training the parameters of the presented model for N times. Finally, experiments are conducted on a GPU Cluster to evaluate the presented model on three datasets, namely Montgomery County chest X-ray set, Shenzhen X-ray set, and NIH chest X-ray set. The results show the presented model achieves a great performance improvement for medical image classification without a significant efficiency reduction compared to the traditional architecture and VGG-16.},
  archive      = {J_ISCI},
  author       = {Qingchen Zhang and Changchuan Bai and Zhuo Liu and Laurence T. Yang and Hang Yu and Jingyuan Zhao and Hong Yuan},
  doi          = {10.1016/j.ins.2020.05.013},
  journal      = {Information Sciences},
  pages        = {91-100},
  shortjournal = {Inf. Sci.},
  title        = {A GPU-based residual network for medical image classification in smart medicine},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MAG-GAN: Massive attack generator via GAN. <em>ISCI</em>,
<em>536</em>, 67–90. (<a
href="https://doi.org/10.1016/j.ins.2020.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks reveal the vulnerability of deep neural networks (DNNs). These attacks fool DNNs by adding small perturbations to normal examples. Currently, most attacks involve generating a single example or target a single deep model. To gain insight into adversarial attacks and develop a robust defense, this study focuses on a generic attack model applicable to most adversarial attacks. A novel mass-generator of adversarial examples with a strong attack ability and involving small perturbations is presented herein. The main contributions of this work include proposing a generic framework for adversarial attacks, designing comprehensive evaluation metrics for adversarial examples , and developing a novel method for mass-generating adversarial examples via a generative adversarial network (MAG-GAN). Finally, experiments were conducted to demonstrate the good performance of MAG-GAN compared with state-of-the-art attack methods. Once the model was trained, adversarial examples were mass-generated with a small perturbation and a strong attack ability. Furthermore, it was found that MAG-GAN model can be adopted as an efficient tool to reveal the vulnerability and improve the defense ability of existing DNNs. A promising result is that the target model mounted in MAG-GAN exhibited a good defense performance after game training, which is equivalent to adversarial training.},
  archive      = {J_ISCI},
  author       = {Jinyin Chen and Haibin Zheng and Hui Xiong and Shijing Shen and Mengmeng Su},
  doi          = {10.1016/j.ins.2020.04.019},
  journal      = {Information Sciences},
  pages        = {67-90},
  shortjournal = {Inf. Sci.},
  title        = {MAG-GAN: Massive attack generator via GAN},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single bus line timetable optimization with big data: A case
study in beijing. <em>ISCI</em>, <em>536</em>, 53–66. (<a
href="https://doi.org/10.1016/j.ins.2020.03.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bus lines are suffering from serious decline in passenger volume due to the rapid development of urban rail transit and shared transport, and big data intelligence may help them change the status quo . However, the tremendous amount of travel data collected in recent years have not got effectively utilization. In order to improve passenger volume for bus lines, this paper devotes to develop a data-driven bus timetable to substitute the existing experience-based bus timetable, which is now widely used by bus lines. Driven by the bus GPS data and IC card data, a timetable optimization model with time-dependent passenger demand and travel time among stops is proposed. The objective of maximizing passenger volume is based on a new preference-based passenger selection model. The working hours constraint is initially formulated, and the headway constraint and departure time constraints are also taken into account. For handling the step functions in both objective and constraints, we introduce a set of 0–1 variables to transform the proposed model into an integer linear programming . A model contraction approach is provided for solving the medium-scale problems and a two-stage solution method is proposed for the large-scale problems. The proposed model and methodology are tested on a real-world bus line in Beijing. The results show that it is able to produce a satisfactory timetable that outperforms the previously used experience-based one in terms of raising the average passenger volume by 8.2\%.},
  archive      = {J_ISCI},
  author       = {Hongguang Ma and Xiang Li and Haitao Yu},
  doi          = {10.1016/j.ins.2020.03.108},
  journal      = {Information Sciences},
  pages        = {53-66},
  shortjournal = {Inf. Sci.},
  title        = {Single bus line timetable optimization with big data: A case study in beijing},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive online data-driven closed-loop parameter control
strategy for swarm intelligence algorithm. <em>ISCI</em>, <em>536</em>,
25–52. (<a href="https://doi.org/10.1016/j.ins.2020.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter control is critical for the performance of any swarm intelligence algorithm. In this study, we propose an adaptive online data-driven closed-loop parameter control (CLPC) strategy for a swarm intelligence algorithm to solve both single-objective and multi-objective optimization problems with better performance. The proposed CLPC strategy involves three key parts: controller design, feedback selection, and reference determination. First, based on the control theory, we adopt a proportional integral derivative (PID) controller in the CLPC strategy, which can adaptively adjust the value of parameter according to the difference between reference and feedback. Second, to reflect and monitor the evolution state in real time, we use the mean shift clustering method and define the convergence entropy and the extension entropy to generate feedback. Finally, the reference should provide useful guidance for parameter control according to the features of optimization problems. Thus, in single-objective optimization, we propose a new lossless fitness landscape analysis method and design a decision tree to determine the reference; in multi-objective optimization, the range of the convergence entropy and the extension entropy are regarded as the reference. In addition, to illustrate the effectiveness of the CLPC strategy, two groups of experiments are performed based on the particle swarm optimization (PSO) algorithm in single-objective and multi-objective optimization. At the optimization algorithm level, we compare our proposed CLPC-PSO algorithm with three standard PSO algorithms, three decreasing inertia weight PSO algorithms, and two adaptive PSO algorithms. At the optimization problem level, we perform abundant experiments based on five single-objective benchmark functions, five multi-objective benchmark functions, and twelve scheduling instances. The statistical results show that the performance of the proposed CLPC-PSO algorithm is considerably better and more stable than those of the other eight PSO variants when faced with different problems having various features.},
  archive      = {J_ISCI},
  author       = {Hui Lu and Yaxian Liu and Shi Cheng and Yuhui Shi},
  doi          = {10.1016/j.ins.2020.05.016},
  journal      = {Information Sciences},
  pages        = {25-52},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive online data-driven closed-loop parameter control strategy for swarm intelligence algorithm},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Event-triggered finite-time adaptive neural control for
nonlinear non-strict-feedback time-delay systems with disturbances.
<em>ISCI</em>, <em>536</em>, 1–24. (<a
href="https://doi.org/10.1016/j.ins.2020.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the tracking problem for a class of nonlinear time-delay systems with external disturbances in a non-strict-feedback structure, and an event-trigger-based finite-time adaptive neural controller is designed. Suitable Lyapunov-Krasovskii functionals are constructed to deal with the time-delay terms in this system. Combining the structural property of radial basis function neural networks and backstepping methodology, the design difficulty from the non-strict-feedback structure of the system is solved. A finite-time prescribed performance function is introduced to drive the tracking error to a small neighborhood of the origin in a finite time. The proposed event-triggered control scheme has a larger threshold than that of the fixed-threshold scheme to reduce the communication burden and ensure that all of the signals of the closed-loop system are semi-globally uniformly ultimately bounded. Simulation results demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Chuang Gao and Xin Liu and Yonghui Yang and Xiaoping Liu and Ping Li},
  doi          = {10.1016/j.ins.2020.05.008},
  journal      = {Information Sciences},
  pages        = {1-24},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered finite-time adaptive neural control for nonlinear non-strict-feedback time-delay systems with disturbances},
  volume       = {536},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple attribute decision making using improved
intuitionistic fuzzy weighted geometric operators of intuitionistic
fuzzy values. <em>ISCI</em>, <em>535</em>, 242–253. (<a
href="https://doi.org/10.1016/j.ins.2020.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel multiple attribute decision making (MADM) method using the improved intuitionistic fuzzy weighted geometric (IIFWG) operator of intuitionistic fuzzy values (IFVs) proposed in this paper. First, we develop the IIFWG operator of IFVs to conquer the weak points of the existing operators of IFVs, where they have the drawbacks that their aggregated values are indeterminate in some situations. Based on the proposed IIFWG operator of IFVs, we present a MADM method to overcome the weak points of the existing MADM methods, which have the shortcomings that they obtain unreasonable ranking orders (ROs) of alternatives or they cannot discriminate the ROs of alternatives in some circumstances.},
  archive      = {J_ISCI},
  author       = {Xin-Yao Zou and Shyi-Ming Chen and Kang-Yun Fan},
  doi          = {10.1016/j.ins.2020.05.011},
  journal      = {Information Sciences},
  pages        = {242-253},
  shortjournal = {Inf. Sci.},
  title        = {Multiple attribute decision making using improved intuitionistic fuzzy weighted geometric operators of intuitionistic fuzzy values},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive fuzzy control design for synchronization of chaotic
time-delay system. <em>ISCI</em>, <em>535</em>, 225–241. (<a
href="https://doi.org/10.1016/j.ins.2020.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on an adaptive synchronization for a class of uncertain chaotic systems (CSs) with time delay . The chaotic systems are represented by Takagi–Sugeno (T-S) fuzzy model. In order to estimate the unknown parameters of the uncertain chaotic systems, we use advanced adaptive laws with smooth projection operator to solve it. In addition, we take the adaptive law as a part of Lyapunov function to make the chaotic systems stable. Different from the previous study of adaptive synchronization of uncertain chaotic systems, this paper fully considers the effect of time delay on uncertain chaotic systems. Finally, by constructing a suitable Lyapunov function (LKF) and using linear matrix inequality (LMI) theory, we can obtain the stability condition of closed-loop system. Furthermore, the simulation cases in this paper illustrate the robust performance of the error system is guaranteed under the uncertain dynamic equation modeling.},
  archive      = {J_ISCI},
  author       = {Zhen-Yu Zhu and Zhan-Shan Zhao and Jing Zhang and Rui-Kun Wang and Zhuqing Li},
  doi          = {10.1016/j.ins.2020.05.056},
  journal      = {Information Sciences},
  pages        = {225-241},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy control design for synchronization of chaotic time-delay system},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-training hierarchical prototype-based approach for
semi-supervised classification. <em>ISCI</em>, <em>535</em>, 204–224.
(<a href="https://doi.org/10.1016/j.ins.2020.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel self-training hierarchical prototype-based approach for semi-supervised classification. The proposed approach firstly identifies meaningful prototypes from labelled samples at multiple levels of granularity and, then, self-organizes a highly transparent, multi-layered recognition model by arranging them in a form of pyramidal hierarchies. After this, the learning model continues to self-evolve its structure and self-expand its knowledge base to incorporate new patterns recognized from unlabelled samples by exploiting the pseudo-label technique. Thanks to its prototype-based nature, the overall computational process of the proposed approach is highly explainable and traceable. Experimental studies with various benchmark image recognition problems demonstrate the state-of-the-art performance of the proposed approach, showing its strong capability to mine key information from unlabelled data for classification.},
  archive      = {J_ISCI},
  author       = {Xiaowei Gu},
  doi          = {10.1016/j.ins.2020.05.018},
  journal      = {Information Sciences},
  pages        = {204-224},
  shortjournal = {Inf. Sci.},
  title        = {A self-training hierarchical prototype-based approach for semi-supervised classification},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed guaranteed two-target tracking over
heterogeneous sensor networks under bounded noises and adversarial
attacks. <em>ISCI</em>, <em>535</em>, 187–203. (<a
href="https://doi.org/10.1016/j.ins.2020.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the distributed guaranteed estimation for tracking two interacting mobile targets over a multi-sensor network in the presence of unknown-but-bounded noises and various adversarial attacks . First, a heterogeneous sensor network framework in terms of two distinct groups of sensors is employed to monitor the two targets. Each sensor in either group possesses different sensing, processing and communicating capabilities, thereby leading to distinct communication topologies among intra- and inter-group sensors. Second, a unified attack model is established to skillfully accommodate multiple adversarial attacks including node manipulation attacks and deception attacks. Third, two different groups of distributed consensus-based estimators are delicately constructed to deal with the network heterogeneity. Criteria for designing the desired estimators are then derived such that the true states of the two maneuvering targets are guaranteed to be enclosed by the calculated estimate ellipsoids at each time step regardless of the noises and attacks. Furthermore, two tractable optimization algorithms , in both single- and two-target tracking cases, are applied to recursively calculate the smallest possible ellipsoidal estimate sets. Finally, numerical verification of distributed two-vehicle tracking is carried out to demonstrate the effectiveness and applicability of the obtained results.},
  archive      = {J_ISCI},
  author       = {Shunyuan Xiao and Xiaohua Ge and Qing-Long Han and Yijun Zhang and Zhenwei Cao},
  doi          = {10.1016/j.ins.2020.05.023},
  journal      = {Information Sciences},
  pages        = {187-203},
  shortjournal = {Inf. Sci.},
  title        = {Distributed guaranteed two-target tracking over heterogeneous sensor networks under bounded noises and adversarial attacks},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anomaly detection in electronic invoice systems based on
machine learning. <em>ISCI</em>, <em>535</em>, 172–186. (<a
href="https://doi.org/10.1016/j.ins.2020.03.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic invoice(E-invoice) has become the product of the information age, its issue will greatly save the cost of enterprises and achieve the goal of financial process automation. Hence, the generalization of electronic invoice is imperative. However, there exists the risk of malicious attacks in electronic invoice systems, such as sudden invoice of large invoice, invoice at abnormal time, etc. These malicious attacks are difficult to detect through the system itself or manually. To provide a secure service platform for the generalization of electronic invoice, this paper studies the attack detection technology of electronic invoice systems which is mainly based on machine learning to complete two aspects of research. The first is to propose a machine learning-based e-invoice anomaly detection method, which can accurately determine the anomalies occurring in the e-invoice systems. The second is to conduct deep fusion analysis on abnormal behaviors, mining potential threats in the electronic invoice systems, and designing and implementing the electronic invoice depth fusion analysis method based on k-means and Skip-gram. The experimental results indicate that the method we proposed can not only detect the malicious attacks effectively, and also capable of mining the potential threats in the electronic invoice systems.},
  archive      = {J_ISCI},
  author       = {Peng Tang and Weidong Qiu and Zheng Huang and Shuang Chen and Min Yan and Huijuan Lian and Zhe Li},
  doi          = {10.1016/j.ins.2020.03.089},
  journal      = {Information Sciences},
  pages        = {172-186},
  shortjournal = {Inf. Sci.},
  title        = {Anomaly detection in electronic invoice systems based on machine learning},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global context based automatic road segmentation via dilated
convolutional neural network. <em>ISCI</em>, <em>535</em>, 156–171. (<a
href="https://doi.org/10.1016/j.ins.2020.05.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road segmentation from remote sensing images is a critical task in many applications. In recent years, various approaches, particularly deep learning-based methods, have been proposed for accurate road segmentation. However, most existing road segmentation methods always obtain unsatisfactory results (e.g., heterogeneous pixels) due to the complex backgrounds and view occlusions of buildings and trees around a road; consequently, road segmentation remains a challenging problem. In this study, we propose a novel global context based dilated convolutional neural network (GC-DCNN) to address the aforementioned problem. The structure of GC-DCNN is similar to that of UNet. In particular, building the encoder of GC-DCNN with three residual dilated blocks is suggested to further enlarge the effective receptive field and learn additional discriminative features . Thereafter, a pyramid pooling module is used to capture the multiscale global context features and fuse them to achieve stronger feature representation. The decoder network upsamples the fused features to the same size as the input image, combining the high-resolution features with the contracting path of the encoder network. Moreover, the dice coefficient loss is adopted as the loss function. This function differs from those in most previous studies but is more suitable for road segmentation. Extensive experimental results on two benchmark datasets compared with several baseline models demonstrate the superiority of the proposed GC-DCNN algorithm.},
  archive      = {J_ISCI},
  author       = {Meng Lan and Yipeng Zhang and Lefei Zhang and Bo Du},
  doi          = {10.1016/j.ins.2020.05.062},
  journal      = {Information Sciences},
  pages        = {156-171},
  shortjournal = {Inf. Sci.},
  title        = {Global context based automatic road segmentation via dilated convolutional neural network},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain-based two-party fair contract signing scheme.
<em>ISCI</em>, <em>535</em>, 142–155. (<a
href="https://doi.org/10.1016/j.ins.2020.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fair contract signing scheme ensures that contract signing participants can fairly exchange the digital signatures of the contract, which has a wide range of applications on the Internet. Verifiable Encrypted Signature (VES) can be used as a fair exchange mechanism for digital signatures, in which it requires a centralized Trusted Third Party (TTP) as an adjudicator. However, there are many security challenges with the centralized TTP. For example, it may disclose the contents of the contract, collude with others, or even occurs a service interruption. To address those problems, in this paper, we propose a two-party fair contract signing scheme based on Ethereum smart contract , which allows participants to fairly perform the contract signing procedures on the blockchain. Specifically, we propose a modified VES scheme in which no centralized adjudicator is needed. Then we design the fair contract signing scheme based on the modified VES scheme. We leverage the Ethereum smart contract technology to ensure fairness, which has the characteristics of decentralization, verifiability, autonomy, efficiency, and tampering resistant. The theoretical analysis and experimental results show that our scheme is secure and feasible.},
  archive      = {J_ISCI},
  author       = {Liang Zhang and Hanlin Zhang and Jia Yu and Hequn Xian},
  doi          = {10.1016/j.ins.2020.05.054},
  journal      = {Information Sciences},
  pages        = {142-155},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based two-party fair contract signing scheme},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attributed graph clustering with subspace stochastic block
model. <em>ISCI</em>, <em>535</em>, 130–141. (<a
href="https://doi.org/10.1016/j.ins.2020.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the principle of homophily, most existing graph clustering approaches assume that the formation of clusters is highly related to node attributes, and thus leverage node information to improve graph clustering performance. However, utilizing all attributes as supplemental information for graph clustering may fail on real-world attributed graphs since only a subset of attributes are truly relevant for the formation of clusters, and the relevant attributes (i.e., attribute subspaces) for different clusters often differ largely in real-world graphs. Therefore, in this paper, we propose a subspace stochastic block model (SSB) to explore the cluster structures in attributed graphs. The key point is to view both topological structure and attribute information as the latent factors to drive the formation of clusters in the new proposed generative model . More specifically, relevant attributes are iteratively learned for each cluster, and subsequently used as valuable information to be integrated into the stochastic block model. To solve the likelihood function, an expectation–maximization strategy is developed to infer all parameters efficiently, and finally all clusters and their corresponding attribute subspaces are identified simultaneously. Extensive experimental results on both synthetic and real-world graphs have demonstrated the effectiveness of SSB, and show its superiority over many state-of-art approaches.},
  archive      = {J_ISCI},
  author       = {Haoran Chen and Zhongjing Yu and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2020.05.044},
  journal      = {Information Sciences},
  pages        = {130-141},
  shortjournal = {Inf. Sci.},
  title        = {Attributed graph clustering with subspace stochastic block model},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LPG-model: A novel model for throughput prediction in stream
processing, using a light gradient boosting machine, incremental
principal component analysis, and deep gated recurrent unit network.
<em>ISCI</em>, <em>535</em>, 107–129. (<a
href="https://doi.org/10.1016/j.ins.2020.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the volume and velocity of streaming data have been increasing rapidly. Thus, real-time processing scenarios for streaming data have continued to increase. Stream processing tasks face huge challenges in areas such as load optimization, task scheduling , and resource management. Throughput prediction for stream processing tasks is a key technology in these areas. To predict the throughput of stream processing tasks accurately and efficiently, we propose a novel model named the LPG-model. It includes three main components: a light gradient boosting machine (LightGBM), incremental principal component analysis (IPCA), and an evolving deep gated recurrent unit (GRU) network. Unlike existing state-of-the-art models, the LPG-model not only offers a network structure adaptation mechanism (hidden layer adaptation mechanism), but also provides feature processing mechanisms for streaming data. Data preprocessing provides an interpolation method for missing values through an incremental interpolation mechanism and two normalization methods for features through incremental normalization mechanisms. An efficient dimensionality reduction mechanism provided by the LightGBM and IPCA is used to improve the prediction efficiency of the LPG-model. The hidden layer growing mechanism of the evolving deep GRU network is capable of learning new knowledge and maintaining previous knowledge from data streams. Moreover, it also has the ability to capture the temporal aspects of the data streams. The experimental results from four open-source benchmarks illustrate that the LPG-model is more accurate and efficient than state-of-the-art algorithms or networks, under the prequential test-then-train protocol. This proves the effectiveness of the LPG-model in throughput prediction scenarios for stream processing tasks. Furthermore, the numerical results from standard benchmark problems of data streams indicate that the LPG-model has potential to reduce the execution time of high-dimensional data streams with a high classification accuracy .},
  archive      = {J_ISCI},
  author       = {Zheng Chu and Jiong Yu and Askar Hamdulla},
  doi          = {10.1016/j.ins.2020.05.042},
  journal      = {Information Sciences},
  pages        = {107-129},
  shortjournal = {Inf. Sci.},
  title        = {LPG-model: A novel model for throughput prediction in stream processing, using a light gradient boosting machine, incremental principal component analysis, and deep gated recurrent unit network},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new watermark decoder in DNST domain using singular values
and gaussian-cauchy mixture-based vector HMT. <em>ISCI</em>,
<em>535</em>, 81–106. (<a
href="https://doi.org/10.1016/j.ins.2020.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are three indispensable, yet contrasting requirements for a watermarking scheme : imperceptibility , robustness, and payload. Therefore, it is a challenge to obtain a tradeoff among above requirements in image watermark detection . In this paper, we propose a new statistical watermark decoder in discrete non-separable Shearlet transform (DNST) domain using singular values and Gaussian-Cauchy mixture-based vector hidden Markov tree (HMT). Our method can obtain great performance in imperceptibility , robustness and payload, and it is necessary for image copyright protection . We first perform DNST on the host image, and apply singular value decomposition (SVD) to the significant DNST domain high entropy blocks. We then embed the digital watermark into the DNST high entropy blocks by modifying the robust singular values . At the receiver, by combining the Gaussian-Cauchy mixture-based vector HMT and maximum likelihood (ML) decision, we propose a new blind image watermark decoder in DNST domain. Here, robust DNST domain singular values are firstly modeled by using Gaussian-Cauchy mixture-based vector HMT, where the Gaussian-Cauchy mixture marginal distribution and various strong dependencies of DNST domain singular values are incorporated. Then the statistical model parameters of Gaussian-Cauchy mixture-based vector HMT are estimated using parameter-expanded expectation–maximization (PXEM) approach. And finally, a blind image watermark decoder is developed using Gaussian-Cauchy mixture-based vector HMT and ML decision rule. The major contribution of this paper is the use of singular value, Gaussian-Cauchy mixture-based vector HMT and PXEM algorithms , which enhances the performance of watermarking scheme . Experimental results on some test images and comparison with well-known existing methods demonstrate the efficacy and superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xiang-yang Wang and Tao-tao Wen and Xin Shen and Pan-pan Niu and Hong-ying Yang},
  doi          = {10.1016/j.ins.2020.05.034},
  journal      = {Information Sciences},
  pages        = {81-106},
  shortjournal = {Inf. Sci.},
  title        = {A new watermark decoder in DNST domain using singular values and gaussian-cauchy mixture-based vector HMT},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attribute group for attribute reduction. <em>ISCI</em>,
<em>535</em>, 64–80. (<a
href="https://doi.org/10.1016/j.ins.2020.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of rough set, how to improve the efficiency of obtaining reduct has been paid much attention to. One of the typical strategies is to reduce the number of comparisons among samples, it follows that the time consumption of generating binary relation can be saved for quickly obtaining reduct. Nevertheless, such mechanism is only designed by reducing the number of times to scan samples, which fails in reducing the iterations of evaluating attributes. To fill such gap, an acceleration strategy based on attribute group is proposed. Firstly, all of the candidate attributes are divided into different groups. Secondly, in the process of searching reduct, only the attributes out of those groups which contain at least one attribute in the potential reduct should be evaluated. It should be noticed that this is the key which can reduce the number of evaluations of candidate attributes. Finally, the above two steps are repeated until the constraint defined in attribute reduction is satisfied. To demonstrate the effectiveness of our proposed method, the experiments have been conducted over three neighborhood rough set models by leveraging four measures. Compared with the existing forward greedy searching approach over 12 UCI data sets, the experimental results show that our attribute group based approach can maintain the classification performance derived by reducts while significantly accelerating the searching process of obtaining reduct. This study suggests a new trend concerning the problem of quickly computing reduct.},
  archive      = {J_ISCI},
  author       = {Yan Chen and Keyu Liu and Jingjing Song and Hamido Fujita and Xibei Yang and Yuhua Qian},
  doi          = {10.1016/j.ins.2020.05.010},
  journal      = {Information Sciences},
  pages        = {64-80},
  shortjournal = {Inf. Sci.},
  title        = {Attribute group for attribute reduction},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust h∞ sliding mode control for nonlinear stochastic t-s
fuzzy singular markovian jump systems with time-varying delays.
<em>ISCI</em>, <em>535</em>, 42–63. (<a
href="https://doi.org/10.1016/j.ins.2020.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the robust H ∞ H∞ stabilization problem for stochastic T-S fuzzy singular Markovian jump systems with time delays is investigated by using integral sliding mode control . A novel fuzzy integral-type sliding surface function is designed by fully taking the singular derivative matrix into account. By the utilization of linear matrix inequality technique, a delay-dependent criterion is derived, which guarantees the sliding mode dynamics to be stochastically admissible with a prescribed H ∞ H∞ performance. Moreover, a suitable sliding mode law is synthesized to ensure the stochastic admissibility of the resulting closed-loop system, and the proposed sliding mode control law can steer the trajectories of the controlled system to the specified sliding surface in finite time. Finally, three examples are provided to illustrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Junchao Ren and Guangxu He and Jun Fu},
  doi          = {10.1016/j.ins.2020.05.029},
  journal      = {Information Sciences},
  pages        = {42-63},
  shortjournal = {Inf. Sci.},
  title        = {Robust h∞ sliding mode control for nonlinear stochastic T-S fuzzy singular markovian jump systems with time-varying delays},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neighborhood rough set-based three-way clustering
considering attribute correlations: An approach to classification of
potential gout groups. <em>ISCI</em>, <em>535</em>, 28–41. (<a
href="https://doi.org/10.1016/j.ins.2020.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using modern information theory to classify and identify high-risk disease groups is one of the research concerns in medical decision-making. The early diagnosis of gout is missing a single indicator, and relying on artificial labeling of disease characteristics is not only costly for decision-making, but also has a high misdiagnosis rate. Aiming at incomplete and attribute-related random large sample data, we propose a three-way clustering algorithm based on neighborhood rough sets, which is used to initially label the data, reduce the rate of misdiagnosis, and improve decision-making efficiency. Firstly, a neighborhood rough set theory in a heterogeneous information system is established. Secondly, the Best-Worst method-based neighborhood rough set attribute reduction model considering attribute correlation is constructed. Thirdly, a neighborhood rough set-based three-way clustering method for heterogeneous information system is proposed. Finally, we use 2,683 random samples and the proposed model to identify and classify potential gout patients in the samples. The results show that the proposed model can be used to mark and cluster potential gout groups in random samples without prior probability and with fuzzy decision rules, which is helpful for clinical decision-making.},
  archive      = {J_ISCI},
  author       = {Xiaoli Chu and Bingzhen Sun and Xue Li and Keyu Han and JiaQi Wu and Yan Zhang and Qingchun Huang},
  doi          = {10.1016/j.ins.2020.05.039},
  journal      = {Information Sciences},
  pages        = {28-41},
  shortjournal = {Inf. Sci.},
  title        = {Neighborhood rough set-based three-way clustering considering attribute correlations: An approach to classification of potential gout groups},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis on the relationship between uncertainty and
misclassification rate of classifiers. <em>ISCI</em>, <em>535</em>,
16–27. (<a href="https://doi.org/10.1016/j.ins.2020.05.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides new insight into the analysis on the relationship between uncertainty and misclassification of a classifier. We formulate the relationship explicitly by taking entropy as a measurement of uncertainty and by analyzing the misclassification rate based on the membership degree difference. Focusing on binary classification problems, this study theoretically and experimentally validates that the misclassification rate will definitely be upgrading with the increase of uncertainty if two conditions are satisfied: (1) the distributions of two classes based on membership degree difference are unimodal, and (2) these two distributions attain peaks when the membership degree difference is less and larger than zero, respectively. This work aims to provide some practical guidelines for improving classifier performance through clearly expressing and understanding the relationship between uncertainty and misclassification of a classifier.},
  archive      = {J_ISCI},
  author       = {Xinlei Zhou and Xizhao Wang and Cong Hu and Ran Wang},
  doi          = {10.1016/j.ins.2020.05.059},
  journal      = {Information Sciences},
  pages        = {16-27},
  shortjournal = {Inf. Sci.},
  title        = {An analysis on the relationship between uncertainty and misclassification rate of classifiers},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Malware-detection method with a convolutional recurrent
neural network using opcode sequences. <em>ISCI</em>, <em>535</em>,
1–15. (<a href="https://doi.org/10.1016/j.ins.2020.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel malware-detection model with a convolutional recurrent neural network using opcode sequences. Statistically, an executable file is considered as a set of consecutive machine codes. First, the theoretical foundation on which opcode sequences can be used to detect malware has been discussed. Next, an algorithm for extracting opcode sequences from executables and a deep learning-based malware-detection method that uses the opcode sequences as input have been presented. The proposed model comprises an opcode-level convolutional autoencoder that transforms a long opcode sequence to a relatively short compressed sequence at the front end and a dynamic recurrent neural network classifier that performs a prediction task using the codes generated by the opcode-level convolutional autoencoder at the rear end. Experimentally, the proposed model provided a malware-detection accuracy of 96\% 96\% , receiver operating characteristic-area under the curve of 0.99 0.99 , and true positive rate (TPR) of 95\% 95\% . The highest accuracy and TPR achieved by existing malware-detection methods using opcode sequences were 97\% 97\% and 82\% 82\% , respectively. Compared with this method, the proposed model delivered a slightly lower accuracy of 96\% 96\% but a considerably larger TPR of 95\% 95\% . Therefore, the proposed model is capable of more reliable malware detection.},
  archive      = {J_ISCI},
  author       = {Seungho Jeon and Jongsub Moon},
  doi          = {10.1016/j.ins.2020.05.026},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Malware-detection method with a convolutional recurrent neural network using opcode sequences},
  volume       = {535},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid cooperative co-evolution algorithm framework for
optimising power take off and placements of wave energy converters.
<em>ISCI</em>, <em>534</em>, 218–244. (<a
href="https://doi.org/10.1016/j.ins.2020.03.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wave energy technologies have the potential to play a significant role in the supply of renewable energy on a world scale. One of the most promising designs for wave energy converters (WECs) are fully submerged buoys. In this work, we explore the optimisation of WEC arrays consisting of three-tether buoys. Such arrays can be optimised for total energy output by adjusting both the relative positions of buoys and also the power-take-off (PTO) parameters for each buoy. The search space for these parameters is complex and multi-modal. Moreover, the evaluation of each parameter setting is computationally expensive and thus limits the number of full model evaluations that can be made. To handle this problem, we propose a new hybrid cooperative co-evolution algorithm (HCCA). HCCA consists of a symmetric local search plus Nelder-Mead and a cooperative co-evolution algorithm (CC) with a backtracking strategy for optimising the positions and PTO settings of WECs, respectively. For assessing the effectiveness of the proposed approach five popular Evolutionary Algorithms (EAs), four alternating optimisation methods and two recent hybrid ideas (LS-NM and SLS-NM-B) are compared in four real wave situations (Adelaide, Tasmania, Sydney and Perth) with two wave farm sizes (4 and 16). The experimental study shows that the hybrid cooperative framework performs best in terms of both runtime and quality of obtained solutions.},
  archive      = {J_ISCI},
  author       = {Mehdi Neshat and Bradley Alexander and Markus Wagner},
  doi          = {10.1016/j.ins.2020.03.112},
  journal      = {Information Sciences},
  pages        = {218-244},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid cooperative co-evolution algorithm framework for optimising power take off and placements of wave energy converters},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The design of variable-length coding matrix for improving
error correcting output codes. <em>ISCI</em>, <em>534</em>, 192–217. (<a
href="https://doi.org/10.1016/j.ins.2020.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thus far, all existing Error Correcting Output Codes (ECOC) algorithms produce coding matrices with an equal size for all classes. Yet, this paper proposes a variable-length codewords based ECOC (VL-ECOC), which generates longer codes for hard classes than those for easy classes. VL-ECOC consists of two phases: the overall-class phase and the hard-class phase. In the first phase, the centroids of the top two toughest classes are selected as the centroids of the positive group and the negative group respectively, whereas other classes are assigned to their nearer groups. The remaining hard classes with high error rates will be proceeded to the second phase, in which the K nearest neighbors of the misclassified samples are employed to generate new columns. The codewords generated in the second phase are applied to the decoding process of the hard classes. Consequently, both the easy and hard classes contain distinct code lengths. To verify the performance of VL-ECOC, comprehensive experiments are carried out on the UCI data and the microarray data sets. The experiment results demonstrate that owing to the additional codewords for the hard classes, our algorithm can better handle the class imbalance problem and achieve higher performance in most cases.},
  archive      = {J_ISCI},
  author       = {Kai-Jie Feng and Sze-Teng Liong and Kun-Hong Liu},
  doi          = {10.1016/j.ins.2020.04.021},
  journal      = {Information Sciences},
  pages        = {192-217},
  shortjournal = {Inf. Sci.},
  title        = {The design of variable-length coding matrix for improving error correcting output codes},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pre-processing approaches for collaborative filtering based
on hierarchical clustering. <em>ISCI</em>, <em>534</em>, 172–191. (<a
href="https://doi.org/10.1016/j.ins.2020.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RS) support users to find relevant contents, such as movies, books, songs, and other products based on their preferences. Such preferences are gathered by analyzing past users’ interactions, however, data collected for this purpose are typically prone to sparsity and high dimensionality . Clustering-based techniques have been proposed to handle those problems effectively and efficiently by segmenting the data into a number of similar groups based on predefined characteristics. Although such techniques have gained increasing attention in the recommender systems community, they are usually bound to a particular recommender system and/or require critical parameters, such as the number of clusters. In this paper, we present three variants of a general-purpose method to optimally extract users’ groups from a hierarchical clustering algorithm, specifically targeting RS problems. The proposed extraction methods do not require critical parameters and enable any recommender algorithm to be used at the recommendation step. Our experiments have shown promising recommendation results in the context of nine well-known public datasets from different domains.},
  archive      = {J_ISCI},
  author       = {Fernando S. de Aguiar Neto and Arthur F. da Costa and Marcelo G. Manzato and Ricardo J.G.B. Campello},
  doi          = {10.1016/j.ins.2020.05.021},
  journal      = {Information Sciences},
  pages        = {172-191},
  shortjournal = {Inf. Sci.},
  title        = {Pre-processing approaches for collaborative filtering based on hierarchical clustering},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Drosophila-inspired 3D moving object detection based on
point clouds. <em>ISCI</em>, <em>534</em>, 154–171. (<a
href="https://doi.org/10.1016/j.ins.2020.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D moving object detection is one of the most critical tasks in dynamic scene analysis. In this paper, we propose a novel Drosophila-inspired 3D moving object detection method using Lidar sensors. According to the theory of elementary motion detector, we have developed a motion detector based on the shallow visual neural pathway of Drosophila. This detector is sensitive to the movement of objects and can well suppress background noise. Designing neural circuits with different connection modes, the approach searches for motion areas in a coarse-to-fine fashion and extracts point clouds of each motion area to form moving object proposals. An improved 3D object detection network is then used to estimate the point clouds of each proposal and efficiently generates the 3D bounding boxes and the object categories. We evaluate the proposed approach on the widely-used KITTI benchmark, and state-of-the-art performance was obtained by using the proposed approach on the task of motion detection.},
  archive      = {J_ISCI},
  author       = {Li Wang and Dawei Zhao and Tao Wu and Hao Fu and Zhiyu Wang and Liang Xiao and Xin Xu and Bin Dai},
  doi          = {10.1016/j.ins.2020.05.006},
  journal      = {Information Sciences},
  pages        = {154-171},
  shortjournal = {Inf. Sci.},
  title        = {Drosophila-inspired 3D moving object detection based on point clouds},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general control strategy for planar 3-DoF underactuated
manipulators with one passive joint. <em>ISCI</em>, <em>534</em>,
139–153. (<a href="https://doi.org/10.1016/j.ins.2020.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a general control strategy based on the trajectory planning and tracking control for the planar 3-DoF underactuated manipulators with one passive joint at different position. According to the target position of the system, a set of target angles of all links are quickly obtained by using differential evolution algorithm . In order to achieve the control objective of the system from the initial position to the target position, we design the trajectory for each active link of the system, which is composed of two parts. The first part of the trajectory is designed according to the initial and target angle of the active link. The second part of the trajectory is designed based on the constraints between the passive joint and the active joints. Meanwhile, the parameters of the trajectories are optimized by the differential evolution algorithm to ensure that all links reach to their target angles eventually by tracking the designed trajectories. Then, the sliding mode variable structure controllers are designed to make all active links track their trajectories. The effectiveness of the proposed strategy is demonstrated through simulation results.},
  archive      = {J_ISCI},
  author       = {Zixin Huang and Xuzhi Lai and Pan Zhang and Qingxin Meng and Min Wu},
  doi          = {10.1016/j.ins.2020.05.002},
  journal      = {Information Sciences},
  pages        = {139-153},
  shortjournal = {Inf. Sci.},
  title        = {A general control strategy for planar 3-DoF underactuated manipulators with one passive joint},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Early prediction for mode anomaly in generative adversarial
network training: An empirical study. <em>ISCI</em>, <em>534</em>,
117–138. (<a href="https://doi.org/10.1016/j.ins.2020.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mode anomaly (MA for short) significantly blocks the application of generative adversarial networks (GANs). Although diverse metrics have been proposed to measure the MA, and a lot of efforts have been made to resolve the MA, none of them gives a quantitative definition for MA detection. Moreover, very few studies concentrate on the early-stage prediction of MA. In this paper, we make the first effort to this field with a systematic empirical study. To this end, we first give a fine-grained definition where the MA is categorized into three typical sub-patterns. Afterwards, traditional MA metrics are studied with extensive experiments on numbers of representative combinations of subjects (including 13 GANs and 3 datasets) to explore their sensitivity for the MA across different training steps. We find that in most of cases, the MA can be reasonably predicted in very early training stage through our sensitivity studies. Under the insight, we propose a novel prediction strategy using conception of “anomaly sign”. The evaluation results on diverse experimental subjects demonstrate the feasibility and high accuracy for the early prediction of MA. We also discuss the prediction efficiency, as well as analyze the prediction effectiveness from human perception.},
  archive      = {J_ISCI},
  author       = {Chenkai Guo and Dengrong Huang and Jianwen Zhang and Jing Xu and Guangdong Bai and Naipeng Dong},
  doi          = {10.1016/j.ins.2020.05.046},
  journal      = {Information Sciences},
  pages        = {117-138},
  shortjournal = {Inf. Sci.},
  title        = {Early prediction for mode anomaly in generative adversarial network training: An empirical study},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Adaptively constrained dynamic time warping for time series
classification and clustering. <em>ISCI</em>, <em>534</em>, 97–116. (<a
href="https://doi.org/10.1016/j.ins.2020.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification and clustering are important for data mining research, which is conducive to recognizing movement patterns, finding customary routes, and detecting abnormal trajectories in transport (e.g. road and maritime) traffic. The dynamic time warping (DTW) algorithm is a classical distance measurement method for time series analysis . However, the over-stretching and over-compression problems are typical drawbacks of using DTW to measure distances. To address these drawbacks, an adaptive constrained DTW (ACDTW) algorithm is developed to calculate the distances between trajectories more accurately by introducing new adaptive penalty functions. Two different penalties are proposed to effectively and automatically adapt to the situations in which multiple points in one time series correspond to a single point in another time series. The novel ACDTW algorithm can adaptively adjust the correspondence between two trajectories and obtain greater accuracy between different trajectories. Numerous experiments on classification and clustering are undertaken using the UCR time series archive and real vessel trajectories. The classification results demonstrate that the ACDTW algorithm performs better than four state-of-the-art algorithms on the UCR time series archive. Furthermore, the clustering results reveal that the ACDTW algorithm has the best performance among three existing algorithms in modeling maritime traffic vessel trajectory.},
  archive      = {J_ISCI},
  author       = {Huanhuan Li and Jingxian Liu and Zaili Yang and Ryan Wen Liu and Kefeng Wu and Yuan Wan},
  doi          = {10.1016/j.ins.2020.04.009},
  journal      = {Information Sciences},
  pages        = {97-116},
  shortjournal = {Inf. Sci.},
  title        = {Adaptively constrained dynamic time warping for time series classification and clustering},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of multiple operating modes based on fused
features for continuous annealing processes. <em>ISCI</em>,
<em>534</em>, 85–96. (<a
href="https://doi.org/10.1016/j.ins.2020.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a new method to identify operating modes for Continuous Annealing Processes (CAP) based on multiple models consisting of key variables with multi-scale features. The existing operating modes in the CAP are first described in detail, allowing key variables influencing the multiple modes to be selected. The distribution characteristics of each variable are then analyzed to select the corresponding detection methods. Furthermore, the multi-scale features of each variable are then fused to establish multiple models for improving the detectability of the process mode. Finally, a case study based on historical data is performed. The proposed method demonstrated identified different modes in CAP and improved identification performances with fused features.},
  archive      = {J_ISCI},
  author       = {Wenshuo Song and Weihua Cao and Wenkai Hu and Min Wu},
  doi          = {10.1016/j.ins.2020.04.015},
  journal      = {Information Sciences},
  pages        = {85-96},
  shortjournal = {Inf. Sci.},
  title        = {Identification of multiple operating modes based on fused features for continuous annealing processes},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stacked isomorphic autoencoder based soft analyzer and its
application to sulfur recovery unit. <em>ISCI</em>, <em>534</em>, 72–84.
(<a href="https://doi.org/10.1016/j.ins.2020.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is an important and effective tool for process soft sensor modeling in industrial artificial intelligence. Traditional deep learning methods like stacked autoencoder (SAE) usually learn high-level features from their low-level ones progressively by minimizing the reconstruction error for the inputs at each layer. However, the reconstruction cannot be exactly accurate. There is loss cumulation of raw data information from the lowest to the highest levels in SAE. To deal with this problem, a novel deep stacked isomorphic autoencoder (SIAE) is proposed to obtain better feature representation for raw input data in this paper. Different from the original SAE, SIAE aims to extract abstract features at each layer from its previous one by stacking hierarchical isomorphic autoencoders (IAE), in which each IAE reconstructs the same raw input data as well as possible. Thus, SIAE can better describe the complex data patterns and obtain good features for the raw data. Then, SIAE is used to construct soft sensor model for quality prediction. The application on an industrial sulfur recovery unit shows that SIAE can improve the prediction performance for the quality variable.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Yuan and Yalin Wang and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.ins.2020.03.018},
  journal      = {Information Sciences},
  pages        = {72-84},
  shortjournal = {Inf. Sci.},
  title        = {Stacked isomorphic autoencoder based soft analyzer and its application to sulfur recovery unit},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-source information fusion based heterogeneous network
embedding. <em>ISCI</em>, <em>534</em>, 53–71. (<a
href="https://doi.org/10.1016/j.ins.2020.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous network embedding aims to learn a mapping between network data in original topological space and vectored data in low dimensional latent space, while encoding valuable information, such as structural and semantic information. The resulting vector representation has shown promising performance for extensive real-world applications, such as node classification and node clustering. However, most of existing methods merely focus on modeling network structural information, ignoring the rich multi-source information of different types of nodes. In this paper, we propose a novel Multi-source Information Fusion based Heterogeneous Network Embedding (MIFHNE) approach. We first capture the semantic information using the strategy of meta-graph based random walk. Subsequently, we jointly model the structural proximity, attribute information and label information in the framework of Nonnegative Matrix Factorization (NMF). Theoretical proofs and comprehensive experiments on two real-world heterogeneous network datasets demonstrate the feasibility and effectiveness of our approach.},
  archive      = {J_ISCI},
  author       = {Bentian Li and Dechang Pi and Yunxia Lin and Izhar Ahmed Khan and Lin Cui},
  doi          = {10.1016/j.ins.2020.05.012},
  journal      = {Information Sciences},
  pages        = {53-71},
  shortjournal = {Inf. Sci.},
  title        = {Multi-source information fusion based heterogeneous network embedding},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust fusion kalman estimators for networked mixed
uncertain systems with random one-step measurement delays, missing
measurements, multiplicative noises and uncertain noise variances.
<em>ISCI</em>, <em>534</em>, 27–52. (<a
href="https://doi.org/10.1016/j.ins.2020.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For mixed uncertain multisensor networked systems simultaneously with four uncertainties including random one-step measurement delays, missing measurements, multiplicative noises and uncertain noise variances, three new approaches of solving robust fusion estimation problem are presented. They include augmented state approach with fictitious white noises, extended Lyapunov equation approach, and universal integrated covariance intersection (ICI) fusion approach. Applying them, the minimax robust local and five fused time-varying Kalman estimators (predictor, filter an smoother) are presented in the sense that their actual estimation error variances are guaranteed to have the corresponding minimal upper bounds for all admissible uncertainties. The five robust fusers include centralized fuser, fusers weighted respectively by matrices, diagonal matrices and scalars, and ICI fuser. Their robustness and accuracy relations are proved. The proposed approaches and results constitute an important methodology and a unified robust fusion Kalman filtering theory of solving the robust estimation problem. A simulation example applied to the vehicle suspension system shows their effectiveness and applicability.},
  archive      = {J_ISCI},
  author       = {Chenjian Ran and Zili Deng},
  doi          = {10.1016/j.ins.2020.04.044},
  journal      = {Information Sciences},
  pages        = {27-52},
  shortjournal = {Inf. Sci.},
  title        = {Robust fusion kalman estimators for networked mixed uncertain systems with random one-step measurement delays, missing measurements, multiplicative noises and uncertain noise variances},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast occluded passenger detector based on MetroNet and
tiny MetroNet. <em>ISCI</em>, <em>534</em>, 16–26. (<a
href="https://doi.org/10.1016/j.ins.2020.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metro passenger detection is always a significant task and a bottleneck in metro video surveillance system . Much recent research has demonstrated that Convolutional Neural Network (CNN) is more powerful than other machine learning algorithms in numerous computer vision tasks. Motivated by the research, this paper proposes MetroNet and Tiny MetroNet for detecting occluded metro passengers in metro embedded system with limited hardware resources. MetroNet consists of smaller CNN-SqueezeNet, Region Proposal Network (RPN) and Detection Head subnet. Besides, the repulsion loss is adopted to effectively prevent detection results from worsening caused by severe passengers’ occlusion during training phase. On the other hand, considering that some platforms have more limited hardware resources, a simple version of the MetroNet named Tiny MetroNet is designed and a novel, tiny passenger feature network is proposed as backbone. Based on three datasets, two MetroNets are tested and compared to existing state-of-the-art detection networks on CPU and GPU mode. The experiment results demonstrate that MetroNet has real-time performance and better detection accuracy. Tiny MetroNet achieves fast detection speed and smaller model size with acceptable performance degradation . Even for the ARM embedded system , their performance is competitive and can meet the application requirements of high-speed metros.},
  archive      = {J_ISCI},
  author       = {Qiang Guo and Quanli Liu and Wei Wang and Yuanqing Zhang and Qiang Kang},
  doi          = {10.1016/j.ins.2020.05.009},
  journal      = {Information Sciences},
  pages        = {16-26},
  shortjournal = {Inf. Sci.},
  title        = {A fast occluded passenger detector based on MetroNet and tiny MetroNet},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Least loss: A simplified filter method for feature
selection. <em>ISCI</em>, <em>534</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2020.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the relevant set of features in a dataset is an important part of data analytics. Discarding significant variables or keeping irrelevant variables has significant effects on the performance of the learning algorithm during knowledge discovery. In this paper, a feature selection method called Least Loss (L 2 ) is proposed that significantly reduces the dimensionality of data by disposing weakly correlated variables in a robust manner without diminishing the predictive performance of classifiers. The proposed method is based on quantifying the similarity between the observed and expected probabilities and generating scores for each independent variable, which makes it simple and intuitive. The evaluation of the proposed method was done by comparing its performance against Information Gain (IG) and Chi Square (CHI) feature selection methods on 27 different datasets modeled using a probabilistic classifier. The results reveal that L 2 is highly competitive with respect to error rate, precision, and recall measures while substantially reducing the number of selected variables in the datasets. Our study would be of high interest to data analysts, scholars and domain experts who deal with applications that include large numbers of features using statistical analysis methods.},
  archive      = {J_ISCI},
  author       = {Fadi Thabtah and Firuz Kamalov and Suhel Hammoud and Seyed Reza Shahamiri},
  doi          = {10.1016/j.ins.2020.05.017},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Least loss: A simplified filter method for feature selection},
  volume       = {534},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial-complexity robust deadlock controllers for a
class of automated manufacturing systems with unreliable resources using
petri nets. <em>ISCI</em>, <em>533</em>, 181–199. (<a
href="https://doi.org/10.1016/j.ins.2020.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of automated manufacturing systems (AMSs) with unreliable resources, most existing robust deadlock controllers have high computational complexity or relatively low permissiveness . This work focuses on the deadlock control problem of AMSs with a kind of unreliable resources. Petri nets are used to model the dynamic behaviors of such failure-prone AMSs. First a robust deadlock prevention controller is developed for a large class of AMSs under consideration. Such a robust controller guarantees that the system can process all types of parts continuously through any one of their routes, even if one of unreliable resources fails. Also, this robust controller is proved to be optimal, i.e., maximally permissive, during one resource failure period. Then by using the one-step look-ahead method, we establish a polynomial-complexity robust deadlock avoidance policy (DAP) with the same permissiveness as the obtained robust deadlock prevention controller. That is, such a robust DAP not only has low computational complexity , but also is maximally permissive during one resource failure period.},
  archive      = {J_ISCI},
  author       = {Yanxiang Feng and Keyi Xing and MengChu Zhou and Hefeng Chen and Feng Tian},
  doi          = {10.1016/j.ins.2020.05.007},
  journal      = {Information Sciences},
  pages        = {181-199},
  shortjournal = {Inf. Sci.},
  title        = {Polynomial-complexity robust deadlock controllers for a class of automated manufacturing systems with unreliable resources using petri nets},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpretable multi-scale graph descriptors via structural
compression. <em>ISCI</em>, <em>533</em>, 169–180. (<a
href="https://doi.org/10.1016/j.ins.2020.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representations that preserve relevant topological information allow the use of a rich machine learning toolset for data-driven network analytics. Some notable graph representations in the literature are fruitful in their respective applications but they either lack interpretability or are unable to effectively encode a graph’s structure at both local and global scale. In this work, we propose the Higher-Order Structure Descriptor (HOSD): an interpretable graph descriptor that captures information about the patterns in a graph at multiple scales. Scaling is achieved using a novel graph compression technique that reveals successive higher-order structures. The proposed descriptor is invariant to node permutations due to its graph-theoretic nature. We analyze the HOSD algorithm for time complexity and also prove the NP-completeness of three interesting graph compression problems . A faster version, HOSD-Lite, is also presented to approximate HOSD on dense graphs. We showcase the interpretability of our model by discussing structural patterns found within real-world datasets using HOSD. HOSD and HOSD-Lite are evaluated on benchmark datasets for applicability to classification problems; results demonstrate that a simple random forest setup based on our representations competes well with the current state-of-the-art graph embeddings .},
  archive      = {J_ISCI},
  author       = {Ammar Ahmed and Zohair Raza Hassan and Mudassir Shabbir},
  doi          = {10.1016/j.ins.2020.05.032},
  journal      = {Information Sciences},
  pages        = {169-180},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable multi-scale graph descriptors via structural compression},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A consensus reaching process with quantum subjective
adjustment in linguistic group decision making. <em>ISCI</em>,
<em>533</em>, 150–168. (<a
href="https://doi.org/10.1016/j.ins.2020.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consensus reaching process (CRP) is essential to obtain a final solution in group decision making (GDM). This paper focuses on constructing a consensus mechanism where decision makers (DMs) use linguistic term sets (LTSs) to express their preferences. LTSs can describe real decision making well. Adjusting opinions can improve the consensus level, we assume that the adjusted opinion combines an initial preference and a referenced preference. The subjective behavior characteristics expressed by DMs would affect the CRP. To simulate human behavior, quantum probability theory is applied to aggregate referenced opinions, reflecting the interference effect caused by subjective beliefs flowing toward decision classification paths. The paths are composed of the clusters with the highest consensus and consistency degrees. Moreover, the combination is generated based on the subjective willingness defined by the consensus position of the recognized DM in the group. An optimization model is set to control individual consistency after implementing modifications. Finally, a numerical example illustrates the principle of the constructed model.},
  archive      = {J_ISCI},
  author       = {Xiao Tan and Jianjun Zhu and Yuhuai Zhang},
  doi          = {10.1016/j.ins.2020.05.003},
  journal      = {Information Sciences},
  pages        = {150-168},
  shortjournal = {Inf. Sci.},
  title        = {A consensus reaching process with quantum subjective adjustment in linguistic group decision making},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group anomaly detection based on bayesian framework with
genetic algorithm. <em>ISCI</em>, <em>533</em>, 138–149. (<a
href="https://doi.org/10.1016/j.ins.2020.03.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is an important application field of evolutionary algorithm . Unlike traditionly anomaly detection, group anomaly detection aims to discover the anomalous aggregate behaviors in data points. Over past decades, a large number of promising methods have been successfully applied for group anomaly detection. However, they inherently neglect the correlations among groups in data points, limiting their abilities. This paper presents a correlated hierarchical generative model , which can model the intricate correlations hidden in groups by introducing a logistic normal distribution to capture the correlations among groups. With the proposed model, we construct a full variational Bayesian framework , which can data-adaptively optimize the model parameters of the proposed model. The model is designed and trained using Genetic Algorithm (GA), which helps automating the use of generative model. Further, a new score function is proposed as an anomaly criterion to estimate final anomaly groups in data points. Several experiments on synthetic data and real astronomical star data from Sloan Digital Sky Survey demonstrate the effectiveness of proposed method compared with the-state-of-art methods, in terms of average accurac (AP) and area under the Receiver Operating Characteristic(ROC) curve(AUC).},
  archive      = {J_ISCI},
  author       = {Wanjuan Song and Wenyong Dong and Lanlan Kang},
  doi          = {10.1016/j.ins.2020.03.110},
  journal      = {Information Sciences},
  pages        = {138-149},
  shortjournal = {Inf. Sci.},
  title        = {Group anomaly detection based on bayesian framework with genetic algorithm},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Large group decision-making incorporating decision risk and
risk attitude: A statistical approach. <em>ISCI</em>, <em>533</em>,
120–137. (<a href="https://doi.org/10.1016/j.ins.2020.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a statistical method incorporating decision risk and risk attitude into large group decision-making. The decision-making groups are divided into subgroups based on their attitudes to risk, and the evaluation information for the decision-makers within the same subgroup is combined to form the sample dataset. Next, the internal decision risk levels of all subgroups are measured using sample standard deviations and reduced through a feedback mechanism. Significance testing is used to determine the criterion weights and to measure the external decision risk levels of subgroups. The internal and external decision risk levels are then combined to yield the subgroup weights. Confidence interval is used to transform the sample data into interval numbers, which are then aggregated and analyzed to yield the decision-making results. Meanwhile, risk attitudes are taken into account throughout the decision-making process by various means. A case study and comparison analyses, along with sensitivity analyses, are used to illustrate the feasibility and rationality of the proposed method. Our experiments suggest that decision risk and risk attitude matter in large group decision-making.},
  archive      = {J_ISCI},
  author       = {Xiangyu Zhong and Xuanhua Xu and Xiaohong Chen and Mark Goh},
  doi          = {10.1016/j.ins.2020.04.003},
  journal      = {Information Sciences},
  pages        = {120-137},
  shortjournal = {Inf. Sci.},
  title        = {Large group decision-making incorporating decision risk and risk attitude: A statistical approach},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Associative memory optimized method on deep neural networks
for image classification. <em>ISCI</em>, <em>533</em>, 108–119. (<a
href="https://doi.org/10.1016/j.ins.2020.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved excellent performance in the field of image classification . However, even to state-of-the-art deep neural networks , there are still many critical images that are difficult to be classified effectively. Enlightened by the brain function of associative memory , we propose a novel classification optimization method based on deep neural networks to improve image classifiers. Psychologists have studied associative memory for a long time. A popular theory is that ideas and memory are associated together in the mind through experience. By applying this theory to object recognition, our method focuses on using the association among different images of the same category to improve image classifiers based on deep neural networks. The association, which is memorized by the LSTM network in our method, could infer a sequence of associative images and form inner data augmentation effectively. Further, we introduce the LSTM network into an end-to-end deep learning framework to boost the performance of image classifiers. Experiments on four benchmark datasets reveal that our method produces a consistent improvement to the existing powerful classifiers. Moreover, as far as we know, our method achieves the best classification accuracies of 97.3\%, 96.0\%, and 89.1\% on Flower102, Caltech101, and Caltech256 datasets, respectively.},
  archive      = {J_ISCI},
  author       = {Gang Yang and Fei Ding},
  doi          = {10.1016/j.ins.2020.05.038},
  journal      = {Information Sciences},
  pages        = {108-119},
  shortjournal = {Inf. Sci.},
  title        = {Associative memory optimized method on deep neural networks for image classification},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ameliorated teaching–learning-based optimization
algorithm based study of image segmentation for multilevel thresholding
using kapur’s entropy and otsu’s between class variance. <em>ISCI</em>,
<em>533</em>, 72–107. (<a
href="https://doi.org/10.1016/j.ins.2020.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, multi-threshold image segmentation approaches using an improved teaching–learning-based optimization algorithm (DI-TLBO) are presented and the proposed DI-TLBO-based methods obtain satisfactory segmentation results. This work is presented as follows. Firstly, two random numbers are introduced to determine the learning methods of the learner in the teacher phases and the learner phases of DI-TLBO. Randomness of the learning methods further improves global optimization ability of DI-TLBO. Self-feedback learning phase and mutation-crossover phase are also introduced into DI-TLBO algorithm, which makes DI-TLBO achieve better exploration ability. The comparative results of DI-TLBO with other evolutionary algorithms (EAs) on a set of benchmarks functions demonstrate that DI-TLBO acquires better solution accuracy than other EAs. Then the proposed DI-TLBO algorithm is applied to solve multi-level threshold image segmentation problems modeled by Otsu’s between class variance function and Kapur’s entropy function. Experiments comparing DI-TLBO-based methods with other EAs based approaches on standard test images show that DI-TLBO-based methods possess superior performance in terms of both solution accuracy and stability of segmentation results. Finally, the proposed DI-TLBO-based methods are successfully applied in casting X-ray image segmentation for multi-level threshold. Although the defects in high resolution X-ray image ( 3072 × 2400 3072×2400 ) are easy to be ignored and omitted when being detected artificially, all the defects are segmented perfectly using the proposed DI-TLBO-based methods.},
  archive      = {J_ISCI},
  author       = {Bo Wu and Jianxin Zhou and Xiaoyuan Ji and Yajun Yin and Xu Shen},
  doi          = {10.1016/j.ins.2020.05.033},
  journal      = {Information Sciences},
  pages        = {72-107},
  shortjournal = {Inf. Sci.},
  title        = {An ameliorated teaching–learning-based optimization algorithm based study of image segmentation for multilevel thresholding using kapur’s entropy and otsu’s between class variance},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discriminative deep multi-task learning for facial
expression recognition. <em>ISCI</em>, <em>533</em>, 60–71. (<a
href="https://doi.org/10.1016/j.ins.2020.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multi-task learning (DMTL) is an efficient machine learning technique that has been widely utilized for facial expression recognition. However, current deep multi-task learning methods typically only consider the information of class labels, while ignoring the local information of sample spatial distribution. In this paper, we propose a discriminative DMTL (DDMTL) facial expression recognition method, which overcomes the above shortcomings by considering both the class label information and the samples’ local spatial distribution information simultaneously. We further design a siamese network to evaluate the local spatial distribution through an adaptive reweighting module, utilizing the class label information with different confidences. In addition, by taking the advantage of the provided local distribution information of samples, DDMTL is able to achieve acceptable results even if the number of training samples is small. We implement experiments on three facial expression datasets. The experimental results demonstrate that DDMTL is superior to the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Hao Zheng and Ruili Wang and Wanting Ji and Ming Zong and Wai Keung Wong and Zhihui Lai and Hexin Lv},
  doi          = {10.1016/j.ins.2020.04.041},
  journal      = {Information Sciences},
  pages        = {60-71},
  shortjournal = {Inf. Sci.},
  title        = {Discriminative deep multi-task learning for facial expression recognition},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GLDH: Toward more efficient global low-density
locality-sensitive hashing for high dimensions. <em>ISCI</em>,
<em>533</em>, 43–59. (<a
href="https://doi.org/10.1016/j.ins.2020.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite decades of intensive effort, the current solutions for efficiently searching high-dimensional data spaces are not entirely satisfactory. This paper proposes a more efficient global low-density locality sensitive hashing search algorithm (GLDH) based on the minimal cut hyperplane and ensemble learning . The innovation is that a novel global low-density hyperplane candidate set is constructed by the graph cut method, the minimum information gain method and random maximum entropy method are used to greedily select the hyperplane, and the ensemble learning method is used to query the global approximate nearest-neighbors data. This paper proves that the GLDH algorithm produces a low error hyperplane partition. The results of extensive experiments show that the proposed GLDH method performs better than the latest methods when using the same hash coding length for datasets from different fields.},
  archive      = {J_ISCI},
  author       = {Yiqi Li and Ruliang Xiao and Xin Wei and Huakun Liu and Shi Zhang and Xin Du},
  doi          = {10.1016/j.ins.2020.04.046},
  journal      = {Information Sciences},
  pages        = {43-59},
  shortjournal = {Inf. Sci.},
  title        = {GLDH: Toward more efficient global low-density locality-sensitive hashing for high dimensions},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel design of sparse deep belief network with
multi-objective optimization. <em>ISCI</em>, <em>533</em>, 24–42. (<a
href="https://doi.org/10.1016/j.ins.2020.03.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep belief network (DBN) is an import deep learning model and restricted Boltzmann machine (RBM) is one of its basic models. The traditional DBN and RBM have numerous redundant features. Hence an improved strategy is required to perform sparse operations on them. Previously, we have proposed our own sparse DBN (SDBN): using a multi-objective optimization (MOP) algorithm to learn sparse features, which solves the contradiction between the reconstruction error and network sparsity of RBM. Due to the optimization algorithm and millions of parameters of the network itself, the training process is difficult. Therefore, in this paper, we propose an efficient parallel strategy to speed up the training of SDBN networks. Self-adaptive Quantum Multi-objectives Evolutionary algorithm based on Decomposition (SA-QMOEA/D) that we have proposed as the multi-objective optimization algorithm has the hidden parallelism of populations. Based on this, we not only parallelize the DBN network but also realize the parallelism of the multi-objective optimization algorithm. In order to further verify the advantages of our approach, we apply it to the problem of facial expression recognition (FER). The obtained experimental results demonstrate that our parallel algorithm achieves a significant speedup performance and a higher accuracy rate over previous CPU implementations and other conventional methods.},
  archive      = {J_ISCI},
  author       = {Yangyang Li and Shuangkang Fang and Xiaoyu Bai and Licheng Jiao and Naresh Marturi},
  doi          = {10.1016/j.ins.2020.03.084},
  journal      = {Information Sciences},
  pages        = {24-42},
  shortjournal = {Inf. Sci.},
  title        = {Parallel design of sparse deep belief network with multi-objective optimization},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Least squares projection twin support vector clustering
(LSPTSVC). <em>ISCI</em>, <em>533</em>, 1–23. (<a
href="https://doi.org/10.1016/j.ins.2020.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a prominent unsupervised learning technique. In the literature, many plane based clustering algorithms are proposed, such as the twin support vector clustering (TWSVC) algorithm. In this work, we propose an alternative algorithm based on projection axes termed as least squares projection twin support vector clustering (LSPTSVC). The proposed LSPTSVC finds projection axis for every cluster in a manner that minimizes the within class scatter, and keeps the clusters of other classes far away. To solve the optimization problem , the concave-convex procedure (CCCP) is utilized in the proposed method. Moreover, the solution of proposed LSPTSVC involves a set of linear equations leading to very less training time. To verify the performance of the proposed algorithm, several experiments are performed on synthetic and real world benchmark datasets. Experimental results and statistical analysis show that the proposed LSPTSVC performs better than existing algorithms w.r.t. clustering accuracy as well as training time. Moreover, a comparison of the proposed method with existing algorithms is presented on biometric and biomedical applications. Better generalization performance is achieved by proposed LSPTSVC on clustering of facial images, and Alzheimer’s disease data.},
  archive      = {J_ISCI},
  author       = {B. Richhariya and M. Tanveer and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.ins.2020.05.001},
  journal      = {Information Sciences},
  pages        = {1-23},
  shortjournal = {Inf. Sci.},
  title        = {Least squares projection twin support vector clustering (LSPTSVC)},
  volume       = {533},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor n-tubal rank and its convex relaxation for low-rank
tensor recovery. <em>ISCI</em>, <em>532</em>, 170–189. (<a
href="https://doi.org/10.1016/j.ins.2020.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent popular tensor tubal rank, defined based on tensor singular value decomposition (t-SVD), yields promising results. However, its framework is applicable only to three-way tensors and lacks the flexibility necessary tohandle different correlations along different modes. To tackle these two issues, we define a new tensor unfolding operator, named mode- k1k2 tensor unfolding, as the process of lexicographically stacking all mode- k1k2 slices of an N -way tensor into a three-way tensor, which is a three-way extension of the well-known mode- k tensor matricization. On this basis, we define a novel tensor rank, named the tensor N -tubal rank, as a vector consisting of the tubal ranks of all mode- k1k2 unfolding tensors, to depict the correlations along different modes. To efficiently minimize the proposed N -tubal rank, we establish its convex relaxation: the weighted sum of the tensor nuclear norm (WSTNN). Then, we apply the WSTNN to low-rank tensor completion (LRTC) and tensor robust principal component analysis (TRPCA). The corresponding WSTNN-based LRTC and TRPCA models are proposed, and two efficient alternating direction method of multipliers (ADMM)-based algorithms are developed to solve the proposed models. Numerical experiments demonstrate that the proposed models significantly outperform the compared ones.},
  archive      = {J_ISCI},
  author       = {Yu-Bang Zheng and Ting-Zhu Huang and Xi-Le Zhao and Tai-Xiang Jiang and Teng-Yu Ji and Tian-Hui Ma},
  doi          = {10.1016/j.ins.2020.05.005},
  journal      = {Information Sciences},
  pages        = {170-189},
  shortjournal = {Inf. Sci.},
  title        = {Tensor N-tubal rank and its convex relaxation for low-rank tensor recovery},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UAV-aided trustworthy data collection in
federated-WSN-enabled IoT applications. <em>ISCI</em>, <em>532</em>,
155–169. (<a href="https://doi.org/10.1016/j.ins.2020.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In emerging applications of the Internet of Things (IoT), wireless sensor networks (WSNs) are usually federally deployed for these purposes of data gathering, tracking and monitoring. Under the universal WSN architecture, a mass of collected data will be converged on deployed sinks. Therefore, reasonable solutions for sink deployment must be achieved to optimally operate federated-WSN-enabled IoT applications. To address this issue, the deployment of unmanned aerial vehicles (UAVs) acting as mobile sinks is investigated, in which a new concept of ‘great full-coverage subgraph’ with the most complete connectivity is introduced to generate candidate areas for deploying UAVs. Thereby, the investigation is transformed into solving a traditional K -center problem formulated as a multi-objective joint optimization with multiple constraints. Subsequently, to address serious security vulnerabilities on UAV-aided trustworthy data collection, a lightweight authority authentication model using specific procedures is investigated to enforce the data collection session to be conducted only by both trusted sensors and UAVs with an acceptable authentication delay. Finally, numerical analysis and evaluation results are shown to demonstrate efficiencies of investigations.},
  archive      = {J_ISCI},
  author       = {Ming Tao and Xueqiang Li and Huaqiang Yuan and Wenhong Wei},
  doi          = {10.1016/j.ins.2020.03.053},
  journal      = {Information Sciences},
  pages        = {155-169},
  shortjournal = {Inf. Sci.},
  title        = {UAV-aided trustworthy data collection in federated-WSN-enabled IoT applications},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized ordinal sums of aggregation operators on bounded
lattices. <em>ISCI</em>, <em>532</em>, 139–154. (<a
href="https://doi.org/10.1016/j.ins.2020.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, four kinds of generalized ordinal sums of aggregation operators on bounded lattices are provided and discussed. Firstly, necessary and sufficient conditions for lower (resp. upper) generalized ordinal sum of many summands to be an aggregation operator are provided, in which case that the smallest (resp. greatest) aggregation operator that coincides with each summand is given. Meanwhile, the idempotent lower (resp. upper) generalized ordinal sum of idempotent aggregation operators is also discussed. Then the relationships between these four kinds of generalized ordinal sums are given. Finally, the lattice structures of some sets of special aggregation operators are investigated.},
  archive      = {J_ISCI},
  author       = {Haiwei Wang and Bin Zhao},
  doi          = {10.1016/j.ins.2020.04.045},
  journal      = {Information Sciences},
  pages        = {139-154},
  shortjournal = {Inf. Sci.},
  title        = {Generalized ordinal sums of aggregation operators on bounded lattices},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asynchronous control strategy for semi-markov switched
system and its application. <em>ISCI</em>, <em>532</em>, 125–138. (<a
href="https://doi.org/10.1016/j.ins.2020.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of modeling and control for DC-DC converter is investigated. A novel switched system model is established and an asynchronous control strategy is designed. Firstly, the DC-DC converter is modeled by the semi-Markov switched system with uncertainty and external disturbance . In which, the change of resistance parameter and the jump of input voltage are considered. Additionally, the sojourn-time of the switch is considered in the new model, in this way, it can be more accurately to depict the dynamic behavior of the plant. Then, in order to guarantee the stability of the plant, a state feedback asynchronous controller is proposed. Furthermore, the stability conditions of the closed-loop system with a prescribed H ∞ index factor are given and the controller gains are solved. Finally, a numerical simulation and a practical experiment are executed to verify the superiority of proposed control strategies.},
  archive      = {J_ISCI},
  author       = {Meng Li and Yong Chen and Longyu Xu and Zhang-yong Chen},
  doi          = {10.1016/j.ins.2020.04.004},
  journal      = {Information Sciences},
  pages        = {125-138},
  shortjournal = {Inf. Sci.},
  title        = {Asynchronous control strategy for semi-markov switched system and its application},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep reinforcement learning for pedestrian collision
avoidance and human-machine cooperative driving. <em>ISCI</em>,
<em>532</em>, 110–124. (<a
href="https://doi.org/10.1016/j.ins.2020.03.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent driving technology, human-machine cooperative driving is significant to improve driving safety in abnormal situations, such as distraction or incorrect operations of drivers. For human-machine cooperative driving , the capacity of pedestrian collision avoidance is fundamental and important. This paper proposes a novel learning-based human-machine cooperative driving scheme (L-HMC) with active collision avoidance capacity using deep reinforcement learning . Firstly, an improved deep Q-network (DQN) method is designed to learn the optimal driving policy for pedestrian collision avoidance. In the improved DQN method, two replay buffers with nonuniform samples are designed to shorten the learning process of the optimal driving policy. Then, a human-machine cooperative driving scheme is proposed to assist human drivers with the learned driving policy for pedestrian collision avoidance when the driving behavior of human drivers is dangerous to the pedestrian. The effectiveness of the human-machine cooperative driving scheme is verified on the simulation platform PreScan using a real vehicle dynamic model. The results demonstrate that the deep reinforcement learning-based method can learn an effective driving policy for pedestrian collision avoidance with a fast convergence rate. Meanwhile, the proposed human-machine cooperative driving scheme L-HMC can avoid potential pedestrian collisions through flexible policies in typical scenarios, therefore improving driving safety.},
  archive      = {J_ISCI},
  author       = {Junxiang Li and Liang Yao and Xin Xu and Bang Cheng and Junkai Ren},
  doi          = {10.1016/j.ins.2020.03.105},
  journal      = {Information Sciences},
  pages        = {110-124},
  shortjournal = {Inf. Sci.},
  title        = {Deep reinforcement learning for pedestrian collision avoidance and human-machine cooperative driving},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Many-objective optimization of feature selection based on
two-level particle cooperation. <em>ISCI</em>, <em>532</em>, 91–109. (<a
href="https://doi.org/10.1016/j.ins.2020.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) plays a crucial role in classification, which aims to remove redundant and irrelevant data features.unknown However, for high-dimensional FS problems, Pareto optimal solutions are usually sparse, signifying that most of the decision variables are zero. Solving such problems using most existing evolutionary algorithms is difficult. In this paper, we reformulate FS as a many-objective optimization problem comprising three objectives to be minimized. To solve this problem, we proposed a binary particle swarm optimization with a two-level particle cooperation strategy. In the first level, to maintain rapid convergence, randomly generated ordinary particles and strict particles filtered by ReliefF are combined as the initialized particles. In the second level, under the decomposition multiobjective optimization framework, cooperation between particles is conducted during the update process to search for Pareto solutions more efficiently. In addition, a many-objective reset operation is proposed to enable the algorithm to jump out of the local optimum. Experimental studies on 10 real-world benchmark data sets revealed that our proposed algorithm could effectively reduce the number of features and achieve a competitive classification accuracy compared with some state-of-the-art evolutionary FS methods and non-evolutionary approaches.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Junhao Kang and Hainan Guo},
  doi          = {10.1016/j.ins.2020.05.004},
  journal      = {Information Sciences},
  pages        = {91-109},
  shortjournal = {Inf. Sci.},
  title        = {Many-objective optimization of feature selection based on two-level particle cooperation},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exam paper generation based on performance prediction of
student group. <em>ISCI</em>, <em>532</em>, 72–90. (<a
href="https://doi.org/10.1016/j.ins.2020.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exam paper generation is an indispensable part of teaching. Existing methods focus on the use of question extraction algorithms with labels for each question provided. Obviously, manual labeling is inefficient and cannot avoid label bias. Furthermore, the quality of the exam papers generated by the existing methods is not guaranteed. To address these problems, we propose a novel approach to generating exam papers based on prediction of exam performance. As such, we update the quality of the initially generated questions one by using dynamic programming , as well as in batches by using genetic algorithms . We performed the prediction task by using Deep Knowledge Tracing. Our approach considered the skill weight, difficulty, and distribution of exam scores. By comparisons, experimental results indicate that our approach performed better than the two baselines. Furthermore, it can generate exam papers with adaptive difficulties closely to the expected levels, and the related student exam scores will be guaranteed to be relatively reasonable distribution. In addition, our approach was evaluated in a real learning scenarios and shows advantages.},
  archive      = {J_ISCI},
  author       = {Zhengyang Wu and Tao He and Chenjie Mao and Changqin Huang},
  doi          = {10.1016/j.ins.2020.04.043},
  journal      = {Information Sciences},
  pages        = {72-90},
  shortjournal = {Inf. Sci.},
  title        = {Exam paper generation based on performance prediction of student group},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Key energy-consumption feature selection of thermal power
systems based on robust attribute reduction with rough sets.
<em>ISCI</em>, <em>532</em>, 61–71. (<a
href="https://doi.org/10.1016/j.ins.2020.03.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanism analysis is the main method for energy-consumption feature selection of thermal power systems . Although this method can select a few features with specific physical meanings as the input variables for energy-consumption modeling, it may ignore some important attributes which affect the fitting and generalization capabilities of the model. We propose a robust attribute reduction method with rough set theory and apply it to the above task. Taking a boiler combustion system of some 600MW power unit as experimental subject, an energy-consumption model with the selected key features is built. Several comparative experiments were carried out on the operational data to evaluate the performance of the energy-consumption model. The experimental results show that the robust attribute reduction algorithm has strong generalization ability , and the energy-consumption model built with key features has a strong fitting ability and high prediction accuracy, thus providing an effective method for energy-consumption prediction and optimization of the thermal power system.},
  archive      = {J_ISCI},
  author       = {Dong Lianjie and Chen Degang and Wang Ningling and Lu Zhanhui},
  doi          = {10.1016/j.ins.2020.03.085},
  journal      = {Information Sciences},
  pages        = {61-71},
  shortjournal = {Inf. Sci.},
  title        = {Key energy-consumption feature selection of thermal power systems based on robust attribute reduction with rough sets},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evidence theory based model fusion method for degradation
modeling and statistical analysis. <em>ISCI</em>, <em>532</em>, 33–60.
(<a href="https://doi.org/10.1016/j.ins.2020.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several methods have been proposed to handle uncertainty issues, including process uncertainty and parameter uncertainty, in stochastic-process based degradation modeling and statistical analysis. However, these methods oftentimes do not address the uncertainty issues well under small sample conditions. Hence, due to the powerful ability of evidence theory to describe uncertainty, especially under small sample conditions, an evidence theory based model fusion method is proposed. The candidate models are considered as different evidence sources and give evidences about the evaluated product based on likelihood. Considering the heterogeneous characteristics of the evidences predicted from different candidate models, the reliability degree is introduced to convert the evidences and estimated based on goodness-of-fit. By fusing converted evidences, inferences and estimations of reliability, degradation mean, degradation variance, and mean time to failure are obtained. The effectiveness of the proposed method is verified by previously published degradation datasets and comparing to Bayesian model averaging method and model selecting method. The degradation mean and variance estimations are more precise and more stable compared to the other two methods under small sample conditions. Furthermore, the proposed method can be used to consider the uncertainty issues by belief, plausibility and uncertainty measure, even though under extremely small sample conditions.},
  archive      = {J_ISCI},
  author       = {Di Liu and Shaoping Wang and Mileta M. Tomovic and Chao Zhang},
  doi          = {10.1016/j.ins.2020.04.042},
  journal      = {Information Sciences},
  pages        = {33-60},
  shortjournal = {Inf. Sci.},
  title        = {An evidence theory based model fusion method for degradation modeling and statistical analysis},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced word embeddings using multi-semantic representation
through lexical chains. <em>ISCI</em>, <em>532</em>, 16–32. (<a
href="https://doi.org/10.1016/j.ins.2020.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between words in a sentence often tells us more about the underlying semantic content of a document than its actual words, individually. In this work, we propose two novel algorithms, called Flexible Lexical Chain II and Fixed Lexical Chain II . These algorithms combine the semantic relations derived from lexical chains, prior knowledge from lexical databases, and the robustness of the distributional hypothesis in word embeddings as building blocks forming a single system. In short, our approach has three main contributions: (i) a set of techniques that fully integrate word embeddings and lexical chains; (ii) a more robust semantic representation that considers the latent relation between words in a document; and (iii) lightweight word embeddings models that can be extended to any natural language task. We intend to assess the knowledge of pre-trained models to evaluate their robustness in the document classification task. The proposed techniques are tested against seven word embeddings algorithms using five different machine learning classifiers over six scenarios in the document classification task. Our results show the integration between lexical chains and word embeddings representations sustain state-of-the-art results, even against more complex systems.},
  archive      = {J_ISCI},
  author       = {Terry Ruas and Charles Henrique Porto Ferreira and William Grosky and Fabrício Olivetti de França and Débora Maria Rossi de Medeiros},
  doi          = {10.1016/j.ins.2020.04.048},
  journal      = {Information Sciences},
  pages        = {16-32},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced word embeddings using multi-semantic representation through lexical chains},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Privacy-aware offloading for training tasks of generative
adversarial network in edge computing. <em>ISCI</em>, <em>532</em>,
1–15. (<a href="https://doi.org/10.1016/j.ins.2020.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the generative adversarial network (GAN), with complex training processes in the physical machine (PM), has achieved great priority in image generation , audio conversion, image translation, etc. To improve the training efficiency of GAN, the edge computing paradigm is accepted as an alternative of the PMs to accommodate the training tasks, that is, the training tasks are migrated to the edge nodes (ENs) for hosting. However, it is still a key challenge to keep the overall network performance (i.e., load balance, transmission time) and privacy protection of training tasks at the same time. To address this challenge, a privacy-aware task offloading method, named POM, is developed accordingly in this paper. First, improving the strength pareto evolutionary algorithm (SPEA2) is fully investigated to obtain the offloading strategies for collaboratively improving the training performance and privacy preservation . Then, the most balanced offloading strategy is acquired for training GAN. Eventually, systematic experiments indicate that POM achieves an optimal performance efficiently among the other representative benchmark methods.},
  archive      = {J_ISCI},
  author       = {Xiaolong Xu and Xihua Liu and Xiaochun Yin and Shoujin Wang and Quan Qi and Lianyong Qi},
  doi          = {10.1016/j.ins.2020.04.026},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-aware offloading for training tasks of generative adversarial network in edge computing},
  volume       = {532},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial attacks on deep-learning-based radar range
profile target recognition. <em>ISCI</em>, <em>531</em>, 159–176. (<a
href="https://doi.org/10.1016/j.ins.2020.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target recognition based on a high-resolution range profile (HRRP) has always been a research hotspot in the radar signal interpretation field. Deep learning has been an important method for HRRP target recognition. However, recent research has shown that optical image target recognition methods based on deep learning are vulnerable to adversarial samples. Whether HRRP target recognition methods based on deep learning can be attacked remains an open question. In this paper, four methods of generating adversarial perturbations are proposed. Algorithm 1 generates the nontargeted fine-grained perturbation based on the binary search method. Algorithm 2 generates the targeted fine-grained perturbation based on the multiple-iteration method. Algorithm 3 generates the nontargeted universal adversarial perturbation (UAP) based on aggregating some fine-grained perturbations. Algorithm 4 generates the targeted universal perturbation based on scaling one fine-grained perturbation. These perturbations are used to generate adversarial samples to attack HRRP target recognition methods based on deep learning under white-box and black-box attacks. The experiments are conducted with actual radar data and show that the HRRP adversarial samples have certain aggressiveness. Therefore, HRRP target recognition methods based on deep learning have potential security risks.},
  archive      = {J_ISCI},
  author       = {Teng Huang and Yongfeng Chen and Bingjian Yao and Bifen Yang and Xianmin Wang and Ya Li},
  doi          = {10.1016/j.ins.2020.03.066},
  journal      = {Information Sciences},
  pages        = {159-176},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial attacks on deep-learning-based radar range profile target recognition},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic organization model of automated negotiation for 3PL
providers selection. <em>ISCI</em>, <em>531</em>, 139–158. (<a
href="https://doi.org/10.1016/j.ins.2020.03.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To keep their competitive edge and improve customer satisfaction, it is popular for many companies to outsource their logistics to proper Third-Party Logistics (3PL) providers. The evaluation and selection of 3PL providers in their business processes are expected to be solved dynamically. In this paper, based on the theory of automated negotiation, a Dynamic Organization Model (DOM) was designed for an online E-commerce Platform (EP) from the perspective of companies outsourcing logistics. During the negotiation, the involved 3PL provider agents may autonomously make decisions upon both the negotiation context and the dynamic market arguments in an iterative manner, and both the basic attributes of 3PL providers and the historical cooperation data with them are considered. Through comprehensive evaluation and negotiation, the most suitable 3PL provider may be determined as the contractual partner. Finally, the effectiveness of DOM is testified by a case study instantiated with a coal company and several 3PL providers.},
  archive      = {J_ISCI},
  author       = {Tai-Guang Gao and Min Huang and Qing Wang and Xing-Wei Wang},
  doi          = {10.1016/j.ins.2020.03.086},
  journal      = {Information Sciences},
  pages        = {139-158},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic organization model of automated negotiation for 3PL providers selection},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Managing noncooperative behaviors in large-scale group
decision-making: Integration of independent and supervised
consensus-reaching models. <em>ISCI</em>, <em>531</em>, 119–138. (<a
href="https://doi.org/10.1016/j.ins.2020.03.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale group decision-making (LSGDM) has been widely studied to address increasingly complex decision-making problems. The consensus-reaching process is usually designed to reduce differences between decision-makers and achieve high-consensus decision results. Opinion adjustment is a good solution for promoting consensus, but there are always some decision-makers who refuse to adjust or make small compromises. Many noncooperative behaviors may exist in the consensus-reaching process. Traditional consensus-reaching models dealing with noncooperative behaviors focus on situations where only one decision-maker modifies his or her opinion in each consensus iteration. However, some, or even all, decision-makers may adjust their opinions in one iteration, especially at the beginning. In this study, a mixed consensus-reaching model for managing noncooperative behaviors is proposed. We first develop a novel method to calculate the weights of decision-makers in LSGDM environments. An independent consensus-reaching model is then put forward to address situations where multiple decision-makers modify their opinions in each iteration. By combining this independent consensus model with traditional consensus models, a mixed consensus model is constructed. Finally, a case study is used to show the feasibility and applicability of the proposed model, and a comparative analysis illustrates its advantages for managing noncooperative behaviors in LSGDM situations.},
  archive      = {J_ISCI},
  author       = {Zhi-jiao Du and Su-min Yu and Xuan-hua Xu},
  doi          = {10.1016/j.ins.2020.03.100},
  journal      = {Information Sciences},
  pages        = {119-138},
  shortjournal = {Inf. Sci.},
  title        = {Managing noncooperative behaviors in large-scale group decision-making: Integration of independent and supervised consensus-reaching models},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-dimensional tree guided efficient global association
for decomposition-based evolutionary many-objective optimization.
<em>ISCI</em>, <em>531</em>, 97–118. (<a
href="https://doi.org/10.1016/j.ins.2020.03.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The suitable association between solutions and subproblems or reference vectors (RVs) is very critical to decomposition-based evolutionary algorithms for many-objective optimization problems (MaOPs). However, the original local association approach leads to the mismatch often and the currently existing global ones have to exhaust all subproblems expensively. In this paper, a multi-dimensional tree guided global association (TGA) mechanism is proposed to associate a solution with the nearest RV more efficiently. The TGA mechanism first constructs a nonlinear multi-dimensional tree (MDTree) to organize all RVs of subproblems. It further introduces a direction dissimilarity metric to measure the mismatches of associations between solutions and RVs. More significantly, owing to the compatibility between this metric and the RV MDTree, the TGA mechanism is capable to prune the RV MDTree to find the nearest RV to a solution in a logarithmic time complexity. In addition, an instantiation of a decomposition-based evolutionary algorithm using the TGA mechanism together with an adaptive aggregation approach is further designed to facilitate the empirical validation of the mechanism. The performance of the mechanism is extensively assessed on the normalized and scaled DTLZ benchmark MaOPs, WFG test suite, as well as two engineering problems. A statistical comparison with several existing local and global association approaches demonstrates the superior effectiveness and computational efficiency of the mechanism.},
  archive      = {J_ISCI},
  author       = {Weiqin Ying and Junjie Huang and Yu Wu and Yali Deng and Yuehong Xie and Zhenyu Wang and Zhiyi Lin},
  doi          = {10.1016/j.ins.2020.03.093},
  journal      = {Information Sciences},
  pages        = {97-118},
  shortjournal = {Inf. Sci.},
  title        = {Multi-dimensional tree guided efficient global association for decomposition-based evolutionary many-objective optimization},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy implications: Alpha migrativity and generalised laws
of importation. <em>ISCI</em>, <em>531</em>, 87–96. (<a
href="https://doi.org/10.1016/j.ins.2020.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we discuss the law of α -migrativity as applied to fuzzy implication functions in a meaningful way. A generalisation of this law leads us to Pexider-type functional equations connected with the law of importation, viz., the generalised law of importation I(C(x,α),y)=I(x,J(α,y)) (GLI) and the generalised cross-law of importation I(C(x,α),y)=J(x,I(α,y)) (CLI), where C is a generalised conjunction. In this article we investigate only (GLI). We begin by showing that the satisfaction of law of importation by the pairs ( C, I ) and/or ( C, J ) does not necessarily lead to the satisfaction of (GLI). Hence, we study the conditions under which these three laws are related.},
  archive      = {J_ISCI},
  author       = {Michał Baczyński and Balasubramaniam Jayaram and Radko Mesiar},
  doi          = {10.1016/j.ins.2020.04.033},
  journal      = {Information Sciences},
  pages        = {87-96},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy implications: Alpha migrativity and generalised laws of importation},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep neural network of multi-form alliances for
personalized recommendations. <em>ISCI</em>, <em>531</em>, 68–86. (<a
href="https://doi.org/10.1016/j.ins.2020.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The collaborative filtering adopted by traditional recommendation system has data sparsity problem, and the matrix decomposition method simply decomposes users and items into linear models for potential factors. These limitations have led to limited effectiveness for traditional recommendation algorithms . In this case, the recommendation system based on deep learning has emerged. Most of the current deep learning recommendations use deep neural networks to model some basic information, and in the modeling process, according to the input data categories, multiple mapping paths are used to map the original data to the potential vector space. However, these recommendations ignore that the alliance between different categories may have a potential impact on the recommendation effect. Aiming at this problem, this paper proposes a feedforward deep neural network of multi-form category features combination for recommendation, which is deep alliance neural network . According to the different alliance modes, it can be divided into deep series network (DSN), deep parallel network (DPN) and deep random network (DRN), which are used to solve the recommendation problem of implicit feedback. At the same time, a fusion model SMLP based on deep alliance neural network and traditional Multi-Layer Perceptron (MLP) is proposed to try to explore the performance of the fusion model. Finally, experiments on public datasets show that our proposed method significantly improves the existing methods. Empirical evidence indicates that deep series network and deep parallel network can provide better recommendation performance, while the recommended performance of deep random network and fusion model SMLP is not ideal. This indicates that the deep alliance network needs to pay special attention to the order of the category features in the process of category features association.},
  archive      = {J_ISCI},
  author       = {Xuna Wang and Qingmei Tan and Lifan Zhang},
  doi          = {10.1016/j.ins.2020.03.062},
  journal      = {Information Sciences},
  pages        = {68-86},
  shortjournal = {Inf. Sci.},
  title        = {A deep neural network of multi-form alliances for personalized recommendations},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-domain ontology construction and alignment from online
customer product reviews. <em>ISCI</em>, <em>531</em>, 47–67. (<a
href="https://doi.org/10.1016/j.ins.2020.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews often contain detailed sentiment towards different aspects of products and these opinions help consumers to be familiar with products. The introduction of domain ontology from online reviews may help consumers to obtain relevant information about products quickly. Nonetheless, they may compare products in multiple domains for purchase decisions. On this basis, the comparison of products in different domains induces that ontology alignment becomes a fundamental task to form a cross-domain ontology. However, due to large-scale text data and complex alignment mapping relations , many alignment algorithms are far from performing effectively. In this paper, a series of natural language processing approaches are applied to construct domain ontologies from online product reviews. Next, a new ontology alignment method is proposed to make purchase decisions regarding cross-domain product comparisons, in which a semantic-based algorithm and a structure-based algorithm are integrated to form a cross-domain ontology. Categories of experiments were conducted on reviews of smartphone and digital camera. Compared with benchmarked alignment tools, it shows that the proposed method yields to more accurate results. Finally, a case study with a customer friendly website is illustrated to present how the alignment of cross-domain ontology is able to help consumers on purchase decision support.},
  archive      = {J_ISCI},
  author       = {Qian Geng and Siyu Deng and Danping Jia and Jian Jin},
  doi          = {10.1016/j.ins.2020.03.058},
  journal      = {Information Sciences},
  pages        = {47-67},
  shortjournal = {Inf. Sci.},
  title        = {Cross-domain ontology construction and alignment from online customer product reviews},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient scientific workflow scheduling for
deadline-constrained parallel tasks in cloud computing environments.
<em>ISCI</em>, <em>531</em>, 31–46. (<a
href="https://doi.org/10.1016/j.ins.2020.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data centers for cloud computing must accommodate numerous parallel task executions simultaneously. Therefore, data centers have many virtual machines (VMs). Minimizing the scheduling length of parallel task sets becomes a critical requirement in cloud computing systems . In this study, we propose an efficient priority and relative distance (EPRD) algorithm to minimize the task scheduling length for precedence constrained workflow applications without violating the end-to-end deadline constraint. This algorithm consists of two processes. First, a task priority queue is established. Then, a VM is mapped for a task in accordance with its relative distance. The proposed method can effectively improve VM utilization and scheduling performance. Extensive rigorous experiments based on randomly generated and real-world workflow applications demonstrate that the resource reduction rate and scheduling length of the EPRD algorithm significantly surpass those of existing algorithms.},
  archive      = {J_ISCI},
  author       = {Longxin Zhang and Liqian Zhou and Ahmad Salah},
  doi          = {10.1016/j.ins.2020.04.039},
  journal      = {Information Sciences},
  pages        = {31-46},
  shortjournal = {Inf. Sci.},
  title        = {Efficient scientific workflow scheduling for deadline-constrained parallel tasks in cloud computing environments},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust graph-based semi-supervised sparse feature
selection method. <em>ISCI</em>, <em>531</em>, 13–30. (<a
href="https://doi.org/10.1016/j.ins.2020.03.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is used for excluding redundant features and enhancing learning performance. Abundant unlabeled data are existed in many applications which can be used in semi-supervised feature selection. Semi-supervised sparse feature selection methods have been presented to apply labeled and unlabeled data and consider the correlation among features. Most of the sparse methods utilize square-norm based loss function which is sensitive to outliers. In this paper, we propose a robust Graph-based Semi-Supervised Sparse Feature Selection (GS 3 FS) method based on the mixed convex and non-convex l 2,p -norm (0 &lt; p ≤ 1) minimization on regularization and loss function. The l 2,p -norm based regularization ensures that the method selects relevant and sparse features, and the l 2,p -norm based loss function makes the method robust to outliers. Proposed method takes the advantages of manifold learning and l 2,p -norm minimization on regularization and loss function. The method includes the mixed l 2,p -norm which is difficult to solve. To solve the proposed method for the convex ( p = 1) and non-convex (0 &lt; p &lt;1) cases, we propose an efficient unified algorithm and prove its convergence. Extensive experiments are carried out on various classification and regression datasets for evaluating the proposed method. The results indicate that the proposed method selects the relevant features and improves the performance of classification and regression models.},
  archive      = {J_ISCI},
  author       = {Razieh Sheikhpour and Mehdi Agha Sarram and Sajjad Gharaghani and Mohammad Ali Zare Chahooki},
  doi          = {10.1016/j.ins.2020.03.094},
  journal      = {Information Sciences},
  pages        = {13-30},
  shortjournal = {Inf. Sci.},
  title        = {A robust graph-based semi-supervised sparse feature selection method},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An asymmetric knowledge representation learning in manifold
space. <em>ISCI</em>, <em>531</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2020.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge graph is constructed to acquire a large amount of structured knowledge that can be read by computers. To effectively complete the knowledge graph, embedding representation models that encode entities and relations in real number tensor space are proposed, such as the TransE model and its extension models, namely, the flexible translation model (FT), dynamic translation model (DT) and manifold-based representation model (OrbitE). These above baselines are proposed to alleviate the problem of inaccurate triple representation in complex relations and have achieved good results. However, with the improvement of the effect, the number of parameters increases. Therefore, an asymmetric knowledge representation learning model in manifold space (MAKR) is proposed in this paper. The position of the golden triple is expanded to the manifold based on the OrbitE model. Then, the embedded representations of the head and tail entities are separately weighted by the corresponding different embedded relations, which are the same manifold space in the same triples instead of the same points. The MAKR alleviates the asymmetry and imbalance of relations and the unsatisfactory precise prediction. Moreover, the time and space complexities of the proposed MAKR are low. Finally, the effectiveness of the MAKR is verified by four datasets: FB15K, WN18, FB13 and WN11. Compared to other baselines, the MAKR has achieved better performance in both triple classification and link prediction tasks.},
  archive      = {J_ISCI},
  author       = {Yongming Han and Guofei Chen and Zhongkun Li and Zhiqiang Geng and Fang Li and Bo Ma},
  doi          = {10.1016/j.ins.2020.04.036},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {An asymmetric knowledge representation learning in manifold space},
  volume       = {531},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fingerprint image enhancement and reconstruction using the
orientation and phase reconstruction. <em>ISCI</em>, <em>530</em>,
201–218. (<a href="https://doi.org/10.1016/j.ins.2020.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fingerprints are the one of the most important means in the forensics as a means of identification of the criminals owning to the uniqueness and the distinct features in them. Fingerprint identification is considered as an important means for the identification of the people around the globe. Minutiae are the details present in the human fingerprints which are used as a means of identification and verification. Minutiae are the distinctive points which can be used for the effective reconstruction of the fingerprint image . However, there was a limitation that was considered. The minutiae points are completely not enough for reconstruction of the image. Many spurious minutiae are not included and the results for the latent fingerprints are not as accurate as they are for the normal data sets. In this paper, a novel technique has been proposed which considers the minutiae density and the orientation field direction for the reconstruction of the fingerprint. Two public domain databases Fingerprint verification competition 2002 (FVC2002) and fingerprint verification competition 2004 (FVC2004) have been used for the experimental results and to validate the suggested methods for the fingerprint reconstruction and enhancement.},
  archive      = {J_ISCI},
  author       = {Rashmi Gupta and Manju Khari and Deepti Gupta and Rubén González Crespo},
  doi          = {10.1016/j.ins.2020.01.031},
  journal      = {Information Sciences},
  pages        = {201-218},
  shortjournal = {Inf. Sci.},
  title        = {Fingerprint image enhancement and reconstruction using the orientation and phase reconstruction},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General framework for consistencies in decision contexts.
<em>ISCI</em>, <em>530</em>, 180–200. (<a
href="https://doi.org/10.1016/j.ins.2020.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a general framework which provides a unified approach to attribute reduction in decision contexts across various generalizations of Formal Concept Analysis. The framework is demonstrated on an attribute reduction method which has been studied multiple times separately for each of the generalizations. Specifically, we use the framework to elevate the discernibility matrix based method to a more general setting.},
  archive      = {J_ISCI},
  author       = {Radek Janostik and Jan Konecny},
  doi          = {10.1016/j.ins.2020.02.045},
  journal      = {Information Sciences},
  pages        = {180-200},
  shortjournal = {Inf. Sci.},
  title        = {General framework for consistencies in decision contexts},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PAN: Pipeline assisted neural networks model for
data-to-text generation in social internet of things. <em>ISCI</em>,
<em>530</em>, 167–179. (<a
href="https://doi.org/10.1016/j.ins.2020.03.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Internet of Things (SIoT) is an emerging paradigm connecting the Internet of things and social networks, enabling the social functions expanded into human-to-thing or inter-thing. There is an urgent issue of how to realize the social contact for communications between human and things or between things. This requires the natural language generation (NLG), focusing on generating text in human languages from non-linguistic data, which is of vital importance to achieve the interaction without barriers between human and other smart objects in SIoT. However, the existing solutions for data-to-text transformation rely on the specific template and standard neural networks models, which are not flexible when applying to the cross-domain data with diverse meaning. In this paper, we propose a novel model, called pipeline assisted neural networks (PAN), which integrates the traditional pipeline modules and neural generation systems, to conduct data-to-text generation tasks in SIoT. Our new PAN model makes use of attention module and gate mechanism to complete content selection, by analyzing records correlation and filtering redundant records. Then, a dedicated neural network is developed for salient span selection, pointing and transition to achieve content planning. In the end, we conduct experiments on the ROTOWIRE dataset to evaluate the performance of PAN. The results demonstrate that our proposed PAN model outperforms the existing solutions.},
  archive      = {J_ISCI},
  author       = {Nan Jiang and Jing Chen and Ri-Gui Zhou and Changxing Wu and Honglong Chen and Jiaqi Zheng and Tao Wan},
  doi          = {10.1016/j.ins.2020.03.080},
  journal      = {Information Sciences},
  pages        = {167-179},
  shortjournal = {Inf. Sci.},
  title        = {PAN: Pipeline assisted neural networks model for data-to-text generation in social internet of things},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information fusion on the two-layer network for robust
estimation of multiple geometric structures. <em>ISCI</em>,
<em>530</em>, 148–166. (<a
href="https://doi.org/10.1016/j.ins.2020.03.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel and effective model fitting method to estimate multiple geometric structures on a two-layer network, where vertices in the first layer denote model hypotheses and vertices in the second layer denote data points. Instead of only considering the consensus information on model hypotheses or the preference information on data points, we combine these two kinds of information into a two-layer network. Based on this formulation, we first distinguish vertices with the quantities of information they contain in both layers by using an information theoretic algorithm. We then fuse the retained model hypotheses in the first layer together with the generated hypotheses from the retained data points in the second layer. Finally, the proposed method, namely Information Fusion on Two-Layer Network (IFTLN), detects model instances from the fused model hypotheses vertices according to three key elements ( i.e. , the local maximum value of weighting score, the distance between vertices, and the local density). Overall, IFTLN can not only automatically and simultaneously estimate the number and parameters of model instances with a large number of outliers, but also effectively handle significantly unbalanced distribution of data points among model instances. Comprehensive experiments are performed on both synthetic data and real images, and superior performances are achieved by the proposed method in comparison with some state-of-the-art model fitting methods.},
  archive      = {J_ISCI},
  author       = {Qiming Li and Xiaodong Lan and Jun Li},
  doi          = {10.1016/j.ins.2020.03.106},
  journal      = {Information Sciences},
  pages        = {148-166},
  shortjournal = {Inf. Sci.},
  title        = {Information fusion on the two-layer network for robust estimation of multiple geometric structures},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). An enhanced multi-objective evolutionary optimization
algorithm with inverse model. <em>ISCI</em>, <em>530</em>, 128–147. (<a
href="https://doi.org/10.1016/j.ins.2020.03.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithm based on the inverse model (IM-MOEA) is a popular method to solve multi-objective optimization problems (MOPs). However, IM-MOEA has some drawbacks such as low accuracy and difficulty in dealing with MOPs with irregular PFs. To address these issues, adaptive reference vector mechanism and nonrandom grouping strategy are employed in IM-MOEA, which enhances the reliability of the inverse model . In addition, a modified selection mechanism is used to choose candidate solutions. Further, an enhanced IM-MOEA with adaptive reference vectors and nonrandom grouping (AN-IMMOEA) is proposed in this paper. The experimental results on 27 MOPs indicate that the proposed method has a better performance than other MOEAs.},
  archive      = {J_ISCI},
  author       = {Zhechen Zhang and Sanyang Liu and Weifeng Gao and Jingwei Xu and Shengqi Zhu},
  doi          = {10.1016/j.ins.2020.03.111},
  journal      = {Information Sciences},
  pages        = {128-147},
  shortjournal = {Inf. Sci.},
  title        = {An enhanced multi-objective evolutionary optimization algorithm with inverse model},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic maintenance of rough approximations in multi-source
hybrid information systems. <em>ISCI</em>, <em>530</em>, 108–127. (<a
href="https://doi.org/10.1016/j.ins.2020.03.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-life applications, the data collected from different information sources are always located in diverse sites and characterized by different types of attributes. In this paper, we call this type of data as multi-source hybrid data. Existed rough set models only work well with single source data or multi-source data with one type of attributes, which are not suitable for processing multi-source hybrid data. Furthermore, in dynamic data environment, multi-source hybrid data are typically evolving over time, including the addition of objects and attributes and the revision of missing values in each information source. It will result in the update of information granulation and rough approximation structures. To address these issues, we present an extended rough set model, named as multi-source composite rough sets (MCRS), by integrating different types of attributes and fusing multiple composite relations derived from different information sources. Two novel matrix operators are proposed to construct the matrix-based representation of rough approximations. Then, under the variations of objectives, attributes and attribute values in the multi-source hybrid information system, we present incremental mechanisms based on matrices for the maintenance of approximations by utilizing the previously accumulated matrices information and transmitting location information of part elements in each composite relation matrix. In addition, we develop the incremental algorithms for updating composite rough approximations. A series of comparative experiments show that the proposed algorithm outperforms the static algorithm and other extended incremental algorithms in terms of the efficiency of computation and transmission.},
  archive      = {J_ISCI},
  author       = {Yanyong Huang and Tianrui Li and Chuan Luo and Hamido Fujita and Shi-jinn Horng and Bin Wang},
  doi          = {10.1016/j.ins.2020.03.097},
  journal      = {Information Sciences},
  pages        = {108-127},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic maintenance of rough approximations in multi-source hybrid information systems},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing incremental deep learning for FCCU end-point
quality prediction. <em>ISCI</em>, <em>530</em>, 95–107. (<a
href="https://doi.org/10.1016/j.ins.2020.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the refining process, Fluid Catalytic Cracking Unit (FCCU) end-point quality prediction plays an important role in real-time quality monitoring, optimization and control. Due to the process uncertainties (such as changes of raw materials, abrasion of mechanic components, catalyst deactivation , changes in the external environment, etc), data distribution of process data in FCCU is time-varying, which leads to accuracy degradation of the quality prediction model. Therefore, to deal with the time varying characteristic of process data and avoid accuracy degradation of the quality prediction model, real-time processing should be considered. In this paper, an enhancing incremental deep learning approach is proposed for the online quality prediction of the absorption-stabilization system in FCCU. First, the offline model is built by Stacked Auto Encoder-Deep Neural Network (SAE-DNN). To determine whether the data distribution has changed and model modification is needed, a concept drift detector is proposed for the regression problem by defining an error bound in the Statistical Test of Equal Proportions (STEPD). If the model modification is needed, then the top layer of the offline SAE-DNN model is expanded by Random Vector Functional Link (RVFL) structure, and the parameters in the expansion layer is dynamically assigned by the new coming data with the group lasso regularization and the L2 regularization . The proposed approach is validated by predicting the Saturated Vapor Pressure (SVP) of stabilized gasoline in the FCCU. The experimental results show that the proposed approach can deal with the time-varying characteristic of process data and avoid accuracy degradation under process uncertainties.},
  archive      = {J_ISCI},
  author       = {Xu Zhang and Yuanyuan Zou and Shaoyuan Li},
  doi          = {10.1016/j.ins.2020.04.013},
  journal      = {Information Sciences},
  pages        = {95-107},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing incremental deep learning for FCCU end-point quality prediction},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incentive compatible and anti-compounding of wealth in
proof-of-stake. <em>ISCI</em>, <em>530</em>, 85–94. (<a
href="https://doi.org/10.1016/j.ins.2020.03.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric reward function is proposed as an alternative choice to circumvent the problem of compounding. However, it’s not so desirable since no parties have incentives to participate in the consensus mechanism . In this paper, we tailor a new bonus reward function by adding random salts to the geometric reward function. The new reward function is a tradeoff between equitablity and incentive compatibility. We conclude that the quitability of the new reward function is optimal compared with others. Beyond that, we present Gini coefficients to fine-evaluate euqitability of reward functions. We propose a new metric (aka. reward ratio) to quantify the level of incentive compatibility. Our simulation results show that the new reward function performs better than others in both incentive compatibility and anti-compounding.},
  archive      = {J_ISCI},
  author       = {Yilei Wang and Guoyu Yang and Andrea Bracciali and Ho-fung Leung and Haibo Tian and Lishan Ke and Xiaomei Yu},
  doi          = {10.1016/j.ins.2020.03.098},
  journal      = {Information Sciences},
  pages        = {85-94},
  shortjournal = {Inf. Sci.},
  title        = {Incentive compatible and anti-compounding of wealth in proof-of-stake},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making based on acceptable consistency
analysis of interval linguistic hesitant fuzzy preference relations.
<em>ISCI</em>, <em>530</em>, 66–84. (<a
href="https://doi.org/10.1016/j.ins.2020.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To represent decision makers’ qualitative uncertainty and hesitation judgments, interval linguistic hesitant fuzzy variables (ILHFVs) are efficient tools, which can be regarded as an expansion of interval linguistic variables (ILVs). Taking the merits of ILHFVs and preference relations, this paper focuses on group decision making (GDM) with interval linguistic hesitant fuzzy preference relations (ILHFPRs). By considering the consistency of ILHFPRs, a new definition of acceptable consistency is presented. Using the acceptable consistency index, some models are built to measure whether a given ILHFPR is acceptable consistent. If the consistency is unacceptable, some models are constructed to derive acceptable consistent ILHFPRs by considering the total adjustment and the number of adjusting ILVs. In order to cope with incomplete ILHFPRs, some models for obtaining the values of unknown ILVs are proposed. For GDM with ILHFPRs, an index for measuring the consensus degree of ILHFPRs is proposed. When ILHFPRs do not meet the requirement of the consensus, some models for enhancing the consensus degree are proposed. According to the analysis of acceptable additive consistency and consensus of ILHFPRs, a new method for GDM with ILHFPRs is proposed. In order to show the merits of the proposed GDM method , an application example is used.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen and Shaolin Zhang},
  doi          = {10.1016/j.ins.2020.03.070},
  journal      = {Information Sciences},
  pages        = {66-84},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on acceptable consistency analysis of interval linguistic hesitant fuzzy preference relations},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel linguistic approach for multi-granular information
fusion and decision-making using risk-based linguistic d numbers.
<em>ISCI</em>, <em>530</em>, 43–65. (<a
href="https://doi.org/10.1016/j.ins.2020.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The D numbers methodology is a new mathematical approach that has been developed to improve some constraints surrounding evidence theory by managing information uncertainty and incompleteness. Various studies have been conducted on developing D numbers. One of the main extensions of the D numbers methodology is linguistic D numbers, which employs linguistic terms as a set of evaluations of D numbers. In this study, linguistic D numbers are further extended to an interval-valued belief structure. Additionally, to consider the various risk scenarios of each linguistic D number, a risk-based linguistic D numbers model is presented, based on proposed interval-valued linguistic D numbers. The efficiency of the proposed model is investigated by applying it to numerical examples and considering a case study. The results show the robustness of the risk-based linguistic D numbers methodology while simultaneously applying various risk scenarios.},
  archive      = {J_ISCI},
  author       = {Hamidreza Seiti and Ashkan Hafezalkotob and Enrique Herrera-Viedma},
  doi          = {10.1016/j.ins.2020.04.006},
  journal      = {Information Sciences},
  pages        = {43-65},
  shortjournal = {Inf. Sci.},
  title        = {A novel linguistic approach for multi-granular information fusion and decision-making using risk-based linguistic d numbers},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach to generate pattern-efficient sets of
non-dominated vectors for multi-objective optimization. <em>ISCI</em>,
<em>530</em>, 22–42. (<a
href="https://doi.org/10.1016/j.ins.2020.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pareto optimality is the fundamental construct employed to determine whether a given solution to a multi-criteria mathematical optimization model is preferred to another solution. In this paper we describe an approach (Pattern Efficient Set Algorithm – PESA) to generating a pattern-efficient set of non-dominated vectors to a multi-objective optimization problem . Our approach incorporates an optimization model designed to yield certain non-dominated vectors that can fill gaps between already generated non-dominated vectors, providing a way to deal with the adjacency of generated non-dominated vectors and to quantify the gaps between them. We also propose a pseudo-randomized variant of PESA (rPESA) that randomly generates hypothetical bounds for the objective functions and uses them in the optimization model. To test our approach we selected ten problems from the literature, including bi-objective, 3-objective, 5-objective and 10-objective test instances with non-convex, disconnected or continuous Pareto. The inverted generational distance (IGD) and the hyper-volume (HV) are used as performance metrics to measure the quality of the obtained approximations . We also present graphically the numerical results from applying our method.},
  archive      = {J_ISCI},
  author       = {Bogdana Stanojević and Fred Glover},
  doi          = {10.1016/j.ins.2020.04.040},
  journal      = {Information Sciences},
  pages        = {22-42},
  shortjournal = {Inf. Sci.},
  title        = {A new approach to generate pattern-efficient sets of non-dominated vectors for multi-objective optimization},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting approximate dictionary-based entity extraction with
synonyms. <em>ISCI</em>, <em>530</em>, 1–21. (<a
href="https://doi.org/10.1016/j.ins.2020.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary-based entity extraction is an important task in many data analysis applications, such as academic search, document classification , and code auto-debugging. To improve the effectiveness of extraction, many previous studies focused on the problem of approximate dictionary-based entity extraction, which aims at finding all substrings in documents that are similar to pre-defined entities in the reference entity dictionary. However, these studies only consider syntactical similarity metrics, such as Jaccard and edit distance. In real-world scenarios, there are many cases where syntactically different strings can express the same meaning. Existing approximate entity extraction work fails to identify such kind of semantic similarity and will definitely suffer from low recall. In this paper, we come up with the new problem of an approximate dictionary-based entity extraction with synonyms and propose an end-to-end framework Aeetes to solve it. We propose a new similarity measure Asymmetric Rule-based Jaccard ( JaccAR ) to combine the synonym rules with syntactic similarity metrics and capture the semantic similarity expressed in the synonyms. We devise and implement a filter-and-verification based strategy to improve the overall efficiency. To this end, we propose several pruning techniques to reduce the filter cost and develop novel strategies to improve verification performance. Experimental results on three real-world datasets demonstrate the superior effectiveness and efficiency of Aeetes .},
  archive      = {J_ISCI},
  author       = {Jin Wang and Chunbin Lin and Mingda Li and Carlo Zaniolo},
  doi          = {10.1016/j.ins.2020.04.025},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {Boosting approximate dictionary-based entity extraction with synonyms},
  volume       = {530},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evidential integrated method for maintaining case base
and vocabulary containers within CBR systems. <em>ISCI</em>,
<em>529</em>, 214–229. (<a
href="https://doi.org/10.1016/j.ins.2019.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cases and vocabulary maintenance presents a crucial task to preserve high competent Case-Based Reasoning (CBR) systems, since the accuracy of their offered solutions are strongly dependent on stored cases and their describing attributes quality. The maintenance aims generally at eliminating two types of undesirable knowledge which are noisy and redundant data. However, inexpedient Case Base Maintenance (CBM) or vocabulary maintenance may not only greatly decrease CBR competence in solving new problems, but also reduce its performance in term of retrieval time. Besides, to provide a high maintenance quality, it is necessary to manage uncertainty within knowledge since “real-world data are never perfect” and stored cases within a CBR system’s Case Base (CB) describe real-world experiences. Hence, we propose, in this paper, a new integrated method that maintains both of the CB and the vocabulary knowledge containers of CBR systems by offering a new alternating technique to properly detect noisiness and redundancy whether in cases or features. During the learning steps of our new integrated maintenance policy, which drives the decision making about cases and attributes selection, we manage uncertainty using one among the most powerful tools called the Belief Function Theory.},
  archive      = {J_ISCI},
  author       = {Safa Ben Ayed and Zied Elouedi and Eric Lefevre},
  doi          = {10.1016/j.ins.2019.11.009},
  journal      = {Information Sciences},
  pages        = {214-229},
  shortjournal = {Inf. Sci.},
  title        = {An evidential integrated method for maintaining case base and vocabulary containers within CBR systems},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-state deterioration prediction for infrastructure
asset: Learning from uncertain data, knowledge and similar groups.
<em>ISCI</em>, <em>529</em>, 197–213. (<a
href="https://doi.org/10.1016/j.ins.2019.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrastructure assets such as bridges need to be inspected regularly for signs of deterioration. Although a fixed inspection interval could be used, an estimate of the rate of deterioration allows us to schedule the next inspection more cost-effectively. Our earlier work outlined a Bayesian framework that uses both data and knowledge to predict the transition between assets, which has been extended and realised in this paper for asset deterioration prediction. In the Bayesian model , censorship is modelled to incorporate the uncertainty from inspection records and prior of the parameter is used to express expert knowledge. In particular, we also suggest how the prior probabilities of the parameters of a Weibull distribution can be set in practice using expert estimates such as the maximum and average times of a transition from one state to another. Furthermore, assets with similar characteristics may deteriorate similarly. We propose to separate related assets into groups and learn deterioration between these groups. This assumption allows us to tackle the challenge of limited data further and is experimented with the deck inspection records from the National Bridge Inventory database in Wyoming. This database includes over 100 features of each bridge such as structure type and average daily traffic : we use a modified random forest to select a subset of important features to separate assets into groups. The model is extended into hierarchical Bayesian models to learn between groups with the help of hyper-parameters and an aggregated variable from the feature levels. Performance of our method is compared with other existing approaches from various aspects.},
  archive      = {J_ISCI},
  author       = {Haoyuan Zhang and D. William R. Marsh},
  doi          = {10.1016/j.ins.2019.11.017},
  journal      = {Information Sciences},
  pages        = {197-213},
  shortjournal = {Inf. Sci.},
  title        = {Multi-state deterioration prediction for infrastructure asset: Learning from uncertain data, knowledge and similar groups},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multipopulation cooperative particle swarm optimization with
a mixed mutation strategy. <em>ISCI</em>, <em>529</em>, 179–196. (<a
href="https://doi.org/10.1016/j.ins.2020.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional particle swarm optimization algorithm learns from the two best experiences: the best position previously learned by the particle itself and the best position learned by the entire population to date. This learning strategy is simple and ordinary, but when addressing high-dimensional optimization problems , it is unable to quickly find the global optimal solution due to its low efficiency. This paper proposes a multipopulation cooperative particle swarm optimization (MPCPSO) algorithm with a dynamic segment-based mean learning strategy and a multidimensional comprehensive learning strategy. In MPCPSO, the dynamic segment-based mean learning strategy (DSMLS), which is employed to construct learning exemplars, achieves information sharing and coevolution between populations. The multidimensional comprehensive learning strategy (MDCLS) is employed to speed up convergence and improve the accuracy of MPCPSO solutions. Additionally, a differential mutation operator is introduced to increase the population diversity and enhance the global exploration ability of MPCPSO. Sixteen benchmark functions and seven well-known PSO variants are employed to verify the advantages of MPCPSO. The comparison results indicate that MPCPSO has a faster convergence speed, obtains more accurate solutions, and is more robust.},
  archive      = {J_ISCI},
  author       = {Wei Li and Xiang Meng and Ying Huang and Zhang-Hua Fu},
  doi          = {10.1016/j.ins.2020.02.034},
  journal      = {Information Sciences},
  pages        = {179-196},
  shortjournal = {Inf. Sci.},
  title        = {Multipopulation cooperative particle swarm optimization with a mixed mutation strategy},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RepeatPadding: Balancing words and sentence length for
language comprehension in visual question answering. <em>ISCI</em>,
<em>529</em>, 166–178. (<a
href="https://doi.org/10.1016/j.ins.2020.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA) is a complicated Turing-AI task which needs not only to understand the multi-modality inputs but also reason to provide correct answer. Nowadays, there are complicated and sophisticated modules for reasoning in popular works. However, the language representation which is frequently treated as the guider of VQA hasn’t been fully explored in current researches, leading to insufficient reasoning and unsatisfactory answer. In this work, two types of method including VieAns and RepeatPadding which focus on language processing are proposed to balance the sentence by cropping and padding the question, where the language information is transformed to different expressions and further pushes the language model to grab more representative features for further boosting the accuracy of predicted answers. Experiments on the benchmark COCO-QA and VQA2.0 datasets are conducted to demonstrate the effectiveness of the proposed method. Particularly, the proposed RepeatPadding method is more suitable for different language models.},
  archive      = {J_ISCI},
  author       = {Yu Long and Pengjie Tang and Zhihua Wei and Jinjing Gu and Hanli Wang},
  doi          = {10.1016/j.ins.2020.04.034},
  journal      = {Information Sciences},
  pages        = {166-178},
  shortjournal = {Inf. Sci.},
  title        = {RepeatPadding: Balancing words and sentence length for language comprehension in visual question answering},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Experiential knowledge representation and reasoning based on
linguistic petri nets with application to aluminum electrolysis cell
condition identification. <em>ISCI</em>, <em>529</em>, 141–165. (<a
href="https://doi.org/10.1016/j.ins.2020.03.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy Petri nets (FPNs) play an important role in knowledge representation and reasoning (KRR), and they have been widely used in many fields. Linguistic terms are usually used to express the experiential knowledge of decision-makers in the above fields. However, cognitive nonconformity, fuzziness and uncertainty of experiential knowledge are widespread in industrial production processes, making it difficult for current FPNs to precisely model the experience or cognition of experts. In an effort to overcome the shortcomings of FPNs, linguistic Petri nets (LPNs) are proposed based on interval type-2 fuzzy sets theory and FPNs in this paper. The extended TOPSIS (ETOPSIS) is proposed to fuse together the cognition of multiple decision-makers. An interval type-2 fuzzy ordered weighted averaging operator is proposed to improve the knowledge reasoning capability of LPNs. Two comparisons are presented to demonstrate the validity of the proposed ETOPSIS and LPNs. In addition, the KRR model for aluminum electrolysis cell condition identification (AECCI) is proposed and AECCI results show the proposed methods are efficient to embrace cognitive nonconformity and manage fuzziness and uncertainty of experiential knowledge.},
  archive      = {J_ISCI},
  author       = {Weichao Yue and Weihua Gui and Yongfang Xie},
  doi          = {10.1016/j.ins.2020.03.079},
  journal      = {Information Sciences},
  pages        = {141-165},
  shortjournal = {Inf. Sci.},
  title        = {Experiential knowledge representation and reasoning based on linguistic petri nets with application to aluminum electrolysis cell condition identification},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure extended wildcard pattern matching protocol from
cut-and-choose oblivious transfer. <em>ISCI</em>, <em>529</em>, 132–140.
(<a href="https://doi.org/10.1016/j.ins.2020.03.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure two-party pattern matching involves two parties, where a server owns the long text and a client has the pattern. The goal is for the client to learn the positions in which his pattern appears in the text, while leaking nothing to the server. In secure wildcard pattern matching (WPM), wildcards that can match any character arbitrarily are allowed in the pattern of the client. In this study, we first propose an extended variant of the standard WPM functionality, which we termed extended wildcard pattern matching (EWPM). The EWPM functionality allows the client to acquire the entire set of substrings that match his pattern, rather than the corresponding locations. We constructed a secure protocol of the EWPM functionality using cut-and-choose oblivious transfer (CCOT) in a semi-honest model. The efficiency of the proposed protocol approximates that of the state-of-the-art scheme. Furthermore, we implemented our protocol to demonstrate its actual practicality. The experimental result shows that when the pattern length is 2 10 and the text length is less than 2 20 , the total execution time is less than 2 s.},
  archive      = {J_ISCI},
  author       = {Xiaochao Wei and Lin Xu and Minghao Zhao and Hao Wang},
  doi          = {10.1016/j.ins.2020.03.087},
  journal      = {Information Sciences},
  pages        = {132-140},
  shortjournal = {Inf. Sci.},
  title        = {Secure extended wildcard pattern matching protocol from cut-and-choose oblivious transfer},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new dynamic strategy for dynamic multi-objective
optimization. <em>ISCI</em>, <em>529</em>, 116–131. (<a
href="https://doi.org/10.1016/j.ins.2020.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After detecting the change of the environment, it is effective to respond to the change of the environment. However, the majorities of these methods only respond to the change of the environment once, ignoring the use of new more environment information. In this paper, we propose a new algorithm for dynamic multi-objective optimization by combining the evolutionary algorithm and the dynamic strategy. The dynamic strategy consists of two parts which correspond to two responses to the environmental change: restart strategy (RS) and adjustment strategy (AS). RS is to use a small amount of the new environment information and local search to re-initialize the population which is expected to be close to the Pareto solutions in the new environment after the environment change. RS is beneficial for quickly responding to environment changes. AS is to adjust the current population with high quality solutions after getting more accurate environmental information. RS is expected to accelerate the convergence speed of the algorithm. The proposed algorithm is tested on a variety of test instances with different changing dynamics. Experimental results show that the proposed algorithm is very competitive for dynamic multi-objective optimization in comparison with state of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yan Wu and Lulu Shi and Xiaoxiong Liu},
  doi          = {10.1016/j.ins.2020.04.011},
  journal      = {Information Sciences},
  pages        = {116-131},
  shortjournal = {Inf. Sci.},
  title        = {A new dynamic strategy for dynamic multi-objective optimization},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ostrowski-type inequalities for fuzzy-valued functions and
its applications in quadrature theory. <em>ISCI</em>, <em>529</em>,
101–115. (<a href="https://doi.org/10.1016/j.ins.2020.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a new characterization of the switching points for generalized Hukuhara differentiable fuzzy-valued functions. New results on generalized Hukuhara differential and integral calculus for fuzzy-valued functions are developed.Also some Ostrowski-type inequalities for fuzzy-valued functions are obtained, with which is formulated a new quadrature rules to deal with integral of fuzzy-valued functions and show that our results are better than previous ones. Moreover, numerical examples are provided in order to illustrate the applicability of the mathematical tools developed herein.},
  archive      = {J_ISCI},
  author       = {T.M. Costa and A. Flores-Franulič and Y. Chalco-Cano and I. Aguirre-Cipe},
  doi          = {10.1016/j.ins.2020.04.037},
  journal      = {Information Sciences},
  pages        = {101-115},
  shortjournal = {Inf. Sci.},
  title        = {Ostrowski-type inequalities for fuzzy-valued functions and its applications in quadrature theory},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). State-based fault diagnosis of discrete-event systems with
partially observable outputs. <em>ISCI</em>, <em>529</em>, 87–100. (<a
href="https://doi.org/10.1016/j.ins.2020.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a state-based method for solving the problems of diagnosis and diagnosability of discrete-event systems (DES) with partially observable outputs, due to the lack or limitations of sensors. The diagnoser used for diagnosis consists of two parts: a state estimator and a failure decision-maker. The state estimator makes the state estimation of a system based on the observed output sequence and transfers the estimation to the failure decision-maker that determines whether a fault occurs or not. Moreover, the state or condition (failure status) of the system is not required to be known when launching the diagnoser; thus the system and the diagnoser do not have to be initialized simultaneously, i.e., the diagnoser may be initialized at any moment while the system is operational. Under the premise that the outputs of a system are partially observable, the notion of diagnosability is given and an efficient algorithm for verification of diagnosability is designed with the polynomial computational complexity with respect to the number of system states. Finally, the proposed algorithm is applied to a pump-valve-controller system.},
  archive      = {J_ISCI},
  author       = {Deguang Wang and Xi Wang and Zhiwu Li},
  doi          = {10.1016/j.ins.2020.04.027},
  journal      = {Information Sciences},
  pages        = {87-100},
  shortjournal = {Inf. Sci.},
  title        = {State-based fault diagnosis of discrete-event systems with partially observable outputs},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control with prescribed performance tracking for input
quantized nonlinear systems using self-scrambling gain feedback.
<em>ISCI</em>, <em>529</em>, 73–86. (<a
href="https://doi.org/10.1016/j.ins.2020.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of control with prescribed performance tracking for a class of nonlinear systems in the presence of quantized input. A novel state feedback control scheme by self-scrambling gain is proposed, with the first merit that it is computationally inexpensive, since no linearly-parameterized approximators are used, and the second merit that it is self-adjustable with respect to different levels of tracking errors. Based on a smoothly transformed error variables, the output and virtual tracking errors are guaranteed to converge to some predefined arbitrarily small residual sets regardless of transient and steady bounds. The closed-loop system is proved by rigorously mathematical derivation to be globally stable, and two comparative illustrative examples are given to demonstrate the advantages and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Shigen Gao and Chen Wu and Hairong Dong and Bin Ning},
  doi          = {10.1016/j.ins.2020.04.010},
  journal      = {Information Sciences},
  pages        = {73-86},
  shortjournal = {Inf. Sci.},
  title        = {Control with prescribed performance tracking for input quantized nonlinear systems using self-scrambling gain feedback},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A future intelligent traffic system with mixed autonomous
vehicles and human-driven vehicles. <em>ISCI</em>, <em>529</em>, 59–72.
(<a href="https://doi.org/10.1016/j.ins.2020.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) being an essential component of the future smart city traffic system is a hot topic in recent years, even though it is still in its development stage. It is conceivable that in the near future, AVs and human-driven vehicles (HVs) will have to co-exist in traffic systems. This is the first paper to study a mixed traffic system from a micro perspective based on the cellular automation model. In this system, by the use of sensors or mutual information exchange, each AV will have a ‘foresight’ and will be able to know the speeds and positions of vehicles in front of it. In the circular road scenario, we studied how the traffic capacity is influenced by the degree of foresight, the ratio of AVs to HVs, vehicle density, and the probability of random deceleration of HVs. Then we came up with the below conclusions: (a) The optimal foresight is k = 5 k=5 . An AV only needs to gather the information of the 5 vehicles in front of it. (b) The two critical factors to measure the capacity of a traffic network are the critical vehicle density and the maximum average flow. When the ratio of AVs to HVs is increased, these two critical factors increase at an accelerating rate. (c) Even if a low ratio of HVs is running in the system, it will have an appreciable negative impact. An increased probability of random deceleration can expand the hysteresis loop range and reduce average flow. (d) Within a specific range of vehicle density, there is an optimal ratio of AVs at which the traffic system has the maximum average flow. This has implications in controlling the ratio of AVs. Finally, theoretical solutions of critical vehicle density are obtained by using the mean-field theory in physics. If the vehicle density is larger than these critical values, the traffic system will be in a deadlock state, and all vehicles cannot move. These formulas are crucial to controlling the density and the ratio of AVs and HVs in future intelligent traffic systems and will help to avoid large-scale traffic congestion. The above findings will have practical ramifications for precise traffic management and traffic control in a mixed AV and HVs system.},
  archive      = {J_ISCI},
  author       = {Bokui Chen and Duo Sun and Jun Zhou and Wengfai Wong and Zhongjun Ding},
  doi          = {10.1016/j.ins.2020.02.009},
  journal      = {Information Sciences},
  pages        = {59-72},
  shortjournal = {Inf. Sci.},
  title        = {A future intelligent traffic system with mixed autonomous vehicles and human-driven vehicles},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Full state constrained stochastic adaptive integrated
guidance and control for STT missiles with non-affine aerodynamic
characteristics. <em>ISCI</em>, <em>529</em>, 42–58. (<a
href="https://doi.org/10.1016/j.ins.2020.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering a class of skid-to-turn (STT) missiles with stochastic disturbances, non-affine aerodynamic characteristics and full state constraints, a novel full state constrained stochastic adaptive integrated guidance and control (IGC) scheme is proposed in this paper. By introducing several four-order Barrier Lyapunov functions (BLFs), the required state constraints of the stochastic closed-loop system are guaranteed to be never violated. With the aid of mean value theorem and neural network approximation , the non-affine aerodynamic characteristics can be handled. Moreover, by using several hyperbolic tangent functions and estimating the upper bounds of the uncertainties, the adverse effects caused by stochastic disturbances and unknown target maneuvers can be eliminated. The stochastic stability of the closed-loop system is proven based on Lyapunov theory . Numerical simulations results show the effectiveness and the advantages of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Kang Chen},
  doi          = {10.1016/j.ins.2020.03.061},
  journal      = {Information Sciences},
  pages        = {42-58},
  shortjournal = {Inf. Sci.},
  title        = {Full state constrained stochastic adaptive integrated guidance and control for STT missiles with non-affine aerodynamic characteristics},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Infrared and visible image fusion using dual discriminators
generative adversarial networks with wasserstein distance.
<em>ISCI</em>, <em>529</em>, 28–41. (<a
href="https://doi.org/10.1016/j.ins.2020.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial network (GAN) has shown great potential in infrared and visible image fusion. The existing GAN-based methods establish an adversarial game between generative image and source images to train the generator until the generative image contains enough meaningful information from source images. However, they only design one discriminator to force the fused result to complement gradient information from visible image, which may lose some detail information that existing in infrared image and omit some texture information that existing in visible image. To this end, we propose an end-to-end dual discriminators Wasserstein generative adversarial network, termed as D2WGAN, a framework that extends GAN to dual discriminators. In D2WGAN, the fused image can keep pixel intensity and details of infrared image by the first discriminator , and capture rich texture information of visible image by the second discriminator. In addition, to improve the performance of D2WGAN, we employ the GAN with Wasserstein distance. Moreover, in order to make the fused image keep more details from visible image in texture feature domain, we define a novel LBP (local binary pattern) loss. The extensive qualitative and quantitative experiments on public datasets demonstrate that D2WGAN can generate better results compared with the other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jing Li and Hongtao Huo and Kejian Liu and Chang Li},
  doi          = {10.1016/j.ins.2020.04.035},
  journal      = {Information Sciences},
  pages        = {28-41},
  shortjournal = {Inf. Sci.},
  title        = {Infrared and visible image fusion using dual discriminators generative adversarial networks with wasserstein distance},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient approach of recent high utility stream pattern
mining with indexed list structure and pruning strategy considering
arrival times of transactions. <em>ISCI</em>, <em>529</em>, 1–27. (<a
href="https://doi.org/10.1016/j.ins.2020.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of various pattern mining techniques, the High Utility Pattern Mining (HUPM) is a method for finding meaningful patterns from non-binary databases by considering the characteristics of the items. Recently, new data continues to flow over time in diverse fields such as sales data of market, heartbeat sensor data, and social network service . Since these data have a feature that recently generated data have higher influence than the old data, research has been focused on how to efficiently extract hidden knowledge from time-sensitive databases. In this paper, we propose indexed list-based algorithm that mines recent high utility pattern considering the arrival time of inserted data in an environment where new data is continuously accumulated. In other words, to treat the importance of recent data higher than the that of old data, our algorithms reduces the utility values of old transactions according to the time the data is inserted by applying damped window model concept. Moreover, we carry out various experiments to compare our method with state-of-the-art algorithms using real and synthetic datasets in diverse circumstances. Experimental results show that our algorithm outperforms competitors in terms of execution time, memory usage, and scalability test.},
  archive      = {J_ISCI},
  author       = {Hyoju Nam and Unil Yun and Eunchul Yoon and Jerry Chun- Wei Lin},
  doi          = {10.1016/j.ins.2020.03.030},
  journal      = {Information Sciences},
  pages        = {1-27},
  shortjournal = {Inf. Sci.},
  title        = {Efficient approach of recent high utility stream pattern mining with indexed list structure and pruning strategy considering arrival times of transactions},
  volume       = {529},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Verification of c-detectability using petri nets.
<em>ISCI</em>, <em>528</em>, 294–310. (<a
href="https://doi.org/10.1016/j.ins.2020.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detectability describes the property of a system to uniquely determine, after a finite number of observations, the current and the subsequent states . In this paper, we extend detectability to C-detectability that only requires that a given set of crucial states can be distinguished from other states. We define four types of C-detectability in the framework of labeled Petri nets : strong C-detectability, weak C-detectability, periodically strong C-detectability, and periodically weak C-detectability. Moreover, we propose efficient approaches to verify such properties in the case of bounded labeled Petri net systems. The proposed approaches use the notion of basis marking and thus do not require an exhaustive enumeration of the reachability space.},
  archive      = {J_ISCI},
  author       = {Hao Lan and Yin Tong and Jin Guo and Carla Seatzu},
  doi          = {10.1016/j.ins.2020.04.024},
  journal      = {Information Sciences},
  pages        = {294-310},
  shortjournal = {Inf. Sci.},
  title        = {Verification of C-detectability using petri nets},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recurrent neural variational model for follower-based
influence maximization. <em>ISCI</em>, <em>528</em>, 280–293. (<a
href="https://doi.org/10.1016/j.ins.2020.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization, aiming at selecting a small set of seed users in a social network to maximize the spread of influence, has attracted considerable attention recently. Most of the existing influence maximization algorithms focus on the diffusion model of one single-entity, which assumes that only one entity is propagated by users in social network. However, the diffusion situations in real world social networks often involve multiple entities, competitive or complementary, spreading through the whole network, and are more complex than the situations of single independent entity. In this paper, we propose a novel optimization problem , namely, the follower-based influence maximization, which aims to promote a new product into the market by maximizing the influence of a social network where other competitive and complementary products have already been propagating. We tackle this problem by proposing a Recurrent Neural Variational model (RNV) and a follower-based greedy algorithm (RNVGA). The RNV model dynamically tracks entity correlations and cascade correlations through a deep generative model and recurrent neural variational inference, while the RNVGA algorithm applies the greedy approach for submodular maximization and efficiently computes the seed node set for the target product. Extensive experiments have been conducted to evaluate effectiveness and efficiency of our method, and the results show the superiority of our method compared with the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Huimin Huang and Zaiqiao Meng and Shangsong Liang},
  doi          = {10.1016/j.ins.2020.04.023},
  journal      = {Information Sciences},
  pages        = {280-293},
  shortjournal = {Inf. Sci.},
  title        = {Recurrent neural variational model for follower-based influence maximization},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Co-regularized nonnegative matrix factorization for evolving
community detection in dynamic networks. <em>ISCI</em>, <em>528</em>,
265–279. (<a href="https://doi.org/10.1016/j.ins.2020.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in static networks solely emphasizes the clustering accuracy, while evolving community detection in dynamic networks simultaneously takes into account both the clustering accuracy and clustering drift. The available evolutionary clustering algorithms are criticized for failing to fully characterize dynamics of networks and to accurately balance the clustering accuracy and clustering drift. To solve these problems, we propose a co-regularized evolutionary nonnegative matrix factorization for evolving communities in dynamic networks ( Cr-ENMF ). Specifically, both the network and communities at the previous time step are utilized to characterize the clustering drift, which are incorporated into the objective function of Cr-ENMF by regularization . We show that the well-known temporal smoothness framework for evolutionary clustering is a special case of the proposed framework, and prove the equivalence between Cr-ENMF and evolutionary clustering. Thereafter, an iterative strategy is presented to optimize the objective function. The experimental results over both artificial and real world dynamic networks illustrate that Cr-ENMF outperforms state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Xiaoke Ma and Benhui Zhang and Changzhou Ma and Zhiyu Ma},
  doi          = {10.1016/j.ins.2020.04.031},
  journal      = {Information Sciences},
  pages        = {265-279},
  shortjournal = {Inf. Sci.},
  title        = {Co-regularized nonnegative matrix factorization for evolving community detection in dynamic networks},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimation of the parameters of a weighted nuclear norm
model and its application in image denoising. <em>ISCI</em>,
<em>528</em>, 246–264. (<a
href="https://doi.org/10.1016/j.ins.2020.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a method for optimizing a weighted nuclear norm model is proposed. This model optimization solution employs a soft-thresholding operation on the singular values of an observation matrix . To determine the soft-thresholding, we focused on the unique properties of a class of special matrices, termed rank-order similar matrices (ROSMs). The threshold determination problem was solved during training by exploiting these properties. In addition, we applied this optimization method to image denoising . In this application, the denoising does not work on the whole image at once, but rather relies on a set of ROSMs. Each matrix in the set is an ROSM, built by stacking non-local similar patch vectors. This optimization method is applied to every ROSM in the set to obtain estimates of the underlying patches, which are aggregated to reconstruct a restored image. Simulation results of 154 noisy images indicate that the proposed optimization method achieves the same peak signal to noise ratio/mean structural similarity index measure results as those achieved by several other state-of-the-art methods such as block-matching and 3D filtering and weighted nuclear norm minimization. It also outperforms many state-of-the-art methods such as nuclear norm minimization, in terms of the visual quality of images.},
  archive      = {J_ISCI},
  author       = {Hongyao Deng and Jinsong Tao and Xiuli Song and Chunyuan Zhang},
  doi          = {10.1016/j.ins.2020.04.028},
  journal      = {Information Sciences},
  pages        = {246-264},
  shortjournal = {Inf. Sci.},
  title        = {Estimation of the parameters of a weighted nuclear norm model and its application in image denoising},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time adaptive tracking control for unknown nonlinear
systems with a novel barrier lyapunov function. <em>ISCI</em>,
<em>528</em>, 231–245. (<a
href="https://doi.org/10.1016/j.ins.2020.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the issue of adaptive finite-time tracking control for uncertain strict-feedback nonlinear systems with full state constraints. For the first time, a new finite-time adjustable barrier function is introduced, whose design parameters can be regulated dynamically in real time with the change of tracking error. It cannot only converge to a preset region in a finite settling time with a faster convergent barrier, but it further optimizes the system transient performance. By embedding the proposed barrier function, a novel barrier Lyapunov function (BLF) is used for the design of an adaptive finite-time tracking controller, which guarantees that the output tracking error converges to a small region in finite time without violation of the constraint, and then tends to zero. All of the signals in the closed-loop system are bounded. A simulation verifies the effectiveness of the proposed control scheme.},
  archive      = {J_ISCI},
  author       = {Cungen Liu and Xiaoping Liu and Huanqing Wang and Yucheng Zhou and Shouyin Lu},
  doi          = {10.1016/j.ins.2020.04.029},
  journal      = {Information Sciences},
  pages        = {231-245},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time adaptive tracking control for unknown nonlinear systems with a novel barrier lyapunov function},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Noise-based synchronization of bounded confidence opinion
dynamics in heterogeneous time-varying communication networks.
<em>ISCI</em>, <em>528</em>, 219–230. (<a
href="https://doi.org/10.1016/j.ins.2020.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental question that arises in the analysis of the noise-based synchronization of opinion dynamics with bounded confidence (BC) is what opinion structures can be synchronized by noise. In the standard Hegselmann-Krause (HK) model, each agent examines the opinion values of all other agents and then selects neighbors who are appropriate for opinion updating in accordance with the BC scheme. In reality, however, people are more likely to exchange opinions with only a limited set of individuals, resulting in a predetermined local communication network as postulated in the DeGroot model. In this paper, we develop a new model of opinion formation that endows the heterogeneous HK dynamics with a time-varying communication topology, and we investigate its noise-induced synchronization both mathematically and numerically. We show that opinion dynamics in this model are noise-synchronizable if and only if the switching communication graph is uniformly jointly connected. Our rigorous mathematical analysis and simulation experiments demonstrate that connected discourse topology in combination with fair amounts of noise can lead to a quasi-consensus that is inducible from any initial state or any underlying system size. Our findings have profound implications for the design of future strategies of social control and global opinion optimization.},
  archive      = {J_ISCI},
  author       = {Wei Su and Xueqiao Wang and Ge Chen and Yongguang Yu and Tarik Hadzibeganovic},
  doi          = {10.1016/j.ins.2020.04.018},
  journal      = {Information Sciences},
  pages        = {219-230},
  shortjournal = {Inf. Sci.},
  title        = {Noise-based synchronization of bounded confidence opinion dynamics in heterogeneous time-varying communication networks},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blind quality assessment for image superresolution using
deep two-stream convolutional networks. <em>ISCI</em>, <em>528</em>,
205–218. (<a href="https://doi.org/10.1016/j.ins.2020.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous image superresolution (SR) algorithms have been proposed for reconstructing high-resolution (HR) images from input images with lower spatial resolutions. However, effectively evaluating the perceptual quality of SR images remains a challenging research problem. In this paper, we propose a no-reference/blind deep neural network-based SR image quality assessor (DeepSRQ). To learn more discriminative feature representations of various distorted SR images, the proposed DeepSRQ is a two-stream convolutional network including two subcomponents for distorted structure and texture SR images. Different from traditional image distortions, the artifacts of SR images cause both image structure and texture quality degradation. Therefore, we choose the two-stream scheme that captures different properties of SR inputs instead of directly learning features from one image stream. Considering the human visual system (HVS) characteristics, the structure stream focuses on extracting features in structural degradations, while the texture stream focuses on the change in textural distributions. In addition, to augment the training data and ensure the category balance, we propose a stride-based adaptive cropping approach for further improvement. Experimental results on three publicly available SR image quality databases demonstrate the effectiveness and generalization ability of our proposed DeepSRQ method compared with state-of-the-art image quality assessment algorithms.},
  archive      = {J_ISCI},
  author       = {Wei Zhou and Qiuping Jiang and Yuwang Wang and Zhibo Chen and Weiping Li},
  doi          = {10.1016/j.ins.2020.04.030},
  journal      = {Information Sciences},
  pages        = {205-218},
  shortjournal = {Inf. Sci.},
  title        = {Blind quality assessment for image superresolution using deep two-stream convolutional networks},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relationships between fuzzy approximation spaces and their
uncertainty measures. <em>ISCI</em>, <em>528</em>, 181–204. (<a
href="https://doi.org/10.1016/j.ins.2020.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy approximation spaces ( FA -spaces) can be seen as approximation spaces ( A -spaces) in a fuzzy environment. This article studies relationships between FA -spaces and their uncertainty measures. Dependence, partial dependence and independence between FA -spaces, as characterized by the inclusion degree, are first proposed. Then, the distance between FA -spaces is considered in terms of the angle of difference. Next, algebraic, map and lattice features of FA -spaces are obtained. Finally, the uncertainty of FA -spaces is measured by using the dependence between them, an application is given, and to assess the performance of the presented measures, two examples are used to perform effectiveness analysis by means of elementary statistical methods.},
  archive      = {J_ISCI},
  author       = {Guangji Yu},
  doi          = {10.1016/j.ins.2020.04.008},
  journal      = {Information Sciences},
  pages        = {181-204},
  shortjournal = {Inf. Sci.},
  title        = {Relationships between fuzzy approximation spaces and their uncertainty measures},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Oblivious DFA evaluation on joint input and its
applications. <em>ISCI</em>, <em>528</em>, 168–180. (<a
href="https://doi.org/10.1016/j.ins.2020.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Oblivious deterministic finite automata (DFA) evaluation is a powerful two-party primitive that has been widely used in cryptographic protocols . It enables two mutually distrusted participants to obliviously evaluate a DFA (provided by one party) on an input string (provided by the other party), while preserving the privacy of each party from the other one. However, this primitive is not flexible and powerful enough, in the sense that it only supports evaluation on input string that is provided by one participant . In this paper, we propose oblivious DFA evaluation on joint input (denoted as F ODFA JI FODFAJI ), a variant that extends the functionality of traditional oblivious DFA evaluation protocols. The new primitive enables two participants to collaboratively evaluate a DFA on a joint input , where the input is a combination of two input strings provided by both of the participants. To enable modularized instantiation, we first propose and instantiate F OT JC FOTJC – oblivious transfer with joint choice – a functionality as modified oblivious transfer (OT), and then provide an efficient instantiation for F ODFA JI FODFAJI in F OT JC FOTJC -hybrid model. Security proof demonstrates that the proposed protocol is secure under semi-honest model, and theoretical performance analysis shows that it achieves satisfactory efficiency and scalability. F ODFA JI FODFAJI is a basic as well as an important building block for high-level secure outsourced computing tasks. In this paper, we use secure outsourced pattern matching as a case study and show how it can be applied to construct such high-level protocols.},
  archive      = {J_ISCI},
  author       = {Chuan Zhao and Shengnan Zhao and Bo Zhang and Shan Jing and Zhenxiang Chen and Minghao Zhao},
  doi          = {10.1016/j.ins.2020.03.065},
  journal      = {Information Sciences},
  pages        = {168-180},
  shortjournal = {Inf. Sci.},
  title        = {Oblivious DFA evaluation on joint input and its applications},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial example generation with adaptive gradient search
for single and ensemble deep neural network. <em>ISCI</em>,
<em>528</em>, 147–167. (<a
href="https://doi.org/10.1016/j.ins.2020.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have achieved remarkable success in specific domains, such as computer vision , audio processing , and natural language processing . However, researches indicate that deep neural networks are facing many security issues (e.g., adversarial attack , information forgery). In the field of image classification , adversarial samples generated by specific adversarial attack strategies can easily fool deep neural classification models into making unreliable predictions. We find that such adversarial attack algorithms induce large-scale pixel modifications in crafted images to maintain the effectiveness of the adversarial attack. Massive pixel modifications change the inherent characteristics of generated examples and cause large image distortion. To address the mentioned issues, we introduce an adaptive gradient-based adversarial attack method named Adaptive Iteration Fast Gradient Method (AI-FGM), which focuses on seeking the input’s preceding gradient and adjusts the accumulation of perturbed entity adaptively for performing adversarial attacks. By maximizing the specific loss for generating adaptive gradient-based entities, AI-FGM calls for several gradient-based operators on the clean input to map crafted sample with the corresponding prediction directly. AI-FGM helps to reduce unnecessary gradient-based entity accumulation when processing adversary by adaptive gradient-based seeking strategy. Experimental results show that AI-FGM outperforms other gradient-based adversarial attackers in attacking deep neural classification models with fewer pixel modifications (AMP is 0.0017 with L 2 norm in fooling Inception-v3) and higher success rate of invasion on deep neural classification networks in white-box and black-box attack strategy on public image datasets with different resolution.},
  archive      = {J_ISCI},
  author       = {Yatie Xiao and Chi-Man Pun and Bo Liu},
  doi          = {10.1016/j.ins.2020.04.022},
  journal      = {Information Sciences},
  pages        = {147-167},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial example generation with adaptive gradient search for single and ensemble deep neural network},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rank-constrained nonnegative matrix factorization for data
representation. <em>ISCI</em>, <em>528</em>, 133–146. (<a
href="https://doi.org/10.1016/j.ins.2020.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based regularized nonnegative matrix factorization (NMF) methods performed well in many real-world applications. However, it is still an open problem to construct an optimal graph to effectively discover the intrinsic geometric structure of data. In this paper, we propose a new data representation framework, called rank-constrained nonnegative matrix factorization (RCNMF). We impose the rank constraint on the Laplacian matrix of the learned graph, so it can ensure that the number of connected components is consistent with the number of sample categories. Instead of a fixed graph-based regularization , the proposed framework can adaptively adjust the weight of the affinity matrix in each iteration. We develop two versions of RCNMF based on the l 1 and l 2 norms, and introduce their optimization schemes. In addition, their convergence and the complexity analyses are also provided. Experimental results on four benchmark datasets show that our methods outperform state-of-the-art methods in clustering.},
  archive      = {J_ISCI},
  author       = {Zhenqiu Shu and Xiao-Jun Wu and Congzhe You and Zhen Liu and Peng Li and Honghui Fan and Feiyue Ye},
  doi          = {10.1016/j.ins.2020.04.017},
  journal      = {Information Sciences},
  pages        = {133-146},
  shortjournal = {Inf. Sci.},
  title        = {Rank-constrained nonnegative matrix factorization for data representation},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A semantic facial expression intensity descriptor based on
information granules. <em>ISCI</em>, <em>528</em>, 113–132. (<a
href="https://doi.org/10.1016/j.ins.2020.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a granular description for facial expression intensity in which characterization of motion-based expression features is presented by a collection of information granules. First, the motion-based features are extracted based on the facial landmarks to encode the expression intensity. Secondly, the semantic concepts are then generated by involving various mechanisms of fuzzy clustering based on the motion-based features. The resulting clusters can be viewed as numeric prototypes of the descriptors. The information granules are formed around the prototypes according to the principle of justifiable granularity , which is the fundamental idea of Granular Computing . The proposed granular descriptor for expression intensity is tested on the BU-3DFE database, and the experimental results illustrate that the proposed descriptors based on information granules not only can characterize the semantics of facial changes caused by expressions, but also can facilitate the semantic estimation of facial expression intensity.},
  archive      = {J_ISCI},
  author       = {Mingliang Xue and Xiaodong Duan and Wanquan Liu and Yan Ren},
  doi          = {10.1016/j.ins.2020.04.012},
  journal      = {Information Sciences},
  pages        = {113-132},
  shortjournal = {Inf. Sci.},
  title        = {A semantic facial expression intensity descriptor based on information granules},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of topical subpopulations on social media.
<em>ISCI</em>, <em>528</em>, 92–112. (<a
href="https://doi.org/10.1016/j.ins.2020.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle a major challenge of information filtering on social media (SM): rather than address the general question “what are people talking about on SM?”, we consider a finer question, “what are ... talking about on SM?”, where ... stands for some subpopulation of SM users of interest. We take a set expansion approach, where a seed of example members of the target subpopulation is initially defined, and additional SM users who belong to that subpopulation are identified, thus enabling the effective tracking of relevant information that pertains to that subpopulation on SM. Specifically, the Personalized PageRank (PPR) random walk measure is iteratively applied to detect additional members of the subpopulation based on their structural similarity to the seed set within the social media graph. There are several main contributions of this work. We outline Splash PPR , an efficient distributed computation of PPR adapted for potentially large seed sets and very large SM graphs. Using Splash PPR, we examine and tune graph representations towards the retrieval of two subpopulations from Twitter, namely human rights Activists, and Machine Learning practitioners. We believe this work is first to introduce and evaluate a generic framework for subpopulation identification at scale.},
  archive      = {J_ISCI},
  author       = {Ido Dangur and Ron Bekkerman and Einat Minkov},
  doi          = {10.1016/j.ins.2020.04.005},
  journal      = {Information Sciences},
  pages        = {92-112},
  shortjournal = {Inf. Sci.},
  title        = {Identification of topical subpopulations on social media},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crowd counting by using multi-level density-based spatial
information: A multi-scale CNN framework. <em>ISCI</em>, <em>528</em>,
79–91. (<a href="https://doi.org/10.1016/j.ins.2020.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting is an extremely challenging task due to occlusions, scale variations of people’s heads, and non-uniform distributions of people. In this paper, we propose a scale-aware convolutional neural network (CNN), named MMNet, to generate density maps for crowd counting. In comparison with most extant scale-aware works, the proposed MMNet not only captures multi-scale features generated by various sizes of filters, but also integrates multi-scale features generated by different stages to handle scale variations of people’s heads. Considering that crowd density distribution information contains critical information with respect to people’s head sizes, multi-level density-based spatial information is employed to supervise the fusion of multi-scale features in our proposed network. Specifically, two kinds of effective spatial distribution prior representation are introduced by using estimated density maps generated from intermediate stages for integrating two kinds of multi-scale features, respectively. Experimental results demonstrate the effectiveness of our proposed MMNet in comparison to state-of-the-art methods on four benchmark datasets and a real-world application.},
  archive      = {J_ISCI},
  author       = {Li Dong and Haijun Zhang and Yuzhu Ji and Yuxin Ding},
  doi          = {10.1016/j.ins.2020.04.001},
  journal      = {Information Sciences},
  pages        = {79-91},
  shortjournal = {Inf. Sci.},
  title        = {Crowd counting by using multi-level density-based spatial information: A multi-scale CNN framework},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal process mining of timed event logs. <em>ISCI</em>,
<em>528</em>, 58–78. (<a
href="https://doi.org/10.1016/j.ins.2020.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of determining the optimal process model of an event log of traces of events with temporal information is presented. A formal description of the event log and relevant complexity measures are detailed. Then the process model and its replayability score that measures model fitness with respect to the event log are defined. Two process models are formulated, taking into account temporal information. The first, called grid process model, is reminiscent of Petri net unfolding and is a graph with multiple layers of labeled nodes and arcs connecting lower to upper layer nodes. Our second model is an extension of the first. Denoted the time grid process model, it associates a time interval to each arc. Subsequently, a Tabu search algorithm is constructed to determine the optimal process model that maximizes the replayability score subject to the constraints of the maximal number of nodes and arcs. Numerical experiments are conducted to assess the performance of the proposed Tabu search algorithm . Lastly, a healthcare case study was conducted to demonstrate the applicability of our approach for clinical pathway modeling. Special attention was paid on readability, so that final users could interpret the process mining results.},
  archive      = {J_ISCI},
  author       = {Hugo De Oliveira and Vincent Augusto and Baptiste Jouaneton and Ludovic Lamarsalle and Martin Prodel and Xiaolan Xie},
  doi          = {10.1016/j.ins.2020.04.020},
  journal      = {Information Sciences},
  pages        = {58-78},
  shortjournal = {Inf. Sci.},
  title        = {Optimal process mining of timed event logs},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Blind quality assessment for tone-mapped images based on
local and global features. <em>ISCI</em>, <em>528</em>, 46–57. (<a
href="https://doi.org/10.1016/j.ins.2020.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to show high dynamic range (HDR) images by traditional displays, various tone-mapping operators have been designed to convert HDR images into low dynamic range (LDR) images recently. However, how to estimate the visual quality of LDR images effectively is still challenging. In this paper, we propose a novel blind quality assessment method for tone-mapped images with the consideration of naturalness and the perceptual characteristics of human visual system (HVS). First, we design parametric models that describe characteristics of chromatic information in tone-mapped images and extract quality-aware features based on global statistics model to characterize the naturalness of tone-mapped images. Second, motivated by perceptual characteristics that the HVS is highly adaptive to the image texture, we employ local texture features to capture the quality degradation of tone-mapped images. Support vector regression (SVR) is used to train the quality prediction model from features to human ratings. Experimental results indicate that the proposed metric can get better performance in predicting the visual quality of tone-mapped images than the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xuelin Liu and Yuming Fang and Rengang Du and Yifan Zuo and Wenying Wen},
  doi          = {10.1016/j.ins.2020.03.067},
  journal      = {Information Sciences},
  pages        = {46-57},
  shortjournal = {Inf. Sci.},
  title        = {Blind quality assessment for tone-mapped images based on local and global features},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calibrated model-based evidential clustering using
bootstrapping. <em>ISCI</em>, <em>528</em>, 17–45. (<a
href="https://doi.org/10.1016/j.ins.2020.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidential clustering is an approach to clustering in which cluster-membership uncertainty is represented by a collection of Dempster-Shafer mass functions forming an evidential partition. In this paper, we propose to construct these mass functions by bootstrapping finite mixture models . In the first step, we compute bootstrap percentile confidence intervals for all pairwise probabilities (the probabilities for any two objects to belong to the same class). We then construct an evidential partition such that the pairwise belief and plausibility degrees approximate the bounds of the confidence intervals. This evidential partition is calibrated, in the sense that the pairwise belief-plausibility intervals contain the true probabilities “most of the time”, i.e., with a probability close to the defined confidence level. This frequentist property is verified by simulation, and the practical applicability of the method is demonstrated using several real datasets.},
  archive      = {J_ISCI},
  author       = {Thierry Denœux},
  doi          = {10.1016/j.ins.2020.04.014},
  journal      = {Information Sciences},
  pages        = {17-45},
  shortjournal = {Inf. Sci.},
  title        = {Calibrated model-based evidential clustering using bootstrapping},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An incentive mechanism design for mobile crowdsensing with
demand uncertainties. <em>ISCI</em>, <em>528</em>, 1–16. (<a
href="https://doi.org/10.1016/j.ins.2020.03.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) has shown great potential in addressing large-scale data sensing problem by allocating sensing tasks to pervasive mobile users (MU). The MUs will participate in the MCS if they can receive sufficient compensation. Existing work has designed lots of incentive mechanisms for MCS, but ignores the MUs’ resource demand uncertainties that is critical for resource-constrained mobile devices . In this paper, we propose to design an incentive mechanism for MCS by taking the MUs’ own resource demand into the economic model. As different MUs will have different behavior, they will participate in the MCS with different levels. Based on this idea, we formulate the incentive mechanism by using the Stackelberg game theory. Furthermore, a dynamic incentive mechanism (DIM) based on deep reinforcement learning (DRL) approach is investigated without knowing the private information of the MUs. It enables the SP to learn the optimal pricing strategy directly from game experience. Finally, numerical simulations are implemented to evaluate the performance and theoretical properties of the proposed mechanism and approach.},
  archive      = {J_ISCI},
  author       = {Yufeng Zhan and Yuanqing Xia and Jiang Zhang and Ting Li and Yu Wang},
  doi          = {10.1016/j.ins.2020.03.109},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {An incentive mechanism design for mobile crowdsensing with demand uncertainties},
  volume       = {528},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preserving adjustable path privacy for task acquisition in
mobile crowdsensing systems. <em>ISCI</em>, <em>527</em>, 602–619. (<a
href="https://doi.org/10.1016/j.ins.2018.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Crowdsensing is an emerging and promising sensing paradigm in which sensor data can be collected by mobile users equipped with smart devices. In Mobile Crowdsensing Systems (MCS), workers bid for location-based sensing tasks and get rewards from the platform. However, the bidding may leak workers’ path privacy, which means the sensitive locations could be inferred from innocent locations along a path as workers continuously acquire for tasks. This privacy concern may significantly hinder the participation of workers. As a result, this paper designs a novel framework for adjustable path privacy preservation used for task acquisition in MCS. In this framework, workers are allowed to flexibly adjust their privacy preferences on the amount, sensitivity, and cost of private locations. Two algorithms are proposed to determine the set of bidding tasks for workers that jointly consider the privacy concerns and profits. The first algorithm processes in a centralized approach, which is proved to be rational, truthful and efficient. The second algorithm allows workers to decide their task acquisition locally, and guarantees the Nash equilibrium among workers. Both algorithms are validated via real-world dataset. The evaluation results demonstrate that the two proposed algorithms outperform baseline algorithms on both platform and worker sides.},
  archive      = {J_ISCI},
  author       = {Guangchun Luo and Ke Yan and Xu Zheng and Ling Tian and Zhipeng Cai},
  doi          = {10.1016/j.ins.2018.12.013},
  journal      = {Information Sciences},
  pages        = {602-619},
  shortjournal = {Inf. Sci.},
  title        = {Preserving adjustable path privacy for task acquisition in mobile crowdsensing systems},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain-based system for secure outsourcing of bilinear
pairings. <em>ISCI</em>, <em>527</em>, 590–601. (<a
href="https://doi.org/10.1016/j.ins.2018.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure computation outsourcing in Internet of Things (IoT) system is an ongoing research challenge, partly due to the resource-constrained nature of most (inexpensive) IoT devices. In this paper, we focus on the secure outsourcing of bilinear pairings ( SOBP ) (the most computationally expensive operation in pairing-based cryptographic protocols / algorithms). First, we analyze the limitations in existing SOBP -based schemes, such as the one-malicious model ( Strong Assumption ), a secure channel ( Insufficiency ), and a trusted server ( Centralization ). Then, we propose a novel blockchain-based system for SOBP based on a permissioned version (i.e., a blockchain ledger maintained by some permissioned nodes), designed to efficiently address the limitations. Finally, we prove the security of our proposed approach in the one untrusted program model and implement it on Ethereum (an open-source blockchain system) to show its utility.},
  archive      = {J_ISCI},
  author       = {Chao Lin and Debiao He and Xinyi Huang and Xiang Xie and Kim-Kwang Raymond Choo},
  doi          = {10.1016/j.ins.2018.12.043},
  journal      = {Information Sciences},
  pages        = {590-601},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based system for secure outsourcing of bilinear pairings},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An insurance theory based optimal cyber-insurance contract
against moral hazard. <em>ISCI</em>, <em>527</em>, 576–589. (<a
href="https://doi.org/10.1016/j.ins.2018.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important method of risk control in information systems and networks, cyber-insurance has attracted particular attention from both industry and academia. However, two prominent problems hamper the further growth of cyber-insurance. The correlated and interdependent properties of cyber-risks increase the economic risk of insurance companies considerably ; risk pooling can be impeded by these two properties. Further, this situation can be aggravated because cyber-insurance affects the investment for self-protection negatively. This phenomenon is regarded as the ex ante moral hazard. In this study, we establish a mathematical model based on a classic insurance theory to address the abovementioned problems, and propose an optimal cyber-insurance contract scheme that maximizes the expected utility of users. We also propose two personalized contract schemes to incentivize users to invest in self-protection under the no moral hazard and ex ante moral hazard conditions. Extensive experiments are conducted to evaluate the proposed approach, and the experimental results demonstrate the effectiveness and efficiency of the approach.},
  archive      = {J_ISCI},
  author       = {Wanchun Dou and Wenda Tang and Xiaotong Wu and Lianyong Qi and Xiaolong Xu and Xuyun Zhang and Chunhua Hu},
  doi          = {10.1016/j.ins.2018.12.051},
  journal      = {Information Sciences},
  pages        = {576-589},
  shortjournal = {Inf. Sci.},
  title        = {An insurance theory based optimal cyber-insurance contract against moral hazard},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CAMPS: Efficient and privacy-preserving medical primary
diagnosis over outsourced cloud. <em>ISCI</em>, <em>527</em>, 560–575.
(<a href="https://doi.org/10.1016/j.ins.2018.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the flourishing of ubiquitous healthcare and cloud computing technologies, medical primary diagnosis system, which forms a critical capability to link big data analysis technologies with medical knowledge, has shown great potential in improving the quality of healthcare services . However, it still faces many severe challenges on both users’ medical privacy and intellectual property of healthcare service providers, which deters the wide adoption of medical primary diagnosis system. In this paper, we propose an effi c ient and priv a cy-preserving m edical p rimary diagno s is framework (CAMPS). Within CAMPS framework, the precise diagnosis models are outsourced to the cloud server in an encrypted manner, and users can access accurate medical primary diagnosis service timely without divulging their medical data. Specifically, based on partially decryption and secure comparison techniques, a special fast secure two-party vector dominance scheme over ciphertext is proposed, with which CAMPS achieves privacy preservation of user’s query and the diagnosis result, as well as the confidentiality of diagnosis models in the outsourced cloud server. Through extensive analysis, we show that CAMPS can ensure that users’ medical data and healthcare service provider’s diagnosis model are kept confidential, and has significantly reduce computation and communication overhead . In addition, performance evaluations via implementing CAMPS demonstrate its effectiveness in term of the real environment.},
  archive      = {J_ISCI},
  author       = {Jiafeng Hua and Guozhen Shi and Hui Zhu and Fengwei Wang and Ximeng Liu and Hao Li},
  doi          = {10.1016/j.ins.2018.12.054},
  journal      = {Information Sciences},
  pages        = {560-575},
  shortjournal = {Inf. Sci.},
  title        = {CAMPS: Efficient and privacy-preserving medical primary diagnosis over outsourced cloud},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Cloud-assisted privacy-conscious large-scale markowitz
portfolio. <em>ISCI</em>, <em>527</em>, 548–559. (<a
href="https://doi.org/10.1016/j.ins.2018.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of Markowitz portfolio has had enormous value and extensive applications in finance since it came into being. With the advent of the Big-Data era and the increasingly complicated financial market, the resource consumption of computing portfolio investments is significantly increasing. Cloud computing offers a good platform to efficiently compute large-scale portfolio investments, in particular, for resource-limited investors. In this paper, a Markowitz model (MM) is taken into consideration for outsourcing to a public cloud in a privacy-conscious way. As in general computation outsourcing, outsourcing MM inevitably faces four issues, namely, input/output privacy, correctness, verification, and substantial computation gain for investors; it has consistent complexity with the original methods when the cloud solves the encrypted version . However, the proposed cloud-assisted privacy-conscious MM employs location-scrambling and value-alteration encryption operations, which can protect the MM’s input/output privacy well. Moreover, the correctness of solving MM over an encrypted domain in the cloud side can be demonstrated and the results returned by the cloud can be verified. Furthermore, both theoretical and experimental analyses validate that the investor can obtain a huge amount of computational gain, and the cloud complexity consistent with that of the original case when solving the encrypted version .},
  archive      = {J_ISCI},
  author       = {Yushu Zhang and Jin Jiang and Yong Xiang and Ye Zhu and Liangtian Wan and Xiyuan Xie},
  doi          = {10.1016/j.ins.2018.12.055},
  journal      = {Information Sciences},
  pages        = {548-559},
  shortjournal = {Inf. Sci.},
  title        = {Cloud-assisted privacy-conscious large-scale markowitz portfolio},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PRTA: A proxy re-encryption based trusted authorization
scheme for nodes on CloudIoT. <em>ISCI</em>, <em>527</em>, 533–547. (<a
href="https://doi.org/10.1016/j.ins.2019.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In CloudIoT platform, the data is collected and shared by different nodes of Internet of Things (IoT), and data is processed and stored based on cloud servers. It has increased the abilities of IoT on information computation. Meanwhile, it also has enriched the resource in cloud and improved integration of the Internet and human world. All of this offer advantages as well as the new challenges of information security and privacy protection. As the energy limitation of the nodes in IoT, they are particularly vulnerable. It is much easier to hijack the nodes than to attack the data center for hackers. Thus, it is a crucial and urgent issue to realize the trusted update of authorization of nodes. When some nodes are hijacked, both of the behaviors to upload data to servers and to download information from servers should be forbidden. Otherwise, it might cause the serious damage to the sensitive data and privacy of servers. In order to solve this problem, we proposed a Proxy Re-encryption based Trusted Authorization scheme for nodes on CloudIoT (PRTA). PRTA is based on the proxy re-encryption (PRE), and the cloud server will play the roles of data storing and re-encrypting, which would reach the full potential of cloud computing and reduce the cost of nodes. The node’s status is taken as one of the parameters for data re-encryption and it is under the authorization servers’ control, which could ensure the security and reliability of the data and be beneficial for the privacy protection in CloudIoT. Also, the authorization servers are divided into the downloading and uploading kinds, which will make the application range much wider.},
  archive      = {J_ISCI},
  author       = {Mang Su and Bo Zhou and Anmin Fu and Yan Yu and Gongxuan Zhang},
  doi          = {10.1016/j.ins.2019.01.051},
  journal      = {Information Sciences},
  pages        = {533-547},
  shortjournal = {Inf. Sci.},
  title        = {PRTA: A proxy re-encryption based trusted authorization scheme for nodes on CloudIoT},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). APCN: A scalable architecture for balancing accountability
and privacy in large-scale content-based networks. <em>ISCI</em>,
<em>527</em>, 511–532. (<a
href="https://doi.org/10.1016/j.ins.2019.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing accountability and privacy has become extremely important in cyberspace, and the Internet has evolved to be dominated by content transmission. Several research efforts have been devoted to contributing to either accountability or privacy protection, but none of them has managed to consider both factors in content-based networks. An efficient solution is therefore urgently demanded by service and content providers. However, proposing such a solution is very challenging, because the following questions need to be considered simultaneously: (1) How can the conflict between privacy and accountability be avoided? (2) How is content identified and accountability performed based on packets belonging to that content? (3) How can the scalability issue be alleviated on massive content accountability in large-scale networks? To address these questions, we propose the first scalable architecture for balancing Accountability and Privacy in large-scale Content-based Networks (APCN). In particular, an innovative method for identifying content is proposed to effectively distinguish the content issued by different senders and from different flows, enabling the accountability of a content based on any of its packets. Furthermore, a new idea with double-delegate (i.e., source and local delegates) is proposed to improve the performance and alleviate the scalability issue on content accountability in large-scale networks. Extensive NS-3 experiments with real trace are conducted to validate the efficiency of the proposed APCN. The results demonstrate that APCN outperforms existing related solutions in terms of lower round-trip time and higher cache hit rate under different network configurations .},
  archive      = {J_ISCI},
  author       = {Yuxiang Ma and Yulei Wu and Jun Li and Jingguo Ge},
  doi          = {10.1016/j.ins.2019.01.054},
  journal      = {Information Sciences},
  pages        = {511-532},
  shortjournal = {Inf. Sci.},
  title        = {APCN: A scalable architecture for balancing accountability and privacy in large-scale content-based networks},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving cryptosystem for IoT e-healthcare.
<em>ISCI</em>, <em>527</em>, 493–510. (<a
href="https://doi.org/10.1016/j.ins.2019.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy preservation has become a prerequisite for modern applications in the cloud, social media, Internet of things (IoT), and E- healthcare systems. In general, health and medical data contain images and medical information about the patients and such personal data should be kept confidential in order to maintain the patients’ privacy. Due to limitations in digital data properties, traditional encryption schemes over textual and structural one-dimension data cannot be applied directly to e-health data. In addition, when personal data are sent over the open channels, patients may lose privacy of data contents. Hence, a secure lightweight keyframe extraction method is highly required to ensure timely, correct, and privacy-preserving e-health services. Besides this, it is inherently difficult to achieve a satisfied level of security in a cost-effective way while considering the constraints of real-time e-health applications. In this paper, we propose a privacy preserving chaos-based encryption cryptosystem for patients’ privacy protection. The proposed cryptosystem can protect patient’s images from a compromised broker. In particular, we propose a fast probabilistic cryptosystem to secure medical keyframes that are extracted from wireless capsule endoscopy procedure using a prioritization method. The encrypted images produced by our cryptosystem exhibits randomness behavior, which guarantee computational efficiency as well as a highest level of security for the keyframes against various attacks. Furthermore, it processes the medical data without leaking any information, thus preserving patient’s privacy by allowing only authorized users for decryption. The experimental results and security analysis from different perspectives verify the excellent performance of our encryption cryptosystem compared to other recent encryption schemes .},
  archive      = {J_ISCI},
  author       = {Rafik Hamza and Zheng Yan and Khan Muhammad and Paolo Bellavista and Faiza Titouna},
  doi          = {10.1016/j.ins.2019.01.070},
  journal      = {Information Sciences},
  pages        = {493-510},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving cryptosystem for IoT E-healthcare},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving task recommendation with win-win
incentives for mobile crowdsourcing. <em>ISCI</em>, <em>527</em>,
477–492. (<a href="https://doi.org/10.1016/j.ins.2019.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsourcing enables mobile requesters to publish tasks, which can be accomplished by workers with awards. However, existing task allocation schemes face tradeoff between effectiveness and privacy preservation , and most of them lack consideration of win-win incentives for both requesters and workers participation. In this paper, we propose a privacy-preserving task recommendation scheme with win-win incentives in crowdsourcing through developing advanced attribute-based encryption with preparation/online encryption and outsourced decryption technologies. Specifically, we design bipartite matching between published tasks and participant workers, to recommend tasks for eligible workers with interests and provide valuable task accomplishment for requesters in a win-win manner. Furthermore, our scheme reduces encryption cost for requesters by splitting encryption into preparation and online phases, as well as shifts most of the decryption overhead from the worker side to the service platform. Privacy analysis demonstrates requester and worker privacy preservation under chosen-keyword attack and chosen-plaintext attack. Performance evaluation shows cost-efficient computation overhead for requesters and workers.},
  archive      = {J_ISCI},
  author       = {Wenjuan Tang and Kuan Zhang and Ju Ren and Yaoxue Zhang and Xuemin (Sherman) Shen},
  doi          = {10.1016/j.ins.2019.02.011},
  journal      = {Information Sciences},
  pages        = {477-492},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving task recommendation with win-win incentives for mobile crowdsourcing},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). APS: Attribute-aware privacy-preserving scheme in
location-based services. <em>ISCI</em>, <em>527</em>, 460–476. (<a
href="https://doi.org/10.1016/j.ins.2019.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most significant factors for privacy protection, side information has been considered in designing privacy-preserving schemes in Location-Based Services (LBSs) over recent years. However, most existing schemes consider this concept through a straightforward way, such as query probability . In this paper, we consider the basic attribute associating with each location and design an Attribute-aware Privacy-preserving Scheme (APS) to enhance mobile user’s location privacy. Specifically, we first extract basic attributes from the local map, and specialize the Attribute-Aware Side Information (AASI). Then we build an attribute-based hierarchical tree (A-tree), which classifies locations into different categories in term of each location’s attribute. Based on such information, we design APS, which consists of two algorithms, Voronoi Dividing Algorithm (VDA) and Dummy Determining Algorithm (DDA). In VDA, we divide the local map into different Voronoi polygons based on the properties of Voronoi Diagram, which guarantees the selected locations are dispersed. In DDA, we utilize the Four Color Map Theorem to color these Voronoi polygons , which helps mobile users to choose the dummy locations as far as possible. Therefore, our APS provides an optimal dummy set to protect mobile user’s location privacy and query privacy. Finally, thorough analysis and evaluation results illustrate the effectiveness and efficiency of our proposed scheme.},
  archive      = {J_ISCI},
  author       = {Weihao Li and Chen Li and Yeli Geng},
  doi          = {10.1016/j.ins.2019.02.025},
  journal      = {Information Sciences},
  pages        = {460-476},
  shortjournal = {Inf. Sci.},
  title        = {APS: Attribute-aware privacy-preserving scheme in location-based services},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Exploiting location-related behaviors without the GPS data
on smartphones. <em>ISCI</em>, <em>527</em>, 444–459. (<a
href="https://doi.org/10.1016/j.ins.2019.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concerns about location privacy has received considerable attention with the development of Location-based Services (LBSs) over the recent years. Most smartphone users ignore the fact that Apps can infer their locations through accessing WiFi list, although they carefully set location-related permissions to preserve their privacy. Therefore, it is crucial to the public to investigate severe such consequence of WiFi list leakage. In this paper, we develop a tracking scheme for Android , called TrackU, which validate that it is possible to obtain user’s location data as well as their location-related behaviors, just by monitoring the WiFi list without any GPS data. Firstly, it periodically scans available Access Points (APs) nearby and queries the geo-location of the device from LBS providers. Secondly, a drift adjusting algorithm proposed obtains the exact locations considering a set of factors, such as historical location information, average signal strength and changing of WiFi list. To preserve the battery life, an optimization is made to dynamically adjust the positioning interval. Based on the obtained data, we design an activity detection algorithm precisely to infer users’ daily activities, and identify their travel modes, i.e., hovering, walking, and vehicles. Finally, we implement TrackU and carry out a series of experiments with 39 volunteers from seven cities of China. The experiment results show that our design can detect 91.6\% of activities by monitoring the WiFi list, and accurately recognize 94.6\% of user’s travel mode.},
  archive      = {J_ISCI},
  author       = {Fenghua Li and Xinyu Wang and Ben Niu and Hui Li and Chao Li and Lihua Chen},
  doi          = {10.1016/j.ins.2019.05.052},
  journal      = {Information Sciences},
  pages        = {444-459},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting location-related behaviors without the GPS data on smartphones},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient privacy preservation of big data for accurate data
mining. <em>ISCI</em>, <em>527</em>, 420–443. (<a
href="https://doi.org/10.1016/j.ins.2019.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing technologies pervade physical spaces and human lives, and produce a vast amount of data that is available for analysis. However, there is a growing concern that potentially sensitive data may become public if the collected data are not appropriately sanitized before being released for investigation. Although there are more than a few privacy-preserving methods available, they are not efficient, scalable, or have problems with data utility, or privacy. This paper addresses these issues by proposing an efficient and scalable nonreversible perturbation algorithm, PABIDOT , for privacy preservation of big data via optimal geometric transformations. PABIDOT was tested for efficiency, scalability, attack resistance, and accuracy using nine datasets and five classification algorithms . Experiments show that PABIDOT excels in execution speed, scalability, attack resistance, and accuracy in large-scale privacy-preserving data classification when compared with two other, related privacy-preserving algorithms.},
  archive      = {J_ISCI},
  author       = {M.A.P. Chamikara and P. Bertok and D. Liu and S. Camtepe and I. Khalil},
  doi          = {10.1016/j.ins.2019.05.053},
  journal      = {Information Sciences},
  pages        = {420-443},
  shortjournal = {Inf. Sci.},
  title        = {Efficient privacy preservation of big data for accurate data mining},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trajectory privacy-preserving scheme based on a dual-k
mechanism for continuous location-based services. <em>ISCI</em>,
<em>527</em>, 406–419. (<a
href="https://doi.org/10.1016/j.ins.2019.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-based services (LBSs) have increasingly provided by a broad range of devices and applications, but one associated risk is location disclosure. To solve this problem, a commonly method is to adopt K -anonymity in the centralized architecture based on a single trusted anonymizer. However, this strategy may compromise user privacy involving continuous LBSs. In this study, we propose a dual- K mechanism (DKM) to protect the users’ trajectory privacy for continuous LBSs. The proposed DKM method firstly inserted multiple anonymizers between the user and the location service provider (LSP), and K query locations are sent to different anonymizers to achieve K -anonymity. Simultaneously, we combined the dynamic pseudonym and the location selection mechanisms to improve user trajectory privacy. Hence, neither the LSP nor the anonymizer can obtain the user trajectory. Security analyses demonstrates that our proposed scheme can effectively enhance user trajectory privacy protection, and the simulation results prove that the DKM scheme can preserve user trajectory privacy with low overhead on a single anonymizer.},
  archive      = {J_ISCI},
  author       = {Shaobo Zhang and Xinjun Mao and Kim-Kwang Raymond Choo and Tao Peng and Guojun Wang},
  doi          = {10.1016/j.ins.2019.05.054},
  journal      = {Information Sciences},
  pages        = {406-419},
  shortjournal = {Inf. Sci.},
  title        = {A trajectory privacy-preserving scheme based on a dual-K mechanism for continuous location-based services},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Building a dynamic searchable encrypted medical database for
multi-client. <em>ISCI</em>, <em>527</em>, 394–405. (<a
href="https://doi.org/10.1016/j.ins.2019.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-medical record is an emerging health information exchange model based on cloud computing . As cloud computing allows companies and individuals to outsource their data and computation, the medical data is always stored at a third party such as cloud, which brings a variety of risks, such as data leakage to the untrusted cloud server, unauthorized access or modification operations. To assure the confidentiality of the data, the data owner needs to encrypt the sensitive data before uploading to the third party. Yet, issues like encrypted data search, flexible access and control on sensitive data have also remained the most significant challenges. In this paper, we investigate a novel searchable encrypted e-medical framework for multi-client which provides both confidentiality and searchability. Different from previous privacy protecting works in secure data outsourcing, we focus on providing a fine-grained access control encrypted data search scheme including clients and data. Our scheme also enables secure data update of the encrypted database by leveraging a secure dynamic searchable encryption. Furthermore, we implement the proposed scheme based on some existed cryptography library, and conduct several experiments on a selected dataset to evaluate its performance. The results demonstrate that our scheme provides a balance between security and efficiency.},
  archive      = {J_ISCI},
  author       = {Lei Xu and Chungen Xu and Joseph K. Liu and Cong Zuo and Peng Zhang},
  doi          = {10.1016/j.ins.2019.05.056},
  journal      = {Information Sciences},
  pages        = {394-405},
  shortjournal = {Inf. Sci.},
  title        = {Building a dynamic searchable encrypted medical database for multi-client},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving RFID authentication protocol based on
el-gamal cryptosystem for secure TMIS. <em>ISCI</em>, <em>527</em>,
382–393. (<a href="https://doi.org/10.1016/j.ins.2019.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The healthcare environment now provides the facility for patients to communicate with doctors from home via the Internet; this facility is very useful for seriously ill patients. Errors in medication are hazardous and can cause significant harm to patients; therefore, patient medication and information safety are essential issues in such a healthcare environment. To protect this sensitive information , an authentication protocol is needed. Moreover, in the context of sharing data including a patient&#39;s personal information, privacy leakage has become one of the most challenging issues in a telecare medicine information system (TMIS). In this paper, we propose a privacy-preserving radio frequency identification (RFID) authentication protocol based on the El-Gamal cryptosystem , for enhancing patient medication safety in a TMIS. The proposed protocol can achieve a number of security services and can also resist several types of attacks. We have also shown the results obtained by conducting an &quot;Automated Validation of Internet Security Protocols and Applications&quot; (AVISPA) simulation of our protocol. The simulation results verify that the proposed protocol is safe against active and passive attacks. The results of an informal security analysis also indicate that patient information is highly private, and the system is protected against possible related attacks. Our protocol is not only better in terms of protecting the privacy of patients but it also achieves better performance than similar existing protocols.},
  archive      = {J_ISCI},
  author       = {Fatty M. Salem and Ruhul Amin},
  doi          = {10.1016/j.ins.2019.07.029},
  journal      = {Information Sciences},
  pages        = {382-393},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving RFID authentication protocol based on el-gamal cryptosystem for secure TMIS},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incentive mechanism for cooperative authentication: An
evolutionary game approach. <em>ISCI</em>, <em>527</em>, 369–381. (<a
href="https://doi.org/10.1016/j.ins.2019.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile opportunistic networks (MONs), cooperative authentication is an efficient way to filter false or misleading messages. However, due to privacy issues and concerns related to the consumption of resources, without adequate incentives, most mobile users (or nodes) with limited resources often act selfishly. These users are frequently uninterested to help others to authenticate such messages. In this study, a cooperative authentication model was formulated in the form of an evolutionary game. This model addresses the problems caused when cooperative nodes do not have all the information regarding other neighboring nodes, which makes them inadequately rational. Herein, the behavior dynamics and evolutionary stable strategy (ESS) of neighboring nodes were derived. We showed that the behavior dynamics converge to the ESS. This induces the neighboring nodes to independently decide whether to participate in authentication or not, without depending on information from other nodes (therefore, our approach can be implemented in the de-centralized manner). Further, a scheme to help the source node was also designed to determine an optimal budget. Experiments were conducted both on simulated as well as real datasets. The results demonstrate that our approach exhibits overwhelming advantages to incentivize selfish nodes in MONs to cooperate.},
  archive      = {J_ISCI},
  author       = {Liang Fang and Guozhen Shi and Lianhai Wang and Yongjun Li and Shujiang Xu and Yunchuan Guo},
  doi          = {10.1016/j.ins.2019.07.030},
  journal      = {Information Sciences},
  pages        = {369-381},
  shortjournal = {Inf. Sci.},
  title        = {Incentive mechanism for cooperative authentication: An evolutionary game approach},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient approach for secure multi-party computation
without authenticated channel. <em>ISCI</em>, <em>527</em>, 356–368. (<a
href="https://doi.org/10.1016/j.ins.2019.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure multi-party sum is one of the most important secure multi-party computation protocols. It has been widely applied to solve many privacy-preservation problems such as privacy-preserving data mining, secure auction, secure electronic voting, and privacy-preserving statistical data analysis. To guarantee the correctness of the final output and to enhance the security level , the existing secure multi-party sum protocols have to use authenticated channels, even secure channels for participants to communicate, however such a usage requirement significantly reduces their performance. Furthermore, these secure multi-party sum protocols are impossible to run on public networks. In this paper, we propose a new secure multi-party sum protocol that can ensure the correctness of the output result as well as securely protecting the parties’ privacy against attacks without requiring any authenticated/secure channel. The proposed protocol is based on a multi-party sum function employing a variant of ElGamal encryption and a Schnorr signature-derived authentication method , in which both these cryptographic tools use the same private and public keys . Additionally, our comparative evaluation shows that the proposed protocol is efficient and practical.},
  archive      = {J_ISCI},
  author       = {Duy-Hien Vu and The-Dung Luong and Tu-Bao Ho},
  doi          = {10.1016/j.ins.2019.07.031},
  journal      = {Information Sciences},
  pages        = {356-368},
  shortjournal = {Inf. Sci.},
  title        = {An efficient approach for secure multi-party computation without authenticated channel},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving computation in cyber-physical-social
systems: A survey of the state-of-the-art and perspectives.
<em>ISCI</em>, <em>527</em>, 341–355. (<a
href="https://doi.org/10.1016/j.ins.2019.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical-social systems (CPSSs) are leading digital revolutions in academia, industry and government. Due to the rise of big data analytics , tensor computations are currently used in CPSSs. With the increasing popularity of cloud computing or fog computing , big data in CPSSs are usually sent to clouds or fogs for computations. Recently, some studies about privacy-preserving computation have been conducted to address security concerns which enable data analysis and processing in cloud or fog environments in a privacy-preserving way. To fully understand the state-of-the-art advances and discover the research directions of this field, in this survey, both previous and current privacy-preserving schemes are comprehensively reviewed and studied. In addition, a novel privacy-preserving tensor computation framework, a case study, and several future research directions are presented for CPSSs.},
  archive      = {J_ISCI},
  author       = {Jun Feng and Laurence T. Yang and Nicholaus J. Gati and Xia Xie and Benard S. Gavuna},
  doi          = {10.1016/j.ins.2019.07.036},
  journal      = {Information Sciences},
  pages        = {341-355},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving computation in cyber-physical-social systems: A survey of the state-of-the-art and perspectives},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud-based lightweight secure RFID mutual authentication
protocol in IoT. <em>ISCI</em>, <em>527</em>, 329–340. (<a
href="https://doi.org/10.1016/j.ins.2019.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio Frequency Identification (RFID) is a supporting technology for the Internet of things (IoT). RFID enables all physical devices to be connected to IoT. When RFID is widely used and developing rapidly, its security and privacy issues cannot be ignored. The wireless broadcast channel between the tag and the reader may be subject to many security attacks, such as interception, modification, and replay. Messages from unverified tags or readers are also untrustworthy. A secure and stable RFID authentication scheme is critical to IoT. This paper puts forward an efficient and reliable cloud-based RFID authentication scheme. In order to reduce the RFID tag&#39;s overhead, the proposed authentication scheme explores the rotation and enhanced permutation to encrypt data. The proposed protocol not only resists the above common attacks and protects the privacy of the tag, but also adds the cloud server to the RFID system. Performance simulation shows that permutation and rotation are efficient. Security analysis shows that our protocol can resist various attacks, such as tracking, replay, and desynchronization attack . Mutual authentication and backward security are also achieved. Finally, we apply BAN logic to prove the security of the protocol.},
  archive      = {J_ISCI},
  author       = {Kai Fan and Qi Luo and Kuan Zhang and Yintang Yang},
  doi          = {10.1016/j.ins.2019.08.006},
  journal      = {Information Sciences},
  pages        = {329-340},
  shortjournal = {Inf. Sci.},
  title        = {Cloud-based lightweight secure RFID mutual authentication protocol in IoT},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective privacy preserving data publishing by
vectorization. <em>ISCI</em>, <em>527</em>, 311–328. (<a
href="https://doi.org/10.1016/j.ins.2019.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As smart devices and cloud services are rapidly expanding, a large amount of location information can easily be gathered. However, there is a conflict between collecting location data and protecting personal data since obtaining and utilizing the data may be restricted due to privacy concerns. Various methods for anonymity and on the original location data have been studied, but these methods have excessively reduced data utility while stressing highly on privacy preservation . In this article, we suggest a novel model to overcome this fundamental dilemma via a surrogate vector based on the grid environment . Compared to the existing approaches, our model shows a new theoretical advancement in privacy protection, and outstanding performance with respect to time complexity and data utility has been achieved.},
  archive      = {J_ISCI},
  author       = {Chris Soo-Hyun Eom and Charles Cheolgi Lee and Wookey Lee and Carson K. Leung},
  doi          = {10.1016/j.ins.2019.09.035},
  journal      = {Information Sciences},
  pages        = {311-328},
  shortjournal = {Inf. Sci.},
  title        = {Effective privacy preserving data publishing by vectorization},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy by evidence: A methodology to develop
privacy-friendly software applications. <em>ISCI</em>, <em>527</em>,
294–310. (<a href="https://doi.org/10.1016/j.ins.2019.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an increasingly connected world, a diversity of data is collected from the environment and its inhabitants. Because of the richness of the information, privacy becomes an important requirement. Although there are principles and rules, there is still a lack of methodologies to guide the integration of privacy guidelines into the development process. Methodologies like the Privacy by Design ( PbD ) are still vague and leave many open questions on how to apply them in practice. In this work we propose a new concept, called Privacy by Evidence ( PbE ), in the form of a software development methodology to provide privacy-awareness. Given the difficulty in providing total privacy in many applications, we propose to document the mitigations in form of evidences of privacy, aiming to increase the confidence of the project. To validate its effectiveness, PbE has been used during the development of four case studies: a smart metering application; a people counting and monitoring application; an energy efficiency monitoring system; and a two factor authentication system. For these applications, the teams were able to provide seven, five, five, and four evidences of privacy, respectively, and we conclude that PbE can be effective in helping to understand and address the privacy protection needs when developing software.},
  archive      = {J_ISCI},
  author       = {Pedro Barbosa and Andrey Brito and Hyggo Almeida},
  doi          = {10.1016/j.ins.2019.09.040},
  journal      = {Information Sciences},
  pages        = {294-310},
  shortjournal = {Inf. Sci.},
  title        = {Privacy by evidence: A methodology to develop privacy-friendly software applications},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special section on privacy computing: Principles and
applications. <em>ISCI</em>, <em>527</em>, 293. (<a
href="https://doi.org/10.1016/j.ins.2020.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Jinjun Chen and Laurence Yang},
  doi          = {10.1016/j.ins.2020.04.047},
  journal      = {Information Sciences},
  pages        = {293},
  shortjournal = {Inf. Sci.},
  title        = {Special section on privacy computing: Principles and applications},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical clustering supported by reciprocal nearest
neighbors. <em>ISCI</em>, <em>527</em>, 279–292. (<a
href="https://doi.org/10.1016/j.ins.2020.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental tool aiming at classifying data points into groups based on their pairwise distances or similarities. It has found successful applications in all natural and social sciences, including biology, physics, economics, chemistry, astronomy, psychology, and so on. Among various types of algorithms, hierarchical clustering is of particular advantages as it can provide results under different resolutions without the knowledge of a predetermined number of clusters. At the same time, it is usually time-consuming or inaccurate. In this paper, we propose a novel hierarchical clustering algorithm on the basis of a simple hypothesis that two reciprocal nearest data points should be grouped in one cluster. Extensive tests on data sets across multiple domains show that our method is much faster and more accurate than the state-of-the-art benchmarks. We further extend our method to deal with the community detection problem in real networks, achieving remarkably better results than the well-known Girvan-Newman algorithm.},
  archive      = {J_ISCI},
  author       = {Wen-Bo Xie and Yan-Li Lee and Cong Wang and Duan-Bing Chen and Tao Zhou},
  doi          = {10.1016/j.ins.2020.04.016},
  journal      = {Information Sciences},
  pages        = {279-292},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical clustering supported by reciprocal nearest neighbors},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum-inspired algorithm with fitness landscape
approximation in reduced dimensional spaces for numerical function
optimization. <em>ISCI</em>, <em>527</em>, 253–278. (<a
href="https://doi.org/10.1016/j.ins.2020.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In realistic numerical optimization problems , the efficiency of the algorithm is a crucial consideration. Fitness landscape approximation is beneficial for improving the search efficiency in evolutionary algorithms , but this method increases the computational cost significantly with an increase in the dimension. This paper proposes a quantum-inspired algorithm with dimension decomposition and fitness landscape approximation . The high-dimensional problem space is transformed into a low-dimensional projection space for fitness landscape approximation through mapping transformation. Linear approximation for the fitness landscape is performed in the transformed multiple 1D projected spaces. In accordance with two different diversity-retaining strategies, reference sampling points with different characteristics are selected to perform two-point linear approximation. Candidate points in the projection space are estimated and then synthesized as candidate solutions in the problem space. Then, candidate solutions are used in an appropriate population reconstruction mechanism to improve the performance of the algorithm. The proposed algorithms are implemented on benchmark functions abstracted from real-world optimization problems and compared with several algorithms. Experimental results on errors, success rates, and their rankings show the superiority of the proposed approach with the solution diversity priority with regard to effectiveness, adaptability, and stability.},
  archive      = {J_ISCI},
  author       = {Lei Mu and Peng Wang and Gang Xin},
  doi          = {10.1016/j.ins.2020.03.035},
  journal      = {Information Sciences},
  pages        = {253-278},
  shortjournal = {Inf. Sci.},
  title        = {Quantum-inspired algorithm with fitness landscape approximation in reduced dimensional spaces for numerical function optimization},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-language question retrieval with multi-layer
representation and layer-wise adversary. <em>ISCI</em>, <em>527</em>,
241–252. (<a href="https://doi.org/10.1016/j.ins.2020.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cross-language question retrieval (CLQR), users employ a new question in one language to search the community question answering (CQA) archives for similar questions in another language. In addition to the ranking problem in monolingual question retrieval, one needs to bridge the language gap in CLQR. The existing adversarial models for cross-language learning normally rely on a single adversarial component. Since natural languages consist of units of different abstract levels, we argue that crossing the language gap adaptatively on different levels with multiple adversarial components should lead to smoother text representation and better CLQR performance . To this end, we first encode questions into multi-layer representations of different abstract levels with a CNN based model which enhances conventional models with diverse kernel shapes and the corresponding pooling strategy so as to capture different aspects of a text segment. We then impose a set of adversarial components on different layers of question representation so as to decide the appropriate abstract levels and their role in performing cross-language mapping. Experimental results on two real-world datasets demonstrate that our model outperforms state-of-the-art models for CLQR, which is on par with the strong machine translation baselines and most monolingual baselines.},
  archive      = {J_ISCI},
  author       = {Bo Li and Xiaodong Du and Meng Chen},
  doi          = {10.1016/j.ins.2020.01.035},
  journal      = {Information Sciences},
  pages        = {241-252},
  shortjournal = {Inf. Sci.},
  title        = {Cross-language question retrieval with multi-layer representation and layer-wise adversary},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Improving artificial bee colony algorithm using a new
neighborhood selection mechanism. <em>ISCI</em>, <em>527</em>, 227–240.
(<a href="https://doi.org/10.1016/j.ins.2020.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial bee colony (ABC) and its most modifications use a probability method to select good food sources (called solutions) in the onlooker bee search phase. However, the probability selection does not work with increasing of iterations, because the fitness values cannot be used to distinguish two different solutions. In order to tackle this problem, this paper proposes a new ABC (called NSABC), in which a new selection method based on neighborhood radius is used. Unlike the probability selection in the original ABC, NSABC chooses the best solution in the neighborhood radius to generate offspring. Based on the neighborhood radius, two new solution search strategies are modified. The scout bee search phase is improved by using opposition-based learning and the neighborhood radius. To evaluate the search ability of NSABC, there are 22 benchmark problems used in the experiments. Performance comparison shows NSABC achieves better results than five other ABC algorithms .},
  archive      = {J_ISCI},
  author       = {Hui Wang and Wenjun Wang and Songyi Xiao and Zhihua Cui and Minyang Xu and Xinyu Zhou},
  doi          = {10.1016/j.ins.2020.03.064},
  journal      = {Information Sciences},
  pages        = {227-240},
  shortjournal = {Inf. Sci.},
  title        = {Improving artificial bee colony algorithm using a new neighborhood selection mechanism},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-enhanced remote data integrity checking with
updatable timestamp. <em>ISCI</em>, <em>527</em>, 210–226. (<a
href="https://doi.org/10.1016/j.ins.2020.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote data integrity checking (RDIC) enables clients to verify whether the outsourced data is intact without keeping a copy locally or downloading it. Nevertheless, the existing RDIC schemes do not support the pay-as-you-go (PAYG) payment model, where the payment is decided by the volume and duration of the outsourced data . Specifically, none of the existing works have considered the client’s control over changes in storage duration. In this paper, we propose an RDIC scheme to simultaneously check the data content and storage duration represented by an updatable timestamp via the third-party auditor (TPA). Also, our proposed scheme achieves indistinguishable privacy (IND-privacy) against TPA for both data content and timestamp. To bind the content and timestamp in the authenticator and support efficient timestamp update, we construct the authenticator with the randomizable structure-preserving signature (SPS). Additionally, we utilize the Groth-Sahai proof and range proof to provide the IND-privacy and guarantee the timestamp validation in the auditing phase. We formalize the definition and security model and provide the formal proof of our scheme. We also present the theoretical and experimental performance analysis to demonstrate that our scheme is comparable to the previous RDIC schemes which do not consider the storage time.},
  archive      = {J_ISCI},
  author       = {Tong Wu and Guomin Yang and Yi Mu and Rongmao Chen and Shengmin Xu},
  doi          = {10.1016/j.ins.2020.03.057},
  journal      = {Information Sciences},
  pages        = {210-226},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-enhanced remote data integrity checking with updatable timestamp},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Adaptive neural network control for time-varying state
constrained nonlinear stochastic systems with input saturation.
<em>ISCI</em>, <em>527</em>, 191–209. (<a
href="https://doi.org/10.1016/j.ins.2020.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the tracking control issue of nonlinear stochastic systems subject to time-varying full state constraints and input saturation. By employing both neural network-based approximator and backstepping technique, an adaptive neural network (NN) control approach is presented on the basis of the time-varying barrier Lyapunov function . To surmount the influence of saturation nonlinearity , a Gaussian error function-based continuous differentiable saturation model is introduced such that the actual control in the final backstepping step can be achieved. The designed controller can not only achieve the tracking control objective, but also surmount the impact of input saturation to stochastic system performance. Meanwhile, the norm of NN weight vector is taken as estimated parameter, and it can alleviate computation burden. The presented controller can ensure that all the signals in the closed-loop system are bounded in probability and all state variables are restricted the predefined regions. Finally, simulation results are given to illustrate the effectiveness of the established controller.},
  archive      = {J_ISCI},
  author       = {Qidan Zhu and Yongchao Liu and Guoxing Wen},
  doi          = {10.1016/j.ins.2020.03.055},
  journal      = {Information Sciences},
  pages        = {191-209},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive neural network control for time-varying state constrained nonlinear stochastic systems with input saturation},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pose-guided spatiotemporal alignment for video-based person
re-identification. <em>ISCI</em>, <em>527</em>, 176–190. (<a
href="https://doi.org/10.1016/j.ins.2020.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal alignment is a critical problem in video-based person re-identification (re-id) tasks. To address this problem, we propose a pose-guided spatiotemporal alignment (PISA) method to align video sequences for video-based person re-id. First, to perform precise temporal alignment, we align a video sequence to a series of image sets, corresponding to a series of reference pedestrian poses. Each image set is obtained by selecting the images with the same pose and high quality. Furthermore, to perform spatial alignment, we decompose a pedestrian image into human body parts, and accordingly compute the representations over the parts. Finally, we evaluate the similarity between two video sequences by aggregating the distances of the pose-corresponded image sets rather than all pairs. The experimental results on two public datasets show that the proposed method performs favorably against state-of-the-art methods, even deep learning-based approaches.},
  archive      = {J_ISCI},
  author       = {Changxin Gao and Yang Chen and Jin-Gang Yu and Nong Sang},
  doi          = {10.1016/j.ins.2020.04.007},
  journal      = {Information Sciences},
  pages        = {176-190},
  shortjournal = {Inf. Sci.},
  title        = {Pose-guided spatiotemporal alignment for video-based person re-identification},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An endorsement-based trust bootstrapping approach for
newcomer cloud services. <em>ISCI</em>, <em>527</em>, 159–175. (<a
href="https://doi.org/10.1016/j.ins.2020.03.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of providing trustworthy recommendations on newly deployed cloud services/resources for which little or no evidence about their trustworthiness is available. We also provide a two-level dishonesty discouragement mechanism to fight against unfair recommendations at both the collection and aggregation levels. Our solution consists of a (1) mechanism to allow users to self-assess the accuracy of their recommendations and autonomously decide on whether to participate in the recommendation process or not, (2) machine learning technique that generates reliable endorsements on newcomer items through extracting hidden similarities among the specifications of new and existing ones, (3) dishonesty-aware aggregation technique for endorsements coming from multiple advisors, (4) credibility update mechanism that captures the dynamism in the endorsers’ credibility, and (5) incentive mechanism to motivate advisors to participate in the endorsement process. Experiments conducted on the CloudHarmony and Epinions datasets show that our solution improves the accuracy of classifying newly deployed cloud services and yields better performance in protecting the recommendation process against Sybil attacks , in comparison with four existing recommendation approaches.},
  archive      = {J_ISCI},
  author       = {Omar Abdel Wahab and Robin Cohen and Jamal Bentahar and Hadi Otrok and Azzam Mourad and Gaith Rjoub},
  doi          = {10.1016/j.ins.2020.03.102},
  journal      = {Information Sciences},
  pages        = {159-175},
  shortjournal = {Inf. Sci.},
  title        = {An endorsement-based trust bootstrapping approach for newcomer cloud services},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed charge 4D-TP for a breakable item under hybrid random
type-2 uncertain environments. <em>ISCI</em>, <em>527</em>, 128–158. (<a
href="https://doi.org/10.1016/j.ins.2020.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of hybrid random type-2 uncertainty is yet to be used in decision-making problems. Here, under this category, random type-2 triangular fuzzy, random type-2 Gaussian fuzzy and random type-2 zigzag uncertain variables are presented. For illustration, a fixed charge four dimension transportation problem (FC4D-TP) for a breakable item is formulated with its selling prices, purchasing costs, transportation costs, fixed charges, availability, demands and conveyances’ capacities as hybrid random type-2 uncertain parameters. The model is de-randomized using probability chance constraint. The reduced type-2 triangular and Gaussian fuzzy models are de-fuzzified by CV based reduction technique and the type-2 zigzag uncertain model is transformed to deterministic one by expected value-based reduction method. In addition to these, the model with type-2 triangular fuzzy parameters is also de-fuzzified by two other methods such as CV-centroid based defuzzification and nearest interval approximation methods. All these reduced deterministic problems along with some particular models are solved by Generalized Reduced Gradient method using LINGO 18.0 and numerically illustrated. Some sensitivity analyses are presented. Expressions of a previous model are deduced. Importance of FC4D-TP formulation is pointed out. Effects of hybrid uncertainties are also discussed. The proposed nature of parameters’ uncertainty is illustrated.},
  archive      = {J_ISCI},
  author       = {Sukhendu Bera and Pravash Kumar Giri and Dipak Kumar Jana and Kajla Basu and Manoranjan Maiti},
  doi          = {10.1016/j.ins.2020.03.050},
  journal      = {Information Sciences},
  pages        = {128-158},
  shortjournal = {Inf. Sci.},
  title        = {Fixed charge 4D-TP for a breakable item under hybrid random type-2 uncertain environments},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving distributed deep learning based on secret
sharing. <em>ISCI</em>, <em>527</em>, 108–127. (<a
href="https://doi.org/10.1016/j.ins.2020.03.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed deep learning (DDL) naturally provides a privacy-preserving solution to enable multiple parties to jointly learn a deep model without explicitly sharing the local datasets. However, the existing privacy-preserving DDL schemes still suffer from severe information leakage and/or lead to significant increase of the communication cost. In this work, we design a privacy-preserving DDL framework such that all the participants can keep their local datasets private with low communication and computational cost, while still maintaining the accuracy and efficiency of the learned model. By adopting an effective secret sharing strategy, we allow each participant to split the intervening parameters in the training process into shares and upload an aggregation result to the cloud server. We can theoretically show that the local dataset of a particular participant can be well protected against the honest-but-curious cloud server as well as the other participants, even under the challenging case that the cloud server colludes with some participants. Extensive experimental results are provided to validate the superiority of the proposed secret sharing based distributed deep learning (SSDDL) framework.},
  archive      = {J_ISCI},
  author       = {Jia Duan and Jiantao Zhou and Yuanman Li},
  doi          = {10.1016/j.ins.2020.03.074},
  journal      = {Information Sciences},
  pages        = {108-127},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving distributed deep learning based on secret sharing},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient algorithms based on centrality measures for
identification of top-k influential users in social networks.
<em>ISCI</em>, <em>527</em>, 88–107. (<a
href="https://doi.org/10.1016/j.ins.2020.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of influence maximization has grown in popularity and interest in recent decades due to its valuable application in various fields. This problem mainly focuses on identifying Top-K influential users that, when selected, the influence spread will be maximized. Thus, the identification of such nodes is pivotal in increasing the adoption of promoted information and behavior within the network. In this paper, we propose two new efficient algorithms, namely, “MinCDegKatz d-hops (MaxCDegKatz d-hops)” that relies on a combination of centralization measures due to their known efficiency and performance in terms of influence spread and their low runtime complexity. The proposed algorithms combine between the degree centrality as local measure and the Katz centrality as global centrality metric on a graph with preselected weight edges that should exceed a predefined threshold value. Thus, each selected seed set is separated by a number of hops that differ depending on the graph radius. Then, the influence spread is measured for the two proposed algorithms under the Independent Cascade (IC) and Linear Threshold (LT) models. We conducted extensive experiments on a large-scale graph that demonstrated the performance of our proposed algorithms against existing approaches in term of spreading ability and time complexity.},
  archive      = {J_ISCI},
  author       = {Mohammed Alshahrani and Zhu Fuxi and Ahmed Sameh and Soufiana Mekouar and Sheng Huang},
  doi          = {10.1016/j.ins.2020.03.060},
  journal      = {Information Sciences},
  pages        = {88-107},
  shortjournal = {Inf. Sci.},
  title        = {Efficient algorithms based on centrality measures for identification of top-K influential users in social networks},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust manhattan non-negative matrix factorization for image
recovery and representation. <em>ISCI</em>, <em>527</em>, 70–87. (<a
href="https://doi.org/10.1016/j.ins.2020.03.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing robust non-negative matrix factorization methods fail to achieve data recovery and learn a robust representation. This is because these methods suppose that outliers and noise of the original data are the Gaussian distribution . In this paper, we propose a robust non-negative matrix model , called robust Manhattan non-negative matrix factorization , which can handle various noise (e.g. Gaussian noise , Salt and Pepper noise or Contiguous Occlusion). Different from previous robust non-negative matrix factorization models, we utilize mean filter and matrix completion as additional constraints to recover the corrupted data from normal data or neighbouring corrupted data, and achieve a robust low-dimensional representation by Manhattan non-negative matrix factorization . We theoretically compare the robustness of our proposed model with other non-negative matrix factorization models and theoretically prove the effectiveness of the proposed algorithm. Extensive experimental results on the image dataset containing noise and outliers validate the robustness and effectiveness of our proposed model for image recovery and representation.},
  archive      = {J_ISCI},
  author       = {Xiangguang Dai and Xiaojie Su and Wei Zhang and Fangzheng Xue and Huaqing Li},
  doi          = {10.1016/j.ins.2020.03.096},
  journal      = {Information Sciences},
  pages        = {70-87},
  shortjournal = {Inf. Sci.},
  title        = {Robust manhattan non-negative matrix factorization for image recovery and representation},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered control for stochastic networked control
systems against denial-of-service attacks. <em>ISCI</em>, <em>527</em>,
51–69. (<a href="https://doi.org/10.1016/j.ins.2020.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the security issues in networked control systems have become a major challenge, since networked control systems (NCSs) are vulnerable to malicious attacks . In this paper, a new event-triggered mechanism (ETM) is proposed, under which data packets could be actively dropped within consecutive steps, saving more communication resource than the existing ETM. Moreover, the effect of Denial-of-Service (DoS) attacks obeying Bernoulli distribution is considered and analysed. Furthermore, the corresponding estimation error covariance of the state is derived and the performance of system is analysed under the ETM both in the absence and presence of DoS attacks. Finally, the effectiveness of the proposed ETM is demonstrated by Monte Carlo simulation experiments and the feasibility of theoretical results is validated by numerical examples.},
  archive      = {J_ISCI},
  author       = {Li Guo and Hao Yu and Fei Hao},
  doi          = {10.1016/j.ins.2020.03.045},
  journal      = {Information Sciences},
  pages        = {51-69},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered control for stochastic networked control systems against denial-of-service attacks},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General interval-valued overlap functions and
interval-valued overlap indices. <em>ISCI</em>, <em>527</em>, 27–50. (<a
href="https://doi.org/10.1016/j.ins.2020.03.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Overlap functions are aggregation functions that express the overlapping degree between two values. They have been used both as a conjunction in several practical problems (e.g., image processing and decision making), and to generate overlap indices between two fuzzy sets, which can be used to construct fuzzy confidence values to be applied in fuzzy rule based classification systems. Some generalizations of overlap functions were recently proposed, such as n-dimensional and general overlap functions, which allowed their application in n-dimensional problems. More recently, the concept of interval-valued overlap functions was presented, mainly to deal with uncertainty in providing membership functions. In this paper, we introduce: (i) the concept of n-dimensional interval-valued overlap functions, studying their representability , (ii) the definition of general interval-valued overlap functions, providing their characterization and some construction methods. Moreover, we also define the concept of interval-valued overlap index, as well as some constructing methods. In addition, we show an illustrative example where those new concepts are applied.},
  archive      = {J_ISCI},
  author       = {Tiago da Cruz Asmus and Graçaliz Pereira Dimuro and Benjamín Bedregal and José Antonio Sanz and Sidnei Pereira Jr. and Humberto Bustince},
  doi          = {10.1016/j.ins.2020.03.091},
  journal      = {Information Sciences},
  pages        = {27-50},
  shortjournal = {Inf. Sci.},
  title        = {General interval-valued overlap functions and interval-valued overlap indices},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skewed non-gaussian GARCH models for cryptocurrencies
volatility modelling. <em>ISCI</em>, <em>527</em>, 1–26. (<a
href="https://doi.org/10.1016/j.ins.2020.03.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cryptocurrencies have attracted a growing interest from investors, practitioners and researchers. Nevertheless, few studies have focused on the predictability of them. In this paper we propose a new and comprehensive study about cryptocurrency market, evaluating the forecasting performance for three of the most important cryptocurrencies (Bitcoin, Ethereum and Litecoin) in terms of market capitalization . At this aim, we consider non-Gaussian GARCH volatility models, which form a class of stochastic recursive systems commonly adopted for financial predictions. Results show that the best specification and forecasting accuracy are achieved under the Skewed Generalized Error Distribution when Bitcoin/USD and Litecoin/USD exchange rates are considered, while the best performances are obtained for skewed Distribution in the case of Ethereum/USD exchange rate. The obtain findings state the effectiveness – in terms of prediction performance – of relaxing the normality assumption and considering skewed distributions.},
  archive      = {J_ISCI},
  author       = {Roy Cerqueti and Massimiliano Giacalone and Raffaele Mattera},
  doi          = {10.1016/j.ins.2020.03.075},
  journal      = {Information Sciences},
  pages        = {1-26},
  shortjournal = {Inf. Sci.},
  title        = {Skewed non-gaussian GARCH models for cryptocurrencies volatility modelling},
  volume       = {527},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ECC2: Error correcting code and elliptic curve based
cryptosystem. <em>ISCI</em>, <em>526</em>, 301–320. (<a
href="https://doi.org/10.1016/j.ins.2020.03.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code-based cryptography has aroused wide public concern as one of the main candidates for post quantum cryptography to resist attacks against cryptosystems from quantum computation . However, the large key size becomes a drawback that prevents it from wide practical applications although it performs pretty well on the speed of both encryption and decryption. The use of algebraic geometry codes is considered to be a good solution to reduce the key size, but the special structures of algebraic geometry codes results in lots of attacks including Minder’s attack. To cope with the barriers of large key size as well as attacks from the special structures of algebraic codes, we propose a code-based encryption system using elliptic codes. The special structure of elliptic codes helps us to effectively reduce the size of secret key. By choosing the rational points carefully, we build elliptic codes whose minimum weight codeword is hard to sample. Such codes are used in constructing encryption systems such that Minder’s attacks can be resisted. More importantly, we apply the list decoding algorithm in the decryption process thus more errors beyond half of the minimum distance of the code could be corrected, which is the key point to resist other known attacks for algebraic geometry codes based cryptosystems . Our implementation shows that the proposed encryption system performs well on the key size and ciphertext expansion rate.},
  archive      = {J_ISCI},
  author       = {Fangguo Zhang and Zhuoran Zhang and Peidong Guan},
  doi          = {10.1016/j.ins.2020.03.069},
  journal      = {Information Sciences},
  pages        = {301-320},
  shortjournal = {Inf. Sci.},
  title        = {ECC2: Error correcting code and elliptic curve based cryptosystem},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient aggregation scheme resisting on malicious data
mining attacks for smart grid. <em>ISCI</em>, <em>526</em>, 289–300. (<a
href="https://doi.org/10.1016/j.ins.2020.03.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the smart grid, efficient power supplies require near-real-time users’ electricity usage metering data , but these data might leak users’ private information, e.g., living habits. To address this problem, a number of privacy-preserving data aggregation schemes have been proposed in the literature. In this paper, we present a new type of attack, called malicious data mining attack , by which the adversary can infer a target user’s electricity usage data. When considering this attack, the majority of existing data aggregation schemes have one of the following two shortcomings. In one aspect, the schemes based on homomorphic encryption can output an accurate aggregation result, but most of them are vulnerable to this attack. In another aspect, the schemes based on differential privacy able to withstand this attack, but the random noises introduced prevent accurate aggregation results from being computed. In this paper, we propose a novel data aggregation scheme that is not only secure against the malicious data mining attack, but also capable of outputting an accurate aggregation result. Detailed security analyses indicate that the proposed scheme satisfies the desirable properties for privacy-preserving data aggregation in the smart grid, and the simulated results demonstrate that our proposed scheme enjoys low computation and communication overhead .},
  archive      = {J_ISCI},
  author       = {Hua Shen and Yajing Liu and Zhe Xia and Mingwu Zhang},
  doi          = {10.1016/j.ins.2020.03.107},
  journal      = {Information Sciences},
  pages        = {289-300},
  shortjournal = {Inf. Sci.},
  title        = {An efficient aggregation scheme resisting on malicious data mining attacks for smart grid},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating behavior features for cold-start spam review
detection with adversarial learning. <em>ISCI</em>, <em>526</em>,
274–288. (<a href="https://doi.org/10.1016/j.ins.2020.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the wide applications, spam detection has long been a hot research topic in both academia and industry. Existing studies show that behavior features are effective in distinguishing the spam and legitimate reviews. However, it usually takes a long time to collect such features and thus is hard to apply them to cold-start spam review detection tasks. Recent advances leveraged the neural network to encode the various types of textual, behavior, and attribute information for this task. However, the inherent problem, i.e., lack of effective behavior features for new users who post just one review, is still unsolved. In this paper, we exploit the generative adversarial network (GAN) for addressing this problem. The key idea is to generate synthetic behavior features (SBFs) for new users from their easily accessible features (EAFs) . Specifically, we first select six well recognized real behavior features (RBFs) existing for regular users. We then train a GAN framework including a generator to generate SBFs from their EAFs including text, rating, and attribute features, and a discriminator to discriminate RBFs and SBFs. We design a new implementation of generator and discriminator for effective training. The trained GAN is finally applied to new users for generating synthetic behavior features. We conduct extensive experiments on two Yelp datasets. Experimental results demonstrate that our proposed framework significantly outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xiaoya Tang and Tieyun Qian and Zhenni You},
  doi          = {10.1016/j.ins.2020.03.063},
  journal      = {Information Sciences},
  pages        = {274-288},
  shortjournal = {Inf. Sci.},
  title        = {Generating behavior features for cold-start spam review detection with adversarial learning},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Super resolution perception for smart meter data.
<em>ISCI</em>, <em>526</em>, 263–273. (<a
href="https://doi.org/10.1016/j.ins.2020.03.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present the problem formulation and methodology framework of Super Resolution Perception (SRP) on smart meter data. With the widespread use of smart meters, a massive amount of electricity consumption data can be obtained. Smart meter data is the basis of automated billing and pricing, appliance identification, demand response, etc. However, the provision of high-quality data may be expensive in many cases. In this paper, we propose a novel problem - the SRP problem as reconstructing high-quality data from unsatisfactory data in smart grids. Advanced generative models are then proposed to solve the problem. This technology makes it possible for empowering existing facilities without upgrading existing meters or deploying additional meters. We first mathematically formulate the SRP problem under the Maximum a Posteriori (MAP) estimation framework. The dataset namely Super Resolution Perception Dataset (SRPD) is designed for this problem and released. A case study is then presented, which performs SRP on smart meter data. A network namely Super Resolution Perception Convolutional Neural Network (SRPCNN) is proposed to generate high-frequency load data from low-frequency data. Experiments demonstrate that our SRP models can reconstruct high-frequency data effectively. Moreover, the reconstructed high-frequency data can lead to better appliance identification results.},
  archive      = {J_ISCI},
  author       = {Guolong Liu and Jinjin Gu and Junhua Zhao and Fushuan Wen and Gaoqi Liang},
  doi          = {10.1016/j.ins.2020.03.088},
  journal      = {Information Sciences},
  pages        = {263-273},
  shortjournal = {Inf. Sci.},
  title        = {Super resolution perception for smart meter data},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nature-inspired multiobjective patient stratification from
cancer gene expression data. <em>ISCI</em>, <em>526</em>, 245–262. (<a
href="https://doi.org/10.1016/j.ins.2020.03.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stratifying personalized treatment for patients has been one of the main challenges for modern medicine. To solve this problem, various clustering algorithms have been proposed for patient stratification in both quantification and biological ways meaningfully. However, most of the existing clustering algorithms still suffer from many realistic algorithm limitations such as low diagnostic ability and bad generalization. Therefore, to address those restrictions, we propose a novel multiobjective spectral clustering algorithm based on decomposition. A population that consists of distance weight and two other indispensable parameters of the spectral clustering is optimized by the proposed algorithm. Two cluster validity indices are proposed to capture the characteristics of different datasets. To validate the effectiveness and efficiency of the proposed algorithm, we benchmark it on thirty-five real patient stratification datasets and six real-world medical datasets across thousands of comparisons with fifteen algorithms, including ten effective clustering methods and five state-of-the-art multiobjective algorithms. The experimental results indicate that the proposed algorithm performs better than other compared algorithms with high clustering ability for patient stratification. Moreover, extensive analysis of time complexity and parameters are performed to prove the robustness of the proposed algorithm from different perspectives.},
  archive      = {J_ISCI},
  author       = {Yunhe Wang and Zhiqiang Ma and Ka-Chun Wong and Xiangtao Li},
  doi          = {10.1016/j.ins.2020.03.095},
  journal      = {Information Sciences},
  pages        = {245-262},
  shortjournal = {Inf. Sci.},
  title        = {Nature-inspired multiobjective patient stratification from cancer gene expression data},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel methods to finite-time mittag-leffler synchronization
problem of fractional-order quaternion-valued neural networks.
<em>ISCI</em>, <em>526</em>, 221–244. (<a
href="https://doi.org/10.1016/j.ins.2020.03.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two methods to investigate the problem of finite-time Mittag-Leffler synchronization for the systems of fractional-order quaternion-valued neural networks (FQVNNs) with two kinds of activation functions , respectively. Generally, the first method mainly reflects in the new establishment of Lyapunov-Krasovskii functionals (LKFs) and the novel application of a new fractional-order derivative inequality which contains and exploits the wider coefficients with more values. Meanwhile, the second one is embodied in the comprehensive development of both the norm comparison rules and the generalized Gronwall-Bellman inequality with the help of Laplace transform of Mittag-Leffler function. Thanks to the above two methods, the flexible synchronization criteria are easily and separately obtained for the studied four systems of FQVNNs with general activation functions and linear threshold ones. Finally, two numerical simulations are given to demonstrate the feasibility and effectiveness of the newly proposed approaches.},
  archive      = {J_ISCI},
  author       = {Jianying Xiao and Jinde Cao and Jun Cheng and Shouming Zhong and Shiping Wen},
  doi          = {10.1016/j.ins.2020.03.101},
  journal      = {Information Sciences},
  pages        = {221-244},
  shortjournal = {Inf. Sci.},
  title        = {Novel methods to finite-time mittag-leffler synchronization problem of fractional-order quaternion-valued neural networks},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge base enrichment by relation learning from social
tagging data. <em>ISCI</em>, <em>526</em>, 203–220. (<a
href="https://doi.org/10.1016/j.ins.2020.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been considerable interest in transforming unstructured social tagging data into structured knowledge for semantic-based retrieval and recommendation. Research in this line mostly exploits data co-occurrence and often overlooks the complex and ambiguous meanings of tags. Furthermore, there have been few comprehensive evaluation studies regarding the quality of the discovered knowledge. We propose a supervised learning method to discover subsumption relations from tags. The key to this method is quantifying the probabilistic association among tags to better characterise their relations. We further develop an algorithm to organise tags into hierarchies based on the learned relations. Experiments were conducted using a large, publicly available dataset, Bibsonomy, and three popular, human-engineered or data-driven knowledge bases: DBpedia, Microsoft Concept Graph, and ACM Computing Classification System. We performed a comprehensive evaluation using different strategies: relation-level, ontology-level, and knowledge base enrichment based evaluation. The results clearly show that the proposed method can extract knowledge of better quality than the existing methods against the gold standard knowledge bases. The proposed approach can also enrich knowledge bases with new subsumption relations , having the potential to significantly reduce time and human effort for knowledge base maintenance and ontology evolution.},
  archive      = {J_ISCI},
  author       = {Hang Dong and Wei Wang and Frans Coenen and Kaizhu Huang},
  doi          = {10.1016/j.ins.2020.04.002},
  journal      = {Information Sciences},
  pages        = {203-220},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge base enrichment by relation learning from social tagging data},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Plaintext-related image encryption algorithm based on
perceptron-like network. <em>ISCI</em>, <em>526</em>, 180–202. (<a
href="https://doi.org/10.1016/j.ins.2020.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A perceptron-like network based on integer domain was proposed, and then a new image cryptosystem based on the network was proposed in this paper. Different from the structure of classical image cryptosystem, the proposed image cryptosystem employed the perceptron-like network to achieve the diffusion of image information. It firstly generated the pseudo-random key streams from the secret key through chaotic system and S-box of AES. Then it obscured the sequence of plain image by XOR operation. Next, it used two perceptron-like networks to fulfill the information memory and diffusion of the image sequence. Finally, it obscured the diffused sequence using the equivalent keys to obtain the cipher image sequence. Performance analysis and comparison analysis show that the proposed image cryptosystem has the advantages of fast processing speed, strong system sensitivity and high security, and can be applied to the actual image communications.},
  archive      = {J_ISCI},
  author       = {Yong Zhang and Aiguo Chen and Yingjun Tang and Jianwu Dang and Guoping Wang},
  doi          = {10.1016/j.ins.2020.03.054},
  journal      = {Information Sciences},
  pages        = {180-202},
  shortjournal = {Inf. Sci.},
  title        = {Plaintext-related image encryption algorithm based on perceptron-like network},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy preservation for machine learning training and
classification based on homomorphic encryption schemes. <em>ISCI</em>,
<em>526</em>, 166–179. (<a
href="https://doi.org/10.1016/j.ins.2020.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, more and more machine learning algorithms depend on the cloud computing . When a machine learning system is trained or classified in the cloud environment, the cloud server obtains data from the user side. Then, the privacy of the data depends on the service provider, it is easy to induce the malicious acquisition and utilization of data. On the other hand, the attackers can detect the statistical characteristics of machine learning data and infer the parameters of machine learning model through reverse attacks. Therefore, it is urgent to design an effective encryption scheme to protect the data’s privacy without breaking the performance of machine learning. In this paper, we propose a novel homomorphic encryption framework over non-abelian rings, and define the homomorphism operations in ciphertexts space. The scheme can achieve one-way security based on the Conjugacy Search Problem. After that, a homomorphic encryption was proposed over a matrix-ring. It supports real numbers encryption based on the homomorphism of 2-order displacement matrix coding function and achieves fast ciphertexts homomorphic comparison without decrypting any ciphetexts operations’ intermediate result. Furthermore, we use the scheme to realize privacy preservation for machine learning training and classification in data ciphertexts environment. The analysis shows that our proposed schemes are efficient for encryption/decryption and homomorphic operations.},
  archive      = {J_ISCI},
  author       = {Jing Li and Xiaohui Kuang and Shujie Lin and Xu Ma and Yi Tang},
  doi          = {10.1016/j.ins.2020.03.041},
  journal      = {Information Sciences},
  pages        = {166-179},
  shortjournal = {Inf. Sci.},
  title        = {Privacy preservation for machine learning training and classification based on homomorphic encryption schemes},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stacked autoencoder-based community detection method via an
ensemble clustering framework. <em>ISCI</em>, <em>526</em>, 151–165. (<a
href="https://doi.org/10.1016/j.ins.2020.03.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection is a challenging issue because most existing methods are not well suited for complex social networks with ambiguous structures. In this paper, we propose a novel community detection method named Stacked Autoencoder-Based Community Detection Method via Ensemble Clustering (CDMEC). This is the first time that we have attempted to apply four different complex network similarity representations to the community detection problem. This work makes up for the insufficiency of the single similarity matrix to describe the similarity relationship between nodes. These similarity representations can fully describe and consider the sufficient local information between nodes in a network topology . Our CDMEC framework combines transfer learning and a stacked autoencoder to obtain an efficient low-dimensional feature representation of complex networks and aggregates multiple inputs through a novel ensemble clustering framework. This novel framework first uses the basic clustering results to construct a consistent matrix, and then it employs the nonnegative matrix factorization (NMF)-based clustering method to detect reliable clustering results from the consistent matrix. The results of various extensive experiments on artificial benchmark networks and real-world networks showed that the proposed CDMEC framework is superior to the existing state-of-the-art community detection methods and has great potential in solving the community detection problems.},
  archive      = {J_ISCI},
  author       = {Rongbin Xu and Yan Che and Xinmei Wang and Jianxiong Hu and Ying Xie},
  doi          = {10.1016/j.ins.2020.03.090},
  journal      = {Information Sciences},
  pages        = {151-165},
  shortjournal = {Inf. Sci.},
  title        = {Stacked autoencoder-based community detection method via an ensemble clustering framework},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exposing splicing forgery in realistic scenes using deep
fusion network. <em>ISCI</em>, <em>526</em>, 133–150. (<a
href="https://doi.org/10.1016/j.ins.2020.03.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating fake pictures becomes more accessible than ever, but tampered images are more harmful because the Internet propagates misleading information so rapidly. Reliable digital forensic tools are therefore strongly needed. Traditional methods based on hand-crafted features are only useful when tampered images meet specific requirements, and the low detection accuracy prevents them from using in realistic scenes. Recently proposed learning-based methods improve the accuracy, but neural networks usually require to be trained on large labeled databases. This is because commonly used deep and narrow neural networks extract high-level visual features and neglect low-level features where there are abundant forensic cues. To solve the problem, we propose a novel neural network which concentrates on learning low-level forensic features and consequently can detect splicing forgery although the network is trained on a small automatically generated splicing dataset. Furthermore, our fusion network can be easily extended to support new forensic hypotheses without any changes in the network structure. The experimental results show that our method achieves state-of-the-art performance on several benchmark datasets and shows superior generalization capability: our fusion network can work very well even it never sees any pictures in test databases. Therefore, our method can detect splicing forgery in realistic scenes.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Chi-Man Pun},
  doi          = {10.1016/j.ins.2020.03.099},
  journal      = {Information Sciences},
  pages        = {133-150},
  shortjournal = {Inf. Sci.},
  title        = {Exposing splicing forgery in realistic scenes using deep fusion network},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy robust fault-tolerant control for offshore
ship-mounted crane system. <em>ISCI</em>, <em>526</em>, 119–132. (<a
href="https://doi.org/10.1016/j.ins.2020.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel event-triggered fuzzy robust fault-tolerant control approach is designed to handle the offshore ship crane nonlinear system with actuator fault and external disturbance . The main objective of this study is to realize the tracking control ability of the outputs while saving the transmission resources, which is achieved by constructing the integrated adaptive sliding mode controller and event trigger mechanism. The fuzzy logic theory is used both in the observer and controller design processes to approximate the nonlinear unknown functions. First, the information of the crane system state, actuator fault , and lumped disturbance are acquired by designing a fuzzy composite observer. Then, a novel adaptive sliding mode controller is presented by using the estimated values. In the proposed control scheme, two adaptive parameters are contained to consider the disturbance elimination and to enhance the tracking performance. An adaptive law is also included to compensate for the fuzzy approximation error. Furthermore, a novel event-triggered controller is proposed to reduce the transmission load of the crane system while also maintaining the tracking ability of the crane system. The no Zeno phenomenon performance is analyzed and, finally, the application to the crane system is given to show the fault tolerance ability of the proposed method.},
  archive      = {J_ISCI},
  author       = {Bin Guo and Yong Chen},
  doi          = {10.1016/j.ins.2020.03.068},
  journal      = {Information Sciences},
  pages        = {119-132},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy robust fault-tolerant control for offshore ship-mounted crane system},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Interval-valued intuitionistic fuzzy analytic network
process. <em>ISCI</em>, <em>526</em>, 102–118. (<a
href="https://doi.org/10.1016/j.ins.2020.03.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analytic network process framework is investigated to solve multi-criteria decision making problems in interval-valued intuitionistic fuzzy environments. First, a new approximate multiplicative consistent interval-valued intuitionistic fuzzy preference relation is defined, and the equivalent condition of approximate consistency is given by using the chance-constraint programming model of the Me measure. Second, a new method to derive the priorities from the interval-valued intuitionistic fuzzy preference relation is proposed, and the corresponding algorithm flow of the interval-valued intuitionistic fuzzy analytic network process is established. Finally, the feasibility and effectiveness of the interval-valued intuitionistic fuzzy analytic network process are verified by using a numerical example.},
  archive      = {J_ISCI},
  author       = {Yang Yang and Hongxu Li and Zhiming Zhang and Xiaowei Liu},
  doi          = {10.1016/j.ins.2020.03.077},
  journal      = {Information Sciences},
  pages        = {102-118},
  shortjournal = {Inf. Sci.},
  title        = {Interval-valued intuitionistic fuzzy analytic network process},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SOAP: Semantic outliers automatic preprocessing.
<em>ISCI</em>, <em>526</em>, 86–101. (<a
href="https://doi.org/10.1016/j.ins.2020.03.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic Programming (GP) is an evolutionary algorithm for the automatic generation of symbolic models expressed as syntax trees. GP has been successfully applied in many domain, but most research in this area has not considered the presence of outliers in the training set. Outliers make supervised learning problems difficult, and sometimes impossible, to solve. For instance, robust regression methods cannot handle more than 50\% of outlier contamination, referred to as their breakdown point. This paper studies problems where outlier contamination is high, reaching up to 90\% contamination levels, extreme cases that can appear in some domains. This work shows, for the first time, that a random population of GP individuals can detect outliers in the output variable. From this property, a new filtering algorithm is proposed called Semantic Outlier Automatic Preprocessing (SOAP), which can be used with any learning algorithm to differentiate between inliers and outliers. Since the method uses a GP population, the algorithm can be carried out for free in a GP symbolic regression system. The approach is the only method that can perform such an automatic cleaning of a dataset without incurring an exponential cost as the percentage of outliers in the dataset increases.},
  archive      = {J_ISCI},
  author       = {Leonardo Trujillo and Uriel López and Pierrick Legrand},
  doi          = {10.1016/j.ins.2020.03.071},
  journal      = {Information Sciences},
  pages        = {86-101},
  shortjournal = {Inf. Sci.},
  title        = {SOAP: Semantic outliers automatic preprocessing},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel fairness-aware co-scheduling for shared cache
contention game on chip multiprocessors. <em>ISCI</em>, <em>526</em>,
68–85. (<a href="https://doi.org/10.1016/j.ins.2020.03.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threads running on different cores of chip multiprocessors (CMP) can cause thread performance degradation due to contention for shared resources such as shared L2 cache . Some studies have shown that thread co-scheduling can effectively reduce contention for shared resources. However, in a multi-core system with shared caches, mutual interference between threads is unpredictable. As the number of cores increases, we are unlikely to exhaust all possible co-scheduling schemes. In this paper, a novel fairness-aware thread co-scheduling algorithm base on non-cooperative game is proposed to reduce L2 cache misses. We tried to improve the overall performance of the system by scheduling threads fairly. The originality of this work is to model thread scheduling using a non-cooperative game. The execution time of a thread varies depending on which threads are running on other cores of the same chip, because different thread combinations result in different levels of cache contention. Given the interdependence and competition between threads on the CMP architecture, non-cooperative game is used to solve the problem of thread co-scheduling where each thread is considered as a participant in the game. An iterative algorithm ( IA ) is proposed to solve the Nash equilibrium of the non-cooperative game in this paper. Subsequently, it is theoretically proved that IA has a potential game process and finally proves that IA can converge to Nash equilibrium in N iterations, where N is the number of threads. The co-scheduling scheme of all threads is obtained by solving the Nash equilibrium of the IA . Finally, the convergence and effectiveness of IA proposed in this paper is verified by experiments. In addition, we use the cache partition to improve the performance of IA . Experimental results show that the number of total cache misses of IA is less than that of the default scheduling algorithm , IA combined with cache partitioning can further reduce the total cache misses.},
  archive      = {J_ISCI},
  author       = {Zheng Xiao and Liwen Chen and Bangyong Wang and Jiayi Du and Keqin Li},
  doi          = {10.1016/j.ins.2020.03.078},
  journal      = {Information Sciences},
  pages        = {68-85},
  shortjournal = {Inf. Sci.},
  title        = {Novel fairness-aware co-scheduling for shared cache contention game on chip multiprocessors},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Block diagonal representation learning for robust subspace
clustering. <em>ISCI</em>, <em>526</em>, 54–67. (<a
href="https://doi.org/10.1016/j.ins.2020.03.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering groups a set of data into their underlying subspaces according to the low-dimensional subspace structure of data. The performance of spectral clustering-based approaches heavily depends on the learned block diagonal structure of the affinity matrix . However, this structure is fragile in the presence of noise within data. As such, the clustering performance is degraded significantly. On the other hand, in practice, we often do not have a prior knowledge of error distribution at all, which results in that we cannot model the error with suitable norms.  To this end, in this paper, we propose a robust block diagonal representation learning for subspace clustering. Specifically, a non-convex regularizer is directly utilized to constrain the affinity matrix for exploiting the block diagonal structure . Furthermore, we use a penalty matrix to adaptively weight the reconstruction error so that we can handle noise without prior knowledge. We also devise an effective method to compute the parameters related to this matrix, reducing the complexity of the parameter trains. Experimental results show that our method outperformed the state-of-the-art methods on both synthetic data and real-world datasets.},
  archive      = {J_ISCI},
  author       = {Lijuan Wang and Jiawen Huang and Ming Yin and Ruichu Cai and Zhifeng Hao},
  doi          = {10.1016/j.ins.2020.03.103},
  journal      = {Information Sciences},
  pages        = {54-67},
  shortjournal = {Inf. Sci.},
  title        = {Block diagonal representation learning for robust subspace clustering},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive fault-tolerant control for nonlinear multi-agent
systems with DoS attacks. <em>ISCI</em>, <em>526</em>, 39–53. (<a
href="https://doi.org/10.1016/j.ins.2020.03.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fault tolerant control (FTC) problem for nonlinear multi-agent systems (MASs), in the presence of denial-of-service (DoS) attacks and actuator faults . In order to compensate for the effect of actuator faults, nonlinear dynamics and uncertainties, a distributed control strategy is presented by designing adaptive schemes and state-feedback control gains. The uncertainties are assumed to satisfy the integral quadratic constraints (IQCs), which is a more general presentation than the norm-bounded conditions. The aim of DoS attacks is to impede the communication among agents. A switching mechanism is proposed to ensure the tolerance to network disconnections. Based on Lyapunov stability theory and the average dwell time (ADT) approach, it is proved that the MASs can achieve mean square consensus by using the proposed controller. Finally, two illustrative examples are provided to verify the effectiveness of this method.},
  archive      = {J_ISCI},
  author       = {Liang Zhao and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2020.03.083},
  journal      = {Information Sciences},
  pages        = {39-53},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fault-tolerant control for nonlinear multi-agent systems with DoS attacks},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental and decremental fuzzy bounded twin support
vector machine. <em>ISCI</em>, <em>526</em>, 20–38. (<a
href="https://doi.org/10.1016/j.ins.2020.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an incremental variant of the Twin Support Vector Machine (TWSVM) called Fuzzy Bounded Twin Support Vector Machine (FBTWSVM) to deal with large datasets and to learn from data streams. We combine the TWSVM with a fuzzy membership function , so that each input has a different contribution to each hyperplane in a binary classifier . To solve the pair of quadratic programming problems (QPPs), we use a dual coordinate descent algorithm with a shrinking strategy, and to obtain a robust classification with a fast training we propose the use of a Fourier Gaussian approximation function with our linear FBTWSVM. Inspired by the shrinking technique, the incremental algorithm re-utilizes part of the training method with some heuristics, while the decremental procedure is based on a scoring window. The FBTWSVM is also extended for multi-class problems by combining binary classifiers using a Directed Acyclic Graph (DAG) approach. Moreover, we analyzed the theoretical foundation’s properties of the proposed approach and its extension, and the experimental results on benchmark datasets indicate that the FBTWSVM has a fast training and retraining process while maintaining a robust classification performance.},
  archive      = {J_ISCI},
  author       = {Alexandre R. Mello and Marcelo R. Stemmer and Alessandro L. Koerich},
  doi          = {10.1016/j.ins.2020.03.038},
  journal      = {Information Sciences},
  pages        = {20-38},
  shortjournal = {Inf. Sci.},
  title        = {Incremental and decremental fuzzy bounded twin support vector machine},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability analysis of a SAIR rumor spreading model with
control strategies in online social networks. <em>ISCI</em>,
<em>526</em>, 1–19. (<a
href="https://doi.org/10.1016/j.ins.2020.03.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays rumors spread by virtual identities of people in online social networks . In order to study the influence of forcing silence on spreaders, we propose a rumor propagation model with a silence-forcing function in online social networks . The theoretical analysis of the rumor propagation model reveals the existence of the equilibrium points, the backward bifurcation and the local stability. Meanwhile, by choosing the key parameter and time delay as the bifurcation parameters , we have given some conditions of Hopf bifurcation that are easy to judge. Furthermore, the optimal control is discussed to reduce the frequency of rumor propagation. Finally, numerical simulations are presented to prove the correctness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Linhe Zhu and Bingxu Wang},
  doi          = {10.1016/j.ins.2020.03.076},
  journal      = {Information Sciences},
  pages        = {1-19},
  shortjournal = {Inf. Sci.},
  title        = {Stability analysis of a SAIR rumor spreading model with control strategies in online social networks},
  volume       = {526},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multimodal generative and fusion framework for recognizing
faculty homepages. <em>ISCI</em>, <em>525</em>, 205–220. (<a
href="https://doi.org/10.1016/j.ins.2020.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data consist of several data modes, where each mode is a group of similar data sharing the same attributes. Recognizing faculty homepages is essentially a multimodal classification problem in which a target faculty homepage is determined from three different information sources, including text, images, and layout. Conventional strategies in previous studies have been either to concatenate features from various information sources into a compound vector or to input them separately into several different classifiers that are then assembled into a stronger classifier for the final prediction. However, both approaches ignore the connections among different feature sets. We argue that such relations are essential to enhance multimodal classification. Besides, recognizing faculty homepages is a class imbalance problem in which the total number of samples of a minority class is far smaller than the sample numbers of other classes. In this study, we propose a multimodal generative and fusion framework for multimodal learning with the problems of imbalanced data and mutually dependent feature modes. Specifically, a multimodal generative adversarial network is first introduced to rebalance the dataset by generating pseudo features based on each mode and combining them to describe a fake sample. Then, a gated fusion network with the gate and fusion mechanisms is presented to reduce the noise to improve the generalization ability and capture the links among the different feature modes. Experiments on a faculty homepage dataset show the superiority of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Guanyuan Yu and Qing Li and Jun Wang and Di Zhang and Yuehao Liu},
  doi          = {10.1016/j.ins.2020.03.005},
  journal      = {Information Sciences},
  pages        = {205-220},
  shortjournal = {Inf. Sci.},
  title        = {A multimodal generative and fusion framework for recognizing faculty homepages},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-view ensemble learning based on distance-to-model and
adaptive clustering for imbalanced credit risk assessment in P2P
lending. <em>ISCI</em>, <em>525</em>, 182–204. (<a
href="https://doi.org/10.1016/j.ins.2020.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk assessment is a crucial task in the peer-to-peer (P2P) lending industry. In recent years, ensemble learning methods have been verified to perform better in default prediction than individual classifiers and statistical techniques. Real-world loan datasets are imbalanced; however, most studies focus on enhancing overall prediction accuracy rather than improving the identification ability of real default loans. Moreover, some of the features that are significantly correlated with default rates are not attached importance in the model construction of previous studies. To fill these gaps, we propose a distance-to-model and adaptive clustering-based multi-view ensemble (DM–ACME) learning method for predicting default risk in P2P lending. In this method, multi-view learning and an adaptive clustering method are explored to produce an ensemble of diverse ensembles constituted by gradient boosting decision trees . A novel combination strategy called distance-to-model and a soft probability fashion are embedded for model integration. To verify the effectiveness of the proposed ensemble approach, comprehensive analysis on DM–ACME, comparative experiments with several state-of-the-art methods, and feature importance evaluation are conducted with the data provided by Lending Club. Experimental results demonstrate the superiority of the proposed method as well as indicate the importance of some features in loan default prediction.},
  archive      = {J_ISCI},
  author       = {Yu Song and Yuyan Wang and Xin Ye and Dujuan Wang and Yunqiang Yin and Yanzhang Wang},
  doi          = {10.1016/j.ins.2020.03.027},
  journal      = {Information Sciences},
  pages        = {182-204},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view ensemble learning based on distance-to-model and adaptive clustering for imbalanced credit risk assessment in P2P lending},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ontology-based enriched concept graphs for medical document
classification. <em>ISCI</em>, <em>525</em>, 172–181. (<a
href="https://doi.org/10.1016/j.ins.2020.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapidly increasing volume of medical text data, including biomedical literature and clinical records, presents difficulties to biomedical researchers and clinical practitioners. Automatic text classification is an important means for managing medical text data. The main challenge in medical text classification is the complex terminology used in these documents. Therefore, it is critical to handle synonymy, polysemy, and multi-word concepts so that classification is based on the meaning of these documents. The solution to this problem of complex terminology helps in building systems with better access to relevant data, resulting in more effective utilisation of the existing information. In this paper, we present a simple and effective approach to address this challenge. A concept graph is automatically constructed and enriched for each medical text document with the help of a domain-specific similarity matrix that is built using Unified Medical Language System (UMLS) concepts in the training documents. Medical text documents are compared based on their enriched concept graphs using a graph kernel. Classification is then done based on the comparison result. The benefit of this approach is that it allows the incorporation of domain knowledge into the classification framework. The experiments on biomedical abstracts and clinical reports classification show the effectiveness of the proposed approach. Based on evaluation metrics of precision, recall and F1-scores, our method achieves a significantly higher classification performance than other widely used similarity measures for similarity-based text classification.},
  archive      = {J_ISCI},
  author       = {Niloofer Shanavas and Hui Wang and Zhiwei Lin and Glenn Hawe},
  doi          = {10.1016/j.ins.2020.03.006},
  journal      = {Information Sciences},
  pages        = {172-181},
  shortjournal = {Inf. Sci.},
  title        = {Ontology-based enriched concept graphs for medical document classification},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online reliable semi-supervised learning on evolving data
streams. <em>ISCI</em>, <em>525</em>, 153–171. (<a
href="https://doi.org/10.1016/j.ins.2020.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In todays digital era, a massive amount of streaming data is automatically and continuously generated. To learn such data streams, many algorithms have been proposed during the last decade. Due to the dynamic nature of streaming data , the learning algorithms must be adaptive to handle concept drift and work under limited memory and time. Currently, most existing works assume that the true class labels of all incoming instances are immediately available. In real-world applications, labeling every data item in data streams is time and resource consuming. A more realistic situation is that only a few instances in data streams are labeled. Thereby, how to design a new efficient and effective learning algorithm that can handle concept drift, label scarcity, and work under limited resources is of significant importance. In this paper, we propose a new online semi-supervised learning algorithm by modeling concept drifts with a set of micro-clusters. These micro-clusters are dynamically maintained to capture the evolving concepts with error-based representative learning. In this way, local concept drifts are captured more quickly and finally support effective data stream learning. Extensive experiments on several data sets demonstrate that our learning model allows yielding high classification performance compared to many state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Salah Ud Din and Junming Shao and Jay Kumar and Waqar Ali and Jiaming Liu and Yu Ye},
  doi          = {10.1016/j.ins.2020.03.052},
  journal      = {Information Sciences},
  pages        = {153-171},
  shortjournal = {Inf. Sci.},
  title        = {Online reliable semi-supervised learning on evolving data streams},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Modeling of an ultra-supercritical boiler-turbine system
with stacked denoising auto-encoder and long short-term memory network.
<em>ISCI</em>, <em>525</em>, 134–152. (<a
href="https://doi.org/10.1016/j.ins.2020.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ultra-supercritical (USC) coal fired boiler-turbine unit is an advanced power generation system with low emissions and high efficiency. It is also a typical multivariable nonlinear system with great inertia. Generally, building an accurate analytic model using the conventional system identification methods are quite difficult. However, the big data generated by the monitoring system can reflect the USC unit&#39;s operation status and reveal the internal mechanism, if appropriate data analysis methods are developed. A deep neural network (DNN) is proposed in this paper to model a 1000 MW USC unit. In this DNN, stacked denoising auto-encoder is adopted to obtain the intrinsic features from the input data, while the long short-term memory network is in charge of outputting the expected normal behaviors of USC system along the time axis. Furthermore, to guarantee the convergence of this network, a reasonable intensity of added noise is identified via Lyapunov stability method. The DNN model is compared with the traditional multi-layer perception network, the stacked denoising auto-encoder, and two other random neural networks, to show the advantages in forecasting the dynamic behavior of USC unit.},
  archive      = {J_ISCI},
  author       = {Xiangjie Liu and Hao Zhang and Yuguang Niu and Deliang Zeng and Jizhen Liu and Xiaobing Kong and Kwang Y. Lee},
  doi          = {10.1016/j.ins.2020.03.019},
  journal      = {Information Sciences},
  pages        = {134-152},
  shortjournal = {Inf. Sci.},
  title        = {Modeling of an ultra-supercritical boiler-turbine system with stacked denoising auto-encoder and long short-term memory network},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic event-triggered actuator fault estimation and
accommodation for dynamical systems. <em>ISCI</em>, <em>525</em>,
119–133. (<a href="https://doi.org/10.1016/j.ins.2020.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the fault estimation and fault-tolerant control for a class of continuous-time dynamical systems with event-triggered communication mechanism. An internal dynamic variable is introduced into event-triggered scheme to reduce the amount of data transmission by enlarging the inter-event intervals. To enhance the reliability and safety of system, a fault/state estimation observer is adopted to estimate the injected fault signal and system state simultaneously, based on which a fault-tolerant controller is constructed to compensate the impact of actuator fault . A co-design criterion is derived to obtain the fault/state estimation observer, fault-tolerant controller and dynamic event-triggered mechanism, simultaneously. Furthermore, it is proved that the inter-event intervals of event generator are lower bounded by a positive scalar , which thus excludes Zeno phenomenon. Finally, a F-404 aircraft engine system is employed to demonstrate the effectiveness and superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xudong Wang and Zhongyang Fei and Tong Wang and Liu Yang},
  doi          = {10.1016/j.ins.2020.03.016},
  journal      = {Information Sciences},
  pages        = {119-133},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered actuator fault estimation and accommodation for dynamical systems},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can burrows-wheeler transform be replaced in chain code
compression? <em>ISCI</em>, <em>525</em>, 109–118. (<a
href="https://doi.org/10.1016/j.ins.2020.03.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burrows-Wheeler Transform, followed by Move-To-Front Transform, are often used transformation techniques in data compression . They may reduce the information entropy of the input sequence, which becomes more compressible in this way. This paper suggests an alternative, a Prediction-based Move-To-Front Transform, which may replace the aforementioned transformations. According to the context, consisting of a few already seen symbols, the Prediction-based Move-To-Front Transform selects an appropriate ordered domain of symbols to achieve a better match with the currently transforming symbol. Freeman chain code in four and eight directions, Three-Orthogonal chain code, and Vertex Chain Code were used for experiments. We confirmed that the proposed approach, when using an appropriate length of context, reduces the information entropy to a similar extent as the Burrows-Wheeler Transform followed by the Move-To-Front Transform on chain code data. Both approaches led to a very similar compression efficiency on 32 testing shapes when an arithmetic coder was used in the final stage. The proposed approach turned out to be more efficient when longer chain code sequences were used, obtained by merging all the testing chain codes of the same type.},
  archive      = {J_ISCI},
  author       = {Borut Žalik and Domen Mongus and Niko Lukač and Krista Rizman Žalik},
  doi          = {10.1016/j.ins.2020.03.073},
  journal      = {Information Sciences},
  pages        = {109-118},
  shortjournal = {Inf. Sci.},
  title        = {Can burrows-wheeler transform be replaced in chain code compression?},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-layer medical image fusion with tensor-based features.
<em>ISCI</em>, <em>525</em>, 93–108. (<a
href="https://doi.org/10.1016/j.ins.2020.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Replacing Computed tomography (CT) with magnetic resonance image (MRI), MRI- positron electron tomography (PET) or MRI- single photon emission computed tomography (SPECT) imaging might have further advantages due to higher soft-tissue contrast of brain structure and lower dose absorbed by the patient. In this paper, a new three-layer (intensity, detail, and base layers) medical image fusion method with differential features for gray and pseudo-color images is proposed. The proposed method includes three steps. At the first step, differential feature by structure tensor is used to decompose the anatomical MRI medical image into its three-layer image representation. On the other side, differential feature by color tensor is adopted to decompose the functional PET or SPECT medical image into its three-layer image representation. At the second step, spatial frequency metric is proposed to combine the decomposed intensity layers and detail layers and absolute maximum is defined as the image fusion rule of the base layers. At the third step, the fused image is obtained by the addition of the fused intensity layer, the fused detail layer, and the fused base layer. The superiority of the proposed method is demonstrated by subjective and objective evaluation on experimental results.},
  archive      = {J_ISCI},
  author       = {Jiao Du and Weisheng Li and Hengliang Tan},
  doi          = {10.1016/j.ins.2020.03.051},
  journal      = {Information Sciences},
  pages        = {93-108},
  shortjournal = {Inf. Sci.},
  title        = {Three-layer medical image fusion with tensor-based features},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time sensitivity-based popularity prediction for online
promotion on twitter. <em>ISCI</em>, <em>525</em>, 82–92. (<a
href="https://doi.org/10.1016/j.ins.2020.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, companies and individuals tend to use social media to publish information for promoting products and options. Although an increasing body of research has focused on promotional skills on social media, the role of post-publication time is rarely studied. However, publication time of a post plays an important role in its popularity. To select suitable publication times, an effective approach is to predict popularity values of a post when it is published at a series of future time points . However, this task is not trivial because, ( i ) except for publication time, all the features are inefficient, as they are the same, and ( ii ) the new model needs to output multiple popularity values for each input post. To address these challenges, we introduce a latent factor model to build a time sensitivity-based predictive model that can predict posts’ popularity values when they are published at various times. In this model, to alleviate data sparsity , we decompose posts into syntactic units that are derived from dependency parsing results. To take advantage of auxiliary information, we exploit the features of temporal information and neighborhood influence. Experiments with Twitter data demonstrate that the proposed model significantly outperforms state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Chunjing Xiao and Chun Liu and Ying Ma and Zheng Li and Xucheng Luo},
  doi          = {10.1016/j.ins.2020.03.056},
  journal      = {Information Sciences},
  pages        = {82-92},
  shortjournal = {Inf. Sci.},
  title        = {Time sensitivity-based popularity prediction for online promotion on twitter},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving mixed set operations. <em>ISCI</em>,
<em>525</em>, 67–81. (<a
href="https://doi.org/10.1016/j.ins.2020.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving set operations have important practical and theoretical significance and have always been a research focus of secure multiparty computation . Most existing studies focus on single set operations which cannot express many complicated set operations. However, the studies on mixed set operations are highly limited. The available protocols for mixed set operations can only be implemented through a threshold fully homomorphic encryption scheme . Since mixed set operations are necessary in practice, it is necessary to design an efficient and practical secure computation protocol for mixed set operations. In this paper, we propose a new protocol for mixed set operations that is based on a new encoding method and the threshold ElGamal cryptosystem . Through an efficiency analysis, it is proved that the efficiency of the protocol that is proposed in this paper are significantly higher than those of the available protocols.},
  archive      = {J_ISCI},
  author       = {Wenli Wang and Shundong Li and Jiawei Dou and Runmeng Du},
  doi          = {10.1016/j.ins.2020.03.049},
  journal      = {Information Sciences},
  pages        = {67-81},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving mixed set operations},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic resolution bounds of generalized modularity and
multi-scale community detection. <em>ISCI</em>, <em>525</em>, 54–66. (<a
href="https://doi.org/10.1016/j.ins.2020.03.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximization of generalized modularity performs well on networks in which the members of all communities are statistically indistinguishable from each other. However, there is no theory bounding the maximization performance in more realistic networks where edges are heterogeneously distributed within and between communities. Using the random graph properties, we establish asymptotic theoretical bounds on the resolution parameter for which the generalized modularity maximization performs well. From this new perspective on random graph model , we find the resolution limit of modularity maximization can be explained in a surprisingly simple and straightforward way. Given a network produced by the stochastic block models, the communities for which the resolution parameter is larger than their densities are likely to be spread among multiple clusters, while communities for which the resolution parameter is smaller than their background inter-community edge density will be merged into one large component. Therefore, no suitable resolution parameter exits when the intra-community edge density in a subgraph is lower than the inter-community edge density in some other subgraph. For such networks, we propose a progressive agglomerative heuristic algorithm to detect practically significant communities at multiple scales.},
  archive      = {J_ISCI},
  author       = {Xiaoyan Lu and Brendan Cross and Boleslaw K. Szymanski},
  doi          = {10.1016/j.ins.2020.03.082},
  journal      = {Information Sciences},
  pages        = {54-66},
  shortjournal = {Inf. Sci.},
  title        = {Asymptotic resolution bounds of generalized modularity and multi-scale community detection},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparative study of interval type-2 and general type-2
fuzzy systems in medical diagnosis. <em>ISCI</em>, <em>525</em>, 37–53.
(<a href="https://doi.org/10.1016/j.ins.2020.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, computer science has the ability of assisting experts in different application areas. Recently there has been increasing attention in the health area, and there exist different approaches based on artificial intelligence that have been proposed in the diagnosis of several kinds of diseases. In particular, fuzzy systems have been successfully used as Diagnosis Systems, in this way helping doctors to realize a faster and more accurate diagnosis. However, with the emergence of Type-2 Fuzzy Systems, there have been important improvements in handling the uncertainty with respect to traditional Fuzzy Systems (now called Type-1 Fuzzy Systems) in different kinds of problems. In the present paper, a new approach to Fuzzy Diagnosis based on Type-2 Fuzzy Systems is proposed and compared with respect to Type-1 Fuzzy Systems on a set of diagnosis problems, in order to evaluate the relevance of the uncertainty handling in this kind of problems. On the other hand, the paper is also aiming at observing the accuracy behavior in Fuzzy Diagnosis Systems by changing the uncertainty level in the models. Finally, a comparison of Interval Type-2 Fuzzy Systems with respect to General Type-2 Fuzzy Systems for a set of diagnosis problems is presented.},
  archive      = {J_ISCI},
  author       = {Emanuel Ontiveros and Patricia Melin and Oscar Castillo},
  doi          = {10.1016/j.ins.2020.03.059},
  journal      = {Information Sciences},
  pages        = {37-53},
  shortjournal = {Inf. Sci.},
  title        = {Comparative study of interval type-2 and general type-2 fuzzy systems in medical diagnosis},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). STMAG: A spatial-temporal mixed attention graph-based
convolution model for multi-data flow safety prediction. <em>ISCI</em>,
<em>525</em>, 16–36. (<a
href="https://doi.org/10.1016/j.ins.2020.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal safety forecasting has various applications in the neuroscience, climate and transportation domains . It is challenging due to (1) the complex spatial dependency on networks, (2) non-linear temporal dynamics with changing conditions and (3) the inherent difficulty of long-term forecasting. To address these challenges, a safety prediction model called the Spatial-Temporal Mixed Attention Graph-based Convolution model (STMAG) is proposed. Specifically, STMAG captures spatial dependency using graph convolutional networks (GCN), and temporal dependency using the sequence-to-sequence (Seq2Seq) architecture with the mixed attention mechanisms . A case study on the implementation of this model in traffic safety prediction is given as an example. Traffic safety forecasting is one canonical example of such a learning task, which is also a crucial problem to improving transportation and public safety. A number of detailed features (such as vehicle type, braking state, whether changing lanes or not) and exogenous variables (such as weather, time and road condition) are extracted from our big datasets . Finally, we conduct extensive experiments to evaluate the STMAG framework on real-world large-scale road network traffic datasets. Extensive experiments on our dataset show that the STMAG framework makes reasonably accurate predictions and significantly improves the prediction accuracy over baseline approaches.},
  archive      = {J_ISCI},
  author       = {Jingjuan Wang and Qingkui Chen and Huilin Gong},
  doi          = {10.1016/j.ins.2020.03.040},
  journal      = {Information Sciences},
  pages        = {16-36},
  shortjournal = {Inf. Sci.},
  title        = {STMAG: A spatial-temporal mixed attention graph-based convolution model for multi-data flow safety prediction},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). True scores for tartarus with adaptive GAs that evolve FSMs
on GPU. <em>ISCI</em>, <em>525</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2020.03.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Tartarus Problem is one of the candidate benchmark problems in evolutionary algorithms . We take advantage of the graphical processing unit (GPU) to improve the results of the software agents that use finite state machines (FSMs) for this benchmark. While doing so we also contribute to the study of the problem on several grounds. Similar to existing studies we use genetic algorithms to evolve FSMs, but unlike most of them we use adaptive operators for controlling the parameters of the algorithm. We show that the actual number of valid boards is not 297,040, but 74,760, because the agent is indifferent to the rotations of the board. We also show that the agent can only come across 383 different combinations, rather than 6561 that is used in the current literature. A final contribution is that we report the first true scores for the agents by testing them with all available 74,760 boards. Our best solution has a mean score of 8.5379 on all boards.},
  archive      = {J_ISCI},
  author       = {Kaya Oğuz},
  doi          = {10.1016/j.ins.2020.03.072},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {True scores for tartarus with adaptive GAs that evolve FSMs on GPU},
  volume       = {525},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of evolutionary computation for association rule
mining. <em>ISCI</em>, <em>524</em>, 318–352. (<a
href="https://doi.org/10.1016/j.ins.2020.02.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association Rule Mining (ARM) is a significant task for discovering frequent patterns in data mining. It has achieved great success in a plethora of applications such as market basket, computer networks, recommendation systems, and healthcare. In the past few years, evolutionary computation-based ARM has emerged as one of the most popular research areas for addressing the high computation time of traditional ARM. Although numerous papers have been published, there is no comprehensive analysis of existing evolutionary ARM methodologies. In this paper, we review emerging research of evolutionary computation for ARM. We discuss the applications on evolutionary computations for different types of ARM approaches including numerical rules, fuzzy rules, high-utility itemsets, class association rules, and rare association rules. Evolutionary ARM algorithms were classified into four main groups in terms of the evolutionary approach, including evolution-based, swarm intelligence-based, physics-inspired , and hybrid approaches . Furthermore, we discuss the remaining challenges of evolutionary ARM and discuss its applications and future topics.},
  archive      = {J_ISCI},
  author       = {Akbar Telikani and Amir H. Gandomi and Asadollah Shahbahrami},
  doi          = {10.1016/j.ins.2020.02.073},
  journal      = {Information Sciences},
  pages        = {318-352},
  shortjournal = {Inf. Sci.},
  title        = {A survey of evolutionary computation for association rule mining},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive image coding efficiency enhancement using deep
convolutional neural networks. <em>ISCI</em>, <em>524</em>, 298–317. (<a
href="https://doi.org/10.1016/j.ins.2020.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the application of systems for the storage and transmission of images has faced severe challenges owing to the significant increase in the number of images being generated and sent. Therefore, it is necessary to enhance the efficiency of existing coding approaches while maintaining compatibility. This paper proposes an adaptive image coding efficiency enhancement framework that innovatively integrates deep network-based super-resolution (SR) and soft-decoding (SD) into image coding. To address the problem of insufficient number of coding bits at high compression ratios, the given image is downsampled prior to encoding, and the decoded image is super-resolved in the proposed low-resolution coding mode. For the full-resolution coding mode developed for medium or low compression ratios, the given image is directly encoded and the decoded image is enhanced by suppressing the compression noise. To efficiently determine the optimal coding mode of a given image, an adaptive mode decision strategy is proposed by modeling the relationship between the critical coding quality parameter and the distortion caused by successive downsampling and upsampling processes. Experimental results show that the proposed algorithm significantly improves the performance of the widely used image coding standard JPEG, demonstrating the effectiveness of the SR and SD-enabled coding framework.},
  archive      = {J_ISCI},
  author       = {Honggang Chen and Xiaohai He and Cheolhong An and Truong Q. Nguyen},
  doi          = {10.1016/j.ins.2020.03.042},
  journal      = {Information Sciences},
  pages        = {298-317},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive image coding efficiency enhancement using deep convolutional neural networks},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). All-relevant feature selection using multidimensional
filters with exhaustive search. <em>ISCI</em>, <em>524</em>, 277–297.
(<a href="https://doi.org/10.1016/j.ins.2020.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a method for the identification of informative variables in an information system with discrete decision variables. It is targeted specifically towards the discovery of variables that are non-informative when considered alone, but informative when the synergistic interactions between multiple variables are considered. To this end, mutual entropy of all possible k-tuples of variables with a decision variable is computed. Then, for each variable, the maximum information gain due to interactions with other variables is obtained. For non-informative variables, this quantity conforms to well-known statistical distributions. This allows for discerning the truly informative variables from the non-informative ones. To demonstrate this approach, the method is applied to several synthetic datasets that involve complex multidimensional interactions between variables. The performance of the method is also validated on a real-world dataset. It is shown that the method is capable of identifying the most important informative variables, even when the dimensionality of the analysis is smaller than the true dimensionality of the problem. What is more, the high sensitivity of the algorithm allows for the detection of the influence of nuisance variables on the response variable.},
  archive      = {J_ISCI},
  author       = {Krzysztof Mnich and Witold R. Rudnicki},
  doi          = {10.1016/j.ins.2020.03.024},
  journal      = {Information Sciences},
  pages        = {277-297},
  shortjournal = {Inf. Sci.},
  title        = {All-relevant feature selection using multidimensional filters with exhaustive search},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event evolution model for cybersecurity event mining in
tweet streams. <em>ISCI</em>, <em>524</em>, 254–276. (<a
href="https://doi.org/10.1016/j.ins.2020.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rich source of online reports and discussions on social media can be leveraged to investigate the widespread cyber-attacks. In this paper, we study the problem of cybersecurity event mining based on continuous tweet streams. In contrast to traditional static methods that do not consider event evolution, we explore relevance among historical and online events for cyber-attack event discovery and evolution detection. We propose CyberEM , a novel event evolution model with a special focus on cybersecurity events. A pattern clustering algorithm and an NMF-based (non-negative matrix factorization) event aggregation algorithm are devised for cyber-attack indicator extraction and event evolution detection. We leverage both the patterns that belong to the cybersecurity domain and the patterns of the semantic contexts of cybersecurity to refine evolutionary relevance of events across multiple time intervals . Furthermore, we design a dynamic event inference algorithm to discover cybersecurity events and update event aggregation in an online manner. Through extensive evaluations with a large-scale real-world tweet dataset, we demonstrate the superiority of the proposed CyberEM model over existing methods in identifying cybersecurity events and their evolutionary relevance.},
  archive      = {J_ISCI},
  author       = {Xiuwen Liu and Jianming Fu and Yanjiao Chen},
  doi          = {10.1016/j.ins.2020.03.048},
  journal      = {Information Sciences},
  pages        = {254-276},
  shortjournal = {Inf. Sci.},
  title        = {Event evolution model for cybersecurity event mining in tweet streams},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Framework based on communicability to measure the
similarity of nodes in complex networks. <em>ISCI</em>, <em>524</em>,
241–253. (<a href="https://doi.org/10.1016/j.ins.2020.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structural properties of network system components often display strikingly similar behavior when probed at a macroscopic perspective . Those structural properties, largely determining their dynamic behavior, are revealed by the mesoscopic structure of the underlying networks. To demonstrate this empirical conclusion, it is necessary to develop a set of tools to accurately quantify the structural similarity between network nodes. In this paper, we propose a method to measure nodes’ similarity based on network communicability. Precisely, the approach takes Jensen-Shannon divergence between the communicability sequences of nodes as the difference measure and then obtains the similarity between nodes. We use some real-world networks and artificial networks as test objects, and evaluate the rationality of the method through the topological structure behavior and dynamical behavior of similar nodes respectively. Interestingly, the similar nodes obtained in our framework have very similar dynamical behaviors, which is crucial because the dynamic behaviors of nodes are highly dependent on the mesoscopic structure of the underlying networks. Furthermore, compared with previous methods, the method presented in this paper can more accurately quantify the similarity between nodes from a global perspective.},
  archive      = {J_ISCI},
  author       = {Dan Chen and Housheng Su and Gui-Jun Pan},
  doi          = {10.1016/j.ins.2020.03.046},
  journal      = {Information Sciences},
  pages        = {241-253},
  shortjournal = {Inf. Sci.},
  title        = {Framework based on communicability to measure the similarity of nodes in complex networks},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust contour detection operator with combined push-pull
inhibition and surround suppression. <em>ISCI</em>, <em>524</em>,
229–240. (<a href="https://doi.org/10.1016/j.ins.2020.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contour detection is a salient operation in many computer vision applications as it extracts features that are important for distinguishing objects in scenes. It is believed to be a primary role of simple cells in visual cortex of the mammalian brain . Many of such cells receive push-pull inhibition or surround suppression. We propose a computational model that exhibits a combination of these two phenomena. It is based on two existing models, which have been proven to be very effective for contour detection. In particular, we introduce a brain-inspired contour operator that combines push-pull and surround inhibition. It turns out that this combination results in a more effective contour detector, which suppresses texture while keeping the strongest responses to lines and edges, when compared to existing models. The proposed model consists of a Combination of Receptive Field (or CORF) model with push-pull inhibition, extended with surround suppression. We demonstrate the effectiveness of the proposed approach on the RuG and Berkeley benchmark data sets of 40 and 500 images, respectively. The proposed push-pull CORF operator with surround suppression outperforms the one without suppression with high statistical significance.},
  archive      = {J_ISCI},
  author       = {Damiano Melotti and Kevin Heimbach and Antonio Rodríguez-Sánchez and Nicola Strisciuglio and George Azzopardi},
  doi          = {10.1016/j.ins.2020.03.026},
  journal      = {Information Sciences},
  pages        = {229-240},
  shortjournal = {Inf. Sci.},
  title        = {A robust contour detection operator with combined push-pull inhibition and surround suppression},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parallel computing method based on zeroing neural networks
for time-varying complex-valued matrix moore-penrose inversion.
<em>ISCI</em>, <em>524</em>, 216–228. (<a
href="https://doi.org/10.1016/j.ins.2020.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the existing zeroing neural network (ZNN) models from the perspective of control theory . It proposes an exclusive ZNN model for solving the dynamic complex-valued matrix Moore-Penrose inverse problem: the complex-valued zeroing neural network (CVZNN). Then, a method of constructing a special type of saturation-allowed activation function is defined, which relaxes the convex constraint on the activation function when constructing the ZNN model. The convergence of the CVZNN model activated by proposed saturation-allowed functions is analyzed. Besides, the robustness of the CVZNN model under different types of noise interference is investigated based on the perspective of the control theory . Finally, the effectiveness and superiority of the CVZNN model are illustrated by simulation experiments.},
  archive      = {J_ISCI},
  author       = {Xiuchun Xiao and Chengze Jiang and Huiyan Lu and Long Jin and Dazhao Liu and Haoen Huang and Yi Pan},
  doi          = {10.1016/j.ins.2020.03.043},
  journal      = {Information Sciences},
  pages        = {216-228},
  shortjournal = {Inf. Sci.},
  title        = {A parallel computing method based on zeroing neural networks for time-varying complex-valued matrix moore-penrose inversion},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the zeros of the partial hosoya polynomial of graphs.
<em>ISCI</em>, <em>524</em>, 199–215. (<a
href="https://doi.org/10.1016/j.ins.2020.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The partial Hosoya polynomial (or briefly the partial H -polynomial) can be used to construct the well-known Hosoya polynomial. The i th coefficient of this polynomial, defined for an arbitrary vertex u of a graph G , is the number of vertices at distance i from u . The aim of this paper is to determine the partial H -polynomial of several well-known graphs and, then, to investigate the location of their zeros. To pursue, we characterize the structure of graphs with the minimum and the maximum modulus of the zeros of partial H -polynomial. Finally, we define another graph polynomial of the partial H -polynomial, see [9]. Also, we determine the unique positive root of this polynomial for particular graphs.},
  archive      = {J_ISCI},
  author       = {Modjtaba Ghorbani and Matthias Dehmer and Shujuan Cao and Lihua Feng and Jin Tao and Frank Emmert-Streib},
  doi          = {10.1016/j.ins.2020.03.011},
  journal      = {Information Sciences},
  pages        = {199-215},
  shortjournal = {Inf. Sci.},
  title        = {On the zeros of the partial hosoya polynomial of graphs},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leximax minimum solution of addition-min fuzzy relation
inequalities. <em>ISCI</em>, <em>524</em>, 184–198. (<a
href="https://doi.org/10.1016/j.ins.2020.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addition-min fuzzy relation inequalities are introduced to characterize the Peer-to-Peer (P2P) network system. In order to decrease the network congestion , considering both efficiency and fairness, we define the leximax minimum solution for system of addition-min fuzzy relation inequalities. The leximax-optimality refines both Pareto-optimality and max-optimality. For solving the leximax minimum solution, concepts of minimum zero point and minimax value are defined, with corresponding resolution algorithms, i.e. Algorithms I and II. Based on these two algorithms, Algorithm III is further developed to find the unique leximax minimum solution. Numerical examples illustrate the validity of our proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Xiao-Peng Yang},
  doi          = {10.1016/j.ins.2020.03.047},
  journal      = {Information Sciences},
  pages        = {184-198},
  shortjournal = {Inf. Sci.},
  title        = {Leximax minimum solution of addition-min fuzzy relation inequalities},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A knowledge reduction approach for linguistic concept formal
context. <em>ISCI</em>, <em>524</em>, 165–183. (<a
href="https://doi.org/10.1016/j.ins.2020.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal concept analysis (FCA) has been widely studied as an important tool for data processing and knowledge discovery. The present work focuses on FCA under uncertainty while the attributes are described with linguistic terms or attribute description are incomplete. Accordingly, a linguistic concept formal context is introduced first. With an attempt of knowledge reduction, the multi-granularity similarity relationship between linguistic concepts is defined on the basis of granular computing which further divides the linguistic concept set into three parts under λ-granularity (i.e., core linguistic concept, unnecessary linguistic concept, and relative necessary linguistic concept). A multi-granularity linguistic reduction algorithm of incomplete linguistic concept formal context is then introduced. To handle the incompleteness, a new algorithm to complete the incomplete linguistic concept formal context based on the closeness degree between fuzzy objects is proposed. Finally, based on the Boolean matrix and Boolean factor analysis method, the linguistic concept knowledge reduction algorithm to extract the core linguistic concept and reduce the scale of linguistic concept lattice is proposed to handle the complexity, which is achieved by computing the similarity of linguistic concept knowledge in order to handle different types of linguistic information and concept knowledge. The effectiveness and practicability of the proposed model are illustrated by examples.},
  archive      = {J_ISCI},
  author       = {Li Zou and Kuo Pang and Xiaoying Song and Ning Kang and Xin Liu},
  doi          = {10.1016/j.ins.2020.03.002},
  journal      = {Information Sciences},
  pages        = {165-183},
  shortjournal = {Inf. Sci.},
  title        = {A knowledge reduction approach for linguistic concept formal context},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint specific and correlated information exploration for
multi-view action clustering. <em>ISCI</em>, <em>524</em>, 148–164. (<a
href="https://doi.org/10.1016/j.ins.2020.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action clustering is crucial in many practical applications. However, existing action clustering methods work in a single-view manner, which always ignore the relationships among different views and fail to discover correct clusters as the viewpoint and position change. To address the challenges, we propose a unified framework for multi-view human action clustering. First, we design a new Bag-of-Shared-Words (BoSW) model to discover the view-shared visual words that preserve the consistency among visual words of different views. Then, we obtain a more discriminative feature representation, from which the view correlation can be fully explored. Then, we present a novel JOint INformation boTtleneck (JOINT) algorithm to jointly exploit both the view-specific and view-correlated information to improve the action clustering performance. Specifically, JOINT formulates the problem as minimizing an information loss function, which compresses the actions of each view while jointly preserving the complementary view-specific information and correlated information among views. To solve the proposed objective function, a new sequential procedure is presented to guarantee convergence to a local optimal solution . Extensive experiments on three challenging multi-view single-person and interactive action datasets demonstrate the superiority of our algorithm.},
  archive      = {J_ISCI},
  author       = {Shizhe Hu and Xiaoqiang Yan and Yangdong Ye},
  doi          = {10.1016/j.ins.2020.03.029},
  journal      = {Information Sciences},
  pages        = {148-164},
  shortjournal = {Inf. Sci.},
  title        = {Joint specific and correlated information exploration for multi-view action clustering},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-based networked predictive control for networked
control systems subject to two-channel delays. <em>ISCI</em>,
<em>524</em>, 136–147. (<a
href="https://doi.org/10.1016/j.ins.2020.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with a new combination of the event-triggered scheme and the networked predictive control technique for the networked control systems (NCSs) subject to time delays in both sensor-to-controller and controller-to-actuator channels. Firstly, the output-based Luenberger observer is designed for the considered NCSs. Secondly, in order to stabilize the NCSs, the model-based networked predictive control technique is proposed to compensate for the network-induced two-channel delays. Next, two different analysis frameworks are presented, and sufficient conditions for the asymptotic stability of the resulting closed-loop systems are obtained, respectively. Particularly, the proposed event-triggered scheme based on the measured outputs and the state predictions have considerably reduced the times of data transmission over the bandwidth-limited communication networks. Finally, an example of the buck DC-DC converter system is provided to demonstrate the effectiveness of the developed method.},
  archive      = {J_ISCI},
  author       = {Rongni Yang and Yaru Yu and Jian Sun and Hamid Reza Karimi},
  doi          = {10.1016/j.ins.2020.03.031},
  journal      = {Information Sciences},
  pages        = {136-147},
  shortjournal = {Inf. Sci.},
  title        = {Event-based networked predictive control for networked control systems subject to two-channel delays},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-dimensional count data clustering based on an
exponential approximation to the multinomial beta-liouville
distribution. <em>ISCI</em>, <em>524</em>, 116–135. (<a
href="https://doi.org/10.1016/j.ins.2020.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a mixture model for high-dimensional count data clustering based on an exponential-family approximation of the Multinomial Beta-Liouville distribution, which we call EMBL. We deal simultaneously with the problems of fitting the model to observed data and selecting the number of components. The learning algorithm automatically selects the optimal number of components and avoids several drawbacks of the standard Expectation-Maximization algorithm, including the sensitivity to initialization and possible convergence to the boundary of the parameter space. We demonstrate the effectiveness and robustness of the proposed clustering approach through a set of extensive empirical experiments that involve challenging real-world applications. The results reveal that the novel proposed model strives to achieve higher accuracy compared to the state-of-the-art generative models for count data clustering . Furthermore, the superior performance of EMBL demonstrates its flexibility and ability to address the burstiness phenomenon successfully, as well as shows its computational efficiency, especially when dealing with sparse high-dimensional vectors.},
  archive      = {J_ISCI},
  author       = {Nuha Zamzami and Nizar Bouguila},
  doi          = {10.1016/j.ins.2020.03.028},
  journal      = {Information Sciences},
  pages        = {116-135},
  shortjournal = {Inf. Sci.},
  title        = {High-dimensional count data clustering based on an exponential approximation to the multinomial beta-liouville distribution},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge and approximations: A formal study under the
perspective of information systems and rough set theory. <em>ISCI</em>,
<em>524</em>, 97–115. (<a
href="https://doi.org/10.1016/j.ins.2020.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we aim to bring together the operators of epistemic logic and approximation operators of rough set theory by combining the ideas from epistemic logic and rough set logics. The possible world semantics of epistemic logic is extended to capture a situation where we have a set of states, each representing a possible state of affairs and carrying information about a set of objects regarding a set of attributes. We propose a logic that can be used to reason about the knowledge operator as well as the approximation operators generated from the constituent information systems relative to different set of attributes. The important issues of the proposed logic viz. sound and complete deductive systems with respect to various classes of models are also addressed.},
  archive      = {J_ISCI},
  author       = {Md. Aquil Khan and Vineeta Singh Patel},
  doi          = {10.1016/j.ins.2020.03.017},
  journal      = {Information Sciences},
  pages        = {97-115},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge and approximations: A formal study under the perspective of information systems and rough set theory},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making based on acceptable multiplicative
consistency of hesitant fuzzy preference relations. <em>ISCI</em>,
<em>524</em>, 77–96. (<a
href="https://doi.org/10.1016/j.ins.2020.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with group decision making (GDM) with hesitant fuzzy preference relations (HFPRs) based on the acceptable multiplicative consistency and the consensus analysis. We first offer a multiplicative consistency index for fuzzy preference relations (FPRs) and then use the Monte Carlo simulation method to derive the average multiplicative consistency value. After that, a model-based interactive algorithm is offered to test acceptable multiplicative consistency of HFPRs, by which the concept of acceptable multiplicative consistency for HFPRs is obtained. Meanwhile, a model-based interactive algorithm for deriving acceptable multiplicative consistent HFPRs from unacceptable multiplicative consistent ones is provided, where both the total adjustment and the number of adjusted variables are considered. As for incomplete HFPRs, a model-based interactive algorithm for getting the values of missing preferences is provided. Furthermore, the weights of the decision makers are determined by the offered model and an algorithm of model-based adjustment for the consensus level is provided. Finally, a procedure for GDM with acceptable multiplicative consistent HFPRs is given, and a case study about selecting the most suitable project management information systems (PMISs) is provided to show the application of the proposed GDM method and to compare the proposed GDM method with the previous GDM methods.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen and Jie Tang},
  doi          = {10.1016/j.ins.2020.03.037},
  journal      = {Information Sciences},
  pages        = {77-96},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on acceptable multiplicative consistency of hesitant fuzzy preference relations},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kernel truncated regression representation for robust
subspace clustering. <em>ISCI</em>, <em>524</em>, 59–76. (<a
href="https://doi.org/10.1016/j.ins.2020.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering aims to group data points into multiple clusters of which each corresponds to one subspace. Most existing subspace clustering approaches assume that input data lie on linear subspaces . In practice, however, this assumption usually does not hold. To achieve nonlinear subspace clustering, we propose a novel method, called kernel truncated regression representation. Our method consists of the following four steps: 1) projecting the input data into a hidden space, where each data point can be linearly represented by other data points; 2) calculating the linear representation coefficients of the data representations in the hidden space; 3) truncating the trivial coefficients to achieve robustness and block-diagonality; and 4) executing the graph cutting operation on the coefficient matrix by solving a graph Laplacian problem. Our method has the advantages of a closed-form solution and the capacity of clustering data points that lie on nonlinear subspaces. The first advantage makes our method efficient in handling large-scale datasets, and the second one enables the proposed method to conquer the nonlinear subspace clustering challenge. Extensive experiments on six benchmarks demonstrate the effectiveness and the efficiency of the proposed method in comparison with current state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Liangli Zhen and Dezhong Peng and Wei Wang and Xin Yao},
  doi          = {10.1016/j.ins.2020.03.033},
  journal      = {Information Sciences},
  pages        = {59-76},
  shortjournal = {Inf. Sci.},
  title        = {Kernel truncated regression representation for robust subspace clustering},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Code analysis for intelligent cyber systems: A data-driven
approach. <em>ISCI</em>, <em>524</em>, 46–58. (<a
href="https://doi.org/10.1016/j.ins.2020.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber code analysis is fundamental to malware detection and vulnerability discovery for defending cyber attacks . Traditional approaches resorting to manually defined rules are gradually replaced by automated approaches empowered by machine learning . This revolution is accelerated by big code from open source projects which support machine learning models with outstanding performance. In the context of a data-driven paradigm, this paper reviews recent analytic research on cyber code of malicious and common software by using a set of common concepts of similarity, correlation and collective indication. Sharing security goals in recognizing anomalous code that may be malicious or vulnerable. The ability to do so is not determined in isolation, rather drawn for code correlation and context awareness . This paper demonstrates a new research methodology of data driven cyber security (DDCS) and its application in cyber code analysis. The framework of the DDCS methodology consists of three components, i.e., cyber security data processing, cyber security feature engineering, and cyber security modeling. Some challenging issues are suggested to direct the future research.},
  archive      = {J_ISCI},
  author       = {Rory Coulter and Qing-Long Han and Lei Pan and Jun Zhang and Yang Xiang},
  doi          = {10.1016/j.ins.2020.03.036},
  journal      = {Information Sciences},
  pages        = {46-58},
  shortjournal = {Inf. Sci.},
  title        = {Code analysis for intelligent cyber systems: A data-driven approach},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered static/dynamic feedback control for
discrete-time linear systems. <em>ISCI</em>, <em>524</em>, 33–45. (<a
href="https://doi.org/10.1016/j.ins.2020.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper visits the design of event-triggered static and dynamic feedback controllers for discrete-time linear systems. For the efficiency of energy, we make the first attempt to devise a switching event-triggered mechanism (ETM) which is characterized by a switching between the discrete-time sampled-data control and the common continuous ETM. In this sense, the event detector has a waiting time interval after sending a sampling signal. This method facilitates to enlarge the lower bound of inter-execution intervals so that the number of samplings can be reduced essentially. The issue of actuator saturation is also considered in this paper. By generalized sector condition, a switching Lyapunov functional is constructed to derive the sufficient conditions such that the discrete-time linear systems are local stable. Based on the stability conditions, the calculation methods are provided to solve both the desired control gains and the triggering parameters. Finally, numerical simulations are given to validate the effectiveness and superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Sanbo Ding and Xiangpeng Xie and Yajuan Liu},
  doi          = {10.1016/j.ins.2020.03.044},
  journal      = {Information Sciences},
  pages        = {33-45},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered static/dynamic feedback control for discrete-time linear systems},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SiTGRU: Single-tunnelled gated recurrent unit for
abnormality detection. <em>ISCI</em>, <em>524</em>, 15–32. (<a
href="https://doi.org/10.1016/j.ins.2020.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormality detection is a challenging task due to the dependence on a specific context and the unconstrained variability of practical scenarios. In recent years, it has benefited from the powerful features learnt by deep neural networks , and handcrafted features specialized for abnormality detectors. However, these approaches with large complexity still have limitations in handling long-term sequential data (e.g., videos), and their learnt features do not thoroughly capture useful information. Recurrent Neural Networks (RNNs) have been shown to be capable of robustly dealing with temporal data in long-term sequences. In this paper, we propose a novel version of Gated Recurrent Unit (GRU), called Single-Tunnelled GRU for abnormality detection. Particularly, the Single-Tunnelled GRU discards the heavy-weighted reset gate from GRU cells that overlooks the importance of past content by only favouring current input to obtain an optimized single-gated-cell model. Moreover, we substitute the hyperbolic tangent activation in standard GRUs with sigmoid activation, as the former suffers from performance loss in deeper networks. Empirical results show that our proposed optimized-GRU model outperforms standard GRU and Long Short-Term Memory (LSTM) networks on most metrics for detection and generalization tasks on CUHK Avenue and UCSD datasets. The model is also computationally efficient with reduced training and testing time over standard RNNs.},
  archive      = {J_ISCI},
  author       = {Habtamu Fanta and Zhiwen Shao and Lizhuang Ma},
  doi          = {10.1016/j.ins.2020.03.034},
  journal      = {Information Sciences},
  pages        = {15-32},
  shortjournal = {Inf. Sci.},
  title        = {SiTGRU: Single-tunnelled gated recurrent unit for abnormality detection},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge extraction from deep convolutional neural networks
applied to cyclo-stationary time-series classification. <em>ISCI</em>,
<em>524</em>, 1–14. (<a
href="https://doi.org/10.1016/j.ins.2020.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modelling complex processes from raw time series increases the necessity to build Deep Learning (DL) architectures that can manage this type of data structure . However, as DL models become deeper, larger and more diverse datasets are necessary and knowledge extraction will become more difficult. In an attempt to sidestep these issues, in this paper a methodology based on two main steps is presented, the first being to increase size and diversity of time-series datasets for training, and the second to retrieve knowledge from the obtained model. This methodology is compared with other approaches reported in the literature and is tested under two configuration setups of Condition-Based Maintenance problems: fault diagnosis of bearing, and fault severity assessment of a helical gearbox, obtaining not only a performance improvement in comparison, but also in retrieving knowledge about how the signals are being classified.},
  archive      = {J_ISCI},
  author       = {Diego Cabrera and Fernando Sancho and Mariela Cerrada and René-Vinicio Sánchez and Chuan Li},
  doi          = {10.1016/j.ins.2020.03.039},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge extraction from deep convolutional neural networks applied to cyclo-stationary time-series classification},
  volume       = {524},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Haze pollution causality mining and prediction based on
multi-dimensional time series with PS-FCM. <em>ISCI</em>, <em>523</em>,
307–317. (<a href="https://doi.org/10.1016/j.ins.2020.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze has become a frequent disastrous weather condition in China. Its formation consists of evolution process of several pollutants in certain meteorological conditions with complex relationships among these factors of haze formation. How to explore the complex relationships among these multi-dimensional factors as well as effectively predict them have become a key issue in research community. The research in this paper presents a method to quantitatively reveal causality in the formation of haze, which can be used to effectively predict haze pollution. In order to make the complicated relationship among different factors be interpretable, an PS-FCM (Primary Sub-Fuzzy Cognitive Maps) model is proposed and its multi-dimensional causality solution is demonstrated. By considering the formation of haze as an evolving process with time, we explore and discover the causality based on time series data of haze pollution with PS-FCM. Thus, a multi-dimensional time series data mining method based on the PS-FCM is developed to investigate the formation of haze. We validate our model by comparing with other machine learning method via experimental data and discuss the performance of PS-FCM under different transformation functions. The results explicitly show the quantitative causality among the different factors in haze formation.},
  archive      = {J_ISCI},
  author       = {Zhen Peng and Wanquan Liu and Senjian An},
  doi          = {10.1016/j.ins.2020.03.012},
  journal      = {Information Sciences},
  pages        = {307-317},
  shortjournal = {Inf. Sci.},
  title        = {Haze pollution causality mining and prediction based on multi-dimensional time series with PS-FCM},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantization-based event-triggered sliding mode tracking
control of mechanical systems. <em>ISCI</em>, <em>523</em>, 296–306. (<a
href="https://doi.org/10.1016/j.ins.2020.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of the quantization-based event-triggered sliding mode tracking control for mechanical systems . Only the quantized values of measurement outputs and control inputs are transmitted to the controller and actuator sides, respectively. Furthermore, the event-triggering mechanism is located in the controller side and specific events are monitored by using quantized states to determine whether or not the control command should be transmitted. The quantization effect on the selected triggering threshold is analyzed. By using the sliding mode control (SMC) method, the sufficient condition for the stability of the system is given. The quasi-sliding mode band that is caused by quantization and event trigger is introduced for the first time. The proposed method guarantees the uniform ultimate boundedness of the tracking error and ensures the non-accumulation of inter-execution times. Simulation results illustrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yan Yan and Shuanghe Yu and Changyin Sun},
  doi          = {10.1016/j.ins.2020.03.023},
  journal      = {Information Sciences},
  pages        = {296-306},
  shortjournal = {Inf. Sci.},
  title        = {Quantization-based event-triggered sliding mode tracking control of mechanical systems},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TpSpMV: A two-phase large-scale sparse matrix-vector
multiplication kernel for manycore architectures. <em>ISCI</em>,
<em>523</em>, 279–295. (<a
href="https://doi.org/10.1016/j.ins.2020.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse matrix-vector multiplication (SpMV) is one of the important subroutines in numerical linear algebras widely used in lots of large-scale applications. Accelerating SpMV on multicore and manycore architectures based on Compressed Sparse Row (CSR) format via row-wise parallelization is one of the most popular directions. However, there are three main challenges in optimizing parallel CSR-based SpMV: (a) limited local memory of each computing unit can be overwhelmed by assignments to long rows of large-scale sparse matrices; (b) irregular accesses to the input vector result in expensive memory access latency ; (c) sparse data structure leads to low bandwidth usage. This paper proposes a two-phase large-scale SpMV, called tpSpMV , based on the memory structure and computing architecture of multicore and manycore architectures to alleviate the three main difficulties. First, we propose the two-phase parallel execution technique for tpSpMV that performs parallel CSR-based SpMV into two separate phases to overcome the computational scale limitation. Second, we respectively propose the adaptive partitioning methods and parallelization designs using the local memory caching technique for the two phases to exploit the architectural advantages of the high-performance computing platforms and alleviate the problem of high memory access latency . Third, we design several optimizations, such as data reduction, aligned memory accessing, and pipeline technique, to improve bandwidth usage and optimize tpSpMV ’s performance. Experimental results on SW26010 CPUs of the Sunway TaihuLight supercomputer prove that tpSpMV achieves up to 28.61 speedups and yields the performance improvement of 13.16\% over the state-of-the-art work on average.},
  archive      = {J_ISCI},
  author       = {Yuedan Chen and Guoqing Xiao and Fan Wu and Zhuo Tang and Keqin Li},
  doi          = {10.1016/j.ins.2020.03.020},
  journal      = {Information Sciences},
  pages        = {279-295},
  shortjournal = {Inf. Sci.},
  title        = {TpSpMV: A two-phase large-scale sparse matrix-vector multiplication kernel for manycore architectures},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge modeling via contextualized representations for
LSTM-based personalized exercise recommendation. <em>ISCI</em>,
<em>523</em>, 266–278. (<a
href="https://doi.org/10.1016/j.ins.2020.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent education systems have enabled personalized learning (PL). In PL, students are presented with educational contents that are consistent with their personal knowledge states (KS), and the critical task is accurately estimating these states through data. Knowledge tracing (KT) infers KS (latent) through historical student interactions (observed) with the knowledge components (KCs). A wide variety of KT techniques have been developed, from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT). However, in most of these methods, the KCs are represented as stand-alone entities, and the effect of representing KCs using contexts such as learning-related factors has been under-investigated. Also, KT needs to generate personalized results to facilitate tasks such as exercise recommendation. In this paper, we propose two approaches that use a contextualized representation of KCs, one with a content-based approach and another with a Long Short Term Memory (LSTM) network plus a personalization mechanism. By performing extensive experiments on two real-world datasets, results show not only a tangible improvement in prediction accuracy in the KT task compared to existing methods, but also its effectiveness in improving the recommendation precision.},
  archive      = {J_ISCI},
  author       = {Yujia Huo and Derek F. Wong and Lionel M. Ni and Lidia S. Chao and Jing Zhang},
  doi          = {10.1016/j.ins.2020.03.014},
  journal      = {Information Sciences},
  pages        = {266-278},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge modeling via contextualized representations for LSTM-based personalized exercise recommendation},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective feature selection using hybridization of a
genetic algorithm and direct multisearch for key quality characteristic
selection. <em>ISCI</em>, <em>523</em>, 245–265. (<a
href="https://doi.org/10.1016/j.ins.2020.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-objective feature selection approach for selecting key quality characteristics (KQCs) of unbalanced production data is proposed. We define KQC (feature) selection as a bi-objective problem of maximizing the quality characteristic (QC) subset importance and minimizing the QC subset size. Three candidate feature importance measures, the geometric mean (GM), F 1 score and accuracy, are applied to construct three KQC selection models. To solve the models, a two-phase optimization method for selecting the candidate solutions (QC subsets) using a novel multi-objective optimization method (GADMS) and the final KQC set from the candidate solutions using the ideal point method (IPM) is proposed. GADMS is a hybrid method composed of a genetic algorithm (GA) and a local search strategy named direct multisearch (DMS). In GADMS, we combine binary encoding with real value encoding to utilize the advantages of GAs and DMS. The experimental results on four production datasets show that the proposed method with GM performs the best in handling the data imbalance problem and outperforms the benchmark methods. Moreover, GADMS obtains significantly better search performance than the benchmark multi-objective optimization methods, which include a modified nondominated sorting genetic algorithm II (NSGA-II), two multi-objective particle swarm optimization algorithms and an improved DMS method.},
  archive      = {J_ISCI},
  author       = {An-Da Li and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.ins.2020.03.032},
  journal      = {Information Sciences},
  pages        = {245-265},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective feature selection using hybridization of a genetic algorithm and direct multisearch for key quality characteristic selection},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Processing knowledge graph-based complex questions through
question decomposition and recomposition. <em>ISCI</em>, <em>523</em>,
234–244. (<a href="https://doi.org/10.1016/j.ins.2020.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, question answering (QA) over complex questions is the most spotlighted research topic in diverse communities. Different from existing QA approaches for simple questions that require a single relation in a knowledge graph (KG) to find an answer set, QA for complex questions requires to process multiple KG relations . Complex questions often include some representations for constraints (ordinal, temporal, etc.) that restrict an answer set for the given question. Despite lots of efforts to process such questions, there are still limitations in processing constraints, multiple relations, and variables. To solve the issues, we propose a novel QA method that first decomposes an input question and then generates a correct query graph with fully complete semantics. In order to fill with lossy semantics caused by the decomposition task , the proposed method employs Bi-GRU based model. The model integrates individual compositional semantics of sub-query graphs matched to decomposed sub-questions. Experimental results show the best performance compared to the state-of-art on complex questions.},
  archive      = {J_ISCI},
  author       = {Sangjin Shin and Kyong-Ho Lee},
  doi          = {10.1016/j.ins.2020.02.065},
  journal      = {Information Sciences},
  pages        = {234-244},
  shortjournal = {Inf. Sci.},
  title        = {Processing knowledge graph-based complex questions through question decomposition and recomposition},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Natural language modeling with syntactic structure
dependency. <em>ISCI</em>, <em>523</em>, 220–233. (<a
href="https://doi.org/10.1016/j.ins.2020.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In natural language, the relationship among the constituents of a sentence is usually tree-like: words, phrases, and clauses constitute a sentence hierarchically, and the dependency between different constituents induces the syntactic structure. Such a complex tree-like structure is vital for understanding natural languages . However, recurrent neural networks (RNNs) model languages sequentially and fail to encode a hierarchical syntactic dependency comprehensively, therefore causing the networks to underperform on comprehension-based tasks. In this paper, we propose a novel neural language model , called relative syntactic distance LSTM (RSD-LSTM), to capture the syntactic structure dependency dynamically. RSD-LSTM employs a convolutional neural network to compute the relative syntactic distance between sentences to represent the degree of dependency between words and modifies the gating mechanism of LSTM through the relative syntactic distance. Furthermore, we add a direct connection between hidden states to fuse high-level and low-level syntactic features. We conducted extensive experiments on language modeling. The results suggest that RSD-LSTM achieves improvements of 1.82 and 2.03 in perplexity compared with current top methods on the Penn Treebank and WikiText-2 datasets, respectively. Moreover, we conducted experiments on a machine translation application task. Experimental results of this task also show significant improvements of RSD-LSTM compared with baseline models .},
  archive      = {J_ISCI},
  author       = {Kai Shuang and Yijia Tan and Zhun Cai and Yue Sun},
  doi          = {10.1016/j.ins.2020.03.022},
  journal      = {Information Sciences},
  pages        = {220-233},
  shortjournal = {Inf. Sci.},
  title        = {Natural language modeling with syntactic structure dependency},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making with heterogeneous intuitionistic
fuzzy preference relations. <em>ISCI</em>, <em>523</em>, 197–219. (<a
href="https://doi.org/10.1016/j.ins.2020.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy variables are powerful tools to denote positive and negative information simultaneously. Considering the situation where decision makers (DMs) may adopt different types of preference relations to express their judgements, this paper studies group decision making (GDM) with heterogeneous intuitionistic fuzzy preference relations (IFPRs), including intuitionistic fuzzy preference relations (IFPRs), multiplicative intuitionistic fuzzy preference relations (MIFPRs), additive linguistic intuitionistic fuzzy preference relations (ALIFPRs) and multiplicative linguistic intuitionistic fuzzy preference relations (MLIFPRs). We first study their consistency. Then, we discuss the transformation relationships among them. Using consistent MLIFPRs, we further offer a formula for ascertaining DMs’ weights and investigate the consensus. When the individual consensus level is lower than a predefined threshold, a model for increasing the consensus level is built that ensures the smallest total adjustment and allows the adjusted proportions of different judgements to be different. Moreover, we give a new GDM method with heterogeneous IFPRs. Finally, we use an example to illustrate the application of the proposed GDM method and make a comparison of different GDM methods with heterogeneous preference relations.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen and Ruiping Yuan},
  doi          = {10.1016/j.ins.2020.03.010},
  journal      = {Information Sciences},
  pages        = {197-219},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making with heterogeneous intuitionistic fuzzy preference relations},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Globally fuzzy leader-follower consensus of mixed-order
nonlinear multi-agent systems with partially unknown direction control.
<em>ISCI</em>, <em>523</em>, 184–196. (<a
href="https://doi.org/10.1016/j.ins.2020.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates global fuzzy leader-follower consensus problem of mixed-order nonlinear multi-agent systems (MAS) with partially unknown direction control. The follower system is described by a first-order or second-order unknown nonlinear system model with partially unknown direction control and the leader system is described by a second-order time-varying nonlinear system model. Leader can share its position or velocity information with some followers. Due to the different distribution of agents in the network topology , a new hybrid distributed adaptive control protocol is presented in this study. Compared with the asymptotic consensus bounded result, this paper obtains the asymptotic consensus result. The global consensus result is obtained in the paper, which adopts the design method that the fuzzy logic systems (FLSs) acts as a feedforward compensator to approximate the unknown nonlinear dynamics . In the end, a simulation example is given to show the effectiveness of the proposed consensus control protocol.},
  archive      = {J_ISCI},
  author       = {Jiaxi Chen and Junmin Li},
  doi          = {10.1016/j.ins.2020.03.015},
  journal      = {Information Sciences},
  pages        = {184-196},
  shortjournal = {Inf. Sci.},
  title        = {Globally fuzzy leader-follower consensus of mixed-order nonlinear multi-agent systems with partially unknown direction control},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PUMAD: PU metric learning for anomaly detection.
<em>ISCI</em>, <em>523</em>, 167–183. (<a
href="https://doi.org/10.1016/j.ins.2020.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection task, which identifies abnormal patterns in data, has been widely applied to various domains. Most recent work on anomaly detection have focused on an accurate modeling of the normal data based on unsupervised methods . To get a satisfactory anomaly detection accuracy, they need pure normal data without abnormal data. This scenario requires many labels to get pure normal data. In many real-world scenarios, there exist abundant unlabeled data and a limited number of partially labeled anomalies. This paper proposes a novel anomaly detection method, PUMAD, which uses a Positive and Unlabeled (PU) learning approach to learn from abundant unlabeled data and a small number of partially labeled anomalies (i.e., positives). PUMAD successfully works on the anomaly detection scenario by exploiting deep metric learning with a hashing-based filtering method. Extensive experimental results on real-world benchmark datasets demonstrate that our approach based on PU learning is effective to detect anomalies . PUMAD achieves a much higher accuracy of up to 24\% than state-of-the-art competitors.},
  archive      = {J_ISCI},
  author       = {Hyunjun Ju and Dongha Lee and Junyoung Hwang and Junghyun Namkung and Hwanjo Yu},
  doi          = {10.1016/j.ins.2020.03.021},
  journal      = {Information Sciences},
  pages        = {167-183},
  shortjournal = {Inf. Sci.},
  title        = {PUMAD: PU metric learning for anomaly detection},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A genetic algorithm for constructing bijective substitution
boxes with high nonlinearity. <em>ISCI</em>, <em>523</em>, 152–166. (<a
href="https://doi.org/10.1016/j.ins.2020.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substitution box (S-box) is one of the most important components in the design of block ciphers . In this work, different from traditional methods, we convert the construction of n × n S-box into a process of putting n Boolean functions one by one into a container. On this basis, we regard the Boolean function as the chromosome of the S-box and propose a novel genetic algorithm to construct bijective S-boxes with high nonlinearity. In this genetic algorithm , the optimization objective is the nonlinearity of the S-box, and the bijection requirement is converted to its optimization constraint . First, we use a chaotic system to generate the initial S-boxes since chaotic systems have excellent properties like nonlinearity, ergodicity and pseudo-randomness. These initial S-boxes lay a good foundation for subsequent optimization of our algorithm. Then, for the merit of bijectivity and nonlinearity, we elaborately design the crossover and mutation operator of the genetic algorithm to improve the capability of generating bijective S-boxes with high nonlinearity. Under the proposed framework, two theorems can be proven, which imply that the proposed solution ensures bijection and high nonlinearity of the generated S-box. Further experimental analyses corroborate that our method is an effective way for constructing bijective S-boxes with high nonlinearity.},
  archive      = {J_ISCI},
  author       = {Yong Wang and Zhiqiang Zhang and Leo Yu Zhang and Jun Feng and Jerry Gao and Peng Lei},
  doi          = {10.1016/j.ins.2020.03.025},
  journal      = {Information Sciences},
  pages        = {152-166},
  shortjournal = {Inf. Sci.},
  title        = {A genetic algorithm for constructing bijective substitution boxes with high nonlinearity},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An advisable facial semantic characterization based on
axiomatic fuzzy set theory and information granules. <em>ISCI</em>,
<em>523</em>, 133–151. (<a
href="https://doi.org/10.1016/j.ins.2020.02.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing popularity of social networks, a colossal amount of images are being uploaded to the digital world including human faces, and semantic facial descriptors would be very useful to describe some facial action units, which can be further used for affection analysis. In this paper, a novel facial semantic characterization method via Axiomatic Fuzzy Set (AFS) clustering scheme and information granules is proposed. Firstly, semantic descriptions for each facial component are extracted in the framework of the AFS theory . Then in order to further characterize the semantics obtained by the AFS clustering, the information granules are created around the constructed prototypes, that can specify the merits of the semantic facial descriptors. Multiple experiments on the Multi-PIE and BU-4DFE facial databases demonstrate that the proposed facial semantic characterization method not only can obtain more accurate and interpretable descriptions, but also the results are much closer to human perception.},
  archive      = {J_ISCI},
  author       = {Yan Ren and Shuting Zhang and Wanquan Liu and Lidong Wang and Wei Guan},
  doi          = {10.1016/j.ins.2020.02.068},
  journal      = {Information Sciences},
  pages        = {133-151},
  shortjournal = {Inf. Sci.},
  title        = {An advisable facial semantic characterization based on axiomatic fuzzy set theory and information granules},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Three-way decisions of rough vague sets from the
perspective of fuzziness. <em>ISCI</em>, <em>523</em>, 111–132. (<a
href="https://doi.org/10.1016/j.ins.2020.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vague set, as well as intuitionistic fuzzy set, is an extended model of fuzzy sets. On the basis of fuzzy sets, vague sets describe the membership degree of a vague concept by using an interval value instead of a single value. To a certain degree, vague sets have a more powerful ability to process fuzzy information than fuzzy sets. Thus, when characterizing a target concept by vague sets, identifying methods to make scientific and reasonable decisions has become an essential issue. However, existing decision methods always focus on the decisions based on fuzzy concepts, and research on how to make three-way decisions based on vague concepts is still lacking. Therefore, in this paper, the concept of rough vague sets is proposed to construct a rough approximation framework of vague concepts. Then, the fuzziness of the existing approximation approaches is analyzed. Next, improved step-vague set model which is a better approximation approach than existing approaches and the algorithm used to search for a improved step-vague set are proposed. Furthermore, based on the improved step-vague sets, probabilistic rough vague sets and a three-way approximation model with shadowed sets are introduced. Finally, several illustrative examples and relative experiment are listed to verify the effectiveness and significance of the proposed models.},
  archive      = {J_ISCI},
  author       = {Qinghua Zhang and Fan Zhao and Jie Yang and Guoyin Wang},
  doi          = {10.1016/j.ins.2020.03.013},
  journal      = {Information Sciences},
  pages        = {111-132},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decisions of rough vague sets from the perspective of fuzziness},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-period multi-objective optimization framework for
software enhancement and component evaluation, selection and
integration. <em>ISCI</em>, <em>523</em>, 91–110. (<a
href="https://doi.org/10.1016/j.ins.2020.02.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software can be delivered either after it has been entirely developed or it can be delivered in phases. When delivered in phases, software can be enhanced either by upgrading the existing modules in forthcoming phases or by modifying the modules that were developed in previous phases. An incorporated multi-period multiple objective optimization model for the enhancement and establishment of a software system is discussed in this paper. The software system’s total cost is minimized, and the fitness evaluation score of the software components (commercial off-the-shelf and in-house) for modules that are not outsourced, along with vendors for modules that are outsourced, is maximized. The fitness evaluation of module alternatives (software components and vendors) is conducted based on many important qualitative attributes using the Technique for Order Preference by Similarity to Ideal Solution . The model is constrained to critical parameters, such as compatibility, delivery time and integration of alternatives, along with software reliability. To exemplify the applicability of the suggested framework for optimization, the development of e-commerce software is used as a case study.},
  archive      = {J_ISCI},
  author       = {Mukesh Kumar Mehlawat and Pankaj Gupta and Divya Mahajan},
  doi          = {10.1016/j.ins.2020.02.076},
  journal      = {Information Sciences},
  pages        = {91-110},
  shortjournal = {Inf. Sci.},
  title        = {A multi-period multi-objective optimization framework for software enhancement and component evaluation, selection and integration},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary approach for large-scale mine scheduling.
<em>ISCI</em>, <em>523</em>, 77–90. (<a
href="https://doi.org/10.1016/j.ins.2020.02.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the optimum solution for open-pit mine scheduling problems (OPMSPs) is a well-known challenging problem in the mining industry. The existing methodologies for solving large-scale OPMSPs are mostly limited to conventional optimization approaches and heuristics. However, due to the problem’s complexity, represented by high-dimensionality, and hard and soft constraints, the current approaches face challenges in finding good quality solutions with a reasonable computational cost. As an alternative approach, in this paper, we propose an evolutionary approach, based on differential evolution, with three important features: to deal with high-dimensionality, based on the extraction status of each block, we reduce the number of decision variables (blocks) over the planning horizon; to deal with the complex constrained landscape, we develop a repair mechanism that guarantees feasibility and to enhance the algorithm’s performance, we incorporate a local search technique. The experimental results on well-known mine deposits, with up to 112, 687 blocks show that the algorithm has the edge over existing methods to obtain better solutions.},
  archive      = {J_ISCI},
  author       = {Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos A. Coello Coello},
  doi          = {10.1016/j.ins.2020.02.074},
  journal      = {Information Sciences},
  pages        = {77-90},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary approach for large-scale mine scheduling},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way decisions based blocking reduction models in
hierarchical classification. <em>ISCI</em>, <em>523</em>, 63–76. (<a
href="https://doi.org/10.1016/j.ins.2020.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical classification (HC) is effective when categories are organized hierarchically. However, the blocking problem makes the effect of hierarchical classification greatly reduced. Blocking means that samples are easily getting misclassified in high-level classifiers so that the samples are blocked at the high-level of the hierarchy. This issue is caused by the inconsistency between the artificially defined hierarchy and the actual hierarchy of the raw data. Another issue is that it is flippant to strictly process data following the hierarchy. Therefore, special treatment is required for some uncertain data. To address the first issue, we learn category relationships and modify the hierarchy. To address the second issue, we introduce three-way decisions (3WD) to targetedly deal with the ambiguous data. We extend original studies and propose two HC models based on 3WD, collectively referred to as TriHC, for carefully modifying the hierarchy to alleviate the blocking problem. The proposed TriHC model learns new category hierarchies by the following three steps: (1) mining category relations; (2) modifying category hierarchies according to the latent category relations; and (3) using 3WD to divide observed objects into three regions: positive region, boundary region, and negative region, and making decisions based on different strategies. Specifically, based on different category relation mining methods, there are two versions of TriHC, cross-level blocking priori knowledge based TriHC (CLPK-TriHC) and expert classifier based TriHC (EC-TriHC). The CLPK-TriHC model defines a cross-level blocking distribution matrix to mine the category relations between the higher and lower levels. To better exploit category hierarchical relations, the EC-TriHC model builds expert classifiers using topic model to learn latent category topics. Experimental results validate that the proposed methods can simultaneously reduce the blocking and improve the classification accuracy .},
  archive      = {J_ISCI},
  author       = {Wen Shen and Zhihua Wei and Qianwen Li and Hongyun Zhang and Duoqian Miao},
  doi          = {10.1016/j.ins.2020.02.020},
  journal      = {Information Sciences},
  pages        = {63-76},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decisions based blocking reduction models in hierarchical classification},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic multi-objective evolutionary algorithm based on
intensity of environmental change. <em>ISCI</em>, <em>523</em>, 49–62.
(<a href="https://doi.org/10.1016/j.ins.2020.02.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel evolutionary algorithm based on the intensity of environmental change (IEC) to effectively track the moving Pareto-optimal front (POF) or Pareto-optimal set (POS) in dynamic optimization . The IEC divides each individual into two parts according to the evolutionary information feedback from the POS in the current and former evolutionary environment when an environmental change is detected. Two parts, the micro-changing decision and macro-changing decision, are implemented upon different situations of decision components in order to build an efficient information exchange among dynamic environments. In addition, in our algorithm, if a new evolutionary environment is similar to its historical evolutionary environment, the history information will be used for reference to guide the search towards promising decision regions . In order to verify the availability of our idea, the IEC has been extensively compared with four state-of-the-art algorithms over a range of test suites with different features and difficulties. Experimental results show that the proposed IEC is promising.},
  archive      = {J_ISCI},
  author       = {Yaru Hu and Jinhua Zheng and Juan Zou and Shengxiang Yang and Junwei Ou and Rui Wang},
  doi          = {10.1016/j.ins.2020.02.071},
  journal      = {Information Sciences},
  pages        = {49-62},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic multi-objective evolutionary algorithm based on intensity of environmental change},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). A feature-vector generative adversarial network for evading
PDF malware classifiers. <em>ISCI</em>, <em>523</em>, 38–48. (<a
href="https://doi.org/10.1016/j.ins.2020.02.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-Physical Systems (CPS) are increasingly utilizing machine learning (ML) algorithms to resolve different control and decision making problems. CPS are traditionally vulnerable to evasion attacks and adversarial examples , hence the integration of learning algorithms requires that these vulnerabilities are reevaluated to make the cyber-physical systems more secure and robust. In this work, we propose a novel evasion method based on a feature-vector generative adversarial network (fvGAN) to attack a learning-based malware classifier. The generative adversarial network (GAN) has been widely used in the realistic fake-image generation, but it has rarely been studied for adversarial malware generation. This work uses the fvGAN to generate adversarial feature vectors in the feature space, and then transforms them into actual adversarial malware examples. We have experimentally investigated the effectiveness of the proposed approach on a well-known PDF malware classifier, PDFRate, and evaluated the fvGAN-based attack in four evasion scenarios. The results show that the fvGAN model has a high evasion rate within a limited time. We have also compared the proposed approach with two existing attack algorithms, namely Mimicry and GD-KDE, and the results prove that the proposed scheme has better performance both in terms of evasion rate and execution cost.},
  archive      = {J_ISCI},
  author       = {Yuanzhang Li and Yaxiao Wang and Ye Wang and Lishan Ke and Yu-an Tan},
  doi          = {10.1016/j.ins.2020.02.075},
  journal      = {Information Sciences},
  pages        = {38-48},
  shortjournal = {Inf. Sci.},
  title        = {A feature-vector generative adversarial network for evading PDF malware classifiers},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Noise-robust image fusion with low-rank sparse decomposition
guided by external patch prior. <em>ISCI</em>, <em>523</em>, 14–37. (<a
href="https://doi.org/10.1016/j.ins.2020.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to simultaneously achieve noise suppression and fine detail preservation in noisy image fusion. To address this challenge, we propose a novel strategy for noisy image fusion. Assuming that an image can be modeled as a superposition of low-rank and sparse (LR-and-S) components, we develop a novel discriminative dictionary learning algorithm to construct two dictionaries so as to decompose the input image into LR-and-S components. Specifically, to make dictionary possess discriminative power , we enforce spatial morphology constraint on each dictionary. Furthermore, we develop within-class consistency constraint by exploiting the similarity of low-rank components and impose it on the coding coefficients to further improve the discriminative power of the learned dictionary. In image decomposition, external patch prior and internal self-similarity prior of an image are exploited to build image decomposition model , based on which the latent subspace for fusion and recovery is estimated by minimizing rank-regularization of the subspace learned via clustering of similar patches. To construct different components of fused result, we use l 1 -norm maximization rule to fuse the decomposed components. Finally, the fused image is obtained by adding the fused components together. Experiments demonstrate that our method outperforms several state-of-the-art methods in terms of both objective quality assessment and subjective visual perception.},
  archive      = {J_ISCI},
  author       = {Huafeng Li and Xiaoge He and Zhengtao Yu and Jiebo Luo},
  doi          = {10.1016/j.ins.2020.03.009},
  journal      = {Information Sciences},
  pages        = {14-37},
  shortjournal = {Inf. Sci.},
  title        = {Noise-robust image fusion with low-rank sparse decomposition guided by external patch prior},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TSI: Time series to imaging based model for detecting
anomalous energy consumption in smart buildings. <em>ISCI</em>,
<em>523</em>, 1–13. (<a
href="https://doi.org/10.1016/j.ins.2020.02.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart buildings , efficient energy consumption is one of the biggest challenges to solve, which can contribute to reduce the global warming of our planet, due to its relevance. In this paper, a time series to image (TSI) based model is introduced to identify anomalous energy consumption in residential buildings. It has a novel encoding scheme to transform univariate time series data into images for extracting the useful information and one-class support vector machine (OCSVM) for the classification task . The TSI extracts descriptive and representative feature spaces from the data and encode them into images using Markov Transition Function (MTF) . We empirically evaluate the proposed model over publicly available real world dataset and compared the results with the state-of-the-art method. The obtained results are competitive and confirm the applicability of TSI model in real-world scenarios.},
  archive      = {J_ISCI},
  author       = {Muhammad Fahim and Khadija Fraz and Alberto Sillitti},
  doi          = {10.1016/j.ins.2020.02.069},
  journal      = {Information Sciences},
  pages        = {1-13},
  shortjournal = {Inf. Sci.},
  title        = {TSI: Time series to imaging based model for detecting anomalous energy consumption in smart buildings},
  volume       = {523},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial: Special issue on safety and security for
ubiquitous computing and communications. <em>ISCI</em>, <em>522</em>,
317–318. (<a href="https://doi.org/10.1016/j.ins.2020.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Guojun Wang and Jianhua Ma and Laurence T. Yang},
  doi          = {10.1016/j.ins.2020.02.036},
  journal      = {Information Sciences},
  pages        = {317-318},
  shortjournal = {Inf. Sci.},
  title        = {Guest editorial: Special issue on safety and security for ubiquitous computing and communications},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure parameterized pattern matching. <em>ISCI</em>,
<em>522</em>, 299–316. (<a
href="https://doi.org/10.1016/j.ins.2020.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized pattern matching (PPM) is the problem of matching between two given parameterized strings over two constant and parameter alphabets. PPM has special applications in software maintenance, information retrieval, computational biology, and so on. In some applications of PPM, preserving the privacy of the involved parties is essential. For example, a researcher holding an amino acid pattern needs to receive the parameterized matched locations of his/her input with the patterns in a biological database while the database owner has to obtain no information about the matching results and the pattern. In this paper, we define this problem as secure PPM (SPPM), present a scheme to resolve it in the semi-honest and malicious adversarial models , and prove the security of the proposed scheme in the universal composability (UC) framework. The proposed scheme supports wildcard and approximate PPM, too. We evaluate the security and performance of the proposed scheme. The proposed scheme is experimentally evaluated on a case of secure ribonucleic acid (RNA) search over the RNAcentral dataset. Implementation results show that the proposed scheme is secure and efficient for preserving privacy in contexts where PPM is applicable.},
  archive      = {J_ISCI},
  author       = {Maryam Zarezadeh and Hamid Mala and Behrouz Tork Ladani},
  doi          = {10.1016/j.ins.2020.02.046},
  journal      = {Information Sciences},
  pages        = {299-316},
  shortjournal = {Inf. Sci.},
  title        = {Secure parameterized pattern matching},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel graph clustering method with a greedy heuristic
search algorithm for mining protein complexes from dynamic and static
PPI networks. <em>ISCI</em>, <em>522</em>, 275–298. (<a
href="https://doi.org/10.1016/j.ins.2020.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering protein complexes from protein-protein interaction (PPI) networks is one of the primary tasks in bioinformatics. However, most of the state-of-the-art methods still face some challenges, such as the inability to discover overlapping protein complexes, failure to consider the inherent structure of real protein complexes, and non-utilization of biological information. Based on the above mentioned aspects, we present a novel graph clustering method with a greedy heuristic search algorithm for mining protein complexes using a new clustering model in dynamic and static weighted PPI networks (named MPC-C). First, MPC-C constructed dynamic and static weighted PPI networks by combining biological and topological information. Second, initial clusters were obtained using core and multifunctional proteins, following which we proposed a greedy heuristic search algorithm to expand each initial cluster and form candidate protein complexes in dynamic and static weighted PPI networks. Finally, unreliable and highly overlapping protein complexes were discarded. To demonstrate the performance of MPC-C, we tested this method on five PPI networks and compared it with nine other effective methods. The experimental results indicate that MPC-C outperformed the other state-of-the-art methods with respect to various computational and biologically relevant metrics.},
  archive      = {J_ISCI},
  author       = {Rongquan Wang and Caixia Wang and Guixia Liu},
  doi          = {10.1016/j.ins.2020.02.063},
  journal      = {Information Sciences},
  pages        = {275-298},
  shortjournal = {Inf. Sci.},
  title        = {A novel graph clustering method with a greedy heuristic search algorithm for mining protein complexes from dynamic and static PPI networks},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). Self-blast state detection of glass insulators based on
stochastic configuration networks and a feedback transfer learning
mechanism. <em>ISCI</em>, <em>522</em>, 259–274. (<a
href="https://doi.org/10.1016/j.ins.2020.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-blast state of a glass insulator directly affects the safety and reliability of transmission lines. To address the insufficient generalization ability of existing detection methods for insulator self-blast states and the drawbacks of deep neural network structures, the theories of transfer learning and closed-loop control are drawn upon to provide an intelligent detection method for the self-blast states of glass insulators. The method proposed in this paper is based on stochastic configuration networks and a feedback transfer learning mechanism. First, to reduce the redundancy of convolutional kernels in the channel extent, the interleaved group convolution strategy is employed to reconstruct the convolutional layers of the Inception network. Second, in view of the different feature applicabilities of different glass insulator images and based on the adaptive convolution module groups, the data structure of the dynamic feature space of insulator images is built with a certain mapping relationship from global to local. Then, the discriminative measure index is used to evaluate the discriminative information of the feature space to enhance the interpretability of the compact feature spance. Third, the fully connected feature vector of the compact feature space is sent to stochastic configuration networks (SCNs), which have universal approximation property to establish the classification criteria of the self-blast states of insulator images with generalization ability . Finally, an imitation of human thinking patterns is employed that exhibits repeated deliberation and comparison. Consequently, based on generalized error and entropy theories, the evaluation index of the objective function is established to evaluate the uncertain detection results of the self-blast states of glass insulator images in real time. Then, the dynamic transfer learning mechanism is constructed based on the constraint of the measurement index of uncertain detection results to realize self-optimizing regulation of the feature space that exhibits multihierarchy and discrimination and reconstructed classification criteria. The experimental results show that compared with other algorithms, the proposed method enhances the generalization ability and detection accuracy of the model.},
  archive      = {J_ISCI},
  author       = {Qian Zhang and Weitao Li and Hua Li and Jianping Wang},
  doi          = {10.1016/j.ins.2020.02.058},
  journal      = {Information Sciences},
  pages        = {259-274},
  shortjournal = {Inf. Sci.},
  title        = {Self-blast state detection of glass insulators based on stochastic configuration networks and a feedback transfer learning mechanism},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DC-SPP-YOLO: Dense connection and spatial pyramid pooling
based YOLO for object detection. <em>ISCI</em>, <em>522</em>, 241–258.
(<a href="https://doi.org/10.1016/j.ins.2020.02.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the YOLOv2 method is extremely fast on object detection, its detection accuracy is restricted due to the low performance of its backbone network and the under-utilization of multi-scale region features. Therefore, a dense connection (DC) and spatial pyramid pooling (SPP) based YOLO (DC-SPP-YOLO) method is proposed in this paper for ameliorating the object detection accuracy of YOLOv2. Specifically, the backbone network of YOLOv2 adopts the dense connection of convolution layers, which strengthen the feature extraction and alleviate the vanishing-gradient problem. Moreover, an improved spatial pyramid pooling is introduced to pool and concatenate the multi-scale region features, so that the network learns the object features more comprehensively. The DC-SPP-YOLO model is established and trained based on a new loss function composed of MSE (mean square error) loss and cross-entropy loss. The experimental results indicate that the mAP (mean Average Precision) of DC-SPP-YOLO is higher than that of YOLOv2 on the PASCAL VOC datasets and the UA-DETRAC datasets. The effectiveness of DC-SPP-YOLO method proposed is demonstrated.},
  archive      = {J_ISCI},
  author       = {Zhanchao Huang and Jianlin Wang and Xuesong Fu and Tao Yu and Yongqi Guo and Rutong Wang},
  doi          = {10.1016/j.ins.2020.02.067},
  journal      = {Information Sciences},
  pages        = {241-258},
  shortjournal = {Inf. Sci.},
  title        = {DC-SPP-YOLO: Dense connection and spatial pyramid pooling based YOLO for object detection},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving neighborhood construction with apollonius region
algorithm based on density for clustering. <em>ISCI</em>, <em>522</em>,
227–240. (<a href="https://doi.org/10.1016/j.ins.2020.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid rate of information flow today, local identification of similar data points has gained greater significance for information processing in various branches of sciences. Geometric methods are especially useful because of their accuracy in locating similar neighborhood points by means of geometric structures. Geometric methods are not accurate enough for large scale data sets. Because of the persistent serious challenges in data point analysis, we have used a geometric method in which the Apollonius circle is been utilized to achieve high local accuracy. This paper proposes a neighborhood construction algorithm, termed Neighborhood Construction with Apollonius Region Density (NCARD). The neighbors of data points are determined not only by using geometric structures but also by means of density information. For efficient clustering, in comparison with the previous methods, the proposed algorithm can work better for high dimensional data; it is also able to identify local outlier data. Moreover, after locating similar data points with Apollonius circle, we will extract density and relationship among the points leading to a unique and rather accurate neighborhood. The proposed algorithm is more accurate than the state-of-the-art and well-known algorithms up to almost 8–13\% in real and artificial data sets.},
  archive      = {J_ISCI},
  author       = {Shahin Pourbahrami and Leyli Mohammad Khanli and Sohrab Azimpour},
  doi          = {10.1016/j.ins.2020.02.049},
  journal      = {Information Sciences},
  pages        = {227-240},
  shortjournal = {Inf. Sci.},
  title        = {Improving neighborhood construction with apollonius region algorithm based on density for clustering},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-rank matrix regression for image feature extraction and
feature selection. <em>ISCI</em>, <em>522</em>, 214–226. (<a
href="https://doi.org/10.1016/j.ins.2020.02.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many image processing and pattern recognition problems, the input data is commonly the images. The image could be represented as the matrix form. The natural structure information of the matrix is useful for data analysis and representation. However, most of existing methods commonly convert the image as a vector form, which destroys the natural structure of the image. To fully utilize this kind of structure information, we propose a low-rank matrix regression model for feature extraction and feature selection. To efficiently solve the objective functions of the proposed methods, we develop an optimization algorithm based on the alternating direction method of multipliers method. Promising experimental results have demonstrated the effectiveness of our proposed methods.},
  archive      = {J_ISCI},
  author       = {Haoliang Yuan and Junyu Li and Loi Lei Lai and Yuan Yan Tang},
  doi          = {10.1016/j.ins.2020.02.070},
  journal      = {Information Sciences},
  pages        = {214-226},
  shortjournal = {Inf. Sci.},
  title        = {Low-rank matrix regression for image feature extraction and feature selection},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Reinvestigation of evolutionary many-objective
optimization: Focus on the pareto knee front. <em>ISCI</em>,
<em>522</em>, 193–213. (<a
href="https://doi.org/10.1016/j.ins.2020.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximating the entire Pareto front (PF) in many-objective optimization is challenging but often unnecessary because a decision maker is usually only interested in a small portion of the PF. Assuming no preference, we argue that a more appropriate way to address many-objective optimization problems (MaOPs) is to find Pareto-optimal knee solutions—solutions where small improvements in one objective will lead to severe degradation in at least one other objective. Herein, we propose such a method, which uses a distance-based indicator to first identify knee points (knee-detection phase) and then uses a refined fitness assignment strategy to select solutions near the knee points (knee-selection phase). The proposed method is integrated into two traditional algorithms, resulting in k-NSGA-II and k-MOEA/D. We discuss the effects of the parameter that controls the width of the knee region(s) and then analyze the effects of different methods for identifying knee points in the knee-detection phase. Finally, we examine the performances of k-NSGA-II and k-MOEA/D on a set of knee benchmark problems. The experimental results show that k-NSGA-II is competitive on knee test problems with 2 and 4 objectives, while k-MOEA/D performs better than k-NSGA-II with 6 and 8 objectives.},
  archive      = {J_ISCI},
  author       = {Wenhua Li and Rui Wang and Tao Zhang and Mengjun Ming and Kaiwen Li},
  doi          = {10.1016/j.ins.2020.03.007},
  journal      = {Information Sciences},
  pages        = {193-213},
  shortjournal = {Inf. Sci.},
  title        = {Reinvestigation of evolutionary many-objective optimization: Focus on the pareto knee front},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CoVeC: Coarse-grained vertex clustering for efficient
community detection in sparse complex networks. <em>ISCI</em>,
<em>522</em>, 180–192. (<a
href="https://doi.org/10.1016/j.ins.2020.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the problem of community detection in large-scale graphs. In the literature devoted to this topic, an iterative algorithm , called Louvain Method (LM), stands out as an effective and fast solution for this problem. However, the first iterations of the LM are the most costly. To overcome this issue, this paper introduces CoVeC, a Co arse-grained Ve rtex C lustering for efficient community detection in sparse complex networks. CoVeC pre-processes the original graph in order to forward a graph of reduced size to the LM. The subsequent group formation, including the maximization of group quality, as per the modularity metric, is left to the LM. We evaluate our proposal using real-world and synthetic networks, presenting distinct sizes and sparsity levels. Overall, our experimental results show that CoVeC can be a way faster option than the first iterations of the LM, yet similarly effective. In fact, for sparser graphs , the combo CoVeC+LM outperforms the standalone LM and its variations, attaining a mean processing time reduction of 47\% and a mean modularity reduction of only 0.4\%.},
  archive      = {J_ISCI},
  author       = {Gustavo S. Carnivali and Alex B. Vieira and Artur Ziviani and Paulo A.A. Esquef},
  doi          = {10.1016/j.ins.2020.03.004},
  journal      = {Information Sciences},
  pages        = {180-192},
  shortjournal = {Inf. Sci.},
  title        = {CoVeC: Coarse-grained vertex clustering for efficient community detection in sparse complex networks},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Steganalysis of meshes based on 3D wavelet multiresolution
analysis. <em>ISCI</em>, <em>522</em>, 164–179. (<a
href="https://doi.org/10.1016/j.ins.2020.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D steganalysis aims to find the information hidden in 3D models and graphical objects . It is assumed that the information was hidden by 3D steganography or watermarking algorithms . A new set of 3D steganalysis features, derived by using multiresolution 3D wavelet analysis , is proposed in this research study. 3D wavelets relate a given mesh representation with its lower and higher graph resolutions by means of a set of Wavelet Coefficient Vectors (WCVs). The 3D steganalysis features are derived from transformations between a given mesh and its corresponding higher and lower resolutions. They correspond to geometric measures such as ratios and angles between various geometric measures. These features are shown to significantly increase the steganalysis accuracy when detecting watermarks which have been embedded by 3D wavelet-based watermarking algorithms . The proposed features, when used in combination with a previously proposed feature set, is shown to provide the best results in detecting the hidden information embedded by other information hiding algorithms.},
  archive      = {J_ISCI},
  author       = {Zhenyu Li and Adrian G. Bors},
  doi          = {10.1016/j.ins.2020.02.061},
  journal      = {Information Sciences},
  pages        = {164-179},
  shortjournal = {Inf. Sci.},
  title        = {Steganalysis of meshes based on 3D wavelet multiresolution analysis},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-agent autonomous intersection management (MA-AIM)
system for smart cities leveraging edge-of-things and blockchain.
<em>ISCI</em>, <em>522</em>, 148–163. (<a
href="https://doi.org/10.1016/j.ins.2020.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing trend of people moving around urban areas requires more intelligent transportation-support services in smart cities. In this context, the number of traffic collisions, especially in intersections, has rapidly increased as well as the number of vehicles. The leading cause of this is represented by human errors in recognition and decision making. Thus, the development of secure Autonomous Intersection Management (AIM) systems is an emerging challenge. In this paper, we propose a Multi-Agent AIM (MA-AIM) system based on Vehicle-to-Infrastructure (V2I) and Infrastructure-to-Vehicle (I2V) communications able to safely manage vehicles crossing through an intersection leveraging both Edge of Things (EoT) and Blockchain facilities. The proposed system includes an Intersection Manager Agent (IMA) that: i) interacts with vehicles through Driver Agents (DAs) installed on them in an EoT environment, and ii) uses Blockchain mechanisms in order to orchestrate the passage of vehicles crossing the intersection safely. In particular, we implemented a proof-of-concept integrating the AIM 4.0 simulator with Hyperledger Fabric (implementing Blockchain capabilities) and with Node-RED (implementing V2I/I2V communications in an EoT environment). Preliminary experiments show the feasibility and potentiality of our solution.},
  archive      = {J_ISCI},
  author       = {Alina Buzachis and Antonio Celesti and Antonino Galletta and Maria Fazio and Giancarlo Fortino and Massimo Villari},
  doi          = {10.1016/j.ins.2020.02.059},
  journal      = {Information Sciences},
  pages        = {148-163},
  shortjournal = {Inf. Sci.},
  title        = {A multi-agent autonomous intersection management (MA-AIM) system for smart cities leveraging edge-of-things and blockchain},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure and efficient outsourcing computation on large-scale
linear regressions. <em>ISCI</em>, <em>522</em>, 134–147. (<a
href="https://doi.org/10.1016/j.ins.2020.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving large-scale linear regression (LR) becomes more and more prevalent in theoretical research and engineering application , which however is too expensive to solve for limited-resource clients. To meet this challenge, more and more clients shift their expensive computations to powerful clouds in practice. The previous works on secure outsourcing LR usually possess heavy workloads, some of which even have potential limitations. In this paper, we first reveal several limitations in the state-of-the-arts. To overcome these shortcomings, we then propose a novel protocol for securely outsourcing large-scale LR. In our design, a client only utilizes two random vectors to encrypt his/her LR problem and decrypt the solution returned from the cloud, which is quite simple. In addition, the proposed protocol only involves with several vector-vector operations, two matrix-vector multiplications and one matrix-matrix subtraction, which thus achieves high efficiency. We also demonstrate that the proposed protocol can accomplish correctness guarantee, privacy protection and cheating resistance under the assumption of a malicious cloud. At last, extensive theoretical analysis and experimental results are provided to further validate the superiority of the proposed protocol.},
  archive      = {J_ISCI},
  author       = {Yang Yang and Ping Xiong and Qing Huang and Fei Chen},
  doi          = {10.1016/j.ins.2020.03.003},
  journal      = {Information Sciences},
  pages        = {134-147},
  shortjournal = {Inf. Sci.},
  title        = {Secure and efficient outsourcing computation on large-scale linear regressions},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Answering an open problem on t-norms for type-2 fuzzy sets.
<em>ISCI</em>, <em>522</em>, 124–133. (<a
href="https://doi.org/10.1016/j.ins.2020.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proves that a binary operation ⋆ on [0, 1], ensuring that the binary operation ⋏ is a t -norm or ⋎ is a t -conorm, is a t -norm, where ⋏ and ⋎ are special convolution operations defined by ( f ⋏ g ) ( x ) = sup { f ( y ) ★ g ( z ) : y ▵ z = x } , (f⋏g)(x)=sup{f(y)★g(z):y▵z=x}, ( f ⋎ g ) ( x ) = sup { f ( y ) ★ g ( z ) : y ▿ z = x } , (f⋎g)(x)=sup{f(y)★g(z):y▿z=x}, for any f, g ∈ Map ([0, 1], [0, 1]), where △ and ▽ are a continuous t -norm and a continuous t -conorm on [0, 1], answering negatively an open problem posed in [8]. Besides, some characteristics of t -norm and t -conorm are obtained in terms of the binary operations ⋏ and ⋎.},
  archive      = {J_ISCI},
  author       = {Xinxing Wu and Guanrong Chen},
  doi          = {10.1016/j.ins.2020.03.001},
  journal      = {Information Sciences},
  pages        = {124-133},
  shortjournal = {Inf. Sci.},
  title        = {Answering an open problem on t-norms for type-2 fuzzy sets},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability and stabilization of t–s fuzzy systems with
variable delays via new bessel–legendre polynomial based relaxed
integral inequality. <em>ISCI</em>, <em>522</em>, 99–123. (<a
href="https://doi.org/10.1016/j.ins.2020.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the delay-range-dependent (DRD) stability problem in regards to continuous time Takagi–Sugeno (T–S) fuzzy system with variable delays. First, a new integral inequality Lemma referred herein as higher order polynomial based relaxed integral inequality (HOPBRII) is proposed to reduce the estimation gap of the current work with that of Bessel–Legendre polynomial based inequality (BLPBI). Next, a suitable Lyapunov–Krasovskii functional (LKF) is constructed with delay product terms and then using the proposed inequality, suitable condition for DRD stability and stabilization condition of the considered T–S fuzzy system are derived in a linear matrix inequality (LMI) framework. To analyse the advantage theoretically and less conservatism of the proposed method, a new DRD stability condition using similar LKFs and the BLPBI approach is further derived herein. Finally, the efficacy of the proposed stability and stabilization conditions are validated through the solutions of four numerical examples.},
  archive      = {J_ISCI},
  author       = {Rupak Datta and Rajeeb Dey and Baby Bhattacharya and Ramasamy Saravanakumar and Oh-Min Kwon},
  doi          = {10.1016/j.ins.2020.02.060},
  journal      = {Information Sciences},
  pages        = {99-123},
  shortjournal = {Inf. Sci.},
  title        = {Stability and stabilization of T–S fuzzy systems with variable delays via new Bessel–Legendre polynomial based relaxed integral inequality},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure server-aided data sharing clique with attestation.
<em>ISCI</em>, <em>522</em>, 80–98. (<a
href="https://doi.org/10.1016/j.ins.2020.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the security issues in data sharing cliques via remote server. We present a public key re-encryption scheme with delegated equality test on ciphertexts (PRE-DET). The scheme allows users to share outsourced data on the server without performing decryption-then-encryption procedures, allows new users to dynamically join the clique, allows clique users to attest the message underlying a ciphertext, and enables the server to partition outsourced user data without any further help of users after being delegated. We introduce the PRE-DET framework, propose a concrete construction and formally prove its security against five types of adversaries regarding two security requirements on message confidentiality and unforgeability of attestation against the server. We also theoretically analyze and compare the proposed PRE-DET construction with related schemes in terms of ciphertext sizes and computation costs of encryption, decryption, ciphertext equality testing and re-encryption, which confirms the practicality of our construction.},
  archive      = {J_ISCI},
  author       = {Yujue Wang and HweeHwa Pang and Robert H. Deng and Yong Ding and Qianhong Wu and Bo Qin and Kefeng Fan},
  doi          = {10.1016/j.ins.2020.02.064},
  journal      = {Information Sciences},
  pages        = {80-98},
  shortjournal = {Inf. Sci.},
  title        = {Secure server-aided data sharing clique with attestation},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A training-integrity privacy-preserving federated learning
scheme with trusted execution environment. <em>ISCI</em>, <em>522</em>,
69–79. (<a href="https://doi.org/10.1016/j.ins.2020.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models trained on sensitive real-world data promise improvements to everything from medical screening to disease outbreak discovery. In many application domains, learning participants would benefit from pooling their private datasets, training precise machine learning models on the aggregate data, and sharing the profits of using these models. Considering privacy and security concerns often prevent participants from contributing sensitive data for training, researchers proposed several techniques to achieve data privacy in federated learning systems. However, such techniques are susceptible to causative attacks, whereby malicious participants can inject false training results with the aim of corrupting the well-learned model. To end this, in this paper, we propose a new privacy-preserving federated learning scheme that guarantees the integrity of deep learning processes. Based on the Trusted Execution Environment (TEE), we design a training-integrity protocol for this scheme, in which causative attacks can be detected. Thus, each participant is compelled to execute the privacy-preserving learning algorithm of the scheme correctly. We evaluate the performance of our scheme by prototype implementations. The experimental result shows that the scheme is training-integrity and practical.},
  archive      = {J_ISCI},
  author       = {Yu Chen and Fang Luo and Tong Li and Tao Xiang and Zheli Liu and Jin Li},
  doi          = {10.1016/j.ins.2020.02.037},
  journal      = {Information Sciences},
  pages        = {69-79},
  shortjournal = {Inf. Sci.},
  title        = {A training-integrity privacy-preserving federated learning scheme with trusted execution environment},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and optimization of coal blending and coking costs
using coal petrography. <em>ISCI</em>, <em>522</em>, 49–68. (<a
href="https://doi.org/10.1016/j.ins.2020.02.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coke is an important raw material in the steel industry, and its quality directly influences the smelting of iron and steel. To improve coal quality and reduce coal blending costs, we need to predict the coke quality and optimize the coal blending scheme. In this paper, we propose a modeling and optimization method based on the characteristics of the coal blending and coking process . First, we establish a model for predicting coke quality from coking petrography data, based on Gaussian functions and Xgboost-SVR. The model has two components. In the first part, we analyze the key characteristics of the coal blending and coke process, and extract features of the vitrinite reflectance distribution with Gaussian functions . In the second part, we use Xgboost to select a representative feature subset, and then use support vector regression (SVR) to create a model for predicting coal quality. Next, we formulate a multi-constraint optimization problem to describe the coal blending costs, and solve it using a modified particle swarm optimization . Finally, we demonstrate the effectiveness of our modeling and optimization method by applying it to actual process data. This shows that our proposed method can improve prediction performance and reduce the coal blending costs.},
  archive      = {J_ISCI},
  author       = {Yan Yuan and Qilin Qu and Luefeng Chen and Min Wu},
  doi          = {10.1016/j.ins.2020.02.072},
  journal      = {Information Sciences},
  pages        = {49-68},
  shortjournal = {Inf. Sci.},
  title        = {Modeling and optimization of coal blending and coking costs using coal petrography},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A ROI-guided deep architecture for robust facial expressions
recognition. <em>ISCI</em>, <em>522</em>, 35–48. (<a
href="https://doi.org/10.1016/j.ins.2020.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a robust facial expression recognition framework, focusing on discovering the region of interest (ROI) to train an effective face-specific of convolutional neural networks (CNN). By exploiting the relationships among ROI areas, the proposed deep architecture can improve the reliability of predicted targets. Our designed deep model is fine-tuned based on a pre-specified deep CNN instead of a new one trained from scratch. To increase the face expressions toward a robust deep CNN training, a novel data augmentation strategy called artificial face is designed. The performance of our deep architecture is evaluated on state-of-the-art databases such as CK+. To demonstrate the high generalizability of our approach, cross-database validations are conducted on the JAFFE and our own compiled Wild database. Comprehensive experiments have demonstrated the superiority of the method, i.e. , achieving a recognition accuracy of 94.67\% on the CK+ database, 53.77\% on the JAFFE cross-database, 40.13\% on the FER-2013 cross-database, and 37.25\% on the Wild cross-database respectively.},
  archive      = {J_ISCI},
  author       = {Xiao Sun and Pingping Xia and Luming Zhang and Ling Shao},
  doi          = {10.1016/j.ins.2020.02.047},
  journal      = {Information Sciences},
  pages        = {35-48},
  shortjournal = {Inf. Sci.},
  title        = {A ROI-guided deep architecture for robust facial expressions recognition},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A three-stage framework for smoky vehicle detection in
traffic surveillance videos. <em>ISCI</em>, <em>522</em>, 17–34. (<a
href="https://doi.org/10.1016/j.ins.2020.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smoky vehicle exhaust pollutes the air and endangers human health. Existing methods detecting smoky vehicles in traffic surveillance videos are with high false alarm rates due to the diversity of smoke characteristics and continuous interferences of common vehicles. To solve this issue, this paper presents a three-stage framework for smoky vehicle detection. In the first stage, a Robust Pixel Based Adaptive Segmenter (R-PBAS) algorithm, which adapts to cameras shaking, is proposed to extract moving objects. The Cumulative Color Histogram (CCH) is adopted to extract smoke-colored blocks from moving objects. In the second stage, three groups of features, including Non-Redundant Robust Local Binary Pattern (NR-RLBP), Weighted Co-occurrence Histograms of Oriented Gradients (W-CoHOG), and Motion Boundary Histograms (MBH) are proposed to extract texture, gradient, and motion information from smoke-colored blocks, respectively. In the third stage, we fuse smoke blocks to obtain Region of Interest (ROI) and extract frequency domain features based on Discrete Wavelet Transform (DWT). To further improve robustness, the Auto-Regressive and Moving Average (ARMA) Model and Hidden Markov Model (HMM) are adopted to model ROIs in consecutive frames. Extensive experiments show that our method performs better than existing methods.},
  archive      = {J_ISCI},
  author       = {Huanjie Tao and Peng Zheng and Chao Xie and Xiaobo Lu},
  doi          = {10.1016/j.ins.2020.02.053},
  journal      = {Information Sciences},
  pages        = {17-34},
  shortjournal = {Inf. Sci.},
  title        = {A three-stage framework for smoky vehicle detection in traffic surveillance videos},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing MOEA/d with information feedback models for
large-scale many-objective optimization. <em>ISCI</em>, <em>522</em>,
1–16. (<a href="https://doi.org/10.1016/j.ins.2020.02.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multi-objective evolutionary algorithm based on decomposition (MOEA/D) is a classic decomposition-based multi-objective optimization algorithm. In the standard MOEA/D algorithm, the update process of individuals is a forward search process without using the information of previous individuals. However, there is a lot of useful information in the previous iteration. Information Feedback Models (IFM) is a new strategy which can incorporate the information from previous iteration into the updating process. Therefore, this paper proposes a MOEA/D algorithm based on information feedback model, called MOEA/D-IFM. According to the different information feedback models, this paper proposes six variants of MOEA/D, and these algorithms can be divided into two categories according to the way of selecting individuals whether it is random or fixed. At the same time, a new selection strategy has been introduced to further improve the performance of MOEA/D-IFM. The experiments were carried out in four aspects. MOEA/D-IFM were compared with other state-of-the-art multi-objective evolutionary algorithms using CEC 2018 problems in two aspects. The best one of the six improved algorithms was chosen to test on large-scale many-objective problems. In addition, we also use MOEA/D-IFM to solve multi-objective backpack problems.},
  archive      = {J_ISCI},
  author       = {Yin Zhang and Gai-Ge Wang and Keqin Li and Wei-Chang Yeh and Muwei Jian and Junyu Dong},
  doi          = {10.1016/j.ins.2020.02.066},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing MOEA/D with information feedback models for large-scale many-objective optimization},
  volume       = {522},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extensible image object co-segmentation with sparse
cooperative relations. <em>ISCI</em>, <em>521</em>, 422–434. (<a
href="https://doi.org/10.1016/j.ins.2020.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the co-segmentation problems of sparse related image group, how to mine correlations between common objects has been one of the most significant steps. In this paper, we first prioritize the processing efficiency and construct sparse cooperative graph for related images in feature space, instead of examining the full correlations of common foregrounds which lead to high computation cost and great risk of false connection. And more importantly, we design a flexible and efficient extending strategy to reuse the cooperative graph for incremental image data. Then, with the sparse correlations of the image group, we propose a unilateral proposal co-selection method for pair-wise region level co-segmentation. Finally, we have achieved the segmentation results with further pixel level refinement. Our experimental results on publicly available datasets show that, compared with the approaches using dense cooperative constraints, the proposed method can achieve more competitive results with extremely sparse correlative constraints, which shows its bright application prospects for sparse correlated image groups with incremental data due to its high efficiency and flexible extensibility.},
  archive      = {J_ISCI},
  author       = {Kunqian Li and Shengbo Qi and Hua Yang and Liqin Zhou and Dalei Song},
  doi          = {10.1016/j.ins.2020.02.055},
  journal      = {Information Sciences},
  pages        = {422-434},
  shortjournal = {Inf. Sci.},
  title        = {Extensible image object co-segmentation with sparse cooperative relations},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized textural rough sets: Rough set models over two
universes. <em>ISCI</em>, <em>521</em>, 398–421. (<a
href="https://doi.org/10.1016/j.ins.2020.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to reveal the useful aspects of textures for generalized approximation spaces in rough set theory . To this end, we present a counterpart of rough sets over two universes for textures. We compare the textural results with the well-known basic properties of rough sets given in the literature. First, we define a t-seriality and a t-inverse seriality in textures. We show that almost all basic results with respect to rough set model over two universes can be formulated using textures. On the way, we give new results and observations due to lower and upper approximation operators which are not taken into consideration by the researchers. Moreover, we also discuss the revised approximation operators and attribute oriented formal concept lattices in a textural framework.},
  archive      = {J_ISCI},
  author       = {Ayşegül Altay Uğur and Murat Diker},
  doi          = {10.1016/j.ins.2020.02.044},
  journal      = {Information Sciences},
  pages        = {398-421},
  shortjournal = {Inf. Sci.},
  title        = {Generalized textural rough sets: Rough set models over two universes},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Purchase intention-based agent for customer behaviours.
<em>ISCI</em>, <em>521</em>, 380–397. (<a
href="https://doi.org/10.1016/j.ins.2020.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating human activities remains a challenging problem because the decision-making mechanisms underlying these activities are difficult to reproduce and mimic. In this article, we are interested in the simulation of in-store shoppers whose activities are generally divided into two parts: a walking activity and a purchase activity. Since the act of buying is more complex than simply following a shopping list, we propose here to model the attraction relationships that can exist between a product and a customer. This attraction model is used to build a multi-agent simulation whose realism is evaluated through various experiments.},
  archive      = {J_ISCI},
  author       = {Arnaud Doniec and Stéphane Lecoeuche and René Mandiau and Antoine Sylvain},
  doi          = {10.1016/j.ins.2020.02.054},
  journal      = {Information Sciences},
  pages        = {380-397},
  shortjournal = {Inf. Sci.},
  title        = {Purchase intention-based agent for customer behaviours},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fusion collaborative filtering method for sparse data in
recommender systems. <em>ISCI</em>, <em>521</em>, 365–379. (<a
href="https://doi.org/10.1016/j.ins.2020.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering is a fundamental technique in recommender systems , for which memory-based and matrix-factorization-based collaborative filtering are the two types of widely used methods. However, the performance of these two types of methods is limited in the case of sparse data, particularly with extremely sparse data. To improve the effectiveness of the methods in a sparse scenario, this paper proposes a multi-factor similarity measure that captures linear and nonlinear correlations between users resulting from extreme behavior. Subsequently, a fusion method that simultaneously considers the multi-factor similarity and the global rating information in a probability matrix factorization framework is proposed. In our framework, users’ local relations are integrated into the global ratings optimization process, so that prediction accuracy and robustness are improved in sparse data, particularly in extremely sparse data. To verify the performance of the proposed methods, we conduct experiments on four public datasets. The experimental results show that the fusion method is superior to the typical matrix factorization models used in collaborative filtering and significantly improves both the prediction results and robustness in sparse data.},
  archive      = {J_ISCI},
  author       = {Chenjiao Feng and Jiye Liang and Peng Song and Zhiqiang Wang},
  doi          = {10.1016/j.ins.2020.02.052},
  journal      = {Information Sciences},
  pages        = {365-379},
  shortjournal = {Inf. Sci.},
  title        = {A fusion collaborative filtering method for sparse data in recommender systems},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Click-aware purchase prediction with push at the top.
<em>ISCI</em>, <em>521</em>, 350–364. (<a
href="https://doi.org/10.1016/j.ins.2020.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eliciting user preferences from purchase records for performing purchase prediction is challenging because negative feedback is not explicitly observed, and because treating all non-purchased items equally as negative feedback is unrealistic. Therefore, in this study, we present a framework that leverages the past click records of users to compensate for the missing user–item interactions of purchase records, i.e., non-purchased items. We begin by formulating various model assumptions, each one assuming a different order of user preferences among purchased, clicked-but- not-purchased, and non-clicked items, to study the usefulness of leveraging click records. We implement the model assumptions using the Bayesian personalized ranking model, which maximizes the area under the curve for bipartite ranking. However, we argue that using click records for bipartite ranking needs a meticulously designed model because of the relative unreliableness of click records compared with that of purchase records. Therefore, we ultimately propose a novel learning-to-rank method, called P3Stop, for performing purchase prediction. The proposed model is customized to be robust to relatively unreliable click records by particularly focusing on the accuracy of top-ranked items. Experimental results on two real-world e-commerce datasets demonstrate that P3STop considerably outperforms the state-of-the-art implicit-feedback-based recommendation methods, especially for top-ranked items.},
  archive      = {J_ISCI},
  author       = {Chanyoung Park and Donghyun Kim and Min-Chul Yang and Jung-Tae Lee and Hwanjo Yu},
  doi          = {10.1016/j.ins.2020.02.062},
  journal      = {Information Sciences},
  pages        = {350-364},
  shortjournal = {Inf. Sci.},
  title        = {Click-aware purchase prediction with push at the top},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A verifiable multiparty quantum key agreement based on
bivariate polynomial. <em>ISCI</em>, <em>521</em>, 343–349. (<a
href="https://doi.org/10.1016/j.ins.2020.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on a point-to-point quantum key distribution protocol and classical key distribution technologies, the concept of quantum-classical key and a new multi-party quantum-classical key agreement protocol is proposed in this paper. The distributor and any one of the participants use quantum key distribution protocol to negotiate subkey, then each of the participants shares his subkey with other participants using Shamir threshold secret sharing scheme , thus each participant will sort these subkeys and his own subkey in order, and eventually get this quantum-classical key. In this protocol, a pair of function values of binary polynomials are used to ensure the authentication of sub-shares and information among participants, and Lagrange interpolation formula of unary polynomials is used to ensure the recovery of subkeys. Security analysis shows that this protocol is secure, practical and effective.},
  archive      = {J_ISCI},
  author       = {Lei Li and Zhi Li},
  doi          = {10.1016/j.ins.2020.02.057},
  journal      = {Information Sciences},
  pages        = {343-349},
  shortjournal = {Inf. Sci.},
  title        = {A verifiable multiparty quantum key agreement based on bivariate polynomial},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Color image dehazing using gradient channel prior and guided
l0 filter. <em>ISCI</em>, <em>521</em>, 326–342. (<a
href="https://doi.org/10.1016/j.ins.2020.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images obtained in poor weather circumstances such as fog, haze, smog, and thin cloud, suffer from severe contrast, texture, edge, and color degradation issues. To restore these weather degraded images , haze removal techniques are required. An efficient Gradient channel prior (GCP) is designed in this paper. It overcomes various issues such as texture distortion, transmission map misestimation, color distortion, and edge degradation. Thereafter, the transmission map is further refined using a guided L 0 filter. Finally, the restoration model is also improved to reduce the over-saturation of pixels problem associated with the existing haze removal techniques. Extensive experimental results demonstrate that the proposed technique can significantly restore the hazy images, even if images contain high density of haze.},
  archive      = {J_ISCI},
  author       = {Manjit Kaur and Dilbag Singh and Vijay Kumar and Kehui Sun},
  doi          = {10.1016/j.ins.2020.02.048},
  journal      = {Information Sciences},
  pages        = {326-342},
  shortjournal = {Inf. Sci.},
  title        = {Color image dehazing using gradient channel prior and guided l0 filter},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network sparse representation: Decomposition,
dimensionality-reduction and reconstruction. <em>ISCI</em>,
<em>521</em>, 307–325. (<a
href="https://doi.org/10.1016/j.ins.2020.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network science is a field in which real-world systems are abstracted into complex networks for scientific analysis. Dimensionality reduction for large-scale complex networks to reduce the complexity of problems has become a research focus. In this study, we found that real-world networks are composed of a finite number of atoms through self-replication and superposition. Thus, they can be decomposed into a dictionary and sparse coding . The sparse representation we propose simplifies redundant complex structures and reveals the basis and its representation methods for complex networks. Difficult problems can be solved through this representation, including network similarity metrics, recognition, and reconstruction. Experimental results show that the atoms and sparse coding describe the basic structure and connection pattern of complex networks.},
  archive      = {J_ISCI},
  author       = {Xuemeng Zhai and Wanlei Zhou and Gaolei Fei and Cai Lu and Guangmin Hu},
  doi          = {10.1016/j.ins.2020.02.022},
  journal      = {Information Sciences},
  pages        = {307-325},
  shortjournal = {Inf. Sci.},
  title        = {Network sparse representation: Decomposition, dimensionality-reduction and reconstruction},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variational bayesian weighted complex network
reconstruction. <em>ISCI</em>, <em>521</em>, 291–306. (<a
href="https://doi.org/10.1016/j.ins.2020.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex network reconstruction is a hot topic in many fields. Currently, the most popular data-driven reconstruction framework is based on lasso. However, it is found that, in the presence of noise, lasso loses efficiency for weighted networks. This paper builds a new framework to cope with this problem. The key idea is to employ a series of linear regression problems to model the relationship between network nodes, and then to use an efficient variational Bayesian algorithm to infer the unknown coefficients . The numerical experiments conducted on both synthetic and real data demonstrate that the new method outperforms lasso with regard to both reconstruction accuracy and running speed.},
  archive      = {J_ISCI},
  author       = {Shuang Xu and Chunxia Zhang and Pei Wang and Jiangshe Zhang},
  doi          = {10.1016/j.ins.2020.02.050},
  journal      = {Information Sciences},
  pages        = {291-306},
  shortjournal = {Inf. Sci.},
  title        = {Variational bayesian weighted complex network reconstruction},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial temporal incidence dynamic graph neural networks for
traffic flow forecasting. <em>ISCI</em>, <em>521</em>, 277–290. (<a
href="https://doi.org/10.1016/j.ins.2020.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and real-time traffic passenger flows forecasting at transportation hubs, such as subway/bus stations, is a practical application and of great significance for urban traffic planning, control, guidance, etc. Recently deep learning based methods are promised to learn the spatial-temporal features from high non-linearity and complexity of traffic flows. However, it is still very challenging to handle so much complex factors including the urban transportation network topological structures and the laws of traffic flows with spatial and temporal dependencies. Considering both the static hybrid urban transportation network structures and dynamic spatial-temporal relationships among stations from historical traffic passenger flows, a more effective and fine-grained spatial-temporal features learning framework is necessary. In this paper, we propose a novel spatial-temporal incidence dynamic graph neural networks framework for urban traffic passenger flows prediction. We first model dynamic traffic station relationships over time as spatial-temporal incidence dynamic graph structures based on historically traffic passenger flows. Then we design a novel dynamic graph recurrent convolutional neural network , namely Dynamic-GRCNN, to learn the spatial-temporal features representation for urban transportation network topological structures and transportation hubs. To fully utilize the historical passenger flows, we sample the short-term, medium-term and long-term historical traffic data in training, which can capture the periodicity and trend of the traffic passenger flows at different stations. We conduct extensive experiments on different types of traffic passenger flows datasets including subway , taxi and bus flows in Beijing. The results show that the proposed Dynamic-GRCNN effectively captures comprehensive spatial-temporal correlations significantly and outperforms both traditional and deep learning based urban traffic passenger flows prediction methods.},
  archive      = {J_ISCI},
  author       = {Hao Peng and Hongfei Wang and Bowen Du and Md Zakirul Alam Bhuiyan and Hongyuan Ma and Jianwei Liu and Lihong Wang and Zeyu Yang and Linfeng Du and Senzhang Wang and Philip S. Yu},
  doi          = {10.1016/j.ins.2020.01.043},
  journal      = {Information Sciences},
  pages        = {277-290},
  shortjournal = {Inf. Sci.},
  title        = {Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable computation of higher order charlier moments for
signal and image reconstruction. <em>ISCI</em>, <em>521</em>, 251–276.
(<a href="https://doi.org/10.1016/j.ins.2020.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of high-order discrete orthogonal moments is very complex and unstable due to fluctuations in numerical polynomial values. In this paper, we will present new algorithms for the stable computation of high-order discrete orthogonal Charlier polynomials and moments. These algorithms are based on the use of modified recurrence relations of Charlier polynomials with respect to the order n and with respect to the variable x , and on the use of the modified Gram-Schmidt orthonormalization process (GSOP). The algorithms in question allow the cancellation of terms that cause the numerical fluctuations of Charlier polynomial values during the recursive calculations. They also preserve the orthogonality property of high-order Charlier polynomials, which enables an efficient analysis of large-size bio-signals and 2D/3D images. Therefore, the simulation results prove the efficiency of the proposed algorithms when it comes to reconstructing large-size bio-signals and images.},
  archive      = {J_ISCI},
  author       = {Achraf Daoui and Mohamed Yamni and Omar El ogri and Hicham Karmouni and Mhamed Sayyouri and Hassan Qjidaa},
  doi          = {10.1016/j.ins.2020.02.019},
  journal      = {Information Sciences},
  pages        = {251-276},
  shortjournal = {Inf. Sci.},
  title        = {Stable computation of higher order charlier moments for signal and image reconstruction},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New results on stabilization analysis for fuzzy semi-markov
jump chaotic systems with state quantized sampled-data controller.
<em>ISCI</em>, <em>521</em>, 231–250. (<a
href="https://doi.org/10.1016/j.ins.2020.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper, by designing a state quantized sampled-data controller, studies the issue of stochastic stabilization for fuzzy chaotic semi-Markov jump systems (FCSMJSs). First of all, to fully utilize more inner sampling information, a newly augmented Lyapunov functional is constructed on the basis of the proposed sampling-instant-to-present-time fragmentation (SITPTF) approach. Next, a new zero-valued equation, which increases the combinations of some resulting vectors, is given for the first time. After that, a useful discontinuous Lyapunov functional (DLF), which takes full advantage of the property of Wirtinger inequality, is proposed for the FCSMJSs with state quantized sampled-data controller. With the novel augmented Lyapunov functional, the DLF and new zero-valued equation, stochastic stabilization conditions are established. Moreover, in the case of no semi-Markov jump, new stabilization criteria are also got. Compared with some previous criteria, the novel stabilization criteria show less conservatism. Finally, the effectiveness and advantages of the proposed results are shown by several numerical examples.},
  archive      = {J_ISCI},
  author       = {Tao Wu and Lianglin Xiong and Jun Cheng and Xueqin Xie},
  doi          = {10.1016/j.ins.2020.02.051},
  journal      = {Information Sciences},
  pages        = {231-250},
  shortjournal = {Inf. Sci.},
  title        = {New results on stabilization analysis for fuzzy semi-markov jump chaotic systems with state quantized sampled-data controller},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MOEA/d with a self-adaptive weight vector adjustment
strategy based on chain segmentation. <em>ISCI</em>, <em>521</em>,
209–230. (<a href="https://doi.org/10.1016/j.ins.2020.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MOEA/D (multi-objective evolutionary algorithm based on decomposition) decomposes a multi-objective optimization problem (MOP) into a series of single-objective sub-problems through a scalarizing function and a set of uniformly distributed weight vectors , and optimizes these sub-problems simultaneously in a collaborative way. However, when the shape of the true Pareto front (PF) of the multi-objective problem has the characteristic of long tail and sharp peak, the performance of MOEA/D will be greatly affected, that is, the performance of the decomposition-based multi-objective evolutionary algorithm depends heavily on the shape of the true PF. In order to efficiently deal with this situation, a self-adaptive weight vector adjustment strategy based on chain segmentation strategy (CS) is proposed. More specifically, a chain structure is firstly derived from the current population distribution to approximate the shape of the true PF. Then each chain is evenly segmented, and the direction vector from the origin to each segment point is used as the new weight vector. Finally, a set of reasonably distributed weight vectors are obtained to improve the performance of the algorithm. In the experimental section, we integrate CS strategy with three variants of MOEA/D, and the results demonstrate the effectiveness of the proposed strategy. Furthermore, we use MOEA/D-DE (a variant of MOEA/D, which is based on differential evolution operator) as a paradigm to integrate the CS strategy, and compare it with five state-of-the-art algorithms to illustrate that the algorithm integrating the CS strategy is very competitive.},
  archive      = {J_ISCI},
  author       = {Zhiming Dong and Xianpeng Wang and Lixin Tang},
  doi          = {10.1016/j.ins.2020.02.056},
  journal      = {Information Sciences},
  pages        = {209-230},
  shortjournal = {Inf. Sci.},
  title        = {MOEA/D with a self-adaptive weight vector adjustment strategy based on chain segmentation},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hierarchical selection algorithm for multiple attributes
decision making with large-scale alternatives. <em>ISCI</em>,
<em>521</em>, 195–208. (<a
href="https://doi.org/10.1016/j.ins.2020.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multiple attributes decision making (MADM) problem in the presence of large-scale alternatives. Considering the large number of alternatives, we first try to identify if there exist some alternative sets with dominative patterns by determining a hyperplane . If so, the superior alternatives can be easily selected. We then exploit the “divide and conquer” idea and develop a hierarchical MADM algorithm, which selects locally superior alternatives iteratively until the globally best alternative is reached. Specifically, we first divide the large-scale alternatives into several clusters, and determine the attribute weights at each round. We then select the locally superior alternative in each cluster. The attribute weights are updated based on the former attributes weights after each clustering, so as to remain consistent with the attributes weights throughout the hierarchical MADM algorithm. Finally, numerical experiments are conducted to demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Shenghai Zhou and Xun Ji and Xuanhua Xu},
  doi          = {10.1016/j.ins.2020.02.030},
  journal      = {Information Sciences},
  pages        = {195-208},
  shortjournal = {Inf. Sci.},
  title        = {A hierarchical selection algorithm for multiple attributes decision making with large-scale alternatives},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pbsx: A practical private boolean search using intel SGX.
<em>ISCI</em>, <em>521</em>, 174–194. (<a
href="https://doi.org/10.1016/j.ins.2020.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searchable encryption enables private keyword search over encrypted data held on an untrusted cloud. However, existing searchable encryption schemes promise search efficiency at the expense of additional privacy leakage or expensive storage overhead . Intel SGX is a promising tool to allow efficient and private keyword search . However, since the size of enclave created by SGX is limited, frequent sensitive-page swaps between the enclave and the untrusted memory cause severe performance degradation for large datasets. Moreover, SGX does not protect against access pattern leakages which are vulnerable to statistical inference attacks. To overcome the above problems, we present Pbsx, an efficient private boolean searchable encryption scheme using Intel SGX. Pbsx firstly analyzes and chooses the suitable index data structures (e.g. bitmap and bloom filter tree) for private boolean search in the context of Intel SGX. Pbsx then combines these index data structures with oblivious random access machine (ORAM) schemes to design oblivious index data structures (e.g. oblivious bitmap and oblivious bloom filter tree), such that it could provide storage efficiency without suffering from access pattern leakages. Since the direct composition of the index data structures and the ORAM schemes is extremely costly for search operations, we design auxiliary data structures (e.g. map table and id index tree) to mitigate the efficiency barrier. Based on these oblivious index data structures, we propose oblivious search algorithms which can achieve a worst-case sub-linear search time. We implement Pbsx and evaluate the performance of our constructions with various metrics. Comparing with previous schemes, the results indicate that Pbsx can achieve a 5~12x speed-up for the million-level dataset and a 13~51x speed-up for the small dataset. In addition, Pbsx also achieves less access pattern leakages.},
  archive      = {J_ISCI},
  author       = {Qin Jiang and Yong Qi and Saiyu Qi and Wenjia Zhao and Youshui Lu},
  doi          = {10.1016/j.ins.2020.02.031},
  journal      = {Information Sciences},
  pages        = {174-194},
  shortjournal = {Inf. Sci.},
  title        = {Pbsx: A practical private boolean search using intel SGX},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy quality-aware queries to graph databases.
<em>ISCI</em>, <em>521</em>, 160–173. (<a
href="https://doi.org/10.1016/j.ins.2020.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph databases have aroused a large interest in the last years due to their large scope of potential applications (e.g., social networks, biomedical networks, data stemming from the web). However, much published data suffer from quality problems, and graph data are no exception. In this paper, we investigate the issue of dealing with quality information in graph databases, at querying time. A framework is provided that makes it possible to introduce fuzzy quality preferences into graph pattern queries. This question is answered first from a theoretical point of view and then with an application to the Neo4j database management system by the extension of the cypher query language , for which implementation issues are discussed.},
  archive      = {J_ISCI},
  author       = {Olivier Pivert and Etienne Scholly and Grégory Smits and Virginie Thion},
  doi          = {10.1016/j.ins.2020.02.035},
  journal      = {Information Sciences},
  pages        = {160-173},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy quality-aware queries to graph databases},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Knowledge graphs completion via probabilistic reasoning.
<em>ISCI</em>, <em>521</em>, 144–159. (<a
href="https://doi.org/10.1016/j.ins.2020.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing large-scale knowledge base has encountered a bottleneck because of the limitation of natural language processing . Many approaches have been put forward to infer new facts based on existing knowledge. Graph feature models mine rule-like patterns from a knowledge base and use them to predict missing edges. These models take account of the graph structure information and they can explain the existence of a fact reasonably. Existing models only describe local interaction between entities, but how to model co-relationships among facts globally is a tough problem. In this paper, we develop an efficient model which uses association rules to make inferences. First, we use a rule mining model to detect simple association rules and use them to produce large amounts of evidence. Second, based on all the produced evidence and the connections among them, we construct a factor graph which represents the inference space. Then, we develop an EM inference model, wherein the E-step we use Belief Propagation to calculate the marginal distribution of candidate edges and, in the M-step we propose a Generalized Iterative Proportional Fitting algorithm to re-learn the confidence of soft rules. Experiments show that our approach outperforms state-of-the-art approaches in knowledge base completion (KBC) tasks.},
  archive      = {J_ISCI},
  author       = {Richong Zhang and Yongyi Mao and Weihua Zhao},
  doi          = {10.1016/j.ins.2020.02.016},
  journal      = {Information Sciences},
  pages        = {144-159},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge graphs completion via probabilistic reasoning},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized training and scalable implementation of
conditional deep neural networks with early exits for fog-supported IoT
applications. <em>ISCI</em>, <em>521</em>, 107–143. (<a
href="https://doi.org/10.1016/j.ins.2020.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incoming IoT big data era requires efficient and resource-constrained mining of large sets of distributed data. This paper explores a possible approach to this end, combining the two emerging paradigms of Conditional Neural Networks with early exits and Fog Computing . Apart from describing the general framework, we provide four specific contributions. First, after reviewing the basic architectures of CDNNs with early exits and characterizing their computational capacity, we consider three basic algorithms for their supervised training (namely the End-to-End, Layer-Wise and Classifier-Wise training algorithms), and, then, formally characterize and compare the resulting tradeoffs in a Fog-supported implementation. Second, after presenting a reference architecture for the local classifiers equipping the considered CDNNs , we develop an optimized framework for the parallel and distributed setting of their decision thresholds. Third, we propose a greedy algorithm for placing the early exits efficiently on the considered CDNNs and prove its linear scaling complexity. Fourth, we analytically characterize in closed-form and analyze the energy performance of the optimal CDNN-onto-Fog mapping. Finally, extensive numerical tests are presented, in order to test and compare the energy-vs.-implementation complexity-vs.-accuracy performance of the resulting optimized CDNN-over-Fog platforms under the IoT-oriented SVHN and FER-2013 datasets.},
  archive      = {J_ISCI},
  author       = {Enzo Baccarelli and Simone Scardapane and Michele Scarpiniti and Alireza Momenzadeh and Aurelio Uncini},
  doi          = {10.1016/j.ins.2020.02.041},
  journal      = {Information Sciences},
  pages        = {107-143},
  shortjournal = {Inf. Sci.},
  title        = {Optimized training and scalable implementation of conditional deep neural networks with early exits for fog-supported IoT applications},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transfer-stable aggregation functions on finite lattices.
<em>ISCI</em>, <em>521</em>, 88–106. (<a
href="https://doi.org/10.1016/j.ins.2020.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper by Z. Kurač, 2019 deals with a new property, the so-called transfer-stability, characterizing the arithmetic mean . With this property, it is possible to define special forms of arithmetic mean on finite chains. The idempotence property was required for this definition. In this paper, we neglect this necessity and deal only with transfer-stable aggregation functions. Thanks to this fact, it is possible to define these aggregation functions on any finite lattice (hereinafter “lattice”) and not only on finite chains. Transfer-stable aggregation functions can be defined on any finite lattice . Nevertheless, there is a subclass of finite lattices, the so-called transfer-stable lattices, where the behavior of the transfer-stable aggregation functions is simply described because the transfer-stability classes are linearly ordered. Therefore, the main goal of this paper is characterization of these transfer-stable lattices. The second half of the paper deals with some useful properties associated with the lattice of all k -ary transfer-stable aggregation functions.},
  archive      = {J_ISCI},
  author       = {Zbyněk Kurač and Tomáš Riemel and Lenka Rýparová},
  doi          = {10.1016/j.ins.2020.02.043},
  journal      = {Information Sciences},
  pages        = {88-106},
  shortjournal = {Inf. Sci.},
  title        = {Transfer-stable aggregation functions on finite lattices},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forgery attacks on two provably secure certificateless
signature schemes. <em>ISCI</em>, <em>521</em>, 81–87. (<a
href="https://doi.org/10.1016/j.ins.2020.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Hashimoto and Ogata proposed a constant-size certificateless aggregate signature scheme based on bilinear pairings . Karati et al. constructed a new certificateless signature scheme without bilinear pairings . The schemes were proven secure against both Type I and Type II adversaries in the random oracle model under the hardness assumptions of the Elliptic Curve discrete logarithm problem and the Computational Diffie–Hellman problem. In this paper, we first show that Hashimoto and Ogata is insecure against a Super-Type I adversary who knows the user secret key associated to the replaced public key and suggest its improvement to prevent our attack. We also show that Karati et al.’s scheme is entirely broken: anyone can forge certificateless signatures on any messages for any identities from only publicly known information without using any secret information. Thus, the scheme is trivially insecure against the Type I adversary who can replace user public keys and the Type II adversary who knows the master secret key . The attack shows that their security proofs against the Type I and Type II adversaries are flawed since these forgery attacks are never reflected in the proofs. Thus, it should be proposed security models that cover various forgery attacks due to algebraic relations in the underlying groups.},
  archive      = {J_ISCI},
  author       = {Kyung-Ah Shim},
  doi          = {10.1016/j.ins.2020.02.014},
  journal      = {Information Sciences},
  pages        = {81-87},
  shortjournal = {Inf. Sci.},
  title        = {Forgery attacks on two provably secure certificateless signature schemes},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subpopulation initialization driven by linkage learning for
dealing with the long-way-to-stuck effect. <em>ISCI</em>, <em>521</em>,
62–80. (<a href="https://doi.org/10.1016/j.ins.2020.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maintenance of many subpopulations is an important technique employed in evolutionary methods. However, the use of a multi-population approach has its drawbacks. Among all, it requires spending high amounts of available resources. Therefore, the methods that dynamically manage the number of subpopulations gain an increasing interest due to their capability of adjusting the subpopulation number to their current state. They are shown to be capable of reaching excellent results. In this paper, we identify the Long-Way-To-Stuck effect and show it on the base of the practical, NP-complete problem. Such a phenomenon occurs when a randomly initialized population of an evolutionary method must be processed through many iterations before it is incapable of improving the best-found solution. If so, then a large amount of computational resources must be spent on subpopulation initialization, which may turn multi-population methods ineffective. Therefore, in this paper, we propose the Linkage Learning-Driven Subpopulation Initialization (LLDSI) that limits the costs of subpopulation initialization and significantly improves the effectiveness methods dynamically managing the subpopulation number.},
  archive      = {J_ISCI},
  author       = {Michał Witold Przewoźniczek},
  doi          = {10.1016/j.ins.2020.02.027},
  journal      = {Information Sciences},
  pages        = {62-80},
  shortjournal = {Inf. Sci.},
  title        = {Subpopulation initialization driven by linkage learning for dealing with the long-way-to-stuck effect},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Plausibility-promoting generative adversarial network for
abstractive text summarization with multi-task constraint.
<em>ISCI</em>, <em>521</em>, 46–61. (<a
href="https://doi.org/10.1016/j.ins.2020.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive text summarization is an essential task in natural language processing , which aims to generate concise and condensed summaries retaining the salient information of the input document. Despite the progress of previous work, generating summaries, which are informative, grammatically correct and diverse, remains challenging in practice. In this paper, we present a Plausibility-promoting Generative Adversarial Network for Abstractive Text Summarization with Multi-Task constraint (PGAN-ATSMT), which shows promising performance for generating informative, grammatically correct, and novel summaries. First, PGAN-ATSMT adopts a plausibility-promoting generative adversarial network, which jointly trains a discriminative model D and a generative model G via adversarial learning. The generative model G employs the sequence-to-sequence architecture as its backbone, taking as input the original text and generating a corresponding summary. A novel language model based discriminator D is proposed to distinguish the generated summaries by G from the ground truth summaries without the saturation issue in the previous binary classifier discriminator . The generative model G and the discriminative model D are learned with a minimax two-player game, thus this adversarial process can eventually adjust G to produce high-quality and plausible summaries. Second, we propose two extended regularizations for the generative model G using the multi-task learning, sharing its LSTM encoder and LSTM decoder with text categorization task and syntax annotation task, respectively. The auxiliary tasks help to improve the quality of locating salient information of a document and generate high-quality summaries from language modeling perspective alleviating the issues of incomplete sentences and duplicated words. Experimental results on two benchmark datasets illustrate that PGAN-ATSMT achieves better performance than the state-of-the-art baseline methods in terms of both quantitative and qualitative evaluations.},
  archive      = {J_ISCI},
  author       = {Min Yang and Xintong Wang and Yao Lu and Jianming Lv and Ying Shen and Chengming Li},
  doi          = {10.1016/j.ins.2020.02.040},
  journal      = {Information Sciences},
  pages        = {46-61},
  shortjournal = {Inf. Sci.},
  title        = {Plausibility-promoting generative adversarial network for abstractive text summarization with multi-task constraint},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of silicon content variation trend based on
fusion of multilevel features in blast furnace ironmaking.
<em>ISCI</em>, <em>521</em>, 32–45. (<a
href="https://doi.org/10.1016/j.ins.2020.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The silicon content variation trend, which can reflect the quality of molten iron, provides significant information that can assist in ensuring the smooth operation of a blast furnace. This paper proposes a novel dynamic data-driven model for the online classification of the variation trend for the silicon content. Typically, a dynamic model for the silicon content variation trend primarily relies on process data feature extraction. First, a multilevel features fusion algorithm based on mutual information is developed to extract a rich and robust feature representation. Subsequently, the fused multilevel feature vectors and their corresponding trend labels are fed into a recurrent neural network model to capture the process dynamics and classify the variation trend. An experimental simulation and industrial application verified the effectiveness and feasibility of the proposed method. The classification results can provide guidance to ensure that the quality of molten iron is maintained within the desired range in the ironmaking process.},
  archive      = {J_ISCI},
  author       = {Ke Jiang and Zhaohui Jiang and Yongfang Xie and Zhipeng Chen and Dong Pan and Weihua Gui},
  doi          = {10.1016/j.ins.2020.02.039},
  journal      = {Information Sciences},
  pages        = {32-45},
  shortjournal = {Inf. Sci.},
  title        = {Classification of silicon content variation trend based on fusion of multilevel features in blast furnace ironmaking},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving federated k-means for proactive caching
in next generation cellular networks. <em>ISCI</em>, <em>521</em>,
14–31. (<a href="https://doi.org/10.1016/j.ins.2020.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proactive caching is a novel smart communication resource management method that can offer intelligent and economic networking services in the next generation cellular networks . In proactive caching, a common operation is using k -means to estimate content popularity. However, during the process, the base stations have to collect user’s location and content preference information to train a k -means model, which causes user privacy leakage . And current privacy-preserving k -means schemes usually suffer dramatic user quality of experience reduction, and cannot deal with the user dropout condition. Therefore, we propose a privacy-preserving federated k -means scheme (named PFK-means) for proactive caching in the next generation cellular networks . PFK-means is based on two privacy-preserving techniques, federated learning and secret sharing. In PFK-means, a suite of secret sharing protocols are designed to lightweight and efficient federated learning of k -means. These protocols allow privacy-preserving k -means training for proactive caching when there are dropout users. We seriously analyze the security of PFK-means and conduct comprehensive experiments to prove its security, effectiveness and efficiency. Through comparison, we can conclude that PFK-means outperforms other existing related schemes.},
  archive      = {J_ISCI},
  author       = {Yang Liu and Zhuo Ma and Zheng Yan and Zhuzhu Wang and Ximeng Liu and Jianfeng Ma},
  doi          = {10.1016/j.ins.2020.02.042},
  journal      = {Information Sciences},
  pages        = {14-31},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving federated k-means for proactive caching in next generation cellular networks},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered bipartite consensus of multi-agent systems
with switching partial couplings and topologies. <em>ISCI</em>,
<em>521</em>, 1–13. (<a
href="https://doi.org/10.1016/j.ins.2020.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite consensus of multi-agent systems with switching communication topologies is addressed in this paper. Neighboring agents are partially coupled with each other and possess cooperative and antagonistic relationships. Moreover, the couplings can vary according to the change of topology. In order to reduce the number of control updates, centralized and distributed event-triggered mechanisms are adopted in designing consensus protocols. Particularly, the given event-triggered conditions are piecewise functions depending on the variable couplings and topologies. Based on the signed graph theory, the error system for bipartite consensus is derived, meanwhile, errors are verified to converge to zero by constructing a suitable Lyapunov function . A union graph is put forward to represent transmission of singe-level state information within a time interval , then bipartite consensus of the multi-agent system is realized if each union graph has a spanning tree. In addition, Zeno behavior is excluded in the presented event-triggered conditions. Numerical examples further validate the obtained theoretical results.},
  archive      = {J_ISCI},
  author       = {Aihua Hu and Yunyan Wang and Jinde Cao and Ahmed Alsaedi},
  doi          = {10.1016/j.ins.2020.02.038},
  journal      = {Information Sciences},
  pages        = {1-13},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered bipartite consensus of multi-agent systems with switching partial couplings and topologies},
  volume       = {521},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid classification algorithms based on instance
filtering. <em>ISCI</em>, <em>520</em>, 445–455. (<a
href="https://doi.org/10.1016/j.ins.2020.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basic classification algorithms induce a single model from training data. The interpretation of a model is relatively easy, while basic algorithms have limitations in achieving high accuracy. An instance misclassified by a model may be correctly predicted by another. Hybrid classification is a concept that employs basic classification algorithms for model induction and for data preprocessing . Misclassification instances are usually considered to be noise, yet those still may carry useful information for identifying the class values of some other instances. This study proposes hybrid classification algorithms in which training instances are filtered to build three models for prediction. Each testing instance is classified by exactly one of them. The algorithms involved in the proposed hybrid classification algorithms are decision tree induction and naïve Bayesian classifier . The testing results on twenty data sets demonstrate that our hybrid classification algorithms can significantly outperform the basic ones as well as the hybrid algorithm proposed in a previous study. The hybrid classification algorithms based on instance filtering achieve relatively high accuracy and maintain the easy interpretation of learning results.},
  archive      = {J_ISCI},
  author       = {Tzu-Tsung Wong and Nai-Yu Yang and Guo-Hong Chen},
  doi          = {10.1016/j.ins.2020.02.021},
  journal      = {Information Sciences},
  pages        = {445-455},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid classification algorithms based on instance filtering},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible spatial location-based PVO predictor for
high-fidelity reversible data hiding. <em>ISCI</em>, <em>520</em>,
431–444. (<a href="https://doi.org/10.1016/j.ins.2020.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An advanced predictor offers the most effective way for performance enhancement of prediction-error expansion (PEE) based reversible data hiding. Unlike conventional predictors which exploit the correlation among adjacent pixels , pixel-value-ordering (PVO) exploits the one between the largest/smallest two pixels within block regardless of where they are located. Later, the spatial location received the attention from Peng et al. and led to better expansion bins selection. In this paper, a flexible spatial location (FSL) strategy is proposed to optimize the utilization of spatial correlation in PVO prediction. With FSL, pixels within block are no longer collected in a fixed way (e.g., from top to bottom, left to right). Specifically, eight modes of defining spatial location are designed for pixel collection. After pixel sorting, the inverse number of the location sequence is used to evaluate all modes and determine the best one. By determining the optimal mode for each block, the prediction becomes adaptive and thus a prediction-error histogram with higher expansion bin will be obtained. Numerous PVO-based schemes will benefit from FSL. In this paper, how FSL is applied to conventional PEE and high-dimensional PEE is also introduced. Experimental results demonstrate that FSL-PVO is of great significance to better capacity-distortion trade-off.},
  archive      = {J_ISCI},
  author       = {Wenguang He and Zhanchuan Cai and Yaomin Wang},
  doi          = {10.1016/j.ins.2020.02.003},
  journal      = {Information Sciences},
  pages        = {431-444},
  shortjournal = {Inf. Sci.},
  title        = {Flexible spatial location-based PVO predictor for high-fidelity reversible data hiding},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards explainable personalized recommendations by learning
from users’ photos. <em>ISCI</em>, <em>520</em>, 416–430. (<a
href="https://doi.org/10.1016/j.ins.2020.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explaining the output of a complex system, such as a Recommender System (RS), is becoming of utmost importance for both users and companies. In this paper we explore the idea that personalized explanations can be learned as recommendation themselves. There are plenty of online services where users can upload some photos, in addition to rating items. We assume that users take these photos to reinforce or justify their opinions about the items. For this reason we try to predict what photo a user would take of an item, because that image is the argument that can best convince her of the qualities of the item. In this sense, an RS can explain its results and, therefore, increase its reliability. Furthermore, once we have a model to predict attractive images for users, we can estimate their distribution. Thus, the companies acquire a vivid knowledge about the aspects that the clients highlight of their products. The paper includes a formal framework that estimates the authorship probability for a given pair (user, photo). To illustrate the proposal, we use data gathered from TripAdvisor containing the reviews (with photos) of restaurants in six cities of different sizes.},
  archive      = {J_ISCI},
  author       = {Jorge Díez and Pablo Pérez-Núñez and Oscar Luaces and Beatriz Remeseiro and Antonio Bahamonde},
  doi          = {10.1016/j.ins.2020.02.018},
  journal      = {Information Sciences},
  pages        = {416-430},
  shortjournal = {Inf. Sci.},
  title        = {Towards explainable personalized recommendations by learning from users’ photos},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Space-sampling-based fault detection for nonlinear
spatiotemporal dynamic systems with markovian switching channel.
<em>ISCI</em>, <em>520</em>, 400–415. (<a
href="https://doi.org/10.1016/j.ins.2020.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This technical note is devoted to investigating the fault detection problem for a class of nonlinear spatiotemporal dynamic systems. Initially, by using sector nonlinearity approach, the considered nonlinear systems are represented by an Takagi–Sugeno fuzzy model. Second, a new measure method, piecewise measure, is introduced to save the cost of system design. Furthermore, taking into account the switching network transmission channel, a mode-dependent asynchronous fuzzy diagnostic observer is constructed. Then, the sufficient conditions that guarantee the disturbance/control-inputs robustness and fault sensitivity are established to optimize the fault detection system’s performance. Finally, a practical application (cooling fin of a high-speed aerospace vehicle) is given to illustrate the effectiveness of the developed diagnostic observer design strategy.},
  archive      = {J_ISCI},
  author       = {Xiaona Song and Mi Wang and Shuai Song and Zhaoke Ning},
  doi          = {10.1016/j.ins.2020.02.032},
  journal      = {Information Sciences},
  pages        = {400-415},
  shortjournal = {Inf. Sci.},
  title        = {Space-sampling-based fault detection for nonlinear spatiotemporal dynamic systems with markovian switching channel},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sentiment strength detection with a context-dependent
lexicon-based convolutional neural network. <em>ISCI</em>, <em>520</em>,
389–399. (<a href="https://doi.org/10.1016/j.ins.2020.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment strength detection is an essential task in sentiment analysis , wherein the sentiment strength of subjective text is automatically determined. Sentiment analysis has numerous applications in different sectors, including business and social domains. In this study, we present a model to effectively extract the features and strength of sentiment from words and text using a context-dependent, lexicon-based convolutional neural network . To build this convolutional neural network , the model is trained using the sentiment polarity for each word from a co-occurrence pattern of words and labels. Then, a context-dependent lexicon is generated from the corpus, which is used to generate positive and negative sentiment word embeddings . Positive sentiment word embeddings , negative sentiment word embeddings, and the pre-trained word embeddings are input to a 3-channel convolutional neural network (CNN) to predict the strength of the sentiments. Moreover, with the trained convolutional neural network model, we can obtain a learned sentiment strength-specific word embedding, which generates a sentiment strength-specific lexicon (SSS-Lex) that contains word associations and sentiment intensity scores. To validate the effectiveness of sentiment strength detection in the proposed model, we evaluate the model using six real-world datasets. Furthermore, to evaluate the sentiment strength-specific lexicon, we compare it with seven existing lexicons in three evaluation tasks from the SemEval-2015 and SemEval-2016 competitions. Experimental results indicate that the proposed model can predict the sentiment strength of documents more effectively than the baseline methods , and that the SSS-Lex is of higher quality than the existing lexicons.},
  archive      = {J_ISCI},
  author       = {Minghui Huang and Haoran Xie and Yanghui Rao and Jingrong Feng and Fu Lee Wang},
  doi          = {10.1016/j.ins.2020.02.026},
  journal      = {Information Sciences},
  pages        = {389-399},
  shortjournal = {Inf. Sci.},
  title        = {Sentiment strength detection with a context-dependent lexicon-based convolutional neural network},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A neighborhood rough set model with nominal metric
embedding. <em>ISCI</em>, <em>520</em>, 373–388. (<a
href="https://doi.org/10.1016/j.ins.2020.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is an essential tool for measuring uncertainty, which has been widely applied in attribute reduction algorithms. Most of the related researches focus on how to update the lower and the upper approximation operator to match data characteristics or how to improve the efficiency of the attribute reduction algorithm. However, in the nominal data environment, existing rough set models that use the Hamming metric and its variants to evaluate the relations between nominal objects can not capture the inherent ordered relationships and statistic information from nominal values due to the complexity of data. The missing information will affect the accuracy and validity of the data representation, thereby reducing the reliability of rough set models. To overcome this challenge, we propose a novel object dissimilarity measure , i.e., relative object dissimilarity metric(RODM) that learned from nominal data to replace the Hamming metric and then construct a ψ -neighborhood rough set model. It extends the classical rough set model to a robust, representative, and effective model which is close to the characteristics of nominal data. Based on the ψ -neighborhood rough set model, we propose a heuristic two-stage attribute reduction algorithm(HTSAR) to perform the feature selection task. Experiments show that the ψ -neighborhood rough set model can take advantage of more potential knowledge in nominal data and achieve better performance for attribute reduction than the existing rough set model.},
  archive      = {J_ISCI},
  author       = {Sheng Luo and Duoqian Miao and Zhifei Zhang and Yuanjian Zhang and Shengdan Hu},
  doi          = {10.1016/j.ins.2020.02.015},
  journal      = {Information Sciences},
  pages        = {373-388},
  shortjournal = {Inf. Sci.},
  title        = {A neighborhood rough set model with nominal metric embedding},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sliding-window probabilistic threshold aggregate queries on
uncertain data streams. <em>ISCI</em>, <em>520</em>, 353–372. (<a
href="https://doi.org/10.1016/j.ins.2020.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain data streams are ubiquitous in many sensing and networking environments. Probabilistic aggregate query that returns a probability distribution to denote possible answers is extensively used on such streams. In many monitoring applications, it is only necessary to know whether the result distribution exceeds user-defined thresholds. In this paper, we formalize two important query types: sliding-window probabilistic threshold sum query and sliding-window probabilistic threshold count query, which introduce two thresholds (probability and score) into the probability distribution. An intuition solution is to use existing probabilistic aggregate algorithms to obtain the probability distribution and then apply the thresholds to this probability distribution. However, this solution separates the threshold processing from query processing and results in low efficiency. Our work uses Gaussian mixture models to represent uncertain data. Based on the Gaussian properties and probability theory of this model, we design efficient algorithms to answer these queries, which include filtering strategies and exact calculations . Several techniques (e.g., characteristic function, incremental calculation, pruning strategy, and state transition equation) are integrated into the exact calculations to improve time and space efficiency. Experiments on real and synthetic datasets demonstrate that our algorithms outperform existing algorithms.},
  archive      = {J_ISCI},
  author       = {Donghui Chen and Ling Chen},
  doi          = {10.1016/j.ins.2020.02.029},
  journal      = {Information Sciences},
  pages        = {353-372},
  shortjournal = {Inf. Sci.},
  title        = {Sliding-window probabilistic threshold aggregate queries on uncertain data streams},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tackling mismatched uncertainty in robust
constraint-following control of underactuated systems. <em>ISCI</em>,
<em>520</em>, 337–352. (<a
href="https://doi.org/10.1016/j.ins.2020.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mismatched uncertainty makes the control for underactuated systems an intractable problem in the control field. This paper targets this problem based on constraint-following. The uncertainty is (possibly fast) time-varying and bounded. The control goal is to drive underactuated systems to follow prescribed constraints, which may be holonomic or nonholonomic, linear or nonlinear with respect to the velocity. The control is designed in two steps. First, the nominal control without addressing uncertainties and initial condition deviations is investigated. Second, we meticulously decompose uncertainty into matched and mismatched portions. This decomposition makes the mismatched uncertainty “disappear” in the stability analysis. Consequently, we are able to design a class of robust constraint-following controls free from mismatched uncertainty and only based on matched uncertainty. By the Lyapunov approach, we show that the proposed robust controls guarantee uniform boundedness and uniform ultimate boundedness for underactuated systems. Simulation results on a mobile robot are given for demonstrations.},
  archive      = {J_ISCI},
  author       = {Hui Yin and Ye-Hwa Chen and Jin Huang and Hui Lü},
  doi          = {10.1016/j.ins.2020.02.033},
  journal      = {Information Sciences},
  pages        = {337-352},
  shortjournal = {Inf. Sci.},
  title        = {Tackling mismatched uncertainty in robust constraint-following control of underactuated systems},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genie+OWA: Robustifying hierarchical clustering with
OWA-based linkages. <em>ISCI</em>, <em>520</em>, 324–336. (<a
href="https://doi.org/10.1016/j.ins.2020.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the application of the Ordered Weighted Averaging (OWA) data fusion operator in agglomerative hierarchical clustering . The examined setting generalises the well-known single, complete and average linkage schemes. It allows to embody expert knowledge in the cluster merge process and to provide a much wider range of possible linkages. We analyse various families of weighting functions on numerous benchmark data sets in order to assess their influence on the resulting cluster structure. Moreover, we inspect the correction for the inequality of cluster size distribution – similar to the one in the Genie algorithm. Our results demonstrate that by robustifying the procedure with the Genie correction, we can obtain a significant performance boost in terms of clustering quality . This is particularly beneficial in the case of the linkages based on the closest distances between clusters, including the single linkage and its “smoothed” counterparts. To explain this behaviour, we propose a new linkage process called three-stage OWA which yields further improvements. This way we confirm the intuition that hierarchical cluster analysis should rather take into account a few nearest neighbours of each point, instead of trying to adapt to their non-local neighbourhood.},
  archive      = {J_ISCI},
  author       = {Anna Cena and Marek Gagolewski},
  doi          = {10.1016/j.ins.2020.02.025},
  journal      = {Information Sciences},
  pages        = {324-336},
  shortjournal = {Inf. Sci.},
  title        = {Genie+OWA: Robustifying hierarchical clustering with OWA-based linkages},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Dynamic imbalanced business credit evaluation based on
learn++ with sliding time window and weight sampling and FCM with
multiple kernels. <em>ISCI</em>, <em>520</em>, 305–323. (<a
href="https://doi.org/10.1016/j.ins.2020.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A good model of business credit evaluation is an important tool for risk management. Although the dynamic imbalanced data flow is more consistent with the form of collected financial data in the actual situation, existing studies seldom research financial data as this form. This paper proposes a new ensemble model for dynamic imbalanced business credit evaluation based on the improved Learn++ and fuzzy c-means (FCM). To handle dynamic imbalanced financial data, Learn++ is improved by using a sliding time window (STW) and weight sampling (WS). This method is termed Learn++.STW-WS. STW can divide data with the same concept into the same dataset to solve the problem of concept drift which characteristic in dynamic data. Additionally, WS can redistribute the weights for samples of different classes to resolve the issue of imbalance. To satisfy the demand of Learn++.STW-WS on the prediction accuracy of a base classifier, FCM is improved by multiple kernels (MK), and is designated as MK-FCM. Several kernel functions are integrated to construct MK by the mean method, and MK is adopted to improve the calculation method of distances among points for FCM. Therefore, this new ensemble model can solve the problems of dynamic data and imbalanced classes at the same time. In the empirical research, financial data from Chinese listed companies are selected to evaluate business credit risk, and the associated models are adopted to make comparative analysis. The experiment results can fully demonstrate the good performance of the new ensemble model in terms of handling dynamic imbalanced financial data.},
  archive      = {J_ISCI},
  author       = {Lu Wang and Chong Wu},
  doi          = {10.1016/j.ins.2020.02.011},
  journal      = {Information Sciences},
  pages        = {305-323},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic imbalanced business credit evaluation based on learn++ with sliding time window and weight sampling and FCM with multiple kernels},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pre-registration of translated/distorted fingerprints based
on correlation and the orientation field. <em>ISCI</em>, <em>520</em>,
292–304. (<a href="https://doi.org/10.1016/j.ins.2020.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a combined algorithm to register a translated/distorted fingerprint against a reference fingerprint based on correlation and the orientation field. In the first step, correlation is adapted to realize rough registration for correction of the whole translation. As the second step, we register the location-aligned distorted fingerprint with the reference fingerprint by using the orientation filed to correct the nonrigid deformation. By registering a translated/distorted fingerprint against a reference fingerprint, we can increase the similarity of the corresponding fingerprints, thereby improving the result of fingerprint matching. Experiments have been carried out on three databases containing many translated/distorted fingerprints, namely, FVC2004 DB1, the Tsinghua Distorted Fingerprint database and the NIST SD27 database. We also compared our algorithm with other registration algorithms, and the experimental results show improvement in fingerprint matching when using the proposed algorithm for pre-registration.},
  archive      = {J_ISCI},
  author       = {Sheng Lan and Zhenhua Guo and Jane You},
  doi          = {10.1016/j.ins.2020.02.017},
  journal      = {Information Sciences},
  pages        = {292-304},
  shortjournal = {Inf. Sci.},
  title        = {Pre-registration of translated/distorted fingerprints based on correlation and the orientation field},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive finite-time neural control of non-strict feedback
systems subject to output constraint, unknown control direction, and
input nonlinearities. <em>ISCI</em>, <em>520</em>, 271–291. (<a
href="https://doi.org/10.1016/j.ins.2020.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the finite-time controller design for a class of nonlinear systems in the non-strict feedback form subject to unknown system dynamics and disturbances, arbitrary asymmetric time-varying output constraints, four types of input nonlinearities , and unknown control direction. Utilizing the barrier Lyapunov function (BLF) and backstepping technique, an adaptive finite-time controller has been proposed. The difficulties associating with non-strict feedback systems have been handled using the variable separation approach. Furthermore, the unknown control direction problem has been tackled by using the Nussbaum gain function. A unified framework has been utilized for handling four types of input nonlinearities, including saturation, deadzone, backlash, and hysteresis. By applying intelligent approximators, not only the unknown functions have been estimated, but also the explosion of complexity problem occurring in the backstepping technique has been avoided. To reduce the computational burden, only one adaptive law has been applied and the approximator functions are not involved in the control implementation. Under the designed controller, all closed-loop signals remain semi-globally practically finite-time stable (SGPFS) and the tracking error converges to a small neighborhood of the origin in a finite-time. The effectiveness of the proposed controller has been demonstrated through a simulation example.},
  archive      = {J_ISCI},
  author       = {Ali Kamalamiri and Mohammad Shahrokhi and Mohammaderfan Mohit},
  doi          = {10.1016/j.ins.2020.02.005},
  journal      = {Information Sciences},
  pages        = {271-291},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive finite-time neural control of non-strict feedback systems subject to output constraint, unknown control direction, and input nonlinearities},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Balancing composite motion optimization. <em>ISCI</em>,
<em>520</em>, 250–270. (<a
href="https://doi.org/10.1016/j.ins.2020.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic algorithms play an important role in the optimization field thanks to their robustness and programming simplicity. Many meta-heuristic methods have been devised in recent years. Inspired by nature, they usually simulate natural or human-specific phenomena in a better way. A large amount of them are based on complicated behaviors requiring several implementation steps and algorithm-specific control parameters, which impedes users and limits solutions to different types of optimization problems . Hence, designing effective simple and parameter-free optimization methods attracts much attention. In this paper, we propose a novel population-based optimization algorithm based on balancing composite motions (BCMO). The core idea is balancing composite motion properties of individuals in solution space. Equalizing global and local searches via a probabilistic selection model creates a movement mechanism of each individual. Four test suites selected in the literature, which vary from numerical benchmarks to practical problems, to demonstrate the performance of BCMO include: (1) 23 classical benchmark functions , (2) CEC 2005 benchmark functions , (3) CEC 2014 benchmark functions, and (4) 3 real engineering design problems . The statistical results reveal the promising performance and application of BCMO in a variety of optimization and practical problems with constrained and unknown search spaces.},
  archive      = {J_ISCI},
  author       = {Thang Le-Duc and Quoc-Hung Nguyen and H. Nguyen-Xuan},
  doi          = {10.1016/j.ins.2020.02.013},
  journal      = {Information Sciences},
  pages        = {250-270},
  shortjournal = {Inf. Sci.},
  title        = {Balancing composite motion optimization},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reachability preserving compression for dynamic graph.
<em>ISCI</em>, <em>520</em>, 232–249. (<a
href="https://doi.org/10.1016/j.ins.2020.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reachability preserving compression generates small graphs that preserve the information only relevant to reachability queries, and the compressed graph can answer any reachability query without decompression . Existing reachability preserving compression algorithms either require a long compression time or include redundant data in the compressed graph. In this paper, we propose a novel edge sorting alogrithm for fast, non-redudant reachability preserving compression. On the other hand, we found that the current incremental reachability compression algorithms for dynamic graphs may return incorrect results in some cases. Therefore, we propose two novel incremental reachability compression algorithms. An algorithm called incremental reachability preserving compression with optimum compression ratio, which generates an update compressed graph that is exactly the same as the graph computed by recompression . The other algorithm called fast incremental reachability preserving compression, which can update the compressed graph in a short time. Extensive experiments on real datasets show the efficiency and the effectiveness of our methods.},
  archive      = {J_ISCI},
  author       = {Yuzhi Liang and Chen chen and Yukun Wang and Kai Lei and Min Yang and Ziyu Lyu},
  doi          = {10.1016/j.ins.2020.02.028},
  journal      = {Information Sciences},
  pages        = {232-249},
  shortjournal = {Inf. Sci.},
  title        = {Reachability preserving compression for dynamic graph},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient and compact 3D local descriptor based on the
weighted height image. <em>ISCI</em>, <em>520</em>, 209–231. (<a
href="https://doi.org/10.1016/j.ins.2020.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D local descriptors are the fundamental and essential elements that have been commonly applied in 3D computer vision . This paper proposes a novel and effective 3D local descriptor for describing the 3D local shape. The research focuses on accelerating the descriptor generation by simplifying the Local Reference Frame (LRF) and optimizing the feature space through a Weighted Height Image (WHI). An in-depth theoretical analysis of the LRF is conducted. Then, this study proposes a simplified LRF to reduce the redundant computations of the covariance matrix and share the calculations with the 3D information coding. Besides, the feature space is modeled and analyzed in this paper. Based on the analysis, we propose a weighting function to strengthen the abilities of the feature representation. The experimental results indicate that the proposed WHI descriptor outperforms the state-of-the-art (SOTA) algorithms in terms of accuracy and efficiency. Meanwhile, the compactness of the WHI is about six times more than that of the SOTA algorithms. Moreover, for the application of point cloud registration, the proposed WHI exhibits high effectiveness in terms of both accuracy and real-time capability.},
  archive      = {J_ISCI},
  author       = {Tiecheng Sun and Guanghui Liu and Shuaicheng Liu and Fanman Meng and Liaoyuan Zeng and Ru Li},
  doi          = {10.1016/j.ins.2020.02.004},
  journal      = {Information Sciences},
  pages        = {209-231},
  shortjournal = {Inf. Sci.},
  title        = {An efficient and compact 3D local descriptor based on the weighted height image},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heuristic creation of deep rule ensemble through iterative
expansion of feature space. <em>ISCI</em>, <em>520</em>, 195–208. (<a
href="https://doi.org/10.1016/j.ins.2020.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rule learning approaches, which essentially aim to gerenate a decision tree or a set of “if-then” rules, have been popularly used in practice for automatically building rule-based models for prediction tasks, e.g., classification and regression. The key strength of rule-based models is their ability to interpret how an output is obtained given an input, in comparison with models trained by other machine learning approaches , e.g., neural networks . Moreover, ensemble learning approaches have been adopted as a popular way for advancing the performance of rule-based prediction through producing multiple rule-based models with diversity. Traditional approaches of ensemble learning are typically designed to train a single ensemble. In recent years, there have been some studies on creation of multiple ensembles towards increasing the diversity among rule-based models and the depth of ensemble learning. In this paper, we propose a feature expansion driven approach for automatic creation of deep rule ensembles, i.e., the dimensionality of the feature space is increased at each iteration by adding features newly created at the previous iteration. The proposed approach is compared with more recent approaches of rule learning and ensemble creation. The experimental results show that the proposed approach achieves improved performance on various data sets.},
  archive      = {J_ISCI},
  author       = {Han Liu and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.02.001},
  journal      = {Information Sciences},
  pages        = {195-208},
  shortjournal = {Inf. Sci.},
  title        = {Heuristic creation of deep rule ensemble through iterative expansion of feature space},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The fast image encryption algorithm based on lifting scheme
and chaos. <em>ISCI</em>, <em>520</em>, 177–194. (<a
href="https://doi.org/10.1016/j.ins.2020.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image encryption technology is one of the most important means of image information security. Most image encryption algorithms are based on a permutation−diffusion structure. However, some image cryptosystems based on this structure have been proved to be insecure. Thus, a new image encryption structure based on a lifting scheme is proposed in this study. In the proposed algorithm, the plain image is decomposed into low-frequency approximate components and high-frequency detailed components. Pseudo-random sequences generated by chaos are employed to sequentially disturb the two sets of components. Then a lifting scheme is used for image encryption. Compared to the currently popular permutation−diffusion structure, the proposed image cryptography requires fewer pseudo-random numbers, and it has a faster encryption speed and higher security. Simulations, performance analysis, and comparison tests show that the proposed method has the advantages of large key space, fast encryption and decryption speeds, strong system sensitivity, and excellent encryption security. The algorithm can be used in applications such as encryption of medical and cloud images.},
  archive      = {J_ISCI},
  author       = {Yong Zhang},
  doi          = {10.1016/j.ins.2020.02.012},
  journal      = {Information Sciences},
  pages        = {177-194},
  shortjournal = {Inf. Sci.},
  title        = {The fast image encryption algorithm based on lifting scheme and chaos},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering method for production of z-number based if-then
rules. <em>ISCI</em>, <em>520</em>, 155–176. (<a
href="https://doi.org/10.1016/j.ins.2020.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application of clustering algorithms to extract or summarize data from large data sets is a straightforward and effective approach. Sometimes data sets are not only large in size but also include imprecise and partially reliable pieces of information of probabilistic and possibilistic (fuzzy) nature. Information of this kind is referred to as bimodal information. There is a need to summarize such data into a compact set of human tractable “If-Then” rules, being a result of synergy of imprecision of both types. In this paper, we first present an approach to clustering with the purpose of extraction of probabilistic and fuzzy information (bimodal) categories suitable for formation of human-tractable rules. The suggested clustering algorithm utilizes the FCM objective function and an evolutionary algorithm to produce fuzzy sets of fuzzy clusters . To form Z-clusters and use them as components for the rules we exploit the relationship existing between Type-2 Fuzzy and Z-number concepts. A benchmark problem and a real-world application are considered to demonstrate the usefulness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {R.A. Aliev and Witold Pedrycz and B.G. Guirimov and O.H. Huseynov},
  doi          = {10.1016/j.ins.2020.02.002},
  journal      = {Information Sciences},
  pages        = {155-176},
  shortjournal = {Inf. Sci.},
  title        = {Clustering method for production of Z-number based if-then rules},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new secret handshake scheme with multi-symptom
intersection for mobile healthcare social networks. <em>ISCI</em>,
<em>520</em>, 142–154. (<a
href="https://doi.org/10.1016/j.ins.2020.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aggravating trend of aging population in modern societies, Mobile Healthcare Social Network (MHSN) is an attracting platform for improving the life quality of elderly patients and offering mutual supports. In a sustainable MHSN system, one essential issue is to protect sensitive healthcare information while providing information-sharing for patients with multiple symptoms. To achieve multi-symptom matching and cross-domain communications for patients in MHSNs, we propose a new Secret Handshake scheme with Multi-Symptom intersection ( MSSH ), which is derived from a linear-complexity Authorized Private Set Intersection (APSI) based on Schnorr signature. In MSSH , two anonymous patients, who have registered with independent healthcare centers, are able to successfully execute an affiliation-hiding mutual anonymous authentication only if their target authentication policies are satisfied. The authentication policy demands that the designated healthcare center should be matched and the cardinality of their symptoms intersection is not less than a threshold value. Meanwhile, the symptoms outside of the set intersection remain confidential. The formal analysis proves MSSH is secure under the Random Oracle Model (ROM). The experimental results demonstrate that MSSH is efficient and feasible in MHSNs.},
  archive      = {J_ISCI},
  author       = {Yamin Wen and Fangguo Zhang and Huaxiong Wang and Zheng Gong and Yinbin Miao and Yuqiao Deng},
  doi          = {10.1016/j.ins.2020.02.007},
  journal      = {Information Sciences},
  pages        = {142-154},
  shortjournal = {Inf. Sci.},
  title        = {A new secret handshake scheme with multi-symptom intersection for mobile healthcare social networks},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cryptanalysis of a DNA-based image encryption scheme.
<em>ISCI</em>, <em>520</em>, 130–141. (<a
href="https://doi.org/10.1016/j.ins.2020.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, an image encryption scheme using 2D Hénon-Sine map and DNA coding approach is proposed. It adopts the permutation-diffusion architecture. The DNA random coding and exclusive OR is introduced for image diffusion, while image scrambling is implemented by pixel swapping operations. This paper reveals that this encryption scheme is not as secure as declared. Substitution boxes (s-boxes) are firstly employed to summarize the involved complicated DNA encryption operations, the whole encryption scheme is subsequently relaxed as an s-box-then-permutation cipher. Chosen-plaintext attack is feasible for recovering the equivalent secret elements of the s-boxes and permutation vector. The proposed concept of generalizing DNA encryption as s-box substitution is expected to be beneficial for security evaluation and theoretical design of DNA-based image encryption schemes in the future.},
  archive      = {J_ISCI},
  author       = {Junxin Chen and Lei Chen and Yicong Zhou},
  doi          = {10.1016/j.ins.2020.02.024},
  journal      = {Information Sciences},
  pages        = {130-141},
  shortjournal = {Inf. Sci.},
  title        = {Cryptanalysis of a DNA-based image encryption scheme},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault tree and fuzzy d-s evidential reasoning combined
approach: An application in railway dangerous goods transportation
system accident analysis. <em>ISCI</em>, <em>520</em>, 117–129. (<a
href="https://doi.org/10.1016/j.ins.2019.12.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to manage the railway dangerous goods transportation system (RDNGTS) successfully, an explicit and effective previous accident analysis and accident control approach is essential and necessary. In this study a Fault Tree and Fuzzy D-S Evidential Reasoning combined approach is proposed to analyze the RDNGTS accident, which can solve the uncertainty modeling and information fusion problems existing in RDNGTS accident analysis. The approach has six steps: (i) identify causes of accident and calculate their weights based on Fault Tree, (ii) establish the Fuzzy Belief Structure model of causes of accident, (iii) handle initial qualitative and quantitative data, (iv) fuse the pre-processing data based on Fuzzy D-S Evidential Reasoning algorithm , (v) allocate Confidence Level of fuzzy intersection and, (vi) rank the final Fuzzy Belief Structure of each component based on trapezoidal fuzzy numbers and triangular fuzzy numbers. A historical lithium battery railway transportation accident happened in 2016 in China is applied as the background to examine the approach mentioned in this paper. The results show that professional skills and attitudes of transportation staffs are the weakest component in this lithium battery railway transportation accident. Managers of RDNGTS in China should pay more attentions to the professional skills and attitudes of transportation staffs. Some measures such as improve the awareness of safety and protection, train and examine the professional skills of transportation staffs, may be helpful in curbing the negligent working attitude of transportation staffs. Furthermore, the results also show that D-S Evidential Reasoning could provide a unified modeling framework for uncertain, incomplete, inaccurate and even ignorant information. It could solve the limitations in probability reasoning processes effectively.},
  archive      = {J_ISCI},
  author       = {Wencheng Huang and Yuankai Liu and Yue Zhang and Rui Zhang and Minhao Xu and Gatesi Jean De Dieu and Eric Antwi and Bin Shuai},
  doi          = {10.1016/j.ins.2019.12.089},
  journal      = {Information Sciences},
  pages        = {117-129},
  shortjournal = {Inf. Sci.},
  title        = {Fault tree and fuzzy D-S evidential reasoning combined approach: An application in railway dangerous goods transportation system accident analysis},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mode-dependent dynamic output feedback h∞ control of
networked systems with markovian jump delay via generalized integral
inequalities. <em>ISCI</em>, <em>520</em>, 105–116. (<a
href="https://doi.org/10.1016/j.ins.2020.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates stability analysis and design synthesis of a mode-dependent dynamic output feedback H ∞ robust control for networked control systems (NCSs). First, a generalized integral inequality is presented. Then based on this generalized integral inequality, a less conservative H ∞ stability analysis method for NCS with Markovian jump delay is derived. This stability analysis is then extended to design a mode-dependent robust H ∞ controller for NCS with Markovian jump delay. Finally, to verify the effectiveness of our method, two numerical simulations are carried out.},
  archive      = {J_ISCI},
  author       = {Wei Sun and Qiyue Li and Chanjuan Zhao and Sing-Kiong Nguang},
  doi          = {10.1016/j.ins.2020.02.023},
  journal      = {Information Sciences},
  pages        = {105-116},
  shortjournal = {Inf. Sci.},
  title        = {Mode-dependent dynamic output feedback h∞ control of networked systems with markovian jump delay via generalized integral inequalities},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling periodic and aperiodic tasks with time, energy
harvesting and precedence constraints on multi-core systems.
<em>ISCI</em>, <em>520</em>, 86–104. (<a
href="https://doi.org/10.1016/j.ins.2019.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the real-time scheduling problem of multi-core systems powered by renewable energy harvested from environment. They handle two types of software tasks which are mapped to cores statically and not allowed to migrate. A task can be periodic which may depend on other tasks’ results, or aperiodic which is added to the system to cope with external interruptions. The uncertainty of energy availability in energy harvesting systems makes real-time scheduling more challenging because energy constraints can be violated to ensure real-time performance. A novel scheduling strategy is proposed to effectively compute deadlines allowing for tasks and messages to meet related constraints. This method consists of two phases, (i) the first one defines different time slots each of which is characterized by energy and frequency parameters to cope with the energy availability issue, and (ii) the second one calculates the deadlines ensuring real-time system feasibility by considering the invocation of aperiodic task execution and task precedence constraints. The originality of the current work compared with related studies is that it deals with multi-core, periodic and aperiodic tasks, dependency, energy harvesting , and real-time aspects simultaneously.},
  archive      = {J_ISCI},
  author       = {Aicha Goubaa and Mohamed Khalgui and Zhiwu Li and Georg Frey and MengChu Zhou},
  doi          = {10.1016/j.ins.2019.12.034},
  journal      = {Information Sciences},
  pages        = {86-104},
  shortjournal = {Inf. Sci.},
  title        = {Scheduling periodic and aperiodic tasks with time, energy harvesting and precedence constraints on multi-core systems},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Summarization and visualization of multi-level and
multi-dimensional itemsets. <em>ISCI</em>, <em>520</em>, 63–85. (<a
href="https://doi.org/10.1016/j.ins.2020.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequent itemset (FI) mining aims at discovering relevant patterns from sets of transactions. In this work we focus on multi-level and multi-dimensional data, which provide a rich description of subjects through multiple features each at different levels of detail . Summarization of FIs has been only marginally addressed so far with specific reference to multi-level and multi-dimensional FIs. In this paper we fill this gap by proposing SUSHI, a framework for summarizing and visually exploring multi-level and multi-dimensional FIs. Specifically, SUSHI is based on (i) a similarity function for FIs which takes into account both their extensional (support-based) and intensional (feature-based) natures; (ii) theoretical results concerning antimonotonicity of support and similarity in multi-level settings, which allow us to propose an efficient clustering algorithm to generate hierarchical summaries; and (iii) two integrated approaches to summary visualization and exploration: a graph-based one, which highlights inter-cluster relationships, and a tree-based one, which emphasizes the relationships between the representative of each cluster and the other FIs in that cluster. SUSHI is evaluated using both a real and a synthetic dataset in terms of effectiveness, efficiency, and understandability of the summary, with reference to three different strategies for choosing cluster representatives. Overall, SUSHI shows to outperform previous approaches and to be a valuable tool to expedite the analysis of FIs. Besides, one of the three strategies for choosing cluster representatives shows to be the most effective one.},
  archive      = {J_ISCI},
  author       = {Matteo Francia and Matteo Golfarelli and Stefano Rizzi},
  doi          = {10.1016/j.ins.2020.02.006},
  journal      = {Information Sciences},
  pages        = {63-85},
  shortjournal = {Inf. Sci.},
  title        = {Summarization and visualization of multi-level and multi-dimensional itemsets},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel one-dimensional sine powered chaotic map and its
application in a new image encryption scheme. <em>ISCI</em>,
<em>520</em>, 46–62. (<a
href="https://doi.org/10.1016/j.ins.2020.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of data transmission technology, image encryption is becoming a widely discussed topic in the field of information security. In this paper, we introduce a novel one-dimensional sine powered chaotic system (1DSP). Evaluation of the proposed chaotic system indicates the existence of chaotic behavior with high sensitivity and randomness. We further present a new image encryption scheme using 1DSP (1DSP-IE). The proposed scheme uses the 1DSP for sequence addition to improve its security. Furthermore, row-by-row and column-by-column concepts are used for confusion and diffusion operations. This approach breaks the correlation of adjacent pixels by scrambling pixels out of their original rows and columns and applies bit-level pixel value manipulation for each row and then each column to spread any change in the plain image throughout the ciphered image. The simulation results of the proposed 1DSP-IE indicate an effective encryption and decryption process with good speed. In addition, the security analysis illustrates the ability of 1DSP-IE to provide a satisfying level of security in comparison with other image encryption schemes.},
  archive      = {J_ISCI},
  author       = {Ali Mansouri and Xingyuan Wang},
  doi          = {10.1016/j.ins.2020.02.008},
  journal      = {Information Sciences},
  pages        = {46-62},
  shortjournal = {Inf. Sci.},
  title        = {A novel one-dimensional sine powered chaotic map and its application in a new image encryption scheme},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensembles of cost-diverse bayesian neural learners for
imbalanced binary classification. <em>ISCI</em>, <em>520</em>, 31–45.
(<a href="https://doi.org/10.1016/j.ins.2019.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combining traditional diversity and re-balancing techniques serves to design effective ensembles for solving imbalanced classification problems. Therefore, to explore the performance of new diversification procedures and new re-balancing methods is an attractive research subject which can provide even better performances. In this contribution, we propose to create ensembles of the recently introduced binary Bayesian classifiers , that show intrinsic re-balancing capacities, by means of a diversification mechanism which is based on applying different cost policies to each ensemble learner as well as appropriate aggregation schemes. Experiments with an extensive number of representative imbalanced datasets and their comparison with those of several selected high-performance classifiers show that the proposed approach provides the best overal results.},
  archive      = {J_ISCI},
  author       = {Marcelino Lázaro and Francisco Herrera and Aníbal R. Figueiras-Vidal},
  doi          = {10.1016/j.ins.2019.12.050},
  journal      = {Information Sciences},
  pages        = {31-45},
  shortjournal = {Inf. Sci.},
  title        = {Ensembles of cost-diverse bayesian neural learners for imbalanced binary classification},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enabling cloud storage auditing with key-exposure resilience
under continual key-leakage. <em>ISCI</em>, <em>520</em>, 15–30. (<a
href="https://doi.org/10.1016/j.ins.2020.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage auditing is a service that is usually provided to enable clients to verify the integrity of their data stored in the cloud. However, clients risk exposing their secret key. To address the problem of key exposure, researchers have provided “Forward Security” by dividing the entire lifetime of the secret key into several periods and updating the secret key within each of these periods. Forward security can ensure the validity of authenticators before the period in which the secret key is fully exposed. However, the security of these protocols can be broken by launching side-channel attacks to leak the secret key partially rather than fully. In this study, we focus on implementing measures in cloud storage auditing to protect against side-channel attacks in practice. We formalize the definition and security model of a cloud storage auditing protocol, which supports forward security under continual key-leakage, and construct the first protocol. Our protocol remains secure even if an adversary obtains partial leakage of the secret key during a period. In addition, if the secret key were to be fully disclosed in a certain period, our protocol would maintain forward security. Therefore, the proposed protocol provides stronger security compared with existing protocols.},
  archive      = {J_ISCI},
  author       = {Chengyu Hu and Yuqin Xu and Pengtao Liu and Jia Yu and Shanqing Guo and Minghao Zhao},
  doi          = {10.1016/j.ins.2020.02.010},
  journal      = {Information Sciences},
  pages        = {15-30},
  shortjournal = {Inf. Sci.},
  title        = {Enabling cloud storage auditing with key-exposure resilience under continual key-leakage},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An end-to-end inverse reinforcement learning by a boosting
approach with relative entropy. <em>ISCI</em>, <em>520</em>, 1–14. (<a
href="https://doi.org/10.1016/j.ins.2020.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse reinforcement learning (IRL) involves imitating expert behaviors by recovering reward functions from demonstrations. This study proposes a model-free IRL algorithm to solve the dilemma of predicting the unknown reward function. The proposed end-to-end model comprises a dual structure of autoencoders in parallel. The model uses a state encoding method to reduce the computational complexity for high-dimensional environments and utilizes an Adaboost classifier to determine the difference between the predicted and demonstrated reward functions. Relative entropy is used as a metric to measure the difference between the demonstrated and the imitated behavior. The simulation experiments demonstrate the effectiveness of the proposed method in terms of the number of iterations that are required for the estimation.},
  archive      = {J_ISCI},
  author       = {Tao Zhang and Ying Liu and Maxwell Hwang and Kao-Shing Hwang and ChunYan Ma and Jing Cheng},
  doi          = {10.1016/j.ins.2020.01.023},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {An end-to-end inverse reinforcement learning by a boosting approach with relative entropy},
  volume       = {520},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relational galois connections between transitive digraphs:
Characterization and construction. <em>ISCI</em>, <em>519</em>, 439–450.
(<a href="https://doi.org/10.1016/j.ins.2020.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a twofold relational generalization of the notion of Galois connection . It is twofold because it is defined between sets endowed with arbitrary transitive relations and, moreover, both components of the connection are relations, not necessarily functions. A characterization theorem of the notion of relational Galois connection is provided and, then, it is proved that a suitable notion of closure can be obtained within this framework. Finally, we state a necessary and sufficient condition that allows to build a relational Galois connection starting from a single transitive digraph and a single binary relation .},
  archive      = {J_ISCI},
  author       = {Inma P. Cabrera and Pablo Cordero and Emilio Muñoz-Velasco and Manuel Ojeda-Aciego and Bernard De Baets},
  doi          = {10.1016/j.ins.2020.01.034},
  journal      = {Information Sciences},
  pages        = {439-450},
  shortjournal = {Inf. Sci.},
  title        = {Relational galois connections between transitive digraphs: Characterization and construction},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting evolutionary optimization via
fuzzy-classification-assisted selection. <em>ISCI</em>, <em>519</em>,
423–438. (<a href="https://doi.org/10.1016/j.ins.2020.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary optimization , solution selection is an important operator since it will be normally used to decide the optimization direction via determining new solutions. Most selection methods are objective fitness-based approaches which will lead to a waste of fitness evaluations. This is because some evaluated but unpromising solutions are discarded without contributing useful search information. We are, thus, motivated to treat the solution selection as a classification procedure, where the selected solutions and discarded solutions belong to different classes. However, another problem is that the difference between ‘promising’ and ‘unpromising’ solutions becomes fuzzy when iterations go on. Therefore, we employ fuzzy classification to predict the categories of solutions by the fuzzy membership function . And then the predicted results are used to assist solution selection to reduce the number of fitness evaluations. Finally, we propose a fuzzy-classification-assisted selection (FCAS) strategy to boost evolutionary optimization . FCAS is experimentally integrated into two state-of-the-art algorithms and studied on three test suites. The results reveal the efficiency of FCAS for boosting evolutionary optimization.},
  archive      = {J_ISCI},
  author       = {Jinyuan Zhang and Jimmy Xiangji Huang and Qinmin Vivian Hu},
  doi          = {10.1016/j.ins.2020.01.050},
  journal      = {Information Sciences},
  pages        = {423-438},
  shortjournal = {Inf. Sci.},
  title        = {Boosting evolutionary optimization via fuzzy-classification-assisted selection},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual-stream generative adversarial networks for
distributionally robust zero-shot learning. <em>ISCI</em>, <em>519</em>,
407–422. (<a href="https://doi.org/10.1016/j.ins.2020.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) in visual classification aims to recognize novel categories for which few or even no training samples are available. Through recent advances using generative adversarial networks (GANs) for cross-modal generation, several generative methods have been investigated for ZSL to classify unseen categories with synthetic samples. However, these GAN-based ZSL approaches still struggle to generate samples with semantic consistency and significant between-class discrepancy while preserving within-class diversity, which are vital to building classifiers for unseen classes. Accordingly, in this paper, we propose a robust dual-stream GAN to synthesize satisfactory samples for zero-shot visual classification. In more detail, the inter-class discrepancy is maximized by a backbone compatibility loss, which drives the center of the synthesized samples to move towards the center of real samples of the same class while moving further away from samples of different classes. Secondly, in order to preserve the intra-class diversity ignored by most extant paradigms, we propose a stochastic dispersion regularization to encourage the synthesized samples to be distributed at arbitrary points in the visual space of their categories. Finally, unlike previous methods that project visual samples back into semantic space and consequently cause an information degradation problem, we design a dual-stream generator to synthesize visual samples and reconstruct semantic embedding simultaneously, thereby ensuring semantic consistency . Our model outperforms the state-of-the-arts by 4.7\% and 3.0\% on average in two metrics over four real-world datasets, demonstrating its effectiveness and superiority.},
  archive      = {J_ISCI},
  author       = {Huan Liu and Lina Yao and Qinghua Zheng and Minnan Luo and Hongke Zhao and Yanzhang Lyu},
  doi          = {10.1016/j.ins.2020.01.025},
  journal      = {Information Sciences},
  pages        = {407-422},
  shortjournal = {Inf. Sci.},
  title        = {Dual-stream generative adversarial networks for distributionally robust zero-shot learning},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic framework for updating neighborhood
multigranulation approximations with the variation of objects.
<em>ISCI</em>, <em>519</em>, 382–406. (<a
href="https://doi.org/10.1016/j.ins.2019.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough approximations play a significant role in rule extraction and decision making. However, re-scanning the entire data set to update the approximations is time-consuming due to the dynamic characteristics of objects in a neighborhood multigranulation space. In order to reduce the computational time, the neighborhood multigranulation approximations need to be updated in an incremental manner based on previously saved knowledge. Therefore, in this study, we establish a dynamic framework for maintaining the positive, boundary, and negative regions in neighborhood multigranulation spaces when adding or deleting objects from the matrix perspective. First, we explore the incremental mechanisms for updating relevant matrices when adding or deleting multiple objects. Based on the proposed mechanisms, we design the corresponding dynamic algorithms to incrementally update the positive, boundary, and negative regions. Finally, we conduct empirical experiments on benchmark UCI data sets to assess the feasibility and efficiency of our updating algorithms, which demonstrate their promising performance.},
  archive      = {J_ISCI},
  author       = {Chengxiang Hu and Li Zhang},
  doi          = {10.1016/j.ins.2019.12.036},
  journal      = {Information Sciences},
  pages        = {382-406},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic framework for updating neighborhood multigranulation approximations with the variation of objects},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-step communication opinion dynamics model with
self-persistence and influence index for social networks based on the
DeGroot model. <em>ISCI</em>, <em>519</em>, 363–381. (<a
href="https://doi.org/10.1016/j.ins.2020.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing opinion dynamics models often fail to consider the relationship between one agent and people two degrees of separation from the agent. In addition, no accurate weight determination method has yet been fully developed. To address these limitations, this paper proposes a two-step communication opinion dynamics model based on the classical DeGroot model. Self-persistence is introduced to measure the individual’s adherence to the initial opinion, and a new weight determination method proposed that instead of distributing the weights evenly, defines an influence index that is calculated from the self-persistence and node degrees. To guide public opinion using the proposed opinion dynamics model, an optimization model is established by assuming a connected network; however, when the given network is not connected, a subnetwork recognition algorithm is developed and an edge adding algorithm is proposed to alter the structure. Three opinion control strategies are then used to control the opinion formation process. Numerical examples are given to verify the flexibility and practicality of the proposed opinion control strategies, and extensive simulations over random ER networks are given to provide insights into the parameter behavior of the three strategies.},
  archive      = {J_ISCI},
  author       = {Qinyue Zhou and Zhibin Wu and Abdulrahman H. Altalhi and Francisco Herrera},
  doi          = {10.1016/j.ins.2020.01.052},
  journal      = {Information Sciences},
  pages        = {363-381},
  shortjournal = {Inf. Sci.},
  title        = {A two-step communication opinion dynamics model with self-persistence and influence index for social networks based on the DeGroot model},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain-based fair payment smart contract for public
cloud storage auditing. <em>ISCI</em>, <em>519</em>, 348–362. (<a
href="https://doi.org/10.1016/j.ins.2020.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage plays an important role in today’s cloud ecosystem. Increasingly clients tend to outsource their data to the cloud. In spite of its copious advantages, integrity has always been a significant issue. The audit method is commonly used to ensure integrity in cloud scenarios. However, traditional auditing schemes expect a third-party auditor (TPA), which is not always available in the real world. Also, the former scheme implies a limited pay-as-you-go service, as it requires the client to pay for the service in advance. In this paper, we aim to address the aforementioned drawback by adopting blockchain to replace TPA and designing a blockchain-based fair payment smart contract for public cloud storage auditing. In our system, data owner and cloud service provider (CSP) will run a blockchain-based smart contract . The contract ensures that the CSP is required to submit data possession proof regularly. The CSP gets paid only if the verification is passed; otherwise, it gets no remuneration but has to pay the penalties. To reduce the number of interactions in the execution of contract, we present the notion of non-interactive public provable data possession and design a blockchain-based smart contract for public cloud storage auditing based on this primitive.},
  archive      = {J_ISCI},
  author       = {Hao Wang and Hong Qin and Minghao Zhao and Xiaochao Wei and Hua Shen and Willy Susilo},
  doi          = {10.1016/j.ins.2020.01.051},
  journal      = {Information Sciences},
  pages        = {348-362},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based fair payment smart contract for public cloud storage auditing},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A close neighbor mobility method using particle swarm
optimizer for solving multimodal optimization problems. <em>ISCI</em>,
<em>519</em>, 332–347. (<a
href="https://doi.org/10.1016/j.ins.2020.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Niching is an important technique for multimodal optimization. Most existing niching methods require specification of certain niching parameters in order to perform well. But these parameters are usually difficult to set because they depend on the problem. The particle swarm optimization algorithm using the ring neighborhood topology does not require any niche parameters, but the determination of the particle neighborhood in this method is based on the subscript of the particle, and the result fails to achieve the best performance. For better performance, in this paper, a particle swarm optimization algorithm based on the ring neighborhood topology of Euclidean distance between particles is proposed, which is called the close neighbor mobility optimization algorithm . The algorithm mainly includes the following three strategies: elite selection mechanism, close neighbor mobility strategy and modified DE strategy. It mainly uses the Euclidean distance between particles. Each particle forms its own unique niche, evolves in a local scope, and finally locates multiple global optimal solutions with high precision. The algorithm greatly improves the accuracy of the particle. The experimental results show that the close neighbor mobility optimization algorithm has better performance than most single-objective multi-modal algorithms.},
  archive      = {J_ISCI},
  author       = {Juan Zou and Qi Deng and Jinhua Zheng and Shengxiang Yang},
  doi          = {10.1016/j.ins.2020.01.049},
  journal      = {Information Sciences},
  pages        = {332-347},
  shortjournal = {Inf. Sci.},
  title        = {A close neighbor mobility method using particle swarm optimizer for solving multimodal optimization problems},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive bayesian approach to surrogate-assisted
evolutionary multi-objective optimization. <em>ISCI</em>, <em>519</em>,
317–331. (<a href="https://doi.org/10.1016/j.ins.2020.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate models have been widely used for solving computationally expensive multi-objective optimization problems (MOPs). The efficient global optimization (EGO) algorithm, a Bayesian approach to surrogate-assisted optimization, has become very popular in surrogate-assisted evolutionary optimization . In this paper, we propose an adaptive Bayesian approach to surrogate-assisted evolutionary algorithm to solve expensive MOPs. The main idea is to tune the hyperparameter in the acquisition function according to the search dynamics to determine which candidate solutions are to be evaluated using the expensive real objective functions. In addition, the sampling selection criterion switches between an angle based distance and an angle-penalized distance over the course of optimization to achieve a better balance between exploration and exploitation. The performance of the proposed algorithm is examined on a set of benchmark problems and an airfoil design optimization problem using a maximum of 300 real fitness evaluations. Our experimental results show that the proposed algorithm is competitive compared to four popular multi-objective evolutionary algorithms.},
  archive      = {J_ISCI},
  author       = {Xilu Wang and Yaochu Jin and Sebastian Schmitt and Markus Olhofer},
  doi          = {10.1016/j.ins.2020.01.048},
  journal      = {Information Sciences},
  pages        = {317-331},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive bayesian approach to surrogate-assisted evolutionary multi-objective optimization},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). A novel hybrid deep recommendation system to differentiate
user’s preference and item’s attractiveness. <em>ISCI</em>,
<em>519</em>, 306–316. (<a
href="https://doi.org/10.1016/j.ins.2020.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the fast development of online E-commerce Websites and mobile applications, users’ auxiliary information as well as products’ textual information can be easily collected to form a vast amount of training data. Therefore, research efforts are urgently needed to make customized recommendations using such large but sparse data. Deep recommendation model is a natural choice for this research issue. However, most existing approaches try to investigate either user’s auxiliary information such as age and zipcode, or item’s textual information such as product descriptions, reviews or comments. Therefore, it is desired to see whether user’s auxiliary information and item’s textual information could be modeled simultaneously. This paper proposes a novel approach which is essentially a hybrid probabilistic matrix factorization model. Particularly, it has two sub components. One component tries to predict user’s rating scores by capturing user’s personal preferences extracted from auxiliary information. Another component tries to model item’s textual attractiveness to different users via a proposed attention based convolutional neural network . We then propose a global objective function and optimize these two sub components under a unified framework. Extensive experiments are performed on five real-world datasets, i.e., ML-100K, ML-1M, ML-10M, AIV and Amazon sub dataset. The promising experimental results have demonstrated the superiority of our proposed approach when compared with both baseline models and state-of-the-art deep recommendation approaches, i.e., PMF, CDL, CTR, ConvMF, ConvMF+ and D-Attn with respect to RMSE criterion.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Zhang and Huijie Liu and Xiaoyun Chen and Jingbin Zhong and Di Wang},
  doi          = {10.1016/j.ins.2020.01.044},
  journal      = {Information Sciences},
  pages        = {306-316},
  shortjournal = {Inf. Sci.},
  title        = {A novel hybrid deep recommendation system to differentiate user’s preference and item’s attractiveness},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A probability distribution detection based hybrid ensemble
QoS prediction approach. <em>ISCI</em>, <em>519</em>, 289–305. (<a
href="https://doi.org/10.1016/j.ins.2020.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the rapid increase in the number of web services, how to discover services to meet personalized requirements of users in large-scale scenarios has become a popular topic in both industry and academia. The quality of service (QoS) prediction-based web service recommendation system has been widely studied as an effective method for solving this problem. However, due to the sparsity and imbalance of the observed QoS data, existing QoS prediction approaches suffer from limited prediction accuracy and poor scalability. Moreover, existing QoS prediction approaches do not consider the probability distribution of the observed QoS data, which have remarkable impacts on the prediction performance. In this paper, we propose a novel probability distribution detection-based hybrid ensemble QoS prediction model that can dynamically integrate a set of basic prediction models to improve the prediction accuracy instead of designing complex and time-consuming models. Specifically, we first propose an enhanced CF (collaborative filtering)-based approach as the basis of the prediction model. Second, given the results of a set of other basic prediction models, in addition, we propose a distribution detection algorithm to calculate the PCWs (probability confidence weights) of those results. Finally, we combine them dynamically to obtain final results based on PCWs. Experiments based on real datasets show that our approach has higher prediction accuracy and better scalability than existing mainstream QoS prediction approaches.},
  archive      = {J_ISCI},
  author       = {Jun Li and Jian Lin},
  doi          = {10.1016/j.ins.2020.01.046},
  journal      = {Information Sciences},
  pages        = {289-305},
  shortjournal = {Inf. Sci.},
  title        = {A probability distribution detection based hybrid ensemble QoS prediction approach},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recalling-enhanced recurrent neural network: Conjugate
gradient learning algorithm and its convergence analysis. <em>ISCI</em>,
<em>519</em>, 273–288. (<a
href="https://doi.org/10.1016/j.ins.2020.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elman network is a classical recurrent neural network with an internal delay feedback. In this paper, we propose a recalling-enhanced recurrent neural network (RERNN) which has a selective memory property. In addition, an improved conjugate algorithm with generalized Armijo search technique that speeds up the convergence rate is used to train the RERNN model. Further enhancement performance is achieved with adaptive learning coefficients. Finally, we prove weak and strong convergence of the presented algorithm. In other words, as the number of training steps increases, the following has been established for RERNN: (1) the gradient norm of the error function with respect to the weight vectors converges to zero, (2) the weight sequence approaches a fixed optimal point. We have carried out a number of simulations to illustrate and verify the theoretical results that demonstrate the efficiency of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Tao Gao and Xiaoling Gong and Kai Zhang and Feng Lin and Jian Wang and Tingwen Huang and Jacek M. Zurada},
  doi          = {10.1016/j.ins.2020.01.045},
  journal      = {Information Sciences},
  pages        = {273-288},
  shortjournal = {Inf. Sci.},
  title        = {A recalling-enhanced recurrent neural network: Conjugate gradient learning algorithm and its convergence analysis},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic event-triggered resilient control approach to
cyber-physical systems under asynchronous DoS attacks. <em>ISCI</em>,
<em>519</em>, 260–272. (<a
href="https://doi.org/10.1016/j.ins.2020.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the resilient control problem for cyber-physical systems in the presence of denial-of-service (DoS) attacks which are characterized by frequency and duration properties is investigated. We consider the case that information transmission between measurement and control channels may be attacked asynchronously. A novel model is established to describe the asynchronous attack signals by a recursive characterization. Based on this model, a dynamic event-triggered resilient control approach is presented with the aim of resisting the DoS attacks. The stability criterion is derived via the Lyapunov stability theory . In contrast to the existing results on the static event-triggered mechanism, the developed method is more flexible and generates fewer events. Finally, simulation results are provided to verify the effectiveness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Zhi-Hui Zhang and Dan Liu and Chao Deng and Quan-Yong Fan},
  doi          = {10.1016/j.ins.2020.01.047},
  journal      = {Information Sciences},
  pages        = {260-272},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic event-triggered resilient control approach to cyber-physical systems under asynchronous DoS attacks},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An association-constrained LDA model for joint extraction of
product aspects and opinions. <em>ISCI</em>, <em>519</em>, 243–259. (<a
href="https://doi.org/10.1016/j.ins.2020.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Latent Dirichlet Allocation (LDA) model, which is a document-level probabilistic model, has been widely used in topic modeling. However, an essential issue of the LDA is its shortage in identifying co-occurrence relationships (e.g., aspect-aspect, aspect-opinion, etc.) in sentences. To address the problem, we propose an association constrained LDA (AC-LDA) for effectively capturing the co-occurrence relationships. Specifically, based on the basic features of the syntactic structure in product reviews, we formalize three major types of word association combinations and then carefully design corresponding identifications. For reducing the influence of global aspect words on the local distribution, we apply an important constraint on global aspects. Finally, the constraint and related association combinations are merged into the LDA to guide the topic-words allocation in the learning process. Based on the experiments on real-world product review data, we demonstrate that our model can effectively capture the relationships hidden in local sentences and further increase the extraction rate of fine-grained aspects and opinion words. Our results confirm the superiority of the AC-LDA over the state-of-the-art methods in terms of the extraction accuracy. We also verify the strength of our method in identifying irregularly appeared terms, such as non-aspect opinions, low-frequency words, and secondary aspects.},
  archive      = {J_ISCI},
  author       = {Changxuan Wan and Yun Peng and Keli Xiao and Xiping Liu and Tengjiao Jiang and Dexi Liu},
  doi          = {10.1016/j.ins.2020.01.036},
  journal      = {Information Sciences},
  pages        = {243-259},
  shortjournal = {Inf. Sci.},
  title        = {An association-constrained LDA model for joint extraction of product aspects and opinions},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Input initialization for inversion of neural networks using
k-nearest neighbor approach. <em>ISCI</em>, <em>519</em>, 229–242. (<a
href="https://doi.org/10.1016/j.ins.2020.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inversion of neural networks aims to find optimal input variables given a target output, and is widely applicable in an industrial field such as optimizing control variables of complex systems in manufacturing facilities. To achieve optimal inputs using a standard first-order optimization technique, proper initialization of input variables is essential. This paper presents a new initialization method for input variables of neural networks based on k -nearest neighbor ( k -NN) approach. The proposed method finds inputs which resulted in an output close to a target output in a training dataset, and combine them to form initial input variables. Experiments on a toy dataset demonstrate that our method outperforms random initialization. Also, we introduce an exhaustive case study on power scheduling of a heating, ventilation, and air conditioning (HVAC) system in a building to support the effectiveness of the algorithm.},
  archive      = {J_ISCI},
  author       = {Seongbo Jang and Ye-Eun Jang and Young-Jin Kim and Hwanjo Yu},
  doi          = {10.1016/j.ins.2020.01.041},
  journal      = {Information Sciences},
  pages        = {229-242},
  shortjournal = {Inf. Sci.},
  title        = {Input initialization for inversion of neural networks using k-nearest neighbor approach},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combinatorial trace method for network immunization.
<em>ISCI</em>, <em>519</em>, 215–228. (<a
href="https://doi.org/10.1016/j.ins.2020.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Immunizing a subset of nodes in a network - enabling them to identify and withstand the spread of harmful content - is one of the most effective ways to counter the spread of malicious content . It has applications in network security , public health policy, and social media surveillance. Finding a subset of nodes whose immunization results in the least vulnerability of the network is a computationally challenging task. In this work, we establish a relationship between a widely used network vulnerability measure and the combinatorial properties of networks. Using this relationship and graph summarization techniques, we propose an efficient approximation algorithm to find a set of nodes to immunize. We provide theoretical justifications for the proposed solution and analytical bounds on the runtime of our algorithm. We empirically demonstrate on various real-world networks that the performance of our algorithm is an order of magnitude better than the state of the art solution. We also show that in practice the runtime of our algorithm is significantly lower than that of the best-known solution.},
  archive      = {J_ISCI},
  author       = {Muhammad Ahmad and Sarwan Ali and Juvaria Tariq and Imdadullah Khan and Mudassir Shabbir and Arif Zaman},
  doi          = {10.1016/j.ins.2020.01.037},
  journal      = {Information Sciences},
  pages        = {215-228},
  shortjournal = {Inf. Sci.},
  title        = {Combinatorial trace method for network immunization},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust trimap generation based on manifold ranking.
<em>ISCI</em>, <em>519</em>, 200–214. (<a
href="https://doi.org/10.1016/j.ins.2020.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a simple and effective method for creating accurate trimaps based on input images. Most advanced matting algorithms require the user to provide prior information to estimate high-quality alpha masks, where the prior information is primarily in the form of trimaps. A precise trimap is one of the most important factors affecting the performance of the matting algorithm. It is a very tedious task for users to specify a large number of accurate trimaps, and it is even impractical in some applications. Based on manifold ranking, we use strokes to mark the superpixel nodes to create high-quality trimaps. The experimental results show that the method given in this paper can generate high-quality trimaps, thus ensuring the accuracy of the alpha masks that are estimated by the matting algorithm. We verify the performance of the trimaps that are created using the method given in this paper for various matting algorithms.},
  archive      = {J_ISCI},
  author       = {Jinjiang Li and Genji Yuan and Hui Fan},
  doi          = {10.1016/j.ins.2020.01.017},
  journal      = {Information Sciences},
  pages        = {200-214},
  shortjournal = {Inf. Sci.},
  title        = {Robust trimap generation based on manifold ranking},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). T-s fuzzy-based sliding mode controller design for
discrete-time nonlinear model and its applications. <em>ISCI</em>,
<em>519</em>, 183–199. (<a
href="https://doi.org/10.1016/j.ins.2020.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the Takagi–Sugeno (T–S) fuzzy based sliding-mode control (SMC) design of the discrete-time nonlinear model . By constructing a suitable fuzzy membership functions (FMFs) dependent Lyapunov function , the sufficient conditions are derived such that the resultant discrete-time T-S fuzzy model can achieve strictly ( Q , S , R ) − γ (Q,S,R)−γ dissipative, where Q , Q, S S and R R are known matrices with compatible dimensions satisfying Q ≤ 0 Q≤0 and R = R T , R=RT, and γ is a positive constant. Then, the desired control gain can be obtained by solving a set of linear matrix inequalities (LMIs). Besides that, a fuzzy SMC is designed to assure reaching condition. A modified fuzzy sliding-mode controller is also constructed to adapt input saturation. Finally, simulation results are presented to demonstrate the applicability and effectiveness of the proposed approaches.},
  archive      = {J_ISCI},
  author       = {Ramasamy Subramaniam and Dongran Song and Young Hoon Joo},
  doi          = {10.1016/j.ins.2020.01.010},
  journal      = {Information Sciences},
  pages        = {183-199},
  shortjournal = {Inf. Sci.},
  title        = {T-S fuzzy-based sliding mode controller design for discrete-time nonlinear model and its applications},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved SVD-based blind color image watermarking
algorithm with mixed modulation incorporated. <em>ISCI</em>,
<em>519</em>, 161–182. (<a
href="https://doi.org/10.1016/j.ins.2020.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study systematically investigated the use of singular value decomposition (SVD) for the blind watermarking of color images. The proposed algorithm overcomes most of the problems typically encountered when using existing SVD-based schemes, while concurrently enhancing performance in terms of imperceptibility and robustness. After applying SVD to non-overlapping 4 × 4 image blocks, level shifting is used to control the embedding strength in accordance with the intensity of pixels in each block. The proposed watermark embedding process helps to preserve orthonormality in the unitary matrix and compensate for the resulting distortion. Iterative regulation ensures the accurate retrieval of the embedded watermark, while mixed modulation helps to improve robustness without compromising image quality. Experiment results demonstrate that the proposed watermarking algorithm is highly resistant to a variety of image processing attacks and error-free in the absence of attack. The proposed method outperforms existing SVD-based schemes in terms of imperceptibility and robustness at a payload capacity of 1/16 bit per pixel.},
  archive      = {J_ISCI},
  author       = {Hwai-Tsu Hu and Ling-Yuan Hsu and Hsien-Hsin Chou},
  doi          = {10.1016/j.ins.2020.01.019},
  journal      = {Information Sciences},
  pages        = {161-182},
  shortjournal = {Inf. Sci.},
  title        = {An improved SVD-based blind color image watermarking algorithm with mixed modulation incorporated},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating reinforcement learning and skyline computing for
adaptive service composition. <em>ISCI</em>, <em>519</em>, 141–160. (<a
href="https://doi.org/10.1016/j.ins.2020.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In service computing, combining multiple services through service composition to address complex user requirements has become a popular research topic. QoS-aware service composition aims to find the optimal composition scheme with the QoS attributes that best match user requirements. However, certain QoS attributes may continuously change in a dynamic service environment, so service composition methods need to be adaptive. Furthermore, the large number of candidate services poses a key challenge for service composition, where existing service composition approaches based on reinforcement learning (RL) suffer from low efficiency. To deal with the problems above, in this paper, a new service composition approach is proposed which combines RL with skyline computing where the latter is used for reducing the search space and computational complexity . A WSC-MDP model is proposed to solve the large-scale service composition within a dynamically changing environment. To verify the proposed method, a series of comparative experiments are conducted, and the experimental results demonstrate the effectiveness, scalability and adaptability of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Hongbing Wang and Xingguo Hu and Qi Yu and Mingzhu Gu and Wei Zhao and Jia Yan and Tianjing Hong},
  doi          = {10.1016/j.ins.2020.01.039},
  journal      = {Information Sciences},
  pages        = {141-160},
  shortjournal = {Inf. Sci.},
  title        = {Integrating reinforcement learning and skyline computing for adaptive service composition},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Targeted influence maximization under a multifactor-based
information propagation model. <em>ISCI</em>, <em>519</em>, 124–140. (<a
href="https://doi.org/10.1016/j.ins.2020.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information propagation modeling and influence maximization are two important research problems in viral marketing. When marketing information is given, how can the seed nodes be efficiently identified to maximize the spread of the information through the network? To answer this question, we consider multiple factors in information propagation, such as information content, social influence and user authority, and propose a multifactor-based information propagation model (MFIP). Then, we utilize the first-order influence of the nodes to approximate their influence and propose an efficient heuristic algorithm named weighted degree decrease (WDD) to select the seed nodes under the MFIP model. Experimental evaluations with four real-world social network datasets demonstrate the effectiveness and efficiency of our algorithm.},
  archive      = {J_ISCI},
  author       = {Lingfei Li and Yezheng Liu and Qing Zhou and Wei Yang and Jiahang Yuan},
  doi          = {10.1016/j.ins.2020.01.040},
  journal      = {Information Sciences},
  pages        = {124-140},
  shortjournal = {Inf. Sci.},
  title        = {Targeted influence maximization under a multifactor-based information propagation model},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered constrained control with DHP implementation
for nonaffine discrete-time systems. <em>ISCI</em>, <em>519</em>,
110–123. (<a href="https://doi.org/10.1016/j.ins.2020.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an event-based near-optimal control algorithm for nonaffine discrete-time systems with constrained inputs. The method is derived from the dual heuristic dynamic programming (DHP) technique. The challenge caused by saturating actuators is overcome by using a nonquadratic performance index. Then, the event-based control technique is used to decrease the amount of computation. Meanwhile, the stability analysis is provided. It illustrates that the proposed event-based method can asymptotically stabilize the nonaffine systems by using the Lyapunov method . Furthermore, the stability conditions and the design process of the event-based controller are established. The event-based DHP algorithm is implemented by constructing three neural networks , namely, the model network, the critic network, and the action network. Finally, simulation studies are conducted to demonstrate the applicability and the performance of the proposed method.},
  archive      = {J_ISCI},
  author       = {Mingming Ha and Ding Wang and Derong Liu},
  doi          = {10.1016/j.ins.2020.01.020},
  journal      = {Information Sciences},
  pages        = {110-123},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered constrained control with DHP implementation for nonaffine discrete-time systems},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The generalized fuzzy derivative is interactive.
<em>ISCI</em>, <em>519</em>, 93–109. (<a
href="https://doi.org/10.1016/j.ins.2020.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we prove that the generalized difference between A , B ∈ R F C , A,B∈RFC, i.e., fuzzy numbers with continuous endpoints, is given by an interactive difference. To be more precise, we construct a certain joint possibility distribution I such that the generalized difference coincides with the sup- I extension of the subtraction. As an immediate consequence, we have that every notion of difference between A , B ∈ R F C , A,B∈RFC, that has so far appeared in the literature, can be derived from a sup- J extension for some particular choice of J . Moreover, we show that both the generalized and the generalized Hukuhara derivative of a function f : R → R F C f:R→RFC at x ∈ R x∈R can be expressed as the limit for h → 0 of a difference quotient, where the difference is an interactive difference for each h . For short, we say that the generalized (as well as the generalized Hukuhara) difference is interactive.},
  archive      = {J_ISCI},
  author       = {Vinícius F. Wasques and Estevão Esmi and Laécio C. Barros and Peter Sussner},
  doi          = {10.1016/j.ins.2020.01.042},
  journal      = {Information Sciences},
  pages        = {93-109},
  shortjournal = {Inf. Sci.},
  title        = {The generalized fuzzy derivative is interactive},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A three-way decision model based on cumulative prospect
theory. <em>ISCI</em>, <em>519</em>, 74–92. (<a
href="https://doi.org/10.1016/j.ins.2020.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In three-way decision, the description on the risk attitude of decision-makers is a focus topic. In this paper, we propose a novel three-way decision model based on cumulative prospect theory. First, with the aid of a reference point, the value functions are utilized to describe different risk appetites of decision-makers towards gains and losses. Second, the weight functions incorporate the nonlinear transformation of the conditional probability . The cumulative decision weights are decided by taking into account the increasing order of value functions. Then, with value functions and weight functions, the new decision rules of the proposed model are deduced based on the principle of maximizing the cumulative prospect value rather than minimizing the cost. Further, we analyze and prove the existence and uniqueness of thresholds of our model. Then, the decision rules are simplified based on the conditional probability and numerical solutions of thresholds, and the algorithm for deriving three-way decision rules is constructed. Finally, an illustrative example and a series of relevant comparisons are presented to illustrate and validate the effectiveness and feasibility of our model.},
  archive      = {J_ISCI},
  author       = {Tianxing Wang and Huaxiong Li and Libo Zhang and Xianzhong Zhou and Bing Huang},
  doi          = {10.1016/j.ins.2020.01.030},
  journal      = {Information Sciences},
  pages        = {74-92},
  shortjournal = {Inf. Sci.},
  title        = {A three-way decision model based on cumulative prospect theory},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive weighted over-sampling for imbalanced datasets
based on density peaks clustering with heuristic filtering.
<em>ISCI</em>, <em>519</em>, 43–73. (<a
href="https://doi.org/10.1016/j.ins.2020.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from imbalanced datasets poses a major challenge in data mining community. When dealing with imbalanced datasets, conventional classification algorithms generally perform poorly as they are originally designed to work under balanced class distribution scenarios. Although there exist different methods to addressing this issue, sampling methods especially over-sampling techniques have shown great potentials as they aim to improve datasets itself rather than the classifiers, which can allow them to be used for any classifier. In this paper, we propose a novel adaptive weighted over-sampling for imbalanced datasets based on density peaks clustering with heuristic filtering. Unlike other clustering-based over-sampling methods, the proposed approach applies modified density peaks clustering rather than traditional k-means clustering techniques to cluster the minority instances due to its capability of accurately identifying sub-clusters with different sizes and densities, which is beneficial for the proposed method to simultaneously accommodate for between-class and within-class imbalance issues caused by various reasons. Subsequently, the size for each identified sub-cluster to be oversampled is adaptively determined according to its own size and density and then the minority instances within each sub-cluster are oversampled based on their probabilities inversely proportional to their distances to the majority class and their densities with the aim of generating more synthetic minority instances for borderline and sparser ones. Finally, in order to avoid the generation of overlapping, a heuristic filtering strategy is also developed to iteratively move the possibly overlapped minority instances away from the majority class. The extensive experimental results on the different imbalanced datasets demonstrate that the proposed approach can achieve better classification performance in most datasets as compared to the other existing over-sampling techniques.},
  archive      = {J_ISCI},
  author       = {Xinmin Tao and Qing Li and Wenjie Guo and Chao Ren and Qing He and Rui Liu and JunRong Zou},
  doi          = {10.1016/j.ins.2020.01.032},
  journal      = {Information Sciences},
  pages        = {43-73},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive weighted over-sampling for imbalanced datasets based on density peaks clustering with heuristic filtering},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community-aware dynamic network embedding by using deep
autoencoder. <em>ISCI</em>, <em>519</em>, 22–42. (<a
href="https://doi.org/10.1016/j.ins.2020.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding has recently attracted lots of attention due to its wide applications on graph tasks such as link prediction, network reconstruction, node stabilization, and community stabilization, which aims to learn the low-dimensional representations of nodes with essential features. Most existing network embedding methods mainly focus on static or continuous evolution patterns of microscopic node and link structures in networks, while neglecting the dynamics of macroscopic community structures. In this paper, we propose a Community-aware Dynamic Network Embedding method (short for CDNE) which considers the dynamics of macroscopic community structures. First, we model the problem of dynamic network embedding as a minimization of an overall loss function, which tries to maximally preserve the global node structures, local link structures, and continuous community dynamics. Then, we adopt a stacked deep autoencoder algorithm to solve this minimization problem , obtaining the low-dimensional representations of nodes. Extensive experiments on both synthetic networks and real networks demonstrate the superiority of CDNE over the existing methods on tackling various graph tasks.},
  archive      = {J_ISCI},
  author       = {Lijia Ma and Yutao Zhang and Jianqiang Li and Qiuzhen Lin and Qing Bao and Shanfeng Wang and Maoguo Gong},
  doi          = {10.1016/j.ins.2020.01.027},
  journal      = {Information Sciences},
  pages        = {22-42},
  shortjournal = {Inf. Sci.},
  title        = {Community-aware dynamic network embedding by using deep autoencoder},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variational autoencoder based bipartite network embedding by
integrating local and global structure. <em>ISCI</em>, <em>519</em>,
9–21. (<a href="https://doi.org/10.1016/j.ins.2020.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful tool for machine learning on the graph, network embedding, which projects nodes into low-dimensional spaces, has a variety of applications on complex networks. Most current methods and models are not suitable for bipartite networks, which have two different types of nodes and there are no links between nodes of the same type. Furthermore, the only existing methods for bipartite network embedding ignore the internal mechanism and highly nonlinear structures of links. Therefore, in this paper, we propose a new deep learning method to learn the node embedding for bipartite networks based on the widely used autoencoder framework. Moreover, we carefully devise a node-level triplet including two types of nodes to assign the embedding by integrating the local and global structures. Meanwhile, we apply the variational autoencoder (VAE), a deep generation model with natural advantages in data generation and reconstruction, to enhance the node embedding for the highly nonlinear relationships between nodes and complex features. Experiments on some widely used datasets show the effectiveness of the proposed model and corresponding algorithm compared with some baseline network (and bipartite) embedding techniques.},
  archive      = {J_ISCI},
  author       = {Pengfei Jiao and Minghu Tang and Hongtao Liu and Yaping Wang and Chunyu Lu and Huaming Wu},
  doi          = {10.1016/j.ins.2020.01.033},
  journal      = {Information Sciences},
  pages        = {9-21},
  shortjournal = {Inf. Sci.},
  title        = {Variational autoencoder based bipartite network embedding by integrating local and global structure},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secret sharing with secure secret reconstruction.
<em>ISCI</em>, <em>519</em>, 1–8. (<a
href="https://doi.org/10.1016/j.ins.2020.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Threshold secret sharing is a fundamental building block in information security to provide secrecy and robustness services for various cryptographic protocols . According to the definition of ( t , n ) threshold secret sharing, the secret is divided into n shares, such that any t or more than t of these shares allow the secret to be reconstructed; but less than t shares reveal no information of the secret. In other words, this definition only considers protection of the secret from colluded insiders but not outsiders. In this paper, we propose an extended secret sharing scheme , called secret sharing with secure secret reconstruction, in which the secret can be protected in the reconstruction phase from both attacks of insiders and outsiders. In traditional secret sharing schemes, when more than t shares are presented in the secret reconstruction, outsiders only need to intercept t shares to recover the secret. But in our proposed basic scheme, outsiders need to intercept all the released shares to recover the secret. Obviously, requiring more shares in the reconstruction contributes to security enhancement for this process. The limitation of this basic scheme is that it cannot prevent outsiders from learning the secret if they intercept all the released shares. To address this issue, we further extend the basic scheme so that the reconstructed secret is only accessible to shareholders, but not to outsiders. To the best of our knowledge, our extended scheme is the first secret sharing scheme that satisfies this property with information theoretical security.},
  archive      = {J_ISCI},
  author       = {Lein Harn and Zhe Xia and Chingfang Hsu and Yining Liu},
  doi          = {10.1016/j.ins.2020.01.038},
  journal      = {Information Sciences},
  pages        = {1-8},
  shortjournal = {Inf. Sci.},
  title        = {Secret sharing with secure secret reconstruction},
  volume       = {519},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enabling instant- and interval-based semantics in
multidimensional data models: The t+MultiDim model. <em>ISCI</em>,
<em>518</em>, 413–435. (<a
href="https://doi.org/10.1016/j.ins.2019.12.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time is a vital facet of every human activity . Data warehouses , which are huge repositories of historical information, must provide analysts with rich mechanisms for managing the temporal aspects of information. In this paper, we (i) propose T+MultiDim , a multidimensional conceptual data model enabling both instant- and interval-based semantics over temporal dimensions, and (ii) provide suitable OLAP (On-Line Analytical Processing) operators for querying temporal information. T+MultiDim allows one to design typical concepts of a data warehouse including temporal dimensions, and provides one with the new possibility of conceptually connecting different temporal dimensions for exploiting temporally aggregated data. The proposed approach allows one to specify and to evaluate powerful OLAP queries over information from data warehouses. In particular, we define a set of OLAP operators to deal with interval-based temporal data. Such operators allow the user to derive new measure values associated to different intervals/instants, according to different temporal semantics . Moreover, we propose and discuss through examples from the healthcare domain the SQL specification of all the temporal OLAP operators we define.},
  archive      = {J_ISCI},
  author       = {Carlo Combi and Barbara Oliboni and Giuseppe Pozzi and Alberto Sabaini and Esteban Zimányi},
  doi          = {10.1016/j.ins.2019.12.074},
  journal      = {Information Sciences},
  pages        = {413-435},
  shortjournal = {Inf. Sci.},
  title        = {Enabling instant- and interval-based semantics in multidimensional data models: The T+MultiDim model},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantifying consensus of rankings based on q-support
patterns. <em>ISCI</em>, <em>518</em>, 396–412. (<a
href="https://doi.org/10.1016/j.ins.2019.12.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rankings, representing preferences over a set of candidates, are widely used in many applications, e.g., group decision making and information retrieval. Rankings may be obtained by different agents (humans or systems). It is often necessary to evaluate consensus of obtained rankings from multiple agents , as a measure of consensus provides insights into the rankings. Moreover, a consensus measure could provide a quantitative basis for comparing groups and for improving a ranking system. Existing studies on consensus measurement are insufficient, since they did not evaluate consensus among most rankings or consensus with respect to specific preference patterns. In this paper, a novel consensus quantifying approach, without the use of correlation or distance functions as in existing studies of consensus, is proposed based on the concept of q -support patterns, which represent the commonality embedded in a set of rankings. A pattern is regarded as a q -support pattern if it is included by at least q rankings in the ranking set. A method for detecting outliers in a set of rankings is naturally derived from the proposed consensus quantifying approach. Experimental studies are conducted to demonstrate the effectiveness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Zhengui Xue and Zhiwei Lin and Hui Wang and Sally McClean},
  doi          = {10.1016/j.ins.2019.12.070},
  journal      = {Information Sciences},
  pages        = {396-412},
  shortjournal = {Inf. Sci.},
  title        = {Quantifying consensus of rankings based on q-support patterns},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid belief rule base for regional railway safety
assessment with data and knowledge under uncertainty. <em>ISCI</em>,
<em>518</em>, 376–395. (<a
href="https://doi.org/10.1016/j.ins.2019.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keeping regional railway transportation safe is of great importance for railway system engineers and decision makers . However, there are still great challenges in modeling the complicated conditions in regional railway transportation: (1) Multiple types of data and knowledge in complicated correlations need to be analyzed, and (2) The approach must be open and accessible to decision makers so that a balanced decision can be made. To address the above challenges, a safety assessment approach using the hybrid Belief Rule Base (BRB) is proposed. In the new approach, multiple types of information are modeled under the hybrid assumption, and thus, hybrid rules are constructed to form the hybrid BRB. With this, both data and knowledge in complicated correlations can be used for the safety assessment on regional railway transportation, rather than only a single railway station or equipment component. Moreover, the assessment process remains open and accessible which provides good interpretability to stakeholders. An empirical regional railway safety assessment case is studied on the existing line and high speed line in the Cheng-Yu region located in the southwestern China. Five aspects, namely, the environment, equipment, management, passengers, and accident, are analyzed and then disintegrated into sub-factors. With the aspects and sub-factors, a comprehensive model is constructed. Case study results show that (1) the overall safety levels of the high speed line are better than the existing line, (2) the safety assessment results are consistent with the historical reports of accidents and system failures, (3) among all aspects, the environment and equipment have a more direct effect on the overall safety levels, and (4) consistency has also been found with railway accident statistics collected from Japan and Canada.},
  archive      = {J_ISCI},
  author       = {Leilei Chang and Wei Dong and Jianbo Yang and Xinya Sun and Xiaobin Xu and Xiaojian Xu and Limao Zhang},
  doi          = {10.1016/j.ins.2019.12.035},
  journal      = {Information Sciences},
  pages        = {376-395},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid belief rule base for regional railway safety assessment with data and knowledge under uncertainty},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered distributed control for synchronization of
multiple memristive neural networks under cyber-physical attacks.
<em>ISCI</em>, <em>518</em>, 361–375. (<a
href="https://doi.org/10.1016/j.ins.2020.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the synchronization of multiple memristive neural networks (MMNNs) under cyber-physical attacks through distributed event-triggered control. In the field of multi-agent dynamics, memristive neural network (MNN) is considered as a kind of switched systems because of its state-dependent parameters which can lead to the parameters mismatch during synchronization. This will increase the uncertainty of the system and affect the theoretical analysis. Also, neural network is considered as a typical nonlinear system . Therefore, the model studied in this paper is a nonlinear system with switching characteristics. In complex environments, MMNNs may receive mixed attacks, one of which is called cyber-physical attacks that may influence both communication links and MNN nodes to cause changes in topology and physical state. To tackle this issue, we construct a novel Lyapunov functional and use properties of M -matrix to get the criteria for synchronization of MMNNs under cyber-physical attacks. It is worth mentioning that the controllers in this paper are designed to be distributed under event-triggering conditions and Zeno behavior is also excluded. In addition, the algorithm of parameter selection is given to help designing the controllers. One example is given at the end of the paper to support our results.},
  archive      = {J_ISCI},
  author       = {Shengbo Wang and Yuting Cao and Tingwen Huang and Yiran Chen and Shiping Wen},
  doi          = {10.1016/j.ins.2020.01.022},
  journal      = {Information Sciences},
  pages        = {361-375},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered distributed control for synchronization of multiple memristive neural networks under cyber-physical attacks},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attitude quantifier based possibility distribution
generation method for hesitant fuzzy linguistic group decision making.
<em>ISCI</em>, <em>518</em>, 341–360. (<a
href="https://doi.org/10.1016/j.ins.2020.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The possibility distribution-based approach is one of the powerful tools available to manage hesitant fuzzy linguistic term set (HFLTS) information. However, existing possibility distribution studies have not considered the experts’ satisfied preference for HFLTSs in the process of generating the possibility distribution. This paper aims at filling this research gap. To achieve this goal, a novel possibility distribution generation method based on the concept of linguistic quantifier is proposed. This is accomplished by defining a new attitude linguistic quantifier, which is supported with theoretical results to analyze the relationship between the proposed attitude linguistic quantifier with the original linguistic quantifier, attitude indices and the expected linguistic term. The new possibility distribution generation method is proved to be (1) more general than the two main existing approaches, which are particular cases for specific linguistic quantifiers; and (2) useful to implement the concept of soft majority in the resolution process of the decision making situation. Additionally, a new two stages feedback mechanism of attitude adjustment and assessment adjustment is devised to guarantee the convergence of the consensus reaching process. Finally, a framework of group decision making with HFLTSs information is presented and an illustrative example is conducted to verify the proposed method.},
  archive      = {J_ISCI},
  author       = {Jingjing Hao and Francisco Chiclana},
  doi          = {10.1016/j.ins.2020.01.026},
  journal      = {Information Sciences},
  pages        = {341-360},
  shortjournal = {Inf. Sci.},
  title        = {Attitude quantifier based possibility distribution generation method for hesitant fuzzy linguistic group decision making},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph deconvolutional networks. <em>ISCI</em>, <em>518</em>,
330–340. (<a href="https://doi.org/10.1016/j.ins.2020.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs and networks are very common data structure for modelling complex systems that are composed of a number of nodes and topologies, such as social networks, citation networks, biological protein-protein interactions networks, etc. In recent years, machine learning has become an efficient technique to obtain representation of graph for downstream graph analysis tasks, including node classification , link prediction, and community detection. Different with traditional graph analytical models, the representation learning on graph tries to learn low dimensional embeddings by means of machine learning models that could be trained in supervised, unsupervised or semi-supervised manners. Compared with traditional approaches that directly use input node attributes, these embeddings are much more informative and helpful for graph analysis. There are a number of developed models in this respect, that are different in the ways of measuring similarity of vertexes in both original space and feature space. In order to learn more efficient node representation with better generalization property, we propose a task-independent graph representation model, called as graph deconvolutional network (GDN), and corresponding unsupervised learning algorithm in this paper. Different with graph convolution network (GCN) from the scratch, which produces embeddings by convolving input attribute vectors with learned filters, the embeddings of the proposed GDN model are desired to be convolved with filters so that reconstruct the input node attribute vectors as far as possible. The embeddings and filters are alternatively optimized in the learning procedure. The correctness of the proposed GDN model is verified by multiple tasks over several datasets. The experimental results show that the GDN model outperforms existing alternatives with a big margin.},
  archive      = {J_ISCI},
  author       = {Chun-Yang Zhang and Junfeng Hu and Lin Yang and C.L. Philip Chen and Zhiliang Yao},
  doi          = {10.1016/j.ins.2020.01.028},
  journal      = {Information Sciences},
  pages        = {330-340},
  shortjournal = {Inf. Sci.},
  title        = {Graph deconvolutional networks},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple criteria group decision making based on group
satisfaction. <em>ISCI</em>, <em>518</em>, 309–329. (<a
href="https://doi.org/10.1016/j.ins.2020.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To generate solutions to multiple criteria group decision-making (MCGDM) problems that are satisfactory to the decision makers, this paper proposes a new method. To examine whether a group solution is satisfactory to the decision makers, group satisfaction is constructed from alternative assessment and ranking differences between the decision makers and the group. The difference between a decision maker&#39;s assessment and a group&#39;s assessment is designed based on differences in assessment grades, whose normalization is theoretically proven to construct alternative assessment differences. Inspired by Spearman&#39;s rank correlation coefficient, the expected utilities of decision makers’ and the group&#39;s assessments are used to construct alternative ranking differences. An abstract two-variable function with specific properties is designed to relate alternative assessment difference to alternative ranking difference to form group satisfaction. From the constructed group satisfaction, the process of generating group-satisfactory solutions to MCGDM problems is presented. The problem of selecting engineering project management software is analyzed by using the proposed method to demonstrate its applicability. To highlight the importance of group satisfaction in MCGDM, relationships and differences between group satisfaction and group consensus are analyzed through the problem and simulation experiments.},
  archive      = {J_ISCI},
  author       = {Chao Fu and Wenjun Chang and Shanlin Yang},
  doi          = {10.1016/j.ins.2020.01.021},
  journal      = {Information Sciences},
  pages        = {309-329},
  shortjournal = {Inf. Sci.},
  title        = {Multiple criteria group decision making based on group satisfaction},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequential three-way multiple attribute group decisions with
individual attributes and its consensus achievement based on social
influence. <em>ISCI</em>, <em>518</em>, 286–308. (<a
href="https://doi.org/10.1016/j.ins.2020.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, there are many complex multiple attribute group decision making (MAGDM) problems with high decision risk and uncertainty. The decision-making process of the complex MAGDM can encounter the following three problems: (1) Since different experts have different knowledge structures and interests, they master different individual attribute information of alternatives. (2) Experts may have different consensus degrees for alternatives under different attributes. (3) For some alternatives, the experts can not make an immediate decision in the actual decision-making process. The experts need much more information to decide on these alternatives in the subsequent decision step. To solve the problems as mentioned above, we propose sequential three-way multiple attribute group decision making (STWMAGDM) with individual attributes by introducing sequential three-way decisions. Meantime, we construct a multilevel granular structure based on the consensus degree of attributes. Further, at each granularity level, the experts need to reach consensus before deducing decision results. For improving the consensus reaching process, we take into account the social influence among experts with the aid of opinion dynamics. In this case, we construct social networks based on the similarity of experts and the amount of attribute information mastered by experts to describe the social influence. Meanwhile, we modify the model of opinion dynamics by introducing the interaction willingness of experts and establish the corresponding adjustment rules of interaction willingness. Finally, we use two diagnosis examples of breast cancer and heart disease to explain our model in detail. In order to verify the effectiveness of our method, we also perform the corresponding comparative experiments and sensitivity analyses.},
  archive      = {J_ISCI},
  author       = {Mingwei Wang and Decui Liang and Zeshui Xu},
  doi          = {10.1016/j.ins.2020.01.024},
  journal      = {Information Sciences},
  pages        = {286-308},
  shortjournal = {Inf. Sci.},
  title        = {Sequential three-way multiple attribute group decisions with individual attributes and its consensus achievement based on social influence},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local stabilization of nonlinear discrete-time systems with
time-varying delay in the states and saturating actuators.
<em>ISCI</em>, <em>518</em>, 272–285. (<a
href="https://doi.org/10.1016/j.ins.2020.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although most of the control design methods assume unbounded control signals, real systems do have saturating actuators, which may degenerate closed-loop performance or even lead to unstable behavior. Additionally, the delay is generally almost ubiquitous in processes, that is also imposing performance and stability constraints. Our main contribution is to provide a controller design methodology for the stabilization of delayed systems under saturating actuators. Specifically, we address the design of non-Parallel Distributed Compensation (non-PDC) state feedback fuzzy control laws that locally stabilize a class of nonlinear discrete-time systems with state time-varying delay and saturating actuators. The proposed non-PDC control law depends on the current state x k and the state delayed by d ¯ d¯ samples. Based on the Lyapunov–Krasovskii approach, we characterize the safe region of initial conditions through two sets: an ellipsoidal one for the current state vector, and another set for the delayed state vectors. Through two convex optimization procedures , we can maximize the estimate of the region of attraction of the closed-loop control system. Additionally, a relaxation method inspired by the Frank-Wolfe algorithm is introduced, yielding better estimates of the region of attraction. The achievements are compared with other finds in the literature, illustrating the efficiency of this proposal.},
  archive      = {J_ISCI},
  author       = {Luís F.P. Silva and Valter J.S. Leite and Eugênio B. Castelan and Michael Klug and Kevin Guelton},
  doi          = {10.1016/j.ins.2020.01.029},
  journal      = {Information Sciences},
  pages        = {272-285},
  shortjournal = {Inf. Sci.},
  title        = {Local stabilization of nonlinear discrete-time systems with time-varying delay in the states and saturating actuators},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid many-objective particle swarm optimization algorithm
for green coal production problem. <em>ISCI</em>, <em>518</em>, 256–271.
(<a href="https://doi.org/10.1016/j.ins.2020.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key aspect in coal production is realizing safe and efficient mining to maximize the utilization of the resources. A requirement for sustainable economic development is realizing green coal production, which is influenced by factors of coal economic, energy, ecological, coal gangue economic and social benefits. To balance these factors, this paper proposes a many-objective optimization model with five objectives for green coal production. Furthermore, a hybrid many-objective particle swarm optimization (HMaPSO) algorithm is designed to solve the established model. A new offspring of the alternative pool is generated by employing different evolutionary operators. The environmental selection mechanism is adopted to select and store the excellent solutions. Two sets of experiments are performed to verify the effectiveness of the proposed approach: First, the HMaPSO algorithm is tested on the DTLZ functions, and its performance is compared with that of several widely used many-objective algorithms. Second, the HMaPSO algorithm is applied to solve the many-objective green coal production optimization model. The computational results demonstrate the effectiveness of the proposed approach, and the simulation results prove that the designed approach can provide promising choices for decision makers in regional planning .},
  archive      = {J_ISCI},
  author       = {Zhihua Cui and Jiangjiang Zhang and Di Wu and Xingjuan Cai and Hui Wang and Wensheng Zhang and Jinjun Chen},
  doi          = {10.1016/j.ins.2020.01.018},
  journal      = {Information Sciences},
  pages        = {256-271},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid many-objective particle swarm optimization algorithm for green coal production problem},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliable correlation tracking via dual-memory selection
model. <em>ISCI</em>, <em>518</em>, 238–255. (<a
href="https://doi.org/10.1016/j.ins.2020.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlation-filter-based trackers have shown favorable accuracy and efficiency in visual tracking. However, most of these trackers are prone to drift in cases of heavy occlusions and temporal tracking failures because they only maintain the short-term memory of target appearance via a highly adaptive update mode. In this paper, we propose a reliable visual tracking method based on a dual-memory selection (DMS) model to alleviate tracking drift. Considering that long-term memory is robust to heavy occlusions while short-term memory performs well in rapid appearance changes, the proposed DMS model combines these two memory patterns of the target appearance and adaptively selects a reliable memory pattern to handle the current tracking challenges via a memory selector. For each memory pattern, a memory tracker is established based on discriminative correlation filters. The short-term tracker aggressively updates the target model to capture recent appearance changes via a linear interpolation update model, while the long-term tracker conservatively updates the target model to maintain historical appearance characteristics with a memory-improved update model and a dynamic learning rate. Furthermore, a novel memory evaluation criterion (MEC) is developed to evaluate the reliability of each tracker for memory selection. From credibility and discriminability measurements considering the temporal context, the memory tracker with the highest reliability score is selected to determine the target location in each frame. Extensive experiments on public benchmark datasets demonstrate that the proposed tracking method performs favorably compared to multiple recent state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Guiji Li and Manman Peng and Ke Nai and Zhiyong Li and Keqin Li},
  doi          = {10.1016/j.ins.2020.01.015},
  journal      = {Information Sciences},
  pages        = {238-255},
  shortjournal = {Inf. Sci.},
  title        = {Reliable correlation tracking via dual-memory selection model},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recognizing novel patterns via adversarial learning for
one-shot semantic segmentation. <em>ISCI</em>, <em>518</em>, 225–237.
(<a href="https://doi.org/10.1016/j.ins.2020.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-shot semantic segmentation aims to recognize unseen object regions by using the reference of only one annotated example. Many deep convolutional neural networks have achieved enormous success on this task. However, most of the existing methods only use a fixed annotated dataset to train the network. The remaining unannotated examples remain difficult to be leveraged and recognized. In this study, we propose a procedure based on the generative adversarial network to enable the one-shot semantic segmentation model for learning information from previously unknown categories. Our method contains a segmentation network that generates segmentation predictions. We then use a discriminator to differentiate the probability maps of segmentation prediction from the ground truth distribution. Consequently, we can ignore the pixels classified as fake and only use trustworthy regions as the label to train the segmentation network , thus achieving semi-supervised learning. Experimental results demonstrate the effectiveness of the proposed adversarial learning method with an average gain of 49.7\% accuracy score on the PASCAL VOC 2012 dataset.},
  archive      = {J_ISCI},
  author       = {Guangchao Yang and Dongmei Niu and Caiming Zhang and Xiuyang Zhao},
  doi          = {10.1016/j.ins.2020.01.016},
  journal      = {Information Sciences},
  pages        = {225-237},
  shortjournal = {Inf. Sci.},
  title        = {Recognizing novel patterns via adversarial learning for one-shot semantic segmentation},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel batch image encryption algorithm using parallel
computing. <em>ISCI</em>, <em>518</em>, 211–224. (<a
href="https://doi.org/10.1016/j.ins.2020.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos-based encryption provides a practical way to protect the confidentiality of digital images nowadays. The increasing convenience ( e.g. , larger bandwidth) of data sharing stimulates the need for encrypting amounts of images in a fast manner. Yet most existing works aim to encrypt an image for each time. Although some parallel encryptions have been proposed, the speed is still far from satisfactory to proceed with the huge increasing number of images. This inspires us to consider another promising way, encrypting a batch of images parallelly for each time. We use maximum available number of threads in parallel computation for full use of processor resources. Considering the batch images as a shared resource, every thread competes with others to encrypt images in the shared resource in a preemptive manner for encryption. A classical permutation-diffusion architecture for chaos-based encryption is utilized for each thread, where logistic map and Lorenz system are used for generating keystream for permutation and diffusion, respectively. We make cryptographical analyses and perform experiments to confirm that the security is guaranteed. The results of efficiency tests demonstrate that the encryption speed is greatly improved compared with the state-of-art image encryption algorithms in parallel as well as serial modes.},
  archive      = {J_ISCI},
  author       = {Wei Song and Yu Zheng and Chong Fu and Pufang Shan},
  doi          = {10.1016/j.ins.2020.01.009},
  journal      = {Information Sciences},
  pages        = {211-224},
  shortjournal = {Inf. Sci.},
  title        = {A novel batch image encryption algorithm using parallel computing},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple attribute decision making based on q-rung orthopair
fuzzy generalized maclaurin symmetic mean operators. <em>ISCI</em>,
<em>518</em>, 181–210. (<a
href="https://doi.org/10.1016/j.ins.2020.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the article, we establish two multiple attribute decision making (MADM) approaches using the developed weighted generalized Maclaurin symmetric mean (q-ROFWGMSM) and weighted generalized geometric Maclaurin symmetric mean (q-ROFWGGMSM) operator concerning q-rung orthopair fuzzy numbers (q-ROFNs). Firstly, inspired by the generalized Maclaurin symmetric mean (G-MSM) and geometric Maclaurin symmetric mean (Geo-MSM) operators, we establish the q-rung orthopair fuzzy G-MSM (q-ROFGMSM) and q-rung orthopair fuzzy Geo-MSM (q-ROFGGMSM) operators, which assumes the grades of membership and non-membership to evaluate information can take any values in interval [0,1] respectively and the attributes are relevant to other multiple attributes. Then, we present its characteristics and some special cases. Moreover, we propose the weighted forms of the q-ROFGMSM and q-ROFGGMSM operator, which is called the q-ROFWGMSM and q-ROFWGGMSM operators, respectively. Then, we present their some characteristics and special examples. Finally, we put forward two new MADM approaches founded on the developed q-ROFWGMSM and q-ROFWGGMSM operators. The developed approaches are more general and more practicable than Liu and Wang&#39;s MADM approach (2018), Wei and Lu&#39;s MADM method (2017), Qin and Liu&#39;s MADM method (2014) and Shen et al.’s MADM approach (2018).},
  archive      = {J_ISCI},
  author       = {Peide Liu and Yumei Wang},
  doi          = {10.1016/j.ins.2020.01.013},
  journal      = {Information Sciences},
  pages        = {181-210},
  shortjournal = {Inf. Sci.},
  title        = {Multiple attribute decision making based on q-rung orthopair fuzzy generalized maclaurin symmetic mean operators},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient two-party privacy-preserving collaborative k-means
clustering protocol supporting both storage and computation outsourcing.
<em>ISCI</em>, <em>518</em>, 168–180. (<a
href="https://doi.org/10.1016/j.ins.2019.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cloud computing has developed well and been applied in many kinds of areas. However, privacy is still the most challenging problem which obstructs it being applied in some privacy-sensitive fields, such as finance and government. Advanced cryptographic algorithms provide data privacy with encryption, which can also support computation on such encrypted data . However, new challenge arises when such ciphertexts come from different parties. In particular, how to execute collaboratively data mining on encrypted data coming from different parties is a key issue from cloud service point of view. This paper focuses on privacy problem on outsourced k -means clustering scheme for two parties. In particular, each party’s data are encrypted only once and then stored in cloud. The proposed privacy-preserving k -means collaborative clustering protocol is executed mainly at the cloud, with O ( k ( m + n ) ) O(k(m+n)) rounds of interactions among the two parties and the cloud, where m and n represent the total numbers of records for the two parties, respectively. It is shown that the protocol is secure in the semi-honest security model and in the malicious model in which only one party is corrupted during the process of centroids re-computation. Both theoretical and experimental analysis of the proposed scheme are also provided.},
  archive      = {J_ISCI},
  author       = {Zoe L. Jiang and Ning Guo and Yabin Jin and Jiazhuo Lv and Yulin Wu and Zechao Liu and Junbin Fang and S.M. Yiu and Xuan Wang},
  doi          = {10.1016/j.ins.2019.12.051},
  journal      = {Information Sciences},
  pages        = {168-180},
  shortjournal = {Inf. Sci.},
  title        = {Efficient two-party privacy-preserving collaborative k-means clustering protocol supporting both storage and computation outsourcing},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An implication based study on łukasiewicz (monteiro)
3-valued algebra and pre-rough algebra. <em>ISCI</em>, <em>518</em>,
157–167. (<a href="https://doi.org/10.1016/j.ins.2020.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper has unfolded from the study on rough sets, mainly from pre-rough algebra. Here we compare between implications of Łukasiewicz (Monteiro) 3-valued algebra and pre-rough algebra. This study aids in presenting an alternative axiomatization of Łukasiewicz (Monteiro) 3-valued algebra.},
  archive      = {J_ISCI},
  author       = {Anirban Saha and Jayanta Sen},
  doi          = {10.1016/j.ins.2020.01.011},
  journal      = {Information Sciences},
  pages        = {157-167},
  shortjournal = {Inf. Sci.},
  title        = {An implication based study on Łukasiewicz (Monteiro) 3-valued algebra and pre-rough algebra},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient and provable certificate-based proxy signature
scheme for IIoT environment. <em>ISCI</em>, <em>518</em>, 142–156. (<a
href="https://doi.org/10.1016/j.ins.2020.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the deployment of sensors and actuators to collect and disseminate data in various applications such as e-healthcare, vehicular adhoc networks (VANETs) and smart factories has revolutionized several new communication technologies. The Internet of Things (IoT) is one of those emerging communication technologies. These revolutionary applications of IoT in industrial environment are termed as Industry 4.0 and it has vitalized the concept of Industrial IoT (IIoT). Being wireless communication , the authentication and integrity of data are the most important challenges. To mitigate these challenges, several digital signature schemes are proposed in the literature. However, due to identity-based or certificate-less construction, those schemes suffer from inborn key escrow and secret key distribution problems. To resolve such issues, the first certificate-based proxy signature (PFCBPS) scheme without pairing is proposed. The proposed PFCBPS scheme is provably secure in random oracle model (ROM). The performance comparison (in terms of computational costs of different phases and length of resulting delegation and signature) shows that the proposed PFCBPS scheme’s total computational cost is 46.69 ms which is 52.24\% of He et al. [8], 61.40\% of Debiao et al. [5], 23.33\% of Seo et al. [20], 28\% of Hu et al. [9] and 36.84\% of Verma and Singh [23]. Thus, it is more suitable to IIoT environment than existing competitive schemes.},
  archive      = {J_ISCI},
  author       = {Girraj Kumar Verma and B.B. Singh and Neeraj Kumar and Mohammad S. Obaidat and Debiao He and Harendra Singh},
  doi          = {10.1016/j.ins.2020.01.006},
  journal      = {Information Sciences},
  pages        = {142-156},
  shortjournal = {Inf. Sci.},
  title        = {An efficient and provable certificate-based proxy signature scheme for IIoT environment},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonnegative self-representation with a fixed rank constraint
for subspace clustering. <em>ISCI</em>, <em>518</em>, 127–141. (<a
href="https://doi.org/10.1016/j.ins.2020.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of approaches to graph-based subspace clustering, which assumes that the clustered data points were drawn from an unknown union of multiple subspaces, have been proposed in recent years. Despite their successes in computer vision and data mining , most neglect to simultaneously consider global and local information, which may improve clustering performance. On the other hand, the number of connected components reflected by the learned affinity matrix is commonly inconsistent with the true number of clusters. To this end, we propose an adaptive affinity matrix learning method, nonnegative self-representation with a fixed rank constraint (NSFRC), in which the nonnegative self-representation and an adaptive distance regularization jointly uncover the intrinsic structure of data. In particular, a fixed rank constraint as a prior is imposed on the Laplacian matrix associated with the data representation coefficients to urge the true number of clusters to exactly equal the number of connected components in the learned affinity matrix. Also, we derive an efficient iterative algorithm based on an augmented Lagrangian multiplier to optimize NSFRC. Extensive experiments conducted on real-world benchmark datasets demonstrate the superior performance of the proposed method over some state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Guo Zhong and Chi-Man Pun},
  doi          = {10.1016/j.ins.2020.01.014},
  journal      = {Information Sciences},
  pages        = {127-141},
  shortjournal = {Inf. Sci.},
  title        = {Nonnegative self-representation with a fixed rank constraint for subspace clustering},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tripled fuzzy metric spaces and fixed point theorem.
<em>ISCI</em>, <em>518</em>, 113–126. (<a
href="https://doi.org/10.1016/j.ins.2020.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important topics of research in fuzzy sets is to get an appropriate notion of fuzzy metric space (FMS), in the paper we propose a new FMS–tripled fuzzy metric space (TFMS), which is a new generalization of George and Veeramani’s FMS. Then we present some related examples, topological properties , convergence of sequences, Cauchy sequence (CS) and completeness of the TFMS. Moreover, we introduce two kinds of notions of generalized fuzzy ψ -contractive (F ψ -C) mappings, and derive a fixed point theorem (FPT) on the mappings in the space.},
  archive      = {J_ISCI},
  author       = {Jing-Feng Tian and Ming-Hu Ha and Da-Zeng Tian},
  doi          = {10.1016/j.ins.2020.01.007},
  journal      = {Information Sciences},
  pages        = {113-126},
  shortjournal = {Inf. Sci.},
  title        = {Tripled fuzzy metric spaces and fixed point theorem},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A no self-edge stochastic block model and a heuristic
algorithm for balanced anti-community detection in networks.
<em>ISCI</em>, <em>518</em>, 95–112. (<a
href="https://doi.org/10.1016/j.ins.2020.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world networks own the characteristic of anti-community structure, i.e. disassortative structure, where nodes share no or few connections inside their groups but most of their connections outside. Detecting anti-community structure can explore negative relations among objects. However, the structures output by the existing algorithms are unbalanced, leading to no or few negative relations to be explored in some groups. Stochastic block models are promising methods for exploring disassortative structures in networks, but their results are highly dependent on the observed structure of a network. In this paper, we first improve the classic stochastic block model and propose a No sElf-edge Stochastic blOck Model (NESOM) for anti-community structure. NESOM considers the edges inside and among groups, respectively, and evolves a new objective function for evaluating anti-community structure. And then, a new heuristic algorithm NESOM-AC is proposed for balanced anti-community detection, which consists of three stages: creation of initial structure, decomposition of redundant group, and adjustment of group membership. Inspired by NESOM, we finally develop a new synthetic benchmark NESOM-Net for performance comparison. Experimental results on NESOM-Net with up to 100,000 nodes and 16 real-world networks demonstrate the effectiveness of NESOM-AC in anti-community detection when compared with five state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Jiajing Zhu and Yongguo Liu and Hao Wu and Zhi Chen and Yun Zhang and Shangming Yang and Changhong Yang and Wen Yang and Xindong Wu},
  doi          = {10.1016/j.ins.2020.01.005},
  journal      = {Information Sciences},
  pages        = {95-112},
  shortjournal = {Inf. Sci.},
  title        = {A no self-edge stochastic block model and a heuristic algorithm for balanced anti-community detection in networks},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph structured sparse subset selection. <em>ISCI</em>,
<em>518</em>, 71–94. (<a
href="https://doi.org/10.1016/j.ins.2019.12.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method for variable subset selection and regression coefficient estimation in linear regression models that incorporates a graph structure of the predictor variables . The proposed method is based on the cardinality constraint that controls the number of selected variables and the graph structured subset constraint that encourages the predictor variables adjacent in the graph to be simultaneously selected or eliminated from the model. Moreover, we develop an efficient discrete projected gradient descent method to handle the NP-hardness of the problem originating from the discrete constraints. Numerical experiments on simulated and real-world data are conducted to demonstrate the usefulness and applicability of the proposed method by comparing it with existing graph regularization methods in terms of the predictive accuracy and variable selection performance. The results confirm that the proposed method outperforms the existing methods.},
  archive      = {J_ISCI},
  author       = {Hyungrok Do and Myun-Seok Cheon and Seoung Bum Kim},
  doi          = {10.1016/j.ins.2019.12.086},
  journal      = {Information Sciences},
  pages        = {71-94},
  shortjournal = {Inf. Sci.},
  title        = {Graph structured sparse subset selection},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CAGE: Constrained deep attributed graph embedding.
<em>ISCI</em>, <em>518</em>, 56–70. (<a
href="https://doi.org/10.1016/j.ins.2019.12.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we deal with complex attributed graphs which can exhibit rich connectivity patterns and whose nodes are often associated with attributes, such as text or images. In order to analyze these graphs, the primary challenge is to find an effective way to represent them by preserving both structural properties and node attribute information. To create low-dimensional and meaningful embedded representations of these complex graphs, we propose a fully unsupervised model based on Deep Learning architectures, called Constrained Attributed Graph Embedding model (CAGE). The main contribution of the proposed model is the definition of a novel two-phase optimization problem that explicitly models node attributes to obtain a higher representation expressiveness while preserving the local and the global structural properties of the graph. We validated our approach on two different benchmark datasets for node classification . Experimental results demonstrate that this novel representation provides significant improvements compared to state of the art approaches, also showing higher robustness with respect to the size of the training data.},
  archive      = {J_ISCI},
  author       = {Debora Nozza and Elisabetta Fersini and Enza Messina},
  doi          = {10.1016/j.ins.2019.12.082},
  journal      = {Information Sciences},
  pages        = {56-70},
  shortjournal = {Inf. Sci.},
  title        = {CAGE: Constrained deep attributed graph embedding},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leveraging multiple features for document sentiment
classification. <em>ISCI</em>, <em>518</em>, 39–55. (<a
href="https://doi.org/10.1016/j.ins.2020.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification is an important research task in Natural Language Processing. To fulfill this type of classification, previous works have focused on leveraging task-specific features. However, they only notice part of the related features. Also, state-of-the-art methods based on neural networks often ignore traditional features. This paper proposes a novel text sentiment classification method that learns the representation of texts by hierarchically incorporating multiple features. More specifically, we design different representations for sentiment words according to the polarity of labeled texts and whether negation exists; we distinguish words with different part-of-speech tags; emoticons, if there are, are to optimize the word vectors obtained in the previous step; apart from word embeddings, character embeddings are also trained. We use a deep neural network to get a sentence-level representation from both word and character sequence. For documents with at least two sentences, we use a hierarchical structure and design a rule to give more weight to import sentences empirically to get a document-level representation. Experimental results on open datasets demonstrate that our method could effectively improve the sentiment classification performance compared with the basic models and state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Li Kong and Chuanyi Li and Jidong Ge and FeiFei Zhang and Yi Feng and Zhongjin Li and Bin Luo},
  doi          = {10.1016/j.ins.2020.01.012},
  journal      = {Information Sciences},
  pages        = {39-55},
  shortjournal = {Inf. Sci.},
  title        = {Leveraging multiple features for document sentiment classification},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable revocable identity-based signature over lattices in
the standard model. <em>ISCI</em>, <em>518</em>, 29–38. (<a
href="https://doi.org/10.1016/j.ins.2020.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revocable identity based signature (RIBS) is a useful cryptographic primitive , which provides a revocation mechanism to revoke misbehaving or malicious users over ID-based public key settings. In the past, many RIBS schemes have been previously proposed, but the security of all these existing schemes is based on traditional complexity assumptions, which are not secure against attacks in the quantum era. Lattice-based cryptography has many attractive features and it is all believed to be secure against attacks of quantum computing . Recently, Hung et al. proposed a RIBS with short size over lattices. However, in their scheme, it requires the private key generator (PKG) to perform linear work in the number of users and does not scale well. Moreover, their scheme is secure in the random oracle model . In this paper, we adopt the binary tree structure to present a scalable lattice-based RIBS scheme which greatly reduces the PKG’S workload associated with users from linear to logarithm. We prove that our proposed scheme is existentially unforgeable against chosen message attacks (EUF-CMA) under standard short integer solutions (SIS) assumption, in the standard model. Compared with the existing RIBS schemes over lattices, our proposed RIBS construction is secure in the standard model with scalability and meanwhile has efficient revocation mechanism with public channels.},
  archive      = {J_ISCI},
  author       = {Congge Xie and Jian Weng and Jiasi Weng and Lin Hou},
  doi          = {10.1016/j.ins.2020.01.008},
  journal      = {Information Sciences},
  pages        = {29-38},
  shortjournal = {Inf. Sci.},
  title        = {Scalable revocable identity-based signature over lattices in the standard model},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolving approach to data streams clustering based on
typicality and eccentricity data analytics. <em>ISCI</em>, <em>518</em>,
13–28. (<a href="https://doi.org/10.1016/j.ins.2019.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose an algorithm for online clustering of data streams. This algorithm is called AutoCloud and is based on the recently introduced concept of Typicality and Eccentricity Data Analytics , mainly used for anomaly detection tasks. AutoCloud is an evolving, online and recursive technique that does not need training or prior knowledge about the data set. Thus, AutoCloud is fully online, requiring no offline processing. It allows creation and merging of clusters autonomously as new data observations become available. The clusters created by AutoCloud are called data clouds, which are structures without pre-defined shape or boundaries. AutoCloud allows each data sample to belong to multiple data clouds simultaneously using fuzzy concepts. AutoCloud is also able to handle concept drift and concept evolution, which are problems that are inherent in data streams in general. Since the algorithm is recursive and online, it is suitable for applications that require a real-time response. We validate our proposal with applications to multiple well known data sets in the literature.},
  archive      = {J_ISCI},
  author       = {Clauber Gomes Bezerra and Bruno Sielly Jales Costa and Luiz Affonso Guedes and Plamen Parvanov Angelov},
  doi          = {10.1016/j.ins.2019.12.022},
  journal      = {Information Sciences},
  pages        = {13-28},
  shortjournal = {Inf. Sci.},
  title        = {An evolving approach to data streams clustering based on typicality and eccentricity data analytics},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Command filtering-based adaptive fuzzy control for permanent
magnet synchronous motors with full-state constraints. <em>ISCI</em>,
<em>518</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2020.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Focusing on the problem of position tracking control for permanent magnet synchronous motors (PMSMs) with full-state constraints, this article proposes an adaptive fuzzy control scheme based on command filtering error compensation mechanism. Firstly, the unknown nonlinear functions of PMSM drive systems are approximated by utilizing the fuzzy logic systems (FLSs). Then, the command filtering technique is employed to deal with the “explosion of complexity” problem arising from conventional backstepping scheme, and the filtering errors are reduced by the error compensation mechanism. In addition, the barrier Lyapunov functions (BLFs) are constructed to guarantee that the state variables are restricted in compact bounding sets. Finally, simulation results show the effectiveness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Mingjun Zou and Jinpeng Yu and Yumei Ma and Lin Zhao and Chong Lin},
  doi          = {10.1016/j.ins.2020.01.004},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {Command filtering-based adaptive fuzzy control for permanent magnet synchronous motors with full-state constraints},
  volume       = {518},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiattribute group decision making based on neutrality
aggregation operators of q-rung orthopair fuzzy sets. <em>ISCI</em>,
<em>517</em>, 427–447. (<a
href="https://doi.org/10.1016/j.ins.2019.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {q -rung orthopair fuzzy sets ( q -ROFSs) are prominent ideas to express fuzzy data in decision-making. The q -ROFSs can dynamically adapt the area of evidence by altering the parameter q ≥ 1 based on the fluctuation degree and therefore support more innumerable possibilities. Hence, this set defeats over the existing Atanassov intuitionistic fuzzy sets (AIFSs) and Pythagorean fuzzy sets (PFS). In today’s life, there is frequently a setup concerning a neutral attitude towards the evaluation of the decision-makers. To arrange a pleasant decision throughout the method, in this paper, we illustrate innovative operational laws by uniting the features of the membership coefficients sum as well as the interaction between the membership degrees into the study for q -ROFSs. Associated with these laws, we establish some weighted averaging neutral aggregation operators (AOs) to aggregate the q -ROF erudition. Furthermore, we introduce an innovative MAGDM (“multiattribute group decision making”) process based on suggested AOs and illustrate with numerous numerical cases to verify it. A contrastive review is also administered to confirm the supremacies of the method.},
  archive      = {J_ISCI},
  author       = {Harish Garg and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2019.11.035},
  journal      = {Information Sciences},
  pages        = {427-447},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute group decision making based on neutrality aggregation operators of q-rung orthopair fuzzy sets},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic time series smoothing for symbolic interval data
applied to neuroscience. <em>ISCI</em>, <em>517</em>, 415–426. (<a
href="https://doi.org/10.1016/j.ins.2019.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aimed to appraise a multivariate time series , high-dimensionality data-set, presented as intervals using a Symbolic Data Analysis (SDA) approach. SDA reduces data dimensionality, considering the complexity of the model information through a set-valued (interval or multi-valued). Additionally, Dynamic Linear Models (DLM) are distinguished by modeling univariate or multivariate time series in the presence of non-stationarity, structural changes and irregular patterns. We considered neurophysiological (EEG) data associated with experimental manipulation of verticality perception in humans, using transcranial electrical stimulation. The innovation of the present work is centered on use of a dynamic linear model with SDA methodology, and SDA applications for analyzing EEG data.},
  archive      = {J_ISCI},
  author       = {Diego C. Nascimento and Bruno Pimentel and Renata Souza and João P. Leite and Dylan J. Edwards and Taiza E.G. Santos and Francisco Louzada},
  doi          = {10.1016/j.ins.2019.12.026},
  journal      = {Information Sciences},
  pages        = {415-426},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic time series smoothing for symbolic interval data applied to neuroscience},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PEER: A direct method for biosequence pattern mining through
waits of optimal k-mers. <em>ISCI</em>, <em>517</em>, 393–414. (<a
href="https://doi.org/10.1016/j.ins.2019.12.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accuracy of alignment-based methods at linear time complexity is desirable for biosequence studies. k -mer statistics is the principal alternative, but selecting the optimal k is crucial for best feature extraction. Prevalent methods require successive trials upon incrementing k for best match with a reference phylogeny tree. We observe that successive intervals(or waits) of optimal length k -mers contain precise information of the sequence such that feature extraction is possible from entropies of the waits. We introduce a method, Pattern Extraction through Entropy Retrieval(PEER), that transforms a sequence into a vector of wait entropies of optimal k -mers. Distance between a pair of sequences amounts to the Euclidean Distance between their wait vectors. We present an analytical determination of optimal k from maximality of total wait entropy. This makes PEER free from the usual multiple trials for obtaining optimal k . We conduct experiments on several benchmark datasets of omics clades for phylogeny analysis and perform an in-depth comparison against seven state-of-the-art alignment-free methods. Phylogeny tree from PEER distance closely resembles the corresponding biological taxonomy and achieves the best Robinson-Foulds score. PEER can sense small artificial mutations within sequence. It is highly scalable with linear time complexity, exceptionally useful for comparing long sequences.},
  archive      = {J_ISCI},
  author       = {Uddalak Mitra and Balaram Bhattacharyya and Tathagato Mukhopadhyay},
  doi          = {10.1016/j.ins.2019.12.072},
  journal      = {Information Sciences},
  pages        = {393-414},
  shortjournal = {Inf. Sci.},
  title        = {PEER: A direct method for biosequence pattern mining through waits of optimal k-mers},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local community detection by the nearest nodes with greater
centrality. <em>ISCI</em>, <em>517</em>, 377–392. (<a
href="https://doi.org/10.1016/j.ins.2020.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most community detection algorithms require the global information of the networks. However, for large scale complex networks, the global information is often expensive and even impossible to obtain. Therefore, local community detection is of tremendous significance. In this paper, a new local community detection algorithm based on NGC nodes, named LCDNN, is proposed. For any node, its NGC node refers to the nearest node with greater centrality. In the LCDNN, local community C initially consists of the given node, v . Then, the remaining nodes are added to the local community one by one, and the added node should satisfy: 1) its NGC node is in C , or it is the NGC node of the center node of C ; and 2) the fuzzy relation between the node and its NGC node is the largest; 3) the fuzzy relation is no less than half of the average fuzzy relation of the current local network. The experimental results on ten real-world and synthetic networks demonstrate that LCDNN is effective and highly competitive. Concurrently, LCDNN can also be extended for multiscale local community detection, and experimental results are provided to demonstrate its effectiveness.},
  archive      = {J_ISCI},
  author       = {Wenjian Luo and Nannan Lu and Li Ni and Wenjie Zhu and Weiping Ding},
  doi          = {10.1016/j.ins.2020.01.001},
  journal      = {Information Sciences},
  pages        = {377-392},
  shortjournal = {Inf. Sci.},
  title        = {Local community detection by the nearest nodes with greater centrality},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cube-based incremental outlier detection for streaming
computing. <em>ISCI</em>, <em>517</em>, 361–376. (<a
href="https://doi.org/10.1016/j.ins.2019.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is one of the most critical and challenging tasks of data mining . It aims to find patterns in data that do not conform to expected behavior. Data streams in streaming computing are huge in nature and arrive continuously with changing distribution, which imposes new challenges for outlier detection algorithms in time and space efficiency. Incremental local outlier factor (ILOF) detection dynamically updates the profiles of data points, while the arrival of consecutive and massive volume data points in a streaming manner causes high local data density and leads to expensive time and space overhead. Our work is motivated by its deficiencies, and in this paper we propose a cube-based outlier detection algorithm (CB-ILOF). The data space of streaming data is divided into multiple cubes, then the outlier detection of data points is transferred into the outlier detection of cubes, which significantly reduces time and memory overhead. We also present a performance evaluation on 5 datasets. Experimental results show the superiority of the CB-ILOF over the ILOF on accuracy, memory usage, and execution time.},
  archive      = {J_ISCI},
  author       = {Jianhua Gao and Weixing Ji and Lulu Zhang and Anmin Li and Yizhuo Wang and Zongyu Zhang},
  doi          = {10.1016/j.ins.2019.12.060},
  journal      = {Information Sciences},
  pages        = {361-376},
  shortjournal = {Inf. Sci.},
  title        = {Cube-based incremental outlier detection for streaming computing},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel heterogeneous grouping method based on magic square.
<em>ISCI</em>, <em>517</em>, 340–360. (<a
href="https://doi.org/10.1016/j.ins.2019.12.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grouping students appropriately to increase learning achievement is important in learning and teaching . Traditional grouping methods include both homogeneous and heterogeneous grouping; heterogeneous grouping has been claimed to improve students&#39; learning achievement and learning process in both cooperative and collaborative learning . Recently, machine–learning-based grouping approaches have been proposed to produce better heterogeneous groups . One main drawback of these machine-learning-based methods is that they are highly affected by parameter settings; setting the appropriate parameters is difficult for general users. Consequently, the most adopted heterogeneous grouping methods currently are s-shape placement, random assignment, and self-grouping, as the three methods do not require additional parameter settings. Herein, a new heterogeneous grouping algorithm named MASA (magic square-based heterogeneous grouping algorithm) is proposed. As in the s-shape placement method, the only parameter required in MASA is the number of groups. Experimental analysis on 92 datasets indicated that MASA was superior to the s-shape placement, random assignment, and self-grouping methods for generating better heterogeneous groups . Additionally, MASA is an adaptive method that can generate several grouping results simultaneously, and users can select the preferred solution.},
  archive      = {J_ISCI},
  author       = {Chun-Cheng Peng and Cheng-Jung Tsai and Ting-Yi Chang and Jen-Yuan Yeh and Meng-Chu Lee},
  doi          = {10.1016/j.ins.2019.12.088},
  journal      = {Information Sciences},
  pages        = {340-360},
  shortjournal = {Inf. Sci.},
  title        = {Novel heterogeneous grouping method based on magic square},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Intuitionistic fuzzy TOPSIS method based on CVPIFRS models:
An application to biomedical problems. <em>ISCI</em>, <em>517</em>,
315–339. (<a href="https://doi.org/10.1016/j.ins.2020.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to obtain the weights of a set of criteria by means of real-world data, an effective method based on the covering-based variable precision intuitionistic fuzzy rough set (CVPIFRS) models is presented. By combining the CVPIFRS models with the idea of TOPSIS , we propose a decision-making method to effectively settle the complex and changeable bone transplant selections, which is one of typical multi-attribute decision-making (MADM) problems. The sensitivity analysis of the proposed method shows that the approach is highly flexible and can be applied to a wide range of environments by adjusting the values of the intuitionistic fuzzy (IF) variable precision, together with the choice of different IF logical operators. Through a comparison of the proposed method and some existing MADM methods, it is shown that our method is more effective in dealing with these complex and changeable bone transplant selections issues.},
  archive      = {J_ISCI},
  author       = {Li Zhang and Jianming Zhan and Yiyu Yao},
  doi          = {10.1016/j.ins.2020.01.003},
  journal      = {Information Sciences},
  pages        = {315-339},
  shortjournal = {Inf. Sci.},
  title        = {Intuitionistic fuzzy TOPSIS method based on CVPIFRS models: An application to biomedical problems},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed and adaptive triggering control for networked
agents with linear dynamics. <em>ISCI</em>, <em>517</em>, 297–314. (<a
href="https://doi.org/10.1016/j.ins.2019.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes distributed event-triggered schemes for achieving state consensus for multi-agent linear systems. For each agent modeled by a linear control system in R n , Rn, a positive signal is embedded in its event function, with the aim of guaranteeing an asymptotic convergence to state consensus for networked linear systems interacted in an undirected and connected graph, and with Zeno triggering excluded for all the agents. The proposed distributed event-based consensus algorithm allows each agent to update its own control at its own triggering times instead of using continuous updates, which thereby avoids complicated computation steps involving data fusion and matrix exponential calculations as used in several event-based control schemes reported in the literature. We further propose a totally distributed and adaptive event-based algorithm, in the sense that each agent utilizes only local measurements with respect to its neighboring agents in its event detection and control update. In this framework, the proposed algorithm is independent of any global network information such as Laplacian matrix eigenvalues associated with the underlying interaction graph. A positive L 1 L1 signal function is included in the adaptive event-based algorithm to guarantee asymptotic consensus convergence and Zeno-free triggering for all the agents. Simulations are provided to validate the performance and superiority of the developed event-based consensus strategies.},
  archive      = {J_ISCI},
  author       = {Na Huang and Zhiyong Sun and Brian D.O. Anderson and Zhisheng Duan},
  doi          = {10.1016/j.ins.2019.12.064},
  journal      = {Information Sciences},
  pages        = {297-314},
  shortjournal = {Inf. Sci.},
  title        = {Distributed and adaptive triggering control for networked agents with linear dynamics},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human behavior recognition from multiview videos.
<em>ISCI</em>, <em>517</em>, 275–296. (<a
href="https://doi.org/10.1016/j.ins.2020.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of deep learning techniques, a significant number of applications related to home care systems have emerged recently. In particular, detecting abnormal events in a smart home environment has been extensively studied. In this paper, we adopt deep learning techniques, including convolutional neural networks (CNNs) and long short-term memory (LSTM) networks, to construct deep networks to learn the long-term dependencies from videos for human behavior recognition in a multiview framework. We adopt two cameras as our sensors to efficiently overcome the problem of occlusions and contour ambiguity for improving the accuracy performance of the multiview framework. After performing a series of image preprocessing on the raw data, we obtain human silhouette images as the input to our training model. In addition, because real-world datasets are complicated for analysis, labeling data is time consuming. Therefore, we present an image clustering method based on a stacked convolutional autoencoder (SCAE), which generates clustering labels for autolabeling. Finally, we set up our experimental environment as a normal residence to collect a large dataset, and the experimental results demonstrate the novelty of our proposed models.},
  archive      = {J_ISCI},
  author       = {Yu-Ling Hsueh and Wen-Nung Lie and Guan-You Guo},
  doi          = {10.1016/j.ins.2020.01.002},
  journal      = {Information Sciences},
  pages        = {275-296},
  shortjournal = {Inf. Sci.},
  title        = {Human behavior recognition from multiview videos},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On matching of intuitionistic fuzzy sets. <em>ISCI</em>,
<em>517</em>, 254–274. (<a
href="https://doi.org/10.1016/j.ins.2019.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, we describe the new measure of matching two intuitionistic fuzzy sets. The operations known in the intuitionistic fuzzy set theory are used, and the perturbation of one intuitionistic fuzzy set by another intuitionistic fuzzy set is understood as an impact of one intuitionistic fuzzy set on another intuitionistic fuzzy set. The opposite case can also be considered wherein the second intuitionistic fuzzy set is perturbed by the first one. The introduced measure of the perturbation of one intuitionistic fuzzy set by another intuitionistic fuzzy set is considered instead of commonly used distance between two intuitionistic fuzzy sets. In general, the new measure can be asymmetric and therefore can provide more information compare to a distance between intuitionistic fuzzy sets. The values of such measures of intuitionistic fuzzy sets’ perturbation are ranged between 0 and 1. In this paper specific mathematical properties of the measure of intuitionistic fuzzy sets’ perturbation are studied. The presented methodology is explained by several illustrative examples.},
  archive      = {J_ISCI},
  author       = {Maciej Krawczak and Grażyna Szkatuła},
  doi          = {10.1016/j.ins.2019.11.050},
  journal      = {Information Sciences},
  pages        = {254-274},
  shortjournal = {Inf. Sci.},
  title        = {On matching of intuitionistic fuzzy sets},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval multiplicative pairwise comparison matrix:
Consistency, indeterminacy and normality. <em>ISCI</em>, <em>517</em>,
244–253. (<a href="https://doi.org/10.1016/j.ins.2019.12.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To manifest human judgments, a long-established method called Pairwise Comparison (PC) has been successfully applied in the Analytic Hierarchy Process (AHP). In practice, human judgments are often made with uncertainty, and can be characterized by an Interval Multiplicative Pairwise Comparison Matrix (IMPCM). Since consistency is a key issue that has plagued decision makers and researchers for a long time, it is useful to propose a transformation that can effectively convert an inconsistent IMPCM into a consistent one, especially in group decision-making. However, a consistent IMPCM is not sufficient to be acceptable, indeterminacy should also be considered. Moreover, the interval priority weights should be normalized . To consider consistency, indeterminacy , and normality simultaneously, we put forward a new definition of acceptable IMPCM. To obtain such an acceptable IMPCM, we propose a theorem of consistency, a consistent transformation, and a normalized prioritization scheme. As a result, the proposed methods guarantee an inconsistent IMPCM can be directly converted into an acceptable IMPCM. Five theorems are proved to corroborate the proposed methods. A numerical example is presented to illustrate the validity and superiority of the proposed methods. Finally, discussion and conclusions are given.},
  archive      = {J_ISCI},
  author       = {Ting Kuo},
  doi          = {10.1016/j.ins.2019.12.066},
  journal      = {Information Sciences},
  pages        = {244-253},
  shortjournal = {Inf. Sci.},
  title        = {Interval multiplicative pairwise comparison matrix: Consistency, indeterminacy and normality},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simplified optimized control using reinforcement learning
algorithm for a class of stochastic nonlinear systems. <em>ISCI</em>,
<em>517</em>, 230–243. (<a
href="https://doi.org/10.1016/j.ins.2019.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a reinforcement learning (RL) based optimized control approach is developed by implementing tracking control for a class of stochastic nonlinear systems with unknown dynamic. The RL is constructed in identifier-actor-critic architecture, where the identifier aims for determining the stochastic system in mean square , the actor aims for executing the control action and the critic aims for evaluating the control performance. In almost all of the published RL-based optimal control , since both actor and critic updating laws are yielded on the basis of implementing gradient descent method to the square of Bellman residual error , these methods are very complex and are performed difficultly. By contrast, the proposed optimized control is obviously simple because the RL algorithm is derived based on the negative gradient of a simple positive function. Furthermore, the proposed approach can remove the assumption of persistence excitation, which is required for most RL based adaptive optimal control . Finally, based on the adaptive identifier, the system stability is proven by using the quadratic Lyapunov function rather than quartic Lyapunov function , which is usually required for most stochastic systems. Simulation further demonstrates that the optimized stochastic approach can achieve the desired control objective.},
  archive      = {J_ISCI},
  author       = {Guoxing Wen and C. L. Philip Chen and Wei Nian Li},
  doi          = {10.1016/j.ins.2019.12.039},
  journal      = {Information Sciences},
  pages        = {230-243},
  shortjournal = {Inf. Sci.},
  title        = {Simplified optimized control using reinforcement learning algorithm for a class of stochastic nonlinear systems},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Key regeneration-free ciphertext-policy attribute-based
encryption and its application. <em>ISCI</em>, <em>517</em>, 217–229.
(<a href="https://doi.org/10.1016/j.ins.2019.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute-based encryption (ABE) provides a promising solution for enabling scalable access control over encrypted data stored in the untrusted servers (e.g., cloud) due to its ability to perform data encryption and decryption defined over descriptive attributes . In order to bind different components which correspond to different attributes in a user’s attribute-based decryption key together, key randomization technique has been applied in most existing ABE schemes. This randomization method , however, also empowers a user the capability of regenerating a newly randomized decryption key over a subset of the attributes associated with the original decryption key. Because key randomization breaks the linkage between this newly generated key and the original key, a malicious user could leak the new decryption key to others without taking any responsibility for the key abuse. To solve this problem, we think of key regeneration-free ABE to disallow a user from randomizing his/her decryption key in any manner, i.e., a user can only delegate his/her decryption key in exactly the same form without any modification so that any abused or pirated key can be traced back to its original owner. Motivated by strongly unforgeable signature, we first define a security notion called strong key unforgeability, and show that ABE schemes equipped with the strong key unforgeability are immune to key regeneration. We then provide a generic transformation to convert ciphertext-policy ABE (CP-ABE) schemes of certain type to key regeneration-free CP-ABE schemes, and show how the transformation works by presenting two concrete constructions.},
  archive      = {J_ISCI},
  author       = {Hui Cui and Robert H. Deng and Baodong Qin and Jian Weng},
  doi          = {10.1016/j.ins.2019.12.025},
  journal      = {Information Sciences},
  pages        = {217-229},
  shortjournal = {Inf. Sci.},
  title        = {Key regeneration-free ciphertext-policy attribute-based encryption and its application},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ordinal sums of triangular norms on bounded lattices.
<em>ISCI</em>, <em>517</em>, 198–216. (<a
href="https://doi.org/10.1016/j.ins.2019.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with the problem of ordinal sum construction for t-norms on subintervals of a given bounded lattice L to obtain a t-norm on L without any additional requirements. Some illustrative examples are added to emphasize the difference of our method from some existing methods in the literature. Finally, we generalize our construction method to ensure its applicability for a greater number of t-norms on the subintervals .},
  archive      = {J_ISCI},
  author       = {Ümit Ertuğrul and Merve Yeşilyurt},
  doi          = {10.1016/j.ins.2019.12.056},
  journal      = {Information Sciences},
  pages        = {198-216},
  shortjournal = {Inf. Sci.},
  title        = {Ordinal sums of triangular norms on bounded lattices},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive memory programming for the dynamic bipartite
drawing problem. <em>ISCI</em>, <em>517</em>, 183–197. (<a
href="https://doi.org/10.1016/j.ins.2019.12.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite drawing problem is a well-known NP-hard combinatorial optimization problem with numerous applications. The aim is to minimize the number of edge crossings in a two-layer graph, in which the edges are drawn as straight lines. We consider the dynamic variant of this problem, called the dynamic bipartite drawing problem (DBDP), which consists of adding (resp. or removing) vertices and edges to (resp. or from) a given bipartite drawing, thereby obtaining a new drawing with a layout similar to that of the original drawing. To solve this problem, we propose a tabu search method that incorporates adaptive memory to search the solution space efficiently. In this study, we compare the explicit memory in the proposed method, which is called iterated solution-based tabu search (ISB-TS), with that in the previous best method on the basis of attributive memory, thereby comparing these two memory implementations. Extensive computational experiments on two sets of more than 1000 problem instances indicate that the proposed ISB-TS is highly competitive in comparison with existing methods. Key components of the approach are analyzed to evaluate their effect on the proposed algorithm and determine which search mechanisms are better suited for this type of problems.},
  archive      = {J_ISCI},
  author       = {Bo Peng and Donghao Liu and Zhipeng Lü and Rafael Martí and Junwen Ding},
  doi          = {10.1016/j.ins.2019.12.077},
  journal      = {Information Sciences},
  pages        = {183-197},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive memory programming for the dynamic bipartite drawing problem},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault detection for switched systems with all modes unstable
based on interval observer. <em>ISCI</em>, <em>517</em>, 167–182. (<a
href="https://doi.org/10.1016/j.ins.2019.12.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on observer-based fault detection (FD) for switched systems . By the introduction of the interval observer, the error dynamic system is proposed. In light of the switching logic, exponential stability of the augmented system is firstly achieved. Then, to ensure the fault sensitivity as well as disturbance robustness, H ∞ / H − H− performance analysis is employed. One thing has to be mentioned is that we investigate the unobservable condition of ( A i ; C i ). Moreover, the instability of the error dynamic system brought by the unobservability is eliminated by the switching strategy using average dwell time (ADT) method. Afterwards, sufficient conditions guaranteing the H ∞ / H − H− performance level are obtained, which is divided into disturbance attenuation and fault sensitivity analysis. Finally, examples demonstrating the effectiveness of the provided method are provided.},
  archive      = {J_ISCI},
  author       = {Qingyu Su and Zhongxin Fan and Tong Lu and Yue Long and Jian Li},
  doi          = {10.1016/j.ins.2019.12.071},
  journal      = {Information Sciences},
  pages        = {167-182},
  shortjournal = {Inf. Sci.},
  title        = {Fault detection for switched systems with all modes unstable based on interval observer},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granular neural networks: The development of granular input
spaces and parameters spaces through a hierarchical allocation of
information granularity. <em>ISCI</em>, <em>517</em>, 148–166. (<a
href="https://doi.org/10.1016/j.ins.2019.12.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of granular output optimization of neural networks with fixed connections within a given input space is explored. The numeric output optimization is a highly nonlinear problem if nonlinear activation functions are used; the granular output optimization becomes an even more challenging task. We solve the problem by developing an optimal hierarchical allocation of information granularity , proposing a new objective function which considers both specificity and evidence, and engaging here efficient techniques of evolutionary optimization . In contrast to the existing techniques, the hierarchical one builds a three-level hierarchy to allocate information granularity to the input space and the architecture (parameters) of the network. Granulating both the input features and the architecture at the same time return a different result with the single factor granulation. The constructed granular neural network emphasizes the abstract nature of data and the granular nature of nonlinear mapping of the architecture. Experimental studies completed for synthetic data and publicly available data sets are used to realize the algorithm.},
  archive      = {J_ISCI},
  author       = {Song Mingli and Jing Yukai},
  doi          = {10.1016/j.ins.2019.12.081},
  journal      = {Information Sciences},
  pages        = {148-166},
  shortjournal = {Inf. Sci.},
  title        = {Granular neural networks: The development of granular input spaces and parameters spaces through a hierarchical allocation of information granularity},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust and blind image watermarking in DCT domain using
inter-block coefficient correlation. <em>ISCI</em>, <em>517</em>,
128–147. (<a href="https://doi.org/10.1016/j.ins.2019.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a robust and transparent watermarking method that exploits block-based discrete cosine transform (DCT) coefficient modification. The difference in the DCT coefficients of two blocks is calculated and modified based on the watermark bit to adjust this difference to a predefined range. The first coefficient in the upper left corner of the array basis function is known as the direct current (DC) coefficient, whereas the remainder includes the alternating current (AC) coefficients. The extent of the DCT coefficient modifications depends on the DC coefficient and median of the AC coefficients ordered by a zig-zag sequence. The robustness of the proposed method against various attacks was evaluated experimentally, and experimental results demonstrate that the proposed method possesses great robustness against various single and combined attacks.},
  archive      = {J_ISCI},
  author       = {Hung-Jui Ko and Cheng-Ta Huang and Gwoboa Horng and Shiuh-Jeng WANG},
  doi          = {10.1016/j.ins.2019.11.005},
  journal      = {Information Sciences},
  pages        = {128-147},
  shortjournal = {Inf. Sci.},
  title        = {Robust and blind image watermarking in DCT domain using inter-block coefficient correlation},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Phrase2Vec: Phrase embedding based on parsing.
<em>ISCI</em>, <em>517</em>, 100–127. (<a
href="https://doi.org/10.1016/j.ins.2019.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text is one of the most common unstructured data, and usually, the most primary task in text mining is to transfer the text into a structured representation. However, the existing text representation models split the complete semantic unit and neglect the order of words, finally lead to understanding bias. In this paper, we propose a novel phrase-based text representation method that takes into account the integrity of semantic units and utilizes vectors to represent the similarity relationship between texts. First, we propose HPMBP (Hierarchical Phrase Mining Based on Parsing) which mines hierarchical phrases by parsing and uses BOP (Bag Of Phrases) to represent text. Then, we put forward three phrase embedding models, called Phrase2Vec, including Skip-Phrase, CBOP (Continuous Bag Of Phrases), and GloVeFP (Global Vectors For Phrase Representation). They learn the phrase vector with semantic similarity, further obtain the vector representation of the text. Based on Phrase2Vec, we propose PETC (Phrase Embedding based Text Classification) and PETCLU (Phrase Embedding based Text Clustering). PETC utilizes the phrase embedding to get the text vector, which is fed to a neural network for text classification. PETCLU gets the vectorization expression of text and cluster center by Phrase2Vec, furthermore extends the K-means model for text clustering . To the best of our knowledge, it is the first work that focuses on the phrase-based English text representation. Experiments show that the introduced Phrase2Vec outperforms state-of-the-art phrase embedding models in the similarity task and the analogical reasoning task on Enwiki, DBLP, and Yelp dataset. PETC is superior to the baseline text classification methods in the F1-value index by about 4\%. PETCLU is also ahead of the prevalent text clustering methods in entropy and purity indicators. In summary, Phrase2Vec is a promising approach to text mining.},
  archive      = {J_ISCI},
  author       = {Yongliang Wu and Shuliang Zhao and Wenbin Li},
  doi          = {10.1016/j.ins.2019.12.031},
  journal      = {Information Sciences},
  pages        = {100-127},
  shortjournal = {Inf. Sci.},
  title        = {Phrase2Vec: Phrase embedding based on parsing},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clonal selection based intelligent parameter inversion
algorithm for prestack seismic data. <em>ISCI</em>, <em>517</em>, 86–99.
(<a href="https://doi.org/10.1016/j.ins.2019.12.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amplitude variation with offset (AVO) elastic parameter inversion is an approach of oil exploration that employs seismic information, and it is a problem of non-linear optimization. When using a quasi-linear or linear approach to solve the problem, the inversion result is unreliable or inaccurate. Metaheuristic search methods, e.g., bio-inspired optimization algorithms such as genetic algorithms , are capable of handling highly non-linear optimization problems and thus provide a promising approach for oil and gas exploration . As one of the metaheuristic search approaches, the immune clone selection algorithm exhibits the property of fast convergence and strong global search capability. In this paper, the immune clone selection algorithm is used to address the problem of AVO elastic parameter inversion. This algorithm employs the specific initialization strategy of Aki as well as the approximation equation of Rechard, which is utilized in the elastic parameter inversion process to smooth the initialization parameter curve. Additionally, the genetic operation in the algorithm is improved in accordance. The results of multiple experiments demonstrate that the approach could significantly improve the inversion accuracy, and the correlation coefficient of the elastic parameters acquired via inversion is specifically high.},
  archive      = {J_ISCI},
  author       = {Xuesong Yan and Pengpeng Li and Ke Tang and Liang Gao and Ling Wang},
  doi          = {10.1016/j.ins.2019.12.083},
  journal      = {Information Sciences},
  pages        = {86-99},
  shortjournal = {Inf. Sci.},
  title        = {Clonal selection based intelligent parameter inversion algorithm for prestack seismic data},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Statistical learning and estimation of piano fingering.
<em>ISCI</em>, <em>517</em>, 68–85. (<a
href="https://doi.org/10.1016/j.ins.2019.12.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic estimation of piano fingering is important for understanding the computational process of music performance and applicable to performance assistance and education systems. While a natural way to formulate the quality of fingerings is to construct models of the constraints/costs of performance, it is generally difficult to find appropriate parameter values for these models. Here we study an alternative data-driven approach based on statistical modeling in which the appropriateness of a given fingering is described by probabilities . Specifically, we construct two types of hidden Markov models (HMMs) and their higher-order extensions. We also study deep neural network (DNN)-based methods for comparison. Using a newly released dataset of fingering annotations, we conduct systematic evaluations of these models as well as a representative constraint-based method. We find that the methods based on high-order HMMs outperform the other methods in terms of estimation accuracies. We also quantitatively study individual difference of fingering and propose evaluation measures that can be used with multiple ground truth data. We conclude that the HMM-based methods are currently state of the art and generate acceptable fingerings in most parts and that they have certain limitations such as ignorance of phrase boundaries and interdependence of the two hands.},
  archive      = {J_ISCI},
  author       = {Eita Nakamura and Yasuyuki Saito and Kazuyoshi Yoshii},
  doi          = {10.1016/j.ins.2019.12.068},
  journal      = {Information Sciences},
  pages        = {68-85},
  shortjournal = {Inf. Sci.},
  title        = {Statistical learning and estimation of piano fingering},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning reinforced attentional representation for
end-to-end visual tracking. <em>ISCI</em>, <em>517</em>, 52–67. (<a
href="https://doi.org/10.1016/j.ins.2019.12.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although numerous recent tracking approaches have made tremendous advances in the last decade, achieving high-performance visual tracking remains a challenge. In this paper, we propose an end-to-end network model to learn reinforced attentional representation for accurate target object discrimination and localization . We utilize a novel hierarchical attentional module with long short-term memory and multi-layer perceptrons to leverage both inter- and intra-frame attention to effectively facilitate visual pattern emphasis. Moreover, we incorporate a contextual attentional correlation filter into the backbone network to make our model trainable in an end-to-end fashion. Our proposed approach not only takes full advantage of informative geometries and semantics but also updates correlation filters online without fine-tuning the backbone network to enable the adaptation of variations in the target object’s appearance. Extensive experiments conducted on several popular benchmark datasets demonstrate that our proposed approach is effective and computationally efficient.},
  archive      = {J_ISCI},
  author       = {Peng Gao and Qiquan Zhang and Fei Wang and Liyi Xiao and Hamido Fujita and Yan Zhang},
  doi          = {10.1016/j.ins.2019.12.084},
  journal      = {Information Sciences},
  pages        = {52-67},
  shortjournal = {Inf. Sci.},
  title        = {Learning reinforced attentional representation for end-to-end visual tracking},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Set-membership filtering with incomplete observations.
<em>ISCI</em>, <em>517</em>, 37–51. (<a
href="https://doi.org/10.1016/j.ins.2019.12.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the set-membership estimation problem for a class of discrete time-varying systems with incomplete observations. A set-membership filter is developed and a recursive algorithm is proposed to calculate the state estimate ellipsoid which contains the true value. To solve the problem that the conventional set-membership filter cannot guarantee the stability when applied to discrete time-varying systems with incomplete observations, a quantitative analysis method about incomplete observations is developed and a tight bound of the estimation error is found based on interval analysis and some bounded noise assumptions. In terms of bounded assumptions, the relationship between the bound of estimated error and the data dropout rate is obtained. If the data dropout rate is less than a maximal value, the set-membership filter is asymptotically stable. The proposed filter is applied to a two-state example to demonstrate the effectiveness of theoretical results.},
  archive      = {J_ISCI},
  author       = {Yuan Wang and Jian Huang PhD and Dongrui Wu PhD and Zhi-Hong Guan and Yan-Wu Wang},
  doi          = {10.1016/j.ins.2019.12.087},
  journal      = {Information Sciences},
  pages        = {37-51},
  shortjournal = {Inf. Sci.},
  title        = {Set-membership filtering with incomplete observations},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Manifold learning for efficient gravitational search
algorithm. <em>ISCI</em>, <em>517</em>, 18–36. (<a
href="https://doi.org/10.1016/j.ins.2019.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms provide a practical tool for optimization in a high-dimensional search space. Some mimic phenomenons of nature such as swarms and flocks. Prominent one is the Gravitational Search Algorithm (GSA) inspired by Newton’s law of gravity to manipulate agents modeled as point masses in the search space. The law of gravity states that interaction forces are inversely proportional to the squared distance in the Euclidean space between two objects. In this paper we claim that when the set of solutions lies in a lower-dimensional manifold, the Euclidean distance would yield unfitted forces and bias in the results, thus causing suboptimal and slower convergence. We propose to modify the algorithm and utilize geodesic distances gained through manifold learning via diffusion maps. In addition, we incorporate elitism by storing exploration data. We show the high performance of this approach in terms of the final solution value and the rate of convergence compared to other meta-heuristic algorithms including the original GSA. In this paper we also provide a comparative analysis of the state-of-the-art optimization algorithms on a large set of standard benchmark functions .},
  archive      = {J_ISCI},
  author       = {Chen Giladi and Avishai Sintov},
  doi          = {10.1016/j.ins.2019.12.047},
  journal      = {Information Sciences},
  pages        = {18-36},
  shortjournal = {Inf. Sci.},
  title        = {Manifold learning for efficient gravitational search algorithm},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical optimal control for input-affine nonlinear
systems through the formulation of stackelberg game. <em>ISCI</em>,
<em>517</em>, 1–17. (<a
href="https://doi.org/10.1016/j.ins.2019.12.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substantial efforts have been undertaken to explore nonzero-sum differential games. Most of these studies are devoted to devising algorithms to pursue Nash equilibrium , where all players with the same access to information will take policies synchronously. However, when it comes to hierarchical optimization and asymmetric information, Nash equilibrium is ineffective. The Stackelberg game provides us with an idea of leader-follower strategy to cope with this conundrum. The paper investigates hierarchical optimal control for continuous-time two-player input-affine systems characterized by nonlinear dynamics and quadratic cost functions. By introducing new costates, this optimization problem is formulated as a Stackelberg game in conjunction with a parametric optimization problem . Besides, the closed-loop information is available for both players. An adaptive learning algorithm is thus developed to approximately obtain the open-loop Stackelberg equilibrium while ensuring the uniform ultimate bounded stability of this closed-loop system, and two approximators structured by neural networks put this purpose into practice. Finally, two numerical examples illustrate that the proposed methodology can accurately obtain optimal solutions, and a comparative example illustrates its characteristics.},
  archive      = {J_ISCI},
  author       = {Chaoxu Mu and Ke Wang and Qichao Zhang and Dongbin Zhao},
  doi          = {10.1016/j.ins.2019.12.078},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical optimal control for input-affine nonlinear systems through the formulation of stackelberg game},
  volume       = {517},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Group decision making with incomplete intuitionistic
multiplicative preference relations. <em>ISCI</em>, <em>516</em>,
560–571. (<a href="https://doi.org/10.1016/j.ins.2019.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic multiplicative preference relations (IMPRs) have been widely applied in decision making for their ability to efficiently express the uncertainty of information. This paper investigates the decision making with incomplete IMPRs. First, a new consistency of incomplete IMPRs is defined. Then, we present some optimization models for estimating missing values by maximizing the consistency level . After that, the group IMPR is derived by using membership degrees in individual intuitionistic multiplicative judgments. Subsequently, a transformation method is offered to build a consistent IMPR through a normalized intuitionistic fuzzy priority weight vector . Moreover, a model is presented to get intuitionistic fuzzy priority weights. Finally, we propose a group decision making (GDM) method with incomplete IMPRs. A practical GDM problem on venue selection for communication drills is offered to indicate the specific application of main theoretical results.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen and Chao Wang},
  doi          = {10.1016/j.ins.2019.12.042},
  journal      = {Information Sciences},
  pages        = {560-571},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making with incomplete intuitionistic multiplicative preference relations},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fractional discrete tchebyshev moments and their
applications in image encryption and watermarking. <em>ISCI</em>,
<em>516</em>, 545–559. (<a
href="https://doi.org/10.1016/j.ins.2019.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete Tchebyshev moments (DTMs), as a kind of typical discrete orthogonal moments, have been widely used in image analysis. However, the order of DTMs is restricted to an integer, and the fractional versions of DTMs have not been investigated. A novel framework for deriving fractional order DTMs (FrDTMs) by the eigen-decomposition of kernel matrices is proposed in this paper, and some properties of the proposed FrDTMs are analyzed. Two applications, i.e., image encryption and image watermarking , are investigated to validate the superiorities of the proposed FrDTMs.},
  archive      = {J_ISCI},
  author       = {Bin Xiao and Jiangxia Luo and Xiuli Bi and Weisheng Li and Beijing Chen},
  doi          = {10.1016/j.ins.2019.12.044},
  journal      = {Information Sciences},
  pages        = {545-559},
  shortjournal = {Inf. Sci.},
  title        = {Fractional discrete tchebyshev moments and their applications in image encryption and watermarking},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rules acquisition of formal decision contexts based on
three-way concept lattices. <em>ISCI</em>, <em>516</em>, 529–544. (<a
href="https://doi.org/10.1016/j.ins.2019.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept lattices can supply much more information than classical concept lattices since they contain the positive information and negative information between objects and attributes simultaneously. Taking advantage of this, the rules acquisition for formal decision contexts from the perspective of three-way concept lattices are discussed, and the results are compared with the common decision rules based on classical concept lattices. Firstly, the definition of object-induced three-way consistence of a formal decision context is presented. Then, positive decision rules and negative decision rules are proposed for an object-induced three-way consistent formal decision context. Furthermore, we give semantic explanation for these rules, and compare them with common rules obtained from a strongly consistent lattice. In parallel, the similar issues are investigated from the perspective of attributes, including the definition of attribute-induced three-way consistence of a formal decision context, rules acquisition based on an attribute-induced three-way consistent formal decision context, and rules comparison. Finally, the relationships among the three types of consistence, namely, object-induced three-way consistence, attribute-induced three-way consistence, and existing strongly consistence are discussed to make the contents compact. Some theoretical examples are given to illustrate the main results of this paper.},
  archive      = {J_ISCI},
  author       = {Ling Wei and Lin Liu and Jianjun Qi and Ting Qian},
  doi          = {10.1016/j.ins.2019.12.024},
  journal      = {Information Sciences},
  pages        = {529-544},
  shortjournal = {Inf. Sci.},
  title        = {Rules acquisition of formal decision contexts based on three-way concept lattices},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Public-key authenticated encryption with keyword search
revisited: Security model and constructions. <em>ISCI</em>,
<em>516</em>, 515–528. (<a
href="https://doi.org/10.1016/j.ins.2019.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cloud era, it is necessary to store sensitive data in an encrypted form. This arises the interesting and challenging problem of searching on encrypted data . However, previous Public-key Encryption with Keyword Search (PEKS) inherently cannot resist against inside keyword guessing attacks. To alleviate this issue, recently Huang and Li proposed the notion of Public-key Authenticated Encryption with Keyword Search (PAEKS), which requires the data sender not only encrypting a keyword using the receiver’s public key, but also authenticating it using his secret key. This paper first revisits HL-PAEKS security model and finds that it did not capture a realistic threat, called (outside) chosen multi-ciphertext attacks. That is, an outside adversary can decide whether two encrypted files share some identical keywords or not. To resolve this issue, we propose a new PAEKS security model that captures both (outside) chosen multi-ciphertext attacks and (inside) keyword guessing attacks. Then, we give a concrete PAEKS scheme and prove its security in the new PAEKS security model. We also propose a method to simplify data sender’s key management using identity-based key exchange protocol . Finally, we provide implementation results of our schemes to show the comparable efficiency of our schemes with previous PEKS/PAEKS schemes.},
  archive      = {J_ISCI},
  author       = {Baodong Qin and Yu Chen and Qiong Huang and Ximeng Liu and Dong Zheng},
  doi          = {10.1016/j.ins.2019.12.063},
  journal      = {Information Sciences},
  pages        = {515-528},
  shortjournal = {Inf. Sci.},
  title        = {Public-key authenticated encryption with keyword search revisited: Security model and constructions},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified framework of identity-based sequential aggregate
signatures from 2-level HIBE schemes. <em>ISCI</em>, <em>516</em>,
505–514. (<a href="https://doi.org/10.1016/j.ins.2019.12.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity-based sequential aggregate signature (IBSAS for short) schemes, introduced by Boldyreva et al. [CCS 2007], allow a large quantity of signers to generate one signature sequentially, in which these messages as well as their order can be attested by employing their identities. In such a scheme, storage space and bandwidth overhead can be reduced. To our best knowledge, though many concrete IBSAS schemes have been constructed in literature, none of them is constructed under a standard computational hardness assumption and unforgeable under the standard model. The problem of how to construct such schemes is still open. Latterly, Gentry et al. [PKC 2018] proposed a unified construction of SAS (i.e., abbreviated form of sequential aggregate signature) schemes by employing trapdoor permutation and ideal ciphers. Motivated by the above problem and hints, here we study how to construct IBSAS schemes in a new unified perspective. By employing 2-level HIBE (i.e., abbreviated form of hierarchical identity-based encryption) schemes, we present unified construction of IBSAS schemes and give a rigorous proof of their unforgeability. The unified construction is then instantiated to get a concrete IBSAS scheme, which has existential unforgeability under the standard model using a standard computational hardness assumption (i.e., the CDH assumption). An extra fruit is that it can be used to construct an existentially unforgeable IBSAS scheme using the Learning with Errors problem, which is constructed under a lattice hardness assumption for the first time. In the end, we show a detailed performance comparison among our schemes and previous ones.},
  archive      = {J_ISCI},
  author       = {Yanqing Yao and Zhoujun Li and Hua Guo},
  doi          = {10.1016/j.ins.2019.12.076},
  journal      = {Information Sciences},
  pages        = {505-514},
  shortjournal = {Inf. Sci.},
  title        = {A unified framework of identity-based sequential aggregate signatures from 2-level HIBE schemes},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On graph entropy measures based on the number of independent
sets and matchings. <em>ISCI</em>, <em>516</em>, 491–504. (<a
href="https://doi.org/10.1016/j.ins.2019.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the graph entropy measures based on the number of independent sets and matchings. The reason to study these measures relates to the fact that the independent set and matching problem is computationally demanding. However, these features can be calculated for smaller networks. In case one can establish efficient estimations, those measures may be also used for larger graphs. So, we establish some upper and lower bounds as well as some information inequalities for these information-theoretic quantities. In order to give further evidence, we also generate numerical results to study these measures such as list the extremal graphs for these entropies. Those results reveal the two entropies possess some new features.},
  archive      = {J_ISCI},
  author       = {Pengfei Wan and Xinzhuang Chen and Jianhua Tu and Matthias Dehmer and Shenggui Zhang and Frank Emmert-Streib},
  doi          = {10.1016/j.ins.2019.11.020},
  journal      = {Information Sciences},
  pages        = {491-504},
  shortjournal = {Inf. Sci.},
  title        = {On graph entropy measures based on the number of independent sets and matchings},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GANCCRobot: Generative adversarial nets based chinese
calligraphy robot. <em>ISCI</em>, <em>516</em>, 474–490. (<a
href="https://doi.org/10.1016/j.ins.2019.12.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic calligraphy, as a typical application of robot movement planning, is of great significance for the inheritance and education of calligraphy culture. The existing implementations of such robots often suffer from its limited ability for font generation and evaluation, leading to poor writing style diversity and writing quality. This paper proposes a calligraphic robotic framework based on the generative adversarial nets (GAN) to address such limitation. The robot implemented using such framework is able to learn to write fundamental Chinese character strokes with rich diversities and good quality that is close to the human level, without the requirement of specifically designed evaluation functions thanks to the employment of the revised GAN. In particular, the type information of the stroke is introduced as condition information, and the latent codes are applied to maximize the style quality of the generated strokes. Experimental results demonstrate that the proposed model enables a calligraphic robot to successfully write fundamental Chinese strokes based on a given type and style, with overall good quality. Although the proposed model was evaluated in this report using calligraphy writing, the underpinning research is readily applicable to many other applications, such as robotic graffiti and character style conversion.},
  archive      = {J_ISCI},
  author       = {Ruiqi Wu and Changle Zhou and Fei Chao and Longzhi Yang and Chih-Min Lin and Changjing Shang},
  doi          = {10.1016/j.ins.2019.12.079},
  journal      = {Information Sciences},
  pages        = {474-490},
  shortjournal = {Inf. Sci.},
  title        = {GANCCRobot: Generative adversarial nets based chinese calligraphy robot},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discovering differential features: Adversarial learning for
information credibility evaluation. <em>ISCI</em>, <em>516</em>,
453–473. (<a href="https://doi.org/10.1016/j.ins.2019.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on A dversarial N etworks and inspirited by the S hared- P rivate model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning . Another extracts credibility features (henceforth, private features) from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves state-of-the-art performance, boosting the accuracy by 2.1\%, 3.1\%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8\% performance improvements.},
  archive      = {J_ISCI},
  author       = {Lianwei Wu and Yuan Rao and Ambreen Nazir and Haolin Jin},
  doi          = {10.1016/j.ins.2019.12.040},
  journal      = {Information Sciences},
  pages        = {453-473},
  shortjournal = {Inf. Sci.},
  title        = {Discovering differential features: Adversarial learning for information credibility evaluation},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). And-like-uninorm based consistency analysis and optimized
fuzzy weight closed-form solution of triangular fuzzy additive
preference relations. <em>ISCI</em>, <em>516</em>, 429–452. (<a
href="https://doi.org/10.1016/j.ins.2019.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on multiplicative consistency of triangular fuzzy additive preference relations (TFAPRs) and deriving a closed-form solution of optimized triangular fuzzy weights (TFWs) from TFAPRs. And-like-uninorm based indices are introduced to measure increasing part vagueness, decreasing part vagueness and overall vagueness for ]0,1[-valued triangular fuzzy preferences and TFAPRs. An index is then defined to measure row vagueness proportionality of TFAPRs. An and-like-uninorm based method is further proposed to generate multiplicatively consistent TFAPRs from ]0,1[-valued TFWs. By discussing equivalency of ]0,1[-valued TFW vectors, the paper presents two frameworks of normalized TFWs called multiplicatively modal-value-normalized TFWs and multiplicatively support-interval-normalized TFWs. Based on crucial properties of consistent TFAPRs, a logarithmic least square (LLS) model is established to seek multiplicatively support-interval-normalized TFWs from TFAPRs. By decomposing its goals and constraints, the LLS model is transformed into two least square models whose closed-form solutions are found by the Lagrange multiplier method. On basis of the obtained closed-form solution of TFWs, an algorithm including acceptable consistency checking is developed for decision making with TFAPRs. The rationality and advantages of the presented models are illustrated by a numerical example with five TFAPRs and a comparative analysis.},
  archive      = {J_ISCI},
  author       = {Zhou-Jing Wang and Jian Lin},
  doi          = {10.1016/j.ins.2019.12.055},
  journal      = {Information Sciences},
  pages        = {429-452},
  shortjournal = {Inf. Sci.},
  title        = {And-like-uninorm based consistency analysis and optimized fuzzy weight closed-form solution of triangular fuzzy additive preference relations},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximal chains on the interval [0,1] with respect to
t-norm-partial orders and uninorm-partial orders. <em>ISCI</em>,
<em>516</em>, 419–428. (<a
href="https://doi.org/10.1016/j.ins.2019.12.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, characterizations of maximal chains with respect to a t-norm-partial order, a uninorm-partial order, or a partial order on the interval [0,1] are studied. Based on these properties, some special t-norms and uninorms can be constructed which have some given maximal chains . Moreover, some partial orders on the interval [0,1] which can not be a t-norm-partial order or a uninorm-partial order are investigated and characterized.},
  archive      = {J_ISCI},
  author       = {Qihong Duan and Bin Zhao},
  doi          = {10.1016/j.ins.2019.12.073},
  journal      = {Information Sciences},
  pages        = {419-428},
  shortjournal = {Inf. Sci.},
  title        = {Maximal chains on the interval [0,1] with respect to t-norm-partial orders and uninorm-partial orders},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DGHNL: A new deep genetic hierarchical network of learners
for prediction of credit scoring. <em>ISCI</em>, <em>516</em>, 401–418.
(<a href="https://doi.org/10.1016/j.ins.2019.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit scoring (CS) is an effective and crucial approach used for risk management in banks and other financial institutions. It provides appropriate guidance on granting loans and reduces risks in the financial area. Hence, companies and banks are trying to use novel automated solutions to deal with CS challenge to protect their own finances and customers. Nowadays, different machine learning (ML) and data mining (DM) algorithms have been used to improve various aspects of CS prediction. In this paper, we introduce a novel methodology, named Deep Genetic Hierarchical Network of Learners (DGHNL). The proposed methodology comprises different types of learners, including Support Vector Machines (SVM), k-Nearest Neighbors (kNN), Probabilistic Neural Networks (PNN), and fuzzy systems. The Statlog German (1000 instances) credit approval dataset available in the UCI machine learning repository is used to test the effectiveness of our model in the CS domain. Our DGHNL model encompasses five kinds of learners, two kinds of data normalization procedures, two extraction of features methods, three kinds of kernel functions , and three kinds of parameter optimizations. Furthermore, the model applies deep learning , ensemble learning , supervised training, layered learning, genetic selection of features (attributes), genetic optimization of learners parameters, and novel genetic layered training (selection of learners) approaches used along with the cross-validation (CV) training-testing method (stratified 10-fold). The novelty of our approach relies on a proper flow and fusion of information (DGHNL structure and its optimization). We show that the proposed DGHNL model with a 29-layer structure is capable to achieve the prediction accuracy of 94.60\% (54 errors per 1000 classifications) for the Statlog German credit approval data. It is the best prediction performance for this well-known credit scoring dataset, compared to the existing work in the field.},
  archive      = {J_ISCI},
  author       = {Paweł Pławiak and Moloud Abdar and Joanna Pławiak and Vladimir Makarenkov and U Rajendra Acharya},
  doi          = {10.1016/j.ins.2019.12.045},
  journal      = {Information Sciences},
  pages        = {401-418},
  shortjournal = {Inf. Sci.},
  title        = {DGHNL: A new deep genetic hierarchical network of learners for prediction of credit scoring},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computation of moments for probabilistic finite-state
automata. <em>ISCI</em>, <em>516</em>, 388–400. (<a
href="https://doi.org/10.1016/j.ins.2019.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation of moments of probabilistic finite-state automata (PFA) is researched in this article. First, the computation of moments of the length of the paths is introduced for general PFA, and then, the computation of moments of the number of times that a symbol appears in the strings generated by the PFA is described. These computations require a matrix inversion . Acyclic PFA, such as word graphs, are quite common in many practical applications. Algorithms for the efficient computation of the moments for acyclic PFA are also presented in this paper.},
  archive      = {J_ISCI},
  author       = {Joan Andreu Sánchez and Verónica Romero},
  doi          = {10.1016/j.ins.2019.12.052},
  journal      = {Information Sciences},
  pages        = {388-400},
  shortjournal = {Inf. Sci.},
  title        = {Computation of moments for probabilistic finite-state automata},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Addressing site selection for earthquake shelters with
hesitant multiplicative linguistic preference relation. <em>ISCI</em>,
<em>516</em>, 370–387. (<a
href="https://doi.org/10.1016/j.ins.2019.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the damage caused by earthquakes, the paper develops a decision-making method under uncertainty, which validly addresses the site selection for earthquake shelters. Since site selection after earthquakes is an emergency decision-making process, during which there always exists inaccuracy and complexity, it is more rational to adopt fuzzy theory to handle this problem. Therefore, we introduce a hesitant multiplicative linguistic preference relation (HMLPR) and propose its consistency measure based on the eigenvector method. An adjustment method is provided to repair the unacceptably consistent HMLPR into acceptably consistent one, and the parameter of the adjustment method is also discussed. To manifest the validity and availability of the proposed method, we choose the Wenchuan Earthquake on May 12th 2008 as the background event. Upon establishing the indicators including scale and location, risk of disaster, rescue facilities, feasibility and resident aspect, three experts from Institute for Disaster Management and Reconstruction of Sichuan University are invited to address the site selection for temporary shelters. The obtained result is approved by the experts as the optimal choice in the case of this paper. Finally, we complete the comparative analysis. The processing efficiency of the proposed method keeps stable and fast when the number of experts and the number of criteria increase from 3 to 10 respectively, which demonstrates that the proposed method is more robust and efficient than the existing method.},
  archive      = {J_ISCI},
  author       = {Hangyao Wu and Peijia Ren and Zeshui Xu},
  doi          = {10.1016/j.ins.2019.12.059},
  journal      = {Information Sciences},
  pages        = {370-387},
  shortjournal = {Inf. Sci.},
  title        = {Addressing site selection for earthquake shelters with hesitant multiplicative linguistic preference relation},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable disk-based topic modeling for memory limited
devices. <em>ISCI</em>, <em>516</em>, 353–369. (<a
href="https://doi.org/10.1016/j.ins.2019.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disk-based algorithms have the ability to process large-scale data which do not fit into the memory, so they provide good scalability to a mobile device with limited memory resources. In general, the speed of disk I/O is much slower than that of memory access, the total amount of disk I/O is the most crucial factor which determines the efficiency of disk-based algorithms. This paper proposes BlockLDA, an efficient disk-based Latent Dirichlet Allocation (LDA) inference algorithm which can efficiently infer an LDA model when both of the data and model do not fit into the memory. BlockLDA manages the data and model as a set of small blocks so that it can support efficient disk I/O as well as process the LDA inference in a block-wise manner. In addition, it utilizes advanced techniques which help to minimize the amount of disk I/O, including 1) a space reduction algorithm to dynamically manage the block-wise model considering its changing sparsity and 2) a local scheduling algorithm to carefully select the next data blocks so that the number of page faults is minimized. Our experimental results demonstrate that BlockLDA shows better scalability and efficiency than its disk-based and in-memory competitors under the memory-limited environment.},
  archive      = {J_ISCI},
  author       = {Byungju Kim and Dongha Lee and Jinoh Oh and Hwanjo Yu},
  doi          = {10.1016/j.ins.2019.12.058},
  journal      = {Information Sciences},
  pages        = {353-369},
  shortjournal = {Inf. Sci.},
  title        = {Scalable disk-based topic modeling for memory limited devices},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the negation of a dempster–shafer belief structure based
on maximum uncertainty allocation. <em>ISCI</em>, <em>516</em>, 346–352.
(<a href="https://doi.org/10.1016/j.ins.2019.12.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probability theory and Dempster–Shafer theory are two germane theories to represent and handle uncertain information. Recent study suggested a transformation to obtain the negation of a probability distribution based on the maximum entropy . Correspondingly, determining the negation of a belief structure, however, is still an open issue in Dempster–Shafer theory, which is very important in theoretical research and practical applications. In this paper, a negation transformation for belief structures is proposed based on maximum uncertainty allocation, and several important properties satisfied by the transformation have been studied. The proposed negation transformation is more general and could be totally compatible with existing transformation for probability distributions.},
  archive      = {J_ISCI},
  author       = {Xinyang Deng and Wen Jiang},
  doi          = {10.1016/j.ins.2019.12.080},
  journal      = {Information Sciences},
  pages        = {346-352},
  shortjournal = {Inf. Sci.},
  title        = {On the negation of a Dempster–Shafer belief structure based on maximum uncertainty allocation},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical and communication-efficient deniable
authentication with source-hiding and its application on wi-fi privacy.
<em>ISCI</em>, <em>516</em>, 331–345. (<a
href="https://doi.org/10.1016/j.ins.2019.12.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Authentication service in communication is essential. However, information flows transmitted during an authentication process might reveal some personal information. In this paper, we propose a deniable authentication protocol with source hiding which does not reveal any private information, therefore the privacy of participants is preserved. With our approach, the sender is able to deny an authentication process to any third party. The receiver can not prove that the sender has participated in this authentication, though it is sure that the sender is legitimate. We construct this protocol without using “Encryption-then-MAC” paradigm, therefore the underlying building block is not required to be CCA2 secure, and is a more realistic authentication protocol for practical privacy-preserving Internet-based applications. We also show how to apply it in Wi-Fi authentication to prevent the location leakage.},
  archive      = {J_ISCI},
  author       = {Shengke Zeng and Yi Mu and Hongjie Zhang and Mingxing He},
  doi          = {10.1016/j.ins.2019.12.069},
  journal      = {Information Sciences},
  pages        = {331-345},
  shortjournal = {Inf. Sci.},
  title        = {A practical and communication-efficient deniable authentication with source-hiding and its application on wi-fi privacy},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conflict analysis under one-vote veto based on approximate
three-way concept lattice. <em>ISCI</em>, <em>516</em>, 316–330. (<a
href="https://doi.org/10.1016/j.ins.2019.12.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis, which plays an important role in our society, has attracted more and more attentions. However, the existing conflict analysis models are not effective enough to evaluate the inconsistency degree of cliques that have more than two individuals. Besides, for each clique, its allied, conflict and neutral attributes have not been explicitly defined and thoroughly explored. Therefore, due to the lack of enough explicit clues, we cannot further formulate some strategies manipulating the conflict degrees of related cliques to realize the specific objectives. Last but not least, one-vote veto is seldom considered, although it plays a vital role in many fields, such as venture capital and United Nations Security Council resolutions. In order to solve these problems, we resort to three-way concept analysis and describe a clique by using the intent of a specific concept. On the basis of the obtained specific concepts, we derive the allied, conflict and neutral attributes of cliques, and further make decisions and explore the maximal coalitions and minimum conflict sets. Finally, in order to cater dynamic environment, we also describe an incremental algorithm for conflict analysis.},
  archive      = {J_ISCI},
  author       = {Huilai Zhi and Jianjun Qi and Ting Qian and Ruisi Ren},
  doi          = {10.1016/j.ins.2019.12.065},
  journal      = {Information Sciences},
  pages        = {316-330},
  shortjournal = {Inf. Sci.},
  title        = {Conflict analysis under one-vote veto based on approximate three-way concept lattice},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-labeling methods for unsupervised transfer ranking.
<em>ISCI</em>, <em>516</em>, 293–315. (<a
href="https://doi.org/10.1016/j.ins.2019.12.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A lack of reliable relevance labels for training ranking functions is a significant problem for many search applications. Transfer ranking is a technique aiming to transfer knowledge from an existing machine learning ranking task to a new ranking task. Unsupervised transfer ranking is a special case of transfer ranking where there aren’t any relevance labels available for the new task, only queries and retrieved documents. One approach to tackling this problem is to impute relevance labels for (document-query) instances in the target collection. This is done by using knowledge from the source collection. We propose three self-labeling methods for unsupervised transfer ranking: an expectation-maximization based method (RankPairwiseEM) for estimating pairwise preferences across documents, a hard-assignment expectation-maximization based algorithm (RankHardLabelEM), which directly assigns imputed relevance labels to documents, and a self-learning algorithm (RankSelfTrain), which gradually increases the number of imputed labels. We have compared the three algorithms on three large public test collections using LambdaMART as the base ranker and found that (i) all the proposed algorithms show improvements over the original source ranker in different transferring scenarios; (ii) RankPairwiseEM and RankSelfTrain significantly outperform the source rankers across all environments. We have also found that they are not significantly worse than the model directly trained on the target collection; and (iii) self-labeling methods are significantly better than previous instance-weighting based solutions on a variety of collections.},
  archive      = {J_ISCI},
  author       = {Pengfei Li and Mark Sanderson and Mark Carman and Falk Scholer},
  doi          = {10.1016/j.ins.2019.12.067},
  journal      = {Information Sciences},
  pages        = {293-315},
  shortjournal = {Inf. Sci.},
  title        = {Self-labeling methods for unsupervised transfer ranking},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid multi-resolution multi-objective ensemble model and
its application for forecasting of daily PM2.5 concentrations.
<em>ISCI</em>, <em>516</em>, 266–292. (<a
href="https://doi.org/10.1016/j.ins.2019.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM2.5 concentrations forecasting can provide early air pollution warning information for the public in advance. In this study, a novel multi-resolution ensemble model for multi-step PM2.5 concentrations forecasting is proposed. This model utilizes the high resolution (1-h) and low resolution (1-day) data as the input, and outputs low resolution PM2.5 concentrations forecasting data. For the high resolution data, real-time wavelet packet decomposition (WPD) is applied to generate sub-layers, the features within the high resolution sublayers are extracted by stacked auto-encoder (SAE), and the extracted features are fed into the bidirectional long short term memory (BiLSTM) to generate PM2.5 concentrations forecasting results. For the low resolution data, the forecasting results are obtained by the real-time WPD and BiLSTM . The forecasting results obtained by the high and low resolution data are combined by the non-dominated sorting genetic algorithm (NSGA-II) algorithm to output the deterministic forecasting results. The bivariate kernel density estimation (BKDE) algorithm is applied to describe the heteroscedasticity and non-Gaussian characteristics of the deterministic forecasting residuals and produce probabilistic forecasting results. Four real air pollutant data are utilized to validate the proposed model. The experimental results show the proposed model has better forecasting performances than the benchmark models.},
  archive      = {J_ISCI},
  author       = {Liu Hui and Duan Zhu and Chen Chao},
  doi          = {10.1016/j.ins.2019.12.054},
  journal      = {Information Sciences},
  pages        = {266-292},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid multi-resolution multi-objective ensemble model and its application for forecasting of daily PM2.5 concentrations},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Modeling a stochastic age-structured capital system with
poisson jumps using neural networks. <em>ISCI</em>, <em>516</em>,
254–265. (<a href="https://doi.org/10.1016/j.ins.2019.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an approach for modeling a stochastic age-structured capital system (SASCS) with Poisson jumps, in which the transfer rate of capital, noise intensity and jump intensity are approximated by a type of feedforward neural networks (FNNs). The approximate stock of capital for the system is calculated using Euler’s scheme in time discretization . Based on Barkholder-Davis-Gundys inequality and Gronwalls lemma, the error between the approximate stock of capital and the actual stock of capital is estimated by using mean squares . Theoretical analysis of the convergence of the approximate stock of capital is conducted, and some numerical results are presented to justify our findings.},
  archive      = {J_ISCI},
  author       = {Jie Ren and Qimin Zhang and Feilong Cao and Chunmei Ding and Li Wang},
  doi          = {10.1016/j.ins.2019.12.048},
  journal      = {Information Sciences},
  pages        = {254-265},
  shortjournal = {Inf. Sci.},
  title        = {Modeling a stochastic age-structured capital system with poisson jumps using neural networks},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep learning approach for multi-attribute data: A study
of train delay prediction in railway systems. <em>ISCI</em>,
<em>516</em>, 234–253. (<a
href="https://doi.org/10.1016/j.ins.2019.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamical systems that contain moving objects generate multi-attribute data, including static, time-series, and spatiotemporal formats. The diversity of the data formats creates challenges for the accurate modeling of these systems, for example, the state/location/trajectory prediction of moving objects. We developed a deep learning (DL) approach that combines 3-dimensional convolutional neural networks (3D CNN), long short-term memory (LSTM) recurrent neural network, and fully-connected neural network (FCNN) architectures to address this problem. The proposed model, named CLF-Net, uses individual factors with different attributes as input to achieve better predictions. The spatiotemporal features are fed into the 3D CNN, the time-series variables are fed into the LSTM, and the non-time-series factors are fed into the FCNN, respectively. A case study of train delay prediction for four railway lines with different operational features shows that the CLF-Net outperforms conventional machine learning models and the state-of-the-art DL models with regard to the performance metrics of the root mean squared error and mean absolute error.},
  archive      = {J_ISCI},
  author       = {Ping Huang and Chao Wen and Liping Fu and Qiyuan Peng and Yixiong Tang},
  doi          = {10.1016/j.ins.2019.12.053},
  journal      = {Information Sciences},
  pages        = {234-253},
  shortjournal = {Inf. Sci.},
  title        = {A deep learning approach for multi-attribute data: A study of train delay prediction in railway systems},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lightweight group convolutional network for single image
super-resolution. <em>ISCI</em>, <em>516</em>, 220–233. (<a
href="https://doi.org/10.1016/j.ins.2019.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning methods have demonstrated significant reconstruction performance on Single Image Super-Resolution (SISR). However, most of them demand a huge amount of computational and memory consumption and hard to be applied to real-world applications. To this end, we propose a fast Lightweight Group Convolution Network (LGCN) model for SISR to alleviate this problem. Specifically, we develop a cascaded memory group convolutional network for SISR, which cascades several Memory Group Convolutional Networks (MGCN). There are two main merits on MGCN. One is that it consists of several group convolutional layers and 1  ×  1 convolutional layers with densely connected structure. The group convolution is utilized to reduce the parameters of LGCN, and the 1  ×  1 convolution is not only used to create a linear combination of the output of group convolutional layer, but also to gather local information progressively. The other one is that it utilizes channel attention unit to model channel-wise relationships to improve performance. Experimental results on four popular datasets show that the proposed LGCN not only outperforms the state-of-the-art SISR methods, but also achieves faster speed.},
  archive      = {J_ISCI},
  author       = {Aiping Yang and Bingwang Yang and Zhong Ji and Yanwei Pang and Ling Shao},
  doi          = {10.1016/j.ins.2019.12.057},
  journal      = {Information Sciences},
  pages        = {220-233},
  shortjournal = {Inf. Sci.},
  title        = {Lightweight group convolutional network for single image super-resolution},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). No-reference quality index of depth images based on
statistics of edge profiles for view synthesis. <em>ISCI</em>,
<em>516</em>, 205–219. (<a
href="https://doi.org/10.1016/j.ins.2019.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual view synthesis has been increasingly popular due to the wide applications of multi-view and free-viewpoint videos. In view synthesis, texture images are rendered to generate the new viewpoint with the guidance of the depth images. The quality of depth images is vital for generating high-quality synthesized views. While the impact of texture image and the rendering process on the quality of the synthesized view has been extensively studied, the quality evaluation of depth images remains largely unexplored. With this motivation, this paper presents a no-reference image quality index for depth maps by modeling the statistics of edge profiles (SEP) in a multi-scale framework. The Canny operator is first utilized to locate the edges in depth images. Then the edge profiles are constructed, based on which the first-order and second-order statistical features are extracted for portraying the distortions in depth images. Finally, the random forest is employed for building the quality assessment model for depth maps . Experiments are conducted on two annotated view synthesis image/video quality databases. The experimental results and comparisons demonstrate that the proposed metric outperforms the relevant state-of-the-art quality metrics by a large margin. Furthermore, it has better generalization ability .},
  archive      = {J_ISCI},
  author       = {Leida Li and Xi Chen and Jinjian Wu and Shiqi Wang and Guangming Shi},
  doi          = {10.1016/j.ins.2019.12.061},
  journal      = {Information Sciences},
  pages        = {205-219},
  shortjournal = {Inf. Sci.},
  title        = {No-reference quality index of depth images based on statistics of edge profiles for view synthesis},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Evidence reasoning rule-based classifier with uncertainty
quantification. <em>ISCI</em>, <em>516</em>, 192–204. (<a
href="https://doi.org/10.1016/j.ins.2019.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Dempster–Shafer evidence theory (DST)-based classifier design , the newly proposed evidence reasoning (ER) rule can be used as a multi-attribute classifier to combine multiple pieces of evidence generated from quantitative samples or qualitative knowledge of many attributes. Different from the classical Dempster&#39;s combination (DC) rule and its improved forms, ER rule definitely distinguishes the reliability and importance weight of evidence. The former reflects the ability of a single attribute or the corresponding evidence to give correct classification results whereas the latter clarifies the relative importance of evidence when it is combined with other pieces of evidence. Here how to determine the reliability factor is a key problem because it is the connection between the preceding evidence acquisition and the following evidence combination with the importance weights. Therefore, the main aim of this paper is to present a universal method for obtaining the reliability factor by quantifying the uncertainties of samples and the generated evidence. Experiential results on five popular benchmark databases taken from University of California Irvine (UCI) machine learning database show the improved classifier can give higher classification accuracy than the original ER-based classifier without considering uncertainty quantification and other classical or mainstream classifiers.},
  archive      = {J_ISCI},
  author       = {Xiaobin Xu and Deqing Zhang and Yu Bai and Leilei Chang and Jianning Li},
  doi          = {10.1016/j.ins.2019.12.037},
  journal      = {Information Sciences},
  pages        = {192-204},
  shortjournal = {Inf. Sci.},
  title        = {Evidence reasoning rule-based classifier with uncertainty quantification},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical solution to clone problem in anonymous
information system. <em>ISCI</em>, <em>516</em>, 158–191. (<a
href="https://doi.org/10.1016/j.ins.2019.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloning user&#39;s identity is always a thorny problem for an information system, especially for an anonymous system. With the development of big data applications , clone behaviors sometimes even become attacks on these systems. But until now, there has been no very satisfactory anti-clone scheme in the anonymous system. After analyzing the problems in existing anti-clone schemes, without any assumptions about physical security, we provide a practical solution to the clone problem in anonymous authentication system. In our scheme, the authentication is not only related to user&#39;s private key, but also related to user&#39;s current state, which is constantly updated by the system. Therefore, the authentication trajectories of user and clone will inevitably overlap, and it results in information leakage so as to indentify clone behaviors and revoke clone user&#39;s credential. Meanwhile, we prove that honest users are truly anonymous and their login behaviors are unlinkable with complete security proofs. According to the analysis of the system function and the system efficiency, our scheme is much more efficient and has the best anti-clone properties comparing with the existing schemes.},
  archive      = {J_ISCI},
  author       = {Bin Lian and Gongliang Chen and Lang Wang and Jialin Cui and Ping Yu and Dake He},
  doi          = {10.1016/j.ins.2019.12.014},
  journal      = {Information Sciences},
  pages        = {158-191},
  shortjournal = {Inf. Sci.},
  title        = {A practical solution to clone problem in anonymous information system},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-view RBM with posterior consistency and domain
adaptation. <em>ISCI</em>, <em>516</em>, 142–157. (<a
href="https://doi.org/10.1016/j.ins.2019.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restricted Boltzmann machine (RBM) and extensions are rarely used in the field of multi-view learning. In this paper, we first present a multi-view RBM model for classification, which is named RBM with posterior consistency (PCRBM). PCRBM computes multiple representations by regularizing the marginal likelihood function with the consistency among representations from multiple views. However, PCRBM ignores the specific information of each view, where the learned representations just contain the consistency information among multiple views. To address this problem, we propose a novel multi-view RBM model and name it as RBM with posterior consistency and domain adaptation (PDRBM). PDRBM divides the hidden units of each view into two groups: the one is the view-consistency group that contains the consistency information among multiple views, and the other is the view-specific group that contains the information unique to this separate view. In addition, PDRBM balances the relationship among view-consistency hidden representations for multi-view classification. Contrasting with existing multi-view classification methods, PDRBM has achieved satisfactory results on two-class and multi-class classification multi-view datasets.},
  archive      = {J_ISCI},
  author       = {Nan Zhang and Shifei Ding and Tongfeng Sun and Hongmei Liao and Lijuan Wang and Zhongzhi Shi},
  doi          = {10.1016/j.ins.2019.12.062},
  journal      = {Information Sciences},
  pages        = {142-157},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view RBM with posterior consistency and domain adaptation},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving social and behavior recommendations via network
embedding. <em>ISCI</em>, <em>516</em>, 125–141. (<a
href="https://doi.org/10.1016/j.ins.2019.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, information is generated at an unprecedented rate. Users are in great need of recommender systems to provide the potential friends or interested items for them. Social (i.e. friend) recommendation and behavior (i.e. item) recommendation are two types of popular services in real-world applications. Although researchers have proposed various models for each task, a unified model to address both tasks elegantly and effectively is still in demand. In this paper, we propose a model called SBRNE which integrates social and behavior recommendations into a unified framework through modeling social and behavior information simultaneously. Specifically, SBRNE models social and behavior information simultaneously via employing users’ latent interests as a bridge, and derives improved performance on both social and behavior recommendation tasks. In addition, by introducing an efficient network embedding procedure, users’ latent representations are advanced, and effectiveness and efficiency of recommendation tasks are improved accordingly. Results on both real-world and synthetic datasets demonstrate that: 1). SBRNE outperforms selected baselines on social and behavior recommendation tasks; 2). SBRNE performs stable on recommendation tasks for cold-start users; 3). The network embedding procedure can improve the effectiveness of SBRNE; 4). The hyper-parameter learning procedure can improve both the effectiveness and efficiency of SBRNE.},
  archive      = {J_ISCI},
  author       = {Weizhong Zhao and Huifang Ma and Zhixin Li and Xiang Ao and Ning Li},
  doi          = {10.1016/j.ins.2019.12.038},
  journal      = {Information Sciences},
  pages        = {125-141},
  shortjournal = {Inf. Sci.},
  title        = {Improving social and behavior recommendations via network embedding},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint dimensionality reduction and metric learning for image
set classification. <em>ISCI</em>, <em>516</em>, 109–124. (<a
href="https://doi.org/10.1016/j.ins.2019.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with the traditional classification task based on a single image, an image set contains more complementary information, which is of great benefit to correctly classify a query subject. Thus, image set classification has attracted much attention from researchers. However, the main challenge is how to effectively represent an image set to fully exploit the latent discriminative feature . Unlike in previous works where an image set was represented by a single or a hybrid mode, in this paper, we propose a novel multi-model fusion method across the Euclidean space to the Riemannian manifold to jointly accomplish dimensionality reduction and metric learning. To achieve the goal of our framework, we first introduce three distance metric learning models, namely, Euclidean-Euclidean, Riemannian-Riemannian and Euclidean-Riemannian to better exploit the complementary information of an image set. Then, we aim to simultaneously learn two mappings performing dimensionality reduction and a metric matrix by integrating the two heterogeneous spaces (i.e., the Euclidean space and the Riemannian manifold space) into the common induced Mahalanobis space in which the within-class data sets are close and the between-class data sets are separated. This strategy can effectively handle the severe drawback of not considering the distance metric learning when performing dimensionality reduction in the existing set based methods. Furthermore, to learn a complete Mahalanobis metric, we adopt the L 2,1 regularized metric matrix for optimal feature selection and classification. The results of extensive experiments on face recognition, object classification, gesture recognition and handwritten classification demonstrated well the effectiveness of the proposed method compared with other image set based algorithms.},
  archive      = {J_ISCI},
  author       = {Wenzhu Yan and Quansen Sun and Huaijiang Sun and Yanmeng Li},
  doi          = {10.1016/j.ins.2019.12.041},
  journal      = {Information Sciences},
  pages        = {109-124},
  shortjournal = {Inf. Sci.},
  title        = {Joint dimensionality reduction and metric learning for image set classification},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Public key encryption with equality test in the standard
model. <em>ISCI</em>, <em>516</em>, 89–108. (<a
href="https://doi.org/10.1016/j.ins.2019.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public key encryption with equality test (PKEET) is a cryptosystem that allows a tester who has trapdoors issued by one or more users U i to perform equality tests on ciphertexts encrypted using public key(s) of U i . Since this feature has a lot of practical applications including search on encrypted data , several PKEET schemes have been proposed so far. However, to the best of our knowledge, all the existing proposals are proven secure only under the hardness of number-theoretic problems and/or the random oracle heuristics. In this paper, we show that this primitive can be achieved not only generically from well-established other primitives but also even without relying on the random oracle heuristics. More precisely, our generic construction for PKEET employs a two-level hierarchical identity-based encryption scheme, which is selectively secure against chosen plaintext attacks , a strongly unforgeable one-time signature scheme and a cryptographic hash function . Our generic approach toward PKEET has several advantages over all the previous works; it directly leads the first standard model construction and also directly implies the first lattice-based construction. Finally, we show how to extend our approach to the identity-based setting.},
  archive      = {J_ISCI},
  author       = {Hyung Tae Lee and San Ling and Jae Hong Seo and Huaxiong Wang and Taek-Young Youn},
  doi          = {10.1016/j.ins.2019.12.023},
  journal      = {Information Sciences},
  pages        = {89-108},
  shortjournal = {Inf. Sci.},
  title        = {Public key encryption with equality test in the standard model},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Restoring incomplete PUMLPRs for evaluating the management
way of online public opinion. <em>ISCI</em>, <em>516</em>, 72–88. (<a
href="https://doi.org/10.1016/j.ins.2019.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the age of big data explosion, the management of online public opinion has encountered great challenges. Which way can effectively manage online public opinion has become a decision-making question for us to think about. Probabilistic uncertain multiplicative linguistic preference relations (PUMLPRs) are a remarkable instrument to solve uncertain evaluation problems. This paper uses the PUMLPRs to assess the management ways of the online public opinion. Owing to the intricacy of decision-making domain, the PUMLPRs are not always complete. We get the complete PUMLPRs in two steps: the repair for uncertain multiplicative linguistic variables and the repair for probability . Moreover, the consistency of the complete PUMLPRs is researched. Then the final priorities are obtained by the proposed possibility degree formula. After that, the numerical example that helps assess the valid way to manage online public opinion is performed to check the feasibility of the proposed decision-making procedure.},
  archive      = {J_ISCI},
  author       = {Wanying Xie and Zeshui Xu and Zhiliang Ren and Enrique Herrera Viedma},
  doi          = {10.1016/j.ins.2019.12.030},
  journal      = {Information Sciences},
  pages        = {72-88},
  shortjournal = {Inf. Sci.},
  title        = {Restoring incomplete PUMLPRs for evaluating the management way of online public opinion},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pressure sensor placement in water distribution networks for
leak detection using a hybrid information-entropy approach.
<em>ISCI</em>, <em>516</em>, 56–71. (<a
href="https://doi.org/10.1016/j.ins.2019.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes an optimization framework based on a hybrid information-entropy approach to identify leakage events in water distribution networks (WDN). Optimization-based methods are widely employed in the literature for such purposes; however, they are constrained by time-consuming procedures. Hence, researchers eliminate parts of the decision space to curtail the computational burden. Here, we propose an information theory-based approach, using Value of Information (VOI) and Transinformation Entropy (TE) methods, in conjunction with an optimization model to explore the entire decision space. VOI allows for the entire feasible space search through intelligent sampling, which in turn ensures robust solutions. TE minimizes redundant information and helps maximize the spatial distribution of sensors. The herein proposed model is developed within a multi-objective optimization framework that renders a set of Pareto-optimal solutions. ELimination and Choice Expressing the REality (ELECTRE) multi-criteria decision-making model is then used to select the best compromise solution given several weighting scenarios. The results of this study show that the information-entropy based scheme can improve the precision of leak detection by enhancing the decision space, and can reduce the computational burden.},
  archive      = {J_ISCI},
  author       = {Mohammad Sadegh Khorshidi and Mohammad Reza Nikoo and Narges Taravatrooy and Mojtaba Sadegh and Malik Al-Wardy and Ghazi Ali Al-Rawas},
  doi          = {10.1016/j.ins.2019.12.043},
  journal      = {Information Sciences},
  pages        = {56-71},
  shortjournal = {Inf. Sci.},
  title        = {Pressure sensor placement in water distribution networks for leak detection using a hybrid information-entropy approach},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource and replica management strategy for optimizing
financial cost and user experience in edge cloud computing system.
<em>ISCI</em>, <em>516</em>, 33–55. (<a
href="https://doi.org/10.1016/j.ins.2019.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge cloud computing can provide resources that are close to users and reduce response time. However, the edge cloud computing system still faces many challenges on addressing the overload problem due to its limited capacity. In this paper, a resource management strategy is proposed to satisfy the workloads of the edge cloud, while minimizing the financial cost of the rented nodes. Furthermore, the replica management strategy, which consists of the replica allocation and consistency preservation strategy, is studied. A dynamic replica allocation strategy is proposed to satisfy the user experience while reducing the storage overheads . In addition, the replica consistency preservation strategy is proposed for guaranteeing the data consistency and correctness. Finally, extensive experiments are conducted based on a real-world dataset. With the increase in the time, the proposed resource management algorithm can significantly reduce the total financial cost of the rented nodes and SLA default rate and improve the CPU utilization. For instance, the total financial cost of the proposed algorithm averagely achieves up to 32.27\% and 53.65\% reduction over that of CAAS algorithm and DRM algorithm, respectively. In addition, the proposed replica allocation algorithm can effectively reduce the data transmission time and the storage overhead.},
  archive      = {J_ISCI},
  author       = {Chunlin Li and Jingpan Bai and Yi Chen and Youlong Luo},
  doi          = {10.1016/j.ins.2019.12.049},
  journal      = {Information Sciences},
  pages        = {33-55},
  shortjournal = {Inf. Sci.},
  title        = {Resource and replica management strategy for optimizing financial cost and user experience in edge cloud computing system},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selective prototype-based learning on concept-drifting data
streams. <em>ISCI</em>, <em>516</em>, 20–32. (<a
href="https://doi.org/10.1016/j.ins.2019.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream mining has gained increasing attention in recent years due to its wide range of applications. In this paper, we propose a new selective prototype-based learning (SPL) method on evolving data streams, which dynamically maintains representative instances to capture the time-changing concepts, and make predictions in a local fashion. As an instance-based learning model, SPL only maintains some important prototypes (i.e., ISet ) via error-driven representativeness learning. The fast condensed nearest neighbor (FCNN) rule, is further introduced to compress these prototypes, making the algorithm also applicable under memory constraints. To better distinguish noises from the instances associated with the new emerging concept, a potential concept instance set (i.e., PSet ) is used to store all misclassified instances. Relying on the potential concept instance set, a local-aware distribution-based concept drift detection approach is proposed. SPL has several attractive benefits: (a) it can fit the evolving data streams very well by maintaining a small size of instance set; (b) it is capable of capturing both gradual and sudden concept drifts effectively; (c) it has great capabilities to distinguish noise/outliers from drifting instances. Experimental results show that the SPL has better classification performance than many other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Dongzi Chen and Qinli Yang and Jiaming Liu and Zhu Zeng},
  doi          = {10.1016/j.ins.2019.12.046},
  journal      = {Information Sciences},
  pages        = {20-32},
  shortjournal = {Inf. Sci.},
  title        = {Selective prototype-based learning on concept-drifting data streams},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low dimensional mid-term chaotic time series prediction by
delay parameterized method. <em>ISCI</em>, <em>516</em>, 1–19. (<a
href="https://doi.org/10.1016/j.ins.2019.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to predict the future behavior of complex systems with insufficient information, i.e., low dimensional mid-term chaotic time series prediction in mathematical terms , is not only a significant theoretical problem, but a more intricate practical problem. To address this issue, a Delay Parameterized Method (DPM) for low dimensional mid-term chaotic time series forecasting is presented. The correlation function, which immerses the low dimensional information into reconstructed space, is introduced to bridge time series and hidden order of system in DPM. Traversal algorithm and intelligent algorithm including particle swarm optimization or genetic algorithm , are used to obtain the optimal parameters for prediction. In addition, the applications of the proposed method on Lorenz chaotic time series, stress-strain signals and stock K-line maps show that it produces high quality predictions.},
  archive      = {J_ISCI},
  author       = {Xiaoxiang Guo and Yutong Sun and Jingli Ren},
  doi          = {10.1016/j.ins.2019.12.021},
  journal      = {Information Sciences},
  pages        = {1-19},
  shortjournal = {Inf. Sci.},
  title        = {Low dimensional mid-term chaotic time series prediction by delay parameterized method},
  volume       = {516},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security-preserving social data sharing methods in modern
social big knowledge systems. <em>ISCI</em>, <em>515</em>, 404–416. (<a
href="https://doi.org/10.1016/j.ins.2019.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, the development of social computing systems has realized the efficient information exchange between large groups of people. Nowadays, social computing systems are rather complex platforms supported by not only traditional sociology theory but also computer science and big data based applications. With the increase of the social computing systems’ complexities, serious issues of social digital security and privacy have shown up since, in recent years, more and more social data leakage incidents are happening. This fact is due to reasons on many different aspects since there are many sources threatening the security and privacy of the social data in such a complex social computing system. In this paper, we improve the traditional social data protection schemes by combining the information fragmentation concepts with the distributed system architectures to build a novel social data protection scheme. We use social photo protection as the fundamental scenario and deploy our novel scheme to illustrate the improvement on the protection level with the protection analysis in detail. A security analysis of practically realizing such a scheme is also evaluated in this paper.},
  archive      = {J_ISCI},
  author       = {Xuan Chen},
  doi          = {10.1016/j.ins.2019.12.028},
  journal      = {Information Sciences},
  pages        = {404-416},
  shortjournal = {Inf. Sci.},
  title        = {Security-preserving social data sharing methods in modern social big knowledge systems},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure k-skyband computation framework in distributed
multi-party databases. <em>ISCI</em>, <em>515</em>, 388–403. (<a
href="https://doi.org/10.1016/j.ins.2019.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a secure k -skyband computation framework in distributed multi-party databases, in which we can compute multi-party k -skyband without disclosing attributes of each object in a party to other parties, which is essential in privacy-aware applications. Although several secure skyline computation algorithms have been proposed, all of the conventional methods require a large amount of communication and computationally expensive secure comparison. Due to the large computational and communication complexities, they are not suitable for comparing or querying over a significant number of encrypted objects, which are located in privacy-preserving distributed multi-party databases. In the proposed framework, we used a secure multi-party sorting method that uses a homomorphic encryption scheme in the semi-honest adversary model and then uses the sorting order of the objects’ attributes on each dimension for k -skyband computation. The detailed security analysis shows that the proposed framework can achieve secure multi-party k -skyband computation without leaking sensitive information to others. Besides that, the performance evaluations via extensive simulations also demonstrate the efficiency of our proposed framework.},
  archive      = {J_ISCI},
  author       = {Mahboob Qaosar and Asif Zaman and Md. Anisuzzaman Siddique and Chen Li and Yasuhiko Morimoto},
  doi          = {10.1016/j.ins.2019.12.027},
  journal      = {Information Sciences},
  pages        = {388-403},
  shortjournal = {Inf. Sci.},
  title        = {Secure k-skyband computation framework in distributed multi-party databases},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AREA: An adaptive reference-set based evolutionary algorithm
for multiobjective optimisation. <em>ISCI</em>, <em>515</em>, 365–387.
(<a href="https://doi.org/10.1016/j.ins.2019.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population-based evolutionary algorithms have great potential to handle multiobjective optimisation problems . However, the performance of these algorithms depends largely on problem characteristics. There is a need to improve these algorithms for wide applicability. References, often specified by the decision maker’s preference in different forms, are very effective to boost the performance of algorithms. This paper proposes a novel framework for effective use of references to strengthen algorithms. This framework considers references as search targets which can be adjusted based on the information collected during the search. The proposed framework is combined with new strategies, such as reference adaptation and adaptive local mating, to solve different types of problems. The proposed algorithm is compared with state-of-the-arts on a wide range of problems with diverse characteristics. The comparison and extensive sensitivity analysis demonstrate that the proposed algorithm is competitive and robust across different types of problems studied in this paper.},
  archive      = {J_ISCI},
  author       = {Shouyong Jiang and Hongru Li and Jinglei Guo and Mingjun Zhong and Shengxiang Yang and Marcus Kaiser and Natalio Krasnogor},
  doi          = {10.1016/j.ins.2019.12.011},
  journal      = {Information Sciences},
  pages        = {365-387},
  shortjournal = {Inf. Sci.},
  title        = {AREA: An adaptive reference-set based evolutionary algorithm for multiobjective optimisation},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Worst-case ϵ-stealthy false data injection attacks in
cyber-physical systems. <em>ISCI</em>, <em>515</em>, 352–364. (<a
href="https://doi.org/10.1016/j.ins.2019.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of designing the worst-case ϵ-stealthy false data injection attacks in cyber-physical systems is investigated. The attacker attempts to degrade the remote state estimation performance by modifying the transmitted sensor measurements. Different from the existing ϵ-stealthy actuator attacks where the effect of the attacks is characterized by the information theoretic analysis , the remote estimation error is calculated with the statistical characteristics of the innovations and the problem is transformed into a constrained optimization problem with multiple decision variables. By utilizing the properties of the K-L divergence and mutual information, the problem is solved with the Lagrange multiplier method and the worst-case attack strategy is derived, which maximizes the estimation error and guarantees the stealthiness. Finally, simulation examples are provided to demonstrate the results.},
  archive      = {J_ISCI},
  author       = {Yi-Gang Li and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2019.12.029},
  journal      = {Information Sciences},
  pages        = {352-364},
  shortjournal = {Inf. Sci.},
  title        = {Worst-case ϵ-stealthy false data injection attacks in cyber-physical systems},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relation constrained attributed network embedding.
<em>ISCI</em>, <em>515</em>, 341–351. (<a
href="https://doi.org/10.1016/j.ins.2019.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims at learning a low-dimensional dense vector for each node in the network. In recent years, it has attracted great research attention due to its wide applications. Most existing studies model the graph structure only and neglect the attribute information. Although several attributed network embedding methods take the node attribute into account, they mainly focus on the basic relations between the nodes and their attributes like a user and his/her interests (attributes). The composite relations between two nodes, and two nodes’ attributes, and the related nodes and their attributes, contain rich information and can enhance the performance of many network analysis tasks. For example, two scholars having the common interests as “nature language processing” and “knowledge graph” may collaborate in the future and there will be a new edge in the network. However, such important information is still under-exploited. To address this limitation, we propose a novel framework to exploit the abundant relation information to enhance attributed network embedding. The main idea is to employ the multiple types of relations in attributed networks as the constraints to improve the network representation. To this end, we first construct the composite relations between two nodes and their attributes in addition to the commonly used basic relations. We then develop a relation constrained attributed network (RCAN) framework to learn the node representations by constraining them with these relations. We conduct extensive experiments on three real-world datasets to show the effectiveness of our proposed RCAN as an attributed network embedding method for modeling various social networks. The results demonstrate that our method achieves significantly better performance than the state-of-the-art baselines in both the link prediction and node clustering tasks .},
  archive      = {J_ISCI},
  author       = {Yiqi Chen and Tieyun Qian},
  doi          = {10.1016/j.ins.2019.12.033},
  journal      = {Information Sciences},
  pages        = {341-351},
  shortjournal = {Inf. Sci.},
  title        = {Relation constrained attributed network embedding},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sliding mode control of automotive electronic valve system
under weighted try-once-discard protocol. <em>ISCI</em>, <em>515</em>,
324–340. (<a href="https://doi.org/10.1016/j.ins.2019.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the sliding mode control problem is addressed for the automotive electronic valve system, which is described by the Markovian model according to the voltage failure. It is supposed that both the system states and the system modes are unavailable to the controller. In order to avoid data collision on the sensor-to-controller transmission, the scheduling among the sensor nodes is ruled by the weighted try-once-discard protocol. A mode detector via a hidden Markovian model is introduced, and an asynchronous token-dependent state observer is proposed. Dependent on the hidden mode information and current token directive, a sliding mode controller is constructed to assure the reachability of a sliding region. Besides, the hidden Markovian model approach is developed to derive mean-square stability conditions for the augmented system . Eventually, simulation studies are provided to demonstrate the validity of the proposed control scheme for the system under consideration.},
  archive      = {J_ISCI},
  author       = {Zhiru Cao and Yugang Niu and Hamid Reza Karimi},
  doi          = {10.1016/j.ins.2019.12.032},
  journal      = {Information Sciences},
  pages        = {324-340},
  shortjournal = {Inf. Sci.},
  title        = {Sliding mode control of automotive electronic valve system under weighted try-once-discard protocol},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EHAUSM: An efficient algorithm for high average utility
sequence mining. <em>ISCI</em>, <em>515</em>, 302–323. (<a
href="https://doi.org/10.1016/j.ins.2019.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying high utility sequences in a quantitative sequence database is an important data mining task . However, a key problem of current approaches is that extensions of a high utility sequence often have a high utility. Hence, traditional techniques are often biased toward finding long patterns. To circumvent this problem, this paper proposes techniques for the problem of high average-utility sequence (HAUS) mining ( H A U S M HAUSM ). HAUSs are more meaningful than high utility sequences because the former are found using the average-utility measure, which consider the length of patterns in utility calculations. H A U S M HAUSM is more general than high average-utility itemset mining but it is also a more difficult problem because the downward-closure property used for search space reduction does not hold for the average-utility. To overcome that challenge, this paper introduces two upper bounds and a weak upper bound on the average-utility measure, and four width pruning, depth pruning, reducing, and tightening strategies. These strategies are designed to eliminate candidate HAUSs to speed up HAUS mining. Based on these theoretical results, a novel algorithm named EHAUSM is proposed for H A U S M HAUSM . Experiments on both real-life and synthetic quantitative sequence databases have confirmed its efficiency in terms of memory consumption and runtime.},
  archive      = {J_ISCI},
  author       = {Tin Truong and Hai Duong and Bac Le and Philippe Fournier-Viger},
  doi          = {10.1016/j.ins.2019.11.018},
  journal      = {Information Sciences},
  pages        = {302-323},
  shortjournal = {Inf. Sci.},
  title        = {EHAUSM: An efficient algorithm for high average utility sequence mining},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uniform random posets. <em>ISCI</em>, <em>515</em>, 294–301.
(<a href="https://doi.org/10.1016/j.ins.2019.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple algorithm generating labelled posets of given size according to the almost uniform distribution. By “almost uniform” we understand that the distribution of generated posets converges in total variation to the uniform distribution. Our method is based on a Markov chain generating directed acyclic graphs.},
  archive      = {J_ISCI},
  author       = {Patryk Kozieł and Małgorzata Sulkowska},
  doi          = {10.1016/j.ins.2019.12.018},
  journal      = {Information Sciences},
  pages        = {294-301},
  shortjournal = {Inf. Sci.},
  title        = {Uniform random posets},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A mixed attributes oriented dynamic SOM fuzzy cluster
algorithm for mobile user classification. <em>ISCI</em>, <em>515</em>,
280–293. (<a href="https://doi.org/10.1016/j.ins.2019.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of mobile user behavior analysis, clustering algorithm is used to do the user classification. Usually the mobile user’s dataset is mixed, which contains both numerical and categorical type of data. It leads to inaccurate results when doing the user classification using traditional algorithms like K-Means and which are affected by the initialization process extremely. On the other hand, K-Prototypes algorithm is used to process the mixed data. It is difficult to ascertain the coefficient of classification attribute weight. Based on the above problems, this paper proposes a mixed attributes oriented dynamic SOM fuzzy cluster algorithm (D-SOMFCM-OMA) for mobile user classification. Firstly, the algorithm proposed in this paper gives the primary clustering using Self-Organizing feature Map (SOM) to get the initial clustering parameters. As the preprocessing of clustering, this step reduces effects caused by inappropriate initialization. Then, the algorithm utilizes the improved dynamic fuzzy K-Prototypes cluster method in the second-time clustering to classify users dynamically. It calculates weight of all kinds of attributes according to the proportion of the attribute and uses fine-tuned coefficient to adjust the attribute weight. For improving the clustering effect, the algorithm uses Jaccard distance to calculate the distance in the mixed attribute variables. Further, this paper defines the user mean membership threshold which is an indicator to determine whether different groups need to be added. Finally, some comparison experiments are conducted on the UCI standard datasets to show the advantage of the improved fuzzy clustering algorithm oriented the mixed attributes (IFCM-OMA). Also the other experiment using dataset of UCI verify the validity of the algorithm of D-SOMFCM-OMA.},
  archive      = {J_ISCI},
  author       = {Guangxia Xu and Linghao Zhang and Chuang Ma and Yanbing Liu},
  doi          = {10.1016/j.ins.2019.12.019},
  journal      = {Information Sciences},
  pages        = {280-293},
  shortjournal = {Inf. Sci.},
  title        = {A mixed attributes oriented dynamic SOM fuzzy cluster algorithm for mobile user classification},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way decision on two universes. <em>ISCI</em>,
<em>515</em>, 263–279. (<a
href="https://doi.org/10.1016/j.ins.2019.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set models on two universes are important generalizations of Pawlak’s classical model. In most of the two-universe models, the upper and lower approximations are constructed based on inclusion relation. We generalize inclusion relation to the general evaluation function and define the models of three-way decision on two universes. As an important class of evaluation functions, subsethood measures are considered. We compare our models with other five existing two-universe models in rough set theory and point out that the model of three-way decision on two-universe unifies the five two-universe models. Besides, properties of the two-universe model of three-way decision are also given. More importantly, we propose an approach to computing the pair of thresholds α and β . Our approach is based on the maximum value of the accuracy measure with respect to tri-partitions of a universe induced by all thresholds.},
  archive      = {J_ISCI},
  author       = {Xiaonan Li and Qianqian Sun and Hongmei Chen and Huangjian Yi},
  doi          = {10.1016/j.ins.2019.12.020},
  journal      = {Information Sciences},
  pages        = {263-279},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision on two universes},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure distributed estimation against false data injection
attack. <em>ISCI</em>, <em>515</em>, 248–262. (<a
href="https://doi.org/10.1016/j.ins.2019.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of wireless sensor networks , many distributed algorithms have been studied by researchers. This paper considers the situation of distributed estimation with false data injection (FDI) attack. Owing to the fact that Kullback-Leibler (KL) divergence is very effective to detect outliers caused by FDI attack, a distributed adaptive algorithm over KL divergence is proposed to detect FDI attack. When the malicious nodes are detected, three algorithms are explored separately to weaken the impact of FDI attack. The performance of the three algorithms is analyzed in mean and mean-square. The effectiveness of the three proposed algorithms is shown through some illustrative examples under continual FDI attack and time-sharing FDI attack.},
  archive      = {J_ISCI},
  author       = {Yi Hua and Feng Chen and Shuwei Deng and Shukai Duan and Lidan Wang},
  doi          = {10.1016/j.ins.2019.12.016},
  journal      = {Information Sciences},
  pages        = {248-262},
  shortjournal = {Inf. Sci.},
  title        = {Secure distributed estimation against false data injection attack},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attention-aware perceptual enhancement nets for
low-resolution image classification. <em>ISCI</em>, <em>515</em>,
233–247. (<a href="https://doi.org/10.1016/j.ins.2019.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying low-resolution (LR) images is notoriously challenging because of their noisy representation and limited information. Existing approaches mainly solve this challenge by training carefully designed architectures on LR datasets or by employing an image-resizing algorithm in a straightforward manner. However, the performance improvements of these methods are usually limited or even trivial in the case of LR images. In this work, we address the LR image classification problem by developing an end-to-end architecture that internally elevates representations of an LR image to “super-resolved” ones. This approach imparts characteristics similar to those of high-resolution (HR) images and is thus more discriminative and representative for image classification . For this purpose, we propose an innovative unified framework, named Attention-aware Perceptual Enhancement Nets (APEN), which integrates perceptual enhancement and an attention mechanism in an end-to-end manner for LR image classification. Specifically, the framework includes a perceptual enhancement network to generate super-resolved images from LR images. In addition, a novel attention mechanism is presented to highlight informative regions, while restricting the semantic deviation of super-resolved images. Additionally, we designed a feature rectification strategy to promote the adaptability of category decision. Experiments conducted on publicly available datasets demonstrate the superiority of our method against state-of-the-art methods on both LR and HR datasets.},
  archive      = {J_ISCI},
  author       = {Xiaobin Zhu and Zhuangzi Li and Xianbo Li and Shanshan Li and Feng Dai},
  doi          = {10.1016/j.ins.2019.12.013},
  journal      = {Information Sciences},
  pages        = {233-247},
  shortjournal = {Inf. Sci.},
  title        = {Attention-aware perceptual enhancement nets for low-resolution image classification},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BPF++: A unified factorization model for predicting retweet
behaviors. <em>ISCI</em>, <em>515</em>, 218–232. (<a
href="https://doi.org/10.1016/j.ins.2019.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the prediction of retweet behaviors has attracted significant attention, as it can facilitate with a number of tasks, such as popular tweet prediction, personalized recommendation and business intelligence . However, in existing studies, two main problems exists in the prediction of retweet behaviors. (1) The relationship between users is extremely simple when social influences are used for prediction. (2) An effective framework that unifies the effects of both heterogeneous social relations of users and multidimensional similarities of tweets does not exist. Therefore, we propose a unified factorization model that incorporates social influence and tweet similarity into a traditional Bayesian Poisson factorization (BPF) model, named BPF++. Specifically, we utilize a variety of social influence and tweet similarity jointly to improve performance. Furthermore, we integrate trust strengths between users and degrees of similarity between tweets to the framework. We adopt an efficient coordinate ascent algorithm to learn the parameters of the BPF++ model. Extensive experiments are conducted to evaluate the performance of our model on the Sina Weibo dataset. Results demonstrate improvements of 113.64\% and 116.28\% in the NDCG@3 and precision@3 scores, respectively, compared with BPF.},
  archive      = {J_ISCI},
  author       = {Shaoqing Wang and Cuiping Li and Zheng Wang and Hong Chen and Kai Zheng},
  doi          = {10.1016/j.ins.2019.12.017},
  journal      = {Information Sciences},
  pages        = {218-232},
  shortjournal = {Inf. Sci.},
  title        = {BPF++: A unified factorization model for predicting retweet behaviors},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and implementation of a simple dynamical 4-d chaotic
circuit with applications in image encryption. <em>ISCI</em>,
<em>515</em>, 191–217. (<a
href="https://doi.org/10.1016/j.ins.2019.10.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a simple yet highly dimensional hybrid diode bridge circuit network that can exhibit complex chaotic behaviours. Further, since our network is characterised by smooth fourth-order exponential nonlinearity, we employ a distinctive approach to assess its different properties: we examine the circuit stability near fixed points. Specifically, we evaluate dynamic complexity using the Lyaponov spectrum analysis, bifurcation analysis and phase space trajectories; additionally, we assess coexisting attractors in the parameter space using numerical and experimental analysis. Furthermore, we report assessments of our network in terms of remerging Feigenbaum trees and metastable chaos. Finally, these properties, and especially the chaotic series of the coexisting attractors, were exploited to implement a chaos-based image encryption protocol using S-box construction and PRNG generation mechanisms. To validate the performance of our protocol, we employed standard security analysis including correlation coefficient , pixel change rate , information entropy, time complexity and key space analysis whose outcome were compared alongside available state-of-the-art methods. Outcomes suggest promising applications for our chaotic circuit network in image encryption .},
  archive      = {J_ISCI},
  author       = {Nestor Tsafack and Jacques Kengne and Bassem Abd-El-Atty and Abdullah M. Iliyasu and Kaoru Hirota and Ahmed A. Abd EL-Latif},
  doi          = {10.1016/j.ins.2019.10.070},
  journal      = {Information Sciences},
  pages        = {191-217},
  shortjournal = {Inf. Sci.},
  title        = {Design and implementation of a simple dynamical 4-D chaotic circuit with applications in image encryption},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling hierarchical category transition for next POI
recommendation with uncertain check-ins. <em>ISCI</em>, <em>515</em>,
169–190. (<a href="https://doi.org/10.1016/j.ins.2019.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing next POI recommendation studies rely on users’ certain check-ins at individual POIs (e.g., Italian restaurant). In reality, users may leave some uncertain check-ins in the places (e.g., shopping mall), which are named as collective POIs . It indicates that we cannot always access users’ precise check-ins at collective POIs, thus existing approaches fail to work well. To this end, we propose a new research problem, that aims to recommend next individual POIs with uncertain check-ins at collective POIs. It is, however, difficult to learn complete and accurate users’ check-in transition patterns with uncertain check-ins. Besides, uncertain check-ins aggravate the cold start issue, as the individual POIs inside collective POIs cannot be observed in users’ historical check-ins. To tackle these challenges, we devise a novel h ierarchical c ategory t ransition (HCT) framework, which exploits category transitions at different layers to model users’ preference transition patterns in different granularity . By doing so, HCT predicts users’ preferred categories inside collective POIs. As bounded to specific categories, HCT further adopts hierarchical dependencies between POIs and categories to capture the semantic relatedness of POIs, thus easing the cold start issue. Empirical studies on multiple datasets show the superiority of HCT against state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Lu Zhang and Zhu Sun and Jie Zhang and Horst Kloeden and Felix Klanner},
  doi          = {10.1016/j.ins.2019.12.006},
  journal      = {Information Sciences},
  pages        = {169-190},
  shortjournal = {Inf. Sci.},
  title        = {Modeling hierarchical category transition for next POI recommendation with uncertain check-ins},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Life-like network automata descriptor based on binary
patterns for network classification. <em>ISCI</em>, <em>515</em>,
156–168. (<a href="https://doi.org/10.1016/j.ins.2019.09.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a descriptor based on binary patterns extracted from network-automata time-evolution patterns (TEP) aiming to characterize networks. More, in particular, we explore TEPs descriptors from the Life-Like Network Automata (LLNA), a cellular automaton inspired by the rules of the “Life-Like” family that uses a network as tessellation, and based on its dynamics to extract features for network characterization. In recent work, the LLNA has been introduced as a pattern recognition tool that uses a descriptor based on the histograms of complexity measures such as the entropy, word length, and Lempel-Ziv complexity. However, these descriptors correspond to continuous values, and consequently, their histograms lack of an optimal number of bins, which therefore turns out to be a parametric issue. To overcome this disadvantage, we propose a new descriptor that computes feature vectors formed by discrete binary patterns histograms with different lengths D . Furthermore, we show a statistical improvement of the proposed method compared to earlier approaches such as the original LLNA and classical network structural measurements. Our experimental results show the performance improvement of the proposed method in six synthetic network databases and eight real network databases.},
  archive      = {J_ISCI},
  author       = {Lucas C. Ribas and Jeaneth Machicao and Odemir M. Bruno},
  doi          = {10.1016/j.ins.2019.09.063},
  journal      = {Information Sciences},
  pages        = {156-168},
  shortjournal = {Inf. Sci.},
  title        = {Life-like network automata descriptor based on binary patterns for network classification},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving clustering for big data in
cyber-physical-social systems: Survey and perspectives. <em>ISCI</em>,
<em>515</em>, 132–155. (<a
href="https://doi.org/10.1016/j.ins.2019.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering technique plays a critical role in data mining , and has received great success to solve application problems like community analysis, image retrieval , personalized recommendation, activity prediction, etc. This paper first reviews the traditional clustering and the emerging multiple clustering methods , respectively. Although the existing methods have superior performance on some small or certain datasets, they fall short when clustering is performed on CPSS big data because of the high cost of computation and storage. With the powerful cloud computing , this challenge can be effectively addressed, but it brings enormous threat to individual or company’s privacy. Currently, privacy preserving data mining has attracted widespread attention in academia. Compared to other reviews, this paper focuses on privacy preserving clustering technique, guiding a detailed overview and discussion. Specifically, we introduce a novel privacy-preserving tensor-based multiple clustering, propose a privacy-preserving tensor-based multiple clustering analytic and service framework, and give an illustrated case study on the public transportation dataset. Furthermore, we indicate the remaining challenges of privacy preserving clustering and discuss the future significant research in this area.},
  archive      = {J_ISCI},
  author       = {Yaliang Zhao and Samwel K. Tarus and Laurence T. Yang and Jiayu Sun and Yunfei Ge and Jinke Wang},
  doi          = {10.1016/j.ins.2019.10.019},
  journal      = {Information Sciences},
  pages        = {132-155},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving clustering for big data in cyber-physical-social systems: Survey and perspectives},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New construction of an ordinal sum of t-norms and t-conorms
on bounded lattices. <em>ISCI</em>, <em>515</em>, 116–131. (<a
href="https://doi.org/10.1016/j.ins.2019.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new ordinal sum construction of t-norms and t-conorms on bounded lattices based on interior and closure operators . The proposed method generalizes several known constructions and provides a simple tool to introduce new classes of t-norms and t-conorms.},
  archive      = {J_ISCI},
  author       = {Antonín Dvořák and Michal Holčapek},
  doi          = {10.1016/j.ins.2019.12.003},
  journal      = {Information Sciences},
  pages        = {116-131},
  shortjournal = {Inf. Sci.},
  title        = {New construction of an ordinal sum of t-norms and t-conorms on bounded lattices},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommending investors for new startups by integrating
network diffusion and investors’ domain preference. <em>ISCI</em>,
<em>515</em>, 103–115. (<a
href="https://doi.org/10.1016/j.ins.2019.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, many startups have sprung up, which create a huge demand for financial support from venture investors. However, due to the information asymmetry between investors and companies, the financing process is usually challenging and time-consuming, especially for the startups that have not yet obtained any investment. Because of this, effective data-driven techniques to automatically match startups with potentially relevant investors would be highly desirable. Here, we analyze 34,469 valid investment events collected from www.itjuzi.com and consider the cold-start problem of recommending investors for new startups. We address this problem by constructing different tripartite network representations of the data where nodes represent investors, companies, and companies’ domains. First, we find that investors have strong domain preferences when investing, which motivates us to introduce virtual links between investors and investment domains in the tripartite network construction. Our analysis of the recommendation performance of diffusion-based algorithms applied to various network representations indicates that prospective investors for new startups are effectively revealed by integrating network diffusion processes with investors’ domain preference.},
  archive      = {J_ISCI},
  author       = {Shuqi Xu and Qianming Zhang and Linyuan Lü and Manuel Sebastian Mariani},
  doi          = {10.1016/j.ins.2019.11.045},
  journal      = {Information Sciences},
  pages        = {103-115},
  shortjournal = {Inf. Sci.},
  title        = {Recommending investors for new startups by integrating network diffusion and investors’ domain preference},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial-temporal data-driven service recommendation with
privacy-preservation. <em>ISCI</em>, <em>515</em>, 91–102. (<a
href="https://doi.org/10.1016/j.ins.2019.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing popularity of web service sharing communities have produced a considerable amount of web services that share similar functionalities but vary in Quality of Services (QoS) performances. To alleviate the heavy service selection burden on users, lightweight recommendation ideas, e.g., Collaborative Filtering (CF) have been developed to aid users to select their preferred services. However, existing CF methods often face two challenges. First, service QoS is often context-aware and hence depends on the spatial and temporal information of service invocations heavily. While it requires challenging efforts to integrate both spatial and temporal information into service recommendation decision-making process simultaneously. Second, the location-aware and time-aware QoS data often contain partial sensitive information of users, which raise an emergent privacy-preservation requirement when performing service recommendations. In view of above two challenges, in this paper, we integrate the spatial-temporal information of QoS data and Locality-Sensitive Hashing (LSH) into recommendation domain and bring forth a location-aware and time-aware recommendation approach considering privacy concerns. At last, a set of experiments conducted on well-known WS-DREAM dataset show the feasibility of our approach.},
  archive      = {J_ISCI},
  author       = {Lianyong Qi and Xuyun Zhang and Shancang Li and Shaohua Wan and Yiping Wen and Wenwen Gong},
  doi          = {10.1016/j.ins.2019.11.021},
  journal      = {Information Sciences},
  pages        = {91-102},
  shortjournal = {Inf. Sci.},
  title        = {Spatial-temporal data-driven service recommendation with privacy-preservation},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new self-paced method for multiple instance boosting
learning. <em>ISCI</em>, <em>515</em>, 80–90. (<a
href="https://doi.org/10.1016/j.ins.2019.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-instance learning is a useful tool for solving label ambiguity. MILBoost is one of the algorithms, which uses boosting method to handle the multiple instance learning problems. Although MILBoosting has achieved good effect on multiple instance learning , little work has been done on the problem of multiple instance learning where a small number of bags are labeled. In this paper, we propose a new approach by incorporating the SPL and boosting into the procedure of multiple instance learning, called Self-Paced Boost Multiple Instance Learning (SP-B-MIL). The proposed approach can improve the effectiveness and robustness of multi-instance learning when a small number of bags are labeled. We first reformulate the multiple instance boosting model with a self-paced loss formulation. Then we propose a self-paced function for realizing desired self-paced scheme, which makes it possible to select instances from different bags during each iteration. Finally, we design a simple and effective algorithm to solve the optimization problem . Experimental results show that the proposed algorithm is comparable to the classical algorithms in some multi-instance learning benchmark data sets.},
  archive      = {J_ISCI},
  author       = {Yanshan Xiao and Xiaozhou Yang and Bo Liu},
  doi          = {10.1016/j.ins.2019.12.015},
  journal      = {Information Sciences},
  pages        = {80-90},
  shortjournal = {Inf. Sci.},
  title        = {A new self-paced method for multiple instance boosting learning},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatio-spectral networks for color-texture analysis.
<em>ISCI</em>, <em>515</em>, 64–79. (<a
href="https://doi.org/10.1016/j.ins.2019.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture is one of the most-studied visual attributes for image characterization since the 1960s. However, most hand-crafted descriptors are monochromatic, focusing on grayscale images and discarding the color information. Therefore this work proposes a new method for color texture analysis considering all color channels in a more thorough approach. It consists of modeling color images as directed complex networks that we named Spatio-Spectral Network (SSN). Its topology includes within-channel connections that cover spatial patterns of individual color channels, while between-channel connections tackle spectral properties of channel pairs in an opponent fashion. Image descriptors are obtained through topological characterization of the modeled network in a multiscale approach with radially symmetric neighboring. Experiments with four datasets cover several aspects of color-texture analysis, and results demonstrate that SSN overcomes all the compared literature methods, including known deep convolutional networks . It also has the most stable performance between datasets, achieving 98.5(± 1.1) of average accuracy against 97.1(± 1.3) of MCND and 96.8(± 3.2) of AlexNet. Additionally, an experiment verifies the performance of the methods under different color spaces , showing that SSN presents the highest performance and robustness.},
  archive      = {J_ISCI},
  author       = {Leonardo F.S. Scabini and Lucas C. Ribas and Odemir M. Bruno},
  doi          = {10.1016/j.ins.2019.11.042},
  journal      = {Information Sciences},
  pages        = {64-79},
  shortjournal = {Inf. Sci.},
  title        = {Spatio-spectral networks for color-texture analysis},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CONAN: A framework for detecting and handling collusion in
crowdsourcing. <em>ISCI</em>, <em>515</em>, 44–63. (<a
href="https://doi.org/10.1016/j.ins.2019.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contrast to the traditional view that individuals should work independently to realize the crowd wisdom, crowdsourcing workers often collaborate with each other in task processing either explicitly or implicitly. Some may even collude for obtaining rewards easily, for example, by plagiarizing others’ answers. Collusion behavior sabotages the independency among workers, and will subvert the benefits of task redundancy that is commonly adopted in crowdsourcing. Therefore, dealing with collusion is critical for ensuring the quality of crowdsourcing. Existing work usually treats all the collusive answers as being harmful, thus simply filters away them once they are detected. However, it is not always the best strategy in practice. In particular, when the collusive answers are plagiarized from a worker with good ability, utilizing them instead of simple elimination can benefit the result quality. In this work, we first propose a collusion-aware framework for detecting and handling collusion in crowdsourcing properly. Second, we design a collusion detection method based on the statistical test of the consistency of workers’ answers across tasks. Third, we provide a theoretical means to determine when collusive answers should be kept and utilized, then we design a collusion-aware answer aggregation method. Finally, we conducted thorough evaluation with both synthetic and real-world datasets, and the results demonstrate the effectiveness of our approach.},
  archive      = {J_ISCI},
  author       = {Pengpeng Chen and Hailong Sun and Yili Fang and Xudong Liu},
  doi          = {10.1016/j.ins.2019.12.012},
  journal      = {Information Sciences},
  pages        = {44-63},
  shortjournal = {Inf. Sci.},
  title        = {CONAN: A framework for detecting and handling collusion in crowdsourcing},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of vehicle speed for batches to minimize supply
chain cost under uncertain demand. <em>ISCI</em>, <em>515</em>, 26–43.
(<a href="https://doi.org/10.1016/j.ins.2019.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of vehicle speed during transportation has been an essential concern since it leads to reduction in carbon emission which decreases negative consequences on environment. This paper optimizes the vehicle speed for batches being shipped to customers to minimize the supply chain cost under uncertain demand and to reduce the carbon emissions. The problem of regulating the speed at each stage is disintegrated into a set of subproblems . They can be easily dealt with first approximating by dynamic programming formulation. Then a set of differential equations associated with total costs can be obtained from the formulation and solved. Furthermore, a numerical case study related to truck transportation is provided to realize the advantages of varying speed policy over fixed speed policy.},
  archive      = {J_ISCI},
  author       = {Jasashwi Mandal and Adrijit Goswami and Junwei Wang and Manoj Kumar Tiwari},
  doi          = {10.1016/j.ins.2019.12.009},
  journal      = {Information Sciences},
  pages        = {26-43},
  shortjournal = {Inf. Sci.},
  title        = {Optimization of vehicle speed for batches to minimize supply chain cost under uncertain demand},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formal approach for discovering work transference networks
from workflow logs. <em>ISCI</em>, <em>515</em>, 1–25. (<a
href="https://doi.org/10.1016/j.ins.2019.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a formal principle for discovering work transference networks of workflow-supported organizational employees from workflow enactment histories contained in event logs. This originates from the strong belief that those work transference networks, hidden in workflow enactment activities and histories, can both connote the degree of work sharing and work relevancy between workflow performers and denote their degree of work intensity. In this paper, we devise a series of formal definitions and algorithms for discovering a work transference network from a workflow procedure, and from its enactment histories in event logs. The final goal of the paper is to theoretically build the principle of fidelity into workflow human resource planning and its performance, via a novel concept of work transference networks that can be discovered from a workflow model and, moreover, rediscovered from its enactment history. In deploying the proposed principle, we base the formal representation on information control net theory, which can graphically and mathematically represent workflow procedures. We apply directed graph theory to formally and graphically define the work transference network model proposed in this paper. For the sake of verifying and validating the proposed concepts and algorithms, we implement a work transference network rediscovery system, and apply it to a workflow enactment event log dataset, in an experimental study. Finally, we describe the implications of discovering and rediscovering work transference networks, as a human resource management and evaluation technique, in workflow-supported enterprises and organizations.},
  archive      = {J_ISCI},
  author       = {Hyun Ahn and Kwanghoon Pio Kim},
  doi          = {10.1016/j.ins.2019.11.036},
  journal      = {Information Sciences},
  pages        = {1-25},
  shortjournal = {Inf. Sci.},
  title        = {Formal approach for discovering work transference networks from workflow logs},
  volume       = {515},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Adaptive neural control for non-strict-feedback nonlinear
systems with input delay. <em>ISCI</em>, <em>514</em>, 605–616. (<a
href="https://doi.org/10.1016/j.ins.2019.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the controller design problem is considered for non-strict-feedback systems with input delay. An appropriate auxiliary system is utilized to deal with the difficulties appeared in input delay. By the utilization of backstepping and adaptive neural control, a state-feedback stabilization controller is developed. The designed controller enables the variables in the closed-loop system to be semi-globally uniformly ultimately bounded in a small interval around the origin. The main significance of this research is that an intelligent control scheme is extended to a class of nonlinear systems with non-strict-feedback form and input delay, simultaneously. Finally, an example is given to show the effectiveness of the control method .},
  archive      = {J_ISCI},
  author       = {Huanqing Wang and Siwen Liu and Xuebo Yang},
  doi          = {10.1016/j.ins.2019.09.043},
  journal      = {Information Sciences},
  pages        = {605-616},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive neural control for non-strict-feedback nonlinear systems with input delay},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). OCam: Out-of-core coordinate descent algorithm for matrix
completion. <em>ISCI</em>, <em>514</em>, 587–604. (<a
href="https://doi.org/10.1016/j.ins.2019.09.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there are increasing reports that most datasets can be actually stored in disks of a single off-the-shelf workstation, and utilizing out-of-core methods is much cheaper and even faster than using a distributed system. For these reasons, out-of-core methods have been actively developed for machine learning and graph processing. The goal of this paper is to develop an efficient out-of-core matrix completion method based on coordinate descent approach. Coordinate descent-based matrix completion (CD-MC) has two strong benefits over other approaches: 1) it does not involve heavy computation such as matrix inversion and 2) it does not have step-size hyper-parameters, which reduces the effort for hyper-parameter tuning. Existing solutions for CD-MC have been developed and analyzed for in-memory setting and they do not take disk-I/O into account. Thus, we propose OCam , a novel o ut-of-core c oordinate descent a lgorithm for m atrix completion. Our evaluation results and cost analyses provide sound evidences supporting the following benefits of OCam : (1) Scalability – OCam is a truly scalable out-of-core method and thus decomposes a matrix larger than the size of memory, (2) Efficiency – OCam is super fast. OCam is up to 10x faster than the state-of-the-art out-of-core method, and up to 4.1x faster than a competing distributed method when using eight machines. The source code of OCam will be available for reproducibility.},
  archive      = {J_ISCI},
  author       = {Dongha Lee and Jinoh Oh and Hwanjo Yu},
  doi          = {10.1016/j.ins.2019.09.077},
  journal      = {Information Sciences},
  pages        = {587-604},
  shortjournal = {Inf. Sci.},
  title        = {OCam: Out-of-core coordinate descent algorithm for matrix completion},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast finite-time adaptive stabilization of high-order
uncertain nonlinear systems with output constraint and zero dynamics.
<em>ISCI</em>, <em>514</em>, 571–586. (<a
href="https://doi.org/10.1016/j.ins.2019.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of fast finite-time adaptive stabilization for a class of high-order uncertain nonlinear systems with an output constraint and zero dynamics. A continuous stabilizer with an adaptive mechanism is constructed by utilizing a tangent function and a serial of nonnegative integral functions equipped with sign functions, which guarantees the system output to be restricted in a pre-specified region and a faster convergence speed of system states compared to traditional finite-time stabilizers. The main novelty of this paper is the skillful selection of Lyapunov functions and the new perspective of constructing a fast finite-time adaptive stabilizer with the consideration of output constraints as well as dynamic and parameter uncertainties. A simple example is given to demonstrate the effectiveness of the proposed strategy.},
  archive      = {J_ISCI},
  author       = {Zong-Yao Sun and Cheng-Qian Zhou and Chih-Chiang Chen and Qinghua Meng},
  doi          = {10.1016/j.ins.2019.11.006},
  journal      = {Information Sciences},
  pages        = {571-586},
  shortjournal = {Inf. Sci.},
  title        = {Fast finite-time adaptive stabilization of high-order uncertain nonlinear systems with output constraint and zero dynamics},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving categorization of mobile applications
based on large-scale usage data. <em>ISCI</em>, <em>514</em>, 557–570.
(<a href="https://doi.org/10.1016/j.ins.2019.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorization of mobile applications (apps) according to their functionalities is essential for app stores in maintaining a huge quantity of apps efficiently and securely. The problem in existing methods is that the apps are uploaded from untrusted sources and the static features extracted for categorization can be easily masked by obfuscation or encryption. To solve this problem and improve the categorization accuracy, we propose to extract features from usage data generated by apps running on mobile devices . Usage data, such as average running time or number of active users of an app, is hard to be manipulated by untrusted developers, while different types of apps generate different usage patterns. Based on this observation, we propose a new privacy-preserving categorization method of mobile apps based on learning patterns from a large scale of usage data. Firstly, the usage data collected from different users is anonymized by shuffling. Then we formalize the usage data as time series, extract and cluster usage data for each app based on Dynamic Time Warping. We utilize the Shape Features to segment the clustered time series and transform them into feature vectors. Finally, we adopt five machine learning methods to train and test the categorization models on 3,086 apps. The results show that SVM performs the best. When we exclude apps with the small number of the usage data flows under 50,000, the categorization performance (F1-score) of our method is improved to be over 96\%, which is significantly better than the previous methods.},
  archive      = {J_ISCI},
  author       = {Yongzhong He and Chao Wang and Guangquan Xu and Wenjuan Lian and Hequn Xian and Wei Wang},
  doi          = {10.1016/j.ins.2019.11.007},
  journal      = {Information Sciences},
  pages        = {557-570},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving categorization of mobile applications based on large-scale usage data},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Connectivity-preserving design strategy for distributed
cooperative tracking of uncertain nonaffine nonlinear time-delay
multi-agent systems. <em>ISCI</em>, <em>514</em>, 541–556. (<a
href="https://doi.org/10.1016/j.ins.2019.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distributed connectivity-preserving cooperative tracking problem is addressed for networked nonaffine nonlinear time-delay multi-agent systems with different communication ranges. State delays, nonaffine nonlinearities, and control directions of followers are assumed to be heterogenous and completely unknown. Unlike the literature on the cooperative control of time-delay multiagents , this paper contributes to establish a universal memoryless tracking strategy using nonlinear cooperative errors for preserving the initial connectivity among agents and simultaneously achieving cooperative tracking in the presence of unknown time-varying delays. A distributed approximation-based tracker for each follower is recursively constructed, and its stability is analyzed, without employing potential functions used for the connectivity preservation problem in the literature. Simulation examples are provided to validate the presented approach.},
  archive      = {J_ISCI},
  author       = {Sung Jin Yoo},
  doi          = {10.1016/j.ins.2019.11.012},
  journal      = {Information Sciences},
  pages        = {541-556},
  shortjournal = {Inf. Sci.},
  title        = {Connectivity-preserving design strategy for distributed cooperative tracking of uncertain nonaffine nonlinear time-delay multi-agent systems},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-lingual multi-keyword rank search with semantic
extension over encrypted data. <em>ISCI</em>, <em>514</em>, 523–540. (<a
href="https://doi.org/10.1016/j.ins.2019.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of searchable encryption technology sheds new light on the problem of secure search over encrypted data , which has been a research hotspot in the past few years. However, most existing search schemes based on searchable encryption only support queries in a certain language. The few searchable encryption schemes that have implemented multilingual search fail to achieve automated cross-lingual retrieval, which significantly impacts users search experience. Additionally, most of these schemes only support the exact matching and can-not provide semantic search . Hence, the implementation of cross-lingual and semantic search together remains an open topic for searchable encryption. To the best of our knowledge, no previous research has investigated the problem of cross-lingual ranked search over encrypted cloud data. To address this issue, we propose a cross-lingual multi-keyword rank search (CLRSE) scheme upon the Open Multilingual Wordnet. Our CLRSE scheme can break the barrier of languages, and realizes intelligent and personalized search through flexible keyword and language preference settings. Additionally, an improved scheme is developed to speed up the sorting process. We evaluate the performance of our scheme including security, functionality, precision, and efficiency, with extensive experiments.},
  archive      = {J_ISCI},
  author       = {Zhitao Guan and Xueyan Liu and Longfei Wu and Jun Wu and Ruzhi Xu and Jinhu Zhang and Yuanzhang Li},
  doi          = {10.1016/j.ins.2019.11.013},
  journal      = {Information Sciences},
  pages        = {523-540},
  shortjournal = {Inf. Sci.},
  title        = {Cross-lingual multi-keyword rank search with semantic extension over encrypted data},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A congestion game framework for service chain composition in
NFV with function benefit. <em>ISCI</em>, <em>514</em>, 512–522. (<a
href="https://doi.org/10.1016/j.ins.2019.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network function virtualization (NFV) is a network paradigm that aims at softwarizing network functions that usually have been implemented on specific hardware devices. In this paper, the service chain composition problem in NFV with function benefit is investigated. Using the non-cooperative game theory, the service chain configuration is converted to the seeking for the Nash equilibrium of the formulated game. The semi-tensor product (STP) of matrices is used as the algebraic tool for the game formulation and the Nash equilibrium calculation. The results on the service chain composition of the NFV are elaborated with a numerical example.},
  archive      = {J_ISCI},
  author       = {Shuting Le and Yuhu Wu and Mitsuru Toyoda},
  doi          = {10.1016/j.ins.2019.11.015},
  journal      = {Information Sciences},
  pages        = {512-522},
  shortjournal = {Inf. Sci.},
  title        = {A congestion game framework for service chain composition in NFV with function benefit},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic leader-following consensus for asynchronous
sampled-data multi-agent systems under switching topology.
<em>ISCI</em>, <em>514</em>, 499–511. (<a
href="https://doi.org/10.1016/j.ins.2019.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the leader-following consensus problem for asynchronous sampled-data multi-agent systems with an active leader and under switching topology , in which the asynchrony means that each agent’s update actions are independent of the others’. First, the dynamic leader-following consensus problem for asynchronous sampled-data systems is transformed into the convergence problem of products of infinite general sub-stochastic matrices (PIGSSM), where the general sub-stochastic matrices are matrices with row sum no more than 1 but their elements are not necessarily nonnegative. We develop a method to cope with the corresponding convergence problem by matrix decomposition . In particular, we split the general sub-stochastic matrix into a sub-stochastic matrix which is a nonnegative matrix with row sum no more than 1, and a matrix with negative elements and row sum 0. Then based on a graphical approach and matrix analysis technique, we present a sufficient condition for the achievement of dynamic leader-following consensus in the asynchronous setting. Finally, simulation examples are demonstrated to verify the theoretical results.},
  archive      = {J_ISCI},
  author       = {Hong Xia and Qi Dong},
  doi          = {10.1016/j.ins.2019.11.016},
  journal      = {Information Sciences},
  pages        = {499-511},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic leader-following consensus for asynchronous sampled-data multi-agent systems under switching topology},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HesGCN: Hessian graph convolutional networks for
semi-supervised classification. <em>ISCI</em>, <em>514</em>, 484–498.
(<a href="https://doi.org/10.1016/j.ins.2019.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manifold or local geometry of samples have been recognized as a powerful tool in machine learning areas, especially in the graph-based semi-supervised learning (GSSL) problems. Over recent decades, plenty of manifold assumption-based SSL algorithms (MSSL) have been proposed including graph embedding and graph regularization models, where the objective is to utilize the local geometry of data distributions. One of most representative MSSL approaches is graph convolutional networks (GCN), which effectively generalizes the convolutional neural networks to deal with the graphs with the arbitrary structures by constructing and fusing the Laplacian-based structure information. However, the null space of the Laplacian remains unchanged along the underlying manifold, it causes the poor extrapolating ability of the model. In this paper, we introduce a variant of GCN, i.e. Hessian graph convolutional networks (HesGCN). In particularly, we get a more efficient convolution layer rule by optimizing the one-order spectral graph Hessian convolutions. In addition, the spectral graph Hessian convolutions is a combination of the Hessian matrix and the spectral graph convolutions. Hessian gets a richer null space by the existence of its two-order derivatives, which can describe the intrinsic local geometry structure of data accurately. Thus, HesGCN can learn more efficient data features by fusing the original feature information with its structure information based on Hessian. We conduct abundant experiments on four public datasets. Extensive experiment results validate the superiority of our proposed HesGCN compared with many state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Sichao Fu and Weifeng Liu and Dapeng Tao and Yicong Zhou and Liqiang Nie},
  doi          = {10.1016/j.ins.2019.11.019},
  journal      = {Information Sciences},
  pages        = {484-498},
  shortjournal = {Inf. Sci.},
  title        = {HesGCN: Hessian graph convolutional networks for semi-supervised classification},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new divergence measure for belief functions in d–s
evidence theory for multisensor data fusion. <em>ISCI</em>,
<em>514</em>, 462–483. (<a
href="https://doi.org/10.1016/j.ins.2019.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer (D–S) evidence theory is useful for handling uncertainty problems in multisensor data fusion. However, the question of how to handle highly conflicting evidence in D–S evidence theory is still an open issue. In this paper, a new reinforced belief divergence measure, called RB , RB, is developed to measure the discrepancy between basic belief assignments (BBAs) in D–S evidence theory. The proposed RB RB divergence is the first such measure to consider the correlations between both belief functions and subsets of the sets of belief functions, thus allowing it to provide a more convincing and effective solution for measuring the discrepancy between BBAs. Additionally, the RB RB divergence has certain benefits in terms of measurement. In particular, it has the properties of nonnegativeness, nondegeneracy , symmetry and satisfaction of the triangle inequality . Based on the RB RB divergence, an algorithm for multisensor data fusion is then designed. Through a comparative analysis, it is verified that the proposed method is more feasible and reasonable than previous methods for measuring the divergence between BBAs. Finally, the proposed algorithm is effectively applied to a real-world classification fusion problem.},
  archive      = {J_ISCI},
  author       = {Fuyuan Xiao},
  doi          = {10.1016/j.ins.2019.11.022},
  journal      = {Information Sciences},
  pages        = {462-483},
  shortjournal = {Inf. Sci.},
  title        = {A new divergence measure for belief functions in D–S evidence theory for multisensor data fusion},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust fitting for the sugeno integral with respect to
general fuzzy measures. <em>ISCI</em>, <em>514</em>, 449–461. (<a
href="https://doi.org/10.1016/j.ins.2019.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Sugeno integral is an expressive aggregation function with potential applications across a range of decision contexts. Its calculation requires only the lattice minimum and maximum operations, making it particularly suited to ordinal data and robust to scale transformations. However, for practical use in data analysis and prediction, we require efficient methods for learning the associated fuzzy measure. While such methods are well developed for the Choquet integral , the fitting problem is more difficult for the Sugeno integral because it is not amenable to being expressed as a linear combination of weights, and more generally due to plateaus and non-differentiability in the objective function. Previous research has hence focused on heuristic approaches or simplified fuzzy measures. Here we show that the problem of fitting the Sugeno integral to data such that the maximum absolute error is minimized can be solved using an efficient bilevel program. This method can be incorporated into algorithms that learn fuzzy measures with the aim of minimizing the median residual. This equips us with tools that make the Sugeno integral a feasible option in robust data regression and analysis. We provide experimental comparison with a genetic algorithms approach and an example in data analysis.},
  archive      = {J_ISCI},
  author       = {Gleb Beliakov and Marek Gagolewski and Simon James},
  doi          = {10.1016/j.ins.2019.11.024},
  journal      = {Information Sciences},
  pages        = {449-461},
  shortjournal = {Inf. Sci.},
  title        = {Robust fitting for the sugeno integral with respect to general fuzzy measures},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Destructure-and-restructure matrix approximation.
<em>ISCI</em>, <em>514</em>, 434–448. (<a
href="https://doi.org/10.1016/j.ins.2019.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A matrix approximation is used to predict the missing values of a matrix, which has many applications in recommender systems . After predicting the missing values of a user-item rating matrix, we can recommend unrated items to a user according to their approximated values. This paper proposes a new approximation scheme for large and sparse global matrices, which is called a destructure-and-restructure matrix approximation . The basic idea is to first destructure a global matrix into many local matrices, and then restructure it from local matrix approximations. However, distance computation is a challenging issue in matrix destructure because no prior knowledge about the most appropriate feature vectors and distance measures are available. To deal with this issue, we propose a novel scheme that does not require any distance computation for local matrix construction, which is based on the application of convergence probabilities of a graph random walk. At first, a user-item bipartite graph is built from the global matrix. After performing random walk on the bipartite graph , we select several user-item pairs as anchors. Then, another random walk with restart is applied to construct local matrices from anchors. For each local matrix, we propose a weighted matrix factorization that is based on the rating distribution of the training data. In the restructure process, we first compute the approximation credibility of each local matrix, and we then finally obtain the global matrix approximation weighted from credible local approximations. Our experiments on five real-world datasets show that the proposed solution outperforms the state-of-the-art schemes in terms of lower prediction errors and higher coverage ratios.},
  archive      = {J_ISCI},
  author       = {Xuejiao Yang and Bang Wang},
  doi          = {10.1016/j.ins.2019.11.025},
  journal      = {Information Sciences},
  pages        = {434-448},
  shortjournal = {Inf. Sci.},
  title        = {Destructure-and-restructure matrix approximation},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CLP-ID: Community-based link prediction using information
diffusion. <em>ISCI</em>, <em>514</em>, 402–433. (<a
href="https://doi.org/10.1016/j.ins.2019.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, most link prediction algorithms have focused on node similarity owing to the associated low computational complexity and promising accuracy. In addition to the classical CN-based indexes, some methods are based on network features, such as community structure, information dissemination , and intermediary influence probability , which are used for link prediction. Although these methods provide new insight into the problem and achieve improvements in certain respects, they also have some limitations. For example, it is difficult to predict target links if the number of interconnections between communities is small. However, most studies aim at achieving higher link prediction accuracy even though a network obtained by these methods is not optimized for information spread. Therefore, we propose a community-based link prediction method using an information diffusion algorithm (CLP-ID) to predict the missing links. First, we present a community detection algorithm that divides the network into clusters. Then, a novel algorithm based on information diffusion and community structure is proposed to predict target links. Finally, we conduct experiments on real-world networks to validate the performance of the proposed algorithm and compare it with state-of-the-art algorithms. Statistical tests demonstrate that the proposed method significantly differs from state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Shashank Sheshar Singh and Shivansh Mishra and Ajay Kumar and Bhaskar Biswas},
  doi          = {10.1016/j.ins.2019.11.026},
  journal      = {Information Sciences},
  pages        = {402-433},
  shortjournal = {Inf. Sci.},
  title        = {CLP-ID: Community-based link prediction using information diffusion},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preprocessing methodology for time series: An industrial
world application case study. <em>ISCI</em>, <em>514</em>, 385–401. (<a
href="https://doi.org/10.1016/j.ins.2019.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel preprocessing methodology, framed within the field of time series forecasting. The aim is to get quality data and to extract information on the most important variables involved in a real-world crude oil refining process. To achieve this objective, the methodology incorporates the addition of dynamic knowledge, treatment of the noise present in the data, reduction of the dimensionality, feature selection and the introduction of slopes in the variables. Predictions are made for each step of the methodology and evaluated based on four measures: MAE, MSE, SMAPE and the delay in the prediction as compared to the original variable. The final solution is chosen based on these four measures and delivered to the experts so that they can optimize the crude oil refining process.},
  archive      = {J_ISCI},
  author       = {Juan Antonio Cortés-Ibáñez and Sergio González and José Javier Valle-Alonso and Julián Luengo and Salvador García and Francisco Herrera},
  doi          = {10.1016/j.ins.2019.11.027},
  journal      = {Information Sciences},
  pages        = {385-401},
  shortjournal = {Inf. Sci.},
  title        = {Preprocessing methodology for time series: An industrial world application case study},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient network seeding under variable node cost and
limited budget for social networks. <em>ISCI</em>, <em>514</em>,
369–384. (<a href="https://doi.org/10.1016/j.ins.2019.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of information diffusion on networks highly depends on both the network structure and the set of early spreaders. Moreover, in various realistic scenarios, to seed different nodes implies different costs, as in the case of viral marketing, where costs often correlate with local network structure. The budgeted influence maximization (BIM) problem consists in determining a seed set whose diffusion maximizes the total number of influenced nodes, provided that the seeding cost is within a given budget. We investigate efficient seeding strategies for the BIM problem under the deterministic fixed threshold diffusion model . In particular, we introduce the concept of surrounding sets : relatively cheap seeds neighboring expensive, structurally-privileged nodes, which then become spreaders at lower costs. Numerical experiments with several real networks indicate our method outperforms strategies that seed nodes based on their influence/cost ratios. A key insight from our evaluation is that larger diffusion is generally attained from the surrounding sets that consider the two-hop neighborhood of influential nodes , as opposed to their immediate neighbors only.},
  archive      = {J_ISCI},
  author       = {R.C. de Souza and D.R. Figueiredo and A.A. de A. Rocha and A. Ziviani},
  doi          = {10.1016/j.ins.2019.11.029},
  journal      = {Information Sciences},
  pages        = {369-384},
  shortjournal = {Inf. Sci.},
  title        = {Efficient network seeding under variable node cost and limited budget for social networks},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Group decision making with hesitant fuzzy linguistic
preference relations. <em>ISCI</em>, <em>514</em>, 354–368. (<a
href="https://doi.org/10.1016/j.ins.2019.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hesitant fuzzy linguistic preference relations (HFLPRs) can be used to describe hesitant judgments of decision makers (DMs). To further research the utilization of HFLPRs, this paper develops a new group decision making (GDM) method with HFLPRs. First, a consensus checking method is proposed to measure the consensus level of individual HFLPRs. Then, a definition of acceptable consensus is introduced. Furthermore, to help experts whose consensus levels are below a predefined threshold to revise their preferences, a consensus reaching procedure is developed, where the acceptable multiplicative consistency of the revised individual HFLPRs is guaranteed. After that, a step-by-step algorithm is developed to help us solve GDM problems with HFLPRs. An application example is implemented to indicate the utilization of our method and to compare with previous research.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2019.11.030},
  journal      = {Information Sciences},
  pages        = {354-368},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making with hesitant fuzzy linguistic preference relations},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neither global nor local: A hierarchical robust subspace
clustering for image data. <em>ISCI</em>, <em>514</em>, 333–353. (<a
href="https://doi.org/10.1016/j.ins.2019.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we consider the problem of subspace clustering in the presence of spatially contiguous noise, occlusion, and disguise. We argue that self-expressive representation of data, which is a key characteristic of current state-of-the-art approaches, is severely sensitive to occlusions and complex real-world noises. To alleviate this problem, we highlight the importance of previously neglected local representations in improving robustness and propose a hierarchical framework that combines the robustness of local-patch-based representations and the discriminative property of global representations. This approach consists of two main steps: 1) A top-down stage, in which the input data are subject to repeated division to smaller patches and 2) a bottom-up stage, in which the low rank embedding of representation matrices of local patches in the field of view of a corresponding patch in the upper level are merged on a Grassmann manifold. This unified approach provides two key pieces of information for neighborhood graph of the corresponding patch on the upper level: cannot-links and recommended-links. This supplies a robust summary of local representations which is further employed for computing self-expressive representations using a novel weighted sparse group lasso optimization problem . Numerical results for several data sets confirm the efficiency of our approach.},
  archive      = {J_ISCI},
  author       = {Maryam Abdolali and Mohammad Rahmati},
  doi          = {10.1016/j.ins.2019.11.031},
  journal      = {Information Sciences},
  pages        = {333-353},
  shortjournal = {Inf. Sci.},
  title        = {Neither global nor local: A hierarchical robust subspace clustering for image data},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Multiplicative data envelopment analysis cross-efficiency
and stochastic weight space acceptability analysis for group decision
making with interval multiplicative preference relations. <em>ISCI</em>,
<em>514</em>, 319–332. (<a
href="https://doi.org/10.1016/j.ins.2019.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with group decision making (GDM) with interval multiplicative preference relations (IMPRs), this paper proposes a novel method based on multiplicative data envelopment analysis (DEA) cross-efficiency and stochastic weight space acceptability analysis. We first develop a multiplicative DEA model to evaluate the relative efficiency of all alternatives of a given multiplicative preference relation (MPR). Then, we present a method, free from consistency adjustment, to derive a priority vector using the multiplicative DEA cross-efficiency with respect to the given MPR. For GDM with IMPRs, we consider the decision makers’ weights as a uniform distribution for acceptability analysis. A modified unacceptability index is further defined to measure the unlikeliness for a particular alternative in a particular rank. Finally, we develop an assignment problem model to achieve an optimal ranking by minimizing the total rank unacceptability, and to compute the expected priority vector of all alternatives. Numerical examples are provided to show the applicability and justifications of the proposed GDM method.},
  archive      = {J_ISCI},
  author       = {Jinpei Liu and Shu-Cherng Fang and Huayou Chen},
  doi          = {10.1016/j.ins.2019.11.032},
  journal      = {Information Sciences},
  pages        = {319-332},
  shortjournal = {Inf. Sci.},
  title        = {Multiplicative data envelopment analysis cross-efficiency and stochastic weight space acceptability analysis for group decision making with interval multiplicative preference relations},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Video-based recipe retrieval. <em>ISCI</em>, <em>514</em>,
302–318. (<a href="https://doi.org/10.1016/j.ins.2019.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recipe retrieval has received great attention in the research community, which focuses on retrieving a textual recipe given a text or an image as the query. However, cooking is an interesting activity, and many useful elements are hidden in the dynamic videos, which might be omitted in the statistic texts and images. On the other hand, although a number of video-based retrieval methods have been investigated in the past, existing technologies mainly focus on general applications and seldom take the domain-specific feature into account. To bridge the above gap, we investigate a new problem of video-based recipe retrieval, which refers to retrieving a cooking video from a list of video candidates given a textual recipe as the query, or the reverse side. In this work, we first propose a hierarchical attention network to learn the representations of textual recipe and its cooking procedures. Moreover, we employ reinforcement learning to dynamically locate a video moment given a cooking procedure as the query. Thereafter, the representations of video moments and cooking procedures are projected into a common space and optimized with a pairwise ranking loss, which is able to distinguish the matched and unmatched video moment-cooking procedure pairs. Therefore, the retrieval process between cooking videos and textual recipes is performed as the assembling matching results of video moments and cooking procedures. By experimenting on a self-collected dataset, we demonstrate the effectiveness and rationality of our proposed solution on the scope of both overall performance comparison and micro-level analyses.},
  archive      = {J_ISCI},
  author       = {Da Cao and Ning Han and Hao Chen and Xiaochi Wei and Xiangnan He},
  doi          = {10.1016/j.ins.2019.11.033},
  journal      = {Information Sciences},
  pages        = {302-318},
  shortjournal = {Inf. Sci.},
  title        = {Video-based recipe retrieval},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Certificateless aggregate signature scheme secure against
fully chosen-key attacks. <em>ISCI</em>, <em>514</em>, 288–301. (<a
href="https://doi.org/10.1016/j.ins.2019.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Certificateless aggregate signature (CLAS) schemes enjoy the benefits of both certificateless cryptography and aggregate signature features. Specifically, it not only simplifies the certificate management without introducing the key escrow problem but also transforms many signatures into one aggregate signature to save communication and computation cost. CLAS is a powerful cryptographic tool, yet its security should be thoroughly analyzed before being implemented. In this paper, we give a new insight into the security of CLAS schemes. We introduce a potential and realistic attack called fully chosen-key attacks that has not been considered in the traditional security models and define the security model against fully chosen-key attacks . In contrast to the traditional models, the adversary is allowed to hold all the signers’ private keys and its goal is not to forge an aggregate signature but to output invalid single signatures that can be aggregated into a valid aggregate signature. We find there is no CLAS scheme secure in traditional security models that is secure against fully chosen-key attacks and then demonstrate how to reinforce the security of an existing scheme to withstand such an attack.},
  archive      = {J_ISCI},
  author       = {Ge Wu and Futai Zhang and Limin Shen and Fuchun Guo and Willy Susilo},
  doi          = {10.1016/j.ins.2019.11.037},
  journal      = {Information Sciences},
  pages        = {288-301},
  shortjournal = {Inf. Sci.},
  title        = {Certificateless aggregate signature scheme secure against fully chosen-key attacks},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended dissipativity asynchronous static output feedback
control of markov jump systems. <em>ISCI</em>, <em>514</em>, 275–287.
(<a href="https://doi.org/10.1016/j.ins.2019.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with both continuous- and discrete-time extended dissipativity-based control problems for Markov jump systems. Hidden Markov model is employed to describe the jump asynchronization behavior between the original system and the controller. Then, an asynchronous static output feedback controller is designed. By using the mode-dependent Lyapunov function technique with slack matrices, several sufficient conditions are obtained to ensure that the closed-loop systems are stochastically stable with extended dissipativity performance. Based on these conditions, solutions to the controller gains are derived. Finally, simulation results are presented to illustrate the feasibility and the effectiveness of the proposed approaches.},
  archive      = {J_ISCI},
  author       = {Shanling Dong and Mei Fang and Shiming Chen},
  doi          = {10.1016/j.ins.2019.11.038},
  journal      = {Information Sciences},
  pages        = {275-287},
  shortjournal = {Inf. Sci.},
  title        = {Extended dissipativity asynchronous static output feedback control of markov jump systems},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep relevant representation learning for soft sensing.
<em>ISCI</em>, <em>514</em>, 263–274. (<a
href="https://doi.org/10.1016/j.ins.2019.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft sensing provides a reliable estimation of difficult-to-measure variables and is important for process control, optimization, and monitoring. The extraction of beneficial information from the abundance of available data in modern industrial processes and the development of data-driven soft sensors are becoming areas of increasing interest. In addition, the use of deep neural networks (DNNs) has become a popular data processing and feature extraction technique owing to its superiority in generating high-level abstract representations from massive amounts of data. A deep relevant representation learning (DRRL) approach based on a stacked autoencoder is proposed for the development of an efficient soft sensor. Representations from conventional DNN methods are not extracted for an output prediction, and thus a mutual information analysis is conducted between the representations and the output variable in each layer. Analysis results indicate that irrelevant representations are eliminated during the training of the subsequent layer. Hence, relevant information is highlighted in a layer-by-layer manner. Deep relevant representations are then extracted, and a soft sensor model is established. The results of a numerical example and an industrial oil refining process show that the prediction performance of the proposed DRRL-based soft sensing approach is better than that of other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xuefeng Yan and Jie Wang and Qingchao Jiang},
  doi          = {10.1016/j.ins.2019.11.039},
  journal      = {Information Sciences},
  pages        = {263-274},
  shortjournal = {Inf. Sci.},
  title        = {Deep relevant representation learning for soft sensing},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CREDO: Efficient and privacy-preserving multi-level medical
pre-diagnosis based on ML-kNN. <em>ISCI</em>, <em>514</em>, 244–262. (<a
href="https://doi.org/10.1016/j.ins.2019.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the promotion of online medical pre-diagnosis system, more and more research has begun to pay attention to the issue of privacy, and existing privacy-preserving schemes are designed for single-label data. However, medical users may infect many different diseases at the same time, it is necessary to take multi-label instances into account. In this paper, we propose an efficient and privacy-preserving multi-level medical pre-diagnosis scheme, called CREDO, which based on multi-label k -nearest-neighbors (ML- k NN). With CREDO, medical users can ensure their sensitive health information secure, and service provider can provide high-efficiency service without revealing pre-diagnosis model data. Specifically, service provider first narrows down the scope of medical instances needed to be calculated based on k -means clustering, then provides service for medical users based on ML- k NN classification. The query vector is encrypted before being sent out and directly operated in the service provider, meanwhile, the pre-diagnosis result can only be achieved by the medical user. Through extensive analysis, we show that CREDO can resist multifarious known security threats, and has much lower computation complexity than the compared scheme. Moreover, performance evaluations based on a real medical dataset demonstrate that our proposed scheme is highly efficient in terms of computation and communication overhead .},
  archive      = {J_ISCI},
  author       = {Dan Zhu and Hui Zhu and Ximeng Liu and Hui Li and Fengwei Wang and Hao Li and Dengguo Feng},
  doi          = {10.1016/j.ins.2019.11.041},
  journal      = {Information Sciences},
  pages        = {244-262},
  shortjournal = {Inf. Sci.},
  title        = {CREDO: Efficient and privacy-preserving multi-level medical pre-diagnosis based on ML-kNN},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Properties of approximation operators over 1-neighborhood
systems from the perspective of special granules. <em>ISCI</em>,
<em>514</em>, 234–243. (<a
href="https://doi.org/10.1016/j.ins.2019.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As generalizations of Pawlak-neighborhood systems, 1-neighborhood systems with symmetry or transitivity are closely related to both partition spaces and covering spaces. In this article, we analyze the properties of a single covering-based approximation operator on symmetric or transitive 1-neighborhood systems. We also investigate the relationships between different covering-based approximation operators on them. Theoretically, we illuminate some necessary and sufficient conditions for 1-neighborhood systems being symmetric, transitive, or partitions with one or two approximation operators. To reduce potential computation complexity owing to these equivalent characterizations, objects dealt by approximation operators in this work are three particular kinds of granules, namely, points of universes, elements of 1-neighborhood systems, and cores of 1-neighborhood systems. As experimental results indicate, this study outdoes some related works in terms of computational efficiency, establishing the advantages of computing on these granules. Furthermore, our research has resulted in a solution to a problem posed by Yun et al. (Axiomatization and conditions for neighborhoods in a covering to form a partition. Information Sciences 181(2011)1735–1740).},
  archive      = {J_ISCI},
  author       = {Zuoming Yu and Dongqiang Wang and Miao Liang},
  doi          = {10.1016/j.ins.2019.11.043},
  journal      = {Information Sciences},
  pages        = {234-243},
  shortjournal = {Inf. Sci.},
  title        = {Properties of approximation operators over 1-neighborhood systems from the perspective of special granules},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Insights into the effects of control parameters and mutation
strategy on self-adaptive ensemble-based differential evolution.
<em>ISCI</em>, <em>514</em>, 203–233. (<a
href="https://doi.org/10.1016/j.ins.2019.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work explores the challenges in identifying appropriate and significant parameter configurations in differential evolution (DE) under the influence of population diversity and dimension size. For most DE algorithms , the configuration of control parameters is a vital prerequisite for balancing exploration and exploitation within the confinement of a search space. This study investigates the implementation of various adaptive parameter setting configurations on benchmark functions via the proposal of an algorithmic scheme called self-adaptive ensemble-based DE (SAEDE). This algorithm uses self-adaptive and ensemble mechanisms to set the relevant parameters for each generation. SAEDE is compared with two other ensemble-based DEs, and their performance is evaluated using 34 benchmark functions consisting of 20 low dimensions and 14 high dimensions . Furthermore, the convergence of these DEs is tested by using Q -measure. Experimental results indicate that SAEDE achieves the highest frequency of maximum success rate in 28 out of the 34 benchmark functions. SAEDE also achieves the lowest Q -measure of 4237318. These findings show the competitiveness and efficiency of SAEDE in locating optimal solutions while avoiding exhaustive searches of suitable parameters by users in terms of achieving optimization while minimizing the dependency on user setting.},
  archive      = {J_ISCI},
  author       = {Shir Li Wang and Farid Morsidi and Theam Foo Ng and Haldi Budiman and Siew Chin Neoh},
  doi          = {10.1016/j.ins.2019.11.046},
  journal      = {Information Sciences},
  pages        = {203-233},
  shortjournal = {Inf. Sci.},
  title        = {Insights into the effects of control parameters and mutation strategy on self-adaptive ensemble-based differential evolution},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A many-objective particle swarm optimizer based on indicator
and direction vectors for many-objective optimization. <em>ISCI</em>,
<em>514</em>, 166–202. (<a
href="https://doi.org/10.1016/j.ins.2019.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing the convergence and diversity simultaneously is very challenging for traditional many-objective evolutionary algorithms on solving many objective optimization problems (MaOPs). A novel many-objective particle swarm optimization (PSO) algorithm based on the unary epsilon indicator and the direction vectors , termed as IDMOPSO, is proposed to robustly and effectively address MaOPs. The strategies of selecting personal best (pbest) and global best (gbest) take both the convergence and diversity into consideration. The selection of personal best is based on the unary epsilon indicator and the Pareto dominance to enhance the capability of local exploration. Apart from this, an external archive based on the unary epsilon indicator and the direction vectors is used to maintain the non-dominated solutions found during the search process. Extensive comparative experiments on DTLZ, DTLZ −1 , WFG, and WFG −1 problems with varied number of objectives show that IDMOPSO is effective and flexible in addressing MaOPs. The effectiveness of the proposed strategies is also analyzed in detail.},
  archive      = {J_ISCI},
  author       = {Jianping Luo and Xiongwen Huang and Yun Yang and Xia Li and Zhenkun Wang and Jiqiang Feng},
  doi          = {10.1016/j.ins.2019.11.047},
  journal      = {Information Sciences},
  pages        = {166-202},
  shortjournal = {Inf. Sci.},
  title        = {A many-objective particle swarm optimizer based on indicator and direction vectors for many-objective optimization},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining weighted subgraphs in a single large graph.
<em>ISCI</em>, <em>514</em>, 149–165. (<a
href="https://doi.org/10.1016/j.ins.2019.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted single large graphs are often used to simulate complex systems, and thus mining frequent subgraphs in a weighted large graph is an important issue that has attracted the attention of many researchers. Within the studies on the mining of frequent subgraphs, the Graph Mining (GraMi) algorithm is considered as a state-of-the-art algorithm. However, this algorithm can only be implemented on graph datasets which have node labels and edge labels, without weights, and this means that the importance of all objects in a large graph is the same. In this paper, we propose a frequent subgraph algorithm on a weighted large graph, called Weighted Graph Mining (WeGraMi), which is based on two effective strategies to mining weighted subgraphs. Firstly, we apply a new strategy to calculate the weight of all mined subgraphs, which is based on the weights of the nodes in that subgraph. Secondly, we apply a search space pruning strategy based on the existing weights; if a frequent subgraph cannot satisfy the given weighting threshold, that subgraph will be pruned, which can reduce the processing time and storage space needed. With both directed and undirected graph datasets, our experimental results show that the runtime as well as the memory requirements of our algorithm are significantly better than those of GraMi.},
  archive      = {J_ISCI},
  author       = {Ngoc-Thao Le and Bay Vo and Lam B.Q. Nguyen and Hamido Fujita and Bac Le},
  doi          = {10.1016/j.ins.2019.12.010},
  journal      = {Information Sciences},
  pages        = {149-165},
  shortjournal = {Inf. Sci.},
  title        = {Mining weighted subgraphs in a single large graph},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-rank nonnegative matrix factorization on stiefel
manifold. <em>ISCI</em>, <em>514</em>, 131–148. (<a
href="https://doi.org/10.1016/j.ins.2019.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low rank is an important but ill-posed problem in the development of nonnegative matrix factorization (NMF) algorithms because the essential information is often encoded in a low-rank intrinsic data matrix, whereas noise and outliers are contained in a residue matrix. Most existing NMF approaches achieve low rank by directly specifying the dimensions of the factor matrices . A few others impose the low rank constraint on the factor matrix and use the alternating direction method of multipliers to solve the optimization problem . In contrast to previous approaches, this paper proposes a novel method for low-rank nonnegative matrix factorization on a Stiefel manifold (LNMFS), which utilizes the low rank structure of intrinsic data and transforms it into a Frobenius norm of the latent factors . To obtain orthogonal factors as distinct patterns, we further impose orthogonality constraints by assuming that the basis matrix lies on a Stiefel manifold . In addition, to improve the robustness of the data in a manifold structure, we incorporate the graph smoothness of the coefficient matrix . Finally, we develop an efficient alternative iterative algorithm to solve the optimization problem and provide proof of its convergence. Extensive experiments on real-world datasets demonstrate the superiority of the proposed method compared with other representative NMF-based algorithms.},
  archive      = {J_ISCI},
  author       = {Ping He and Xiaohua Xu and Jie Ding and Baichuan Fan},
  doi          = {10.1016/j.ins.2019.12.004},
  journal      = {Information Sciences},
  pages        = {131-148},
  shortjournal = {Inf. Sci.},
  title        = {Low-rank nonnegative matrix factorization on stiefel manifold},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving data aggregation scheme for dynamic
groups in fog computing. <em>ISCI</em>, <em>514</em>, 118–130. (<a
href="https://doi.org/10.1016/j.ins.2019.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing has garnered significant attention in recent years, since it can bridge the cloud and terminal devices and provide low latency, location awareness, and geo-distribution at the edge of the network. Data aggregation is a prime candidate for fog computing applications. However, most previous works about data aggregation do not focus on the fog computing. In addition, existing secure data aggregation schemes in fog computing usually do not support dynamic groups and arbitrary aggregation functions. In this paper, we construct concrete data encryption , data aggregation and data decryption algorithms, and further propose a privacy-preserving and collusion-resistant data aggregation scheme for dynamic groups in fog computing. Specifically, in the proposed protocol, the cloud server can periodically collect raw data and compute arbitrary aggregation functions on them. Even if some malicious terminal devices collude with the fog device or the cloud server, the honest terminal devices’ privacy cannot be breached. The fog device can filter out false data and aggregate all terminal devices’ ciphertexts to save the bandwidth. Besides, dynamic join and exit of terminal devices is achieved. Detailed security analysis shows that our scheme holds k -source anonymity. Our scheme is also demonstrated to be efficient via extensive experiments.},
  archive      = {J_ISCI},
  author       = {Xiaodong Shen and Liehuang Zhu and Chang Xu and Kashif Sharif and Rongxing Lu},
  doi          = {10.1016/j.ins.2019.12.007},
  journal      = {Information Sciences},
  pages        = {118-130},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving data aggregation scheme for dynamic groups in fog computing},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aggregation of infinite chains of intuitionistic fuzzy sets
and their application to choices with temporal intuitionistic fuzzy
information. <em>ISCI</em>, <em>514</em>, 106–117. (<a
href="https://doi.org/10.1016/j.ins.2019.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the first method for aggregating infinite sequences of intuitionistic fuzzy sets in the literature. This new tool allows us to aggregate an infinite list of intuitionistic fuzzy sets over time –a particular case of temporal intuitionistic fuzzy sets – into a traditional intuitionistic fuzzy set. As an application, we define scores and accuracy degrees of temporal intuitionistic fuzzy elements. Then we use these tools to solve the decision making problem where data come in the form of intuitionistic fuzzy sets along an indefinitely long number of periods.},
  archive      = {J_ISCI},
  author       = {José Carlos R. Alcantud and Azadeh Zahedi Khameneh and Adem Kilicman},
  doi          = {10.1016/j.ins.2019.12.008},
  journal      = {Information Sciences},
  pages        = {106-117},
  shortjournal = {Inf. Sci.},
  title        = {Aggregation of infinite chains of intuitionistic fuzzy sets and their application to choices with temporal intuitionistic fuzzy information},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid query expansion using lexical resources and word
embeddings for sentence retrieval in question answering. <em>ISCI</em>,
<em>514</em>, 88–105. (<a
href="https://doi.org/10.1016/j.ins.2019.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Answering (QA) systems based on Information Retrieval return precise answers to natural language questions, extracting relevant sentences from document collections. However, questions and sentences cannot be aligned terminologically, generating errors in the sentence retrieval. In order to augment the effectiveness in retrieving relevant sentences from documents, this paper proposes a hybrid Query Expansion (QE) approach, based on lexical resources and word embeddings , for QA systems. In detail, synonyms and hypernyms of relevant terms occurring in the question are first extracted from MultiWordNet and, then, contextualized to the document collection used in the QA system. Finally, the resulting set is ranked and filtered on the basis of wording and sense of the question, by employing a semantic similarity metric built on the top of a Word2Vec model. This latter is locally trained on an extended corpus pertaining the same topic of the documents used in the QA system. This QE approach is implemented into an existing QA system and experimentally evaluated, with respect to different possible configurations and selected baselines, for the Italian language and in the Cultural Heritage domain, assessing its effectiveness in retrieving sentences containing proper answers to questions belonging to four different categories.},
  archive      = {J_ISCI},
  author       = {Massimo Esposito and Emanuele Damiano and Aniello Minutolo and Giuseppe De Pietro and Hamido Fujita},
  doi          = {10.1016/j.ins.2019.12.002},
  journal      = {Information Sciences},
  pages        = {88-105},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid query expansion using lexical resources and word embeddings for sentence retrieval in question answering},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Transfer learning for vehicle detection using two cameras
with different focal lengths. <em>ISCI</em>, <em>514</em>, 71–87. (<a
href="https://doi.org/10.1016/j.ins.2019.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a vehicle detection method using transfer learning for two cameras with different focal lengths. A detected vehicle region in an image of one camera is transformed into a binary map. After that, the map is used to filter convolutional neural network (CNN) feature maps which are computed for the other camera’s image. We also introduce a robust evolutionary algorithm that is used to compute the relationship between the two cameras in an off-line mode efficiently. We capture video sequences and sample them to make a dataset that includes images with different focal lengths for vehicle detection. We compare the proposed vehicle detection method with baseline detection methods, including faster region proposal networks (Faster-RCNN), single-shot-multi-Box detector (SSD), and detector using recurrent rolling convolution (RRC), in the same experimental context. The experimental results show that the proposed method can detect vehicles at a wide range of distances accurately and robustly, and significantly outperforms the baseline detection methods.},
  archive      = {J_ISCI},
  author       = {Vinh Quang Dinh and Farzeen Munir and Shoaib Azam and Kin-Choong Yow and Moongu Jeon},
  doi          = {10.1016/j.ins.2019.11.034},
  journal      = {Information Sciences},
  pages        = {71-87},
  shortjournal = {Inf. Sci.},
  title        = {Transfer learning for vehicle detection using two cameras with different focal lengths},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Removing moiré patterns from single images. <em>ISCI</em>,
<em>514</em>, 56–70. (<a
href="https://doi.org/10.1016/j.ins.2019.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interference between the grids of the camera sensor and the screen cause moiré patterns to always appear on photographs captured from a screen, significantly affecting people’s ability to review images. We propose a novel method to remove such a screen moiré pattern from a single image. We characterize the degraded image as a composition of two layers: the latent layer and the moiré pattern layer. Because the screen moiré pattern is global and content-independent, we regard it as a group of sublayers , and we find that each sublayer after the shear transformation has a low-rank property. Combined with the piecewise constant feature of the latent layer, a convex model is proposed to solve the demoiréing problem. Experiments on synthetic and real data demonstrate its feasibility and efficiency.},
  archive      = {J_ISCI},
  author       = {Faming Fang and Tingting Wang and Shuyan Wu and Guixu Zhang},
  doi          = {10.1016/j.ins.2019.12.001},
  journal      = {Information Sciences},
  pages        = {56-70},
  shortjournal = {Inf. Sci.},
  title        = {Removing moiré patterns from single images},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Hybrid adversarial network for unsupervised domain
adaptation. <em>ISCI</em>, <em>514</em>, 44–55. (<a
href="https://doi.org/10.1016/j.ins.2019.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances suggest that adversarial domain adaptation has been embedding into deep neural networks to learn domain-transferable representations, which reduces distribution divergence in both the training and test samples. However, previous adversarial learning algorithms only resort to learn domain-transferable feature representation by bounding the feature distribution discrepancy cross-domain. These approaches, however, may lead to misalignment and poor generalization results due to without further exploiting class information and task-special adaptation. To cope with this issue, a joint adversarial learning with class information and domain alignment deep network architecture , is proposed which is named Hybrid Adversarial Network (HAN). Specifically, it incorporates a classification loss to learn a discriminative classifier, and a domain adversarial network learns a domain-transferable representation to reduce domain shift. Meanwhile, a CORAL loss is used to minimize the discrepancy between the covariance matrices in the two domains. Additionally, we introduce an adaptation layer for further boosting the performance of HAN model. Comprehensive cross-domain visual recognition experiments validate that our method exceeds the state-of-the-art methods on three real-world benchmark including Office-31, Office-Home, and ImageCLEF-DA datasets.},
  archive      = {J_ISCI},
  author       = {Changchun Zhang and Qingjie Zhao and Yu Wang},
  doi          = {10.1016/j.ins.2019.12.005},
  journal      = {Information Sciences},
  pages        = {44-55},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid adversarial network for unsupervised domain adaptation},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual incremental fuzzy schemes for frequent itemsets
discovery in streaming numeric data. <em>ISCI</em>, <em>514</em>, 15–43.
(<a href="https://doi.org/10.1016/j.ins.2019.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering frequent itemsets is essential for finding association rules , yet too computational expensive using existing algorithms. It is even more challenging to find frequent itemsets upon streaming numeric data. The streaming characteristic leads to a challenge that streaming numeric data cannot be scanned repetitively. The numeric characteristic requires that streaming numeric data should be pre-processed into itemsets, e.g., fuzzy-set methods can transform numeric data into itemsets with non-integer membership values. This leads to a challenge that the frequency of itemsets are usually not integer. To overcome such challenges, fast methods and stream processing methods have been applied. However, the existing algorithms usually either still need to re-visit some previous data multiple times, or cannot count non-integer frequencies. Those existing algorithms re-visiting some previous data have to sacrifice large memory spaces to cache those previous data to avoid repetitive scanning. When dealing with big streaming data nowadays, such large-memory requirement often goes beyond the capacity of many computers. Those existing algorithms unable to count non-integer frequencies would be very inaccurate in estimating the non-integer frequencies of frequent itemsets if used with integer approximation of frequency-counting. To solve the aforementioned issues, in this paper we propose two incremental schemes for frequent itemsets discovery that are capable to work efficiently with streaming numeric data. In particular, they are able to count non-integer frequency without re-visiting any previous data. The key of our schemes to the benefits in efficiency is to extract essential statistics that would occupy much less memory than the raw data do for the ongoing streaming data. This grants the advantages of our schemes 1) allowing non-integer counting and thus natural integration with a fuzzy-set discretization method to boost robustness and anti-noise capability for numeric data, 2) enabling the design of a decay ratio for different data distributions, which can be adapted for three general stream models: landmark, damped and sliding windows, and 3) achieving highly-accurate fuzzy-item-sets discovery with efficient stream-processing. Experimental studies demonstrate the efficiency and effectiveness of our dual schemes with both synthetic and real-world datasets.},
  archive      = {J_ISCI},
  author       = {Hui Zheng and Peng Li and Qing Liu and Jinjun Chen and Guangli Huang and Junfeng Wu and Yun Xue and Jing He},
  doi          = {10.1016/j.ins.2019.11.023},
  journal      = {Information Sciences},
  pages        = {15-43},
  shortjournal = {Inf. Sci.},
  title        = {Dual incremental fuzzy schemes for frequent itemsets discovery in streaming numeric data},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-region dissipative dynamic output feedback control
for 2-d FM systems with missing measurements. <em>ISCI</em>,
<em>514</em>, 1–14. (<a
href="https://doi.org/10.1016/j.ins.2019.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the finite-region dissipative dynamic output feedback control problem for a class of discrete-time two-dimensional (2-D) Fornasini–Marchesini (FM) systems with missing measurements. Firstly, the definitions of finite-region boundedness (FRB) and finite-region ( T, S, R )-ϑ-dissipativity are introduced for 2-D FM systems. Secondly, sufficient conditions on the FRB and finite-region ( T, S, R )-ϑ-dissipativity of the resultant closed-loop 2-D systems are obtained by the construction of the Lyapunov function and the special recursive formulas . Thirdly, based on the decoupling technique, the desired dynamic output feedback controller design method for the considered 2-D systems is further provided. In the end, an example of the metal rolling process is given to show the effectiveness of the proposed design results.},
  archive      = {J_ISCI},
  author       = {Rongni Yang and Lingling Li and Xiaojie Su},
  doi          = {10.1016/j.ins.2019.11.044},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {Finite-region dissipative dynamic output feedback control for 2-D FM systems with missing measurements},
  volume       = {514},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimization for location-based and
preferences-aware recommendation. <em>ISCI</em>, <em>513</em>, 614–626.
(<a href="https://doi.org/10.1016/j.ins.2019.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location is of vital importance in recommender systems . This paper proposes a novel multi-objective framework for location-based and preference-aware recommendation. Under this framework, location-based recommendation is modeled as a multiobjective optimization problem and two contradictory objective functions are taken into consideration. One objective function aims to depict the performance of recommendation algorithm to recommend similar items. Another objective function reflects the ability of recommendation algorithm to recommend diverse items. It is a challenge to optimize these two contradictory objective functions simultaneously. In this paper, a novel multi-objective evolutionary algorithm is proposed to solve this modeled multiobjective optimization problem . The proposed algorithm can return a series of high-quality recommendation candidate solutions in one run and every solution is a trade-off between these two objective functions. The proposed algorithm is applied on two real recommendation scenarios: movie recommendation and music recommendation. Experimental results show that the proposed algorithm can produce recommendation solutions which are much better than those produced by existing algorithms in location-based recommendation and the proposed algorithm also has great performance in alleviating data sparsity and cold-start problems.},
  archive      = {J_ISCI},
  author       = {Shanfeng Wang and Maoguo Gong and Yue Wu and Mingyang Zhang},
  doi          = {10.1016/j.ins.2019.11.028},
  journal      = {Information Sciences},
  pages        = {614-626},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective optimization for location-based and preferences-aware recommendation},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Deep and broad URL feature mining for android malware
detection. <em>ISCI</em>, <em>513</em>, 600–613. (<a
href="https://doi.org/10.1016/j.ins.2019.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the scale and diversity of malicious software on mobile networks have grown significantly, thereby causing considerable danger to users’ property and personal privacy. In this study, we propose a malware detection method that uses the URLs visited by apps to identify malware. A multi-view neural network is used to create a malware detection model that emphasizes depth and width. This neural network can create multiple views of inputs automatically and distribute soft attention weights to focus on different features of inputs. Multiple views preserve rich semantic information from inputs for classification without requiring complicated feature engineering. In addition, we conduct comprehensive experiments to compare the proposed method with others and verify the validity of the detection model. The experimental results show that our method achieves robust and timely malware detection. It can not only effectively detect malware discovered in different months of a certain year, but also detect potentially malicious apps in the third-party app market. We also compare the detection results of the proposed method on wild apps with 10 popular anti-virus scanners, and the final result shows that our approach ranks second in terms of detection performance.},
  archive      = {J_ISCI},
  author       = {Shanshan Wang and Zhenxiang Chen and Qiben Yan and Ke Ji and Lizhi Peng and Bo Yang and Mauro Conti},
  doi          = {10.1016/j.ins.2019.11.008},
  journal      = {Information Sciences},
  pages        = {600-613},
  shortjournal = {Inf. Sci.},
  title        = {Deep and broad URL feature mining for android malware detection},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust principal component analysis: A factorization-based
approach with linear complexity. <em>ISCI</em>, <em>513</em>, 581–599.
(<a href="https://doi.org/10.1016/j.ins.2019.09.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rankness has been widely observed in real world data and there is often a need to recover low-rank matrices in many machine learning and data mining problems. Robust principal component analysis (RPCA) has been used for such problems by separating the data into a low-rank and a sparse part. The convex approach to RPCA has been well studied due to its elegant properties in theory and many extensions have been developed. However, the state-of-the-art algorithms for the convex approach and their extensions are usually expensive in complexity due to the need for solving singular value decomposition (SVD) of large matrices. In this paper, we propose a novel RPCA model based on matrix tri-factorization, which only needs the computation of SVDs for very small matrices. Thus, this approach reduces the complexity of RPCA to be linear and makes it fully scalable. It also overcomes the drawback of the state-of-the-art scalable approach such as AltProj, which requires the precise knowledge of the true rank of the low-rank component. As a result, our method is about 4 times faster than AltProj. Our method can be used as a light-weight, scalable tool for RPCA in the absence of the precise value of the true rank.},
  archive      = {J_ISCI},
  author       = {Chong Peng and Yongyong Chen and Zhao Kang and Chenglizhao Chen and Qiang Cheng},
  doi          = {10.1016/j.ins.2019.09.074},
  journal      = {Information Sciences},
  pages        = {581-599},
  shortjournal = {Inf. Sci.},
  title        = {Robust principal component analysis: A factorization-based approach with linear complexity},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive robust h∞ control for double support balance
systems. <em>ISCI</em>, <em>513</em>, 565–580. (<a
href="https://doi.org/10.1016/j.ins.2019.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive robust H ∞ control scheme is developed for controlling double support balance systems with uncertain parameters and external disturbances . A coordination transformation of the dual-cylinder electro-hydraulic motion model is used to help in designing the H ∞ controller, which aims to against external disturbances and parameter uncertainties from the linear part of the system. An updating law for the parameters of the adaptive controller is proposed to compensate some negative effects caused by the nonlinear parameter drift. It can be clearly observed from the simulation results that the proposed control scheme performs robustly with respect to both the external disturbances and the system parameter uncertainties.},
  archive      = {J_ISCI},
  author       = {Shujiang Li and Wei Wang},
  doi          = {10.1016/j.ins.2019.10.006},
  journal      = {Information Sciences},
  pages        = {565-580},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive robust h∞ control for double support balance systems},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smart fault-detection approach with feature production and
extraction processes. <em>ISCI</em>, <em>513</em>, 553–564. (<a
href="https://doi.org/10.1016/j.ins.2019.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a smart fault-detection approach with feature production and extraction procedures is developed for industrial ball bearing systems. By developing a set of chaotic-mapping systems composed of a main system and data-feeding system with appropriate parameters, the vibration signals of different fault states captured from ball bearings in the time domain can be mathematically mapped to the chaotic domain for feature production. Furthermore, through the designed feature extraction process, the relevant Euclidean feature values (EFVs) can be obtained for the classification of four different fault states. Three fault conditions at diameters of 7 mil, 14 mil, and 21 mil and a depth of 0.011 inches are illustrated for performance investigations. The experimental results show that the proposed smart detection approach is effective and feasible for identifying different fault states in real time.},
  archive      = {J_ISCI},
  author       = {Shih-Yu Li and Kai-Ren Gu},
  doi          = {10.1016/j.ins.2019.11.010},
  journal      = {Information Sciences},
  pages        = {553-564},
  shortjournal = {Inf. Sci.},
  title        = {A smart fault-detection approach with feature production and extraction processes},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NoteSum: An integrated note summarization system by using
text mining algorithms. <em>ISCI</em>, <em>513</em>, 536–552. (<a
href="https://doi.org/10.1016/j.ins.2019.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study implemented an integrated system of Note Summarization (NoteSum) that merged with multi-users’ notes and searched for relevant information on the Internet and, slides, and textbooks to create a summary for students to learn effectively. The integrated system&#39;s framework consists of four different modules: Topic Identification Module, Supporting Material Finding Module, Content Mapping Module and Learning Material Integrating Module. Five experiments were conducted; these resulted in the following findings. First, translating notes with the assistance of topic terms could enhance translation quality . Second, when mapping contents, NoteSum performed better in a discussion-based course rather than in a technical course. Third, the Jensen-Shannon (JS) Divergence was used to assess the generated summary that performed better for the discussion-based course. Fourth, the three attributes—presence of topic terms, number of non-topic words, and ratio of the words with important parts of speech—had different effects on different subjects. Finally, we compared NoteSum with other existing summarization systems. The results indicated that the NoteSum-generated summary was closer to students’ original notes and thus resulted in better performance in readability, informativeness, and completeness. All the results confirm that our proposed NoteSum is an effective note summarization system for student learning.},
  archive      = {J_ISCI},
  author       = {Hei-Chia Wang and Wei-Fan Chen and Chen-Yu Lin},
  doi          = {10.1016/j.ins.2019.11.011},
  journal      = {Information Sciences},
  pages        = {536-552},
  shortjournal = {Inf. Sci.},
  title        = {NoteSum: An integrated note summarization system by using text mining algorithms},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic incremental h∞ control for discrete-time switched
systems with disturbance dependent noise. <em>ISCI</em>, <em>513</em>,
519–535. (<a href="https://doi.org/10.1016/j.ins.2019.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the (reverse)mode-dependent average dwell time ((reverse)MDADT) scheme incorporated with multiple incremental Lyapunov functions are utilized to investigate the incremental H ∞ control for nonlinear discrete-time stochastic switched systems (SSS). The sufficient conditions in terms of (reverse)MDADT for the incremental H ∞ control are derived such that an incrementally globally asymptotically stable in the mean (IGASiM) system with a prescribed H ∞ disturbance attenuation level is obtained. It is shown that an incremental H ∞ control could be attained when all of the subsystems are non-IGASiM. Moreover, when the discrete-time SSS is composed of some IGASiM and non-IGASiM subsystems, a (reverse)MDADT based relationship between these two kinds of subsystems is established such that an IGASiM discrete-time SSS with incremental L 2 -gain property is obtained. Two numerical examples are presented to demonstrate the effectiveness of the results.},
  archive      = {J_ISCI},
  author       = {Yuanhong Ren and Weiqun Wang and Weisong Zhou and Mingxuan Shen},
  doi          = {10.1016/j.ins.2019.11.014},
  journal      = {Information Sciences},
  pages        = {519-535},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic incremental h∞ control for discrete-time switched systems with disturbance dependent noise},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-modal medical image segmentation based on
vector-valued active contour models. <em>ISCI</em>, <em>513</em>,
504–518. (<a href="https://doi.org/10.1016/j.ins.2019.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positron emission tomography (PET), magnetic resonance imaging (MRI) and computed tomography (CT) are widely utilized medical imaging modalities that provide essential anatomic and structural details. Many medical segmentation methods are not effective for a single-modal image of poor quality (e.g., low contrast in CT or low spatial resolution in PET). For practical radiotherapy treatment planning, multi-modal imaging information is regularly used. In this paper, a novel vector-valued active contour model is proposed to segment multi-modal medical images simultaneously for abnormal tissue regions. The method makes use of the functionality information and anatomical structure information advantages from each modality. Since each modality has its own signal characteristics, we use region-based information, combining hybrid mean intensities simultaneously. Furthermore, by utilizing a two-dimensional vector field with different image modalities, edge-based information is used to constrain the results of the image segmentation . The proposed approach is evaluated on datasets including lung PET-CT and brain MRI-CT images. Our qualitative and quantitative research results confirm the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Lingling Fang and Xin Wang and Lujie Wang},
  doi          = {10.1016/j.ins.2019.10.051},
  journal      = {Information Sciences},
  pages        = {504-518},
  shortjournal = {Inf. Sci.},
  title        = {Multi-modal medical image segmentation based on vector-valued active contour models},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An uncertainty-aware computational trust model considering
the co-existence of trust and distrust in social networks.
<em>ISCI</em>, <em>513</em>, 465–503. (<a
href="https://doi.org/10.1016/j.ins.2019.10.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are few trust models capable of incorporating the co-existence of trust and distrust as distinct concepts. In this regard, most of the existing trust models implicitly use distrust parameters to refine and calculate trust values . However, recent studies have indicated that trust and distrust are two distinct but co-existing concepts. In other words, although trust and distrust are constructed based on different characteristics, they can be used together in the decision making and recommendation processes. In this paper, we present a trust-distrust model for social networks considering subjective and objective characteristics of trust and distrust simultaneously. Competence, honesty, satisfaction, similarity, motivation, availability, tendency to be trusted, the existence of long-term connection/friendship, and centrality are the trustworthiness characteristics covered by the model. Also, surprisal, dishonesty, dissatisfaction, conflict degree, account lifetime, and sudden changes in the number of friends, likes, and comments are the distrust characteristics considered by the model. The proposed model takes into account the uncertainty, sharpness, and vagueness of the beliefs by using subjective logic. The results of the conducted evaluations demonstrate that the proposed model is highly accurate in the decision-making process and has a 90\% accuracy in calculating the trust and distrust. We have also compared the results with other similar approaches, by which the proposed model showed a 34\% improvement.},
  archive      = {J_ISCI},
  author       = {Nastaran Hakimi Aghdam and Mehrdad Ashtiani and Mohammad Abdollahi Azgomi},
  doi          = {10.1016/j.ins.2019.10.067},
  journal      = {Information Sciences},
  pages        = {465-503},
  shortjournal = {Inf. Sci.},
  title        = {An uncertainty-aware computational trust model considering the co-existence of trust and distrust in social networks},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantics-aware influence maximization in social networks.
<em>ISCI</em>, <em>513</em>, 442–464. (<a
href="https://doi.org/10.1016/j.ins.2019.10.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization ( IM ) plays an essential role in various social network applications. One such application is viral marketing to trigger a large cascade of product adoption from a small number of users by utilizing “Word-of-Mouth” effect in social networks. IM aims to return a set of users that can influence the largest fraction of a network, such as the early user who demonstrates the good features of a product in marketing. The traditional IM algorithms treat all users equally and ignore semantic context associated with the users, though it has been studied previously. To consider the semantics, we introduce a semantics-aware influence maximization ( SIM ) problem. The SIM problem integrates semantic information of users with influence maximization by measuring influence spread based on semantic values under a given model, and it aims to find a set of users that maximizes the influence spread, shown to be NP-hard. Generalized Reverse Influence Set based framework for SIM problems (GRIS-SIM) is used to solve SIM with different semantics, which provides a ( 1 − 1 / e − ε ) (1−1/e−ε) -approximation solution for each SIM instance. To our knowledge, the guarantee is state-of-the-art in the IM studies. GRIS-SIM enables auto-generation of sampling strategies for various social networks. In this study, we also present three sampling strategies that can be generated to achieve the best approximation guarantee, and one of the three is proved to be the optimal strategy by having the same performance guarantee within the optimal time. Furthermore, in order to show the generality and effectiveness of the proposed GRIS technique, we apply it into solving other IM problems (e.g., the distance-aware influence maximization, DAIM ). Extensive experiments on both real-life and synthetic datasets demonstrate the effectiveness, efficiency, and scalability of our methods. The results on large real data show that GRIS-SIM is able to achieve 58\% improvement on average in expected influence compared with rivals, and the method adopting GRIS can achieve 65\% improvement on average.},
  archive      = {J_ISCI},
  author       = {Yipeng Chen and Qiang Qu and Yuanxiang Ying and Hongyan Li and Jialie Shen},
  doi          = {10.1016/j.ins.2019.10.075},
  journal      = {Information Sciences},
  pages        = {442-464},
  shortjournal = {Inf. Sci.},
  title        = {Semantics-aware influence maximization in social networks},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data imbalance in classification: Experimental evaluation.
<em>ISCI</em>, <em>513</em>, 429–441. (<a
href="https://doi.org/10.1016/j.ins.2019.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of Big Data has ushered a new era of scientific breakthroughs. One of the common issues that affects raw data is class imbalance problem which refers to imbalanced distribution of values of the response variable. This issue is present in fraud detection, network intrusion detection , medical diagnostics, and a number of other fields where negatively labeled instances significantly outnumber positively labeled instances. Modern machine learning techniques struggle to deal with imbalanced data by focusing on minimizing the error rate for the majority class while ignoring the minority class. The goal of our paper is demonstrate the effects of class imbalance on classification models . Concretely, we study the impact of varying class imbalance ratios on classifier accuracy. By highlighting the precise nature of the relationship between the degree of class imbalance and the corresponding effects on classifier performance we hope to help researchers to better tackle the problem. To this end, we carry out extensive experiments using 10-fold cross validation on a large number of datasets. In particular, we determine that the relationship between the class imbalance ratio and the accuracy is convex.},
  archive      = {J_ISCI},
  author       = {Fadi Thabtah and Suhel Hammoud and Firuz Kamalov and Amanda Gonsalves},
  doi          = {10.1016/j.ins.2019.11.004},
  journal      = {Information Sciences},
  pages        = {429-441},
  shortjournal = {Inf. Sci.},
  title        = {Data imbalance in classification: Experimental evaluation},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying landmarks to enhance memory-based collaborative
filtering. <em>ISCI</em>, <em>513</em>, 412–428. (<a
href="https://doi.org/10.1016/j.ins.2019.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory-based Collaborative Filtering (CF) has been a widely used approach for personalised recommendation with considerable success in many applications. An important issue regarding memory-based CF lies in similarity computation: the sparsity of the rating matrix leads to similarity computations based on few co-rated items between users, resulting in high sensitive predictions. Additionally, the ‘sparse’ similarity computation has high computational cost, due to the dimensionality of the item space. In this paper, we pursue both these issues. We propose a new model to compute similarity by representing users (or items) through their distances to preselected users, named landmarks. Such user modelling allows the introduction of more ratings into similarity computations through transitive relations created by the landmarks. Unlike conventional memory-based CF, the proposal builds a new user space defined by distances to landmarks, avoiding sensitivity in similarity computations. Findings from our experiments show that the proposed modelling achieves better accuracy than the ‘sparse’ similarity representation in all tested datasets, and has also yielded competitive accuracy results against the compared model-based CF algorithms . Furthermore, the proposed implementation has beaten all compared methods in terms of computational performance, becoming a promising alternative to memory-based CF algorithms for large datasets.},
  archive      = {J_ISCI},
  author       = {Gustavo R. Lima and Carlos E. Mello and Adria Lyra and Geraldo Zimbrao},
  doi          = {10.1016/j.ins.2019.10.041},
  journal      = {Information Sciences},
  pages        = {412-428},
  shortjournal = {Inf. Sci.},
  title        = {Applying landmarks to enhance memory-based collaborative filtering},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The data richness estimation framework for federated data
warehouse integration. <em>ISCI</em>, <em>513</em>, 397–411. (<a
href="https://doi.org/10.1016/j.ins.2019.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A federated data warehouse is a tool that provides an end-user a unified perspective on a finite set of independent data warehouses. This requires creating a global schema from partial schemas, which remains purely virtual. This is a result of iterative integration of participating data warehouses. It is then used to simulate that the aforementioned set of participating warehouses as an effectively one, “super” data warehouse exposed to the end-user. In this paper, authors present a framework, that can be used to evaluate the profitability of adding a new data warehouse to the existing federation, in terms of increased data richness and its expressiveness. Solid formal foundations are provided, along with heuristic algorithms , an experimental verification (which involved two different experimental procedures) and a statistical analysis of obtained results.},
  archive      = {J_ISCI},
  author       = {Rafał Kern and Adrianna Kozierkiewicz and Marcin Pietranik},
  doi          = {10.1016/j.ins.2019.10.046},
  journal      = {Information Sciences},
  pages        = {397-411},
  shortjournal = {Inf. Sci.},
  title        = {The data richness estimation framework for federated data warehouse integration},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid deep learning model for efficient intrusion
detection in big data environment. <em>ISCI</em>, <em>513</em>, 386–396.
(<a href="https://doi.org/10.1016/j.ins.2019.10.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The volume of network and Internet traffic is expanding daily, with data being created at the zettabyte to petabyte scale at an exceptionally high rate. These can be characterized as big data, because they are large in volume, variety, velocity, and veracity. Security threats to networks, the Internet, websites, and organizations are growing alongside this growth in usage. Detecting intrusions in such a big data environment is difficult. Various intrusion-detection systems (IDSs) using artificial intelligence or machine learning have been proposed for different types of network attacks, but most of these systems either cannot recognize unknown attacks or cannot respond to such attacks in real time. Deep learning models, recently applied to large-scale big data analysis , have shown remarkable performance in general but have not been examined for detection of intrusions in a big data environment . This paper proposes a hybrid deep learning model to efficiently detect network intrusions based on a convolutional neural network (CNN) and a weight-dropped, long short-term memory (WDLSTM) network. We use the deep CNN to extract meaningful features from IDS big data and WDLSTM to retain long-term dependencies among extracted features to prevent overfitting on recurrent connections. The proposed hybrid method was compared with traditional approaches in terms of performance on a publicly available dataset, demonstrating its satisfactory performance.},
  archive      = {J_ISCI},
  author       = {Mohammad Mehedi Hassan and Abdu Gumaei and Ahmed Alsanad and Majed Alrubaian and Giancarlo Fortino},
  doi          = {10.1016/j.ins.2019.10.069},
  journal      = {Information Sciences},
  pages        = {386-396},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid deep learning model for efficient intrusion detection in big data environment},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A spatiotemporal attention mechanism-based model for
multi-step citywide passenger demand prediction. <em>ISCI</em>,
<em>513</em>, 372–385. (<a
href="https://doi.org/10.1016/j.ins.2019.10.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In taxi dispatch systems, predicting citywide passenger pickup/dropoff demand is indispensable for developing effective taxi distribution and scheduling strategies to resolve the demand-service mismatch. Compared with predicting next-step only, predicting multiple steps is preferable since it can provide a long term view, thus preventing short-sighted strategies. However, multi-step citywide passenger demand prediction (MsCPDP) is challenging due to the complicated spatiotemporal correlations in the distribution of passenger demand and the lack of ground truth from pre-steps for the prediction of subsequent steps. In this paper, a deep-learning-based prediction model with spatiotemporal attention mechanism is proposed for MsCPDP. The model, called ST-Attn, follows the general encoder-decoder framework for modelling sequential data but adopts a multiple-output strategy without recurrent neural network units. The spatiotemporal attention mechanism learns to determine the focus on those parts of the city at certain periods that are more relevant to the passenger demand in the predicted region and time period. In addition, a pre-predicted result calculated by spatiotemporal kernel density estimation is fed to ST-Attn, which provides a reference for further accurate prediction. Experiments on three real-world datasets are carried out to verify ST-Attn’s performance, and the results show that ST-Attn outperforms the baselines in terms of MsCPDP.},
  archive      = {J_ISCI},
  author       = {Yirong Zhou and Jun Li and Hao Chen and Ye Wu and Jiangjiang Wu and Luo Chen},
  doi          = {10.1016/j.ins.2019.10.071},
  journal      = {Information Sciences},
  pages        = {372-385},
  shortjournal = {Inf. Sci.},
  title        = {A spatiotemporal attention mechanism-based model for multi-step citywide passenger demand prediction},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Block change learning for knowledge distillation.
<em>ISCI</em>, <em>513</em>, 360–371. (<a
href="https://doi.org/10.1016/j.ins.2019.10.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks perform well but require high-performance hardware for their use in real-world environments. Knowledge distillation is a simple method for improving the performance of a small network by using the knowledge of a large complex network. Small and large networks are referred to as student and teacher models, respectively. Previous knowledge distillation approaches perform well in a relatively small teacher network (20–30 layers) but poorly in large teacher networks (50 layers). Here, we propose an approach called block change learning that performs local and global knowledge distillation by changing blocks comprised of layers. The method focuses on the knowledge transfer without losing information in a large teacher model, as the approach considers intra-relationships between layers using local knowledge distillation and inter-relationships between corresponding blocks. The results are demonstrated this approach as superior to state-of-the-art methods using feature extraction datasets (Market1501 and DukeMTMC-relD) and object classification datasets (CIFAR-100 and Caltech256). Furthermore, we showed that the performance of the proposed approach was superior to that of a fine-tuning approach using pretrained models.},
  archive      = {J_ISCI},
  author       = {Hyunguk Choi and Younkwan Lee and Kin Choong Yow and Moongu Jeon},
  doi          = {10.1016/j.ins.2019.10.074},
  journal      = {Information Sciences},
  pages        = {360-371},
  shortjournal = {Inf. Sci.},
  title        = {Block change learning for knowledge distillation},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Virtual linguistic trust degree-based evidential reasoning
approach and its application to emergency response assessment of railway
station. <em>ISCI</em>, <em>513</em>, 341–359. (<a
href="https://doi.org/10.1016/j.ins.2019.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real life, the assessment information is usually expressed by virtual linguistic terms , but the trust degrees of different assessment values to the same reference grade are usually ignored. In addition, the provided information is usually incomplete or uncertain, because the objective things’ characteristics are elusive and the decision maker&#39;s knowledge is limited. To solve such problems, in this paper, we first propose the virtual linguistic trust degree. Then, in view of the nonlinear changes of the decision maker&#39;s psychological states, we depict the virtual linguistic trust degree by a nonlinear function , and present some relevant aggregation operators. In order to avoid the loss of information, we propose a novel evidential reasoning approach that combines the virtual linguistic trust degree with basic unit-interval monotonic function . In this approach, the normalized basic probability mass can be obtained by the continuous basic unit-interval monotonic function , which satisfies the consensus axiom of original evidential reasoning. Meanwhile, we propose the normalized factor on the basis of the rule that the remaining unassigned probability mass is assigned into any subsets, and then present the whole framework of an extended evidential reasoning algorithm . Furthermore, a numerical example about the emergency response assessment of railway station is conducted to show the usage of the algorithm. Finally, the validity of this algorithm is demonstrated by the comparative analysis.},
  archive      = {J_ISCI},
  author       = {Jianmei Ye and Zeshui Xu and Xunjie Gou},
  doi          = {10.1016/j.ins.2019.11.001},
  journal      = {Information Sciences},
  pages        = {341-359},
  shortjournal = {Inf. Sci.},
  title        = {Virtual linguistic trust degree-based evidential reasoning approach and its application to emergency response assessment of railway station},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient temporal core maintenance of massive graphs.
<em>ISCI</em>, <em>513</em>, 324–340. (<a
href="https://doi.org/10.1016/j.ins.2019.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k − k− core is a cohesive subgraph such that every vertex has at least k neighbors within the subgraph, which provides a good measure to evaluate the importance of vertices as well as their connections. Unfortunately, k − k− core cannot adequately reveal the structure of a temporal graph , in which two vertices may connect multiple edges containing time information. As a result, ( k , h ) − (k,h)− core is derived from k − k− core, which is also called temporal core, to provide a well-formulated definition, where h represents the number of temporal edges between two vertices. However, it is costly to repeatedly decompose a temporal graph changing over time.To address this challenge, we study the method of ( k , h ) − (k,h)− core maintenance, which can find current ( k , h ) − (k,h)− cores with less computational efforts. To estimate the influence scope of inserted (removed) edges, we propose quasi-temporal core, denoted by quasi − ( k , h ) − −(k,h)− core, which relaxes the constraint of ( k , h ) − (k,h)− core but still has similar properties to ( k , h ) − (k,h)− core. With the aid of quasi − ( k , h ) − −(k,h)− core, our insertion algorithm finds the minimum incremental graph for each influenced ( k , h ) − (k,h)− core, and the removal algorithm adjusts each influenced ( k , h ) − (k,h)− core in the minimal range. Experimental results verify effectiveness and scalability of our proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Wen Bai and Yadi Chen and Di Wu},
  doi          = {10.1016/j.ins.2019.11.003},
  journal      = {Information Sciences},
  pages        = {324-340},
  shortjournal = {Inf. Sci.},
  title        = {Efficient temporal core maintenance of massive graphs},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient variable interdependency-identification and
decomposition by minimizing redundant computations for large-scale
global optimization. <em>ISCI</em>, <em>513</em>, 289–323. (<a
href="https://doi.org/10.1016/j.ins.2019.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many variable decomposition methods for cooperative co-evolution (CC) have been proposed, researches on scalable and efficient decomposition have rarely been done, particularly, for the large-scale global optimization (LSGO) problems. In this paper, we propose an efficient variable interdependency identification and decomposition method, called EVIID. Different from existing studies focusing on only limited scale efficient or accurate variable decomposition, our purpose is to develop a scalable variable decomposition method with high efficiency and accuracy even on very high-dimensional problems. EVIID utilizes three core strategies: a binary variable space search, a dynamic perturbation caching, and a pre-variable sorting. Their synergy effect enables scalable and efficient variable decomposition without sacrificing decomposition accuracy by pruning many redundant computations required to identify interdependencies among decision variables. In comprehensive experiments, EVIID showed highly scalable decomposition ability on 1000 to 10,000 dimensional benchmark problems compared against the state-of-the-art variable decomposition methods . Moreover, when EVIID was embedded into practical CC frameworks, it showed good optimization performance and also fast convergence.},
  archive      = {J_ISCI},
  author       = {Kyung Soo Kim and Yong Suk Choi},
  doi          = {10.1016/j.ins.2019.10.049},
  journal      = {Information Sciences},
  pages        = {289-323},
  shortjournal = {Inf. Sci.},
  title        = {An efficient variable interdependency-identification and decomposition by minimizing redundant computations for large-scale global optimization},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed nonlinear kalman filter with communication
protocol. <em>ISCI</em>, <em>513</em>, 270–288. (<a
href="https://doi.org/10.1016/j.ins.2019.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an optimal design of the general distributed nonlinear Kalman-based filtering algorithm to tackle the discrete-time estimation problem with noisy communication networks. The algorithm extends the Kalman filter by enabling it to predict the noisy communication data and fuse it with the received neighboring information to produce a posterior estimate value. In the prediction step, the unscented transformations of the estimate values and covariances originated in the Unscented Kalman Filter (UKF) are exploited. In the update step, a communication protocol is appended to the posterior estimator, which consequently leads to a modified posterior error covariance containing the covariance of the communication term with its communication gain. Both Kalman and communication gains are then optimised to collectively minimise the mean-squared estimation error. Afterwards, stochastic stability analysis is performed to guarantee its exponential boundedness . To exemplify the performance, this algorithm is applied to a group of robots in a sensor network assigned to estimate an unknown information distribution over an area in the optimal coverage control problem. Comparative numerical experiments finally verify the effectiveness of our design.},
  archive      = {J_ISCI},
  author       = {Hilton Tnunay and Zhenhong Li and Zhengtao Ding},
  doi          = {10.1016/j.ins.2019.10.053},
  journal      = {Information Sciences},
  pages        = {270-288},
  shortjournal = {Inf. Sci.},
  title        = {Distributed nonlinear kalman filter with communication protocol},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CAOM: A community-based approach to tackle opinion
maximization for social networks. <em>ISCI</em>, <em>513</em>, 252–269.
(<a href="https://doi.org/10.1016/j.ins.2019.10.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion Maximization Problem (OMP) targets at selecting a subset of influential initial nodes and eventually generating the maximum opinion spread. The current OMP methods mainly pay attention to the improvement of efficient algorithms, which hardly obtain high efficiency and stable accuracy in large-scale social networks. In this paper, we study the OMP with the community-based approach. To be specific, we first formulate the OMP and construct the weight-based opinion model to estimate the dynamic change of opinion value. In particular, to generate the influential individuals, we propose a Community-based Approach for the OMP (CAOM), including: community detection, selection of candidate nodes and generation of seed nodes. Then, to reduce the computational complexity effectively and distribute seed nodes into the reasonable communities, the significant communities are devised. Based on the one-hop measure and the potential nodes of each community, the candidate nodes are selected. For each community, we acquire the influence score based on its neighbors within community and beyond community. Finally, we develop the two-hop measure and Elimination of Overlapping Influence (EOI) to determine seed nodes from candidate nodes. Experimental results in ten social networks demonstrate that CAOM can accelerate the opinion spread with smaller running time compared with the baselines.},
  archive      = {J_ISCI},
  author       = {Qiang He and Xingwei Wang and Fubing Mao and Jianhui Lv and Yuliang Cai and Min Huang and Qingzheng Xu},
  doi          = {10.1016/j.ins.2019.10.064},
  journal      = {Information Sciences},
  pages        = {252-269},
  shortjournal = {Inf. Sci.},
  title        = {CAOM: A community-based approach to tackle opinion maximization for social networks},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Dispatched attention with multi-task learning for nested
mention recognition. <em>ISCI</em>, <em>513</em>, 241–251. (<a
href="https://doi.org/10.1016/j.ins.2019.10.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity mentions usually contain other mention in the task of named entity recognition (NER). Nested entities pose challenge to the task of NER. Existing methods fail to sufficiently capture the boundaries information between nested entities, which limits the performance of the task. In this paper, we propose a dispatched attention neural model with multi-task learning for the task. In particular, given an input sentence, a bi-directional Long Short Term Memory (BiLSTM) encodes it as common contextualized hidden representation. Then position and syntax information are leveraged into attention network for capturing mention span features. The attention representation of each task is dispatched to subsequent task to exchange boundaries information for nested mentions. Finally, Conditional Random Fields (CRFs) are used to extract nested mentions in an inside-out order for each task. Results on ACE2005 and GENIA datasets show that the proposed model outperforms state-of-the-art systems, showing its effectiveness in detecting nested mentions.},
  archive      = {J_ISCI},
  author       = {Hao Fei and Yafeng Ren and Donghong Ji},
  doi          = {10.1016/j.ins.2019.10.065},
  journal      = {Information Sciences},
  pages        = {241-251},
  shortjournal = {Inf. Sci.},
  title        = {Dispatched attention with multi-task learning for nested mention recognition},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ProUM: Projection-based utility mining on sequence data.
<em>ISCI</em>, <em>513</em>, 222–240. (<a
href="https://doi.org/10.1016/j.ins.2019.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility is an important concept in Economics. A variety of applications consider utility in real-life situations, which has lead to the emergence of utility-oriented mining (also called utility mining) in the recent decade. Utility mining has attracted a great amount of attention, but most of the existing studies have been developed to deal with itemset-based data. Time-ordered sequence data is more commonly seen in real-world situations, which is different from itemset-based data. Since they are time-consuming and require large amount of memory usage, current utility mining algorithms still have limitations when dealing with sequence data. In addition, the mining efficiency of utility mining on sequence data still needs to be improved, especially for long sequences or when there is a low minimum utility threshold. In this paper, we propose an efficient Pro jection-based U tility M ining (ProUM) approach to discover high-utility sequential patterns from sequence data. The utility-array structure is designed to store the necessary information of the sequence-order and utility. ProUM can significantly improve the mining efficiency by utilizing the projection technique in generating utility-array, and it effectively reduces the memory consumption. Furthermore, a new upper bound named sequence extension utility is proposed and several pruning strategies are further applied to improve the efficiency of ProUM. By taking utility theory into account, the derived high-utility sequential patterns have more insightful and interesting information than other kinds of patterns. Experimental results showed that the proposed ProUM algorithm significantly outperformed the state-of-the-art algorithms in terms of execution time, memory usage, and scalability.},
  archive      = {J_ISCI},
  author       = {Wensheng Gan and Jerry Chun-Wei Lin and Jiexiong Zhang and Han-Chieh Chao and Hamido Fujita and Philip S. Yu},
  doi          = {10.1016/j.ins.2019.10.033},
  journal      = {Information Sciences},
  pages        = {222-240},
  shortjournal = {Inf. Sci.},
  title        = {ProUM: Projection-based utility mining on sequence data},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of an interval type-2 fuzzy model with justifiable
uncertainty. <em>ISCI</em>, <em>513</em>, 206–221. (<a
href="https://doi.org/10.1016/j.ins.2019.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout previous design proposals of Interval Type-2 Fuzzy Logic Systems most of the research work concentrates on optimal design to best fit data behavior and rarely focus on the inner model essence of Type-2 Fuzzy Systems, which is uncertainty . In this way, failing to focus on this key aspect, which is how much uncertainty exists within the model to better represent the data. In this paper a design methodology for a Mamdani based Interval Type-2 Fuzzy Logic System (MAM-IT2FLS) with Center-Of-Sets defuzzification is presented, using descriptive statistics and granular computing theory to better define the limits of uncertainty within the Interval Type-2 Membership Functions (IT2MF) as extracted from available data. This allows us to justify the uncertainty within the entire Type-2 Fuzzy Logic model, as well as to create the fuzzy model using FCM grouping and to compute IT2MF parameters from MAM-IT2FLS rules using simple steps. This is unlike hybrid learning models with Back-Propagation that adjust IT2MF parameters with gradient based numeric optimization algorithms which are time efficient but unstable for convergence, and evolutionary computation with robust convergence and slow learning time. Experimentation is carried out with six regression benchmark datasets, measuring RMSE and R 2 in order to evaluate the performance of the proposed methodology whilst maintaining justifiable uncertainty in its model.},
  archive      = {J_ISCI},
  author       = {Juan E. Moreno and Mauricio A. Sanchez and Olivia Mendoza and Antonio Rodríguez-Díaz and Oscar Castillo and Patricia Melin and Juan R. Castro},
  doi          = {10.1016/j.ins.2019.10.042},
  journal      = {Information Sciences},
  pages        = {206-221},
  shortjournal = {Inf. Sci.},
  title        = {Design of an interval type-2 fuzzy model with justifiable uncertainty},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust subspace clustering based on non-convex low-rank
approximation and adaptive kernel. <em>ISCI</em>, <em>513</em>, 190–205.
(<a href="https://doi.org/10.1016/j.ins.2019.10.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a relatively advanced method, the low-rank kernel space clustering method shows good performance in dealing with nonlinear structure of high-dimensional data. Unfortunately, this method is sensitive to large corruptions and doesn’t balance the contribution of all singular values . To solve the above problems, the low-rank kernel method is modified, and a robust subspace clustering method (LAKRSC) based on non-convex low-rank approximation and adaptive kernel is proposed. In our model, the weighted Schatten p -norm is introduced to balance the importance of different singular values , which can more accurately approximate the rank function and be more flexible in practical applications. Therefore, applying weighted Schatten p -norm to adaptive kernel can approximate the original low rank hypothesis better when the data is mapped into the feature space. In addition, our model uses correntropy to handle complex noise which enhances the robustness of the model. A new algorithm HQ&amp;ADMM, combined by Half-Quadratic technique (HQ) and ADMM, is studied to solve our model. Experiments on four real-world datasets show that the clustering performance of LAKRSC is significantly better than that of several more advanced methods.},
  archive      = {J_ISCI},
  author       = {Xuqian Xue and Xiaoqian Zhang and Xinghua Feng and Huaijiang Sun and Wei Chen and Zhigui Liu},
  doi          = {10.1016/j.ins.2019.10.058},
  journal      = {Information Sciences},
  pages        = {190-205},
  shortjournal = {Inf. Sci.},
  title        = {Robust subspace clustering based on non-convex low-rank approximation and adaptive kernel},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ternary reversible number-conserving cellular automata are
trivial. <em>ISCI</em>, <em>513</em>, 180–189. (<a
href="https://doi.org/10.1016/j.ins.2019.10.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel method to study the reversibility of d -dimensional number-conserving multi-state cellular automata with the von Neumann neighborhood. We apply this method to ternary such cellular automata , for which, up to now, nothing was known about their reversibility . It turns out that they are all trivial: the only reversible such cellular automata are shifts that are intrinsically 1-dimensional.},
  archive      = {J_ISCI},
  author       = {Barbara Wolnik and Bernard De Baets},
  doi          = {10.1016/j.ins.2019.10.068},
  journal      = {Information Sciences},
  pages        = {180-189},
  shortjournal = {Inf. Sci.},
  title        = {Ternary reversible number-conserving cellular automata are trivial},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). H∞ leader-following consensus of nonlinear multi-agent
systems under semi-markovian switching topologies with partially unknown
transition rates. <em>ISCI</em>, <em>513</em>, 168–179. (<a
href="https://doi.org/10.1016/j.ins.2019.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the H ∞ leader-following consensus problem for nonlinear multi-agent systems under semi-Markovian switching topologies . The switching of the topologies is governed by a semi-Markovian jump process, which covers a Markovian jump process as a special case. In many practical systems, it is difficult to obtain the transition rate matrix , thus the transition rates are considered to be not completely known in the paper. External perturbations are considered in the paper, and H ∞ control theory is applied. By utilising stochastic technique, sufficient conditions expressed in terms of linear matrix inequalities are derived to ensure that the H ∞ leader-following consensus can be reached with a prescribed performance index. Finally, a numerical example is given to show the effectiveness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Minhong He and Jingru Mu and Xiaowu Mu},
  doi          = {10.1016/j.ins.2019.11.002},
  journal      = {Information Sciences},
  pages        = {168-179},
  shortjournal = {Inf. Sci.},
  title        = {H∞ leader-following consensus of nonlinear multi-agent systems under semi-markovian switching topologies with partially unknown transition rates},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary many-objective assembly of cloud services via
angle and adversarial direction driven search. <em>ISCI</em>,
<em>513</em>, 143–167. (<a
href="https://doi.org/10.1016/j.ins.2019.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud service composition (CSC) is an effective way to carry out large-scale complicated applications by the ensemble of existing individual services. Each service typically involves several Quality of Service (QoS) criteria contracted for non-functional aspects like time or price, among others, which greatly influence the overall performance of the resulting applications. Service composition approaches have emerged as an important technique in leveraging the quality of composite service efficiently and have attracted significant attention. However, most existing proposals ignore the many-objective nature of CSC and consider up to three objectives, the optimization of diverse QoS aspects of CSC from a many-objective perspective (at least four) still lacks. On another aspect, due to the rapid growth of nondominated solutions in high-dimensional objective spaces, the traditional multi-objective optimization algorithms are usually not capable of handling problems possessing many objectives. To address the above issue, we develop an angle and adversarial direction based optimizer for many-objective CSC scenarios, which evolves a number of subpopulations with adversarial search directions in a parallel paradigm. Additionally, vector angle based selection criterion, which adaptively captures beacon individuals, is utilized to diversify the population. Extensive experiments are carried out on a series of CSC instances utilizing synthetic datasets and the results show that our proposition is competitive and has better versatility compared with the state-of-the-art.},
  archive      = {J_ISCI},
  author       = {Jiajun Zhou and Liang Gao and Xifan Yao and Chunjiang Zhang and Felix T.S. Chan and Yingzi Lin},
  doi          = {10.1016/j.ins.2019.10.054},
  journal      = {Information Sciences},
  pages        = {143-167},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary many-objective assembly of cloud services via angle and adversarial direction driven search},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community detection based on modularity and k-plexes.
<em>ISCI</em>, <em>513</em>, 127–142. (<a
href="https://doi.org/10.1016/j.ins.2019.10.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community identification is of great worth for analyzing the structure or characteristics of a complex network. Many community detection methods have been developed, such as modularity-based optimization models, which are widely used but significantly restricted in “resolution limit”. In this paper, we propose a novel algorithm, called modularity optimization with k -plexes (MOKP), to solve this problem, and this algorithm can identify communities smaller than a scale. The proposed algorithm uses k -plexes to generate community seeds from the whole network and assigns the remaining nodes by modularity optimization. To save computational time, we further propose the improved MOKP algorithm (IMOKP) by reducing the scale of the network before community seeds generation and adjusting rules of nodes assignment. Extensive experimental results demonstrate our proposed algorithms perform better than several state-of-the-art algorithms in terms of accuracy of detected communities on various networks, and can effectively detect small communities in terms of a newly defined index, namely small community level, on multiple networks as well.},
  archive      = {J_ISCI},
  author       = {Jinrong Zhu and Bilian Chen and Yifeng Zeng},
  doi          = {10.1016/j.ins.2019.10.076},
  journal      = {Information Sciences},
  pages        = {127-142},
  shortjournal = {Inf. Sci.},
  title        = {Community detection based on modularity and k-plexes},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image representation of pose-transition feature for 3D
skeleton-based action recognition. <em>ISCI</em>, <em>513</em>, 112–126.
(<a href="https://doi.org/10.1016/j.ins.2019.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, skeleton-based human action recognition has received more interest from industrial and research communities for many practical applications thanks to the popularity of depth sensors. A large number of conventional approaches, which have exploited handcrafted features with traditional classifiers, cannot learn high-level spatiotemporal features to precisely recognize complex human actions. In this paper, we introduce a novel encoding technique, namely Pose-Transition Feature to Image (PoT2I), to transform skeleton information to image-based representation for deep convolutional neural networks (CNNs). The spatial joint correlations and temporal pose dynamics of an action are exhaustively depicted by an encoded color image . For learning action models, we fine-tune end-to-end a pre-trained network to thoroughly capture multiple high-level features at multi-scale action representation. The proposed method is benchmarked on several challenging 3D action recognition datasets (e.g., UTKinect-Action3D, SBU-Kinect Interaction, and NTU RGB+D) with different parameter configurations for performance analysis. Outstanding experimental results with the highest accuracy of 90.33\% on the most challenging NTU RGB+D dataset demonstrate that our action recognition method with PoT2I outperforms state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Thien Huynh-The and Cam-Hao Hua and Trung-Thanh Ngo and Dong-Seong Kim},
  doi          = {10.1016/j.ins.2019.10.047},
  journal      = {Information Sciences},
  pages        = {112-126},
  shortjournal = {Inf. Sci.},
  title        = {Image representation of pose-transition feature for 3D skeleton-based action recognition},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A service recommendation algorithm with the transfer
learning based matrix factorization to improve cloud security.
<em>ISCI</em>, <em>513</em>, 98–111. (<a
href="https://doi.org/10.1016/j.ins.2019.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system (RS) is designed to provide personalized services based on the users’ historical data. It has been applied in various fields and is expected to recommend the suitable services for the different kinds of users. Considering the importance of individual privacy, current users gradually tend not to expose personal information. This means RS may face the highly sparse datasets in the fields of cloud security . In general, the accuracy of recommendation will be improved with the growth of individual data, but the cold start problem is exactly in this contradictory phenomenon: this question evolves to produce sufficiently accurate recommendation result under the data scarcity problem. RS has to recommend services for the rarely historical data users and the latent users might drain along with the production of counter effects. To alleviate data scarcity problem in cloud security environment, this work is to introduce similar domain knowledge based on the transfer learning . Besides, the content and location based methods have been proved that these ideas work under this situation. So, this work also employs latent dirichlet allocation (LDA) to analysis the service descriptions and explore the relationship between the content and location information. In this framework, the suitable combination of LDA and word2vec models will balance the accuracy and speed which benefit service recommendation particularly. The related experiments demonstrate the effectiveness on the real word dataset. It can be found that the transfer learning based word2vec model shows the potentiality to explore the relationship between topic words, and improve the LDA algorithm from the content relationship. This proves that in both cold start environment and warm start environment, the proposed algorithm is more robust than other model-based state-of-art methods.},
  archive      = {J_ISCI},
  author       = {Chao Lei and Hongjun Dai and Zhilou Yu and Rui Li},
  doi          = {10.1016/j.ins.2019.10.004},
  journal      = {Information Sciences},
  pages        = {98-111},
  shortjournal = {Inf. Sci.},
  title        = {A service recommendation algorithm with the transfer learning based matrix factorization to improve cloud security},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mildip: An energy efficient code offloading framework in
mobile cloudlets. <em>ISCI</em>, <em>513</em>, 84–97. (<a
href="https://doi.org/10.1016/j.ins.2019.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The explosive growth of connected mobile devices in Edge of Things (EoT) computing offers an opportunity to support high-quality life in smart cities but also results in an extremely high energy consumption in battery limited mobile devices . Accordingly, to increase the battery life or improve performance of mobile devices, code offloading has been proposed. Moreover, with the development of the technology about low-latency and low-power of device-to-device communication, offloading codes to surrounding mobile devices in nearby cloudlets has been widely applied. However, the existing works on the mobile cloudlets mostly focus on code distribution and scheduling but ignores the affection of the energy efficiency of CPU. According to the CPU Energy/Frequency Convexity Rule, there is an optimal clock frequency that can minimize energy consumption. In recent years, a novel processor architectures with adjustable frequency have been proposed to deliver various kinds of energy efficiency and CPU performance. Taking the processor frequency into consideration, we propose an energy-efficient code offloading framework as MilDip to offload partitioned heavy tasks to around mobile devices and to operate these tasks in the state of low CPU performance and high energy efficiency. We formulate offloading problem as a mixed-integer nonlinear optimization problem , with the goal of energy efficiency maximization. Based on the formulation, we further propose a heuristic algorithm COFS based on CPU frequency scaling. Extensive simulated experiments are provided to evaluate the performance of our method. The simulation results show that up to 77\% of energy can be saved by using COFS compared to the local execution. Moreover, when enough devices surround the terminal, COFS energy consumption tends to stabilize. From the experiments, we can also conclude that COFS can save more about 20\% ~ 50\% energy consumption comparing to other schemes.},
  archive      = {J_ISCI},
  author       = {Feng Lu and Lin Gu and Laurence Tianruo Yang and Liwen Shao and Hai Jin},
  doi          = {10.1016/j.ins.2019.10.008},
  journal      = {Information Sciences},
  pages        = {84-97},
  shortjournal = {Inf. Sci.},
  title        = {Mildip: An energy efficient code offloading framework in mobile cloudlets},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven software defined network attack detection:
State-of-the-art and perspectives. <em>ISCI</em>, <em>513</em>, 65–83.
(<a href="https://doi.org/10.1016/j.ins.2019.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SDN (Software Defined Network) has emerged as a revolutionary technology in network, a substantial amount of researches have been dedicated to security of SDNs to support their various applications. The paper firstly analyzes State-of-the-Art of SDN security from data perspectives. Then some typical network attack detection (NAD) methods are surveyed, including machine learning based methods and statistical methods. After that, a novel tensor based network attack detection method named tensor principal component analysis (TPCA) is proposed to detect attacks. After surveying the last data-driven SDN frameworks, a tensor based big data-driven SDN attack detection framework is proposed for SDN security. In the end, a case study is illustrated to verify the effectiveness of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Puming Wang and Laurence T. Yang and Xin Nie and Zhian Ren and Jintao Li and Liwei Kuang},
  doi          = {10.1016/j.ins.2019.08.047},
  journal      = {Information Sciences},
  pages        = {65-83},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven software defined network attack detection: State-of-the-art and perspectives},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). (fI,ω)-implications and distributivity of implications on l
over t-representable t-norms: The case of strict and nilpotent t-norms.
<em>ISCI</em>, <em>513</em>, 30–64. (<a
href="https://doi.org/10.1016/j.ins.2019.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new class of intuitionistic fuzzy implications (IFIs) known as ( f I , ω ) (fI,ω) -implications is introduced which is a generalized form of Yager’s f-implications in intuitionistic fuzzy environment (IFE). The basic properties of these implications are discussed in detail. It is shown that ( f I , ω ) (fI,ω) -implications are not only the generalizations of Yager’s f-implications, but also the generalizations of R R -, ( S , N ) (S,N) - and Q L QL -implications in IFE. The distributivity equations I I ( T ( u , v ) , w ) = S ( I I ( u , w ) , I I ( v , w ) ) II(T(u,v),w)=S(II(u,w),II(v,w)) and I I ( u , T 1 ( v , w ) ) = T 2 ( I I ( u , v ) , I I ( u , w ) ) II(u,T1(v,w))=T2(II(u,v),II(u,w)) over t-representable t-norms and t-conorms generated from nilpotent and strict t-norms in IF set theory are discussed. Also, we solve the open problems concerning characterize all of the correct solutions of the distributive equation I I ( u , T 1 ( v , w ) ) = T 2 ( I I ( u , v ) , I I ( u , w ) ) II(u,T1(v,w))=T2(II(u,v),II(u,w)) when t-norms are strict and nilpotent .},
  archive      = {J_ISCI},
  author       = {Vishnu Singh and Shiv Prasad Yadav},
  doi          = {10.1016/j.ins.2019.11.051},
  journal      = {Information Sciences},
  pages        = {30-64},
  shortjournal = {Inf. Sci.},
  title        = {(fI,ω)-implications and distributivity of implications on l over t-representable t-norms: The case of strict and nilpotent t-norms},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3DACN: 3D augmented convolutional network for time series
data. <em>ISCI</em>, <em>513</em>, 17–29. (<a
href="https://doi.org/10.1016/j.ins.2019.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data and non-time series data are increasing in the credit system of financial market, so that an effective and intelligent data mining model plays a critical role to analyze hybrid time series data. In addition, traditional mining models sometimes fail to converge because of imbalanced data problem. Therefore, we propose a 3D Augmented Convolutional Network (3DACN) to extract time series information and solve the serious imbalanced data problem. By using the augmented algorithm on time series data, hybrid time series data are enlarged to generate more examples on the minority classes. 3DACN ensures the latent variables with an Expectation-Maximization(EM) algorithm to improve F1 score (F1) and Area Under Curve (AUC). Experimental results show that in the benchmark of Bank database, it can gain F1 score by 81.1\% and the AUC by 88.2\% respectively; while in the benchmark of Credit Risk database, the 3DACN can reach high performance on F1 score by 88.1\% and the AUC by 88.4\%.},
  archive      = {J_ISCI},
  author       = {Songwen Pei and Tianma Shen and Xianrong Wang and Chunhua Gu and Zhong Ning and Xiaochun Ye and Naixue Xiong},
  doi          = {10.1016/j.ins.2019.11.040},
  journal      = {Information Sciences},
  pages        = {17-29},
  shortjournal = {Inf. Sci.},
  title        = {3DACN: 3D augmented convolutional network for time series data},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Position-aware hierarchical transfer model for aspect-level
sentiment classification. <em>ISCI</em>, <em>513</em>, 1–16. (<a
href="https://doi.org/10.1016/j.ins.2019.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, attention-based neural networks (NNs) have been widely used for aspect-level sentiment classification (ASC). Most neural models focus on incorporating the aspect representation into attention, however, the position information of each aspect is not studied well. Furthermore, the existing ASC datasets are relatively small owing to the labor-intensive labeling that largely limits the performance of NNs. In this paper, we propose a position-aware hierarchical transfer (PAHT) model that models the position information from multiple levels and enhances the ASC performance by transferring hierarchical knowledge from the resource-rich sentence-level sentiment classification (SSC) dataset. We first present aspect-based positional attention in the word and the segment levels to capture more salient information toward a given aspect. To make up for the limited data for ASC, we devise three sampling strategies to select related instances from the large-scale SSC dataset for pre-training and transfer the learned knowledge into ASC from four levels: embedding, word, segment and classifier. Extensive experiments on four benchmark datasets demonstrate that the proposed model is effective in improving the performance of ASC. Particularly, our model outperforms the state-of-the-art approaches in terms of accuracy over all the datasets considered.},
  archive      = {J_ISCI},
  author       = {Jie Zhou and Qin Chen and Jimmy Xiangji Huang and Qinmin Vivian Hu and Liang He},
  doi          = {10.1016/j.ins.2019.11.048},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {Position-aware hierarchical transfer model for aspect-level sentiment classification},
  volume       = {513},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resilient and secure remote monitoring for a class of
cyber-physical systems against attacks. <em>ISCI</em>, <em>512</em>,
1592–1605. (<a href="https://doi.org/10.1016/j.ins.2019.10.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the resilient and secure remote monitoring of a cyber-physical system of a discrete time-varying state-space form against attacks. The specific statistical characteristic, magnitude, occurring place and time of the attack signals are not required during the monitor design and attack detection procedures. First, an optimal ellipsoidal state prediction and estimation method is delicately developed in such a way that the recursively computed prediction ellipsoid and estimate ellipsoid can both guarantee the containment of the true system state at each time step regardless of the unknown but bounded input signal. It is expected that the two ellipsoids can resist certain attacks as the calculated state prediction and state estimate are sets in state-space rather than single pointwise vectors, thus potentially enhancing the resilience of the remote monitoring system. Second, a set-based evaluation mechanism in combination with a remedy measure are proposed to provide timely detection of certain attacks. Furthermore, a numerically efficient algorithm is established to achieve resilience and attack detection of the remote monitoring system. Finally, it is shown through several case studies on a water supply distribution system that the proposed methods can provide quantitative analysis and evaluation of the potential consequences of various attacks on the remote monitoring system.},
  archive      = {J_ISCI},
  author       = {Xiaohua Ge and Qing-Long Han and Xian-Ming Zhang and Derui Ding and Fuwen Yang},
  doi          = {10.1016/j.ins.2019.10.057},
  journal      = {Information Sciences},
  pages        = {1592-1605},
  shortjournal = {Inf. Sci.},
  title        = {Resilient and secure remote monitoring for a class of cyber-physical systems against attacks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new algorithm for positive influence maximization in
signed networks. <em>ISCI</em>, <em>512</em>, 1571–1591. (<a
href="https://doi.org/10.1016/j.ins.2019.10.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of online social networks, the problem of influence maximization (IM) has attracted much attention from researchers and has been applied in many areas such as marketing and finance. Since positive and negative relations may exist between individuals in social networks, the problem of influence maximization in signed networks has a wide range of applications. This paper presents an efficient algorithm for positive influence maximization in signed networks in the independent cascade model. First, we propose an independent path-based algorithm to compute the activation probabilities between the node pairs. Based on the activation probability , we define a propagation increment function to avoid simulating the influence spreading for selecting candidate seed nodes. We present an algorithm to select the seed nodes to obtain the largest positive influence spreading in the signed network. Empirical results in social networks show that our algorithm can have wider positive influence spreading than other methods.},
  archive      = {J_ISCI},
  author       = {Weijia Ju and Ling Chen and Bin Li and Wei Liu and Jun Sheng and Yuwei Wang},
  doi          = {10.1016/j.ins.2019.10.061},
  journal      = {Information Sciences},
  pages        = {1571-1591},
  shortjournal = {Inf. Sci.},
  title        = {A new algorithm for positive influence maximization in signed networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multifactorial optimization via explicit multipopulation
evolutionary framework. <em>ISCI</em>, <em>512</em>, 1555–1570. (<a
href="https://doi.org/10.1016/j.ins.2019.10.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multifactorial Optimization (MFO) has attracted considerable attention in the community of evolutionary computation, which aims to deal with multiple optimization tasks simultaneously by information transfer. Unfortunately, information transfer may cause both positive and negative effects. To address this issue, this paper exploits an explicit multipopulation evolutionary framework (MPEF) to intelligently take advantage of positive information transfer and effectively reduce negative information transfer. In MPEF, each task possesses an independent population and has its random mating probability for exploiting the information of other tasks. Moreover, the random mating probability of each task is adjusted adaptively. The benefits of using MPEF are twofold. 1) Various well-developed search engines can be easily embedded into MPEF for solving the single task of multifactorial optimization problems . 2) The positive information transfer can be exploited. Meanwhile, negative information transfer can be prevented. A multifactorial evolutionary algorithm (named MFMP) is realized as an instance by embedding a well-designed search engine into MPEF. The experimental results on some MFO benchmark problems demonstrate the advantage of MFMP over some state-of-the-art algorithms. Moreover, MFMP is also successfully employed to solve the spread spectrum radar polyphase code design (SSRPCD) problem.},
  archive      = {J_ISCI},
  author       = {Genghui Li and Qiuzhen Lin and Weifeng Gao},
  doi          = {10.1016/j.ins.2019.10.066},
  journal      = {Information Sciences},
  pages        = {1555-1570},
  shortjournal = {Inf. Sci.},
  title        = {Multifactorial optimization via explicit multipopulation evolutionary framework},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel equal division values based on players’ excess vectors
and their applications to logistics enterprise coalitions.
<em>ISCI</em>, <em>512</em>, 1543–1554. (<a
href="https://doi.org/10.1016/j.ins.2019.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some sub-coalitions can not be formed or fail to satisfy the superadditivity in many realistic cooperative transferable utility (TU) games, which particularly exists in the logistics service industry. To exploit some novel solutions for addressing these TU games, we firstly propose again the equal surplus division value based on the least square method and players’ common excess vector, and then introduce the weighted equal surplus division value. Both of them belong to the family of the least square values. Inspired by the fact that many TU games base the profit distribution strategies not only on the egalitarian principle but also on the utility principle, the equal contribution division value and the weighted equal contribution division value based on the least square method and players’ contribution excess vector are spontaneously generated. An algorithm is described to make the four solutions proposed in this paper satisfy the property of individual rationality . Finally, to show the advantages, the practicability and the rationality of the four solutions, a practical example about the profit distribution strategy of a logistics enterprise coalition is illustrated and the contrastive analysis among them is given.},
  archive      = {J_ISCI},
  author       = {Jia-Cai Liu and Wen-Jian Zhao and Benjamin Lev and Deng-Feng Li and Jiuh-Biing Sheu and Yong-Wu Dai},
  doi          = {10.1016/j.ins.2019.09.019},
  journal      = {Information Sciences},
  pages        = {1543-1554},
  shortjournal = {Inf. Sci.},
  title        = {Novel equal division values based on players’ excess vectors and their applications to logistics enterprise coalitions},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A time-varying mirrored s-shaped transfer function for
binary particle swarm optimization. <em>ISCI</em>, <em>512</em>,
1503–1542. (<a href="https://doi.org/10.1016/j.ins.2019.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary Particle swarm optimization (BPSO) is one of the most popular swarm intelligence algorithms to solve binary optimization problems. It has a few parameters, simple structure, and high execution speed. A transfer function is applied in BPSO to convert the continuous search space to the binary one. This algorithm and its variants can sometimes find local optima or exhibit slow convergence speed. Thus, many researchers have improved the structure of BPSO and its transfer function to overcome these shortcomings. In this study, a new time-varying mirrored S-shaped transfer function for BPSO (TVMS-BPSO) is introduced to enhance global exploration and local exploitation in the algorithm. The performance of the proposed transfer function has been compared with some well-known BPSO algorithms and binary meta-heuristic algorithms. These algorithms have been evaluated by CEC 2005 benchmark functions and set of 0–1 multidimensional knapsack problem (MKP) benchmark instances. The experimental results showed that the new transfer function significantly enhances the efficiency of BPSO for both local and global topologies in terms of solution accuracy and convergence speed.},
  archive      = {J_ISCI},
  author       = {Zahra Beheshti},
  doi          = {10.1016/j.ins.2019.10.029},
  journal      = {Information Sciences},
  pages        = {1503-1542},
  shortjournal = {Inf. Sci.},
  title        = {A time-varying mirrored S-shaped transfer function for binary particle swarm optimization},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A heterogeneous QUALIFLEX method with criteria interaction
for multi-criteria group decision making. <em>ISCI</em>, <em>512</em>,
1481–1502. (<a href="https://doi.org/10.1016/j.ins.2019.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Green supplier selection complexity involves such problems which usually need to offer the management of dependencies among criteria in the selection process. Meanwhile, heterogeneous contexts are adopted based on different criteria, which drives to propose a novel multi-criteria group decision making (MCGDM) method. To solve this problem, this paper proposes a new MCGDM approach for heterogeneous information and dependent criteria based on the QUALItative FLEXible (QUALIFLEX) method and Choquet integral. For managing dependency among criteria, a new graphical representation of criteria interaction is presented and the identification of fuzzy measure is then obtained considering group consensus reaching. The multi-criteria heterogeneous QUALIFLEX method with regard to dependency of criteria is finally applied to a green supplier selection problem and a comparative analysis is performed to illustrate its feasibility and effectiveness.},
  archive      = {J_ISCI},
  author       = {Liang Yingying and Qin Jindong and Luis Martínez and Liu Jun},
  doi          = {10.1016/j.ins.2019.10.044},
  journal      = {Information Sciences},
  pages        = {1481-1502},
  shortjournal = {Inf. Sci.},
  title        = {A heterogeneous QUALIFLEX method with criteria interaction for multi-criteria group decision making},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing rumor influence in multiplex online social
networks based on human individual and social behaviors. <em>ISCI</em>,
<em>512</em>, 1458–1480. (<a
href="https://doi.org/10.1016/j.ins.2019.10.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing popularity of online social networks , an environment has been set up that can spread rumors in a faster and wider manner than ever before, which can have widespread repercussions on society. Nowadays, individuals are joining multiple online social networks and rumors simultaneously propagating amongst them, thereby creating a new dimension to the problem of rumor propagation. Motivated by these facts, this paper attempts to address the rumor influence minimization in multiplex online social networks. In this work, we consider modeling the propagation process of such fictitious information as a significant step toward minimizing its influence. Thus, we analyze the individual and social behaviors in social networks; subsequently, we propose a novel rumor diffusion model , named the HISBmodel. In this model, we propose a formulation of an individual behavior towards a rumor analog to damped harmonic motion . Following this, the opinions of individuals in the propagation process are incorporated. Furthermore, the rules of rumor transmission between individuals in multiplex networks are incorporated by considering individual and social behaviors. Further, we present the HISBmodel propagation process that describes the spread of rumors in multiplex online social networks. Based on this model, we propose a truth campaign strategy in minimizing the influence of rumors in multiplex online social networks from the perspective of network inference and by exploiting the survival theory. This strategy selects the most influential nodes as soon as the rumor is detected and launches a truth campaign to raise awareness against it, so as to prevent the influence of rumors. Accordingly, we propose a greedy algorithm based on the likelihood principle, which guarantees an approximation within 63\% of the optimal solution. Systematically, experiments have been conducted on real single networks crawled from Twitter, Facebook, and Slashdot as well as on multiplex networks of real online social networks (Facebook, Twitter, and YouTube). First, the results indicate the HISBmodel can reproduce all the trends of real-world rumor propagation more realistically than the models presented in the literature. Moreover, the simulations illustrate that the proposed model highlights the impact of human factors accurately in accordance with the literature. Second, compared to the methods in the literature, the experiments prove the efficiency of our strategy in minimizing the influence of rumors in the cases of single network and multiplex social network propagation . The results prove that the proposed method can capture the dynamic propagation process of the rumor and select the target nodes more accurately in order to minimize the influence of rumors.},
  archive      = {J_ISCI},
  author       = {Adil Imad Eddine Hosni and Kan Li Professor and Sadique Ahmad},
  doi          = {10.1016/j.ins.2019.10.063},
  journal      = {Information Sciences},
  pages        = {1458-1480},
  shortjournal = {Inf. Sci.},
  title        = {Minimizing rumor influence in multiplex online social networks based on human individual and social behaviors},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GraPASA: Parametric graph embedding via siamese
architecture. <em>ISCI</em>, <em>512</em>, 1442–1457. (<a
href="https://doi.org/10.1016/j.ins.2019.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph representation learning or graph embedding is a classical topic in data mining . Current embedding methods are mostly non-parametric, where all the embedding points are unconstrained free points in the target space. These approaches suffer from limited scalability and an over-flexible representation. In this paper, we propose a parametric graph embedding by fusing graph topology information and node content information. The embedding points are obtained through a highly flexible non-linear transformation from node content features to the target space. This transformation is learned using the contrastive loss function of the siamese network to preserve node adjacency in the input graph. On several benchmark network datasets, the proposed GraPASA method shows a significant margin over state-of-the-art techniques on benchmark graph representation tasks.},
  archive      = {J_ISCI},
  author       = {Yujun Chen and Ke Sun and Juhua Pu and Zhang Xiong and Xiangliang Zhang},
  doi          = {10.1016/j.ins.2019.10.027},
  journal      = {Information Sciences},
  pages        = {1442-1457},
  shortjournal = {Inf. Sci.},
  title        = {GraPASA: Parametric graph embedding via siamese architecture},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Sparse unmixing of hyperspectral data with bandwise model.
<em>ISCI</em>, <em>512</em>, 1424–1441. (<a
href="https://doi.org/10.1016/j.ins.2019.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse unmixing has long been a hot research topic in the area of hyperspectral image (HSI) analysis. Most of the traditional sparse unmixing methods usually assume to only take the Gaussian noise into consideration. However, there are also other types of noise in real HSI, i.e. , impulse noise, stripes, dead lines and so on. In addition, the intensity of Gaussian noise is usually different for each band of real HSI. To this end, we propose a novel sparse unmixing method with the bandwise model (SUBM) to address the above mentioned problems simultaneously. Besides, the alternative direction method of multipliers (ADMM) is adopted for solving the proposed SUBM. Moreover, we conduct extensive experiments on synthetic and real datasets to demonstrate effectiveness of the proposed sparse unmixing method under the bandwise model.},
  archive      = {J_ISCI},
  author       = {Chang Li and Yu Liu and Juan Cheng and Rencheng Song and Jiayi Ma and Chenhong Sui and Xun Chen},
  doi          = {10.1016/j.ins.2019.10.036},
  journal      = {Information Sciences},
  pages        = {1424-1441},
  shortjournal = {Inf. Sci.},
  title        = {Sparse unmixing of hyperspectral data with bandwise model},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental route inference from low-sampling GPS data: An
opportunistic approach to online map matching. <em>ISCI</em>,
<em>512</em>, 1407–1423. (<a
href="https://doi.org/10.1016/j.ins.2019.10.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the surging of smart device sensing and mobile networking , GPS data has been widely available for identifying vehicle position and route on the road map. For many real-time applications, such as traffic sensing and route recommendation, it is critical to immediately infer travelling route with incoming GPS data. In this paper, an opportunistic approach to online map matching is proposed to incrementally infer routes from low-sampling GPS data with low output latency. Unlike the hidden Markov model (HMM)-based approach, which often experiences certain delay between the GPS observation and inference, our algorithm can produce immediate inference when a new GPS point becomes available. Furthermore, a rollback mechanism is provided to correct the already inferred route when some abnormal situations are detected during the opportunistic inference process. We evaluate the proposed algorithm using real dataset of GPS trajectories over 100 cities around the world. Experimental results show that our algorithm is better than, or at least comparable to the state-of-the-art algorithms in terms of inference accuracy. More importantly, our algorithm can yield much shorter output latency and require less execution time, which is critical for many real-time navigation applications and location-based services.},
  archive      = {J_ISCI},
  author       = {Linbo Luo and Xiangting Hou and Wentong Cai and Bin Guo},
  doi          = {10.1016/j.ins.2019.10.060},
  journal      = {Information Sciences},
  pages        = {1407-1423},
  shortjournal = {Inf. Sci.},
  title        = {Incremental route inference from low-sampling GPS data: An opportunistic approach to online map matching},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning heterogeneous traffic patterns for travel time
prediction of bus journeys. <em>ISCI</em>, <em>512</em>, 1394–1406. (<a
href="https://doi.org/10.1016/j.ins.2019.10.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of travel time prediction of bus journeys which consist of bus riding times (may involve multiple bus services) and also the waiting times at transfer points. We propose a novel method called Traffic Pattern centric Segment Coalescing Framework (TP-SCF) that relies on learned disparate patterns of traffic conditions across different bus line segments for bus journey travel time prediction. Specifically, the proposed method consists of a training and a prediction stage. In the training stage, the bus lines are partitioned into bus line segments and the common travel time patterns of segments from different bus lines are explored using Non-negative Matrix Factorization (NMF). Bus line segments with similar patterns are classified into the same cluster. The clusters are then coalesced in order to extract data records for model training and bus journey time prediction. A separate Long Short Term Memory (LSTM) based model is trained for each cluster to predict the bus travel time under various traffic conditions. During prediction, a given bus journey is partitioned into the riding time components and waiting time components. The riding time components are predicted using the corresponding LSTM models of the clusters while the waiting time components are estimated based on historical bus arrival time records. We evaluated our method on large scale real-world bus travel data involving 30 bus services, and the results show that the proposed method notably outperforms the state-of-the-art approaches for all the scenarios considered.},
  archive      = {J_ISCI},
  author       = {Peilan He and Guiyuan Jiang and Siew-Kei Lam and Yidan Sun},
  doi          = {10.1016/j.ins.2019.10.073},
  journal      = {Information Sciences},
  pages        = {1394-1406},
  shortjournal = {Inf. Sci.},
  title        = {Learning heterogeneous traffic patterns for travel time prediction of bus journeys},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpretable multiclass classification by MDL-based rule
lists. <em>ISCI</em>, <em>512</em>, 1372–1393. (<a
href="https://doi.org/10.1016/j.ins.2019.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretable classifiers have recently witnessed an increase in attention from the data mining community because they are inherently easier to understand and explain than their more complex counterparts. Examples of interpretable classification models include decision trees , rule sets, and rule lists. Learning such models often involves optimizing hyperparameters, which typically requires substantial amounts of data and may result in relatively large models. In this paper, we consider the problem of learning compact yet accurate probabilistic rule lists for multiclass classification . Specifically, we propose a novel formalization based on probabilistic rule lists and the minimum description length (MDL) principle. This results in virtually parameter-free model selection that naturally allows to trade-off model complexity with goodness of fit , by which overfitting and the need for hyperparameter tuning are effectively avoided. Finally, we introduce the Classy algorithm, which greedily finds rule lists according to the proposed criterion. We empirically demonstrate that Classy selects small probabilistic rule lists that outperform state-of-the-art classifiers when it comes to the combination of predictive performance and interpretability . We show that Classy is insensitive to its only parameter, i.e., the candidate set, and that compression on the training set correlates with classification performance, validating our MDL-based selection criterion.},
  archive      = {J_ISCI},
  author       = {Hugo M. Proença and Matthijs van Leeuwen},
  doi          = {10.1016/j.ins.2019.10.050},
  journal      = {Information Sciences},
  pages        = {1372-1393},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable multiclass classification by MDL-based rule lists},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectral based hypothesis testing for community detection in
complex networks. <em>ISCI</em>, <em>512</em>, 1360–1371. (<a
href="https://doi.org/10.1016/j.ins.2019.10.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network analysis is one of the most important branches in modern science, it has brought great advances which help us better understanding complex systems. Recently, detecting community structure within networks has played a more and more critical role in network analysis, due to the fact that it has many crucial applications in a wide range of disciplines, such as sociology, biology, computer science, and other disciplines which can be represented as graphs, hence the problem of detecting communities in networks has attracted a lot of attention from researchers in different areas. However, most of existing algorithms and approaches are built on an assumption that the number of communities in a network is prior known, whereas in many cases, we do not know too much information about this vital quantity. In this work, by fitting networks with stochastic block model, we put forward a novel hypothesis testing framework which can automatically determine the number of communities in various networks. By combining our hypothesis testing method with a motif based clustering approach , we design a recursive bipartitioning algorithm which can fast detect community structure in simulated networks, as well as various real networks.},
  archive      = {J_ISCI},
  author       = {Zhishan Dong and Shuangshuang Wang and Qun Liu},
  doi          = {10.1016/j.ins.2019.10.056},
  journal      = {Information Sciences},
  pages        = {1360-1371},
  shortjournal = {Inf. Sci.},
  title        = {Spectral based hypothesis testing for community detection in complex networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive lagrangian relaxation-based algorithm for a
coordinated water supply and wastewater collection network design
problem. <em>ISCI</em>, <em>512</em>, 1335–1359. (<a
href="https://doi.org/10.1016/j.ins.2019.10.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last century has seen an increased prevalence and duration of droughts as well as the water shortage especially in Middle East countries like Iran. This urgent situation in Iran such as Urmia Lake in the west Azerbaijan province is a motivation for us to model a new coordinated water supply and wastewater collection network design problem . Due to the uncertainty, as one of inherent sections of the water supply chain, a two-stage stochastic programming approach is used to formulate the problem. To solve the proposed model, a Lagrangian relaxation-based algorithm formulated by a new adaptive strategy is employed. This algorithm considers both upper and lower bounds of the problem to reach a performance solution. The proposed algorithm is compared with two similar algorithms from the literature to reveal its performance. As such, the efficiency of the proposed model is evaluated by some sensitivity analyses. Finally, a comprehensive discussion is provided to show the main findings and practical insights of this research.},
  archive      = {J_ISCI},
  author       = {Amir Mohammad Fathollahi-Fard and Mostafa Hajiaghaei-Keshteli and Guangdong Tian and Zhiwu Li},
  doi          = {10.1016/j.ins.2019.10.062},
  journal      = {Information Sciences},
  pages        = {1335-1359},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive lagrangian relaxation-based algorithm for a coordinated water supply and wastewater collection network design problem},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recursive algorithm to increase the speed of
regression-based binary recommendation systems. <em>ISCI</em>,
<em>512</em>, 1324–1334. (<a
href="https://doi.org/10.1016/j.ins.2019.10.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel method is proposed to solve the Regression-based Binary Recommendation problem (RBR). The RBR is a univariate minimization problem , which has been solved recently using the Trichotomy approach with a logarithmic time complexity. The Trichotomy can obtain the global optimal minimum of univariate quasi-convex function. In this paper, it has been asserted that the objective function of the RBR problem is not necessarily quasi-convex; therefore, the Trichotomy method cannot always find its optimal solution that can be ultimately achieved by using the full search. Nonetheless, the difficulty of the full search method is that for each possible value of the variable of the problem, the objective function of the problem must be computed which involves the user-item tables to be reviewed entirely for each possible value of the variable. Since these tables are usually large, the runtime of the full search method is very high. In this paper, to unravel this difficulty, we made use of a recursive method to compute the objective function. Our proposed algorithm requires only one review of the user-item tables. Hence, the runtime of our proposed method is far less than the two other methods.},
  archive      = {J_ISCI},
  author       = {Mahla Mohammadzadeh Khadem and Yahya Forghani},
  doi          = {10.1016/j.ins.2019.10.072},
  journal      = {Information Sciences},
  pages        = {1324-1334},
  shortjournal = {Inf. Sci.},
  title        = {A recursive algorithm to increase the speed of regression-based binary recommendation systems},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust visual tracking based on variational auto-encoding
markov chain monte carlo. <em>ISCI</em>, <em>512</em>, 1308–1323. (<a
href="https://doi.org/10.1016/j.ins.2019.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a novel visual tracker based on the variational auto-encoding Markov chain Monte Carlo (VAE-MCMC) method. A target is tracked over time with the help of multiple geometrically related supporters whose motions correlate with those of the target. Good supporters are obtained using variational auto-encoding techniques that measure the confidence of supporters in terms of marginal probabilities . These probabilities are then used in the MCMC method to search for the best state of the target. We extend the VAE-MCMC method to a variational mixture of posteriors (VampPrior)-MCMC and hierarchical VampPrior-MCMC methods. Experimental results demonstrate that the supporters are useful for robust visual tracking and that the variational auto-encoding can accurately estimate the distribution of supporters’ states. Moreover, our proposed VAE-MCMC method quantitatively and qualitatively outperforms recent state-of-the-art tracking methods.},
  archive      = {J_ISCI},
  author       = {Junseok Kwon},
  doi          = {10.1016/j.ins.2019.09.015},
  journal      = {Information Sciences},
  pages        = {1308-1323},
  shortjournal = {Inf. Sci.},
  title        = {Robust visual tracking based on variational auto-encoding markov chain monte carlo},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended decision field theory with social-learning for
long-term decision-making processes in social networks. <em>ISCI</em>,
<em>512</em>, 1293–1307. (<a
href="https://doi.org/10.1016/j.ins.2019.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling and analysis of human behaviors in social networks are essential in fields such as online business, marketing, and finance. However, the establishment of a generalized decision-making framework for human behavior is challenging due to different decision structures among individuals. Thus, we propose a new decision-making framework, Decision Field Theory with Learning (DFT-L), which combines the DFT model and the DeGroot model. We investigated three factors influencing preference evolution: previous experiences, current evaluations, and neighbors’ preferences. The equilibrium status of social networks within this framework is obtained as an explicit formula under the independent and identically distributed (IID) conditions on weight values. This facilitates the identification of limiting expected preference values and covariance matrices . A simulation analysis using simulated and real networks is performed to validate the DFT-L framework and to demonstrate its efficiency compared with the original DFT. Our finding confirms that the diffusion process within DFT-L propagates fastest in the random network and slowest in the ring-lattice network. We also show that interactions among people affect the agent&#39;s decision within DFT-L and intensify embedded society characteristics, which helps to analyze irregular behaviors such as information cascades in social networks.},
  archive      = {J_ISCI},
  author       = {Seunghan Lee and Young-Jun Son},
  doi          = {10.1016/j.ins.2019.10.025},
  journal      = {Information Sciences},
  pages        = {1293-1307},
  shortjournal = {Inf. Sci.},
  title        = {Extended decision field theory with social-learning for long-term decision-making processes in social networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommendation system exploiting aspect-based opinion mining
with deep learning method. <em>ISCI</em>, <em>512</em>, 1279–1292. (<a
href="https://doi.org/10.1016/j.ins.2019.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the developments of e-commerce websites, user textual review has become an important source of information for improving the performance of recommendation systems, as they contain fine-grained users’ opinions that generally reflect their preference towards products. However, most of the classical recommender systems (RSs) often ignore such user opinions and therefore fail to precisely capture users’ specific sentiments on products. Although a few of the approaches have attempted to utilize fine-grained users’ opinions for enhancing the accuracy of recommendation systems to some extent, most of these methods basically rely on handcrafted and rule-based approaches that are generally known to be time-consuming and labour-intensive. As such, their application is limited in practice. Thus, to overcome the above problems, this paper proposes a recommendation system that utilizes aspect-based opinion mining (ABOM) based on the deep learning technique to improve the accuracy of the recommendation process. The proposed model consists of two parts: ABOM and rating prediction. In the first part, we use a multichannel deep convolutional neural network (MCNN) to better extract aspects and generate aspect-specific ratings by computing users’ sentiment polarities on various aspects. In the second part, we integrate the aspect-specific ratings into a tensor factorization (TF) machine for the overall rating prediction. Experimental results using various datasets show that our proposed model achieves significant improvements compared with the baseline methods .},
  archive      = {J_ISCI},
  author       = {Aminu Da&#39;u and Naomie Salim and Idris Rabiu and Akram Osman},
  doi          = {10.1016/j.ins.2019.10.038},
  journal      = {Information Sciences},
  pages        = {1279-1292},
  shortjournal = {Inf. Sci.},
  title        = {Recommendation system exploiting aspect-based opinion mining with deep learning method},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single image super resolution using dictionary learning and
sparse coding with multi-scale and multi-directional gabor feature
representation. <em>ISCI</em>, <em>512</em>, 1264–1278. (<a
href="https://doi.org/10.1016/j.ins.2019.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, sparse representation theory has shown the state-of-art performance in image super resolution (SR) field. The sparse representation based single image SR methods learn dictionaries to discover the co-occurence relationship between low-resolution (LR) and high-resolution (HR) image feature spaces to generate satisfactory SR images. However, most existing learning based methods focus on Gradient and Laplacian filters to achieve accurate feature representation in SR task. In this paper, a novel multi-scale and multi-directional feature descriptor approach is proposed to improve SR quality. In the proposed approach, Gabor filter is first used as feature representation in learning based super resolution to extract image features at different scales and orientations. Therefore, the difficulty of capturing the complex local structures in all scale and directions using traditional 1-D filters is resolved by the proposed Gabor filter approach. Then the efficient mapping between LR and HR images is achieved by searching the sparse representation coefficients over the LR and HR dictionaries in dictionary learning phase. Finally, the learned relationship is applied to validation LR input in order to achieve accurate SR image in reconstruction phase. The experimental results show that the proposed method outperforms other state-of-art methods in terms of both quantity and quality.},
  archive      = {J_ISCI},
  author       = {Selen Ayas and Murat Ekinci},
  doi          = {10.1016/j.ins.2019.10.040},
  journal      = {Information Sciences},
  pages        = {1264-1278},
  shortjournal = {Inf. Sci.},
  title        = {Single image super resolution using dictionary learning and sparse coding with multi-scale and multi-directional gabor feature representation},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A general fragments allocation method for join query in
distributed database. <em>ISCI</em>, <em>512</em>, 1249–1263. (<a
href="https://doi.org/10.1016/j.ins.2019.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of fragments allocation is key for improving performance of join query in distributed database . Current strategies concentrate on using heuristic rules to allocate fragments to corresponding locations, such as picking the location with maximum required data or with greedy algorithm . Notwithstanding their benefits, under distributed environment, facing various query plans, different data distributions and expensive network cost, their scene-sensitive character may easily generate low quality allocation plan due to lack of generalization ability . In this paper, for breaking this limitation, we propose a general strategy for allocating fragments(AlCo, Al locate fragments based on Co st). AlCo evaluates multiple candidate allocation plans based on cost, which is realized by a modified genetic algorithm employed from PostgreSQL . Our fitness function (cost model) synthetically considers various changeable factors to support generalization ability . For reducing the risks caused by randomization of genetic algorithm , AlCo provides an upper bound computed through current heuristic methods to improve the robustness of our genetic algorithm. We implement AlCo in a distributed database system , and the experiments show that, on TPC-H benchmark, AlCo is up to 2x–4x better on performance than existing strategies and performs well in robustness and scalability.},
  archive      = {J_ISCI},
  author       = {Jintao Gao and Wenjie Liu and Zhanhuai Li and Jian Zhang and Li Shen},
  doi          = {10.1016/j.ins.2019.10.043},
  journal      = {Information Sciences},
  pages        = {1249-1263},
  shortjournal = {Inf. Sci.},
  title        = {A general fragments allocation method for join query in distributed database},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determining the most representative image on a web page.
<em>ISCI</em>, <em>512</em>, 1234–1248. (<a
href="https://doi.org/10.1016/j.ins.2019.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate how to determine the most representative image on a Web page. This problem has not been thoroughly investigated and, up to today, only expert-based algorithms have been proposed in the literature. We attempt to improve the performance of known algorithms with the use of Support Vector Machines (SVM). Besides, our algorithm distinguishes itself from existing literature with the introduction of novel image features , including previously unused meta-data protocols. Also, we design and attempt a less-restrictive ranking methodology in the image preprocessing stage of our algorithm. We find that the application of the SVM framework with our improved classification methodology increases the F 1 score from 27.2\% to 38.5\%, as compared to a state-of-the-art method. Introducing novel image features and applying backward feature selection, we find that the F 1 score rises to 40.0\%. Lastly, we use a class-weighted SVM in order to resolve the imbalance in number of representative images. This final modification improves the classification performance of our algorithm even further to 43.9\%, outperforming our benchmark algorithms, including those of Facebook and Google. Suggested beneficiaries are the search engine community, image retrieval community, including the commercial sector due to superior performance.},
  archive      = {J_ISCI},
  author       = {Krishna Vyas and Flavius Frasincar},
  doi          = {10.1016/j.ins.2019.10.045},
  journal      = {Information Sciences},
  pages        = {1234-1248},
  shortjournal = {Inf. Sci.},
  title        = {Determining the most representative image on a web page},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning imbalanced datasets based on SMOTE and gaussian
distribution. <em>ISCI</em>, <em>512</em>, 1214–1233. (<a
href="https://doi.org/10.1016/j.ins.2019.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The learning of imbalanced datasets is a ubiquitous challenge for researchers in the fields of data mining and machine learning . Conventional classifiers are often biased towards the majority class, and loss functions attempt to optimize the quantities. In this paper, we present two effective sampling methods that improve the data distributions. One rebalanced method, the Adaptive-SMOTE, improves the SMOTE method by adaptively selecting groups of Inner and Danger data from the minority class such that a new minority class is compiled based on the selected data, thus preventing an expansion of the category boundary and strengthening the distributional characteristics of the original data. The other method, Gaussian Oversampling, combines dimension reduction with the Gaussian distribution , which makes the tail of the Gaussian distribution thinner. Cross-validation experiments on 15 datasets show that the two sampling methods achieve significant improvements compared with other typical methods. The Adaptive-SMOTE has higher F -measure and Acc values than other existing sampling methods and higher robustness to classifiers and datasets with different values of Imb. Gaussian Oversampling is more efficient when dealing with extremely imbalanced classifications.},
  archive      = {J_ISCI},
  author       = {Tingting Pan and Junhong Zhao and Wei Wu and Jie Yang},
  doi          = {10.1016/j.ins.2019.10.048},
  journal      = {Information Sciences},
  pages        = {1214-1233},
  shortjournal = {Inf. Sci.},
  title        = {Learning imbalanced datasets based on SMOTE and gaussian distribution},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A vague multidimensional dependency structure: Conditional
versus unconditional fuzzy copula models. <em>ISCI</em>, <em>512</em>,
1202–1213. (<a href="https://doi.org/10.1016/j.ins.2019.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ambiguity refers to a fogginess inducing some lack of precision in variables, parameters or magnitudes in models whose aim is to represent real phenomena or better that are strictly linked to the human feelings and beliefs. It has recently become an usual model assumption in several stream of literature. Here we focus on multivariate models affected by ambiguity and provide a rigorous modellization of the main ingredients causing a multidimensional fuzzification . We introduce a conditional fuzzified model, where a certain level of uncertainty affects the set of univariate margins individually taken and also an unconditional model where the ambiguity involves the dependency structure as well. Both these models, i.e. the conditional and the unconditional fuzzy copula model, are compared and their convergence is discussed. Finally a pricing application of these multidimensional fuzzy models, based on Sugeno measures, is proposed.},
  archive      = {J_ISCI},
  author       = {Silvia Romagnoli},
  doi          = {10.1016/j.ins.2019.10.052},
  journal      = {Information Sciences},
  pages        = {1202-1213},
  shortjournal = {Inf. Sci.},
  title        = {A vague multidimensional dependency structure: Conditional versus unconditional fuzzy copula models},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kernel density estimation based sampling for imbalanced
class distribution. <em>ISCI</em>, <em>512</em>, 1192–1201. (<a
href="https://doi.org/10.1016/j.ins.2019.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced response variable distribution is a common occurrence in data science. In fields such as fraud detection, medical diagnostics, system intrusion detection and many others where abnormal behavior is rarely observed the data under study often features disproportionate target class distribution. One common way to combat class imbalance is through resampling of the minority class to achieve a more balanced distribution. In this paper, we investigate the performance of the sampling method based on kernel density estimation (KDE). We believe that KDE offers a more natural way to generate new instances of minority class that is less prone to overfitting than other standard sampling techniques. It is based on a well established theory of nonparametric statistical estimation. Numerical experiments show that KDE can outperform other sampling techniques on a range of real life datasets as measured by F 1 -score and G-mean. The results remain consistent across a number of classification algorithms used in the experiments. Furthermore, the proposed method outperforms the benchmark methods irregardless of the class distribution ratio. We conclude, based on the solid theoretical foundation and strong experimental results, that the proposed method would be a valuable tool in problems involving imbalanced class distribution.},
  archive      = {J_ISCI},
  author       = {Firuz Kamalov},
  doi          = {10.1016/j.ins.2019.10.017},
  journal      = {Information Sciences},
  pages        = {1192-1201},
  shortjournal = {Inf. Sci.},
  title        = {Kernel density estimation based sampling for imbalanced class distribution},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scheduling scheme in the cloud computing environment using
deep q-learning. <em>ISCI</em>, <em>512</em>, 1170–1191. (<a
href="https://doi.org/10.1016/j.ins.2019.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task scheduling , which plays a vital role in cloud computing , is a critical factor that determines the performance of cloud computing . From the booming economy of information processing to the increasing need of quality of service (QoS) in the business of networking, the dynamic task-scheduling problem has attracted worldwide attention. Due to its complexity, task scheduling has been defined and classified as an NP-hard problem. Additionally, most dynamic online task scheduling often manages tasks in a complex environment, which makes it even more challenging to balance and satisfy the benefits of each aspect of cloud computing. In this paper, we propose a novel artificial intelligence algorithm, called deep Q -learning task scheduling (DQTS), that combines the advantages of the Q -learning algorithm and a deep neural network . This new approach is aimed at solving the problem of handling directed acyclic graph (DAG) tasks in a cloud computing environment. The essential idea of our approach uses the popular deep Q -learning (DQL) method in task scheduling, where fundamental model learning is primarily inspired by DQL. Based on developments in WorkflowSim, experiments are conducted that comparatively consider the variance of makespan and load balance in task scheduling. Both simulation and real-life experiments are conducted to verify the efficiency of optimization and learning abilities in DQTS. The result shows that when compared with several standard algorithms precoded in WorkflowSim, DQTS has advantages regarding learning ability, containment, and scalability. In this paper, we have successfully developed a new method for task scheduling in cloud computing.},
  archive      = {J_ISCI},
  author       = {Zhao Tong and Hongjian Chen and Xiaomei Deng and Kenli Li and Keqin Li},
  doi          = {10.1016/j.ins.2019.10.035},
  journal      = {Information Sciences},
  pages        = {1170-1191},
  shortjournal = {Inf. Sci.},
  title        = {A scheduling scheme in the cloud computing environment using deep Q-learning},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced digital chaotic maps based on bit reversal with
applications in random bit generators. <em>ISCI</em>, <em>512</em>,
1155–1169. (<a href="https://doi.org/10.1016/j.ins.2019.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital chaotic maps are becoming increasingly popular in the area of cryptography due to commonalities but have drawbacks which adversely effect security strength. Thus, enhancing digital chaotic maps in terms of their chaoticity and statistical properties contributes towards the improvement of chaos-based cryptography. This paper proposes a bit reversal approach to address these issues. The proposed method modifies chaotic state values (represented as fixed point numbers) by reversing the order of their fractional bits . Experimental verification indicates that chaotic maps modified by the proposed approach depict better chaotic performance, have higher complexity and larger chaotic parameter range. These results exceed those of existing digital chaotic maps and other chaotification methods. The simplicity of the proposed bit reversal approach and the use of fixed point representation makes it easy to implement on any computing platform. This approach is also highly flexible as it does not require any external inputs, making it a universal method for enhancing any digital chaotic map. As a proof-of-concept, a pseudorandom bit generator (PRBG) was designed based on cascading chaotic maps modified by the proposed method. Simulation and security analysis indicate that the proposed PRBG is statistically random, has a uniform data distribution and high key sensitivity.},
  archive      = {J_ISCI},
  author       = {Moatsum Alawida and Azman Samsudin and Je Sen Teh},
  doi          = {10.1016/j.ins.2019.10.055},
  journal      = {Information Sciences},
  pages        = {1155-1169},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced digital chaotic maps based on bit reversal with applications in random bit generators},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nullnorms on bounded lattices derived from t-norms and
t-conorms. <em>ISCI</em>, <em>512</em>, 1134–1154. (<a
href="https://doi.org/10.1016/j.ins.2019.10.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nullnorms with an annihilator a in any point of a bounded lattice are generalizations and unifications of t-norms and t-conorms. This study continues to investigate the construction of nullnorms on bounded lattices. We propose some methods to construct nullnorms derived from t-norms and t-conorms on bounded lattices, where some sufficient and necessary conditions on theirs annihilator are required. As a by-product of these constructions, idempotent nullnorms on bounded lattices are obtained. Further, we provide some illustrative examples of the new classes of nullnorms (idempotent nullnorms) on bounded lattices.},
  archive      = {J_ISCI},
  author       = {Gül Deniz Çaylı},
  doi          = {10.1016/j.ins.2019.10.059},
  journal      = {Information Sciences},
  pages        = {1134-1154},
  shortjournal = {Inf. Sci.},
  title        = {Nullnorms on bounded lattices derived from t-norms and t-conorms},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MP3 steganalysis based on joint point-wise and block-wise
correlations. <em>ISCI</em>, <em>512</em>, 1118–1133. (<a
href="https://doi.org/10.1016/j.ins.2019.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growing attention on multimedia security, various MP3 steganographic and steganalytic algorithms have been proposed increasingly. However, the existing MP3 steganalysis is lack of good universality and detection performance. To address this problem, we devise an effective MP3 steganalytic algorithm based on joint point-wise and block-wise correlations of quantified modified discrete cosine transfer coefficients matrix . On the one hand, a universal rich high pass filtering module for MP3 steganalysis is deployed to boost the sensitiveness of the algorithm to the subtle signal brought by the data hiding. On the other hand, based on the principle of MP3 encoding and the characteristics of MP3 steganography, multi-scale correlations measure module is introduced, which is used to measure the changes of point-wise, 2 × 2 block-wise, and 4 × 4 block-wise correlations due to steganography separately. Additionally, customized feature optimization, including truncated threshold selection and high pass filters measure, is performed based on the properties of MP3 steganography. Experimental results illustrate that our proposed algorithm can be applied to various MP3 steganographic algorithms , bitrates, duration, and relative payloads. Detection accuracies are promoted by more than 20\% averagely compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yuntao Wang and Xiaowei Yi and Xianfeng Zhao},
  doi          = {10.1016/j.ins.2019.10.037},
  journal      = {Information Sciences},
  pages        = {1118-1133},
  shortjournal = {Inf. Sci.},
  title        = {MP3 steganalysis based on joint point-wise and block-wise correlations},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pareto optimal strategy for linear stochastic systems with
h∞ constraint in finite horizon. <em>ISCI</em>, <em>512</em>, 1103–1117.
(<a href="https://doi.org/10.1016/j.ins.2019.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we derive conditions for the existence of Pareto efficient strategy and Pareto solution under H ∞ constraint for the linear quadratic (LQ) finite horizon cooperative differential game of stochastic systems with state-, control- and disturbance-multiplicative noise. Firstly, we present a stochastic bounded real lemma (SBRL) with any initial condition for the considered stochastic system. Next, a necessary and sufficient condition for Pareto optimal strategy under the H ∞ constraint is researched by two cross-coupled generalized differential Riccati equations (GDREs), which is the key contribution of this paper. Another contribution is that the Pareto solution for every controller is given under the Pareto efficient strategy and worst-case external disturbance . Finally, a practical example is given to illustrate the effectiveness of our results.},
  archive      = {J_ISCI},
  author       = {Xiushan Jiang and Senping Tian and Tianliang Zhang and Weihai Zhang},
  doi          = {10.1016/j.ins.2019.10.005},
  journal      = {Information Sciences},
  pages        = {1103-1117},
  shortjournal = {Inf. Sci.},
  title        = {Pareto optimal strategy for linear stochastic systems with h∞ constraint in finite horizon},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparative study of machine translation for multilingual
sentence-level sentiment analysis. <em>ISCI</em>, <em>512</em>,
1078–1102. (<a href="https://doi.org/10.1016/j.ins.2019.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis has become a key tool for several social media applications , including, analysis of user’s opinions about products and services, support for politics during campaigns and even identification of market trending. Multiple existing sentiment analysis methods explore different techniques, usually relying on lexical resources or learning approaches. Despite the significant interest in this theme and amount of research efforts in the field, almost all existing methods are designed to work with only English content. Most current strategies in other languages consist of adapting existing lexical resources, without presenting proper validations and basic baseline comparisons. In this work, we take a different step into this field. We focus on evaluating existing efforts proposed to do language specific sentiment analysis with a simple yet effective baseline approach. To do it, we evaluated sixteen methods for sentence-level sentiment analysis proposed for English, and compared them with three language-specific methods. Based on fourteen human labeled language-specific datasets, we provide an extensive quantitative analysis of existing multilingual approaches. Our results suggest that simply translating the input text in a specific language to English and then using one of the existing best methods developed for English can be better than the existing language-specific approach evaluated. We also rank methods according to their prediction performance and identify those that acquired the best results using machine translation across different languages. As a final contribution to the research community, we release our codes, datasets, and the iFeel 3.0 system, a Web framework and tool for multilingual sentence-level sentiment analysis 1 . We hope our system sets up a new baseline for future sentence-level methods developed in a wide set of languages.},
  archive      = {J_ISCI},
  author       = {Matheus Araújo and Adriano Pereira and Fabrício Benevenuto},
  doi          = {10.1016/j.ins.2019.10.031},
  journal      = {Information Sciences},
  pages        = {1078-1102},
  shortjournal = {Inf. Sci.},
  title        = {A comparative study of machine translation for multilingual sentence-level sentiment analysis},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-based fault-tolerant control for networked control
systems applied to aircraft engine system. <em>ISCI</em>, <em>512</em>,
1063–1077. (<a href="https://doi.org/10.1016/j.ins.2019.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the observer-based fault-tolerant control (FTC) for a class of networked control systems (NCSs) subject to system fault and external disturbance . Firstly, in order to reduce the number of sampled data transmissions, an improved adaptive event-triggered mechanism (AETM) is proposed, which can not only reflect the whole real-time information of the addressed NCSs, but also help to enlarge the application areas. Then based on the triggered output signals, a combined observer is proposed to estimate the state and system fault, and the estimations are further utilized to design the fault-tolerant controller. By choosing an augmented Lyapunov–Kroasovskii functional (LKF), two sufficient conditions on co-designing the AETM, observer, and controller are presented in terms of linear matrix inequalities (LMIs). Moreover, we adopt the derived methods to tackle the robust FTC for networked aircraft engine model. Finally, two numerical examples are provided to demonstrate the effectiveness of our obtained results by some simulations and comparisons.},
  archive      = {J_ISCI},
  author       = {Tao Li and Xiaoling Tang and Jifeng Ge and Shumin Fei},
  doi          = {10.1016/j.ins.2019.10.039},
  journal      = {Information Sciences},
  pages        = {1063-1077},
  shortjournal = {Inf. Sci.},
  title        = {Event-based fault-tolerant control for networked control systems applied to aircraft engine system},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Movement patterns of a particle swarm in high dimensional
spaces. <em>ISCI</em>, <em>512</em>, 1043–1062. (<a
href="https://doi.org/10.1016/j.ins.2019.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high dimensional problem spaces, particle swarm optimization (PSO) is prone to unwanted roaming behaviour due to initial velocity explosion. A particle swarm’s movement patterns are strongly influenced by the inertia weight and acceleration coefficients . This paper investigates whether the initial velocity explosion can be curbed by appropriate choice of the inertia weight and the acceleration coefficients , which restrict the standard deviation of particle positions. It is shown that roaming behaviour cannot be solved by reducing swarm variance directly, but that the relationship between the parameters must also be considered. Furthermore, the paper investigates different movement patterns that may be exhibited by the swarm. It is shown that optimal parameter configurations differ between low and high dimensional problems. Specifically, parameter configurations which produce very smooth particle trajectories and restrict the swarm’s movement range are advantageous in high dimensional spaces. These movement patterns correspond to high inertia weight and low acceleration coefficients (eg. w = 0.9694 , w=0.9694, c 1 = c 2 = 0.099381 c1=c2=0.099381 ). Swarms with smooth particle trajectories exhibited significantly less unwanted roaming behaviour than swarms with chaotic or oscillating particle trajectories.},
  archive      = {J_ISCI},
  author       = {Elre T. Oldewage and Andries P. Engelbrecht and Christopher W. Cleghorn},
  doi          = {10.1016/j.ins.2019.09.057},
  journal      = {Information Sciences},
  pages        = {1043-1062},
  shortjournal = {Inf. Sci.},
  title        = {Movement patterns of a particle swarm in high dimensional spaces},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applying social network analysis to genetic algorithm in
optimizing project risk response decisions. <em>ISCI</em>, <em>512</em>,
1024–1042. (<a href="https://doi.org/10.1016/j.ins.2019.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {R isk interaction changes the probability of occurring a risk and also the impact of the risk, which calls for new approaches for making risk response decision (RRD). In this work, a simulation-based network model of abstracting the risk interactions is built for evaluating the RRDs. Meanwhile, genetic algorithm (GA) is tailored and improved for optimizing the RRDs, whose crossover operator is designed and enhanced by the social network analysis (SNA). Specifically, the application of SNA is two-fold: transforming the network for changing risk and risk interaction into the same network element; designing a new index to quantify the element’s significance in the network view. Double-sorting map crossover is proposed for tailoring GA, and accordingly, multi-sorting map crossover is designed by integrating the quantified significance. An application example of the proposed approach is provided to illustrate its process and utility. Furthermore, contrastive analysis is conducted based on three different size cases, and the result demonstrates that the improvement in the GA is effective.},
  archive      = {J_ISCI},
  author       = {Lei Wang and Tao Sun and Chen Qian and Mark Goh and Vikas Kumar Mishra},
  doi          = {10.1016/j.ins.2019.10.012},
  journal      = {Information Sciences},
  pages        = {1024-1042},
  shortjournal = {Inf. Sci.},
  title        = {Applying social network analysis to genetic algorithm in optimizing project risk response decisions},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional wasserstein generative adversarial
network-gradient penalty-based approach to alleviating imbalanced data
classification. <em>ISCI</em>, <em>512</em>, 1009–1023. (<a
href="https://doi.org/10.1016/j.ins.2019.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data mining , common classification algorithms cannot effectively learn from imbalanced data . Oversampling addresses this problem by creating data for the minority class in order to balance the class distribution before the model is trained. The Traditional oversampling approaches are based on Synthetic Minority Oversampling TEchnique (SMOTE), which focus on local information but generates insufficiently realistic data. In contrast, the Generative Adversarial Network (GAN) captures the true data distribution in order to generate data for the minority class. However, both approaches are problematic owing to mode collapse and unstable training. To overcome these problems, we propose Conditional Wasserstein GAN- Gradient Penalty (CWGAN-GP), a novel and efficient synthetic oversampling approach for imbalanced datasets, which can be constructed by adding auxiliary conditional information to the WGAN-GP. CWGAN-GP generates more realistic data and overcomes the aforementioned problems. Experiments on 15 different benchmarked datasets and two real imbalanced datasets empirically demonstrate that CWGAN-GP increases the quality of synthetic data; furthermore, our approach outperforms the other oversampling approaches based on three evaluation metrics (F-measure, G-mean, and the area under the receiver operating characteristic curve) for five classifiers. Friedman and Nemenyi post hoc statistical tests also confirm that CWGAN-GP is superior to the other oversampling approaches.},
  archive      = {J_ISCI},
  author       = {Ming Zheng and Tong Li and Rui Zhu and Yahui Tang and Mingjing Tang and Leilei Lin and Zifei Ma},
  doi          = {10.1016/j.ins.2019.10.014},
  journal      = {Information Sciences},
  pages        = {1009-1023},
  shortjournal = {Inf. Sci.},
  title        = {Conditional wasserstein generative adversarial network-gradient penalty-based approach to alleviating imbalanced data classification},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient distance join query processing in distributed
spatial data management systems. <em>ISCI</em>, <em>512</em>, 985–1008.
(<a href="https://doi.org/10.1016/j.ins.2019.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ubiquitous use of spatial data applications and the large amounts of such data these applications use, the processing of large-scale distance joins in distributed systems is becoming increasingly popular. Distance Join Queries (DJQs) are important and frequently used operations in numerous applications, including data mining , multimedia and spatial databases . DJQs (e.g., k Nearest Neighbor Join Query, k Closest Pair Query, ε Distance Join Query, etc.) are costly operations, since they involve both the join and distance-based search, and performing DJQs efficiently is a challenging task. Recent Big Data developments have motivated the emergence of novel technologies for distributed processing of large-scale spatial data in clusters of computers, leading to Distributed Spatial Data Management Systems (DSDMSs). Distributed cluster-based computing systems can be classified as Hadoop-based or Spark-based systems. Based on this classification, in this paper, we compare two of the most recent and leading DSDMSs, SpatialHadoop and LocationSpark, by evaluating the performance of several existing and newly proposed parallel and distributed DJQ algorithms under various settings with large spatial real-world datasets. A general conclusion arising from the execution of the distributed DJQ algorithms studied is that, while SpatialHadoop is a robust and efficient system when large spatial datasets are joined (since it is built on top of the mature Hadoop platform), LocationSpark is the clear winner in total execution time efficiency when medium spatial datasets are combined (due to in-memory processing provided by Spark). However, LocationSpark requires higher memory allocation when large spatial datasets are involved in DJQs (even more so when k and ε are large). Finally, this detailed performance study has demonstrated that the new distributed DJQ algorithms we have proposed are efficient, robust and scalable with respect to different parameters, such as dataset sizes, k , ε and number of computing nodes.},
  archive      = {J_ISCI},
  author       = {Francisco García-García and Antonio Corral and Luis Iribarne and Michael Vassilakopoulos and Yannis Manolopoulos},
  doi          = {10.1016/j.ins.2019.10.030},
  journal      = {Information Sciences},
  pages        = {985-1008},
  shortjournal = {Inf. Sci.},
  title        = {Efficient distance join query processing in distributed spatial data management systems},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fabric defect inspection based on lattice segmentation and
template statistics. <em>ISCI</em>, <em>512</em>, 964–984. (<a
href="https://doi.org/10.1016/j.ins.2019.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated fabric inspection is desirable for quality control of fabric industry. However, it is challenging due to some unpredictable fabric defects which may only occur during the production. Hence, methods aiming at automated fabric inspection are commonly developed in absence of defective samples. This paper proposes a novel automated fabric inspection method based on lattice segmentation and template statistics (LSTS) focusing on the patterned fabric images containing repetitive texture primitives. The proposed method attempts to infer the placement rule of texture primitives and divide the image into none-overlapping lattices as texture primitives which represent the given image by hundreds of lattices instead of millions of pixels. The defects are then efficiently identified by comparing the lattice similarity w. r. t. the benchmarks named template statistics . The template statistics are learnt from defect-free samples through a modular framework in which multiple feature extraction methods like Gabor filters and local binary pattern can be flexibly combined according to their inspection efficiencies. The performance of the proposed method is evaluated in the databases of dot-, box- and star-patterned fabric images. By comparing the resultant and ground-truth images, an overall detection rate of 0.977 is achieved, which is competitive with the state-of-the-arts.},
  archive      = {J_ISCI},
  author       = {Liang Jia and Chen Chen and Shoukun Xu and Ju Shen},
  doi          = {10.1016/j.ins.2019.10.032},
  journal      = {Information Sciences},
  pages        = {964-984},
  shortjournal = {Inf. Sci.},
  title        = {Fabric defect inspection based on lattice segmentation and template statistics},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid convolution network for serial number recognition
on banknotes. <em>ISCI</em>, <em>512</em>, 952–963. (<a
href="https://doi.org/10.1016/j.ins.2019.09.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the sole identity of banknote, serial number has played a crucial role in monitoring the circulation of currencies. Serial number recognition plays an important role in financial market, which requires fast and accurate performances in real applications. In this paper, a hybrid convolution network model has been proposed, in which a dilated-based convolution neural network is employed to improve the recognition accuracy and a quantitative neural network method is developed to speed up the identification process. In dilated-based convolution neural network, the convolution layer and the pooling layer have been replaced by dilated convolution, which can reduce the computation cost. The quantitative neural network based method quantizes the weight parameters to an integer power of two, which transforms the original multiplication operation to a shift operation and can greatly reduce the time. The proposed model was examined and tested on four different banknotes with 35,000 banknote images including RMB, HKD, USD and GBP. The experimental results show that, the proposed model can efficiently improve the recognition accuracy to 99.89\% and reduce the recognition time to less than 0.1 ms, and it outperforms the other algorithms on both recognition accuracy and recognition speed.},
  archive      = {J_ISCI},
  author       = {Feng Wang and Huiqing Zhu and Wei Li and Kangshun Li},
  doi          = {10.1016/j.ins.2019.09.070},
  journal      = {Information Sciences},
  pages        = {952-963},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid convolution network for serial number recognition on banknotes},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving network embedding with partially available vertex
and edge content. <em>ISCI</em>, <em>512</em>, 935–951. (<a
href="https://doi.org/10.1016/j.ins.2019.09.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims to learn a low-dimensional representation for each vertex in a network, which has recently shown its power in many graph mining problems such as vertex classification and link prediction. Most existing methods learn such representations according to network structure information, and some methods further consider vertex content in a network. Unlike prior works, we study the problem of network embedding with two distinctive properties: (1) content information exists on both vertices and edges; (2) only a part of vertices and edges have content information. To solve this problem, we propose a novel P artially available V ertex and E dge C ontent B oosted network embedding method, namely PVECB , which uses available vertex and edge content information to fine-tune structure-only representations through two hand-designed mechanisms respectively. Empirical results on four real-world datasets demonstrate that our method can effectively boost structure-only representations to capture more accurate proximities between vertices.},
  archive      = {J_ISCI},
  author       = {Lin Lan and Pinghui Wang and Junzhou Zhao and Jing Tao and John C.S. Lui and Xiaohong Guan},
  doi          = {10.1016/j.ins.2019.09.083},
  journal      = {Information Sciences},
  pages        = {935-951},
  shortjournal = {Inf. Sci.},
  title        = {Improving network embedding with partially available vertex and edge content},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A refined hölder’s inequality for choquet expectation by
cauchy-schwarz’s inequality. <em>ISCI</em>, <em>512</em>, 929–934. (<a
href="https://doi.org/10.1016/j.ins.2019.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first introduce a refined Hölder’s inequality in Choquet calculus. Then by this inequality, we show that Cauchy-Schwarz inequality and Hölder’s inequality for Choquet expectation are equivalent when the monotone measure is submodular or the integrands are comonotonic, thus closing the series of papers in this literature. Note that it is obvious that Hölder’s inequality implies Cauchy-Schwarz’s inequality. But the converse is an interesting subject. This paper focuses on this subject.},
  archive      = {J_ISCI},
  author       = {Hamzeh Agahi},
  doi          = {10.1016/j.ins.2019.10.010},
  journal      = {Information Sciences},
  pages        = {929-934},
  shortjournal = {Inf. Sci.},
  title        = {A refined hölder’s inequality for choquet expectation by cauchy-schwarz’s inequality},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consensus of multi-agent systems with finite-time and
fixed-time observation. <em>ISCI</em>, <em>512</em>, 909–928. (<a
href="https://doi.org/10.1016/j.ins.2019.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed control problem of single-input high-order multi-agent systems (MASs). Firstly, a nonlinear observation system is proposed to track the target system in a finite-time, and a distributed event-triggered protocol is designed to reduce the frequency of data transmission. Moreover, we popularize the distributed event-triggered algorithm to general directed networks. Applying the tree-type error method and implicit Lyapunov functions , some criteria are derived to ensure the finite-time observation and asymptotical consensus. Furthermore, based on single-output state, a fixed-time nonlinear observer is introduced, and the asymptotical consensus is also considered utilizing the distributed event-triggered protocol. Finally, the effectiveness of the control strategies is demonstrated via some numerical simulations.},
  archive      = {J_ISCI},
  author       = {Zhiyong Yu and Shuzhen Yu and Haijun Jiang},
  doi          = {10.1016/j.ins.2019.10.023},
  journal      = {Information Sciences},
  pages        = {909-928},
  shortjournal = {Inf. Sci.},
  title        = {Consensus of multi-agent systems with finite-time and fixed-time observation},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient discrete PSO coupled with a fast local search
heuristic for the DNA fragment assembly problem. <em>ISCI</em>,
<em>512</em>, 880–908. (<a
href="https://doi.org/10.1016/j.ins.2019.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on Particle Swarm Optimization (PSO) applied to the DNA fragment assembly problem. Existing PSO algorithms for this permutation-based combinatorial problem use the Smaller Position Value (SPV) rule to transform continuous vectors into permutations of integers. However, this approach has limitations and is not suitable for this NP-hard problem. Here we propose a new discrete PSO that works directly in the search space of permutations and effectively addresses the fragment assembly problem. In our proposal, the fact that relative ordering of DNA fragments is most indicative of assembly accuracy is exploited in the particle update mechanism. This is implemented through a new operator called Probabilistic Edge Recombination (PER). This operator builds a new position through the probabilistic recombination of edges (adjacency relations) between fragments from the current position, the personal best, and the group best. Additionally, we design variants of the proposed PSO algorithm by applying heuristic information and/or local search. With this aim, we develop a new fast variant of the best state-of-the-art local search algorithm for the assembly problem. Extensive experiments have been conducted to demonstrate the efficiency and effectiveness of the algorithms used. In comparison with the state-of-the-art assembly techniques, our algorithms achieve a better performance.},
  archive      = {J_ISCI},
  author       = {Abdelkamel Ben Ali and Gabriel Luque and Enrique Alba},
  doi          = {10.1016/j.ins.2019.10.026},
  journal      = {Information Sciences},
  pages        = {880-908},
  shortjournal = {Inf. Sci.},
  title        = {An efficient discrete PSO coupled with a fast local search heuristic for the DNA fragment assembly problem},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 2D hybrid chaos map for image security transform based on
framelet and cellular automata. <em>ISCI</em>, <em>512</em>, 855–879.
(<a href="https://doi.org/10.1016/j.ins.2019.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important data in the social networks is image, so improving the existing methods can be essential to obtain a safe environment for transforming. In this paper, we provide some safe ways to transfer images securely by using cryptography and steganography methods. In order to enhance the security of the image transmission, we introduce a new type of uniformly distributed 2D hybrid chaos map based on Logistic, Sine and Tent maps, and use the cellular automata and discrete framelet transform in the proposed algorithms and also mix the position of the image pixels by applying kinds of shifts. To show that the proposed algorithms are able to resist various attacks, different types of simulation results and security analysis are used.},
  archive      = {J_ISCI},
  author       = {Y. Khedmati and R. Parvaz and Y. Behroo},
  doi          = {10.1016/j.ins.2019.10.028},
  journal      = {Information Sciences},
  pages        = {855-879},
  shortjournal = {Inf. Sci.},
  title        = {2D hybrid chaos map for image security transform based on framelet and cellular automata},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiattribute group decision making based on intuitionistic
fuzzy partitioned maclaurin symmetric mean operators. <em>ISCI</em>,
<em>512</em>, 830–854. (<a
href="https://doi.org/10.1016/j.ins.2019.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiattribute group decision making (MAGDM) method based on the proposed weighted partitioned Maclaurin symmetric mean (IFWPMSM) operators for intuitionistic fuzzy numbers (IFNs). Firstly, motivated by the partitioned Bonferroni mean (PBM) and the Maclaurin symmetric mean (MSM), we present the partitioned MSM (PMSM) operator considering the hypothesis that all attributes can be cut into some groups, where the attributes in the same group are relevant to other multiple attributes of the same group, but the attributes in different groups are irrelevant. Then, we present its characteristics and some special cases. Then, we generalize the PMSM operator to propose the intuitionistic fuzzy PMSM (IFPMSM) operator for IFNs and its weighted form (IFWPMSM) for IFNs. Then, we present several characteristics and special examples of the presented IFPMSM operator and the proposed IFWPMSM operator. Finally, we propose a new MAGDM method based on the proposed IFWPMSM operator and make a comparison with the existing approaches to interpret the usability and the validity of the proposed method.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Shyi-Ming Chen and Yumei Wang},
  doi          = {10.1016/j.ins.2019.10.013},
  journal      = {Information Sciences},
  pages        = {830-854},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute group decision making based on intuitionistic fuzzy partitioned maclaurin symmetric mean operators},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On efficiently diversified top-k geo-social keyword query
processing in road networks. <em>ISCI</em>, <em>512</em>, 813–829. (<a
href="https://doi.org/10.1016/j.ins.2019.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of geo-positioning technologies, the volumes of spatio-textual data are growing rapidly. These data are available in many applications such as location-based services and geo-social networks, and thus, various types of geo-social keyword queries have been intensively studied in the literature. A top- k geo-social keyword (T k GSK) query retrieves the objects by considering spatial, social, and textual constraints between the query and objects. Moreover, the result diversification is becoming a common practice to enhance the quality of the query result. Motivated by these, in this paper, we study the problem of diversified top-k geo-social keyword (D k GSK) query , which considers not only the relevance but also the diversity of the result. We first prove that this problem is NP-hard, and then, we present an exact algorithm with several effective pruning strategies. Also, we develop an approximate algorithm with proved approximation ratio to support the D k GSK query. Considerable experiments on real data sets demonstrate the effectiveness and efficiency of our proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Jingwen Zhao and Yunjun Gao and Chunyu Ma and Pengfei Jin and Shiting Wen},
  doi          = {10.1016/j.ins.2019.10.021},
  journal      = {Information Sciences},
  pages        = {813-829},
  shortjournal = {Inf. Sci.},
  title        = {On efficiently diversified top-k geo-social keyword query processing in road networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach for learning label correlation with
application to feature selection of multi-label data. <em>ISCI</em>,
<em>512</em>, 795–812. (<a
href="https://doi.org/10.1016/j.ins.2019.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each example of multi-label data is represented in an object with its feature vector (i.e. an instance) while being related to multiple labels. Learning label correlation can effectively reduce the labels needed to be predicted and optimize the classification performance. For this reason, label correlation plays a crucial role in multi-label learning and has been explored by many existing algorithms. Generally, every label has its own indispensable features, and it is reasonable to assume that a higher repetitiveness of indispensable features represents higher correlations among labels. Inspired by this fact, the essential elements for each label, which are composed of indispensable features, are constructed in this paper. A method is proposed for learning label correlation and applying it to feature selection of multi-label data based on the overlap of different families of essential elements related to label. Firstly, the essential elements of each label are defined and characterized to reflect the internal connection between features and label. In addition, a process for calculating the essential elements of a single label is provided. Secondly, by considering the overlap of the essential element collections that are determined by the different labels, relevancy of label and corresponding relevance judgement matrix with the label set are described. Therefore, several labels with strong relationships are assigned to a relevant group of labels. Meanwhile, local and global label correlations can be computed. Thus a novel multi-label learning algorithm, called CLSF, is presented to select a compact subset of indispensable features for each relevant group of labels by applying local label correlation to feature selection of multi-label data. Finally, comprehensive experiments on eleven benchmark data sets clearly illustrate the effectiveness and efficiency of CLSF against five other multi-label learning algorithms.},
  archive      = {J_ISCI},
  author       = {Xiaoya Che and Degang Chen and Jusheng Mi},
  doi          = {10.1016/j.ins.2019.10.022},
  journal      = {Information Sciences},
  pages        = {795-812},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for learning label correlation with application to feature selection of multi-label data},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Personalized image quality assessment with social-sensed
aesthetic preference. <em>ISCI</em>, <em>512</em>, 780–794. (<a
href="https://doi.org/10.1016/j.ins.2019.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalization is emerging as a key research objective for image aesthetics assessment, and how to incorporate personal preferences into aesthetics models is a crucial issue to be solved. Prior studies usually require users to explicitly express their aesthetic preferences in certain ways, which are time-consuming and labor-intensive. In this paper, inspired by the observation that human cognition and behavior influence each other, we propose to sense user aesthetic preferences from their favoring behavior on social media platforms . In this manner, personalized image aesthetics assessment can be realized without adding any extra burden to users. Towards this goal, we gather user favoring behavior over professional social photos and consider both user personal preference and common aesthetic standard to deal with the unreliability of user favoring behavior. Besides, we follow the idea of collaborative filtering and optimize the pairwise ranking between images to alleviate the data sparsity problem. Finally, a deep neural network architecture is developed for personalized aesthetics modeling. A simulated evaluation is carried out on two benchmark aesthetics datasets, even though users’ true preferences cannot be directly observed. The results demonstrate the potential of our approach for personalized image aesthetics assessment.},
  archive      = {J_ISCI},
  author       = {Chaoran Cui and Wenya Yang and Cheng Shi and Meng Wang and Xiushan Nie and Yilong Yin},
  doi          = {10.1016/j.ins.2019.10.011},
  journal      = {Information Sciences},
  pages        = {780-794},
  shortjournal = {Inf. Sci.},
  title        = {Personalized image quality assessment with social-sensed aesthetic preference},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel forecasting model for the long-term fluctuation of
time series based on polar fuzzy information granules. <em>ISCI</em>,
<em>512</em>, 760–779. (<a
href="https://doi.org/10.1016/j.ins.2019.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long-term fluctuation of time series is generally composed of a large number of short-term behaviors with various dynamical characteristics, where kinds of fluctuation patterns in different periods change mutually. In this paper, we propose a novel method to construct fuzzy information granules in polar coordinates and achieve the prediction of long-term fluctuation of time series on the basis of the short-term fluctuation patterns. Firstly, time series are divided into segments by means of the sliding time windows, and fuzzy information granules are defined based on the regression models to indicate the fluctuation patterns of segments of time series. The transfers among different information granules form a dynamical network containing rich inference information. Next, the constructed networks are analyzed to capture the transfer characteristics of fuzzy information granules. The results show that only a few types of fuzzy information granules and fuzzy relation groups play the key role in the fluctuation mechanism, which always have specific targets. Hence, according to the distribution of the transfer probability , a prediction scheme on the granularity level can be established. By utilizing both synthetic and real-life data sets, examples are shown to illustrate the effectiveness and feasibility of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Chao Luo and Xi Song and YuanJie Zheng},
  doi          = {10.1016/j.ins.2019.10.020},
  journal      = {Information Sciences},
  pages        = {760-779},
  shortjournal = {Inf. Sci.},
  title        = {A novel forecasting model for the long-term fluctuation of time series based on polar fuzzy information granules},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analyzing center/surround retinex. <em>ISCI</em>,
<em>512</em>, 741–759. (<a
href="https://doi.org/10.1016/j.ins.2019.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The receptive fields in the Human Visual System (HVS) are organized in such a way that they not merely capture information on the photoreceptor’s exposition to light but also on the differences in firing rates of their center and surround cells. This organization can be related with the human’s ability to cope with the high dynamic range of natural scenes. As a way to mimic this behavior E. Land proposed in 1986 a perception model consisting in two steps, namely, a local adaptation followed by a global transform. This model gave rise to the so-called Center/Surround tone-mapping algorithms, which are used to map the intensity values of high dynamic range (HDR) images to the limited range of displayable images (typically using 8-bits per channel). In this paper we unify the different Center/Surround algorithms proposed in the literature using a common framework and analyze several possibilities for the local and global operations involved. We accompany our study with quantitative and qualitative results that permit us to suggest the best pair of local/global transforms for a Center/Surround method.},
  archive      = {J_ISCI},
  author       = {Jose-Luis Lisani and Jean-Michel Morel and Ana-Belen Petro and Catalina Sbert},
  doi          = {10.1016/j.ins.2019.10.009},
  journal      = {Information Sciences},
  pages        = {741-759},
  shortjournal = {Inf. Sci.},
  title        = {Analyzing center/surround retinex},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structured subspace embedding on attributed networks.
<em>ISCI</em>, <em>512</em>, 726–740. (<a
href="https://doi.org/10.1016/j.ins.2019.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed network embedding aims to learn low-dimensional node vector representations in the network. To date, the primary strategy of the existing approaches is to combine topological structure with attribute information based on the homophily assumption imposed on the whole attributed networks. However, this strategy ignores the formation of community structure driven by different subspaces of attributes. In fact, (1) not all attributes are relevant to the formation of clusters; (2) the generating mechanisms of different clusters may depend on distinct relevant attributes. Therefore, we propose a new network embedding method in this paper, called Structured Subspace Embedding (SSE), to learn a compact low-dimensional vector representation. We wish to consider the cluster structure in subspaces of attributes, which reflects the different generating mechanisms of cluster structure. To this end, the attribute matrix is first represented as a latent feature representation via matrix factorization . Afterward, the local homophily constraint between network topological structure and latent feature representation is imposed. Finally, the community-selection constraint is added to further ensure the latent feature representation has a subspace cluster structure via sparse representation . Extensive experimental results on real-world networks have demonstrated its superiority on both tasks of community detection and node classification over many state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Zhongjing Yu and Zhong Zhang and Haoran Chen and Junming Shao},
  doi          = {10.1016/j.ins.2019.10.015},
  journal      = {Information Sciences},
  pages        = {726-740},
  shortjournal = {Inf. Sci.},
  title        = {Structured subspace embedding on attributed networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Making use of observable parameters in evolutionary dynamic
optimization. <em>ISCI</em>, <em>512</em>, 708–725. (<a
href="https://doi.org/10.1016/j.ins.2019.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In evolutionary dynamic optimization (EDO), most of the existing studies have assumed that dynamic optimization problems are black boxes. However, for many real-world problems, the dynamic parameters that cause the problems to change are observable. However, determining the utility of these parameters in improving optimization performance has not yet been well studied. In this paper, we propose and compare three strategies for this task: rote learning, fitting data with a feedforward neural network and an ensemble strategy. The main idea of these strategies is to learn the relation between the observable parameters and the optimal solutions and then predict new optima once the environment changes. We also propose a set of test cases representing different kinds of characteristics of real-world problems. In the experiments, the proposed strategies are compared with existing methods that do not use observable parameters, and the results validate our proposed strategies.},
  archive      = {J_ISCI},
  author       = {Tao Zhu and Wenjian Luo and Chenyang Bu and Huansheng Ning},
  doi          = {10.1016/j.ins.2019.10.024},
  journal      = {Information Sciences},
  pages        = {708-725},
  shortjournal = {Inf. Sci.},
  title        = {Making use of observable parameters in evolutionary dynamic optimization},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rapid compressed sensing reconstruction: A semi-tensor
product approach. <em>ISCI</em>, <em>512</em>, 693–707. (<a
href="https://doi.org/10.1016/j.ins.2019.09.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large-scale applications of compressed sensing (CS), the time cost to reconstruct the original signal is too high. To accelerate the reconstruction and reduce the space cost of the measurement matrix , a novel parallel reconstruction approach based on a semi-tensor product (STP) is proposed. A low-dimensional random matrix where the dimensions are 1/4 (or 1/16, 1/64, 1/256, 1/1024 or even 1/4096) that of conventional CS is generated to sample the original data, and then a parallel reconstruction method is proposed to obtain the solution with the iteratively re-weighted least-squares (IRLS) algorithm. The peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and time cost of reconstruction were evaluated and compared with matrices of different dimensions, and comparisons were also conducted with other state-of-the-art methods. Numerical results show that the speed can be effectively improved (10×, or 100×, even 1000×) and the storage space of the matrix can also be remarkably reduced; that is, the matrix can be 1/4096 of conventional CS. Furthermore, the numerical results show that our formulation outperforms conventional CS in speed of reconstruction and in its comparable quality, which is important for real-time and physical implementation of applications.},
  archive      = {J_ISCI},
  author       = {Jinming Wang and Zhenyu Xu and Zhangquan Wang and Sen Xu and Jun Jiang},
  doi          = {10.1016/j.ins.2019.09.071},
  journal      = {Information Sciences},
  pages        = {693-707},
  shortjournal = {Inf. Sci.},
  title        = {Rapid compressed sensing reconstruction: A semi-tensor product approach},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-pass hashing feature representation and searching method
for copy-move forgery detection. <em>ISCI</em>, <em>512</em>, 675–692.
(<a href="https://doi.org/10.1016/j.ins.2019.09.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a two-pass hashing feature representation and searching method for copy-move forgery detection with a good score and high efficiency. First, the normalized moment transformation is presented to extract the corresponding block features from multiple frequency images. The multiple-dimensional features of each pixel are projected into the corresponding hashing bin to obtain the corresponding hashing features. Then, a novel two-pass hashing feature representation is proposed to concatenate multiple hashing features as the bit sequence. Based on the two-pass hashing feature representations, the two-pass hashing searching algorithm searches and updates the nearest pixel matches in high efficiency. Finally, post-processing operations are proposed to accurately identify the forgery regions. The experimental results show that the proposed copy-move forgery detection method can achieve the best scores among the state-of-the-art methods, even under various attacks. In addition, the proposed method has a very high detection efficiency without iterations.},
  archive      = {J_ISCI},
  author       = {Zhong Jun-Liu and Pun Chi-Man},
  doi          = {10.1016/j.ins.2019.09.085},
  journal      = {Information Sciences},
  pages        = {675-692},
  shortjournal = {Inf. Sci.},
  title        = {Two-pass hashing feature representation and searching method for copy-move forgery detection},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A non-revisiting genetic algorithm based on a novel binary
space partition tree. <em>ISCI</em>, <em>512</em>, 661–674. (<a
href="https://doi.org/10.1016/j.ins.2019.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most popular evolutionary algorithms for solving complex optimization problems , genetic algorithm has been extensively studied in the last three decades. Since genetic algorithm is a stochastic algorithm that may revisit duplicated solutions, it could suffer from low convergence speed on some real-world problems making algorithms likely to get trapped into local optimums. To address this issue, this paper proposes a non-revisiting genetic algorithm with a novel binary space partition (BSP) tree. The proposed BSP tree records all the generated solutions, which enables the algorithm to quickly determine whether a newly generated solution is duplicated or not. Moreover, the proposed algorithm fine-tunes the solutions according to the topology of the BSP tree in each generation, and thus can improve the population diversity and convergence speed. In comparison to six representative evolutionary algorithms , the proposed non-revisiting genetic algorithm exhibits better overall performance on eight benchmark problems, the power system fault diagnosis problem, and the molecular signatures selection problem.},
  archive      = {J_ISCI},
  author       = {Yansen Su and Neng Guo and Ye Tian and Xingyi Zhang},
  doi          = {10.1016/j.ins.2019.10.016},
  journal      = {Information Sciences},
  pages        = {661-674},
  shortjournal = {Inf. Sci.},
  title        = {A non-revisiting genetic algorithm based on a novel binary space partition tree},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to securely outsource the extended euclidean algorithm
for large-scale polynomials over finite fields. <em>ISCI</em>,
<em>512</em>, 641–660. (<a
href="https://doi.org/10.1016/j.ins.2019.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing gives resource-constrained clients great conveniences to outsource exorbitant computations to a public cloud. The extended Euclidean algorithm with large-scale polynomials over finite fields is fundamental and widespread in computer science and cryptography, yet it is computationally overloaded for quantities of lightweight devices emerged with the dawn of internet of things (IoT). In this respect, we design an efficient outsourcing algorithm that enables a lightweight client to achieve this heavy computation with the assistance of a remote cloud server. By comprehensively employing the variable substitution, random polynomial-based blind technique and unimodular matrix transformation , our algorithm achieves the goals of cheating resistance, privacy preservation , and high efficiency. Concretely, our algorithm is based on single untrusted program model which avoids the too strong security assumption between multiple servers, and it enables the client to detect the cloud’s misbehaviors with (optimal) probability 1. Also, Thorough theoretical analysis indicates that the algorithm provides robust input/output privacy. Moreover, the algorithm only needs one round interaction between the client and the cloud. Strict theoretical analysis and extensive experimental evaluations demonstrate our algorithm’s practical efficiency and effectiveness. Finally, an important application of our algorithm on securely outsourcing the expensive key generation step of NTRU cryptosystem is given.},
  archive      = {J_ISCI},
  author       = {Qiang Zhou and Chengliang Tian and Hanlin Zhang and Jia Yu and Fengjun Li},
  doi          = {10.1016/j.ins.2019.10.007},
  journal      = {Information Sciences},
  pages        = {641-660},
  shortjournal = {Inf. Sci.},
  title        = {How to securely outsource the extended euclidean algorithm for large-scale polynomials over finite fields},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fully scalable big data framework for botnet detection
based on network traffic analysis. <em>ISCI</em>, <em>512</em>, 629–640.
(<a href="https://doi.org/10.1016/j.ins.2019.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many traditional Botnet detection methods have trouble scaling up to meet the needs of multi-Gbps networks. This scalability challenge is not just limited to bottlenecks in the detection process, but across all individual components of the Botnet detection system including data gathering, storage, feature extraction, and analysis. In this paper, we propose a fully scalable big data framework that enables scaling for each individual component of Botnet detection. Our framework can be used with any Botnet detection method - including statistical methods, machine learning methods, and graph-based methods. Our experimental results show that the proposed framework successfully scales in live tests on a real network with 5Gbps of traffic throughput and 50 millions IP addresses visits. In addition, our run time scales logarithmically with respect to the volume of the input for example, when the scale of the input data multiplies by 4 × , the total run time increases by only 31\%. This is significant improvement compared to schemes such as Botcluster in which run time increases by 86\% under similar scale condition.},
  archive      = {J_ISCI},
  author       = {S.H. Mousavi and M. Khansari and R. Rahmani},
  doi          = {10.1016/j.ins.2019.10.018},
  journal      = {Information Sciences},
  pages        = {629-640},
  shortjournal = {Inf. Sci.},
  title        = {A fully scalable big data framework for botnet detection based on network traffic analysis},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intrusion-resilient public cloud auditing scheme with
authenticator update. <em>ISCI</em>, <em>512</em>, 616–628. (<a
href="https://doi.org/10.1016/j.ins.2019.09.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key-exposure resilient cloud storage auditing can create a secure cloud storage during before and after the key-exposure period. However, the malicious cloud server can still tamper with and even discard the client’s files which are uploaded during the key-exposure period without being detected. So as to cope with this problem, we propose an intrusion-resilient public cloud auditing scheme, in which auditing authenticators are updated periodically to prevent the malicious cloud from tampering with these files using the exposed key. In addition, our scheme is secure unless the client and TPA (Third Party Auditor) are compromised in the same time period. This is different from Yu et al.’s scheme proposed in TIFS 2017, which is not secure if the client and TPA are compromised in different periods. Finally, the scheme can protect the client’s file privacy, and prevent a curious TPA from recovering the file. The security analysis and the results of the experiment indicate that the security and performance of the scheme are acceptable.},
  archive      = {J_ISCI},
  author       = {Yan Xu and Song Sun and Jie Cui and Hong Zhong},
  doi          = {10.1016/j.ins.2019.09.080},
  journal      = {Information Sciences},
  pages        = {616-628},
  shortjournal = {Inf. Sci.},
  title        = {Intrusion-resilient public cloud auditing scheme with authenticator update},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parsimonious generalization of fuzzy thematic sets in
taxonomies applied to the analysis of tendencies of research in data
science. <em>ISCI</em>, <em>512</em>, 595–615. (<a
href="https://doi.org/10.1016/j.ins.2019.09.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel method, referred to as ParGenFS, for finding a most specific generalization of a query set represented by a fuzzy set of topics assigned to leaves of the rooted tree of a taxonomy. The query set is generalized by “lifting” it to one or more “head subjects” in the higher ranks of the taxonomy. The head subjects should cover the query set, with the possible addition of some “gaps”, taxonomy nodes covered by the head subject but irrelevant to the query set. To decrease the numbers of gaps, we admit some “offshoots”, nodes belonging to the query set but not covered by a head subject. The method globally minimizes the total number of head subjects, gaps and offshoots, each suitably weighted. Our algorithm is applied to the structural analysis and description of a collection of 17,685 abstracts of research papers published in 17 Springer journals related to Data Science for the 20-year period 1998–2017. Our taxonomy of Data Science (TDS) is extracted from the Association for Computing Machinery Computing Classification System 2012 (ACM-CCS), a six-level hierarchical taxonomy manually developed by a team of ACM experts. The TDS also includes a number of additional leaves that we added to cater for recent developments not represented in the ACM-CCS taxonomy. We find fuzzy clusters of leaf topics over the text collection, using specially developed machinery. Three of the clusters are indeed thematic, relating to the Data Science sub-areas of (a) learning, (b) information retrieval, and (c) clustering. These three clusters are then lifted in the TDS using ParGenFS, which allows us to draw some conclusions about tendencies in developments in these areas.},
  archive      = {J_ISCI},
  author       = {Dmitry Frolov and Susana Nascimento and Trevor Fenner and Boris Mirkin},
  doi          = {10.1016/j.ins.2019.09.082},
  journal      = {Information Sciences},
  pages        = {595-615},
  shortjournal = {Inf. Sci.},
  title        = {Parsimonious generalization of fuzzy thematic sets in taxonomies applied to the analysis of tendencies of research in data science},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constrained relational topic models. <em>ISCI</em>,
<em>512</em>, 581–594. (<a
href="https://doi.org/10.1016/j.ins.2019.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relational topic models (RTM) have been widely used to discover hidden topics in a collection of networked documents. In this paper, we introduce the class of Constrained Relational Topic Models (CRTM), a semi-supervised extension of RTM that, apart from modeling the structure of the document network, explicitly models some available domain knowledge. We propose two instances of CRTM that incorporate prior knowledge in the form of document constraints. The models smooth the probability distribution of topics such that two constrained documents can either share the same topics or denote distinct themes. Experimental results on benchmark relational datasets show significant performances of CRTM on a semi-supervised document classification task .},
  archive      = {J_ISCI},
  author       = {Silvia Terragni and Elisabetta Fersini and Enza Messina},
  doi          = {10.1016/j.ins.2019.09.039},
  journal      = {Information Sciences},
  pages        = {581-594},
  shortjournal = {Inf. Sci.},
  title        = {Constrained relational topic models},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tensor-based mathematical framework and new centralities for
temporal multilayer networks. <em>ISCI</em>, <em>512</em>, 563–580. (<a
href="https://doi.org/10.1016/j.ins.2019.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although networks provide a powerful methodology to study a variety of real-world and engineered systems, their current formulation does not typically account for multiple interaction types that vary in space and time, or address interconnected systems such as networks of networks. Unavoidably, ignoring time-dependence and multiple interactions of topological structures might lead to important temporal and structural information loss and may obscure the actual organization. To achieve a deep understanding of the time-varying and interconnected complex networked systems, in this paper, we develop a more general mathematical model , referred to as a temporal multilayer network, which explicitly incorporates time-dependence and multiple relationships of topological structures into a system, and provides a natural and reasonable description for real-world complex systems. Furthermore, using a fifth-order tensorial framework to represent temporal multilayer networks, we generalize four important topological metrics, including overlapping degree, entropy, degree correlation and link overlap, to quantitatively evaluate the temporal multilayer networks. In particular, based on the tensorial framework, we propose two iterative refinement centralities for temporal multilayer networks, referred to as TM-eigenvector and TM-PageRank centralities, which are used to quantitatively evaluate the importance of nodes in real-world complex systems. Moreover, we use the theory of multilinear algebra and matrix analysis to strictly prove the convergence of these iterative algorithms . The proposed mathematical frameworks are validated using two real-world temporal multilayer networked systems related to complex diseases, i.e., influenza and heart diseases.},
  archive      = {J_ISCI},
  author       = {Dingjie Wang and Wei Yu and Xiufen Zou},
  doi          = {10.1016/j.ins.2019.09.056},
  journal      = {Information Sciences},
  pages        = {563-580},
  shortjournal = {Inf. Sci.},
  title        = {Tensor-based mathematical framework and new centralities for temporal multilayer networks},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of influencers in complex networks by local
information dimensionality. <em>ISCI</em>, <em>512</em>, 549–562. (<a
href="https://doi.org/10.1016/j.ins.2019.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of influential spreaders in complex networks is a popular topic in studies of network characteristics. Many centrality measures have been proposed to address this problem, but most have limitations. In this paper, a method for identifying influencers in complex networks via the local information dimensionality is proposed. The proposed method considers the local structural properties around the central node; therefore, the scale of locality only increases to half of the maximum value of the shortest distance from the central node. Thus, the proposed method considers the quasilocal information and reduces the computational complexity . The information (number of nodes) in boxes is described via the Shannon entropy , which is more reasonable. A node is more influential when its local information dimensionality is higher. In order to show the effectiveness of the proposed method, five existing centrality measures are used as comparison methods to rank influential nodes in six real-world complex networks. In addition, a susceptible–infected (SI) model and Kendall’s tau coefficient are applied to show the correlation between different methods. Experiment results show the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Tao Wen and Yong Deng},
  doi          = {10.1016/j.ins.2019.10.003},
  journal      = {Information Sciences},
  pages        = {549-562},
  shortjournal = {Inf. Sci.},
  title        = {Identification of influencers in complex networks by local information dimensionality},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A local search algorithm with reinforcement learning based
repair procedure for minimum weight independent dominating set.
<em>ISCI</em>, <em>512</em>, 533–548. (<a
href="https://doi.org/10.1016/j.ins.2019.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum weight independent dominating set problem (MWIDS) is a famous NP-hard combinatorial optimization problem . We herein propose a local search algorithm with reinforcement-learning-based repair procedure (LSRR). The proposed algorithm combines local search with repair procedure based on the mind of reinforcement learning . This algorithm iterates through three procedures: the greedy procedure to improve the initial solution, the local search procedure to further improve the solution, and the repair procedure to destroy the initial solution and then reconstruct a new solution. In addition, because of the particularity of the weight functions in all benchmarks, we propose three novel scoring functions. Experiments are performed on two types of graphs including random graphs and random geometric graphs . Experimental results display that LSRR outperforms the previous MWIDS algorithms significantly.},
  archive      = {J_ISCI},
  author       = {Yiyuan Wang and Shiwei Pan and Chenxi Li and Minghao Yin},
  doi          = {10.1016/j.ins.2019.09.059},
  journal      = {Information Sciences},
  pages        = {533-548},
  shortjournal = {Inf. Sci.},
  title        = {A local search algorithm with reinforcement learning based repair procedure for minimum weight independent dominating set},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ensemble method for inverse reinforcement learning.
<em>ISCI</em>, <em>512</em>, 518–532. (<a
href="https://doi.org/10.1016/j.ins.2019.09.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In inverse reinforcement learning (IRL), a reward function is learnt to generalize experts’ behavior. This paper proposes a model-free IRL algorithm based on an ensemble method , where the reward function is regarded as a parametric function of expected features. In other words, the parameters are updated based on a weak classification method. The IRL is formulated as a problem of a boosting classifier, akin to the renowned Adaboost algorithm for classification, feature expectations from experts’ demonstration, and the trajectory induced by an agent&#39;s current policy. The proposed approach takes individual feature expectation as attractor or expeller, depending on the sign of the residuals of the state trajectories between expert&#39;s demonstration and the one induced by RL with the currently approximated reward function, so as to tackle its central challenges of accurate inference, generalizability , and correctness of prior knowledge. Then, the proposed method is applied further to approximate an abstract reward function from observations of more complex behavior composed of several basic actions. The results of the simulations in a labyrinth are shown to validate the proposed algorithm. Furthermore, behaviors composed of a set of primitive actions on a soccer robot field are examined for the applicability of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jin-Ling Lin and Kao-Shing Hwang and Haobin Shi and Wei Pan},
  doi          = {10.1016/j.ins.2019.09.066},
  journal      = {Information Sciences},
  pages        = {518-532},
  shortjournal = {Inf. Sci.},
  title        = {An ensemble method for inverse reinforcement learning},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LSC: Online auto-update smart contracts for fortifying
blockchain-based log systems. <em>ISCI</em>, <em>512</em>, 506–517. (<a
href="https://doi.org/10.1016/j.ins.2019.09.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart contracts allow verifiable operations to be executed in blockchains , bringing new possibilities for trust establishment in trustless scenarios. However, smart contracts are cumbersome when used as security mechanisms in security scenarios due to two reasons: they have limited power and are inert to changes . In order to mitigate the two problems of employed smart contracts, we propose LSC, a framework for online auto-update smart contracts in blockchain-based log systems, to enable self-adaptive log anomaly detection via smart contracts. Time-varying log anomaly detection patterns are extracted by self-adaptive machine learning log anomaly analysis and are continuously fed to the contracts. The framework allows smart contracts to be automatically updated to express the patterns in low-cost ways. The anomaly detection strategies for audit log systems are shared and collaboratively enforced amongst network nodes to defend against targeted detection evasion. We provide a plain prototype as a proof of the feasibility and efficiency of LSC in log systems.},
  archive      = {J_ISCI},
  author       = {Wei Shao and Zhi Wang and Xiaolu Wang and Kefan Qiu and Chunfu Jia and Chong Jiang},
  doi          = {10.1016/j.ins.2019.09.073},
  journal      = {Information Sciences},
  pages        = {506-517},
  shortjournal = {Inf. Sci.},
  title        = {LSC: Online auto-update smart contracts for fortifying blockchain-based log systems},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PAC: A novel self-adaptive neuro-fuzzy controller for micro
aerial vehicles. <em>ISCI</em>, <em>512</em>, 481–505. (<a
href="https://doi.org/10.1016/j.ins.2019.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There exists an increasing demand for a flexible and computationally efficient controller for micro aerial vehicles (MAVs) due to a high degree of environmental perturbations. In this work, an evolving neuro-fuzzy controller, namely Parsimonious Controller (PAC) is proposed. It features fewer network parameters than conventional approaches due to the absence of rule premise parameters. PAC is built upon a recently developed evolving neuro-fuzzy system known as parsimonious learning machine (PALM) and adopts new rule growing and pruning modules derived from the approximation of bias and variance. These rule adaptation methods have no reliance on user-defined thresholds, thereby increasing the PAC’s autonomy for real-time deployment. PAC adapts the consequent parameters with the sliding mode control (SMC) theory in the single-pass fashion. The boundedness and convergence of the closed-loop control system’s tracking error and the controller’s consequent parameters are confirmed by utilizing the LaSalle–Yoshizawa theorem. Lastly, the controller’s efficacy is evaluated by observing various trajectory tracking performance from a bio-inspired flapping wing micro aerial vehicle (BI-FWMAV) and a rotary wing micro aerial vehicle called hexacopter. Furthermore, it is compared to three distinctive controllers. Our PAC outperforms the linear PID controller and feed-forward neural network (FFNN) based nonlinear adaptive controller . Compared to its predecessor, G-controller, the tracking accuracy is comparable, but the PAC incurs significantly fewer parameters to attain similar or better performance than the G-controller.},
  archive      = {J_ISCI},
  author       = {Md Meftahul Ferdaus and Mahardhika Pratama and Sreenatha G. Anavatti and Matthew A. Garratt and Edwin Lughofer},
  doi          = {10.1016/j.ins.2019.10.001},
  journal      = {Information Sciences},
  pages        = {481-505},
  shortjournal = {Inf. Sci.},
  title        = {PAC: A novel self-adaptive neuro-fuzzy controller for micro aerial vehicles},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient digital signatures from RSA without random
oracles. <em>ISCI</em>, <em>512</em>, 471–480. (<a
href="https://doi.org/10.1016/j.ins.2019.09.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving efficiency of digital signature scheme is important since digital signature scheme is a core building block for many privacy protocols. There are some proposals regarding efficient digital signatures whose security arguments are guaranteed by the standard assumption such as RSA assumption. Although several RSA-based digital signature schemes achieve a short signature size, many of them essentially rely on random oracle heuristics. In 2009, Hohenberger and Water proposed an excellent approach to the design of a short RSA-based signature scheme without random oracles (CRYPTO 2009). However, their scheme requires signers to execute an expensive prime-number generation several times, and leaves the reduction in signing and verifying costs as important open problems. In this paper, we propose an efficient digital signature scheme from the above category. That is, we propose a short RSA signature scheme in the standard model, which requires less prime-number generations than those in the previous best scheme of Böhl, Hofheinz, Jager, Koch, and Striecks (Journal of Cryptology 2015). More precisely, the BHJKS scheme requires signers to generate O (log λ ) prime-numbers for each signature; however, our scheme requires almost a constant time (e.g., log log λ ) of prime-number generation in the signing algorithm, where λ is the security parameter.},
  archive      = {J_ISCI},
  author       = {Jae Hong Seo},
  doi          = {10.1016/j.ins.2019.09.084},
  journal      = {Information Sciences},
  pages        = {471-480},
  shortjournal = {Inf. Sci.},
  title        = {Efficient digital signatures from RSA without random oracles},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive hybrid evolutionary immune multi-objective
algorithm based on uniform distribution selection. <em>ISCI</em>,
<em>512</em>, 446–470. (<a
href="https://doi.org/10.1016/j.ins.2019.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In general, for the iteration process of an evolutionary algorithm (EA), there exists the problem of uneven distribution of individuals in the target space for both multi-objective and single-objective optimization problems. This uneven distribution significantly degrades the population diversity and convergence speed. This paper proposes an adaptive hybrid evolutionary immune algorithm based on a uniform distribution selection mechanism (AUDHEIA) for solving MOPs efficiently. In AUDHEIA, the individuals in the population are mapped to a hyperplane, which is correlated with the objective space and are clustered to increase the diversity of solutions. To improve the distribution of the solutions, the mapped hyperplane is evenly sectioned. With the constantly changing distribution during the iteration, a threshold as a standard for judging the distribution level is adjusted adaptively. When the threshold is not satisfied in the corresponding interval, the distribution enhancement module is activated. Then, the same number of individuals should be selected in each interval. However, sometimes, there are insufficient or no individuals in the interval during the iterative process. To obtain sufficient individuals, the limit optimization variation strategy of the best individual is adopted. Experiments show that this algorithm can escape from local optima and has a high convergence speed. Moreover, the distribution and convergence of this algorithm are superior to the peer algorithms tested in this paper.},
  archive      = {J_ISCI},
  author       = {Qiao Junfei and Li Fei and Yang Shengxiang and Yang Cuili and Li Wenjing and Gu Ke},
  doi          = {10.1016/j.ins.2019.08.032},
  journal      = {Information Sciences},
  pages        = {446-470},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive hybrid evolutionary immune multi-objective algorithm based on uniform distribution selection},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). H∞ bumpless transfer reliable control of markovian switching
LPV systems subject to actuator failures. <em>ISCI</em>, <em>512</em>,
431–445. (<a href="https://doi.org/10.1016/j.ins.2019.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the H ∞ bumpless transfer reliable control problem of Markovian switching linear parameter-varying (LPV) systems subject to actuator failures is addressed. A bumpless transfer reliable control constraint is introduced to describe the transient performance for such systems. By the use of the parameter-dependent Lyapunov function approach to reduce control bumps generated by the Markovian switching, a reliable switching controller which is also parameter-dependent is constructed to attenuate external disturbances . A criterion checking the solvability of the H ∞ bumpless transfer reliable control problem is provided. As an application, a turbofan-engine model is used to verify the validity of the proposed design method.},
  archive      = {J_ISCI},
  author       = {Dong Yang and Guangdeng Zong and Sing Kiong Nguang},
  doi          = {10.1016/j.ins.2019.07.059},
  journal      = {Information Sciences},
  pages        = {431-445},
  shortjournal = {Inf. Sci.},
  title        = {H∞ bumpless transfer reliable control of markovian switching LPV systems subject to actuator failures},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Face hallucination via multiple feature learning with
hierarchical structure. <em>ISCI</em>, <em>512</em>, 416–430. (<a
href="https://doi.org/10.1016/j.ins.2019.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, neighbor-embedding (NE) based methods have been widely exploited for face hallucination. However, the existing NE based methods in spatial domain just employ single type of features for data representation, ignoring the compensatory information among multiple image features , resulting in bias in high resolution (HR) face image reconstruction. To tackle such problem, this paper presents a novel Multiple feature Learning model with Hierarchical Structure (MLHS) for face hallucination. Compared with conventional NE based methods, the proposed MLHS makes full use of multi-level information of face images, which can effectively remedy the flaw caused by just using single type of spatial pixel features, and adopts hierarchical structure to better maintain the manifold consistency hypothesis between the HR and low resolution (LR) patch spaces. The multiple learning strategy and hierarchical structure admit the proposed MLHS to well reconstruct the face details such as eyes, nostrils and mouth. The validity of the proposed MLHS method is confirmed by the comparison experiments in some public face databases.},
  archive      = {J_ISCI},
  author       = {Licheng Liu and Han Liu and Shutao Li and C. L. Philip Chen},
  doi          = {10.1016/j.ins.2019.06.017},
  journal      = {Information Sciences},
  pages        = {416-430},
  shortjournal = {Inf. Sci.},
  title        = {Face hallucination via multiple feature learning with hierarchical structure},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparsity in function and derivative approximation via the
empirical feature space. <em>ISCI</em>, <em>512</em>, 402–415. (<a
href="https://doi.org/10.1016/j.ins.2019.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several practical applications require estimation of the values of a function and its derivative at specific sample locations.This is a challenging task particularly when the explicit forms of the function and its derivative are not known. There have been a few methods proposed in the literature to learn an approximant that simultaneously uses values of a function as well as values of its derivatives or partial derivatives. These methods typically use Support Vector Regression (SVR) and solve a Quadratic Programming Problem (QPP) for the task, which results in a learning model that can estimate the function and derivative values. In this paper, we propose an alternative novel approach that focuses on introducing sparsity in such a learning model, that is based on minimizing the model complexity in the Empirical Feature Space (EFS). Sparsity in such a model is useful when it needs to be evaluated a large number of times as it entails lower computational cost compared to a dense model. The proposed approach, called the EFSRD (EFS Regression for Function and Derivative approximation), involves solving a Linear Programming Problem (LPP). On a number of benchmark examples, EFSRD learns models that offer comparable or better performance, while learning models that are nearly a fourth the size of those obtained by existing approaches.},
  archive      = {J_ISCI},
  author       = {Sumit Soman and Jayadeva and Rajat Thakur and Mayank Sharma and Suresh Chandra},
  doi          = {10.1016/j.ins.2019.06.034},
  journal      = {Information Sciences},
  pages        = {402-415},
  shortjournal = {Inf. Sci.},
  title        = {Sparsity in function and derivative approximation via the empirical feature space},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smoothed self-organizing map for robust clustering.
<em>ISCI</em>, <em>512</em>, 381–401. (<a
href="https://doi.org/10.1016/j.ins.2019.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a Self-Organizing Map (SOM) robust to the presence of outliers, the Smoothed SOM (S-SOM), is proposed. S-SOM improves the properties of input density mapping, vector quantization , and clustering of the standard SOM in the presence of outliers by upgrading the learning rule in order to smooth the representation of outlying input vectors onto the map. The upgrade of the learning rule is based on the complementary exponential distance between the input vector and its closest codebook. The convergence of the S-SOM to a stable state is proved. Three comparative simulation studies and a suggestive application to digital innovation data show the robustness and effectiveness of the proposed S-SOM. Supplementary materials for this article are available.},
  archive      = {J_ISCI},
  author       = {Pierpaolo D’Urso and Livia De Giovanni and Riccardo Massari},
  doi          = {10.1016/j.ins.2019.06.038},
  journal      = {Information Sciences},
  pages        = {381-401},
  shortjournal = {Inf. Sci.},
  title        = {Smoothed self-organizing map for robust clustering},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust face hallucination via locality-constrained
multiscale coding. <em>ISCI</em>, <em>512</em>, 369–380. (<a
href="https://doi.org/10.1016/j.ins.2019.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face hallucination (FH) is to produce face images with High Resolution (HR) from Low Resolution (LR) observations. Unfortunately, most existing FH methods fail to make full use of the local geometrical information, especially when the LR images are corrupted by noise. Inspired by the observation that regions with large scales can provide much useful information, in this paper we propose a Robust Locality-constrained Multiscale Coding (RLMC) based method to forecast HR face images while suppressing noise and outliers. In RLMC, a weight vector is used in the loss function to ease the effect of outliers in data representation. Furthermore, inspired by the observation that abundant local information can be exploited by jointly representing overlapping patches with multiple scales. Simultaneously encoding multiple scale patches encourages different scales to share complementary information, which admits the proposed method to generate more appropriate coefficients for super-resolution reconstruction. Experimental results verified the effectiveness of the proposed method in terms of both quantitative measurements and visual impressions.},
  archive      = {J_ISCI},
  author       = {Na Li and Licheng Liu and Shutao Li and Hui Lin},
  doi          = {10.1016/j.ins.2019.06.041},
  journal      = {Information Sciences},
  pages        = {369-380},
  shortjournal = {Inf. Sci.},
  title        = {Robust face hallucination via locality-constrained multiscale coding},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Note on entropies of hesitant fuzzy linguistic term sets and
their applications. <em>ISCI</em>, <em>512</em>, 352–368. (<a
href="https://doi.org/10.1016/j.ins.2019.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hesitant fuzzy linguistic term set (HFLTS) is very useful in depicting the situations where people are hesitant to provide their opinions or assessments. In a HFLTS, it should be considered two types of uncertainty, fuzziness and hesitation. This paper is aimed to investigate the problem of how apply different uncertainty facets in different decision making settings. First, a new construction method of a fuzzy entropy for HFLTSs is proposed and it is compared with other methods already introduced in the literatures. Afterwards, these entropy formulas are used to propose two algorithms for deriving the criteria weights and experts weights. Different from the existing applications, it is stressed that in the process of deriving the criteria weights, only the hesitancy of the HFLTS should be considered, while in the process of deriving the experts weights with hesitant fuzzy preference relation information, both the fuzziness and hesitancy of the evaluation information should be involved.},
  archive      = {J_ISCI},
  author       = {Cuiping Wei and Rosa M. Rodríguez and Peng Li},
  doi          = {10.1016/j.ins.2019.06.018},
  journal      = {Information Sciences},
  pages        = {352-368},
  shortjournal = {Inf. Sci.},
  title        = {Note on entropies of hesitant fuzzy linguistic term sets and their applications},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-time containment control for nonlinear multi-agent
systems with external disturbances. <em>ISCI</em>, <em>512</em>,
338–351. (<a href="https://doi.org/10.1016/j.ins.2019.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the finite-time containment control for a second-order nonlinear multi-agent system in the presence of external disturbances . First, two finite-time containment control protocols are skillfully developed, of which one is based on a terminal sliding mode and the other is based on a non-singular terminal sliding mode. Second, criteria for designing desired containment control protocols are derived such that the containment performance of the resulting closed-loop leader-following multi-agent system can be guaranteed within a finite time horizon. It is shown that the settling time of the closed-loop system convergence can be estimated under the proposed protocols. Furthermore, finite-time containment control in the scenario of general switching and directed topology is also addressed and the corresponding result is derived. Finally, three illustrative examples are given to verify the effectiveness of the proposed finite-time containment control method .},
  archive      = {J_ISCI},
  author       = {Hui Lü and Wangli He and Qing-Long Han and Xiaohua Ge and Chen Peng},
  doi          = {10.1016/j.ins.2019.05.049},
  journal      = {Information Sciences},
  pages        = {338-351},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time containment control for nonlinear multi-agent systems with external disturbances},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal performance of LTI systems over power constrained
erasure channels. <em>ISCI</em>, <em>512</em>, 327–337. (<a
href="https://doi.org/10.1016/j.ins.2019.05.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the optimal performance of multiple-input multi-output (MIMO) linear time-invariant (LTI) plant is investigated. The communication channel is modeled as a power constrained channel with packet dropouts . The covariance of error signal between reference input and system’s output is chosen as the performance index. Based on the frequency domain analysis method, the exact expressions of the tracking performance limitation are derived. The results reveal that the best performance of NCSs not only has strong connection with both the nonminimum phase zeros and unstable poles of the plant, but also has close relation with the essential feature of reference input signal and communication parameters. Finally, a simulation example is discussed to validate the conclusions.},
  archive      = {J_ISCI},
  author       = {Xiao-Wei Jiang and Xiang-Yong Chen and Ming Chi and Ming-Feng Ge},
  doi          = {10.1016/j.ins.2019.05.077},
  journal      = {Information Sciences},
  pages        = {327-337},
  shortjournal = {Inf. Sci.},
  title        = {Optimal performance of LTI systems over power constrained erasure channels},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting the active period of popularity evolution: A case
study on twitter hashtags. <em>ISCI</em>, <em>512</em>, 315–326. (<a
href="https://doi.org/10.1016/j.ins.2019.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The active period of popularity evolution indicates how long online content receives continuous attention from people. Although predicting popularity evolution has largely been explored, researches on predicting active period still remain open. If we know the duration of active period ahead of time, caching systems, online advertising, etc. can run more effectively. Therefore, predicting active period is of great importance, but it is a non-trivial task because of the two major challenges. First, numerous factors can influence the duration of active period. To predict active period accurately, it&#39;s difficult to consider what factors and how to embed them in DNN model. Second, the triggering time to predict different active periods must be decided carefully, because the durations of active periods differed from one another. This paper addresses these two challenges, focusing on Twitter hashtags as a case study. To deal with the first challenge, a DNN-based prediction framework is proposed, embedding dynamic and static factors by using LSTM and CNN respectively. To deal with the second challenge, an appropriate value of cumulative popularity is set to trigger predicting active period. Experimental and comparative results show the superiority of our prediction solution, comparing with spikeM and SVR .},
  archive      = {J_ISCI},
  author       = {Huang Jianyi and Tang Yuyuan and Hu Ying and Li Jianjiang and Hu Changjun},
  doi          = {10.1016/j.ins.2019.04.028},
  journal      = {Information Sciences},
  pages        = {315-326},
  shortjournal = {Inf. Sci.},
  title        = {Predicting the active period of popularity evolution: A case study on twitter hashtags},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient and accurate 3D modeling based on a novel local
feature descriptor. <em>ISCI</em>, <em>512</em>, 295–314. (<a
href="https://doi.org/10.1016/j.ins.2019.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registration is a key step in 3D modeling. In this paper, we propose an efficient and accurate 3D modeling algorithm composed of pairwise registration and multi-view registration. In pairwise registration, we propose a novel local descriptor named divisional local feature statistics (DLFS) which is generated by first dividing a local space into several partitions along projected radial direction , and then performing the statistics of one spatial and three geometrical attributes on each partition. For improving the compactness of DLFS, a principal component analysis (PCA) technique is used to compress it. Based on the compressed DLFS descriptor together with a game theoretic matching technique and two variants of ICP, the pairwise registration is efficiently and accurately performed. On this basis, a multi-view registration is performed by combining shape growing based registration technique and simultaneous registration method. In this process, a correspondence transition technique is proposed for efficiently and accurately estimating the overlap ratio between any two inputting scans. Extensive experiments are conducted to verify the performance of our algorithms. The results show that the DLFS descriptor has strong robustness, high descriptiveness and efficiency. The results also show that the proposed 3D modeling algorithm is very efficient and accurate.},
  archive      = {J_ISCI},
  author       = {Zhao Bao and Xi Juntong},
  doi          = {10.1016/j.ins.2019.04.020},
  journal      = {Information Sciences},
  pages        = {295-314},
  shortjournal = {Inf. Sci.},
  title        = {Efficient and accurate 3D modeling based on a novel local feature descriptor},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Objective reduction for visualising many-objective solution
sets. <em>ISCI</em>, <em>512</em>, 278–294. (<a
href="https://doi.org/10.1016/j.ins.2019.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualising a solution set is of high importance in many-objective optimisation. It can help algorithm designers understand the performance of search algorithms and decision makers select their preferred solution(s). In this paper, an objective reduction-based visualisation method (ORV) is proposed to view many-objective solution sets. ORV attempts to map a solution set from a high-dimensional objective space into a low-dimensional space while preserving the distribution and the Pareto dominance relation between solutions in the set. Specifically, ORV sequentially decomposes objective vectors which can be linearly represented by their positively correlated objective vectors until the expected number of preserved objective vectors is reached. ORV formulates the objective reduction as a solvable convex problem . Extensive experiments on both synthetic and real-world problems have verified the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Liangli Zhen and Miqing Li and Dezhong Peng and Xin Yao},
  doi          = {10.1016/j.ins.2019.04.014},
  journal      = {Information Sciences},
  pages        = {278-294},
  shortjournal = {Inf. Sci.},
  title        = {Objective reduction for visualising many-objective solution sets},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “recurrent neural network-based semantic
variational autoencoder for sequence-to-sequence learning” [information
sciences 490 (2019) 59-73]. <em>ISCI</em>, <em>512</em>, 277. (<a
href="https://doi.org/10.1016/j.ins.2019.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Myeongjun Jang and Seungwan Seo and Pilsung Kang},
  doi          = {10.1016/j.ins.2019.11.049},
  journal      = {Information Sciences},
  pages        = {277},
  shortjournal = {Inf. Sci.},
  title        = {Corrigendum to “Recurrent neural network-based semantic variational autoencoder for sequence-to-sequence learning” [Information sciences 490 (2019) 59-73]},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A probabilistic view on semilinear copulas. <em>ISCI</em>,
<em>512</em>, 258–276. (<a
href="https://doi.org/10.1016/j.ins.2019.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article advances the theory on multivariate upper semilinear copulas . Probabilistic features of this class are discussed and three subclasses are investigated in detail. The first subclass consists of upper semilinear copulas whose survival copulas are generalised Marshall–Olkin copulas. The second subclass is defined in that they possess identical multivariate diagonals. The third subclass is a family of extendible upper semilinear copulas. Stochastic models and analytical characterisation theorems are derived for each of these subclasses .},
  archive      = {J_ISCI},
  author       = {Henrik Sloot and Matthias Scherer},
  doi          = {10.1016/j.ins.2019.09.069},
  journal      = {Information Sciences},
  pages        = {258-276},
  shortjournal = {Inf. Sci.},
  title        = {A probabilistic view on semilinear copulas},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing privacy-aware internet of things applications.
<em>ISCI</em>, <em>512</em>, 238–257. (<a
href="https://doi.org/10.1016/j.ins.2019.09.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) applications typically collect and analyse personal data that can be used to derive sensitive information about individuals. However, thus far, privacy concerns have not been explicitly considered in software engineering processes when designing IoT applications. With the advent of behaviour driven security mechanisms, failing to address privacy concerns in the design of IoT applications can also have security implications. In this paper, we explore how a Privacy-by-Design (PbD) framework, formulated as a set of guidelines, can help software engineers integrate data privacy considerations into the design of IoT applications. We studied the utility of this PbD framework by studying how software engineers use it to design IoT applications. We also explore the challenges in using the set of guidelines to influence the IoT applications design process. In addition to highlighting the benefits of having a PbD framework to make privacy features explicit during the design of IoT applications, our studies also surfaced a number of challenges associated with the approach. A key finding of our research is that the PbD framework significantly increases both novice and expert software engineers’ ability to design privacy into IoT applications.},
  archive      = {J_ISCI},
  author       = {Charith Perera and Mahmoud Barhamgi and Arosha K. Bandara and Muhammad Ajmal and Blaine Price and Bashar Nuseibeh},
  doi          = {10.1016/j.ins.2019.09.061},
  journal      = {Information Sciences},
  pages        = {238-257},
  shortjournal = {Inf. Sci.},
  title        = {Designing privacy-aware internet of things applications},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calculus for linearly correlated fuzzy function using
fréchet derivative and riemann integral. <em>ISCI</em>, <em>512</em>,
219–237. (<a href="https://doi.org/10.1016/j.ins.2019.09.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript we study integration and derivative theories for interactive fuzzy processes. These theories are based on the Fréchet derivative and the Riemann integral. In addition, we present a connection between these two theories, i.e., some problems may be formulated in both ways. We establish the fundamental theorem of calculus , theorem of existence and the local uniqueness of the solution of fuzzy differential equations and some techniques to solve fuzzy initial value problems . To illustrate the usefulness of the developed theory, we investigate the radioactive decay model.},
  archive      = {J_ISCI},
  author       = {Francielle Santo Pedro and Estevão Esmi and Laécio Carvalho de Barros},
  doi          = {10.1016/j.ins.2019.09.078},
  journal      = {Information Sciences},
  pages        = {219-237},
  shortjournal = {Inf. Sci.},
  title        = {Calculus for linearly correlated fuzzy function using fréchet derivative and riemann integral},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inference attacks on genomic privacy with an improved HMM
and an RCNN model for unrelated individuals. <em>ISCI</em>,
<em>512</em>, 207–218. (<a
href="https://doi.org/10.1016/j.ins.2019.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the collection of large-scale genomic data for individuals has become feasible and affordable. Concurrently, several practical attacks targeting genome re-identification and genotype inference have emerged to threaten the confidentiality of genomic data sharing, leading to security and privacy concerns regarding genomic data. The authors have shown that this problem can be even worse in this paper. Specifically, two possible large-scale genotype inference attack stretegies for nonrelatives have exposed. One is based on an improved hidden Markov model (iHMM), and the other is based on a regressive convolutional neural network (RCNN). By using a genomic privacy metric combining the attacker’s incorrectness, the attacker’s uncertainty, and the genomic privacy loss of the victims, it is shown that with these atrategies, the attack can be significantly more severe than those reported previously. It is also shown that machine learning can be applied to empower large-scale inference attacks against genomic privacy.},
  archive      = {J_ISCI},
  author       = {Hongfa Ding and Youliang Tian and Changgen Peng and Youshan Zhang and Shuwen Xiang},
  doi          = {10.1016/j.ins.2019.09.036},
  journal      = {Information Sciences},
  pages        = {207-218},
  shortjournal = {Inf. Sci.},
  title        = {Inference attacks on genomic privacy with an improved HMM and an RCNN model for unrelated individuals},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive decentralized output feedback PI tracking control
design for uncertain interconnected nonlinear systems with input
quantization. <em>ISCI</em>, <em>512</em>, 186–206. (<a
href="https://doi.org/10.1016/j.ins.2019.09.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of adaptive decentralized proportional-integral (PI) tracking control is investigated for a class of interconnected nonlinear systems with input quantization and unknown functions, where the interconnection terms are bounded by completely unknown functions. By designing an input-driven filter, the unknown states are estimated and then an adaptive decentralized output feedback PI tracking controller is constructed via the backstepping method and neural network technique. The stability of the closed-loop system is addressed based on the Lyapunov function technique plus graph theory, and all the signals in the closed-loop system are uniformly ultimately bounded. Finally, simulation results are utilized to demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Haibin Sun and Guangdeng Zong and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2019.09.072},
  journal      = {Information Sciences},
  pages        = {186-206},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive decentralized output feedback PI tracking control design for uncertain interconnected nonlinear systems with input quantization},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A tree-based neural network model for biomedical event
trigger detection. <em>ISCI</em>, <em>512</em>, 175–185. (<a
href="https://doi.org/10.1016/j.ins.2019.09.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical event trigger detection is a heated research topic since its important role in biomedical event extraction . Previous studies show that syntactic features are very crucial for the task. However, existing methods largely focus on traditional statistical models, and usually capture syntactic features by extracting a set of manually-crafted features based on dependency tree. This limits the performance of the task. In this paper, we propose a tree-based neural network model, which can automatically learn syntactic features from dependency tree for trigger detection. Specifically, we use a recursive neural network to represent whole dependency tree globally, to better incorporate dependency-based syntax information. Results on MLEE and BioNLP-09 datasets show that the proposed model achieves 80.28\% and 73.24\% F1 score, respectively, outperforming traditional statistical models and neural baseline systems.},
  archive      = {J_ISCI},
  author       = {Hao Fei and Yafeng Ren and Donghong Ji},
  doi          = {10.1016/j.ins.2019.09.075},
  journal      = {Information Sciences},
  pages        = {175-185},
  shortjournal = {Inf. Sci.},
  title        = {A tree-based neural network model for biomedical event trigger detection},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clicking position and user posting behavior in online review
systems: A data-driven agent-based modeling approach. <em>ISCI</em>,
<em>512</em>, 161–174. (<a
href="https://doi.org/10.1016/j.ins.2019.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online review systems, a participant&#39;s level of knowledge impacts his/her posting behaviors, and an increase in knowledge occurs when the participant reads the reviews posted on the systems. To capture the collective dynamics of posting reviews, we used real-world big data collected over 153 months to drive an agent-based model for replicating the operation process of online review systems. The model explains the effects of clicking position (e.g., on a review webpage&#39;s serial list) and the number of items per webpage on posting contributions. Reading reviews from the last webpage only, or from the first webpage and last webpage simultaneously, can promote a greater review volume than reading reviews in other positions. This illustrates that representing primacy (first items) and recency (recent items) within one page simultaneously, or displaying recent items in reverse chronological order , are relatively better strategies for the webpage display of online reviews. The number of items plays a nonlinear moderating role in bridging the clicking position and posting behavior, and we determine the optimal number of items. To effectively establish strategies for webpage design in online review systems, business managers must switch from reliance on experience to reliance on an agent-based model as a decision support system for the formalized webpage design of online review systems.},
  archive      = {J_ISCI},
  author       = {Jiang Guoyin and Feng Xiaodong and Liu Wenping and Liu Xingjun},
  doi          = {10.1016/j.ins.2019.09.053},
  journal      = {Information Sciences},
  pages        = {161-174},
  shortjournal = {Inf. Sci.},
  title        = {Clicking position and user posting behavior in online review systems: A data-driven agent-based modeling approach},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vector partitioning quantization utilizing k-means
clustering for physical layer secret key generation. <em>ISCI</em>,
<em>512</em>, 137–160. (<a
href="https://doi.org/10.1016/j.ins.2019.09.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing key generation schemes cannot achieve the optimal performance because the quantization algorithm cannot make full use of channel information, some schemes use amplitude quantization and others use phase quantization. This paper proposes the concept of vector partitioning quantization (VPQ), and several new quantization algorithms are obtained further, which can utilize amplitude and phase at the same time. First, the traditional amplitude quantization (TAQ) and the traditional phase quantization (TPQ) are reviewed in detail. Second, the regular vector partitioning quantization (RVPQ) is proposed based on TAQ and TPQ, and the error probabilities of RVPQ is deduced, moreover, the concept of optimal RVPQ is presented. Then, three irregular vector partitioning quantization (IVPQ) algorithms are proposed which utilizes K-means clustering, including basic K-means quantization (BKQ), lossy K-means quantization (LKQ) and compensation K-means quantization (CKQ). The three K-means quantization algorithms can not only reduce the quantization error rate greatly, but also ensure the confidentiality of key generation. To overcome the problem of weak uniformity caused by K-means, we put forward the balance mechanism (BM) and apply it to three K-means quantization algorithms. Finally, the simulation results show the VPQ algorithms proposed are superior to previous methods.},
  archive      = {J_ISCI},
  author       = {Qingqing Han and Jingmei Liu and Zhiwei Shen and Jingwei Liu and Fengkui Gong},
  doi          = {10.1016/j.ins.2019.09.076},
  journal      = {Information Sciences},
  pages        = {137-160},
  shortjournal = {Inf. Sci.},
  title        = {Vector partitioning quantization utilizing K-means clustering for physical layer secret key generation},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A convolutional neural-based learning classifier system for
detecting database intrusion via insider attack. <em>ISCI</em>,
<em>512</em>, 123–136. (<a
href="https://doi.org/10.1016/j.ins.2019.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Role-based access control (RBAC) in databases provides a valuable level of abstraction to promote security administration at the business enterprise level. With the capacity for adaptation and learning, machine learning algorithms are suitable for modeling normal data access patterns based on large amounts of data and presenting robust statistical models that are not sensitive to user changes. We propose a convolutional neural-based learning classifier system (CN-LCS) that models the role of queries by combining conventional learning classifier system (LCS) with convolutional neural network (CNN) for a database intrusion detection system based on the RBAC mechanism. The combination of modified Pittsburgh-style LCSs for the optimization of feature selection rules and one-dimensional CNNs for modeling and classification in place of traditional rule generation outperforms other machine learning classifiers on a synthetic query dataset. In order to quantitatively compare the inclusion of rule generation and modeling processes in the CN-LCS, we have conducted 10-fold cross-validation tests and analysis through a paired sampled t -test.},
  archive      = {J_ISCI},
  author       = {Seok-Jun Bu and Sung-Bae Cho},
  doi          = {10.1016/j.ins.2019.09.055},
  journal      = {Information Sciences},
  pages        = {123-136},
  shortjournal = {Inf. Sci.},
  title        = {A convolutional neural-based learning classifier system for detecting database intrusion via insider attack},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A projection-based regret theory method for multi-attribute
decision making under interval type-2 fuzzy sets environment.
<em>ISCI</em>, <em>512</em>, 108–122. (<a
href="https://doi.org/10.1016/j.ins.2019.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval type-2 fuzzy sets (IT2FSs) can provide more flexibility than type-1 fuzzy sets (T1FSs) for depicting uncertain information, and multi-attribute decision making (MADM) problems with interval type-2 fuzzy information have received increasing attention. A new projection-based regret theory method is proposed to solve MADM problems under IT2FSs environments. First, a projection model of IT2FSs is defined that takes both the distance and angle information into consideration. Second, integrating the proposed projection model with regret theory, new utility and regret-rejoice functions are developed, respectively. Finally, a case study is provided to demonstrate the effectiveness of the proposed method. Sensitivity analysis shows the stability of the proposed method, and the ranking order does not change with different parameters. Comparisons are made with existing approaches to illustrate the advantage of the proposed method in reflecting decision makers’ psychological factors.},
  archive      = {J_ISCI},
  author       = {Huidong Wang and Xiaohong Pan and Jun Yan and Jinli Yao and Shifan He},
  doi          = {10.1016/j.ins.2019.09.041},
  journal      = {Information Sciences},
  pages        = {108-122},
  shortjournal = {Inf. Sci.},
  title        = {A projection-based regret theory method for multi-attribute decision making under interval type-2 fuzzy sets environment},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Robust reversible data hiding scheme based on two-layer
embedding strategy. <em>ISCI</em>, <em>512</em>, 96–107. (<a
href="https://doi.org/10.1016/j.ins.2019.09.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust reversible data hiding (RRDH) prevents the hidden secret information from unintentional modifications. This paper presents a novel RRDH scheme based on two-layer embedding with reduced capacity-distortion trade-off. The proposed scheme first decomposes the image into two planes namely higher significant bit (HSB) and least significant bit (LSB) planes and then employs prediction error expansion (PEE) to embed the secret data into the HSB plane. The high correlation of HSB plane helps in achieving high embedding capacity. Further, non-malicious attacks such as Joint Photographic Experts Group (JPEG) compression which usually changes the LSBs, will not cause any disturbance to the main contents of original image and the hidden secret data . The experimental results show that the proposed scheme has superior performance than the previous works.},
  archive      = {J_ISCI},
  author       = {Rajeev Kumar and Ki-Hyun Jung},
  doi          = {10.1016/j.ins.2019.09.062},
  journal      = {Information Sciences},
  pages        = {96-107},
  shortjournal = {Inf. Sci.},
  title        = {Robust reversible data hiding scheme based on two-layer embedding strategy},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incentive mechanism for the listing item task in
crowdsourcing. <em>ISCI</em>, <em>512</em>, 80–95. (<a
href="https://doi.org/10.1016/j.ins.2019.09.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is a new strategy of leveraging intelligence from a large number of workers to complete tasks. An incentive mechanism is an effective way for improving the quality of answers in crowdsourcing. However, a special but common type of crowdsourcing task, called listing item task, has not been fully investigated. In this paper, we focus on the incentive mechanism for this listing item task. In particular, we first provide a formal definition of this task. Then, we propose an effective incentive mechanism considering both the precision and recall of the answers. Next, we prove that the proposed mechanism is incentive-compatible and satisfies no free lunch criterion. Finally, we conduct a series of experiments on our crowdsourcing platform CrowdKnow and a public platform ZhiDao. The experimental results demonstrate that our incentive mechanism achieves a remarkable improvement for listing item tasks compared with other related mechanisms.},
  archive      = {J_ISCI},
  author       = {Shaofei Wang and Depeng Dang},
  doi          = {10.1016/j.ins.2019.09.067},
  journal      = {Information Sciences},
  pages        = {80-95},
  shortjournal = {Inf. Sci.},
  title        = {Incentive mechanism for the listing item task in crowdsourcing},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CCFR2: A more efficient cooperative co-evolutionary
framework for large-scale global optimization. <em>ISCI</em>,
<em>512</em>, 64–79. (<a
href="https://doi.org/10.1016/j.ins.2019.09.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative co-evolution (CC) is an explicit means of divide-and-conquer strategy in evolutionary algorithms for solving large-scale optimization problems . The subcomponents generated by CC may have different characteristics. When optimizing the subcomponents, the settings of the subpopulations should take the characteristics into account. CCFR is a previously published CC framework which allocates computational resources among subpopulations according to the contributions of subpopulations to the improvement of the best overall objective value. In this paper, we propose an improved version of CCFR named CCFR2, which can specify unequal-sized subpopulations for optimizing different subcomponents of variables. CCFR2 computes the average improvement of the best overall objective value per fitness evaluation as the contribution of a subpopulation, which considers the subpopulation size in the contribution computation. A control parameter is adopted by CCFR2 to balance the effects of the historical and real-time improvements of the best overall objective value on the contribution computation. Compared with CCFR, CCFR2 is able to save computational resources from obtaining the best overall solution before the evolution starts and evaluating individuals in co-evolutionary cycles. Our experimental results and analysis suggest that CCFR2 improves the performance of CCFR and is a more efficient CC framework for solving large-scale optimization problems .},
  archive      = {J_ISCI},
  author       = {Ming Yang and Aimin Zhou and Changhe Li and Jing Guan and Xuesong Yan},
  doi          = {10.1016/j.ins.2019.09.065},
  journal      = {Information Sciences},
  pages        = {64-79},
  shortjournal = {Inf. Sci.},
  title        = {CCFR2: A more efficient cooperative co-evolutionary framework for large-scale global optimization},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the f-divergence for discrete non-additive measures.
<em>ISCI</em>, <em>512</em>, 50–63. (<a
href="https://doi.org/10.1016/j.ins.2019.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the definition of the f -divergence and the Hellinger distance for non-additive measures in the discrete case. As these measures are based on the derivatives of the measures, we consider the problem of defining the Radon–Nikodym derivative of a non-additive measure. While Radon–Nikodym derivatives for additive measures exist for absolutely continuous measures, this is not the case in the non-additive case. In this paper we will define set-directional and upper, lower and interval derivatives. We will also define when two measures have the same sign. These definitions will be used to introduce alternative definitions of the f -divergence, all extending the classical definition to non-additive measures.},
  archive      = {J_ISCI},
  author       = {Vicenç Torra and Yasuo Narukawa and Michio Sugeno},
  doi          = {10.1016/j.ins.2019.09.033},
  journal      = {Information Sciences},
  pages        = {50-63},
  shortjournal = {Inf. Sci.},
  title        = {On the f-divergence for discrete non-additive measures},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust event-triggered reliable control for t-s fuzzy
uncertain systems via weighted based inequality. <em>ISCI</em>,
<em>512</em>, 31–49. (<a
href="https://doi.org/10.1016/j.ins.2019.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the design of event-triggered reliable control scheme for a class of uncertain Takagi-Sugeno (T-S) fuzzy nonlinear systems involving network transmission delays. Moreover, the designed fuzzy controller is reliable in the sense that the stability and the satisfactory performance of the closed-loop system are achieved not only under normal operation but in the presence of some actuator faults as well. For this notion, a reliable event-trigger scheme is designed for the nonlinear system in transmitting the sampled state information to the controller. By employing Lyapunov-Kraskovskii functional (LKF) and by using the weighted integral inequality, the exponential stability conditions are derived in the form of linear matrix inequalities (LMIs). By solving the proposed LMI conditions the triggering and control gain matrices are obtained via the computational toolbox. Finally, the effectiveness and the less conservativeness of the proposed robust event-triggered controller have been illustrated via some real control systems such as mass-spring-damper physical system, flexible-joint robot arm and variable speed wind turbine system .},
  archive      = {J_ISCI},
  author       = {G. Nagamani and Young Hoon Joo and G. Soundararajan and Reza Mohajerpoor},
  doi          = {10.1016/j.ins.2019.09.034},
  journal      = {Information Sciences},
  pages        = {31-49},
  shortjournal = {Inf. Sci.},
  title        = {Robust event-triggered reliable control for T-S fuzzy uncertain systems via weighted based inequality},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Auto-weighted multi-view co-clustering with bipartite
graphs. <em>ISCI</em>, <em>512</em>, 18–30. (<a
href="https://doi.org/10.1016/j.ins.2019.09.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Co-clustering aims to explore coherent patterns by simultaneously clustering samples and features of data. Several co-clustering methods have been proposed in the past decades. However, in real-world applications, datasets are often with multiple modalities or composed of multiple representations (i.e., views), which provide different yet complementary information. Hence, it is essential to develop multi-view co-clustering models to solve the multi-view application problems. In this paper, a novel multi-view co-clustering method based on bipartite graphs is proposed. To make use of the duality between samples and features of multi-view data, a bipartite graph for each view is constructed such that the co-occurring structure of data can be extracted. The key point of utilizing the bipartite graphs to deal with the multi-view co-clustering task is to reasonably integrate these bipartite graphs and obtain an optimal consensus one. As for this point, the proposed method can learn an optimal weight for each bipartite graph automatically without introducing an additive parameter as previous methods do. Furthermore, an efficient algorithm is proposed to optimize this model with theoretically guaranteed convergence. Extensive experimental results on both toy data and several benchmark datasets have demonstrated the effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Shudong Huang and Zenglin Xu and Ivor W. Tsang and Zhao Kang},
  doi          = {10.1016/j.ins.2019.09.079},
  journal      = {Information Sciences},
  pages        = {18-30},
  shortjournal = {Inf. Sci.},
  title        = {Auto-weighted multi-view co-clustering with bipartite graphs},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward optimal participant decisions with voting-based
incentive model for crowd sensing. <em>ISCI</em>, <em>512</em>, 1–17.
(<a href="https://doi.org/10.1016/j.ins.2019.09.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of crowd sensing in sensing applications, excellent incentive mechanisms are playing an increasingly important role. However, most existing solutions do not fully consider the ability of participants to perform tasks, the degree to which they complete tasks, or the credibility of the task sensing results. In this paper, we aim to develop an incentive model based on voting mechanism for crowd sensing(abbreviated as CIBV), which includes three algorithms. The first is a participant decision algorithm (PDA) that adopts a reverse auction model and comprehensively considers candidate execution capability; the second is the budget balance and extra reward algorithm (BBER); the third is the evaluate algorithm (EA) to be applied at the end of sensing tasks. Compared with previous work, the experimental results show that in our proposed CIBV model, each task is performed by multiple participants, and each participant can perform multiple tasks, our model can greatly improve the participants’ execution ability value and provide the platform with the ability to control the process of selecting participants.},
  archive      = {J_ISCI},
  author       = {Nan Jiang and Dong Xu and Jie Zhou and Hongyang Yan and Tao Wan and Jiaqi Zheng},
  doi          = {10.1016/j.ins.2019.09.068},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Toward optimal participant decisions with voting-based incentive model for crowd sensing},
  volume       = {512},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Erratum to “an efficient linear programming based method for
the influence maximization problem in social networks” [information
sciences 503C (201911) 589–605]. <em>ISCI</em>, <em>511</em>, 309. (<a
href="https://doi.org/10.1016/j.ins.2019.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Evren Guney},
  doi          = {10.1016/j.ins.2019.10.034},
  journal      = {Information Sciences},
  pages        = {309},
  shortjournal = {Inf. Sci.},
  title        = {Erratum to “An efficient linear programming based method for the influence maximization problem in social networks” [Information sciences 503C (201911) 589–605]},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaborative linear manifold learning for link prediction
in heterogeneous networks. <em>ISCI</em>, <em>511</em>, 297–308. (<a
href="https://doi.org/10.1016/j.ins.2019.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in heterogeneous networks aims at predicting missing interactions between pairs of nodes with the help of the topology of the target network and interconnected auxiliary networks. It has attracted considerable attentions from both computer science and bioinformatics communities in the recent years. In this paper, we introduce a novel Collaborative Linear Manifold Learning (CLML) algorithm. It can optimize the consistency of nodes similarities by collaboratively using the manifolds embedded between the target network and the auxiliary network. The experiments on four benchmark datasets have demonstrated the outstanding advantages of CLML, not only in the high prediction performance compared to baseline methods , but also in the capability to predict the unknown interactions in the target networks accurately and effectively.},
  archive      = {J_ISCI},
  author       = {JiaHui Liu and Xu Jin and YuXiang Hong and Fan Liu and QiXiang Chen and YaLou Huang and MingMing Liu and MaoQiang Xie and FengChi Sun},
  doi          = {10.1016/j.ins.2019.09.054},
  journal      = {Information Sciences},
  pages        = {297-308},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative linear manifold learning for link prediction in heterogeneous networks},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BotMark: Automated botnet detection with hybrid analysis of
flow-based and graph-based traffic behaviors. <em>ISCI</em>,
<em>511</em>, 284–296. (<a
href="https://doi.org/10.1016/j.ins.2019.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Botnets have become one of the most serious threats to cyber infrastructure . Most existing work on detecting botnets is based on flow-based traffic analysis by mining their communication patterns. There also exists related work based on anomaly detection in communication graphs . As bots have continuously evolved and become increasingly sophisticated, only using flow-based traffic analysis or graph-based analysis for the detection would result in false negatives or false positives , or can even be evaded. In this work, we propose BotMark, an automated model that detects botnets with hybrid analysis of flow-based and graph-based network traffic behaviors. We extract 15 statistical flow-based traffic features as well as 3 graph-based features in building the detection model. For flow-based detection, we consider the similarity and stability of C-flow as measurements in the detection. In particular, we employ k -means to measure the similarity of C-flows and assign similarity scores, and calculate stability score of C-flows through the distribution of packet length within a C-flow. The graph-based detection is based on the observation that the neighborhoods of anomalous nodes significantly differ from those of normal nodes in communication graphs . In particular, we use least-square technique and Local Outlier Factor (LOF) to calculate anomaly scores that measure the differences of their neighborhoods. Our models use the scores to mark bots. BotMark performs automated botnet detection with hybrid analysis of flow-based and graph-based traffic behaviors by ensemble of the detection results based on similarity scores, stability scores and anomaly scores. We collect a very large size of network traffic by simulating 5 newly propagated botnets, including Mirai, Black energy, Zeus, Athena and Ares in a real computing environment. Extensive experimental results demonstrate the effectiveness of BotMark. It achieves 99.94\% in terms of detection accuracy, outperforming any individual detector with flow-based detection or graph-based detection.},
  archive      = {J_ISCI},
  author       = {Wei Wang and Yaoyao Shang and Yongzhong He and Yidong Li and Jiqiang Liu},
  doi          = {10.1016/j.ins.2019.09.024},
  journal      = {Information Sciences},
  pages        = {284-296},
  shortjournal = {Inf. Sci.},
  title        = {BotMark: Automated botnet detection with hybrid analysis of flow-based and graph-based traffic behaviors},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On state estimation for nonlinear dynamical networks with
random sensor delays and coupling strength under event-based
communication mechanism. <em>ISCI</em>, <em>511</em>, 265–283. (<a
href="https://doi.org/10.1016/j.ins.2019.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the optimized state estimation problem for nonlinear dynamical networks subject to random coupling strength (RCS) and random sensor delays (RSDs) under the event-triggered communication criterion. Firstly, a set of random variables obeying uniform distribution over certain interval is introduced to reflect the stochasticity of the elements of coupling configuration. Furthermore, a series of Bernoulli distributed random variables is introduced to characterize the phenomenon of RSDs, where the inaccuracy of the occurrence probability is depicted. Besides, as a special communication protocol, the event-triggered communication scheme is employed to avoid the potential data collision. Subsequently, a new robust state estimation algorithm is provided for addressed nonlinear dynamical networks by fully taking the available information of RCS and RSDs into account. Moreover, a sufficient condition ensuring the boundedness of state estimation error is presented. Finally, some simulations are utilized to demonstrate the usefulness of the optimized estimation technique proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Jun Hu and Guo-Ping Liu and Hongxu Zhang and Hongjian Liu},
  doi          = {10.1016/j.ins.2019.09.050},
  journal      = {Information Sciences},
  pages        = {265-283},
  shortjournal = {Inf. Sci.},
  title        = {On state estimation for nonlinear dynamical networks with random sensor delays and coupling strength under event-based communication mechanism},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Memory based self-adaptive sampling for noisy
multi-objective optimization. <em>ISCI</em>, <em>511</em>, 243–264. (<a
href="https://doi.org/10.1016/j.ins.2019.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel strategy to adapt sample size of population members of a multi-objective optimization (MOO) problem, where the objective surface is contaminated with noise. The sample size, used for periodic fitness evaluation of a solution, is adapted based on the fitness variance of a sub-population in its neighborhood and is referred to as local neighborhood fitness variance (LNFV). The constraint of selecting accurate functional relationship between sample size and LNFV is surmounted here by employing a novel memory-based sample size adaptation policy. In the early exploration phase of a MOO, the policy memorizes the success or failure of sample sizes assigned to solutions with specific LNFVs. These success and failure history are later utilized to guide solutions of future generations to carefully select sample sizes based on their individual LNFVs. Experiments undertaken disclose the superiority of the proposed realization to the existing counterparts and the state-of-the-art techniques. The proposed algorithms have also been applied on a multi-robot box-pushing problem where the sensory data of twin robots are contaminated with noise. Experimental results here too reveal the efficiency of the proposed realizations in terms of minimization of execution time and energy consumed by the twin robots.},
  archive      = {J_ISCI},
  author       = {Pratyusha Rakshit},
  doi          = {10.1016/j.ins.2019.09.060},
  journal      = {Information Sciences},
  pages        = {243-264},
  shortjournal = {Inf. Sci.},
  title        = {Memory based self-adaptive sampling for noisy multi-objective optimization},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bipartite consensus for networked robotic systems with
quantized-data interactions. <em>ISCI</em>, <em>511</em>, 229–242. (<a
href="https://doi.org/10.1016/j.ins.2019.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bipartite consensus problem of networked robotic systems ( NRSs ) with parametric uncertainties , input disturbances, and quantized-data interactions is addressed in this paper. Some novel distributed estimator-based control algorithms are designed to guarantee that all controlled robots can eventually reach bipartite consensus or their states asymptotically converge to the origin. By employing the Lyapunov argument and nonsmooth analysis theory, several sufficient criteria on control parameters for stabilizing the closed-loop systems and solving the aforementioned problems are provided. Finally, simulation examples are presented to illustrate the proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Teng-Fei Ding and Ming-Feng Ge and Cai-Hua Xiong and Ju H. Park},
  doi          = {10.1016/j.ins.2019.09.046},
  journal      = {Information Sciences},
  pages        = {229-242},
  shortjournal = {Inf. Sci.},
  title        = {Bipartite consensus for networked robotic systems with quantized-data interactions},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel hierarchical architectures for efficient consensus
clustering on big multimedia cluster ensembles. <em>ISCI</em>,
<em>511</em>, 212–228. (<a
href="https://doi.org/10.1016/j.ins.2019.09.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus clustering is a useful tool for robust or distributed clustering applications. However, given the fact that time complexities of the consensus functions scale linearly or quadratically with the number of combined clusterings, execution can be slow or even impossible when operating on big cluster ensembles, a situation encountered when we pursue robust multimedia data clustering . This work introduces hierarchical consensus architectures, an inherently parallel approach based on the divide-and-conquer strategy for computationally efficient consensus clustering, in a bid to make faster, more effective consensus clustering possible in big multimedia cluster ensemble scenarios. Moreover, we define a specific implementation of hierarchical architectures, including a theoretical analysis of its fully parallel implementation computational complexity . In experiments conducted on unimodal and multimedia data sets involving small and big cluster ensembles, we find parallel hierarchical consensus architectures variants perform faster than traditional flat consensus in 75\% of the experiments on small cluster ensembles, a percentage that rises to 100\% on unimodal and multimedia big cluster ensembles, achieving an average speedup ratio of 30.5. Moreover, depending on the consensus function employed, the quality of the obtained consensus partitions ensures robust clustering results .},
  archive      = {J_ISCI},
  author       = {Xavier Sevillano and Joan Claudi Socoró and Francesc Alías},
  doi          = {10.1016/j.ins.2019.09.064},
  journal      = {Information Sciences},
  pages        = {212-228},
  shortjournal = {Inf. Sci.},
  title        = {Parallel hierarchical architectures for efficient consensus clustering on big multimedia cluster ensembles},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Interval-valued hesitant fuzzy multi-granularity three-way
decisions in consensus processes with applications to multi-attribute
group decision making. <em>ISCI</em>, <em>511</em>, 192–211. (<a
href="https://doi.org/10.1016/j.ins.2019.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute group decision making (MAGDM) is a common activity for multi-variable complicated decision making situations by integrating collective wisdom. Aiming at fusing granular computing with three-way decisions (3WD) to study scheme synthesis and analysis of solution space, multi-granularity three-way decisions (MG-3WD) provide multi-dimension problem solving methods for MAGDM problems. By using MG-3WD frameworks, this paper intends to study viable strategies of processing consensus and conflicting opinions provided by different decision makers in the interval-valued hesitant fuzzy (IVHF) MAGDM problem. More specifically, after reviewing the relevant literature, four kinds of IVHF multigranulation decision-theoretic rough sets (MG-DTRSs) over two universes are proposed according to different risk appetites of experts firstly. Then, we explore some fundamental propositions of newly proposed models. Afterwards, solutions to MAGDM problems in the context of mergers and acquisitions (M&amp;A) target selections by using the presented IVHF MG-DTRSs over two universes are constructed. At last, a M&amp;A target selection case study, along with a sensitivity analysis and a comparative analysis, is applied to illustrate the established decision making approaches.},
  archive      = {J_ISCI},
  author       = {Chao Zhang and Deyu Li and Jiye Liang},
  doi          = {10.1016/j.ins.2019.09.037},
  journal      = {Information Sciences},
  pages        = {192-211},
  shortjournal = {Inf. Sci.},
  title        = {Interval-valued hesitant fuzzy multi-granularity three-way decisions in consensus processes with applications to multi-attribute group decision making},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image splicing forgery detection combining coarse to refined
convolutional neural network and adaptive clustering. <em>ISCI</em>,
<em>511</em>, 172–191. (<a
href="https://doi.org/10.1016/j.ins.2019.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a splicing forgery detection method with two parts: a coarse-to-refined convolutional neural network (C2RNet) and diluted adaptive clustering. The proposed C2RNet cascades a coarse convolutional neural network (C-CNN) and a refined CNN (R-CNN) and extracts the differences in the image properties between un-tampered and tampered regions from image patches with different scales. Further, to decrease the computational complexity , an image-level CNN is introduced to replace patch-level CNN in C2RNet. The proposed detection method learns the differences of various image properties to guarantee a stable detection performance, and the image-level CNN tremendously decreases its computational time. After the suspicious forgery regions are located by the proposed C2RNet, the final detected forgery regions are generated by applying the proposed adaptive clustering approach . The experiment results demonstrate that the proposed detection method achieves relatively promising results compared with state-of-the-art splicing forgery detection methods, even under various attack conditions.},
  archive      = {J_ISCI},
  author       = {Bin Xiao and Yang Wei and Xiuli Bi and Weisheng Li and Jianfeng Ma},
  doi          = {10.1016/j.ins.2019.09.038},
  journal      = {Information Sciences},
  pages        = {172-191},
  shortjournal = {Inf. Sci.},
  title        = {Image splicing forgery detection combining coarse to refined convolutional neural network and adaptive clustering},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DeePr-ESN: A deep projection-encoding echo-state network.
<em>ISCI</em>, <em>511</em>, 152–171. (<a
href="https://doi.org/10.1016/j.ins.2019.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a recurrent neural network that requires no training, the reservoir computing (RC) model has attracted widespread attention in the last decade, especially in the context of time series prediction . However, most time series have a multiscale structure, which a single-hidden-layer RC model may have difficulty capturing. In this paper, we propose a novel multiple projection-encoding hierarchical reservoir computing framework called Deep Projection-encoding Echo State Network (DeePr-ESN). The most distinctive feature of our model is its ability to learn multiscale dynamics through stacked ESNs, connected via subspace projections . Specifically, when an input time series is projected into the high-dimensional echo-state space of a reservoir, a subsequent encoding layer (e.g., an autoencoder or PCA) projects the echo-state representations into a lower-dimensional feature space. These representations are the principal components of the echo-state representations, which removes the high frequency components of the representations. These can then be processed by another ESN through random connections. By using projection layers and encoding layers alternately, our DeePr-ESN can provide much more robust generalization performance than previous methods, and also fully takes advantage of the temporal kernel property of ESNs to encode the multiscale dynamics of time series. In our experiments, the DeePr-ESNs outperform both standard ESNs and existing hierarchical reservoir computing models on some artificial and real-world time series prediction tasks.},
  archive      = {J_ISCI},
  author       = {Qianli Ma and Lifeng Shen and Garrison W. Cottrell},
  doi          = {10.1016/j.ins.2019.09.049},
  journal      = {Information Sciences},
  pages        = {152-171},
  shortjournal = {Inf. Sci.},
  title        = {DeePr-ESN: A deep projection-encoding echo-state network},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Offset-free state-space nonlinear predictive control for
wiener systems. <em>ISCI</em>, <em>511</em>, 127–151. (<a
href="https://doi.org/10.1016/j.ins.2019.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is concerned with state space Multiple-Input Multiple-Output (MIMO) Wiener systems which consist of a linear dynamic block connected in series with a nonlinear steady-state (static) one. Model Predictive Control (MPC) algorithms with successive on-line model or trajectory linearisation for dynamic processes described by such Wiener systems are discussed. Advantages of the presented MPC algorithms are: (a) computational efficiency since quadratic optimisation problems are only solved on-line, nonlinear optimisation is not necessary, (b) very good quality of control, (c) offset-free control (no steady-state error in presence of disturbances) assured by a novel approach to disturbance modelling and state estimation, resulting in a simple design and a simple control structure. All features of the discussed algorithms are demonstrated and their performance is compared with that of the MPC algorithm with nonlinear optimisation as well as with the traditional offset-free state-space MPC approach.},
  archive      = {J_ISCI},
  author       = {Maciej Ławryńczuk and Piotr Tatjewski},
  doi          = {10.1016/j.ins.2019.09.042},
  journal      = {Information Sciences},
  pages        = {127-151},
  shortjournal = {Inf. Sci.},
  title        = {Offset-free state-space nonlinear predictive control for wiener systems},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel results on synchronization for a class of switched
inertial neural networks with distributed delays. <em>ISCI</em>,
<em>511</em>, 114–126. (<a
href="https://doi.org/10.1016/j.ins.2019.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a class of state-dependent switched neural networks with inertial items and distributed delays. Several new results are derived to ensure the exponential synchronization of such switched neural networks by using a novel hybrid control scheme and the Lyapunov stability theory . Finally, simulations are given to show the validity of the derived results. We believe the new useful control method of this paper widens the application scope for the switched neural networks.},
  archive      = {J_ISCI},
  author       = {Guodong Zhang and Zhigang Zeng and Di Ning},
  doi          = {10.1016/j.ins.2019.09.048},
  journal      = {Information Sciences},
  pages        = {114-126},
  shortjournal = {Inf. Sci.},
  title        = {Novel results on synchronization for a class of switched inertial neural networks with distributed delays},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible attribute-based proxy re-encryption for efficient
data sharing. <em>ISCI</em>, <em>511</em>, 94–113. (<a
href="https://doi.org/10.1016/j.ins.2019.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasing number of people are sharing their data through third-party platforms. Attribute-based encryption (ABE) is a promising primitive that allows enforcing fine-grained access control on the data to be shared. An issue in ABE is that a priori access policies should be determined during the system setup or encryption phase, but these policies will become obsolete over time. Another issue is that the decryption of ABE generally requires complicated and expensive computations, which may be unaffordable for resource-limited users (e.g., mobile-device users). To address these issues, we propose a new paradigm called hybrid attribute-based proxy re-encryption (HAPRE). In HAPRE, a semitrusted proxy can be authorized to convert ciphertexts of an ABE scheme into ciphertexts of an identity-based encryption (IBE) scheme without letting the proxy know the underlying messages. With these features, HAPRE enables resource-limited users to efficiently access the data previously encrypted by ABE. We construct two HAPRE schemes by utilizing a compact IBE scheme and a key rerandomization technique, and then we prove that the schemes are semantically secure and collusion resistant. Theoretical and experimental analyses demonstrate the efficiency of the HAPRE schemes.},
  archive      = {J_ISCI},
  author       = {Hua Deng and Zheng Qin and Qianhong Wu and Zhenyu Guan and Yunya Zhou},
  doi          = {10.1016/j.ins.2019.09.052},
  journal      = {Information Sciences},
  pages        = {94-113},
  shortjournal = {Inf. Sci.},
  title        = {Flexible attribute-based proxy re-encryption for efficient data sharing},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary approach for efficient prototyping of large
time series datasets. <em>ISCI</em>, <em>511</em>, 74–93. (<a
href="https://doi.org/10.1016/j.ins.2019.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We here describe an algorithm based on an evolutionary strategy to find the prototype series of a set of time series, and we use Dynamic Time Warping (DTW) as a distance measure between series, and do not restrict the search space to the series in the set. The problem of calculating the centroid of a set of time series can be addressed as a minimization problem , using genetic algorithms . Our proposal may be considered among the set of non-classical approaches to genetic algorithms , where an individual gene is a candidate time series for being the centroid or representative of the whole set of series. The representation and operators of genetic algorithms are redesigned, in order to generate efficient summaries, the fitness function of each candidate series to be a prototype is approximated, comparing them only with a subset of randomly selected time series from the original dataset. Three areas are looked at in order to assess the goodness of our proposal: the performance of the prototype generated in terms of a fitness function, the consistency of the prototype generation for use in classical grouping algorithms, and its use in classification algorithms based on the nearest prototypes.},
  archive      = {J_ISCI},
  author       = {Pablo Leon-Alcaide and Luis Rodriguez-Benitez and Ester Castillo-Herrera and Juan Moreno-Garcia and Luis Jimenez-Linares},
  doi          = {10.1016/j.ins.2019.09.044},
  journal      = {Information Sciences},
  pages        = {74-93},
  shortjournal = {Inf. Sci.},
  title        = {An evolutionary approach for efficient prototyping of large time series datasets},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shape-optimizing mesh warping method for stereoscopic
panorama stitching. <em>ISCI</em>, <em>511</em>, 58–73. (<a
href="https://doi.org/10.1016/j.ins.2019.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel shape-optimizing mesh warping method for stereoscopic panorama stitching, which aims to resolve shape distortion and unnatural rotation of traditional stitching methods, simultaneously coping with the challenges, misalignment, and stereoscopic inconsistency. Specifically, based on the grid mesh analysis of projective warping, we propose a differential warping method by gradually changing the inclination angle of each mesh line in non-overlapping regions of the image to reduce shape distortion and unnatural rotation. Furthermore, an extended moving direct linear transformation method is proposed to effectively and robustly improve alignment accuracy and maintain stereoscopic consistency in multiple stereoscopic images. Finally, a consistent seam based on the matched feature points in the left- and right- view images of a stereoscopic image is designed to blend images and generate a stereoscopic panorama image. Experiments demonstrate that the proposed method has a superior performance compared to previous methods.},
  archive      = {J_ISCI},
  author       = {Weiqing Yan and Guanghui Yue and Jindong Xu and Yanwei Yu and Kai Wang and Chang Tang and Xiangrong Tong},
  doi          = {10.1016/j.ins.2019.09.051},
  journal      = {Information Sciences},
  pages        = {58-73},
  shortjournal = {Inf. Sci.},
  title        = {Shape-optimizing mesh warping method for stereoscopic panorama stitching},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General decay lag anti-synchronization of multi-weighted
delayed coupled neural networks with reaction–diffusion terms.
<em>ISCI</em>, <em>511</em>, 36–57. (<a
href="https://doi.org/10.1016/j.ins.2019.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new anti-synchronization concept, called general decay lag anti-synchronization, by combining the definitions of decay synchronization and lag synchronization. Novel criteria for the decay lag anti-synchronization of multi-weighted delayed coupled reaction–diffusion neural networks (MWDCRDNNs) with and without bounded distributed delays are derived by constructing an appropriate nonlinear controller and using the Lyapunov functional method. Moreover, the robust decay lag anti-synchronization of MWDCRDNNs with and without bounded distributed delays is considered. Finally, two numerical simulations are performed to validate the obtained results.},
  archive      = {J_ISCI},
  author       = {Yanli Huang and Jie Hou and Erfu Yang},
  doi          = {10.1016/j.ins.2019.09.045},
  journal      = {Information Sciences},
  pages        = {36-57},
  shortjournal = {Inf. Sci.},
  title        = {General decay lag anti-synchronization of multi-weighted delayed coupled neural networks with reaction–diffusion terms},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiobjective multifactorial optimization algorithm based
on decomposition and dynamic resource allocation strategy.
<em>ISCI</em>, <em>511</em>, 18–35. (<a
href="https://doi.org/10.1016/j.ins.2019.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective multifactorial optimization (MO-MFO), i.e. , multiple multiobjective tasks are simultaneously optimized by a single population, has received considerable attention in recent years. Traditional algorithms for the MO-MFO usually allocate equal computing resources to each task, however, this may not be reasonable due to the fact that different tasks usually have different degrees of difficulty. Motivated by the idea that the limited computing resources should be adaptively allocated to different tasks according to their difficulties, this paper proposes an algorithm for the MO-MFO based on decomposition and dynamic resource allocation strategy (denoted as MFEA/D-DRA). In the MFEA/D-DRA, each multiobjective optimization task is firstly decomposed into a series of single-objective subproblems . Thereafter, a single population is used to evolve all the single-objective subproblems. In the process of evolution, subproblems with fast evolution rate will have the opportunity to get more rewards, i.e. , computing resources. The evolution rate is measured by a utility function and updated periodically. Moreover, different multiobjective optimization tasks can communicate with each other according to a random mating probability . Finally, a set of evenly distributed approximate Pareto optimal solutions is obtained for each multiobjective optimization task . The statistical analysis of experimental results illustrates the superiority of the proposed MFEA/D-DRA algorithm on a variety of benchmark MO-MFO problems.},
  archive      = {J_ISCI},
  author       = {Shuangshuang Yao and Zhiming Dong and Xianpeng Wang and Lei Ren},
  doi          = {10.1016/j.ins.2019.09.058},
  journal      = {Information Sciences},
  pages        = {18-35},
  shortjournal = {Inf. Sci.},
  title        = {A multiobjective multifactorial optimization algorithm based on decomposition and dynamic resource allocation strategy},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive robust control of oxygen excess ratio for PEMFC
system based on type-2 fuzzy logic system. <em>ISCI</em>, <em>511</em>,
1–17. (<a href="https://doi.org/10.1016/j.ins.2019.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Proton Exchange Membrane Fuel Cell (PEMFC) air supply system takes on the characteristics of external disturbances and uncertain parameters, which is difficult to achieve accurate modeling and stability control. In this paper, an adaptive robust controller based on type-2 fuzzy logic systems (T2-FLS) is proposed to control the oxygen excess ratio (OER) of PEMFC air supply system. The controller does not need the unmodeled dynamics, which can be approximated by adaptive T2-FLS whose adaptive parameters are derived based on Lyapunov theory . The stability analysis shows that the system tracking error is uniform ultimate bounded. Finally, the practicability and feasibility of controller are validated by numerical simulation and Hardware-In-Loop (HIL) experiment.},
  archive      = {J_ISCI},
  author       = {H.K. Zhang and Y.F. Wang and D.H. Wang and Y.L. Wang},
  doi          = {10.1016/j.ins.2019.08.005},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive robust control of oxygen excess ratio for PEMFC system based on type-2 fuzzy logic system},
  volume       = {511},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Current trends of granular data mining for biomedical data
analysis. <em>ISCI</em>, <em>510</em>, 341–343. (<a
href="https://doi.org/10.1016/j.ins.2019.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Weiping Ding and Chin-Teng Lin and Alan Wee-Chung Liew and Isaac Triguero and Wenjian Luo},
  doi          = {10.1016/j.ins.2019.10.002},
  journal      = {Information Sciences},
  pages        = {341-343},
  shortjournal = {Inf. Sci.},
  title        = {Current trends of granular data mining for biomedical data analysis},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized hukuhara gâteaux and fréchet derivatives of
interval-valued functions and their application in optimization with
interval-valued functions. <em>ISCI</em>, <em>510</em>, 317–340. (<a
href="https://doi.org/10.1016/j.ins.2019.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the notions of gH-directional derivative, gH-Gâteaux derivative and gH-Fréchet derivative for interval-valued functions are proposed. The existence of gH -Fréchet derivative is shown to imply the existence of gH -Gâteaux derivative and the existence of gH -Gâteaux derivative is observed to indicate the presence of gH -directional derivative. For an interval-valued gH -Lipschitz function, it is proved that the existence of gH -Gâteaux derivative implies the existence of gH -Fréchet derivative. It is observed that for an interval-valued convex function on a linear space, the gH -directional derivative exists at any point for every direction. Concepts of linear and monotonic interval-valued functions are studied in the sequel. Further, it is shown that the proposed derivatives are useful to check the convexity of an interval-valued function and to characterize efficient points of an optimization problem with interval-valued objective function. It is observed that at an efficient point of an interval-valued function, none of its gH -directional derivatives dominates zero and the gH -Gâteaux derivative must contain zero. The entire study is supported by suitable illustrative examples.},
  archive      = {J_ISCI},
  author       = {Debdas Ghosh and Ram Surat Chauhan and Radko Mesiar and Amit Kumar Debnath},
  doi          = {10.1016/j.ins.2019.09.023},
  journal      = {Information Sciences},
  pages        = {317-340},
  shortjournal = {Inf. Sci.},
  title        = {Generalized hukuhara gâteaux and fréchet derivatives of interval-valued functions and their application in optimization with interval-valued functions},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biclustering with missing data. <em>ISCI</em>, <em>510</em>,
304–316. (<a href="https://doi.org/10.1016/j.ins.2019.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biclustering is a statistical learning methodology that simultaneously partitions rows and columns of a rectangular data array into homogeneous subsets. Biclustering is known to be an NP-hard problem, and therefore various heuristic approaches have been proposed. These strategies break down when dealing with any degree of missing data in a two-way table of data values. To address this issue, we propose a new biclustering method based on the work of Li in 2014 [18] . Numerical results show our approach performs well on moderate-sized test cases with even a large missing-value percentage (99\%+). To illustrate the practical usefulness of the method we provide two case studies. The first is an agricultural application where rows represent plant varieties, columns represent planting locations, and data are yield values. The other is a well-known movie rater application where rows represent raters, columns represent movies, and data are ratings.},
  archive      = {J_ISCI},
  author       = {J. Li and J. Reisner and H. Pham and S. Olafsson and S. Vardeman},
  doi          = {10.1016/j.ins.2019.09.047},
  journal      = {Information Sciences},
  pages        = {304-316},
  shortjournal = {Inf. Sci.},
  title        = {Biclustering with missing data},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost-sensitive dual-bidirectional linear discriminant
analysis. <em>ISCI</em>, <em>510</em>, 283–303. (<a
href="https://doi.org/10.1016/j.ins.2019.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most previous cost-sensitive feature extraction methods, the image matrix needs to be converted into vectors. The conversion always leads to a high computation complexity and small sample size problem. To address these issues, we propose a matrix-feature extraction method for face recognition, Cost-sensitive Dual-Bidirectional Linear Discriminant Analysis (CB 2 LDA). It is based on 2D image matrices, which greatly reduces the computation complexity and the probability of falling into small sample size problems. The proposed methods extract 2D matrix features from a diagonal block matrix containing both image matrix A and its transposition A T . With the block matrix , the scatter information in both directions is simultaneously considered in the projections, which helps to preserve the underlying data structure in images. Moreover, it aims to preserve the best cost-weighted discriminative information in the facial images , such that the misclassification costs reach a lower level. The experimental results validate the effectiveness and efficiency of the proposed method.},
  archive      = {J_ISCI},
  author       = {Huaxiong Li and Libo Zhang and Bing Huang and Xianzhong Zhou},
  doi          = {10.1016/j.ins.2019.09.032},
  journal      = {Information Sciences},
  pages        = {283-303},
  shortjournal = {Inf. Sci.},
  title        = {Cost-sensitive dual-bidirectional linear discriminant analysis},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decision-making computational methodology for a class of
type-2 fuzzy intervals: An interval-based approach. <em>ISCI</em>,
<em>510</em>, 256–282. (<a
href="https://doi.org/10.1016/j.ins.2019.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an interval-based computational formulation of the Bellman-Zadeh decision-making approach when the handled information (goals and constraints) is represented by type-2 fuzzy intervals (FIs). Our method, which maintains the flexibility of interval arithmetic and interval reasoning as major objectives, consists of representing an FI by its profiles, which are considered gradual numbers. The developed reflection is based on interval relations to determine a generic formulation of the intersection operation between type-2 FIs, where a computational mechanism can be easily derived. This intersection area is considered an uncertain decision domain that is represented by lower type-1 FI situations and upper type-1 FI bounds that are considered extreme situations in adverse situations and favorable situations, respectively. In this framework, any FI between these FI bounds can be chosen by decision makers as an optimal solution according to a specified decision criterion. In this paper, a risk decision-making criterion is considered; however, other decision criteria can be employed in a similar manner. The proposed vision offers a convenient tool that enables decision makers to manage their judgment in the possible uncertain domain of a decision. The interest of the proposed approach is the extension of inter-interval relations to type-1 and type-2 FIs, where the Bellman-Zadeh decision-making problem using membership functions can be transformed into an interval arithmetic problem using the FI profiles.},
  archive      = {J_ISCI},
  author       = {Reda Boukezzoula and Didier Coquin},
  doi          = {10.1016/j.ins.2019.09.020},
  journal      = {Information Sciences},
  pages        = {256-282},
  shortjournal = {Inf. Sci.},
  title        = {A decision-making computational methodology for a class of type-2 fuzzy intervals: An interval-based approach},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using low-density parity-check codes to improve the McEliece
cryptosystem. <em>ISCI</em>, <em>510</em>, 243–255. (<a
href="https://doi.org/10.1016/j.ins.2019.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing secure and fast asymmetric cryptographic primitives is a priority in cryptography. This fact steams from high demand for fast communication involving an increasing amount of private and sensible information. To this end, we propose an efficient McEliece-based cryptosystem to handle large messages that can be easily implemented in hardware. The main idea is to incorporate Low-Density Parity-Check (LDPC) codes after several parallel runs of the original McEliece cryptosystem . In this way, we achieve a low circuit-depth complexity while profiting from the capability of LDPC codes to deal with high-dimensional data. The proposed cryptosystem is at least as hard as the original McEliece cryptosystem, and therefore, it is believed to be robust to quantum attacks. Moreover, known attacks to McEliece cryptosystems based on LDPC codes are ineffective against our proposal. The key size of the cryptosystem is roughly ten times smaller than the original McEliece for similar levels of security. Finally, we present a variant of the proposed cryptosystem that is resistant to adaptive indistinguishability chosen-chiphertext attacks (IND-CCA2), which is a desirable property that the original McEliece cryptosystem does not fulfill.},
  archive      = {J_ISCI},
  author       = {Pedro Branco and Paulo Mateus and Carlos Salema and André Souto},
  doi          = {10.1016/j.ins.2019.09.030},
  journal      = {Information Sciences},
  pages        = {243-255},
  shortjournal = {Inf. Sci.},
  title        = {Using low-density parity-check codes to improve the McEliece cryptosystem},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective rating prediction based on selective contextual
information. <em>ISCI</em>, <em>510</em>, 218–242. (<a
href="https://doi.org/10.1016/j.ins.2019.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many researchers have realized the importance of contextual information and focused on designing systems that predict user’s contextual preferences. In this respect, several researches have been devoted to Context-Aware Recommender Systems (CARS). One of the remaining issues in these systems especially the collaborative filtering based ones, is determining which contextual information can be adopted to make effective rating prediction. In fact, many contextual dimensions (e.g., location, time, mood etc.) may affect the user’s preferences, but not all of these dimensions are equally important for the rating prediction effectiveness. Many existing CARS approaches cannot fully capture the influence of relevant contextual dimensions and their interaction on the rating, and furthermore cannot obtain a better recommendation performance. To address these issues, we highlight contextual dimensions weighting, study the correlation between them to elicit the most useful ones, and propose two improved rating prediction methods based on collaborative filtering techniques, involving relevant and dependent contextual dimensions. Experimental results, with respect to rating prediction quality and recommendation performance on both public available and large created contextual datasets, show that our proposal outperforms the existing recommender systems especially on the created datasets.},
  archive      = {J_ISCI},
  author       = {Rim Dridi and Saloua Zammali and Tagreed Alsulimani and Khedija Arour},
  doi          = {10.1016/j.ins.2019.09.008},
  journal      = {Information Sciences},
  pages        = {218-242},
  shortjournal = {Inf. Sci.},
  title        = {Effective rating prediction based on selective contextual information},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stabilization of probabilistic boolean networks via pinning
control strategy. <em>ISCI</em>, <em>510</em>, 205–217. (<a
href="https://doi.org/10.1016/j.ins.2019.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stabilization of probabilistic Boolean networks with pinning control is investigated. Only a part of nodes are chosen to be controlled for the aim of high efficiency. Stabilization with probability one and stabilization in probability are respectively discussed. Since the probability of stabilization is not required to be strict one, stabilization in probability is a more practical extension of the former, which is also proven in this work. Stabilization with probability one needs the target state to be transferred to itself with 100\% certainty, while stabilization in probability cannot even guarantee the existence of such a possibility. Thus, stabilization in probability is a different and challenging problem. Some necessary and sufficient conditions are proposed for both types of stabilization via the semi-tensor product of matrices. Based on them, approaches to controller design are also developed. Finally, illustrative examples are provided to demonstrate the effectiveness of the derived results.},
  archive      = {J_ISCI},
  author       = {Chi Huang and Jianquan Lu and Daniel W.C. Ho and Guisheng Zhai and Jinde Cao},
  doi          = {10.1016/j.ins.2019.09.029},
  journal      = {Information Sciences},
  pages        = {205-217},
  shortjournal = {Inf. Sci.},
  title        = {Stabilization of probabilistic boolean networks via pinning control strategy},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A possibilistic regression based on gradual interval
b-splines: Application for hyperspectral imaging lake sediments.
<em>ISCI</em>, <em>510</em>, 183–204. (<a
href="https://doi.org/10.1016/j.ins.2019.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to an epistemic view of intervals, this paper proposes a possibilistic regression based on gradual interval B-splines to represent the input-output data mapping. In this context, an improvement of the parametric fuzzy regression through the notion of gradual interval B-splines is proposed. The proposed gradual regression based on B-splines can be regarded as an extension of the nonparametric interval-based regression where an uncertain dimension is integrated. The proposed method is validated through illustrative and comparative examples. Moreover, it is applied for modeling the input-output behavior between reflectance and wavelengths in an application for hyperspectral imaging for lake sediments.},
  archive      = {J_ISCI},
  author       = {Reda Boukezzoula and Didier Coquin and Kévin Jacq},
  doi          = {10.1016/j.ins.2019.09.031},
  journal      = {Information Sciences},
  pages        = {183-204},
  shortjournal = {Inf. Sci.},
  title        = {A possibilistic regression based on gradual interval B-splines: Application for hyperspectral imaging lake sediments},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Robust deadlock control for automated manufacturing systems
based on elementary siphon theory. <em>ISCI</em>, <em>510</em>, 165–182.
(<a href="https://doi.org/10.1016/j.ins.2019.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource failures may happen from time to time in an automated manufacturing system (AMS) in production practice, leading to that most of deadlock control methods in the literature are not applicable. For a generalized system of simple sequential process with resources (GS 3 PR), this paper develops a robust deadlock control strategy when there exists a type of unreliable resources. To do so, after computing the system’s elementary and dependent strict minimal siphons (SMSs), by using the concept of max′-controllability of siphons, we then check whether an elementary SMS is self-max′-controlled or not, and whether it contains unreliable resources. Afterwards, a constraint set for a siphon is introduced and a monitor is designed for each non-max′-controlled elementary SMS and self-max′-controlled elementary one that contains unreliable resources. Then, if a dependent SMS is max′-controlled with respect to the control depth variables of its elementary siphons, it needs no monitor; otherwise, we add a monitor for such a dependent SMS. Finally, a robust deadlock control algorithm is developed to keep each SMS to be max′-controlled, even if there exists a type of unreliable resources. The proposed method is demonstrated by using examples.},
  archive      = {J_ISCI},
  author       = {GaiYun Liu and LingChun Zhang and Liang Chang and Abdulraham Al-Ahmari and NaiQi Wu},
  doi          = {10.1016/j.ins.2019.09.018},
  journal      = {Information Sciences},
  pages        = {165-182},
  shortjournal = {Inf. Sci.},
  title        = {Robust deadlock control for automated manufacturing systems based on elementary siphon theory},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient chameleon hash functions in the enhanced collision
resistant model. <em>ISCI</em>, <em>510</em>, 155–164. (<a
href="https://doi.org/10.1016/j.ins.2019.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chameleon hash functions are collision resistant when only the hashing keys of the functions are known. In particular, without the knowledge of the secret information, the chameleon hash function is merely like a regular cryptographic hash function, where it is hard to find collisions. However anyone who has trapdoor keys can efficiently generate pre-images for the chameleon hash function. In some applications, such as redactable blockchains , unfortunately the existing properties do not suffice and we need more features. Actually, it is required that without knowing the trapdoor keys, nobody can compute collisions, even if he can see collisions for arbitrary hash functions . In 2017, Ateniese et al. introduced the notion of chameleon hash functions in the enhanced collision resistant model and proposed a construction in the standard model satifying the features. To date, efficient constructions of this kind of chameleon hash functions remain as an open research problem. In this paper, we answer this problem affirmatively by presenting efficient constructions of the chameleon hash function satisfying the enhanced collision resistance. The contributions of this work are twofold. First, we show the weakness of previous work. Then, we proceed with proposing new schemes with more efficiency. Technically, we present a new chameleon hash function in the basic model and based on simple assumptions. This chameleon hash function is well compatible with Groth-Sahai proof systems and the Cramer-Shoup encryption schemes , and can be used as a stepping stone to construct an efficient chameleon hash function in the enhanced collision resistant model. Moreover, we show our basic chameleon hash can be combined with optimal ZK-SNARKs of Groth and Maller that leads to shorter sizes for chameleon hash function in the enhanced collision resistant model.},
  archive      = {J_ISCI},
  author       = {Mojtaba Khalili and Mohammad Dakhilalian and Willy Susilo},
  doi          = {10.1016/j.ins.2019.09.001},
  journal      = {Information Sciences},
  pages        = {155-164},
  shortjournal = {Inf. Sci.},
  title        = {Efficient chameleon hash functions in the enhanced collision resistant model},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the choice of similarity measures for type-2 fuzzy sets.
<em>ISCI</em>, <em>510</em>, 135–154. (<a
href="https://doi.org/10.1016/j.ins.2019.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity measures are among the most common methods of comparing type-2 fuzzy sets and have been used in numerous applications. However, deciding how to measure similarity and choosing which existing measure to use can be difficult. Whilst some measures give results that highly correlate with each other, others give considerably different results. We evaluate all of the current similarity measures on type-2 fuzzy sets to discover which measures have common properties of similarity and, for those that do not, we discuss why the properties are different, demonstrate whether and what effect this has in applications, and discuss how a measure can avoid missing a property that is required. We analyse existing measures in the context of computing with words using a comprehensive collection of data-driven fuzzy sets. Specifically, we highlight and demonstrate how each method performs at clustering words of similar meaning.},
  archive      = {J_ISCI},
  author       = {Josie McCulloch and Christian Wagner},
  doi          = {10.1016/j.ins.2019.09.027},
  journal      = {Information Sciences},
  pages        = {135-154},
  shortjournal = {Inf. Sci.},
  title        = {On the choice of similarity measures for type-2 fuzzy sets},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attention-based context-aware sequential recommendation
model. <em>ISCI</em>, <em>510</em>, 122–134. (<a
href="https://doi.org/10.1016/j.ins.2019.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNN) based recommendation algorithms have been introduced recently as sequence information plays an increasingly important role when modeling user preferences. However, these methods have numerous limitations: they usually give undue importance to sequential changes and place insufficient emphasis on the correlation between adjacent items; additionally, they typically ignore the impacts of context information. To address these issues, we propose an attention-based context-aware sequential recommendation model using Gated Recurrent Unit (GRU), abbreviated as ACA-GRU. First, we consider the impact of context information on recommendations and classify them into four categories, including input context, correlation context, static interest context, and transition context. Then, by redefining the update and reset gate of the GRU unit, we calculate the global sequential state transition of the RNN determined by these contexts, to model the dynamics of user interest. Finally, by leveraging the attention mechanism in the correlation context, the model is able to distinguish the importance of each item in the rating sequence. The impact of outliers that are less informative or less predictive decreases or is ignored. Experimental results indicate that ACA-GRU outperforms state-of-the-art context-aware models as well as sequence recommendation algorithms , demonstrating the effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Weihua Yuan and Hong Wang and Xiaomei Yu and Nan Liu and Zhenghao Li},
  doi          = {10.1016/j.ins.2019.09.007},
  journal      = {Information Sciences},
  pages        = {122-134},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based context-aware sequential recommendation model},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ABFL: An autoencoder based practical approach for software
fault localization. <em>ISCI</em>, <em>510</em>, 108–121. (<a
href="https://doi.org/10.1016/j.ins.2019.08.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault localization is essential to software debugging . Despite existing techniques, such as mutation analysis, development history and bug reports , have made great contributions to fault localization, the challenge of infeasibility still exits in practice due to expense of mutation analysis, lacking of development history and bug reports . To improve accuracy and feasibility in fault code locating, in this paper, we propose ABFL, an Autoencoder Based practical approach for Fault Localization. ABFL first introduces an autoencoder to extract 32 features from software static source code. Then it employs Spectrum Based Fault Localization (SBFL) techniques to calculate 14 types of scores, which are taken as another group of features in software running time. Finally, relying on the constructed ranking model, ABFL integrates two groups of features together and precisely locates faulty statements in code. The executed extensive experiments on the Defects4J repository show that our approach is superior to the state-of-the-art SBFL techniques, ranking the faulty statement at the 1st, 3rd, and 5th positions with 49, 94, and 123 faults, respectively.},
  archive      = {J_ISCI},
  author       = {Zhendong Peng and Xi Xiao and Guangwu Hu and Arun Kumar Sangaiah and Mohammed Atiquzzaman and Shutao Xia},
  doi          = {10.1016/j.ins.2019.08.077},
  journal      = {Information Sciences},
  pages        = {108-121},
  shortjournal = {Inf. Sci.},
  title        = {ABFL: An autoencoder based practical approach for software fault localization},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Return random walks for link prediction. <em>ISCI</em>,
<em>510</em>, 99–107. (<a
href="https://doi.org/10.1016/j.ins.2019.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new method, Return Random Walk, for link prediction to infer new intra-class edges while minimizing the amount of inter-class noise, and we show how to exploit it in an unsupervised densifier method, Dirichlet densification , which can be used to increase the edge density in undirected graphs , setting so that commute times can be better estimated by state-of-the-art methods. Moreover, this approach allows us to predict new intra-class links by exploring vertex similarities analyzing the mathematical relationship between the Cheeger constant and the minimization of the spectral gap , and the meaningful estimation of the commute distances. Our experiments show a significant improvement as inter-class filtering with respect to the state-of-the-art of link prediction, providing a weighting matrix denser and more clustered than others link predictors, and preconditioned the input graph to subsequent tasks of pattern recognition.},
  archive      = {J_ISCI},
  author       = {Manuel Curado},
  doi          = {10.1016/j.ins.2019.09.017},
  journal      = {Information Sciences},
  pages        = {99-107},
  shortjournal = {Inf. Sci.},
  title        = {Return random walks for link prediction},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way convex systems and three-way fuzzy convex systems.
<em>ISCI</em>, <em>510</em>, 89–98. (<a
href="https://doi.org/10.1016/j.ins.2019.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study convex systems under the frame of three-way decision theory. Firstly, we give the notion of three-way convex systems. We obtain an equivalence characterization of three-way convex systems. Then, we propose the concept of three-way fuzzy convex systems in term of L -convex systems. Some related examples are presented. Finally, we establish a one-to-one correspondence between three-way convex systems and three-way fuzzy convex systems.},
  archive      = {J_ISCI},
  author       = {Shao-Yu Zhang and Sheng-Gang Li and Hai-Long Yang},
  doi          = {10.1016/j.ins.2019.09.026},
  journal      = {Information Sciences},
  pages        = {89-98},
  shortjournal = {Inf. Sci.},
  title        = {Three-way convex systems and three-way fuzzy convex systems},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). User interaction-oriented community detection based on
cascading analysis. <em>ISCI</em>, <em>510</em>, 70–88. (<a
href="https://doi.org/10.1016/j.ins.2019.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting user communities in online social networks (OSNs) is of great importance for understanding social dynamics. Compared to user connections, user interactions have been shown to be more meaningful for reflecting peer relationship in OSNs. To this end, we propose a user interaction-oriented community detection method based on cascading analysis. Specifically, user interactions are analyzed from a large collection of social object sharings (e.g., blog posts, photo shares). Both direct and indirect user interactions associated with each social object sharing are then extracted and the cascading relations among these interactions are captured using a graph representation . The proposed method makes use of such cascading relations to extract groups of actively interacting users and adopts a super graph approach to cluster these user groups for detecting communities. An extensive evaluation of our method was performed using three real OSN datasets and compared with three state-of-the-art overlapping community detection methods, namely two general methods applied to the interaction graph and an interaction-based method. Our method outperformed the compared methods, as demonstrated by several evaluation metrics , and produced more robust and stable detection results across different datasets.},
  archive      = {J_ISCI},
  author       = {Linbo Luo and Kexin Liu and Bin Guo and Jianfeng Ma},
  doi          = {10.1016/j.ins.2019.09.022},
  journal      = {Information Sciences},
  pages        = {70-88},
  shortjournal = {Inf. Sci.},
  title        = {User interaction-oriented community detection based on cascading analysis},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered reliable h∞ fuzzy filtering for nonlinear
parabolic PDE systems with markovian jumping sensor faults.
<em>ISCI</em>, <em>510</em>, 50–69. (<a
href="https://doi.org/10.1016/j.ins.2019.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to even-triggered reliable H ∞ H∞ filter design for a class of nonlinear partial differential equation (PDE) systems with Markovian jumping sensor faults. Initially, a Takagi-Sugeno (T-S) fuzzy model is adopted to reconstruct the nonlinear systems . Then, the time delays and signal quantization that often occur in network transmission are taken into account, and an integral-type event-triggered scheme is developed to improve the transmission channel utilization. Furthermore, non-parallel-distributed-compensation technique is introduced to increase the flexibility of filter design and the filter’s parameters can be obtained by solving several linear matrix inequalities. Finally, two numerical simulations and an application study to Catalytic Rod are provided to demonstrate the effectiveness and practicability of the proposed methodology.},
  archive      = {J_ISCI},
  author       = {Xiaona Song and Mi Wang and Baoyong Zhang and Shuai Song},
  doi          = {10.1016/j.ins.2019.09.012},
  journal      = {Information Sciences},
  pages        = {50-69},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered reliable h∞ fuzzy filtering for nonlinear parabolic PDE systems with markovian jumping sensor faults},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On shortened 3D local binary descriptors. <em>ISCI</em>,
<em>510</em>, 33–49. (<a
href="https://doi.org/10.1016/j.ins.2019.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wide-spread mobile systems nowadays desire ultra lightweight local geometric features to accomplish tasks relying on correspondences. Nonetheless, most existing 3D local feature descriptors , though shown to be distinctive and robust, still are real-valued and/or high-dimensional. Accordingly, this paper conducts a comparative study on current bit-selection methods with a focus on shortening 3D local binary descriptors. By analyzing several bit-selection techniques, we develop and evaluate various approaches to obtain a shortened version of a state-of-the-art feature remaining discriminative and robust. Through extensive experiments on four standard datasets with different data modalities (e.g., LiDAR and Kinect) and application scenarios (e.g., 3D object retrieval, 3D object recognition, and point cloud registration), we show that a small subset of representative bits are sufficient to achieve promising feature matching results as the initial descriptor. Moreover, the shortened binary descriptors still hold competitive or better distinctiveness and robustness compared to several state-of-the-art real-valued descriptors, e.g., spin image, SHOT, and RoPS , albeit being dramatically more efficient to match and store. Key to the foreseen research trend of local geometric feature description is dealing with compact binary descriptors; thus, our work may pave the way for this new research direction.},
  archive      = {J_ISCI},
  author       = {Siwen Quan and Jie Ma},
  doi          = {10.1016/j.ins.2019.09.028},
  journal      = {Information Sciences},
  pages        = {33-49},
  shortjournal = {Inf. Sci.},
  title        = {On shortened 3D local binary descriptors},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group public key encryption with equality test against
offline message recovery attack. <em>ISCI</em>, <em>510</em>, 16–32. (<a
href="https://doi.org/10.1016/j.ins.2019.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public key encryption with equality test (PKEET) allows a tester to check whether two ciphertexts encrypted under different public keys contain the same message without decrypting them. In this paper, we first introduce group mechanism into PKEET and propose a new primitive, namely group public key encryption with equality test (G-PKEET). G-PKEET can resist the attack that the tester can recover the message from a given ciphertext by exhaustively guessing the message offline. Furthermore, the group mechanism makes PKEET supporting group granularity authorization, which could authorize a tester to perform the equality test only on ciphertexts of group users, and could greatly reduce not only the storage cost of trapdoors but also the cost of computation and communication. We define security models for G-PKEET, present its concrete construction in bilinear pairings and prove its security in the random oracle model .},
  archive      = {J_ISCI},
  author       = {Yunhao Ling and Sha Ma and Qiong Huang and Ximing Li and Yunzhi Ling},
  doi          = {10.1016/j.ins.2019.09.025},
  journal      = {Information Sciences},
  pages        = {16-32},
  shortjournal = {Inf. Sci.},
  title        = {Group public key encryption with equality test against offline message recovery attack},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A microscopic-view infection model based on linear systems.
<em>ISCI</em>, <em>510</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2019.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the behavior of an infection network is typically addressed from either a microscopic or a macroscopic point-of-view. The trade-off is between following the individual states at some added complexity cost or looking at the ratio of infected nodes. In this paper, we focus on developing an alternative approach based on dynamical linear systems that combines the fine information of the microscopic view without the associated added complexity. Attention is shifted towards the problems of source localization and network topology discovery in the context of infection networks where a subset of the nodes is elected as observers. Finally, the possibility to control such networks is also investigated. Simulations illustrate the conclusions of the paper with particular interest on the relationship of the aforementioned problems with the topology of the network and the selected observer/controller nodes.},
  archive      = {J_ISCI},
  author       = {He Hao and Daniel Silvestre and Carlos Silvestre},
  doi          = {10.1016/j.ins.2019.09.021},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {A microscopic-view infection model based on linear systems},
  volume       = {510},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-objective pigeon-inspired optimization approach to
UAV distributed flocking among obstacles. <em>ISCI</em>, <em>509</em>,
515–529. (<a href="https://doi.org/10.1016/j.ins.2018.06.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV) flocking control with obstacle avoidance is a many-objective optimization problem for centralized algorithms. A UAV flocking distributed optimization control frame is designed to render the many-objective optimization problem into a multi-objective optimization solved by a single UAV. For different objectives, two kinds of criteria are raised to guarantee flight safety: the hard constraints that must be satisfied and the soft ones that will be optimized. Considering the restrictions of onboard computing resources, multi-objective pigeon-inspired optimization (MPIO) is modified based on the hierarchical learning behavior in pigeon flocks. On such a basis, a UAV distributed flocking control algorithm based on the modified MPIO is proposed to coordinate UAVs to fly in a stable formation under complex environments. Comparison experiments with basic MPIO and a modified non-dominated sorting genetic algorithm (NSGA-II) are carried out to show the feasibility, validity, and superiority of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Huaxin Qiu and Haibin Duan},
  doi          = {10.1016/j.ins.2018.06.061},
  journal      = {Information Sciences},
  pages        = {515-529},
  shortjournal = {Inf. Sci.},
  title        = {A multi-objective pigeon-inspired optimization approach to UAV distributed flocking among obstacles},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary mining of skyline clusters of attributed graph
data. <em>ISCI</em>, <em>509</em>, 501–514. (<a
href="https://doi.org/10.1016/j.ins.2018.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph clustering is one of the most important research topics in graph mining and network analysis . Given the abundance of data in many real-world applications, graph nodes and edges could be annotated with multiple sets of attributes that could be derived from heterogeneous data sources. The consideration of these attributes during graph clustering would facilitate the generation of graph clusters with balanced and cohesive intra-cluster structures and nodes with homogeneous properties. In this paper, we propose a graph clustering approach for mining skyline clusters over large attributed graphs based on the dominance relationship. Each skyline solution is optimized simultaneously for multiple fitness functions, each function is defined over the graph topology or over a particular set of attributes derived from multiple data sources. We evaluate our approach experimentally with a large protein-protein interaction network of the human interactome enriched with large sets of heterogeneous cancer-associated attributes. The results demonstrate the efficiency of our approach and show how integrating node attributes from multiple data sources can result in a more robust graph clustering than the consideration of the graph topology alone.},
  archive      = {J_ISCI},
  author       = {Wajdi Dhifli and Nour El Islem Karabadji and Mohamed Elati},
  doi          = {10.1016/j.ins.2018.09.053},
  journal      = {Information Sciences},
  pages        = {501-514},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary mining of skyline clusters of attributed graph data},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modified NSGA-III for sensor placement in water distribution
system. <em>ISCI</em>, <em>509</em>, 488–500. (<a
href="https://doi.org/10.1016/j.ins.2018.06.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contaminant events in drinkable water distribution systems (WDSs) have occurred frequently in recent years, causing severe damages, economic loss, and long-lasting societal impact. A critical and effective method to monitor WDS in real-time is deploying a water quality sensor. However, the placement of such sensors in a water distribution network (WDN) has become a foremost concern around the world. In this paper, we first analyze sensor placement mathematically and prove that it is NP-hard. Subsequently, we distinguish between single- and multi-objective optimization, and attempt, for the first time, to propose a modified NSGA-III to solve many-objective optimization for the sensor placement problem. WDNs of two sizes are employed and simulation results demonstrate the validity and effectiveness of the proposed model and methodology. The future research works are also identified and discussed.},
  archive      = {J_ISCI},
  author       = {Chengyu Hu and Liguo Dai and Xuesong Yan and Wenyin Gong and Xiaobo Liu and Ling Wang},
  doi          = {10.1016/j.ins.2018.06.055},
  journal      = {Information Sciences},
  pages        = {488-500},
  shortjournal = {Inf. Sci.},
  title        = {Modified NSGA-III for sensor placement in water distribution system},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Behavior of crossover operators in NSGA-III for large-scale
optimization problems. <em>ISCI</em>, <em>509</em>, 470–487. (<a
href="https://doi.org/10.1016/j.ins.2018.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional multi-objective optimization evolutionary algorithms (MOEAs) do not usually meet the requirements for online data processing because of their high computational costs. This drawback has resulted in difficulties in the deployment of MOEAs for multi-objective, large-scale optimization problems. Among different evolutionary algorithms , non-dominated sorting genetic algorithm-the third version (NSGA-III) is a fairly new method capable of solving large-scale optimization problems with acceptable computational requirements. In this paper, the performance of three crossover operators of the NSGA-III algorithm is benchmarked using a large-scale optimization problem based on human electroencephalogram (EEG) signal processing. The studied operators are simulated binary (SBX), uniform crossover (UC), and single point (SI) crossovers. Furthermore, enhanced versions of the NSGA-III algorithm are proposed through introducing the concept of Stud and designing several improved crossover operators of SBX, UC, and SI. The performance of the proposed NSGA-III variants is verified on six large-scale optimization problems. Experimental results indicate that the NSGA-III methods with UC and UC-Stud (UCS) outperform the other developed variants.},
  archive      = {J_ISCI},
  author       = {Jiao-Hong Yi and Li-Ning Xing and Gai-Ge Wang and Junyu Dong and Athanasios V. Vasilakos and Amir H. Alavi and Ling Wang},
  doi          = {10.1016/j.ins.2018.10.005},
  journal      = {Information Sciences},
  pages        = {470-487},
  shortjournal = {Inf. Sci.},
  title        = {Behavior of crossover operators in NSGA-III for large-scale optimization problems},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving large-scale many-objective optimization problems by
covariance matrix adaptation evolution strategy with scalable small
subpopulations. <em>ISCI</em>, <em>509</em>, 457–469. (<a
href="https://doi.org/10.1016/j.ins.2018.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent development in evolutionary multi- and many-objective optimization, the problems with large-scale decision variables still remain challenging. In this work, we propose a scalable small subpopulations based covariance matrix adaptation evolution strategy, namely S 3 -CMA-ES, for solving many-objective optimization problems with large-scale decision variables. The proposed S 3 -CMA-ES attempts to approximate the set of Pareto-optimal solutions using a series of small subpopulations instead of a whole population, where each subpopulation converges to only one solution. In the proposed S 3 -CMA-ES, a diversity improvement strategy is designed to generate and select new solutions. The performance of S 3 -CMA-ES is compared with five representative algorithms on 36 test instances with 5–15 objectives and 500–1500 decision variables. The empirical results demonstrate the superiority of the proposed S 3 -CMA-ES.},
  archive      = {J_ISCI},
  author       = {Huangke Chen and Ran Cheng and Jinming Wen and Haifeng Li and Jian Weng},
  doi          = {10.1016/j.ins.2018.10.007},
  journal      = {Information Sciences},
  pages        = {457-469},
  shortjournal = {Inf. Sci.},
  title        = {Solving large-scale many-objective optimization problems by covariance matrix adaptation evolution strategy with scalable small subpopulations},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel many-objective evolutionary algorithm based on
transfer matrix with kriging model. <em>ISCI</em>, <em>509</em>,
437–456. (<a href="https://doi.org/10.1016/j.ins.2019.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the curse of dimensionality caused by the increasing number of objectives, it is very challenging to tackle many-objective optimization problems (MaOPs). Aiming at this issue, this paper proposes a novel many-objective evolutionary algorithm , called Tk-MaOEA, based on transfer matrix assisted by Kriging model . In this approach, for the global space optimization , a transfer matrix is used as a map tool to reduce the number of objectives, which can simplify the optimization process. For the objective optimization , the Kriging model is incorporated to further reduce the computation cost. In addition, the fast non-dominated sorting and farthest-candidate selection (FCS) methods are used to guarantee the diversity of solutions. Comprehensive experiments on a set of benchmark functions have been conducted. Experimental results show that Tk-MaOEA is effective for solving complex MaOPs.},
  archive      = {J_ISCI},
  author       = {Ma Lianbo and Wang Rui and Chen Shengminjie and Cheng Shi and Wang Xingwei and Lin Zhiwei and Shi Yuhui and Huang Min},
  doi          = {10.1016/j.ins.2019.01.030},
  journal      = {Information Sciences},
  pages        = {437-456},
  shortjournal = {Inf. Sci.},
  title        = {A novel many-objective evolutionary algorithm based on transfer matrix with kriging model},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-layer interaction preference based multi-objective
evolutionary algorithm through decomposition. <em>ISCI</em>,
<em>509</em>, 420–436. (<a
href="https://doi.org/10.1016/j.ins.2018.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many problems in real world have not only one objective to be met. In the majority of cases, a set of trade-off solutions which spread evenly along the entire Pareto optimal front are generated by multi-objective evolutionary algorithms (MOEAs). Taking the preference of decision maker (DM) into consideration, some specified solutions can be obtained, which is of great interest in practical applications. In this paper, a novel multi-layer interaction preference based multi-objective evolutionary algorithm through decomposition (denoted as MLIP-MOEA/D) is proposed. In MLIP-MOEA/D, a multi-layer interactive strategy is developed during evolution, in the first-layer interaction, the DM will provide a reference vector and an initial radius to determine a preference range, then all solutions in this range will be updated. The algorithm will stop if the DM is satisfied with the first output result, otherwise it will go on to the second-layer interaction. In this step, the most preferred solution generated from the first-layer interaction will be chosen as the new preference direction, and the weight vector is redefined by the angle-based method, and the range of preferred region is reduced gradually, until the closest solution that meet the DM’s need is found. The algorithm is tested on a set of benchmark problems including DTLZ problems with more than three objectives, the experimental studies show that the proposed algorithm can effectively search the preferred solutions with the preference information and successfully deal with many-objective optimization problems .},
  archive      = {J_ISCI},
  author       = {Ruochen Liu and Runan Zhou and Rui Ren and Jiangdi Liu and Licheng Jiao},
  doi          = {10.1016/j.ins.2018.09.069},
  journal      = {Information Sciences},
  pages        = {420-436},
  shortjournal = {Inf. Sci.},
  title        = {Multi-layer interaction preference based multi-objective evolutionary algorithm through decomposition},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AnD: A many-objective evolutionary algorithm with
angle-based selection and shift-based density estimation. <em>ISCI</em>,
<em>509</em>, 400–419. (<a
href="https://doi.org/10.1016/j.ins.2018.06.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary many-objective optimization has been gaining increasing attention from the evolutionary computation research community. Much effort has been devoted to addressing this issue by improving the scalability of multiobjective evolutionary algorithms , such as Pareto-based, decomposition-based, and indicator-based approaches. Different from current work, we propose an alternative algorithm in this paper called AnD, which consists of an an gle-based selection strategy and a shift-based d ensity estimation strategy. These two strategies are employed in the environmental selection to delete poor individuals one by one. Specifically, the former is devised to find a pair of individuals with the minimum vector angle, which means that these two individuals have the most similar search directions. The latter, which takes both diversity and convergence into account, is adopted to compare these two individuals and to delete the worse one. AnD has a simple structure, few parameters, and no complicated operators. The performance of AnD is compared with that of seven state-of-the-art many-objective evolutionary algorithms on a variety of benchmark test problems with up to 15 objectives. The results suggest that AnD can achieve highly competitive performance. In addition, we also verify that AnD can be readily extended to solve constrained many-objective optimization problems.},
  archive      = {J_ISCI},
  author       = {Zhi-Zhong Liu and Yong Wang and Pei-Qiu Huang},
  doi          = {10.1016/j.ins.2018.06.063},
  journal      = {Information Sciences},
  pages        = {400-419},
  shortjournal = {Inf. Sci.},
  title        = {AnD: A many-objective evolutionary algorithm with angle-based selection and shift-based density estimation},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An angle dominance criterion for evolutionary many-objective
optimization. <em>ISCI</em>, <em>509</em>, 376–399. (<a
href="https://doi.org/10.1016/j.ins.2018.12.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that Pareto dominance encounters difficulties in many-objective optimization. This strict criterion could make most individuals of a population incomparable in a high-dimensional space. A straightforward approach to tackle this issue is modify the Pareto dominance criterion. This is typically done by relaxing the dominance region. However, this modification is often associated with one or more parameters of determining the relaxation degree, and the performance of the corresponding algorithm could be sensitive to such parameters. In this paper, we propose a new dominance criterion, angle dominance, to deal with many-objective optimization problems. This angle dominance criterion can provide sufficient selection pressure towards the Pareto front and be exempt from the parameter tuning. In addition, an interesting property of the proposed dominance criterion, in contrast to existing dominance criteria, lies in its capability to reflect an individual’s extensity in the population. The angle dominance is integrated into NSGA-II (instead of Pareto dominance) and has demonstrated high competitiveness in many-objective optimization in comparison with a range of peer algorithms.},
  archive      = {J_ISCI},
  author       = {Yuan Liu and Ningbo Zhu and Kenli Li and Miqing Li and Jinhua Zheng and Keqin Li},
  doi          = {10.1016/j.ins.2018.12.078},
  journal      = {Information Sciences},
  pages        = {376-399},
  shortjournal = {Inf. Sci.},
  title        = {An angle dominance criterion for evolutionary many-objective optimization},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive penalty-based boundary intersection method for
many-objective optimization problem. <em>ISCI</em>, <em>509</em>,
356–375. (<a href="https://doi.org/10.1016/j.ins.2019.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with domination-based methods, the multi-objective evolutionary algorithm based on decomposition (MOEA/D) is less prone to the difficulty caused by an increase in the number of objectives. It is a promising algorithmic framework for solving many-objective optimization problems (MaOPs). In MOEA/D, the target MaOP is decomposed into a set of single-objective problems by using a scalarizing function with evenly specified weight vectors . Among the available scalarizing functions, penalty-based boundary intersection (PBI) with an appropriate penalty parameter is known to perform well. However, its performance is heavily influenced by the setting of the penalty factor ( θ ), which can take a value from zero to +∞. A limited amount of work has thus far considered the choice of an appropriate value of θ . This paper presents a comprehensive experimental study on WFG and WFG-extend problems featuring two to 15 objectives. A range of values of θ is investigated to understand its influence on the performance of the PBI-based MOEA/D (MOEA/D-PBI). Based on the observations, the range of values of θ are divided into three sub-regions, and a two-stage adaptive penalty scheme is proposed to adaptively choose an appropriate value from 0.001 to 8000 during an optimization run. The results of experiments show that, the robustness of MOEA/D-PBI can be significantly enhanced using the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Yutao Qi and Dazhuang Liu and Xiaodong Li and Jiaojiao Lei and Xiaoying Xu and Qiguang Miao},
  doi          = {10.1016/j.ins.2019.03.040},
  journal      = {Information Sciences},
  pages        = {356-375},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive penalty-based boundary intersection method for many-objective optimization problem},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Objective extraction via fuzzy clustering in evolutionary
many-objective optimization. <em>ISCI</em>, <em>509</em>, 343–355. (<a
href="https://doi.org/10.1016/j.ins.2018.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many-objective optimization problems (MaOPs) , which have more than three objectives to optimize simultaneously, have attracted much attention recently in the community of evolutionary computation. Most existing multi-objective evolutionary algorithms (MOEAs) can fail to find a well-representative set of Pareto optimal solutions in dealing with MaOPs. To solve this problem, one methodology is to improve the search ability of existing MOEAs to approximate the Pareto optimal solutions . A variety of such strategies have been proposed. The other methodology is to simplify MaOPs and deal with the simplified ones with existing MOEAs. This paper follows the second methodology by converting an MaOP into a series of multi-objective optimization problems (MOPs) with fewer objectives and solving these MOPs in an online manner. To achieve this goal, new objectives are constructed as linear combinations of the original objectives. The weight vectors are extracted through fuzzy clustering based on the objective values found during the search. Comparing to other dimension reduction based approaches, the new approach constructs new objectives by using all the information of the original objectives. Extensive experimental studies on ill-posed MaOPs are conducted to reveal the performance of our method and to compare with other related algorithms.},
  archive      = {J_ISCI},
  author       = {Aimin Zhou and Yirui Wang and Jinyuan Zhang},
  doi          = {10.1016/j.ins.2018.11.032},
  journal      = {Information Sciences},
  pages        = {343-355},
  shortjournal = {Inf. Sci.},
  title        = {Objective extraction via fuzzy clustering in evolutionary many-objective optimization},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast hypervolume approximation scheme based on a
segmentation strategy. <em>ISCI</em>, <em>509</em>, 320–342. (<a
href="https://doi.org/10.1016/j.ins.2019.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypervolume indicator based evolutionary algorithms have been reported to be very promising in many-objective optimization, but the high computational complexity of hypervolume calculation in high dimensions restrains its further applications and developments. In this paper, we develop a fast hypervolume approximation method with both improved speed and accuracy than the previous approximation methods via a new segmentation strategy. The proposed approach consists of two crucial process: segmentation and approximation. The segmentation process recursively finds areas easy to be measured and quantified from the original geometric figure as many as possible, and then divides the measurement of the rest areas into several subproblems . In the approximation process, an improved Monte Carlo simulation is developed to estimate these subproblems . Those two processes are mutually complementary to simultaneously improve the accuracy and the speed of hypervolume approximation. To validate its effectiveness, experimental studies on four widely-used instances are conducted and the simulation results show that the proposed method is ten times faster than other comparison algorithms with a same measurement error. Furthermore, we integrate an incremental version of this method into the framework of SMS-EMOA, and the performance of the integrated algorithm is also very competitive among the experimental algorithms.},
  archive      = {J_ISCI},
  author       = {Weisen Tang and Hai-Lin Liu and Lei Chen and Kay Chen Tan and Yiu-ming Cheung},
  doi          = {10.1016/j.ins.2019.02.054},
  journal      = {Information Sciences},
  pages        = {320-342},
  shortjournal = {Inf. Sci.},
  title        = {Fast hypervolume approximation scheme based on a segmentation strategy},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Special issue – advanced methods for evolutionary many
objective optimization. <em>ISCI</em>, <em>509</em>, 318–319. (<a
href="https://doi.org/10.1016/j.ins.2019.09.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Rui Wang and Guohua Wu},
  doi          = {10.1016/j.ins.2019.09.081},
  journal      = {Information Sciences},
  pages        = {318-319},
  shortjournal = {Inf. Sci.},
  title        = {Special issue – advanced methods for evolutionary many objective optimization},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “preventing sybil attacks in P2P file sharing
networks based on the evolutionary game model” [information sciences 470
(2019) 94–108]. <em>ISCI</em>, <em>509</em>, 317. (<a
href="https://doi.org/10.1016/j.ins.2019.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Morteza Babazadeh Shareh and Hamidreza Navidi and Hamid Haj Seyyed Javadi and Mehdi HosseinZadeh},
  doi          = {10.1016/j.ins.2019.03.017},
  journal      = {Information Sciences},
  pages        = {317},
  shortjournal = {Inf. Sci.},
  title        = {Corrigendum to “Preventing sybil attacks in P2P file sharing networks based on the evolutionary game model” [Information sciences 470 (2019) 94–108]},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Dynamic event-triggered mechanism for h∞ non-fragile state
estimation of complex networks under randomly occurring sensor
saturations. <em>ISCI</em>, <em>509</em>, 304–316. (<a
href="https://doi.org/10.1016/j.ins.2019.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of non-fragile H ∞ state estimation is investigated for a class of discrete-time complex networks subject to randomly occurring sensor saturations (ROSSs) under a dynamic event-triggered mechanism (DETM). The ROSS phenomenon is taken into account in the network measurements as a reflection of the probabilistic limitation of the physical sensors, and the DETM is implemented to govern the signal transmission from the sensor to its corresponding state estimator . The objective of the problem addressed is to design an H ∞ non-fragile state estimator under the DETM that can tolerate the possible gain perturbations, thereby possessing the desired non-fragility. By constructing a novel Lyapunov function , a sufficient condition is established such that the estimation error dynamics is exponentially mean-square stable with a prescribed H ∞ performance level, and then the estimator gains are parameterized according to certain matrix inequalities. A simulation example is provided to demonstrate the effectiveness of the proposed state estimation scheme.},
  archive      = {J_ISCI},
  author       = {Qi Li and Zidong Wang and Weiguo Sheng and Fawaz E. Alsaadi and Fuad E. Alsaadi},
  doi          = {10.1016/j.ins.2019.08.063},
  journal      = {Information Sciences},
  pages        = {304-316},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered mechanism for h∞ non-fragile state estimation of complex networks under randomly occurring sensor saturations},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward conditionally anonymous bitcoin transactions: A
lightweight-script approach. <em>ISCI</em>, <em>509</em>, 290–303. (<a
href="https://doi.org/10.1016/j.ins.2019.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bitcoin is being explored for applications in various Internet of Things (IoT) scenarios as a peer-to-peer payment platform. However, security and anonymity problems exist with Bitcoin , which threaten vulnerable IoT facilities. This paper aims to achieve conditional anonymity inside Bitcoin transactions. We first propose an identity-based conditionally anonymous signature (ICAS) algorithm and then design a lightweight Bitcoin script scheme (named pay-to-public-key-hash-with-conditional-anonymity or P2PKHCA), which applies the ICAS algorithm to make conditionally anonymous Bitcoin transactions. P2PKHCA allows the identity manager to trace the real identity of users while preserving users’ anonymity. Furthermore, P2PKHCA is backward compatible in terms of being able to work seamlessly with the existing Bitcoin script scheme pay-to-public-key-hash (P2PKH) in the Bitcoin network. We conduct a security analysis to verify the security features of P2PKHCA and employ a performance evaluation in terms of the cryptographic time and space costs by comparison with P2PKH. The simulation results demonstrate the effectiveness of P2PKHCA in reducing both time cost and data size.},
  archive      = {J_ISCI},
  author       = {Lun Li and Jiqiang Liu and Xiaolin Chang and Tianhao Liu and Jingxian Liu},
  doi          = {10.1016/j.ins.2019.09.011},
  journal      = {Information Sciences},
  pages        = {290-303},
  shortjournal = {Inf. Sci.},
  title        = {Toward conditionally anonymous bitcoin transactions: A lightweight-script approach},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). YAKE! Keyword extraction from single documents using
multiple local features. <em>ISCI</em>, <em>509</em>, 257–289. (<a
href="https://doi.org/10.1016/j.ins.2019.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms, thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available. An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents, nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on texts of different sizes, languages, and domains.},
  archive      = {J_ISCI},
  author       = {Ricardo Campos and Vítor Mangaravite and Arian Pasquali and Alípio Jorge and Célia Nunes and Adam Jatowt},
  doi          = {10.1016/j.ins.2019.09.013},
  journal      = {Information Sciences},
  pages        = {257-289},
  shortjournal = {Inf. Sci.},
  title        = {YAKE! keyword extraction from single documents using multiple local features},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-view laplacian eigenmaps based on bag-of-neighbors for
RGB-d human emotion recognition. <em>ISCI</em>, <em>509</em>, 243–256.
(<a href="https://doi.org/10.1016/j.ins.2019.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion recognition is an important direction in the fields of human-computer interaction and computer vision . However, most existing human emotion researches just focus on one view of the study objects. In this paper, we first introduce a RGB-D video-emotion dataset and a RGB-D face-emotion dataset for research, both of which are collected under psychological principles and methods. Then we propose a new supervised nonlinear multi-view laplacian eigenmaps (MvLE) approach and a multi-hidden-layer out-of-sample network (MHON) that can make full use of RGB view and Depth view of the two datasets. MvLE is employed to map the samples of both views from original spaces into a common subspace. As samples of RGB view and Depth view lie on different spaces, a new distance metric bag of neighbors (BON) introduced in MvLE can capture their similar distributions. Moreover, to adapt to large-scale applications, MHON is developed to get the low-dimensional representations of additional samples and predict their labels. MvLE and MHON can deal with the cases that RGB view and Depth view have different dimensions of original spaces, even different number of samples or categories. The experiment results indicate that the proposed methods achieve considerable improvement over some state-of-art methods.},
  archive      = {J_ISCI},
  author       = {Shenglan Liu and Shuai Guo and Wei Wang and Hong Qiao and Yang Wang and Wenbo Luo},
  doi          = {10.1016/j.ins.2019.08.035},
  journal      = {Information Sciences},
  pages        = {243-256},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view laplacian eigenmaps based on bag-of-neighbors for RGB-D human emotion recognition},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards efficient and effective discovery of markov blankets
for feature selection. <em>ISCI</em>, <em>509</em>, 227–242. (<a
href="https://doi.org/10.1016/j.ins.2019.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Markov blanket (MB), a key concept in a Bayesian network (BN), is essential for large-scale BN structure learning and optimal feature selection. Many MB discovery algorithms that are either efficient or effective have been proposed for addressing high-dimensional data. In this paper, we propose a new algorithm for E fficient and E ffective MB discovery, called EEMB. Specifically, given a target feature, the EEMB algorithm discovers the PC (i.e., parents and children) and spouses of the target simultaneously and can distinguish PC from spouses during MB discovery. We compare EEMB with the state-of-the-art MB discovery algorithms using a series of benchmark BNs and real-world datasets. The experiments demonstrate that EEMB is competitive with the fastest MB discovery algorithm in terms of computational efficiency and achieves almost the same MB discovery accuracy as the most accurate of the compared algorithms.},
  archive      = {J_ISCI},
  author       = {Hao Wang and Zhaolong Ling and Kui Yu and Xindong Wu},
  doi          = {10.1016/j.ins.2019.09.010},
  journal      = {Information Sciences},
  pages        = {227-242},
  shortjournal = {Inf. Sci.},
  title        = {Towards efficient and effective discovery of markov blankets for feature selection},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-fragile h∞ consensus tracking of nonlinear multi-agent
systems with switching topologies and transmission delay via
sampled-data control. <em>ISCI</em>, <em>509</em>, 210–226. (<a
href="https://doi.org/10.1016/j.ins.2019.08.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the sampled-data non-fragile H ∞ consensus tracking problem for Lipschitz nonlinear multi-agent systems with switching topologies and exogenous disturbances is investigated. Each possible interaction topology in the switching topologies set is assumed to contain a directed spanning tree. With introducing a sampled-data mechanism, the information is only capable of being aperiodically transmitted in the network at each sampling instant and unavoidably subject to a transmission delay. Then a protocol collecting the delayed sampled-data information from neighboring agents is proposed not only to provide robustness against some level of controller gain perturbations, but also to regulate consensus performance with an H ∞ disturbance attenuation level. By using tools from algebraic graph theory and Lyapunov–Krasovskii functional technique, it is proved that the concerned consensus tracking problem is solvable if the resultant consensus error system can be asymptotically stabilized. Simulation results verify the theoretical analysis.},
  archive      = {J_ISCI},
  author       = {Xiangli Jiang and Guihua Xia and Zhiguang Feng and Tao Li},
  doi          = {10.1016/j.ins.2019.08.078},
  journal      = {Information Sciences},
  pages        = {210-226},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile h∞ consensus tracking of nonlinear multi-agent systems with switching topologies and transmission delay via sampled-data control},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A knee-guided prediction approach for dynamic
multi-objective optimization. <em>ISCI</em>, <em>509</em>, 193–209. (<a
href="https://doi.org/10.1016/j.ins.2019.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although dynamic multi-objective optimization problems dictate the evolutionary algorithms to quickly track the varying Pareto front when the environmental change occurs, the decision maker in the loop still needs to select a final optimal solution among a large number of candidate solutions before and after the environmental change. Most designs focus on searching for a well-distributed Pareto front which inadvertently demand excessive computational burden during the evolutionary process. In this paper, we propose a novel knee-guided prediction evolutionary algorithm (KPEA) which maintains non-dominated solutions near knee and boundary regions, in order to reduce the burden of maintaining a large and diversified population throughout the evolution process. When a change is detected, this design relocates the knee and boundary solutions based on the movement of the global knee solution in the new environment. In this way, this algorithm incurs a lower computational cost, allowing the evolutionary algorithm to converge quickly. In order to test the performance of the proposed algorithm, five popular dynamic multi-objective evolutionary algorithms (DMOEAs) are compared with KPEA based on two newly proposed metrics. The experimental results validate that the proposed algorithm effectively and efficiently converges to the global knee solution under the changing environments.},
  archive      = {J_ISCI},
  author       = {Fei Zou and Gary G. Yen and Lixin Tang},
  doi          = {10.1016/j.ins.2019.09.016},
  journal      = {Information Sciences},
  pages        = {193-209},
  shortjournal = {Inf. Sci.},
  title        = {A knee-guided prediction approach for dynamic multi-objective optimization},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic relation extraction using sequential and
tree-structured LSTM with attention. <em>ISCI</em>, <em>509</em>,
183–192. (<a href="https://doi.org/10.1016/j.ins.2019.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic relation extraction is crucial to automatically constructing a knowledge graph (KG), and it supports a variety of downstream natural language processing (NLP) tasks such as query answering (QA), semantic search and textual entailment . In addition, the semantic relation extraction task is mainly responsible for identifying entity pairs from raw texts and extracting the semantic relations between the extracted entity pairs. Existing methods consider only lexical-level features and often ignore syntactic features, resulting in poor relation extraction performance. By analyzing the necessity of the syntactic dependency and the contributions of words in a sentence to relation extraction, this paper proposes an end-to-end method that uses bidirectional tree-structured long short-term memory (LSTM) to extract structural features based on the dependency tree of a sentence. To enhance the performance of the relation extraction, the bidirectional sequential LSTM with attention is used to identify word-based features including the positional information of entity pairs and the contribution of words. Then, structural features and word-based features are concatenated to optimize the relation extraction performance. Finally, the proposed method is used on the SemEval 2010 task 8 and the CoNLL04 datasets to validate its performance. The experimental results show that the proposed method achieves state-of-the-art results on the SemEval 2010 task 8 and the CoNLL04 datasets.},
  archive      = {J_ISCI},
  author       = {ZhiQiang Geng and GuoFei Chen and YongMing Han and Gang Lu and Fang Li},
  doi          = {10.1016/j.ins.2019.09.006},
  journal      = {Information Sciences},
  pages        = {183-192},
  shortjournal = {Inf. Sci.},
  title        = {Semantic relation extraction using sequential and tree-structured LSTM with attention},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Seeking affinity structure: Strategies for improving m-best
graph matching. <em>ISCI</em>, <em>509</em>, 164–182. (<a
href="https://doi.org/10.1016/j.ins.2019.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art methods for finding the m -best solutions to graph matching (QAP) rely on exclusion strategies. The k -th best solution is found by excluding all better ones from the search space. This provides diversity, a natural requirement for transforming a MAP problem into a m -best one. Since diversity enforces mode hopping, it is usually combined with a mode-approximation strategy such as marginalisation . However, these methods are generic insofar they do not incorporate the detailed structure of the problem at hand, i.e. the properties of the global affinity matrix which characterise the search space. Without this knowledge, it is thus hard to devise a practical criterion for choosing the next variable to clamp. In this paper, we propose several strategies to select the next variable to clamp, spanning the whole range between depth-first and breadth-first search, and we contribute with a unifying view for characterising the search space on the fly. Our strategies are: a) Number of factors in which the variables participate, b) centrality measures associated with the affinity matrix , and c) discrete pooling. Our experiments show that max number of factors and centrality provide a trade-off between efficiency and accuracy, whereas discrete pooling leads to an improvement of the state-of-the-art},
  archive      = {J_ISCI},
  author       = {Manuel Curado and Francisco Escolano and Miguel A. Lozano and Edwin R. Hancock},
  doi          = {10.1016/j.ins.2019.09.014},
  journal      = {Information Sciences},
  pages        = {164-182},
  shortjournal = {Inf. Sci.},
  title        = {Seeking affinity structure: Strategies for improving m-best graph matching},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Two-layer fuzzy multiple random forest for speech emotion
recognition in human-robot interaction. <em>ISCI</em>, <em>509</em>,
150–163. (<a href="https://doi.org/10.1016/j.ins.2019.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-layer fuzzy multiple random forest (TLFMRF) is proposed for speech emotion recognition . When recognizing speech emotion, there are usually some problems. One is that feature extraction relies on personalized features. The other is that emotion recognition doesn’t consider the differences among different categories of people. In the proposal, personalized and non-personalized features are fused for speech emotion recognition . High dimensional emotional features are divided into different subclasses by adopting the fuzzy C-means clustering algorithm , and multiple random forest is used to recognize different emotional states. Finally, a TLFMRF is established. Moreover, a separate classification of certain emotions which are difficult to recognize to some extent is conducted. The results show that the TLFMRF can identify emotions in a stable manner. To demonstrate the effectiveness of the proposal, experiments on CASIA corpus and Berlin EmoDB are conducted. Experimental results show the recognition accuracies of the proposal are 1.39\%–7.64\% and 4.06\%–4.30\% higher than that of back propagation neural network and random forest respectively. Meanwhile, preliminary application experiments are also conducted to investigate the emotional social robot system, and application results indicate that mobile robot can real-time track six basic emotions, including angry, fear, happy, neutral, sad, and surprise.},
  archive      = {J_ISCI},
  author       = {Luefeng Chen and Wanjuan Su and Yu Feng and Min Wu and Jinhua She and Kaoru Hirota},
  doi          = {10.1016/j.ins.2019.09.005},
  journal      = {Information Sciences},
  pages        = {150-163},
  shortjournal = {Inf. Sci.},
  title        = {Two-layer fuzzy multiple random forest for speech emotion recognition in human-robot interaction},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple-user closest keyword-set querying in road networks.
<em>ISCI</em>, <em>509</em>, 133–149. (<a
href="https://doi.org/10.1016/j.ins.2019.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location-based group queries have attracted increasing attention due to the prevalence of location-based services (LBS) and location-based social networks (LBSN). An important and practical application in these queries is the m ultiple-user c losest k eyword- s et (MCKS) query that aims to search a set of Points of Interest (POIs) for multiple users in road networks . These POIs cover the query keyword-set, are close to the locations of multiple users, and are close to each other. This problem has been proved to be NP-hard. Unfortunately, existing solutions cannot handle this query efficiently and effectively. Specifically, the existing exact approach does not scale well with the network sizes and the existing approximation approaches, though scalable, have large error bounds. To address the above issues, a series of enhanced algorithms are proposed for the MCKS query problem in this paper. Specifically, a 3-approximation feasible result search algorithm is first proposed. Then, using the cost of the result returned by this algorithm as an upper bound, we present an efficient exact algorithm and an approximation algorithm with better performance guarantee. The exact algorithm is designed based on a set of efficient optimizations. The approximation algorithm improves the best-known approximation ratio from 15 7 157 to 1.5. Extensive performance studies with two real datasets demonstrate the effectiveness and efficiency of our proposed algorithms, which outperform existing algorithms significantly.},
  archive      = {J_ISCI},
  author       = {Sen Zhao and Xin Cao},
  doi          = {10.1016/j.ins.2019.09.009},
  journal      = {Information Sciences},
  pages        = {133-149},
  shortjournal = {Inf. Sci.},
  title        = {Multiple-user closest keyword-set querying in road networks},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leakage-resilient group signature: Definitions and
constructions. <em>ISCI</em>, <em>509</em>, 119–132. (<a
href="https://doi.org/10.1016/j.ins.2019.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group signature scheme provides a way to sign messages without revealing identities of the authentic signers. To achieve such functionality and to avoid the abuse of its power, anonymity and traceability are two essential properties for group signature scheme. In traditional group signature schemes, however, these two security properties are based on the perfectly-secure storage of secret information. Unfortunately, defective implementation of a cryptosystem always exists, and therefore unexpected information leakage is inevitable. In reality, side-channel attacks allow an adversary breaks the security of the whole system by eavesdropping a portion of secret information. To tackle this issue, in our work we present the security models of leakage-resilient group signature in bounded leakage setting and furthermore, propose three new black-box constructions of leakage-resilient group signature based on the proposed security models.},
  archive      = {J_ISCI},
  author       = {Jianye Huang and Qiong Huang and Willy Susilo},
  doi          = {10.1016/j.ins.2019.09.004},
  journal      = {Information Sciences},
  pages        = {119-132},
  shortjournal = {Inf. Sci.},
  title        = {Leakage-resilient group signature: Definitions and constructions},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully probabilistic design unifies and supports dynamic
decision making under uncertainty. <em>ISCI</em>, <em>509</em>, 104–118.
(<a href="https://doi.org/10.1016/j.ins.2019.08.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fully probabilistic design (FPD) of decision strategies models the closed decision loop as well as decision aims and constraints by joint probabilities of involved variables. FPD takes the minimiser of cross entropy (CE) of the closed-loop model to its ideal counterpart, expressing the decision aims and constraints, as the optimal strategy . FPD: (a) got an axiomatic basis; (b) extended the decision making (DM) optimising a subjective expected utility (SEU); (c) was nontrivially applied; (d) advocated CE as a proper similarity measure for an approximation of a given probability distribution; (d) generalised the minimum CE principle for a choice of the distribution, which respects its incomplete specification; (e) has opened a way to the cooperation based on sharing of probability distributions. When trying to survey the listed results, scattered in a range of publications, we have found that the results under (b), (d) and (e) can be refined and non-trivially generalised. This determines the paper aims: to provide a complete concise description of FPD with its use and open problems outlined.},
  archive      = {J_ISCI},
  author       = {Miroslav Kárný},
  doi          = {10.1016/j.ins.2019.08.082},
  journal      = {Information Sciences},
  pages        = {104-118},
  shortjournal = {Inf. Sci.},
  title        = {Fully probabilistic design unifies and supports dynamic decision making under uncertainty},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HAPE: A programmable big knowledge graph platform.
<em>ISCI</em>, <em>509</em>, 87–103. (<a
href="https://doi.org/10.1016/j.ins.2019.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heaven Ape (HAPE) is an integrated big knowledge graph platform supporting the construction, management, and operation of large to massive scale knowledge graphs. Its current version described in this paper is a prototype, which consists of three parts: a big knowledge graph knowledge base, a knowledge graph browser on the client side, and a knowledge graph operating system on the server side. The platform is programmed in two high level scripting languages : JavaScript for programming the client side functions and Python for the server side functions. For making the programming more suitable for big knowledge processing and more friendly to knowledge programmers, we have developed two versions of knowledge scripting languages , namely K-script-c and K-script-s, for performing very high level knowledge programming of client resp. server side functions. HAPE borrows ideas from some well-known knowledge graph processing techniques and also invents some new ones as our creation. As an experiment, we transformed a major part of the DBpedia knowledge base and reconstructed it as a big knowledge graph. It works well in some application tests and provides acceptable efficiency.},
  archive      = {J_ISCI},
  author       = {Ruqian LU and Chaoqun FEI and Chuanqing WANG and Shunfeng GAO and Han QIU and Songmao ZHANG and Cungen CAO},
  doi          = {10.1016/j.ins.2019.08.051},
  journal      = {Information Sciences},
  pages        = {87-103},
  shortjournal = {Inf. Sci.},
  title        = {HAPE: A programmable big knowledge graph platform},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making based on multiplicative consistency
and consensus of fuzzy linguistic preference relations. <em>ISCI</em>,
<em>509</em>, 71–86. (<a
href="https://doi.org/10.1016/j.ins.2019.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy linguistic preference relations (FLPRs) are an efficient way to express qualitative judgments of decision makers (DMs). This paper proposes a new group decision making (GDM) method based on the multiplicative consistency and consensus of FLPRs. First, we propose the concepts of consistency index and acceptable multiplicative consistent FLPRs. Then, we propose a method to improve the consistency of a FLPR, by which an acceptable multiplicative consistent FLPR is derived. Subsequently, we propose the consensus index for measuring the agreement among DMs. With respect to some FLPRs have an unacceptable multiplicative consistency and an unacceptable consensus, we propose an integer programming model to make both their consistency and consensus better to yield improved FLPRs with acceptable multiplicative consistency and consensus. Furthermore, the DMs’ comprehensive weight vector is determined. Then, we propose a new GDM algorithm following the multiplicative consistency and consensus of FLPRs. Finally, the feasibility and the applicability of the proposed GDM method are illustrated via an application example and some comparative analyses with the existing GDM methods.},
  archive      = {J_ISCI},
  author       = {Zhang Zhiming and Chen Shyi-Ming and Wang Chao},
  doi          = {10.1016/j.ins.2019.09.002},
  journal      = {Information Sciences},
  pages        = {71-86},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on multiplicative consistency and consensus of fuzzy linguistic preference relations},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neighbourhood-based undersampling approach for handling
imbalanced and overlapped data. <em>ISCI</em>, <em>509</em>, 47–70. (<a
href="https://doi.org/10.1016/j.ins.2019.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalanced datasets are common across different domains including health, security, banking and others. A typical supervised learning algorithm tends to be biased towards the majority class when dealing with imbalanced datasets. The learning task becomes more challenging when there is also an overlap of instances from different classes. In this paper, we propose an undersampling framework for handling class imbalance in binary datasets by removing potential overlapped data points. Our methods are designed to identify and eliminate majority class instances from the overlapping region. Accurate identification and elimination of these instances maximise the visibility of the minority class instances and at the same time minimises excessive elimination of data, which reduces information loss. Four methods based on neighbourhood searching with different criteria to identify potential overlapped instances are proposed in this paper. Extensive experiments using simulated and real-world datasets were carried out. Results show comparable performance with state-of-the-art methods across different common metrics with exceptional and statistically significant improvements in sensitivity.},
  archive      = {J_ISCI},
  author       = {Pattaramon Vuttipittayamongkol and Eyad Elyan},
  doi          = {10.1016/j.ins.2019.08.062},
  journal      = {Information Sciences},
  pages        = {47-70},
  shortjournal = {Inf. Sci.},
  title        = {Neighbourhood-based undersampling approach for handling imbalanced and overlapped data},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Sampled-position states based consensus of networked
multi-agent systems with second-order dynamics subject to communication
delays. <em>ISCI</em>, <em>509</em>, 36–46. (<a
href="https://doi.org/10.1016/j.ins.2019.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the sampled-position states based consensus of networked multi-agent systems with second-order dynamics, where agents are connected through communication channels subject to time-varying communication delays. Note that consensus in such systems cannot be reached if using only the current sampled-position states. This paper investigates the positive effects of time-varying communication delays on the consensus. For two cases, where a directed graph has a fixed or switching topology , several sufficient conditions on consensus are derived by using a discretized Lyapunov-Krasovskii functional method. Based on the obtained conditions, suitable control protocols can be devised through tuning two parameters. Finally, simulation shows that consensus can be achieved using sampled-position states if the time-varying communication delays are within a certain time interval with its lower bound strictly greater than zero.},
  archive      = {J_ISCI},
  author       = {Yanping Yang and Xian-Ming Zhang and Wangli He and Qing-Long Han and Chen Peng},
  doi          = {10.1016/j.ins.2019.08.073},
  journal      = {Information Sciences},
  pages        = {36-46},
  shortjournal = {Inf. Sci.},
  title        = {Sampled-position states based consensus of networked multi-agent systems with second-order dynamics subject to communication delays},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An unsupervised constrained optimization approach to
compressive summarization. <em>ISCI</em>, <em>509</em>, 22–35. (<a
href="https://doi.org/10.1016/j.ins.2019.08.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic summarization is typically aimed at selecting as much information as possible from text documents using a predefined number of words. Extracting complete sentences into a summary is not an optimal way to solve this problem due to redundant information that is contained in some sentences. Removing the redundant information and compiling a summary from compressed sentences should provide a much more accurate result. Major challenges of compressive approaches include the cost of creating large summarization corpora for training the supervised methods, the linguistic quality of compressed sentences, the coverage of the relevant content, and the time complexity of the compression procedure. In this work, we attempt to address these challenges by proposing an unsupervised polynomial-time compressive summarization algorithm. The proposed algorithm iteratively removes redundant parts from original sentences. It uses constituency-based parse trees and hand-crafted rules for generating elementary discourse units (EDUs) from their subtrees (standing for phrases) and selects ones with a sufficient tree gain. We define a parse tree gain as a weighted function of its node weights, which can be computed by any extractive summarization model capable of assigning importance weights to terms. The results of automatic evaluations on a single-document summarization task confirm that the proposed sentence compression procedure helps to avoid redundant information in the generated summaries. Furthermore, the results of human evaluations confirm that the linguistic quality—in terms of readability and coherency—is preserved in the compressed summaries while improving their coverage. However, the same evaluations show that compression in general harms the grammatical correctness of compressed sentences though, in most cases, this effect is not significant for the proposed compression procedure.},
  archive      = {J_ISCI},
  author       = {Natalia Vanetik and Marina Litvak and Elena Churkin and Mark Last},
  doi          = {10.1016/j.ins.2019.08.079},
  journal      = {Information Sciences},
  pages        = {22-35},
  shortjournal = {Inf. Sci.},
  title        = {An unsupervised constrained optimization approach to compressive summarization},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An online-learning-based evolutionary many-objective
algorithm. <em>ISCI</em>, <em>509</em>, 1–21. (<a
href="https://doi.org/10.1016/j.ins.2019.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When optimizing many-objective problems (MaOP), the same strategy might behave differently when facing problems with different features. Therefore, obtaining problem features helps to obtain high-quality solutions. However, in practice, the problem features are unknown during the optimization process. In this case, learning to adjust strategies to match the problem features is a challenging work. In this paper, a learning-based algorithm is proposed, aimed to enhance the generalization ability . On the basis of a decomposition-based many-objective optimization framework, a learning automaton (LA) is included in the algorithm. The LA adjusts the evolutionary strategies of the algorithm to adapt to the problem characteristics, according to the feedback information during the optimizing procedure . An external archive is employed to store the Pareto non-dominant solutions. Based on the external archive , a reference vector adjustment strategy is designed to enhance the capability of solving problems with a degenerate or discrete Pareto front (PF). To validate the performance of the proposed algorithm, a comparison experiment is conducted on a novel authority test suite. Five state-of-the-art algorithms are selected as peer algorithms. The results of the experiment indicate that the proposed algorithm obtains satisfactory performance in determining the convergence and the approximation of the PF.},
  archive      = {J_ISCI},
  author       = {Haitong Zhao and Changsheng Zhang},
  doi          = {10.1016/j.ins.2019.08.069},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {An online-learning-based evolutionary many-objective algorithm},
  volume       = {509},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synergy of granular computing, shadowed sets, and three-way
decisions. <em>ISCI</em>, <em>508</em>, 422–425. (<a
href="https://doi.org/10.1016/j.ins.2019.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Ciucci Davide and Yao Yiyu},
  doi          = {10.1016/j.ins.2019.09.003},
  journal      = {Information Sciences},
  pages        = {422-425},
  shortjournal = {Inf. Sci.},
  title        = {Synergy of granular computing, shadowed sets, and three-way decisions},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep feature learning for histopathological image
classification of canine mammary tumors and human breast cancer.
<em>ISCI</em>, <em>508</em>, 405–421. (<a
href="https://doi.org/10.1016/j.ins.2019.08.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Canine mammary tumors (CMTs) have high incidences and mortality rates in dogs. They are also considered excellent models for human breast cancer studies. Diagnoses of both, human breast cancer and CMTs, are done by histopathological analysis of haematoxylin and eosin (H&amp;E) stained tissue sections by skilled pathologists: a process that is very tedious and time-consuming. The existence of heterogeneous and diverse types of CMTs and the paucity of skilled veterinary pathologists justify the need for automated diagnosis. Deep learning-based approaches have recently gained popularity for analyzing histopathological images of human breast cancer. However, so far, due to the lack of any publicly available CMT database, no studies have focused on the automated classification of CMTs. To the best of our knowledge, we have introduced for the first time a dataset of CMT histopathological images (CMTHis). Further, we have proposed a framework based on VGGNet-16, and evaluated the performance of the fused framework along with different classifiers on the CMT dataset (CMTHis) and human breast cancer dataset (BreakHis). We also explored the effect of data augmentation , stain normalization, and magnification on the performance of the proposed framework. The proposed framework, with support vector machines , resulted in mean accuracies of 97\% and 93\% for binary classification of human breast cancer and CMT respectively, which validates the efficacy of the proposed system.},
  archive      = {J_ISCI},
  author       = {Abhinav Kumar and Sanjay Kumar Singh and Sonal Saxena and K. Lakshmanan and Arun Kumar Sangaiah and Himanshu Chauhan and Sameer Shrivastava and Raj Kumar Singh},
  doi          = {10.1016/j.ins.2019.08.072},
  journal      = {Information Sciences},
  pages        = {405-421},
  shortjournal = {Inf. Sci.},
  title        = {Deep feature learning for histopathological image classification of canine mammary tumors and human breast cancer},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Securing visual search queries in ubiquitous scenarios
empowered by smart personal devices. <em>ISCI</em>, <em>508</em>,
393–404. (<a href="https://doi.org/10.1016/j.ins.2019.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart personal devices are assuming a fundamental role in the ubiquitous communication and computing arena. They provide new sophisticated cameras and new visual search interfaces and facilities that can drastically improve their presence and role in complex IoT-based critical infrastructures, such as healthcare monitoring and emergency systems, or remote access control facilities and smart authentication services. This new scenario calls for strong secure and resilient visual query mechanisms for these devices. In this work we propose an innovative secure visual search system, which is well-suited for ubiquitous computing scenarios empowered by modern smart personal devices. More precisely, we show how to insert, at the visual data acquisition time, a watermark inside the already compressed descriptor characterizing an MPEG-CDVS data stream used in visual queries, to make it possible to decode the watermark on the server side in order to improve the robustness against image-based identity spoofing. Such a security enforcement solution may be practical in several real-life applications involving visual queries performed from personal trusted devices, and it is particularly suitable in all those application domains that require performing visual queries with a high degree of security. It has been extensively tested and achieved satisfactory results: the presence of such a watermark does not affect the image matching performance and functionality.},
  archive      = {J_ISCI},
  author       = {Bruno Carpentieri and Arcangelo Castiglione and Alfredo De Santis and Francesco Palmieri and Raffaele Pizzolante and Xiaofei Xing},
  doi          = {10.1016/j.ins.2019.08.075},
  journal      = {Information Sciences},
  pages        = {393-404},
  shortjournal = {Inf. Sci.},
  title        = {Securing visual search queries in ubiquitous scenarios empowered by smart personal devices},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A penalty-based adaptive secure estimation for power
systems under false data injection attacks. <em>ISCI</em>, <em>508</em>,
380–392. (<a href="https://doi.org/10.1016/j.ins.2019.08.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a penalty-based adaptive secure estimation method for multi-area power systems under false data injection (FDI) attacks, the adaptive secure estimation method specifically takes the characteristics of FDI attacks into account. Firstly, a new measurement modeling is delicately constructed for subarea of power systems , in which both the state and FDI attack information are well considered. Secondly, for convenient solving of constructed mixed variational inequality (MVI), series virtual nodes are effectively introduced to transfer the multi-area power systems with boundary nodes to a boundary system. Then, a penalty-based distributed estimation method is proposed to estimate the state of multi-area power systems under FDI attacks, where the penalty parameter can be adaptively adjusted based on the dynamic internal error and boundary error. Compared with some existing methods, the efficiency and accuracy of proposed method are improved, and the state and attack signals can be estimated simultaneously. Finally, a case study shows the effectiveness of proposed method.},
  archive      = {J_ISCI},
  author       = {Minjing Yang and Hao Zhang and Chen Peng and Yulong Wang},
  doi          = {10.1016/j.ins.2019.08.080},
  journal      = {Information Sciences},
  pages        = {380-392},
  shortjournal = {Inf. Sci.},
  title        = {A penalty-based adaptive secure estimation for power systems under false data injection attacks},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equivalence of 2-rotation symmetric quartic boolean
functions. <em>ISCI</em>, <em>508</em>, 358–379. (<a
href="https://doi.org/10.1016/j.ins.2019.08.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Boolean function in n variables is 2-rotation symmetric if it is invariant under even powers of ρ ( x 1 , … … , x n ) = ( x 2 , … , x n , x 1 ) , ρ(x1,……,xn)=(x2,…,xn,x1), but not under the first power (ordinary rotation symmetry); we call such a function a 2-function. A 2-function is called monomial rotation symmetric (MRS) if it is generated by applying powers of ρ 2 to a single monomial . If the quartic MRS 2-function in 2 n variables has a monomial x 1 x q x r x s , then we use the notation 2-(1, q, r, s ) 2 n for the function. This paper gives a detailed theory of equivalence of quartic MRS 2-functions in 2 n variables. Such a theory was provided for the cubic MRS 2-functions in two 2015 papers of Cusick and Johns. As in the earlier papers, the two main topics in the theory are describing the affine equivalence classes of the functions under certain groups of permutations ; and giving details of the linear recursions that the Hamming weights of any sequence of functions 2-(1, q, r, s ) 2 n (with q n=s,s+1,… can be shown to satisfy. The discussion for both of these topics uses new ideas because the quartic theory naturally divides into two cases.},
  archive      = {J_ISCI},
  author       = {Thomas W. Cusick and Younhwan Cheon and Kelly Dougan},
  doi          = {10.1016/j.ins.2019.08.074},
  journal      = {Information Sciences},
  pages        = {358-379},
  shortjournal = {Inf. Sci.},
  title        = {Equivalence of 2-rotation symmetric quartic boolean functions},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting tissue-specific protein functions using
multi-part tensor decomposition. <em>ISCI</em>, <em>508</em>, 343–357.
(<a href="https://doi.org/10.1016/j.ins.2019.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proteins are complex molecules that play many critical functions in the human body. They are expressed in different tissues in the body where their functions vary depending on the tissue they are expressed in. The disorder of protein interactome affects their biological functions which results in diseases. Therefore, understanding and assessing different tissue-specific protein functions in the human body is essential for disease diagnostics and therapeutics. However, it is a hard task as it requires laboratory experimentations and resources which are expensive and have limited scalability. Thus, multiple computational approaches were developed to predict tissue-specific protein functions. These approaches managed to provide predictions with high scalability and efficiency. However, they still suffer from high rates of false positives . In this work, we propose a new method for predicting tissue-specific protein functions using tensor factorisation with multi-part embeddings. We model proteins, functions, and their corresponding tissues as a tensor, and we apply tensor factorisation to learn scores for all possible protein-function associations for each of the studied tissues. We then show by experimental evaluation that our model outperforms the state-of-the-art models with a margin of 33.3\% and 13\% on the area under precision recall and ROC curves respectively.},
  archive      = {J_ISCI},
  author       = {Sameh K. Mohamed},
  doi          = {10.1016/j.ins.2019.08.061},
  journal      = {Information Sciences},
  pages        = {343-357},
  shortjournal = {Inf. Sci.},
  title        = {Predicting tissue-specific protein functions using multi-part tensor decomposition},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding the maximal adversary structure from any given
access structure. <em>ISCI</em>, <em>508</em>, 329–342. (<a
href="https://doi.org/10.1016/j.ins.2019.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure multi-party computation is an important research area in cryptography, and the secret sharing scheme (SSS) is one of the main tools for constructing multi-party computation protocols. The access structure and the adversary structure are two important subsets of participants in an SSS. In general, the collection of all qualified subsets that can reconstruct the secret s , is known as an access structure, while no information regarding this secret is available to any unqualified subsets, and the collection of unqualified subsets is described as an adversary structure. The maximal adversary, which will become a qualified subset if any one participant not in this unqualified subset is added. At present, there is no effective algorithm to determine the maximal adversary structure for any given access structure. In this paper, we propose two algorithms to determine the maximal adversary structure from any given access structure, in which a binary tree is introduced to construct such algorithms. Moreover, a special type of access structure is established, from which the maximal adversary structure can be directly characterized, and the maximal adversary structure in this case is shown to be the largest when the number of participants of each qualified polynomial in the access structure is three.},
  archive      = {J_ISCI},
  author       = {Chunming Tang and Qiuxia Xu and Gengran Hu},
  doi          = {10.1016/j.ins.2019.08.057},
  journal      = {Information Sciences},
  pages        = {329-342},
  shortjournal = {Inf. Sci.},
  title        = {Finding the maximal adversary structure from any given access structure},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-factor one-order cross-association fuzzy logical
relationships based forecasting models of time series. <em>ISCI</em>,
<em>508</em>, 309–328. (<a
href="https://doi.org/10.1016/j.ins.2019.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing multi-factor one-order (MFOO) forecasting models , each fuzzy logical relation (FLR) has one consequent and more than one premise reflecting the association between the fuzzy values at two consecutive moments, and its premises are related to all the factors involved in forecasting. When using such FLRs to realize prediction, no matched FLR cases happened often and thus no logical prediction can be made. Two shortcomings are found for that: one is that more premises make FLRs matching more difficult; the other is that there are no enough FLRs. To overcome these shortcomings, this paper proposes two kinds of FLRs: short cross-association FLRs and long cross-association FLRs, which mean the influence on the consequent is from a part of the factors instead of all the factors. Specifically, the long cross-association FLRs aim at finding the association between fuzzy values at two non-consecutive moments. Such cross-associations exist in reality, the construction of them allows more FLRs to be mined from history observations. They can raise the possibility of finding available FLRs for forecasting. Based on the proposed FLRs, two MFOO forecasting models are proposed. Experiments show the advantage of the new FLRs and the good performance of the proposed models.},
  archive      = {J_ISCI},
  author       = {Fang Li and Fusheng Yu},
  doi          = {10.1016/j.ins.2019.08.058},
  journal      = {Information Sciences},
  pages        = {309-328},
  shortjournal = {Inf. Sci.},
  title        = {Multi-factor one-order cross-association fuzzy logical relationships based forecasting models of time series},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain multi-attribute group decision making based on
linguistic-valued intuitionistic fuzzy preference relations.
<em>ISCI</em>, <em>508</em>, 293–308. (<a
href="https://doi.org/10.1016/j.ins.2019.08.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preference relations have shown some advantages in handling multi-attribute group decision making problems, which can assist decision makers to set priorities and make a reasonable decision. In real-life situations, decision makers sometimes express their preference with fuzzy and uncertain linguistic information including positive and negative sides at the same time. In order to deal with the decision-making problems with uncertain linguistic information , we propose an approach for uncertain multi-attribute group decision making based on linguistic-valued intuitionistic fuzzy preference relations (LIFPR). The presented LIFPR based on linguistic truth-valued intuitionistic fuzzy lattice can better express positive and negative evaluation information in the meanwhile. To aggregate linguistic information and reduce information loss of aggregation process, we propose linguistic-valued intuitionistic fuzzy 2-tuple representation model (LIF 2-tuple) and two kinds of linguistic-valued intuitionistic fuzzy aggregation operators. To deal with incomparable LIF 2-tuples, we present positive and negative LIF 2-tuple reference nearness degrees according to preferences. For the inconsistent LIFPR caused by subjective uncertainty, a consistency checking algorithm based on linguistic-valued intuitionistic fuzzy similarity is introduced to check and repair the consistency of a LIFPR. For the incomplete LIFPR caused by objective uncertainty, an improved LIFPR based on additive transitivity is presented to complement the LIFPR. We discuss the procedure of group decision making based on LIFPR with positive and negative evaluation information. An illustrate example shows the proposed approach for group decision making seems more effective for decision making under an uncertain linguistic environment.},
  archive      = {J_ISCI},
  author       = {Pengsen Liu and Hongyue Diao and Li Zou and Ansheng Deng},
  doi          = {10.1016/j.ins.2019.08.076},
  journal      = {Information Sciences},
  pages        = {293-308},
  shortjournal = {Inf. Sci.},
  title        = {Uncertain multi-attribute group decision making based on linguistic-valued intuitionistic fuzzy preference relations},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hesitancy degree-based correlation measures for hesitant
fuzzy linguistic term sets and their applications in multiple criteria
decision making. <em>ISCI</em>, <em>508</em>, 275–292. (<a
href="https://doi.org/10.1016/j.ins.2019.08.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hesitant fuzzy linguistic term set (HFLTS) turns out to be useful in representing people&#39;s hesitant qualitative information. The aim of this paper is to investigate new correlation measures between HFLTSs and apply them in decision-making process. Firstly, the concepts of mean and hesitancy degree of hesitant fuzzy linguistic elements are introduced. Based on them, we address the drawbacks of the existing correlation measures between HFLTSs. Then, a new correlation coefficient between HFLTSs is established. Additionally, the hesitancy degree of the hesitant fuzzy linguistic correlation coefficient is proposed, which is composed by the upper and lower bounds of the hesitant fuzzy linguistic correlation coefficient. To show the applicability of the proposed correlation measures, a correlation coefficient-based method is developed for multiple criteria decision making in the cases that the weights of criteria are either known or unknown. A practical example concerning the strategic management of Sichuan liquor brands in China is given to validate the proposed method. It is verified that the proposed correlation coefficients between HFLTSs is more convincing than the existing ones and the developed correlation coefficient-based hesitant fuzzy linguistic MCDM with the weights of criteria being either completely known or unknown is applicable.},
  archive      = {J_ISCI},
  author       = {Liao Huchang and Gou Xunjie and Xu Zeshui and Zeng Xiao-Jun and Francisco Herrera},
  doi          = {10.1016/j.ins.2019.08.068},
  journal      = {Information Sciences},
  pages        = {275-292},
  shortjournal = {Inf. Sci.},
  title        = {Hesitancy degree-based correlation measures for hesitant fuzzy linguistic term sets and their applications in multiple criteria decision making},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Class-specific attribute value weighting for naive bayes.
<em>ISCI</em>, <em>508</em>, 260–274. (<a
href="https://doi.org/10.1016/j.ins.2019.08.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naive Bayes (NB) is one of the top 10 data mining algorithms . However, its assumption of conditional independence rarely holds true in real-world applications. To alleviate this assumption, numerous attribute weighting approaches have been proposed. However, few of these simultaneously pay attention to the horizontal granularity of attribute values and vertical granularity of class labels. In this study, we propose a new paradigm for fine-grained attribute weighting, named class-specific attribute value weighting. For each class, this approach discriminatively assigns a specific weight to each attribute value. We refer to the resulting improved model as class-specific attribute value weighted NB (CAVWNB). In CAVWNB, the class-specific attribute value weight matrix is learned by either maximizing the conditional log-likelihood (CLL) or minimizing the mean squared error (MSE). Thus, two versions are proposed, which we denote as CAVWNB CLL and CAVWNB MSE , respectively. Extensive experimental results on a large number of datasets show that both CAVWNB CLL and CAVWNB MSE significantly outperform NB and all the other existing state-of-the-art attribute weighting approaches used for comparison.},
  archive      = {J_ISCI},
  author       = {Huan Zhang and Liangxiao Jiang and Liangjun Yu},
  doi          = {10.1016/j.ins.2019.08.071},
  journal      = {Information Sciences},
  pages        = {260-274},
  shortjournal = {Inf. Sci.},
  title        = {Class-specific attribute value weighting for naive bayes},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RDF-TR: Exploiting structural redundancies to boost RDF
compression. <em>ISCI</em>, <em>508</em>, 234–259. (<a
href="https://doi.org/10.1016/j.ins.2019.08.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The number and volume of semantic data have grown impressively over the last decade, promoting compression as an essential tool for RDF preservation, sharing and management. In contrast to universal compressors, RDF compression techniques are able to detect and exploit specific forms of redundancy in RDF data. Thus, state-of-the-art RDF compressors excel at exploiting syntactic and semantic redundancies, i.e., repetitions in the serialization format and information that can be inferred implicitly. However, little attention has been paid to the existence of structural patterns within the RDF dataset; i.e. structural redundancy . In this paper, we analyze structural regularities in real-world datasets, and show three schema-based sources of redundancies that underpin the schema-relaxed nature of RDF. Then, we propose RDF-Tr (RDF Triples Reorganizer) , a preprocessing technique that discovers and removes this kind of redundancy before the RDF dataset is effectively compressed. In particular, RDF-Tr groups subjects that are described by the same predicates, and locally re-codes the objects related to these predicates. Finally, we integrate RDF-Tr with two RDF compressors, HDT and k 2 -triples . Our experiments show that using RDF-Tr with these compressors improves by up to 2.3 times their original effectiveness, outperforming the most prominent state-of-the-art techniques.},
  archive      = {J_ISCI},
  author       = {Antonio Hernández-Illera and Miguel A. Martínez-Prieto and Javier D. Fernández},
  doi          = {10.1016/j.ins.2019.08.081},
  journal      = {Information Sciences},
  pages        = {234-259},
  shortjournal = {Inf. Sci.},
  title        = {RDF-TR: Exploiting structural redundancies to boost RDF compression},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way decision based on improved aggregation method of
interval loss function. <em>ISCI</em>, <em>508</em>, 214–233. (<a
href="https://doi.org/10.1016/j.ins.2019.08.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a hybrid incomplete information table consisting both of the incomplete information table and loss function, the loss function of each object is denoted as an interval. The loss function of similarity class is defined as the aggregation of interval loss functions of all objects in its similarity class. However, existing optimistic aggregation method utilizes the union of interval loss functions of all objects in similarity class, which make the length of the aggregated interval loss function too broad. Pessimistic aggregation method utilizes the intersection of interval loss functions of all objects in similarity class, which make the length of the aggregated interval loss function too narrow. In order to get reasonable aggregated interval loss function, we propose a new aggregation method based on the principle of justifiable granularity , which make the length of the aggregated interval loss function neither too broad nor too narrow. That is, the aggregation result includes the interval loss functions of all objects in similarity class as much as possible and the aggregation result is as specific as possible. Based on the proposed aggregation method, we propose a new three-way decision model. Examples and experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yi Xu and Xusheng Wang},
  doi          = {10.1016/j.ins.2019.08.070},
  journal      = {Information Sciences},
  pages        = {214-233},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision based on improved aggregation method of interval loss function},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards a distributed local-search approach for partitioning
large-scale social networks. <em>ISCI</em>, <em>508</em>, 200–213. (<a
href="https://doi.org/10.1016/j.ins.2019.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale social graph data poses significant challenges for social analytic tools to monitor and analyze social networks. A feasible solution is to parallelize the computation and leverage distributed graph computing frameworks to process such big data. However, it is nontrivial to partition social graphs into multiple parts so that they can be computed on distributed platforms. In this paper, we propose a distributed local search algorithm , named dLS, which enables quality and efficient partition of large-scale social graphs. With the vertex-centric computing model, dLS can achieve massive parallelism . We employ a distributed graph coloring strategy to differentiate neighbor nodes and avoid interference during the parallel execution of each vertex. We convert the original graph into a small graph, Quotient Network , and obtain local search solution from processing the Quotient Network , thus further improving the partition quality and efficiency of dLS. We have evaluated the performance of dLS experimentally using real-life and synthetic social graphs, and the results show that dLS outperforms two state-of-the-art algorithms in terms of partition quality and efficiency.},
  archive      = {J_ISCI},
  author       = {Bin Zheng and Ouyang Liu and Jing Li and Yong Lin and Chong Chang and Bo Li and Tefeng Chen and Hao Peng},
  doi          = {10.1016/j.ins.2019.08.024},
  journal      = {Information Sciences},
  pages        = {200-213},
  shortjournal = {Inf. Sci.},
  title        = {Towards a distributed local-search approach for partitioning large-scale social networks},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered synchronization control of networked
euler-lagrange systems without requiring relative velocity information.
<em>ISCI</em>, <em>508</em>, 183–199. (<a
href="https://doi.org/10.1016/j.ins.2019.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the single- and multi-synchronization control problems of networked Euler-Lagrange systems subject to parameter uncertainties, time-varying disturbances and scarce control resources in a unified framework. Several novel event-triggered control algorithms are developed without requiring relative velocity information, which is capable of significantly mitigating the cost of unnecessary controller updates, signal transmission and computation, while possessing satisfactory control performances. Additionally, based on the Lyapunov stability techniques, the rigorous sufficient criteria for the asymptotic convergence of the synchronization errors are established, and the positive lower bounds of execution intervals are derived to exclude Zeno behaviors. Finally, by further proposing other comparative control algorithms and conceiving a performance index named trigger rate, numerical examples are performed to demonstrate the effectiveness and superiority of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Xiang-Yu Yao and Hua-Feng Ding and Ming-Feng Ge and Ju H. Park},
  doi          = {10.1016/j.ins.2019.08.067},
  journal      = {Information Sciences},
  pages        = {183-199},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered synchronization control of networked euler-lagrange systems without requiring relative velocity information},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new similarity combining reconstruction coefficient with
pairwise distance for agglomerative clustering. <em>ISCI</em>,
<em>508</em>, 173–182. (<a
href="https://doi.org/10.1016/j.ins.2019.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agglomerative clustering is a mainstream clustering method that can produce an informative hierarchical structure of clusters. Existing similarities in agglomerative clustering are typically based on the pairwise distance . Although this type of similarity captures the local structure of data well, it is sensitive to noise and outliers because it considers only the distance between data points. In this paper, we propose a new similarity called RCPD by combining the reconstruction coefficient, which is robust to noise and outliers, with the pairwise distance for agglomerative clustering. Our new similarity takes advantage of both the distance between data points and the linear representation among data points. Thus, RCPD not only captures the local structure of data well but is also robust to noise and outliers. The experimental results on 11 real-world benchmark datasets show that our new clustering method consistently outperforms many state-of-the-art clustering approaches .},
  archive      = {J_ISCI},
  author       = {Zhiling Cai and Xiaofei Yang and Tianyi Huang and William Zhu},
  doi          = {10.1016/j.ins.2019.08.048},
  journal      = {Information Sciences},
  pages        = {173-182},
  shortjournal = {Inf. Sci.},
  title        = {A new similarity combining reconstruction coefficient with pairwise distance for agglomerative clustering},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring trust in social networks based on linear
uncertainty theory. <em>ISCI</em>, <em>508</em>, 154–172. (<a
href="https://doi.org/10.1016/j.ins.2019.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social networks, trust relationships are the basis for interactions among decision nodes. Trust relationships are subjective and dynamic, and there are only few sample data to measure the strength of these connections. Uncertainty theory is a mathematical system that studies the belief degree of experts and provides a new method for measuring trust in social networks. In this paper, uncertainty theory is applied to the modeling of social networks. For any feature where certain information cannot be directly obtained, the recommended trust is derived based on direct trust values, and the constraints of single-path trust chains are established. To avoid secondary uncertainties caused by subjective weighting while considering multi-node, multi-path chains, two weighted trust aggregation operators are developed to accomplish a multi-trust transitive aggregation model. The belief degrees of the nodes, the trust chains and the whole network are quantified, and a social network trust measurement model based on uncertainty theory is constructed. In the case of a lack of data on the trust chain, a trust threshold constraint is used to calculate the range of the incomplete chain.},
  archive      = {J_ISCI},
  author       = {Zaiwu Gong and Hui Wang and Weiwei Guo and Zejun Gong and Guo Wei},
  doi          = {10.1016/j.ins.2019.08.055},
  journal      = {Information Sciences},
  pages        = {154-172},
  shortjournal = {Inf. Sci.},
  title        = {Measuring trust in social networks based on linear uncertainty theory},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proximity semantics for topic-based abstract argumentation.
<em>ISCI</em>, <em>508</em>, 135–153. (<a
href="https://doi.org/10.1016/j.ins.2019.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As we engage in a debate with other parties, it is usual that several issues might come under discussion. Many of these issues are interrelated by the topic they address, while others represent a departure from the focus of the discussion. In this work, we propose to extend Dung’s abstract argumentation frameworks by decorating arguments with a set of interrelated topics. These topics represent what the arguments are addressing and provide a supporting structure for the analysis of multi-topic argumentation. The introduction of a notion of distance between two topics associated with the arguments permits to consider the proximity of an argument to the focus of the debate, supporting in that manner an enriched semantic analysis.},
  archive      = {J_ISCI},
  author       = {Maximiliano C.D. Budán and Maria Laura Cobo and Diego C. Martinez and Guillermo R. Simari},
  doi          = {10.1016/j.ins.2019.08.037},
  journal      = {Information Sciences},
  pages        = {135-153},
  shortjournal = {Inf. Sci.},
  title        = {Proximity semantics for topic-based abstract argumentation},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security control of cyber-physical switched systems under
round-robin protocol: Input-to-state stability in probability.
<em>ISCI</em>, <em>508</em>, 121–134. (<a
href="https://doi.org/10.1016/j.ins.2019.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the sliding mode control (SMC) problem for a class of cyber-physical switched systems , in which both the Round-Robin (RR) protocol scheduling and the deception attacks may happen on the controller-to-actuator (C/A) channels. Under the regulation of RR protocol, only one controller node at each instant can access the network and transmit its signal to the corresponding actuator node, that is, the other actuators cannot obtain any new control information. Especially, the transmitted signal could be contaminated by randomly injecting false data. Thus, a key problem is how to design a suitable sliding surface and a desirable sliding mode controller for guaranteeing the dynamic performance of the closed-loop switched systems . To this end, a compensation strategy is proposed for those actuator nodes that don’t receive any new control signals at certain instant, based which a token-dependent SMC law is designed. Besides, the method of input-to-state stability in probability (ISSiP) is introduced and the sufficient conditions are established for the reachability of the specified sliding surface and the ISSiP of the resultant switched systems. Finally, some numerical simulation results are provided.},
  archive      = {J_ISCI},
  author       = {Haijuan Zhao and Yugang Niu and Tinggang Jia},
  doi          = {10.1016/j.ins.2019.08.056},
  journal      = {Information Sciences},
  pages        = {121-134},
  shortjournal = {Inf. Sci.},
  title        = {Security control of cyber-physical switched systems under round-robin protocol: Input-to-state stability in probability},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An expanded particle swarm optimization based on
multi-exemplar and forgetting ability. <em>ISCI</em>, <em>508</em>,
105–120. (<a href="https://doi.org/10.1016/j.ins.2019.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two phenomena in human society and biological systems. One is that people prefer to extract knowledge from multiple exemplars to obtain better learning ability. The other one is the forgetting ability that helps the encoding and consolidation of new information by removing unused or unwanted memories. Inspired by these phenomena, this paper transplants the multi-exemplar and forgetting ability to particle swarm optimization (PSO), and proposes an eXpanded PSO , called XPSO. Firstly, XPSO expands the “social-learning” part of each particle from one exemplar to two exemplars, learning from both the locally and the globally best exemplars. Secondly, XPSO assigns different forgetting abilities to different particles, simulating the forgetting phenomenon in the human society. Under the multi-exemplar learning model with forgetting ability, XPSO further adopts an adaptive scheme to update the acceleration coefficients and selects a reselection mechanism to update the population topology. The effectiveness of these additional proposed strategies is verified by extensive experiments. Moreover, comparison results among XPSO and other 9 popular PSO as well as 3 non-PSO algorithms on CEC’13 test suite suggest that XPSO attains a very promising performance for solving different types of functions, contributing to both higher solution accuracy and faster convergence speed.},
  archive      = {J_ISCI},
  author       = {Xuewen Xia and Ling Gui and Guoliang He and Bo Wei and Yinglong Zhang and Fei Yu and Hongrun Wu and Zhi-Hui Zhan},
  doi          = {10.1016/j.ins.2019.08.065},
  journal      = {Information Sciences},
  pages        = {105-120},
  shortjournal = {Inf. Sci.},
  title        = {An expanded particle swarm optimization based on multi-exemplar and forgetting ability},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). False data injection attacks against state estimation in the
presence of sensor failures. <em>ISCI</em>, <em>508</em>, 92–104. (<a
href="https://doi.org/10.1016/j.ins.2019.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates false data injection attacks (FDIAs) in power networks equipped with state estimator and bad data detection (BDD) system in the presence of sensor failures. Compared with the existing attacks designed in the noiseless case, a class of sparse undetectable attacks (SUAs) is designed to worsen the estimation performance even in the presence of failures. First, necessary and sufficient conditions for the existence of SUAs in the presence of failures are provided with the help of the concept of orthogonal complement matrix. Second, based on the obtained conditions, an intelligent SUA design strategy is proposed. It is shown that by estimating the failure vector, an SUA can be designed such that the estimator provides incorrect state estimate and the detector does not raise alarm even in the presence of sensor failures. Finally, the effectiveness of the proposed attack design schemes are evaluated numerically for IEEE 5, 9, and 30-bus systems.},
  archive      = {J_ISCI},
  author       = {An-Yang Lu and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2019.08.052},
  journal      = {Information Sciences},
  pages        = {92-104},
  shortjournal = {Inf. Sci.},
  title        = {False data injection attacks against state estimation in the presence of sensor failures},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An incentive-based protection and recovery strategy for
secure big data in social networks. <em>ISCI</em>, <em>508</em>, 79–91.
(<a href="https://doi.org/10.1016/j.ins.2019.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data sources, such as smart vehicles, IoT devices, and sensor networks, differ from traditional data sources in both output volume and variety. Big data is usually stored on various types of network nodes, which is prone to data security and privacy problems, such as virus infection. In particular, the spread of viruses through social networks can cause large-scale destruction and privacy leakage in the network. This paper aims to provide a solution to protect the security of big data. First, the users are divided into five states according to their reactions to data virus: susceptible, contagious, doubt, immune, and recoverable. Then, we propose a novel model for studying the propagation mechanism of data virus. To control the spread of virus and protect data security, an incentive mechanism is introduced. After that, a protection and recovery strategy (PRS) is developed to reduce infected users and increase the immunized. The experimental results on two data sets indicate that our model gives a good description of the data virus propagation process, and PRS is better than both acquaintance immunization and target immunization methods, which validates the privacy preserving strategy for big data in networks.},
  archive      = {J_ISCI},
  author       = {Youke Wu and Haiyang Huang and Ningyun Wu and Yue Wang and Md Zakirul Alam Bhuiyan and Tian Wang},
  doi          = {10.1016/j.ins.2019.08.064},
  journal      = {Information Sciences},
  pages        = {79-91},
  shortjournal = {Inf. Sci.},
  title        = {An incentive-based protection and recovery strategy for secure big data in social networks},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Infrared and visible image fusion based on target-enhanced
multiscale transform decomposition. <em>ISCI</em>, <em>508</em>, 64–78.
(<a href="https://doi.org/10.1016/j.ins.2019.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a target-enhanced multiscale transform (MST) decomposition model for infrared and visible image fusion to simultaneously enhance the thermal target in infrared images and preserve the texture details in visible images. The Laplacian pyramid is initially used to separately decompose two pre-registered source images into low- and high-frequency bands. The common “max-absolute” fusion rule is performed for fusion for high-frequency bands. We use the decomposed infrared low-frequency information to determine the fusion weight of low-frequency bands and highlight the target. Meanwhile, a regularization parameter is introduced to dominate the proportion of the infrared features in a gentle manner, which can be further adjusted according to user requirements. Finally, we use inverse transform with the Laplacian pyramid (LP) to reconstruct the fused image. Qualitative and quantitative experimental results on publicly available datasets demonstrate that the proposed method can generate fused images with clearly highlighted targets and abundant details. These images exhibit better visual effects and objective metric values than those of five other commonly used MST decomposition methods .},
  archive      = {J_ISCI},
  author       = {Jun Chen and Xuejiao Li and Linbo Luo and Xiaoguang Mei and Jiayi Ma},
  doi          = {10.1016/j.ins.2019.08.066},
  journal      = {Information Sciences},
  pages        = {64-78},
  shortjournal = {Inf. Sci.},
  title        = {Infrared and visible image fusion based on target-enhanced multiscale transform decomposition},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Surrogate-assisted classification-collaboration differential
evolution for expensive constrained optimization problems.
<em>ISCI</em>, <em>508</em>, 50–63. (<a
href="https://doi.org/10.1016/j.ins.2019.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive Constrained Optimization Problems (ECOPs) widely exist in various scientific and industrial applications. Surrogate-Assisted Evolutionary Algorithms (SAEAs) have recently exhibited great ability in solving these expensive optimization problems. This paper proposes a Surrogate-Assisted Classification-Collaboration Differential Evolution (SACCDE) algorithm for ECOPs with inequality constraints. In SACCDE, the current population is classified into two subpopulations based on certain feasibility rules, and a classification-collaboration mutation operation is designed to generate multiple promising mutant solutions by not only using promising information in good solutions but also fully exploiting potential information hidden in bad solutions. Afterwards, the surrogate is utilized to identify the most promising offspring solution for accelerating the convergence speed. Furthermore, considering that the population diversity may decrease due to the excessive incorporation of greedy information brought by the classified solutions, a global search framework that can adaptively adjust the classification-collaboration mutation operation based on the iterative information is introduced for achieving an effective global search. Therefore, the proposed algorithm can strike a well balance between local and global search. The experimental results of SACCDE and other state-of-the-art algorithms demonstrate that the performance of SACCDE is highly competitive.},
  archive      = {J_ISCI},
  author       = {Yang Zan and Qiu Haobo and Gao Liang and Cai Xiwen and Jiang Chen and Chen Liming},
  doi          = {10.1016/j.ins.2019.08.054},
  journal      = {Information Sciences},
  pages        = {50-63},
  shortjournal = {Inf. Sci.},
  title        = {Surrogate-assisted classification-collaboration differential evolution for expensive constrained optimization problems},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). A comparative study of decision implication, concept rule
and granular rule. <em>ISCI</em>, <em>508</em>, 33–49. (<a
href="https://doi.org/10.1016/j.ins.2019.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision implication is a basic form of knowledge representation of formal concept analysis in the setting of decision-making. Concept rules are decision implications that reveal the dependencies between condition concepts and decision concepts. Granular rules are concept rules that reveal the dependencies between condition object concepts and decision object concepts. This paper conducts a comparative study of decision implication, concept rule and granular rule. First, we conclude that both concept rules and granular rules are not complete w.r.t. decision implications, and that granular rules are not complete w.r.t. concept rules, implying that there exists information loss when studying decision implications by using only concept rules or granular rules, or when studying concept rules by using only granular rules. Next, with the help of decision implication logic, we identify accurately the information loss in concept rules and granular rules, and explore the underlying reason behind the information loss in concept rules and granular rules. Finally, by using the obtained results, we revisit some work on concept rule and granular rule, make some insightful remarks on the non-redundancy of concept rules and clarify some seemingly misleading statements on the representation of concept rules by granular rules.},
  archive      = {J_ISCI},
  author       = {Shaoxia Zhang and Deyu Li and Yanhui Zhai and Xiangping Kang},
  doi          = {10.1016/j.ins.2019.08.053},
  journal      = {Information Sciences},
  pages        = {33-49},
  shortjournal = {Inf. Sci.},
  title        = {A comparative study of decision implication, concept rule and granular rule},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The assessment of small bowel motility with attentive
deformable neural network. <em>ISCI</em>, <em>508</em>, 22–32. (<a
href="https://doi.org/10.1016/j.ins.2019.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The small bowel is the longest part of the gastrointestinal tract and quick assessment of its motility using Cine-MRI is conducive to the diagnosis of gastroenteric diseases. Because of the complex shape changes that occur frequently in the small bowel, approaches involving human designed features and simple convolutional neural network (CNN) methods fail to achieve satisfactory performance on massive datasets . To meet the challenge of assessing small bowel motility automatically, we propose the integration of deformable convolutional networks into attentive encoder–decoder. With the help of deformable convolution , a tailored CNN can track small bowel segments in different shapes from each MR image of a Cine-MRI sequence. The proposed attentive encoder–decoder performed significantly better than conventional recurrent neural network (RNN) in the assessment of small bowel motility. Experimental results demonstrate that the proposed method not only automatically assesses small bowel motility correctly, but also outperforms state-of-the-art methods. Furthermore, it provides useful information about the physiology of small bowel motility patterns, which can be used in the diagnosis of gastroenteric diseases.},
  archive      = {J_ISCI},
  author       = {Xing Wu and Mingyu Zhong and Yike Guo and Hamido Fujita},
  doi          = {10.1016/j.ins.2019.08.059},
  journal      = {Information Sciences},
  pages        = {22-32},
  shortjournal = {Inf. Sci.},
  title        = {The assessment of small bowel motility with attentive deformable neural network},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-rank local tangent space embedding for subspace
clustering. <em>ISCI</em>, <em>508</em>, 1–21. (<a
href="https://doi.org/10.1016/j.ins.2019.08.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace techniques have gained much attention for their remarkable efficiency in representing high-dimensional data, in which sparse subspace clustering (SSC) and low-rank representation (LRR) are two commonly used prototypes in the fields of pattern recognition, computer vision and signal processing. Both of them aim at constructing a block sparse matrix via linearly representing data to make them be embedded into linear subspaces . However, few datasets satisfy the linear subspace assumption in the real world. In this paper, data are peered from viewpoint of manifold architecture under the framework of sparse representation . A globally low-rank representation with the Frobenius norm minimization is constructed under the constraint of local manifold embedding and a novel low-rank local embedding representation (LRLER) model for subspace clustering of datasets is proposed. In this model, the local as well as global manifold structures of a dataset are concerned. Clusters of a dataset are considered as sub-manifolds embedded in low-dimensional subspaces. To represent and segment samples with hybrid neighbors or interlaced manifold structures, the local tangent space analysis strategy is introduced to characterize the local structure of neighborhood of samples. The coefficients of locally linear embedding are rectified according to the relationship between local tangent spaces of samples and their neighbors. A local tangent space based low-rank local embedding representation model (LRLTSER) is built to deal with data with neighborhood aliasing distortion. Extensive experiments on synthetic datasets and real-world datasets are implemented and experimental results show superior performance of the proposed methods for subspace clustering compared to the state-of-the-art techniques.},
  archive      = {J_ISCI},
  author       = {Tingquan Deng and Dongsheng Ye and Rong Ma and Hamido Fujita and Lvnan Xiong},
  doi          = {10.1016/j.ins.2019.08.060},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {Low-rank local tangent space embedding for subspace clustering},
  volume       = {508},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Three-way class-specific attribute reducts from the
information viewpoint. <em>ISCI</em>, <em>507</em>, 840–872. (<a
href="https://doi.org/10.1016/j.ins.2018.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By virtue of granular computing , attribute reduction of rough sets can effectively perform information processing. Regarding the decision table with granular structures, the traditional classification-based attribute reducts at the macro-top already have the algebra and information interpretations, while the new class-specific attribute reducts at the meso-middle currently have only the algebra explanation. Aiming at the class-specific reducts, this paper establishes three-way types from the information viewpoint, and it further compares the information and algebra types. At first, the three-way information class-specific reducts (including the likelihood, prior, and posterior types) are systematically proposed by using the three-way weighted entropies with uncertainty measurement. Then, optimization preservation conditions of the positive region and weighted entropy are deeply mined to describe reduction targets of the algebra and information types, and relevant conditions related to knowledge coarsening are effectively represented by the granular merging and three-way regions. Furthermore, all four types of class-specific reducts gain their relationships, including the strong-weak relationship based on optimization preservation conditions, the degeneration relationship based on consistency and inconsistency, and the information relationship based on systematic equalities. Finally, algebra and information class-specific reducts and their relationships are verified by a consistency example and an inconsistency example. As a conclusion, the four types of class-specific reducts adopt distinctive algebra or information perspectives to present the difference and emphasis, especially in the inconsistency case, and they have in-depth mutual relationships. This study provides novel insight into attribute reduction based on granular computing , mainly via the information theory and three-way decisions.},
  archive      = {J_ISCI},
  author       = {Xianyong Zhang and Jilin Yang and Lingyu Tang},
  doi          = {10.1016/j.ins.2018.06.001},
  journal      = {Information Sciences},
  pages        = {840-872},
  shortjournal = {Inf. Sci.},
  title        = {Three-way class-specific attribute reducts from the information viewpoint},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An active three-way clustering method via low-rank matrices
for multi-view data. <em>ISCI</em>, <em>507</em>, 823–839. (<a
href="https://doi.org/10.1016/j.ins.2018.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-view clustering algorithms have shown promising performance by combining multiple sources or views of datasets. A problem that has not been addressed satisfactorily is the uncertain relationship between an object and a cluster. Thus, this paper investigates an active three-way clustering method via low-rank matrices that can improve clustering accuracy as clustering proceeds for the multi-view data of high dimensionality . We adopt a three-way clustering representation to reflect the three types of relationships between an object and a cluster, namely, belong-to definitely, uncertain and not belong-to definitely. We construct the consensus low-rank matrix from each weighted low-rank matrix by taking account of the diversity of views, and give the method to solve the optimization problem of objective function based on the improved augmented Lagrangian multiplier algorithm. We suggest an active learning strategy to learn important informative pairwise constraints after measuring the uncertainty of an object based on the entropy concept . The experimental results conducted on real-world datasets have validated the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Hong Yu and Xincheng Wang and Guoyin Wang and Xianhua Zeng},
  doi          = {10.1016/j.ins.2018.03.009},
  journal      = {Information Sciences},
  pages        = {823-839},
  shortjournal = {Inf. Sci.},
  title        = {An active three-way clustering method via low-rank matrices for multi-view data},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way decision making approach to conflict analysis and
resolution using probabilistic rough set over two universes.
<em>ISCI</em>, <em>507</em>, 809–822. (<a
href="https://doi.org/10.1016/j.ins.2019.05.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict analysis aims to identify the intrinsic reasons and find a feasible consensus strategy for a conflict situation. Rough set theory was used to study conflict analysis decision-making in the late 90s. The basic way to express the attitudes of every agent are against, favorable and neutral for any issue in the original Pawlak conflict analysis model. The notion of three-way decision (3WD) was initially developed as a means to interpret decision rules induced in probabilistic rough sets. In this paper, we first present the framework of three-way decision (3WD) using probabilistic rough set over two universes. With respect to the probabilistic positive, negative and boundary regions over two universes, we build the rules for making a decision of acceptance, rejection and non-commitment, respectively. So, there is an one-to-one correspondence between the three attitudes of every agent for any issue in a conflict situation and the three decisions in the probabilistic rough set over two universes. Based on this, we present an improved Pawlak conflict analysis model by using the principle of three-way decision based on probabilistic rough set over two universes. We construct the conflict decision-making information system under the framework of two universes. Then we define the favorable issues set and against issues set of any agent between the agent set and the dispute set over conflict decision-making information system, respectively. Furthermore, according to the principle of Bayesian risk decision-making process over two universes, we calculate the threshold value parameters used in the lower and upper approximations of a feasible consensus strategy over conflict decision-making information system. Finally, we present the decision rules and the algorithm of finding a feasible consensus strategy for conflict situation based on three-way decision-making with the probabilistic approximations over two universes. Compared with the original Pawlak conflict analysis model, the proposed model not only provides a new perspective and methodology to handle the conflict analysis problems but also overcomes the limitations of the original model. Lastly, we illustrate the idea and basic principles established in this paper by analyzing a conflict decision-making scenario.},
  archive      = {J_ISCI},
  author       = {Bingzhen Sun and Xiangtang Chen and Liye Zhang and Weimin Ma},
  doi          = {10.1016/j.ins.2019.05.080},
  journal      = {Information Sciences},
  pages        = {809-822},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision making approach to conflict analysis and resolution using probabilistic rough set over two universes},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy neighborhood covering for three-way classification.
<em>ISCI</em>, <em>507</em>, 795–808. (<a
href="https://doi.org/10.1016/j.ins.2018.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood Covering (NC) is the union of homogeneous neighborhoods and provides a set-level approximation of data distribution. Because of the nonparametric property and the robustness to complex data, neighborhood covering has been widely used for data classification . Most existing methods directly classify data samples according to the nearest neighborhoods. However, the certain classification methods strictly classify the uncertain data and may lead to serious classification mistakes. To tackle this problem, we extend traditional neighborhood coverings to fuzzy ones and thereby propose a Three-Way Classification method with Fuzzy Neighborhood Covering (3WC-FNC). Fuzzy neighborhood covering consists of membership functions and forms an approximate distribution of neighborhood belongingness. Based on the soft partition induced by the memberships of fuzzy neighborhood coverings of different classes, data samples are classified into Positive (certainly belonging to a class), Negative (certainly beyond classes) and Uncertain cases. Experiments verify that the proposed three-way classification method is effective to handle the uncertain data and in the meantime reduce the classification risk.},
  archive      = {J_ISCI},
  author       = {X.D. Yue and Y.F. Chen and D.Q. Miao and H. Fujita},
  doi          = {10.1016/j.ins.2018.07.065},
  journal      = {Information Sciences},
  pages        = {795-808},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy neighborhood covering for three-way classification},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Three-way confusion matrix for classification: A measure
driven view. <em>ISCI</em>, <em>507</em>, 772–794. (<a
href="https://doi.org/10.1016/j.ins.2019.06.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decisions (3WD) is an important methodology in solving problems with uncertainty. A systematic analysis on three-way based uncertainty measures is conducive to the promotion of three-way decisions. Meanwhile, confusion matrix , with multifaceted views, serves as a fundamental role in evaluating classification performance. In this paper, confusion matrix is endowed with semantics of three-way decisions. A collection of measures are thus deduced and summarized into seven measure modes. We further investigate the formulation of three-way regions from a measure driven view. To satisfy the preferences of stakeholder, two different objective functions are formulated, and each of them can include different combinations of measures. To demonstrate the effectiveness, we generate probabilistic three-way decisions for a wealth of datasets. Compared with Gini coefficient based and Shannon entropy based objective functions, our model can deduce more satisfying three-way regions.},
  archive      = {J_ISCI},
  author       = {Jianfeng Xu and Yuanjian Zhang and Duoqian Miao},
  doi          = {10.1016/j.ins.2019.06.064},
  journal      = {Information Sciences},
  pages        = {772-794},
  shortjournal = {Inf. Sci.},
  title        = {Three-way confusion matrix for classification: A measure driven view},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NIS-apriori-based rule generation with three-way decisions
and its application system in SQL. <em>ISCI</em>, <em>507</em>, 755–771.
(<a href="https://doi.org/10.1016/j.ins.2018.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the study, non-deterministic information systems-Apriori-based (NIS-Apriori-based) rule generation from table data sets with incomplete information, SQL implementation, and the unique characteristics of the new framework are presented. Additionally, a few unsolved new research topics are proposed based on the framework. We follow the framework of NISs and propose certain rules and possible rules based on possible world semantics. Although each rule τ depends on a large number of possible tables, we prove that each rule τ is determined by examining only two τ -dependent possible tables. The NIS-Apriori algorithm is an adjusted Apriori algorithm that can handle such tables. Furthermore, it is logically sound and complete with regard to the rules. Subsequently, the implementation of the NIS-Apriori algorithm in SQL is described and a few new topics induced by effects of NIS-Apriori-based rule generation are confirmed. One of the topics that are considered is the possibility of estimating missing values via the obtained certain rules. The proposed methodology and the environment yielded by NIS-Apriori-based rule generation in SQL are useful for table data analysis with three-way decisions.},
  archive      = {J_ISCI},
  author       = {Hiroshi Sakai and Michinori Nakata and Junzo Watada},
  doi          = {10.1016/j.ins.2018.09.008},
  journal      = {Information Sciences},
  pages        = {755-771},
  shortjournal = {Inf. Sci.},
  title        = {NIS-apriori-based rule generation with three-way decisions and its application system in SQL},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On decision evaluation functions in generalized three-way
decision spaces. <em>ISCI</em>, <em>507</em>, 733–754. (<a
href="https://doi.org/10.1016/j.ins.2018.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Hu proposed the notion of three-way decision spaces based on partially ordered sets with involutive negations by the axiomatic definition . However, involutive negation is so strong that imposes restrictions on the use of the theory of three-way decision spaces from theoretical point of view. Therefore, this paper attempts to extend the concept of three-way decision spaces from partially ordered sets with involutive negations to partially ordered sets with negations. At first, we generalize three-way decision spaces and three-way decisions based on general partially ordered sets with negations such that the existing three-way decisions are the specific cases of generalized three-way decision spaces discussed in this paper. And then, we give some new decision evaluation functions in generalized three-way decision spaces (e.g., decision evaluation functions based on fuzzy sets, interval-valued fuzzy sets, fuzzy relations, shadowed sets and hesitant fuzzy sets), which enriched the class of decision evaluation functions. In particular, they provide more choices for decision-makers in realistic decision-making problems. Finally, in order to illustrate the practical applications of the results presented in this paper, we analyse a practical example of an evaluation problem of credit card applicants.},
  archive      = {J_ISCI},
  author       = {Junsheng Qiao and Bao Qing Hu},
  doi          = {10.1016/j.ins.2018.07.032},
  journal      = {Information Sciences},
  pages        = {733-754},
  shortjournal = {Inf. Sci.},
  title        = {On decision evaluation functions in generalized three-way decision spaces},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Frequent pattern discovery with tri-partition alphabets.
<em>ISCI</em>, <em>507</em>, 715–732. (<a
href="https://doi.org/10.1016/j.ins.2018.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of patterns is the basis of sequence analysis. There are various pattern definitions for biological data, texts, and time series. Inspired by the methodology of three-way decisions and protein tri-partition, this paper proposes a frequent pattern discovery algorithm for a new type of pattern by dividing the alphabet into strong, medium, and weak parts. The new type, called a tri-pattern, is more general and flexible than existing ones and is therefore more interesting in applications. Experiments were undertaken on data in various fields to reveal the universality of this new pattern. These include protein sequence mining, petroleum production time series analysis , and forged Chinese text keyword mining. The results show that tri-patterns are more meaningful and desirable than the existing four types of patterns. This study enriches the semantics of sequential pattern discovery and the application fields of three-way decisions.},
  archive      = {J_ISCI},
  author       = {Fan Min and Zhi-Heng Zhang and Wen-Jie Zhai and Rong-Ping Shen},
  doi          = {10.1016/j.ins.2018.04.013},
  journal      = {Information Sciences},
  pages        = {715-732},
  shortjournal = {Inf. Sci.},
  title        = {Frequent pattern discovery with tri-partition alphabets},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Credit scoring using three-way decisions with probabilistic
rough sets. <em>ISCI</em>, <em>507</em>, 700–714. (<a
href="https://doi.org/10.1016/j.ins.2018.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit scoring is a crucial task within risk management for any company in the financial sector. On the one hand, it is in the self-interest of banks to avoid approving credits to customers who probably default. On the other hand, regulators require strict risk management systems from banks to protect their customers and, from “too big to fail institutions”, to avoid bankruptcy with negative impacts on an economy as a whole. However, credit scoring is also expensive and time-consuming. So, any possible method, like three-way decisions, to further increase its efficiency, is worth a try. We propose a two-step approach based on three-way decisions. Customers whose credit applications can be approved or rejected right away are decided in a first step. For the remaining credit applications, additional information is gathered in a second step. Hence, these decisions are more expensive than the ones in the first step. In our paper, we present a methodology to apply three-way decisions with probabilistic rough sets for credit scoring and an extensive case study with more than 7000 credit applications from Chilean micro-enterprises.},
  archive      = {J_ISCI},
  author       = {Sebastián Maldonado and Georg Peters and Richard Weber},
  doi          = {10.1016/j.ins.2018.08.001},
  journal      = {Information Sciences},
  pages        = {700-714},
  shortjournal = {Inf. Sci.},
  title        = {Credit scoring using three-way decisions with probabilistic rough sets},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-way decisions with decision-theoretic rough sets in
multiset-valued information tables. <em>ISCI</em>, <em>507</em>,
684–699. (<a href="https://doi.org/10.1016/j.ins.2018.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of three-way decisions is to divide a universe into three pair-wise disjoint regions and to act on some or all of these regions using appropriate strategies. The decision-theoretic rough set model, a typical three-way decision model, trisects a universe using a pair of thresholds computed from loss functions. Previous studies of decision-theoretic rough set models do not consider loss functions based on multiset values and are unable to deal with multiset-valued information tables. In this paper, two generalized decision-theoretic rough set models involving multiset-valued data are proposed, namely a multiset-decision-theoretic rough set model and a multiset-fuzzy-decision-theoretic rough set model. Two methods are introduced that compute expected costs from loss functions. The first method is based on the mutiset addition and a new normal-multiset multiplication. The second method is based on a new concept known as the p -length of finite normal multisets. These two methods offer different ways of building multiset-decision-theoretic rough set models. By integrating the multiset-decision-theoretic rough set model with the fuzzy decision-theoretic rough set model, a multiset-fuzzy-decision-theoretic rough set model is created, a model which considers fuzzy relations in multiset-valued information tables. An example that recommends different home options is given to illustrate these models.},
  archive      = {J_ISCI},
  author       = {Xue Rong Zhao and Bao Qing Hu},
  doi          = {10.1016/j.ins.2018.08.024},
  journal      = {Information Sciences},
  pages        = {684-699},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decisions with decision-theoretic rough sets in multiset-valued information tables},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Multi-granularity three-way decisions with adjustable
hesitant fuzzy linguistic multigranulation decision-theoretic rough sets
over two universes. <em>ISCI</em>, <em>507</em>, 665–683. (<a
href="https://doi.org/10.1016/j.ins.2019.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of hesitant fuzzy linguistic term sets (HFLTSs), which enables experts to utilize a few possible linguistic terms to evaluate varieties of common qualitative information, plays a significant role in handling situations in cases where these experts are hesitant in offering linguistic expressions . For addressing the challenges of information analysis and information fusion in hesitant fuzzy linguistic (HFL) group decision making, in accordance with the multi-granularity three-way decisions paradigm, the primary purpose of this study is to develop the notion of multigranulation decision-theoretic rough sets (MG-DTRSs) into the HFL background within the two-universe framework. Having revisited the relevant literature, we first propose a hybrid model named adjustable HFL MG-DTRSs over two universes by introducing an adjustable parameter for the expected risk appetite of experts, in which both optimistic and pessimistic versions of HFL MG-DTRSs over two universes are special cases of the adjustable version. Second, some of the fundamental properties of the proposed model are discussed. Then, on the basis of the presented hybrid model, a group decision making approach within the HFL context is further constructed. Finally, a practical example, a comparative analysis, and a validity test concerning person-job fit problems are explored to reveal the rationality and practicability of the constructed decision making rule.},
  archive      = {J_ISCI},
  author       = {Chao Zhang and Deyu Li and Jiye Liang},
  doi          = {10.1016/j.ins.2019.01.033},
  journal      = {Information Sciences},
  pages        = {665-683},
  shortjournal = {Inf. Sci.},
  title        = {Multi-granularity three-way decisions with adjustable hesitant fuzzy linguistic multigranulation decision-theoretic rough sets over two universes},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granularity-driven sequential three-way decisions: A
cost-sensitive approach to classification. <em>ISCI</em>, <em>507</em>,
644–664. (<a href="https://doi.org/10.1016/j.ins.2019.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential three-way decision (S3WD) is a multi-stage decision-making progress that emulates human cognition. S3WD employs coarse-to-fine information granularity and uses various types of costs to determine thresholds to make appropriate decisions. To date, however, few existing models discuss the construction of granules or consider costs in the decision process. This paper describes efforts to develop a granularity-driven sequential three-way decision model to address these two issues, and handle dual-constraint satisfaction problems considering both decision process and decision result costs. A key feature of the model is the incorporation of information granularity into the decision-making process. The model also incorporates a cost structure that accounts for the costs of both the decision process and the decision result. Using this model, we design two algorithms to minimize the cost of the decision process or the cost of the decision result. Our experimental results validate the effectiveness of the algorithms and the viability of the new model.},
  archive      = {J_ISCI},
  author       = {Yu Fang and Cong Gao and Yiyu Yao},
  doi          = {10.1016/j.ins.2019.06.003},
  journal      = {Information Sciences},
  pages        = {644-664},
  shortjournal = {Inf. Sci.},
  title        = {Granularity-driven sequential three-way decisions: A cost-sensitive approach to classification},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Sequential three-way decision based on multi-granular
autoencoder features. <em>ISCI</em>, <em>507</em>, 630–643. (<a
href="https://doi.org/10.1016/j.ins.2019.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoencoder network is an efficient representation learning method. In general, a finer feature set obtained from autoencoder leads to a lower error rate and lower total misclassification cost. However, the network is usually trained for a long time to obtain a finer feature set, leading to a high time cost and total cost. To address this issue, a Sequential Three-Way Decision (S3WD) model is developed to balance the misclassification cost and the time cost in autoencoder based classifications and decisions. To implement the tradeoff strategy, it is necessary to extract a multi-granular feature set. In the network, the associated discriminative information in the extracted features increases with training epochs, which constructs a multi-granular feature structure. An autoencoder-based multi-granular feature description definition is presented. Based on the definition, an autoencoder composed of restricted Boltzmann machines is adopted to extract the multi-granular features. Then, a new cost-sensitive S3WD model is proposed, which aims to find the optimal granule level with the lowest total cost. Finally, the experiments demonstrate the effectiveness of the proposed approaches.},
  archive      = {J_ISCI},
  author       = {Libo Zhang and Huaxiong Li and Xianzhong Zhou and Bing Huang},
  doi          = {10.1016/j.ins.2019.03.061},
  journal      = {Information Sciences},
  pages        = {630-643},
  shortjournal = {Inf. Sci.},
  title        = {Sequential three-way decision based on multi-granular autoencoder features},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequential three-way decisions via multi-granularity.
<em>ISCI</em>, <em>507</em>, 606–629. (<a
href="https://doi.org/10.1016/j.ins.2019.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decisions provide a trisecting-and-acting framework for complex problem solving. For a cost-sensitive decision-making problem under multiple levels of granularity , sequential three-way decisions have come into being. Within this framework, how to act upon the three pair-wise disjoint regions is the most important issue. To this end, we propose a generalized model of sequential three-way decisions via multi-granularity in this paper. Subsequently, we adopt the typical aggregation strategies to implement the following five kinds of multigranulation sequential three-way decisions—the weighted arithmetic mean multigranulation sequential three-way decisions, the optimistic multigranulation sequential three-way decisions, the pessimistic multigranulation sequential three-way decisions, the pessimistic-optimistic multigranulation sequential three-way decisions and the optimistic-pessimistic multigranulation sequential three-way decisions. Furthermore, we discuss the rightness and rationality of the five kinds of multigranulation sequential three-way decisions and also analyze the relationships and differences between them. Finally, the experimental results demonstrate that the first four different multigranulation sequential three-way decisions are effective. These models will accelerate and enrich the development of multigranulation three-way decisions.},
  archive      = {J_ISCI},
  author       = {Jin Qian and Caihui Liu and Duoqian Miao and Xiaodong Yue},
  doi          = {10.1016/j.ins.2019.03.052},
  journal      = {Information Sciences},
  pages        = {606-629},
  shortjournal = {Inf. Sci.},
  title        = {Sequential three-way decisions via multi-granularity},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk appetite dual hesitant fuzzy three-way decisions with
TODIM. <em>ISCI</em>, <em>507</em>, 585–605. (<a
href="https://doi.org/10.1016/j.ins.2018.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our real life, the decision maker is always of bounded rationality under risk and uncertainty. The decision result also can be impacted by the risk appetite of the decision maker . However, the existing research works of three-way decisions rarely involve the risk appetite of the decision maker. To address this drawback and enrich the application, we introduce the risk appetite into three-way decisions. More specifically, under the dual hesitant fuzzy environment, we utilize TODIM (an acronym in Portuguese for Interactive Multi-Criteria Decision Making) as a valuable tool to handle the risk appetite character to construct risk appetite dual hesitant fuzzy three-way decisions. This study takes into account the risk appetite of decision maker and designs a series of decision analysis methodologies for three-way decisions. It can preferably satisfy the practical situation and vastly extend the range of applications. Firstly, based on the dual hesitant fuzzy loss functions, we mainly study dual hesitant fuzzy entropy and cross-entropy measures for determining the conditional probability . In this scenario, the conditional probability information can be objectively learned from the loss function matrix with the aid of the power average (PA) aggregated operator. Then, considering the different comparison methods of dual hesitant fuzzy elements (DHFEs), we further design two types of strategies to deduce risk appetite dual hesitant fuzzy three-way decisions in the framework of TODIM, i.e., Strategies 1 and 2, which mainly rely on the pairwise comparison of loss functions with DHFEs. Strategy 1 is designed based on the score function of DHFEs. Strategy 2 is the likelihood of DHFEs. Meanwhile, some properties are carefully investigated. Finally, the project investment evaluation of online peer-to-peer (P2P) is applied to illustrate and validate these proposed strategies.},
  archive      = {J_ISCI},
  author       = {Decui Liang and Mingwei Wang and Zeshui Xu and Dun Liu},
  doi          = {10.1016/j.ins.2018.12.017},
  journal      = {Information Sciences},
  pages        = {585-605},
  shortjournal = {Inf. Sci.},
  title        = {Risk appetite dual hesitant fuzzy three-way decisions with TODIM},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trice-valued fuzzy sets: Mathematical model for three-way
decisions. <em>ISCI</em>, <em>507</em>, 574–584. (<a
href="https://doi.org/10.1016/j.ins.2018.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the idea to develop a mathematical model for three-way decisions, the aim of the paper is to study trice-valued fuzzy sets, i.e., mappings from a set to a structure called a trice. A trice is a triple semilattice satisfying roundabout absorption laws, suitable for representing multi-dimensional orders, which appear in complex movements in a plane or in a space. Our approach is cutworthy, namely, we investigate cuts of such fuzzy sets and prove theorems of decomposition and synthesis. This new notion provides a possibility to capture vague triangular situations. Therefore, a motivation for our research is to provide a new algebraic and order-theoretic model for three-way decisions, as this topic has been introduced recently for solving particular human problems and for information processing.},
  archive      = {J_ISCI},
  author       = {Kiyomitsu Horiuchi and Branimir Šešelja and Andreja Tepavčević},
  doi          = {10.1016/j.ins.2018.09.007},
  journal      = {Information Sciences},
  pages        = {574-584},
  shortjournal = {Inf. Sci.},
  title        = {Trice-valued fuzzy sets: Mathematical model for three-way decisions},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multigranulation rough-fuzzy clustering based on shadowed
sets. <em>ISCI</em>, <em>507</em>, 553–573. (<a
href="https://doi.org/10.1016/j.ins.2018.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new technique of rough-fuzzy clustering based on multigranulation approximation regions is developed to tackle the uncertainty associated with the fuzzifier parameter m . According to shadowed set theory, the multigranulation approximation regions for each cluster can be formed based on fuzzy membership degrees under the multiple values of fuzzifier parameter with a partially ordered relation. The uncertainty generated by the fuzzifier parameter m can be captured and interpreted through the variations in approximation regions among different levels of granularity, rather than at a single level of granularity under a specific fuzzifier value. An ensemble strategy for updating prototypes is then presented based on the constructed multigranulation approximation regions, in which the prototype calculations that may be spoiled due to the uncertainty caused by a single fuzzifier value can be modified. Finally, a multilevel degranulation mechanism is introduced to evaluate the validity of clustering methods . By integrating the notions of shadowed sets and multigranulation into rough-fuzzy clustering approaches, the overall topology of data can be captured well and the uncertain information implicated in data can be effectively addressed, including the uncertainty generated by fuzzification coefficient, the vagueness arising in boundary regions and overlapping partitions. The essence of the proposed method is illustrated by comparative experiments in terms of several validity indices.},
  archive      = {J_ISCI},
  author       = {Jie Zhou and Zhihui Lai and Duoqian Miao and Can Gao and Xiaodong Yue},
  doi          = {10.1016/j.ins.2018.05.053},
  journal      = {Information Sciences},
  pages        = {553-573},
  shortjournal = {Inf. Sci.},
  title        = {Multigranulation rough-fuzzy clustering based on shadowed sets},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Game theoretic approach to shadowed sets: A three-way
tradeoff perspective. <em>ISCI</em>, <em>507</em>, 540–552. (<a
href="https://doi.org/10.1016/j.ins.2018.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way approximations can be constructed by shadowed sets based on a pair of thresholds. The determination and interpretation of the thresholds is one of the key issues for applying three-way approximations. We apply a principle of tradeoff with games in order to determine the thresholds of three-way approximations in the shadowed set context. The changes of the elevation and reduction errors with the alteration of thresholds are examined and analyzed. The proposed game-theoretic shadowed sets (GTSS) aim to determine the thresholds of three-way approximations according to a principle of tradeoff with games. GTSS employ game theoretic approaches to formulate games between the elevation and reduction errors. A repetition learning mechanism is adopted to gradually reach balanced threshold pairs by repeatedly formulating games and finding the equilibria between the errors. The shadowed set based three-way approximations defined by the resulting thresholds represent a tradeoff between the elevation and reduction errors. Feasibility study and effectiveness analysis of GTSS is conducted with an experimental data set .},
  archive      = {J_ISCI},
  author       = {Yan Zhang and JingTao Yao},
  doi          = {10.1016/j.ins.2018.07.058},
  journal      = {Information Sciences},
  pages        = {540-552},
  shortjournal = {Inf. Sci.},
  title        = {Game theoretic approach to shadowed sets: A three-way tradeoff perspective},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general model of decision-theoretic three-way
approximations of fuzzy sets based on a heuristic algorithm.
<em>ISCI</em>, <em>507</em>, 522–539. (<a
href="https://doi.org/10.1016/j.ins.2018.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A model of decision-theoretic three-way approximations of fuzzy sets that can calculate a pair of interpretable thresholds ( α, β ) by combining shadowed sets with three-way decisions was established by Deng. In that model, the significant contribution is that the value 0.5, which denotes a membership grade with the highest uncertainty, is used to replace the uncertain region with the interval [0,1] in shadowed sets. From the principle of the minimum decision cost, although the lowest overall cost can be achieved precisely in some data distributions based on the value 0.5, there is a difference between the obtained overall cost and the least cost in some cases. Therefore, in this paper, based on Deng’s model, the concept of a general three-way approximation of a fuzzy set is proposed to replace 0.5 with a variable value c (0 &lt; c &lt; 1). Then, the loss function composed of the elevation and reduction operations in shadowed sets is established. In addition, the relationship between the required thresholds ( α, β ) with the different significance and variable value c is discussed. To optimize the loss function, particle swarm optimization (PSO) as a heuristic algorithm is introduced to search for the optimal value c by minimizing the total cost. Finally, the experimental results indicate that the proposed model, which is an extension of Deng’s model, can provide richer insight into data analysis. These conclusions further enrich shadowed sets and three-way decisions to simplify complex problems by a few membership grades.},
  archive      = {J_ISCI},
  author       = {Qinghua Zhang and Deyou Xia and Kaixuan Liu and Guoyin Wang},
  doi          = {10.1016/j.ins.2018.10.051},
  journal      = {Information Sciences},
  pages        = {522-539},
  shortjournal = {Inf. Sci.},
  title        = {A general model of decision-theoretic three-way approximations of fuzzy sets based on a heuristic algorithm},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval data driven construction of shadowed sets with
application to linguistic word modelling. <em>ISCI</em>, <em>507</em>,
503–521. (<a href="https://doi.org/10.1016/j.ins.2018.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval data from different surveyed persons for one linguistic word can reflect the intra- and inter-uncertainties of the word. This study shows how to construct shadowed set models for linguistic words based on the surveyed interval data. Firstly, corresponding to the popularly used fuzzy sets for linguistic words, four kinds of shadowed sets are introduced according to their shapes and named as the normal, the left-shoulder, the right-shoulder, and the non-cored shadowed sets. A data-driven approach that utilizes different statistics to determine the shapes and parameters of the shadowed set models is then proposed. The proposed data-driven approach includes two methods; the first is the tolerance limit method depending on the mean and standard deviation of the remaining interval data after pre-processing, whilst the other is the percentile method relying on the percentiles of the remaining interval data. Additionally, to evaluate the modelling performance, three novel indices are presented to measure the uncertainty-capture capability and accuracy of the constructed shadowed set models. Finally, the proposed approach is applied to two real-world problems. One is the modelling of 32 words in a codebook, and the other is the modelling of the thermal feeling words. The proposed methods are compared with other interval data driven methods, e.g. the enhanced interval approach and the fuzzy statistic method. Our results show that the proposed percentile method performs better in both applications. The proposed approach can also be applied to some other linguistic word modelling applications when it is reasonable to adopt shadowed sets as the words’ models.},
  archive      = {J_ISCI},
  author       = {Chengdong Li and Jianqiang Yi and Hongkai Wang and Guiqing Zhang and Junqing Li},
  doi          = {10.1016/j.ins.2018.11.018},
  journal      = {Information Sciences},
  pages        = {503-521},
  shortjournal = {Inf. Sci.},
  title        = {Interval data driven construction of shadowed sets with application to linguistic word modelling},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shadowed numbers and their standard and multidimensional
arithmetic. <em>ISCI</em>, <em>507</em>, 485–502. (<a
href="https://doi.org/10.1016/j.ins.2018.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A shadowed set was introduced by W. Pedrycz as a concept of modeling vagueness. There are methods and algorithms for obtaining a shadowed set on the basis of a fuzzy set; a shadowed number can also be obtained from a fuzzy number. This article presents definitions of a shadowed number and two concepts of its arithmetic. The first arithmetic is called standard shadowed arithmetic (SSA) and relies on standard interval arithmetic (SIA), while the second is called multidimensional RDM shadowed arithmetic (RDMSA) and is based on multidimensional relative distance measure interval arithmetic (RDMIA). This paper presents the basic properties of operations on shadowed numbers with SSA and RDMSA. It also provides examples that show the difference between the results obtained with SSA and those obtained with multidimensional RDMSA. RDMSA introduces a multidimensional approach to the concept of uncertainty calculation results. Theories and examples presented in this paper will help to develop three-way decision methods and models, and can be applied in granular computing .},
  archive      = {J_ISCI},
  author       = {Marek Landowski},
  doi          = {10.1016/j.ins.2018.11.047},
  journal      = {Information Sciences},
  pages        = {485-502},
  shortjournal = {Inf. Sci.},
  title        = {Shadowed numbers and their standard and multidimensional arithmetic},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Relational granulation method based on quotient space
theory for maximum flow problem. <em>ISCI</em>, <em>507</em>, 472–484.
(<a href="https://doi.org/10.1016/j.ins.2018.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing (GrC) is a problem-solving concept deeply rooted in human thinking. GrC, as a new and rapidly growing paradigm of information processing, has attracted the attention of many researchers and practitioners. GrC is related to granulation, i.e., a process of drawing a set of objects (or points) together based on their indiscernibility, similarity, proximity, or functionality. In general, two types of granulation processes exist: functional granulation and relational granulation. If the process is based entirely on the attributes of the objects, it is known as functional granulation, whereas if the granulation process is based on the relationship between objects, it is known as relational granulation. This paper proposes a novel method, called the maximum flow based on Quotient Space Theory ( M F − Q S T MF−QST ), for solving the maximum flow problems based on Quotient Space Theory for relational granulation. Using the method M F − Q S T , MF−QST, substructures are first detected, and the community is described as a substructure. Next, the relational granulation criterion is discussed in detail. The substructure that satisfies the relational granulation criterion is regarded as a coarse-grained node. Subsequently, the construction of a quotient network that is coarser than the original network is described. Finally, the maximum flow algorithm is used to compute the maximum flow on the quotient network as the approximated maximum flow on the original network within a much shorter period of time . Experimental results demonstrate that the novel method M F − Q S T MF−QST reduces the cumulative running time after simplifying the network structure with a low error rate. The size of the quotient network is significantly reduced, and the node and edge scales are reduced to 20.59\% and 21.62\% on average, respectively.},
  archive      = {J_ISCI},
  author       = {Shu Zhao and Xian Sun and Jie Chen and Zhen Duan and Yanping Zhang and Yiwen Zhang},
  doi          = {10.1016/j.ins.2018.12.009},
  journal      = {Information Sciences},
  pages        = {472-484},
  shortjournal = {Inf. Sci.},
  title        = {Relational granulation method based on quotient space theory for maximum flow problem},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Information structures in a covering information system.
<em>ISCI</em>, <em>507</em>, 449–471. (<a
href="https://doi.org/10.1016/j.ins.2018.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A covering information system as the generalization of an information system is an important model in the field of artificial intelligence . This paper explores information structures in a covering information system, and this kind of structure is viewed as a granular structure from the granular computing viewpoint. The concept of information structures in a covering information system is first described by means of set vectors. Then, relationships between information structures in a covering information system are studied from the two aspects of dependence and separation. Next, properties of information structures in a covering information system are given. Furthermore, invariant characterizations of covering information systems under homomorphisms are presented. Finally, as an application for information structures in a covering information system, the granularity measure of uncertainty for covering information systems is investigated. These results will be very helpful for establishing a framework for granular computing in information systems.},
  archive      = {J_ISCI},
  author       = {Zhaowen Li and Dan Huang and Xiaofeng Liu and Ningxin Xie and Gangqiang Zhang},
  doi          = {10.1016/j.ins.2018.09.048},
  journal      = {Information Sciences},
  pages        = {449-471},
  shortjournal = {Inf. Sci.},
  title        = {Information structures in a covering information system},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inclusion measure-based multi-granulation decision-theoretic
rough sets in multi-scale intuitionistic fuzzy information tables.
<em>ISCI</em>, <em>507</em>, 421–448. (<a
href="https://doi.org/10.1016/j.ins.2018.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-granulation rough sets (MGRSs) and decision-theoretic rough sets (DTRSs) are important and popular extended types of Pawlak’s classical rough set model. Multi-granulation DTRSs (MG-DTRSs), which combine these two generalized rough set models, have been investigated in depth in recent years to handle noisy distributed data. However, this combination cannot be used to acquire knowledge from multi-scale information systems, in which an object may take on different values under the same attribute depending on the scale used to measure it. Two novel types of MG-DTRSs in multi-scale intuitionistic fuzzy (IF) information tables have been developed on the basis of IF inclusion measures in this study to solve this problem. First, we introduce a type of inclusion measure between two IF sets and present the concept of inclusion measure-based DTRSs in multi-scale IF information tables. Second, we present the inclusion measure-based optimistic and pessimistic MG-DTRSs in multi-scale IF information tables, examine their properties, and analyze the three-way decision method based on the presented models. Third, we define the optimal scale selection and present the two optimal scale selection algorithms based on MG-DTRSs in multi-scale IF information tables. Fourth, we provide the reducts of the optimal scales based on MG-DTRSs in multi-scale IF information tables, examine the discernibility function reduction method, and devise two algorithms for computing an optimal approximation scale reduct. Finally, we discuss several possible generalizations related to MG-DTRSs in multi-scale IF information tables. This study provides an MG-DTRS method for acquiring knowledge from multi-scale IF information tables.},
  archive      = {J_ISCI},
  author       = {Bing Huang and Wei-Zhi Wu and Jinjiang Yan and Huaxiong Li and Xianzhong Zhou},
  doi          = {10.1016/j.ins.2018.08.061},
  journal      = {Information Sciences},
  pages        = {421-448},
  shortjournal = {Inf. Sci.},
  title        = {Inclusion measure-based multi-granulation decision-theoretic rough sets in multi-scale intuitionistic fuzzy information tables},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting evolving micro-clusters for data stream
classification with emerging class detection. <em>ISCI</em>,
<em>507</em>, 404–420. (<a
href="https://doi.org/10.1016/j.ins.2019.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning non-stationary data streams is challenging due to the unique characteristics of infinite length and evolving property. Current existing works often concentrate on the concept-drift problem in data streams. Concept evolution, indicating novel classes are emerged in data streams, has gained growing attention recently due to its practical values in many real-world applications. Thereby, how to design a new robust learning model on data streams to handle concept drift, concept evolution and outliers simultaneously, is of significant importance. To this end, we propose a new data stream classification approach, called EMC, which dynamically learns the E volving M icro- C lusters to examine both concept drift and evolution. Specifically, to capture time-changing concept, EMC dynamically maintains a set of online micro-clusters and learns their importance with error-based representative learning. Building upon the evolving micro-clusters, the novel class detector is introduced based on a local density perspective, which allows handling the data streams with complex class distribution. Beyond, EMC allows distinguishing concept drift and evolution from noisy instances. Extensive experiments on both synthetic and real-world data sets show that our method has good classification and novel class detection performance compared to state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Salah Ud Din and Junming Shao},
  doi          = {10.1016/j.ins.2019.08.050},
  journal      = {Information Sciences},
  pages        = {404-420},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting evolving micro-clusters for data stream classification with emerging class detection},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-source data repairing powered by integrity constraints
and source reliability. <em>ISCI</em>, <em>507</em>, 386–403. (<a
href="https://doi.org/10.1016/j.ins.2019.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is crucial to identify and resolve the inconsistencies and conflicts in data. To tackle the inconsistencies, integrity constraints are involved to constrain the attribute values of related entities. As for the multi-source conflicts, the true values of each entity are identified by trusting the reliable sources. In practice, it is common that inconsistencies and conflicts simultaneously appear. To deal with this case, traditional techniques would separately resolve the inconsistencies and conflicts, by conducting different approaches based on the above principles. However, such a procedure may not be the appropriate solution. Specifically, locally resolving conflicts for a certain entity may overlook the information from its related entities, while enforcing constraints on related entities may miss correct values of these entities in turn. To jointly resolve the inconsistencies and conflicts, this paper proposes a novel technique powered by integrity constraints and source reliability. The key component of our solution is to incorporate denial constraints, an expressive type of integrity constraint, into the process of conflict resolution. We formulate it as an optimization problem and develop an iterative algorithm to solve it. Benefiting from this algorithm, the repaired result is not only supported by reliable sources but also satisfies the denial constraints. Additionally, we also propose two optimal strategies to ensure that it is scalable under massive constraints. Experimental results on real-world datasets demonstrate the high accuracy and scalability of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Chen Ye and Hongzhi Wang and Kangjie Zheng and Jing Gao and Jianzhong Li},
  doi          = {10.1016/j.ins.2019.08.044},
  journal      = {Information Sciences},
  pages        = {386-403},
  shortjournal = {Inf. Sci.},
  title        = {Multi-source data repairing powered by integrity constraints and source reliability},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learned sketches for frequency estimation. <em>ISCI</em>,
<em>507</em>, 365–385. (<a
href="https://doi.org/10.1016/j.ins.2019.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Count-Min sketch and its variations are widely used to solve the frequency estimation problem due to its sub-linear space cost. However, the collisions between high-frequency and low-frequency items introduce a significant estimation error. In this paper, we propose two learned sketches called the Learned Count-Min sketch and Learned Augmented sketch. We combine the machine learning methods with the traditional Count-Min sketch and Augmented sketch to improve the performance. We used a regression model trained from historical data to predict the frequencies and separate the high-frequency items and low-frequency items. The experimental results indicated that our learned sketches outperform the traditional Count-Min sketch and Augmented sketch. The learned sketches can provide a more accurate estimation with a more compact synopsis size.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Hongzhi Wang and Jianzhong Li and Hong Gao},
  doi          = {10.1016/j.ins.2019.08.045},
  journal      = {Information Sciences},
  pages        = {365-385},
  shortjournal = {Inf. Sci.},
  title        = {Learned sketches for frequency estimation},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DSTNet: Successive applications of the discrete schroedinger
transform for texture recognition. <em>ISCI</em>, <em>507</em>, 356–364.
(<a href="https://doi.org/10.1016/j.ins.2019.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a strategy for texture recognition by the successive application of the operator corresponding to the state-of-the-art Schroedinger distance transform. The idea is inspired by the recently proposed scattering networks and combines a nonlinear filter that is typically employed to provide “hand-crafted” image descriptors with a recursive scheme that can be easily adapted for an implementation similar to what is employed in convolutional neural networks . The classification performance of the proposal is assessed over well known texture databases, to know, KTHTIPS-2b, UMD and UIUC as well as in a practical problem, i.e., the identification of Brazilian plant species using images collected from their leaves. The proposed method demonstrated to be competitive with other state-of-the-art approaches and confirmed the interest in studies of composite application of nonlinear operators for texture recognition.},
  archive      = {J_ISCI},
  author       = {Joao B. Florindo},
  doi          = {10.1016/j.ins.2019.08.049},
  journal      = {Information Sciences},
  pages        = {356-364},
  shortjournal = {Inf. Sci.},
  title        = {DSTNet: Successive applications of the discrete schroedinger transform for texture recognition},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Link-aware semi-supervised hypergraph. <em>ISCI</em>,
<em>507</em>, 339–355. (<a
href="https://doi.org/10.1016/j.ins.2019.07.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph learning has been widely applied to various learning tasks. To ensure learning accuracy, it is essential to construct an informative hypergraph structure that effectively modulates data correlations. However, existing hypergraph construction methods essentially resort to an unsupervised learning paradigm, which ignores supervisory information, such as pairwise links/non-links. In this article, to exploit the supervisory information, we propose a novel link-aware hypergraph learning model, which modulates high-order correlations of data samples in a semi-supervised manner. To construct a hypergraph, a coefficients matrix of the entire dataset is first calculated by solving a linear regression problem . Then, pairwise link constraints are exploited and propagated to the unconstrained samples, upon which the coefficients matrix is adjusted accordingly. Finally, the adjusted coefficients are used to generate a set of the hyperedges , as well as calculate the corresponding weights. We have validated the proposed link-aware semi-supervised hypergraph model on the problem of image clustering. Superior performance over the state-of-the-art methods demonstrates the effectiveness of the proposed hypergraph model.},
  archive      = {J_ISCI},
  author       = {Taisong Jin and Liujuan Cao and Feiran Jie and Rongrong Ji},
  doi          = {10.1016/j.ins.2019.07.095},
  journal      = {Information Sciences},
  pages        = {339-355},
  shortjournal = {Inf. Sci.},
  title        = {Link-aware semi-supervised hypergraph},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating the reliability of sources of evidence with a
two-perspective approach in classification problems based on evidence
theory. <em>ISCI</em>, <em>507</em>, 313–338. (<a
href="https://doi.org/10.1016/j.ins.2019.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conflict management and accuracy improvement are the two main concerns of classification problems based on the evidence theory. High conflict among sources of evidence can be solved effectively using discounting methods based on source-reliability evaluations. However, these methods may not ensure efficient performance of a classification model. To relieve high conflict and improve accuracy, a two-perspectives approach for reliability evaluation is presented to generate discounting rules. An independent reliability evaluation (IRE) is used to assess the independent reliability of an individual source, under the assumption that the source works independently. The other perspective is the combination reliability evaluation (CRE). It evaluates all the sources by considering the combination relationship among them. Both methods are designed as supervising methods and integrate a new dissimilarity measure proposed in this paper—decision dissimilarity—with the Jousselme distance. The ability of the new dissimilarity measure to effectively discriminate evidence from the truth can be experimentally verified. The proposed approach is not only effective for conflict management but also for the improvement of the performance of classification models based on the evidence theory as it helps implement the correct and specific decisions.},
  archive      = {J_ISCI},
  author       = {Zhao Jie and Xue Rui and Dong Zhenning and Tang Deyu and Wei Wenhong},
  doi          = {10.1016/j.ins.2019.08.033},
  journal      = {Information Sciences},
  pages        = {313-338},
  shortjournal = {Inf. Sci.},
  title        = {Evaluating the reliability of sources of evidence with a two-perspective approach in classification problems based on evidence theory},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logit choice models for interactive attributes.
<em>ISCI</em>, <em>507</em>, 298–312. (<a
href="https://doi.org/10.1016/j.ins.2019.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi attribute decision making (MADM), the choice of a decision-maker (DM) is often the result of an interplay between the DM’s unique attitude, the utilities (specific to the DM) for the attributes, and the degree of positive (or negative) interaction among the attributes. Based on this conglomeration of information, we introduce a few choice models to give the probabilities for different possible choices of a DM. More specifically, the conventional multinomial logit (MNL) model is extended to consider the interaction among the attributes, and also the DM’s unique attitudinal character. The usefulness of the proposed models is illustrated in a real world application .},
  archive      = {J_ISCI},
  author       = {Manish Aggarwal},
  doi          = {10.1016/j.ins.2019.08.013},
  journal      = {Information Sciences},
  pages        = {298-312},
  shortjournal = {Inf. Sci.},
  title        = {Logit choice models for interactive attributes},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving based task allocation with mobile edge
clouds. <em>ISCI</em>, <em>507</em>, 288–297. (<a
href="https://doi.org/10.1016/j.ins.2019.07.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile crowdsensing applications, task allocation has emerged as a new problem to be solved. Many task allocation strategies have been proposed to select the proper participants to complete tasks. Those methods need participants to submit their real locations to the platform in order to realize the optimal task assignment. However, those traditional task allocation strategies have two weaknesses. First, centralized task allocations result in high computing and communications loads. Second, the exposure of real locations increases participants’ concerns regarding location privacy. To address these problems, in this paper, we propose an optimal geo-indistinguishable task allocation (GITA) mechanism using mobile edge clouds. First, the new task that is received by the remote cloud is sent to the mobile edge cloud that is nearest to the task location. Then, the mobile edge clouds serve as distributed controllers to allocate the assigned tasks to the proper candidates. To protect the candidates’ real locations, we utilize a geo-indistinguishable mechanism based on differential privacy to preserve location privacy. Specifically, we obfuscate the participants’ real locations as disturbed locations, and realize the optimal task allocation based on these disturbed locations. Furthermore, we apply multiobjective mixed integer nonlinear optimization to solve this problem. Finally, extensive experimental results show that, compared with the traditional Laplace mechanism and another privacy-preserving task allocation strategy, the GITA mechanism that is proposed in this paper can decrease users’ moving distances and raise the task completion rate .},
  archive      = {J_ISCI},
  author       = {Yongfeng Qian and Yingying Jiang and M. Shamim Hossain and Long Hu and Ghulam Muhammad and Syed Umar Amin},
  doi          = {10.1016/j.ins.2019.07.092},
  journal      = {Information Sciences},
  pages        = {288-297},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving based task allocation with mobile edge clouds},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the transitivity and consistency approximated thresholds
of some consistency indices for pairwise comparison matrices.
<em>ISCI</em>, <em>507</em>, 274–287. (<a
href="https://doi.org/10.1016/j.ins.2019.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several measures have been proposed in the literature to verify the rationality and consistency of judgements expressed by means of pairwise comparisons . However, some of these indices lack a meaningful interpretation because of the absence of thresholds associated with them. In this paper, we first introduce the consistency approximated thresholds for the Salo–Hamalainen index by deriving an inconsistency tolerance level, which is analogous to that proposed for the Consistency Ratio by Saaty, for the Geometric Consistency Index by Aguaron–Moreno Jimenez, and for the Consistency Measure by Koczkodaj. Then, via a simulation, we propose a transitivity threshold, for n × n matrices, which may give meaningful information about the degree of misclassification and the reliability of preferences while avoiding the need to revise the judgements. On varying n , we derive the transitivity thresholds for Salo–Hamalainen and for the other consistency indices proposed in literature.},
  archive      = {J_ISCI},
  author       = {Pietro Amenta and Antonio Lucadamo and Gabriella Marcarelli},
  doi          = {10.1016/j.ins.2019.08.042},
  journal      = {Information Sciences},
  pages        = {274-287},
  shortjournal = {Inf. Sci.},
  title        = {On the transitivity and consistency approximated thresholds of some consistency indices for pairwise comparison matrices},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Erratum to ‘‘multiattribute decision making based on
interval-valued intuitionistic fuzzy values and particle swarm
optimization techniques” [inf. Sci. 397–398 (2017) 206–218].
<em>ISCI</em>, <em>507</em>, 273. (<a
href="https://doi.org/10.1016/j.ins.2019.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Shyi-Ming Chen and Zhi-Cheng Huang},
  doi          = {10.1016/j.ins.2019.08.030},
  journal      = {Information Sciences},
  pages        = {273},
  shortjournal = {Inf. Sci.},
  title        = {Erratum to ‘‘Multiattribute decision making based on interval-valued intuitionistic fuzzy values and particle swarm optimization techniques” [Inf. sci. 397–398 (2017) 206–218]},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Fine-grained neural decoding with distributed word
representations. <em>ISCI</em>, <em>507</em>, 256–272. (<a
href="https://doi.org/10.1016/j.ins.2019.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {fMRI word decoding refers to decode what the human brain is thinking by interpreting functional Magnetic Resonance Imaging (fMRI) scans from people watching or listening to words, representing a sort of mind-reading technology. Existing works decoding words from imaging data have been largely limited to concrete nouns from a relatively small number of semantic categories. Moreover, such studies use different word-stimulus presentation paradigms and different computational models , lacking a comprehensive understanding of the influence of different factors on fMRI word decoding. In this paper, we present a large-scale evaluation of eight word embedding models and their combinations for decoding fine-grained fMRI data associated with three classes of words recorded from three stimulus-presentation paradigms. Specifically, we investigate the following research questions: (1) How does the brain-image decoder perform on different classes of words? (2) How does the brain-image decoder perform in different stimulus-presentation paradigms? (3) How well does each word embedding model allow us to decode neural activation patterns in the human brain? Furthermore, we analyze the most informative voxels associated with different classes of words, stimulus-presentation paradigms and word embedding models to explore their neural basis. The results have shown the following: (1) Different word classes can be decoded most effectively with different word embedding models. Concrete nouns and verbs are more easily distinguished than abstract nouns and verbs. (2) Among the three stimulus-presentation paradigms (picture, sentence and word clouds), the picture paradigm achieves the highest decoding accuracy, followed by the sentence paradigm. (3) Among the eight word embedding models, the model that encodes visual information obtains the best performance, followed by models that encode textual and contextual information. (4) Compared to concrete nouns, which activate mostly vision-related brain regions, abstract nouns activate broader brain regions such as the visual, language and default-mode networks. Moreover, both the picture paradigm and the model that encodes visual information have stronger associations with vision-related brain regions than other paradigms and word embedding models, respectively.},
  archive      = {J_ISCI},
  author       = {Shaonan Wang and Jiajun Zhang and Haiyan Wang and Nan Lin and Chengqing Zong},
  doi          = {10.1016/j.ins.2019.08.043},
  journal      = {Information Sciences},
  pages        = {256-272},
  shortjournal = {Inf. Sci.},
  title        = {Fine-grained neural decoding with distributed word representations},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regularization-based model tree for multi-output regression.
<em>ISCI</em>, <em>507</em>, 240–255. (<a
href="https://doi.org/10.1016/j.ins.2019.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-output regression refers to the simultaneous prediction of several real-valued output variables to improve generalization performance by exploiting output relatedness. We propose a multi-output model tree that utilizes a regularization-based method to exploit the output relatedness when estimating linear models at leaf nodes . The proposed method can explain nonlinear input–output relation and provides easy interpretation of its mechanism based on input space partitioning and models at leaf nodes . The models exploit output relatedness by selecting common input variables to explain related output variables. We also present a computationally efficient two-stage splitting procedure that decreases the number of model estimations by analyzing residuals. We verify the effectiveness of the proposed method in a simulation study and demonstrate that it outperforms existing methods on several benchmark datasets. Furthermore, we apply the proposed method to real industry data as a case study to predict tensile qualities of plates.},
  archive      = {J_ISCI},
  author       = {Jun-Yong Jeong and Ju-Seok Kang and Chi-Hyuck Jun},
  doi          = {10.1016/j.ins.2019.08.034},
  journal      = {Information Sciences},
  pages        = {240-255},
  shortjournal = {Inf. Sci.},
  title        = {Regularization-based model tree for multi-output regression},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A just-in-time-learning based two-dimensional control
strategy for nonlinear batch processes. <em>ISCI</em>, <em>507</em>,
220–239. (<a href="https://doi.org/10.1016/j.ins.2019.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of two-dimensional (2D) integrated model predictive iterative learning control for nonlinear batch processes . A nonlinear process is presented by using local models together with a just-in-time-learning (JITL) method. In order to deal with the problem of massive computation for identifying JITL models, a three-layer searching strategy and an updating mechanism for databases are proposed. First, a dynamic model whose parameters vary with time and batch is established for batch processes . Then, a JITL-based 2D control strategy is devised to realize comprehensive control by combining iterative learning control in batch-axis with model predictive control in time-axis. As a result, not only the closed-loop control performance can be improved, but also the optimization procedure can be simplified. Finally, performance analysis verifies the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Liuming Zhou and Li Jia and Yu-Long Wang},
  doi          = {10.1016/j.ins.2019.08.028},
  journal      = {Information Sciences},
  pages        = {220-239},
  shortjournal = {Inf. Sci.},
  title        = {A just-in-time-learning based two-dimensional control strategy for nonlinear batch processes},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach for efficient updating approximations in
dynamic ordered information systems. <em>ISCI</em>, <em>507</em>,
197–219. (<a href="https://doi.org/10.1016/j.ins.2019.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic data in real-time application are typically updating in a multi-dimensional manner. In this paper, we introduce a novel approach based on Dominance-based Rough Set Approach (DRSA) to efficiently deal with the multi-dimensional variations of attribute set and attribute values in dynamic Ordered Information Systems (OIS). We improve the original notion of the P-generalized decision domains to make the feature value matrix be dominance symmetrical, and propose an efficient strategy based on the improved notion to obtain the dominance feature matrix. Then, we employ the dominance-feature-matrix-based incremental strategy to avoid repeated comparisons between original attributes, so that to efficiently update rough approximations of DRSA with the simultaneously increased attribute set and varied attribute values. In our approach, the steps based on these two combined strategies can work altogether or separately, not only efficiently dealing with the simultaneously increased attribute set and varied attribute values, but also efficiently dealing with the individually increased attribute set or varied attribute values in dynamic OIS. Efficient algorithm based on the updating strategies is designed and multiple groups of experiments are conducted. Experimental results on different real-world data sets show that the proposed algorithm is much faster than other algorithms for dealing with the multi-dimensional or the single-dimensional variations of attribute set and attribute values.},
  archive      = {J_ISCI},
  author       = {Shu Wang and Tianrui Li and Chuan Luo and Jie Hu and Hamido Fujita and Tianqiang Huang},
  doi          = {10.1016/j.ins.2019.08.046},
  journal      = {Information Sciences},
  pages        = {197-219},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for efficient updating approximations in dynamic ordered information systems},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel alternating direction method of multipliers.
<em>ISCI</em>, <em>507</em>, 185–196. (<a
href="https://doi.org/10.1016/j.ins.2019.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the distributed optimization problem, where the objective function is the sum of local cost functions. To solve this problem, a new parallel Alternating Direction Method of Multipliers (ADMM) algorithm is developed, which guarantees that the agents cooperatively reach an optimal agreement. Different from most of the existing ADMM approaches, our algorithm allows all the agents to update their local variables simultaneously in a parallel manner. It is theoretically proved that the local solutions of all the agents could reach a consensus, and converge to the optimal solution asymptotically with the rate of O (1/ k ). Numerical examples are finally provided to validate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jiaqi Yan and Fanghong Guo and Changyun Wen and Guoqi Li},
  doi          = {10.1016/j.ins.2019.08.039},
  journal      = {Information Sciences},
  pages        = {185-196},
  shortjournal = {Inf. Sci.},
  title        = {Parallel alternating direction method of multipliers},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning data streams online — an evolving fuzzy system
approach with self-learning/adaptive thresholds. <em>ISCI</em>,
<em>507</em>, 172–184. (<a
href="https://doi.org/10.1016/j.ins.2019.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the weakness of the existing evolving fuzzy systems (EFSs) where the selection and determination of thresholds for the structure and parameter learning are completely relied on the trial and error strategy, this paper proposes a novel and symmetrical approach with self-learning/adaptive thresholds (EFS-SLAT) for EFSs to overcome such a fundamental weakness. Departing from the common but implicit assumption in the existing EFS approaches that the thresholds are fixed parameters throughout the learning process, EFS-SLAT treats the thresholds as dynamical parameters which are varying with the evolution of systems being learned. By utilizing the online training errors as an indicator to reflect the underfitting and overfitting state of an EFS model, the proposed EFS-SLAT selects and adjusts the values of threshold parameters automatically and dynamically based on the evolving speed and nonlinear degree of the EFS. By testing EFS-SLAT on several well-known benchmark examples, and comparing it with many state-of-the-art approaches, EFS-SLAT is verified to be capable of giving preferable results.},
  archive      = {J_ISCI},
  author       = {Dongjiao Ge and Xiao-Jun Zeng},
  doi          = {10.1016/j.ins.2019.08.036},
  journal      = {Information Sciences},
  pages        = {172-184},
  shortjournal = {Inf. Sci.},
  title        = {Learning data streams online — an evolving fuzzy system approach with self-learning/adaptive thresholds},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A flexible method to defend against computationally
resourceful miners in blockchain proof of work. <em>ISCI</em>,
<em>507</em>, 161–171. (<a
href="https://doi.org/10.1016/j.ins.2019.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain is well known as a decentralized and distributed public digital ledger, and is currently used by most cryptocurrencies to record transactions. One of the fundamental differences between blockchain and traditional distributed systems is that blockchain’s decentralization relies on consensus protocols, such as proof of work (PoW). However, computation systems, such as application specific integrated circuit (ASIC) machines, have recently emerged that are specifically designed for PoW computation and may compromise a decentralized system within a short amount of time. These computationally resourceful miners challenge the very nature of blockchain, with potentially serious consequences. Therefore, in this paper, we propose a general and flexible PoW method that enforces memory usage. Specifically, the proposed method blocks computationally resourceful miners and retains the previous design logic without requiring one to replace the original hash function . We also propose the notion of a memory intensive function (MIF) with a memory usage parameter k ( k MIF kMIF ). Our scheme comprises three algorithms that construct a k MIF kMIF Hash by invoking any available hash function which is not k MIF kMIF to protect against ASICs, and then thwarts the pre-computation of hash results over a nonce. We then design experiments to evaluate memory changes in these three algorithms, and the findings demonstrate that enforcing memory usage in a blockchain can be an effective defense against computationally resourceful miners.},
  archive      = {J_ISCI},
  author       = {Wei Ren and Jingjing Hu and Tianqing Zhu and Yi Ren and Kim-Kwang Raymond Choo},
  doi          = {10.1016/j.ins.2019.08.031},
  journal      = {Information Sciences},
  pages        = {161-171},
  shortjournal = {Inf. Sci.},
  title        = {A flexible method to defend against computationally resourceful miners in blockchain proof of work},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A physiological and behavioral feature authentication scheme
for medical cloud based on fuzzy-rough core vector machine.
<em>ISCI</em>, <em>507</em>, 143–160. (<a
href="https://doi.org/10.1016/j.ins.2019.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical cloud brings in connivance to share medical data within the same hospital or between different hospitals. However, sharing medical data on the cloud faces challenges such as (1) the medical cloud platform is vulnerable to cyber attacks , (2) medical data can be illegally accessed by the doctor without patient’s authorization, and (3) unauthorized access from an attacker. Currently, common security authentication schemes generally use fingerprint or face for identification, but these biometric data are easily copied and reused. At present, widely used biometric authentications such as fingerprint and faceID are easy to be copied and reused. The latest GAN algorithm has broken into almost all face recognition systems, the success proportion of the attack reached 95\%. Therefore, a secure login authentication scheme is needed. In this paper, we propose a physiological and behavioral feature authentication scheme based on fuzzy-rough theory to limit the access right of medical devices. Such a scheme requires the doctor’s own gesture for the authorization to access the medical device. Fuzzy-rough core vector machine (FRCVM) approach is adopted in our scheme to achieve high classification accuracy and efficiency. The results have shown that our solutions are highly secure and practical. To secure the cloud platform and ensure only the authorized doctors can access the patient data, we have designed an efficient data sharing solution that enables medical data stored in the cloud to be hierarchically authorized for patient access. The solution exploits proxy re-encryption to protect patient-centric medical data sharing.},
  archive      = {J_ISCI},
  author       = {Liming Fang and Changchun Yin and Lu Zhou and Yang Li and Chunhua Su and Jinyue Xia},
  doi          = {10.1016/j.ins.2019.08.020},
  journal      = {Information Sciences},
  pages        = {143-160},
  shortjournal = {Inf. Sci.},
  title        = {A physiological and behavioral feature authentication scheme for medical cloud based on fuzzy-rough core vector machine},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). Spatiotemporal road scene reconstruction using
superpixel-based markov random field. <em>ISCI</em>, <em>507</em>,
124–142. (<a href="https://doi.org/10.1016/j.ins.2019.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene reconstruction based on image rendering is an indispensable but challenging task in computer vision and intelligent transportation systems . We propose a framework for reconstructing road scenes as 3D corridor models and consisting of two stages: road detection and scene reconstruction. Road detection is realized by the novel superpixel-based Markov random field . The data fidelity term in the energy function is jointly computed according to superpixel features of color, texture and location. The smoothness term is established from the interaction of spatiotemporally adjacent superpixels. In the subsequent scene reconstruction, the foreground and background regions are modeled independently. Experiments on road detection demonstrate that our proposal outperforms state-of-the-art methods in both accuracy and computation speed. Scene reconstruction experiments further confirm that the scene models retrieved by the proposed method have higher correctness ratio, and can support several applications.},
  archive      = {J_ISCI},
  author       = {Yaochen Li and Yuehu Liu and Jihua Zhu and Shiqi Ma and Zhenning Niu and Rui Guo},
  doi          = {10.1016/j.ins.2019.08.038},
  journal      = {Information Sciences},
  pages        = {124-142},
  shortjournal = {Inf. Sci.},
  title        = {Spatiotemporal road scene reconstruction using superpixel-based markov random field},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the traveling repairman problem with profits: A
novel variable neighborhood search approach. <em>ISCI</em>,
<em>507</em>, 108–123. (<a
href="https://doi.org/10.1016/j.ins.2019.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Repairman Problem with profits generalizes the Traveling Repairman Problem, by taking into account the variability of the repairman’s profit over different time steps in order to maximize the total profit. In this paper, we first analyze the complexities of several neighborhood structures and the efficient updating of objective values of solutions from those neighborhoods. Then we present a new heuristic based on General variable neighborhood search , that uses a local search that combines those neighborhoods in an effective way. Detailed experiments on benchmark instances show that our new method outperforms all previous heuristics. Out of 60 instances tested, it was able to replicate the best known solutions in 20 of them and find new best solutions in the remaining 40.},
  archive      = {J_ISCI},
  author       = {Jun Pei and Nenad Mladenović and Dragan Urošević and Jack Brimberg and Xinbao Liu},
  doi          = {10.1016/j.ins.2019.08.017},
  journal      = {Information Sciences},
  pages        = {108-123},
  shortjournal = {Inf. Sci.},
  title        = {Solving the traveling repairman problem with profits: A novel variable neighborhood search approach},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach to interval-valued probability measures, a
formal method for consolidating the languages of information deficiency:
foundations. <em>ISCI</em>, <em>507</em>, 86–107. (<a
href="https://doi.org/10.1016/j.ins.2019.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a new formal definition of an interval valued probability measure (IVPM) based on a measure theoretic foundation, and shows that various uncertainties that occur in data associated in mathematical analyses, for example, in optimization under uncertainty models, can be unified and formulated within this one common IVPM framework facilitating the solution of many mathematical problems . This article develops a theory, we call generalized uncertainty theory, that will be characterized by the generation of upper and lower bounding functions enclosing all distributions that are possible from the given partial information.},
  archive      = {J_ISCI},
  author       = {K. David Jamison and Weldon A. Lodwick},
  doi          = {10.1016/j.ins.2019.07.044},
  journal      = {Information Sciences},
  pages        = {86-107},
  shortjournal = {Inf. Sci.},
  title        = {A new approach to interval-valued probability measures, a formal method for consolidating the languages of information deficiency: Foundations},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary differential evolution with self-learning for
multi-objective feature selection. <em>ISCI</em>, <em>507</em>, 67–85.
(<a href="https://doi.org/10.1016/j.ins.2019.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important data preprocessing method. This paper studies a new multi-objective feature selection approach, called the Binary Differential Evolution with self-learning (MOFS-BDE). Three new operators are proposed and embedded into the MOFS-BDE to improve its performance. The novel binary mutation operator based on probability difference can guide individuals to rapidly locate potentially optimal areas, the developed One-bit Purifying Search operator (OPS) can improve the self-learning capability of the elite individuals located in the optimal areas, and the efficient non-dominated sorting operator with crowding distance can reduce the computational complexity of the selection operator in the differential evolution. Experimental results on a series of public datasets show that the effective combination of the binary mutation and OPS makes our MOFS-BDE achieve a trade-off between local exploitation and global exploration. The proposed method is competitive in comparison with some representative genetic algorithm-, particle swarm-, differential evolution-, and artificial bee colony-based feature selection algorithms.},
  archive      = {J_ISCI},
  author       = {Yong Zhang and Dun-wei Gong and Xiao-zhi Gao and Tian Tian and Xiao-yan Sun},
  doi          = {10.1016/j.ins.2019.08.040},
  journal      = {Information Sciences},
  pages        = {67-85},
  shortjournal = {Inf. Sci.},
  title        = {Binary differential evolution with self-learning for multi-objective feature selection},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive fault-tolerance control based finite-time
backstepping for hypersonic flight vehicle with full state constrains.
<em>ISCI</em>, <em>507</em>, 53–66. (<a
href="https://doi.org/10.1016/j.ins.2019.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive fuzzy fault-tolerant controller is developed for the Hypersonic Flight Vehicle (HFV) in the presence of unknown inertial and aerodynamic parameters. Based on the functional dissolution technique, the longitudinal model of hypersonic vehicle is transformed into velocity subsystem and altitude subsystem. With consideration of full state constraints, the controller is designed based on finite-time stability theory and the barrier Lyapunov functions (BLFs). To deal with the unknown faults, a new robust adaptive distributive law is proposed. In order to avoid the problem of “explosion of complexity” and obtain the finite-time convergence performance, the fuzzy fault-tolerant dynamic surface control (DSC) is designed. Finally, simulation results are provided to verify the effectiveness of the proposed control scheme. It is shown that all the signals in the closed-loop are bounded.},
  archive      = {J_ISCI},
  author       = {Xuening Tang and Ding Zhai and Xiaojian Li},
  doi          = {10.1016/j.ins.2019.08.012},
  journal      = {Information Sciences},
  pages        = {53-66},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fault-tolerance control based finite-time backstepping for hypersonic flight vehicle with full state constrains},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable neighborhood algebraic differential evolution: An
application to the linear ordering problem with cumulative costs.
<em>ISCI</em>, <em>507</em>, 37–52. (<a
href="https://doi.org/10.1016/j.ins.2019.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algebraic variants of the Differential Evolution (DE) algorithm have been recently proposed to tackle permutation-based optimization problems by means of an algebraic framework, which allows to directly encode the solutions as permutations. The algebraic DE in the permutation space can be characterized by considering different neighborhood definitions such as swapping two adjacent items, swapping any two items, shifting an item to a given position. Here we propose the Variable Neighborhood Differential Evolution for Permutations (VNDEP), which adaptively searches the three neighborhoods together based on a method of dynamic reward. We provide an extensive and systematic analysis of the theoretical tools required in VNDEP, by studying the complexity of the proposed algorithmic components and by introducing the possibility to use a scale factor parameter larger than one. Experiments have been held on a widely used benchmark suite for the Linear Ordering Problem with Cumulative Costs, where VNDEP has been compared with four known permutation-based DE schemes and with respect to the state-of-the-art results for the considered instances. The experiments clearly show that VNDEP systematically outperforms the competitor algorithms and, most impressively, 32 new best known solutions, of the 50 most challenging instances, have been obtained.},
  archive      = {J_ISCI},
  author       = {Marco Baioletti and Alfredo Milani and Valentino Santucci},
  doi          = {10.1016/j.ins.2019.08.016},
  journal      = {Information Sciences},
  pages        = {37-52},
  shortjournal = {Inf. Sci.},
  title        = {Variable neighborhood algebraic differential evolution: An application to the linear ordering problem with cumulative costs},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image encryption algorithm for synchronously updating
boolean networks based on matrix semi-tensor product theory.
<em>ISCI</em>, <em>507</em>, 16–36. (<a
href="https://doi.org/10.1016/j.ins.2019.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies chaotic image encryption technology and an application of matrix semi-tensor product theory, and a Boolean network encryption algorithm for a synchronous update process is proposed. A 2D-LASM chaotic system is used to generate a random key stream. First, a Boolean network is coded, and a Boolean matrix is generated. If necessary, the Boolean network matrix is diffused in one round so that the Boolean matrix can be saved in the form of an image. Then, three random position scramblings are used to scramble the plaintext image. Finally, using a matrix semi-tensor product technique to generate an encrypted image in a second round of diffusion, a new Boolean network can be generated by encoding the encrypted image. In secure communications, users can choose to implement an image encryption transmission or a Boolean network encryption transmission according to their own needs. Compared with other algorithms, this algorithm exhibits good security characteristics.},
  archive      = {J_ISCI},
  author       = {Wang Xingyuan and Gao Suo},
  doi          = {10.1016/j.ins.2019.08.041},
  journal      = {Information Sciences},
  pages        = {16-36},
  shortjournal = {Inf. Sci.},
  title        = {Image encryption algorithm for synchronously updating boolean networks based on matrix semi-tensor product theory},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile access and flexible search over encrypted cloud data
in heterogeneous systems. <em>ISCI</em>, <em>507</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2019.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Never before has data sharing been more convenient with the rapid popularity and wide adoption of cloud computing . However, mobile access and flexible search with security for outsourced data in heterogeneous systems are two major obstacles prior to practical deployment of cloud computing . To meet the requirements in secure mobile access and flexible search to sensitive data, this paper, for the first time, proposes a versatile primitive referred to as an identity based proxy re-encryption system with outsourced equality test (IBPRE-ET). This primitive allows a data owner in an identity based broadcast encryption system (IBBE) seamlessly to share his/her data with a data sharer in an identity based encryption system (IBE). Moreover, it supports a data sharer in an IBBE system to perform search functionality on ciphertexts related to a data sharer in an IBE system. We also formally prove that the proposed IBPRE-ET system is selective secure using a random oracle model . Meanwhile, the theoretic evaluation and experimental result demonstrate our scheme is practical in the heterogeneous system. Finally, we show an application of our IBPRE-ET to the collaborative office automation system.},
  archive      = {J_ISCI},
  author       = {Jianfei Sun and Hu Xiong and Hao Zhang and Li Peng},
  doi          = {10.1016/j.ins.2019.08.026},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Mobile access and flexible search over encrypted cloud data in heterogeneous systems},
  volume       = {507},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered adaptive dynamic programming for
discrete-time multi-player games. <em>ISCI</em>, <em>506</em>, 457–470.
(<a href="https://doi.org/10.1016/j.ins.2019.05.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For multi-player games, the event-triggered adaptive dynamic programming (ADP) method with single triggering condition cannot be used. In this paper, an event-triggered ADP method with multiple triggering conditions is developed for multi-player non-zero-sum (NZS) games. Triggering conditions are designed for each player, and the control inputs will be updated only when the relevant conditions are satisfied. Besides, the developed method is implemented by single-network structure. Therefore, the computational burden can be reduced effectively. Additionally, the stability is analyzed for event-triggered multi-player systems. Finally, two examples are employed to show the effectiveness of the developed method.},
  archive      = {J_ISCI},
  author       = {Ziyang Wang and Qinglai Wei and Derong Liu},
  doi          = {10.1016/j.ins.2019.05.071},
  journal      = {Information Sciences},
  pages        = {457-470},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered adaptive dynamic programming for discrete-time multi-player games},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel local region-based active contour model for image
segmentation using bayes theorem. <em>ISCI</em>, <em>506</em>, 443–456.
(<a href="https://doi.org/10.1016/j.ins.2019.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local region-based active contour methods have been widely used to segment images with intensity inhomogeneity . However, this process can hardly segment images well when influenced by different noise. To simultaneously strengthen the anti-noise ability and preserve the distinction in segmenting images with intensity inhomogeneity , we propose characterizing image regions using local prior region descriptors under the Bayesian criterion for image segmentation . Based on the framework of Bayes theorem , a spatial regularization of connectivity maps based on a Markov random field (MRF) is introduced as the prior probability in our model. The connectivity maps enhance noise robustness by building a relationship between a pixel and its adjacent pixels . Additionally, the conditional probability of the image intensity in each local region is assumed to satisfy a Gaussian distribution with different means and deviations. Furthermore, to decrease time costs, we use the sparse field method (SFM) and compute the means and variances of the intensities in each local region before the evolution of the contour. Extensive experiments have demonstrated that the proposed method is superior to state-of-the-art active contour methods in terms of time efficiency and noise robustness.},
  archive      = {J_ISCI},
  author       = {Li Yupeng and Cao Guo and Wang Tao and Cui Qiongjie and Wang Bisheng},
  doi          = {10.1016/j.ins.2019.08.021},
  journal      = {Information Sciences},
  pages        = {443-456},
  shortjournal = {Inf. Sci.},
  title        = {A novel local region-based active contour model for image segmentation using bayes theorem},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval-valued intuitionistic fuzzy multiple attribute
decision making based on nonlinear programming methodology and TOPSIS
method. <em>ISCI</em>, <em>506</em>, 424–442. (<a
href="https://doi.org/10.1016/j.ins.2019.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiple attribute decision making (MADM) method based on the nonlinear programming (NLP) methodology, the TOPSIS method and interval-valued intuitionistic fuzzy values (IVIFVs). The evaluating values of the alternatives with respect to attributes and the attributes’ weights are represented by IVIFVs. The NLP methodology is applied to get the optimal attributes’ weights. The proposed MADM method can overcome the drawbacks of the existing MADM methods to deal with MADM problems using IVIFVs.},
  archive      = {J_ISCI},
  author       = {Zeng Shouzhen and Chen Shyi-Ming and Fan Kang-Yun},
  doi          = {10.1016/j.ins.2019.08.027},
  journal      = {Information Sciences},
  pages        = {424-442},
  shortjournal = {Inf. Sci.},
  title        = {Interval-valued intuitionistic fuzzy multiple attribute decision making based on nonlinear programming methodology and TOPSIS method},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning based video coding optimizations: A survey.
<em>ISCI</em>, <em>506</em>, 395–423. (<a
href="https://doi.org/10.1016/j.ins.2019.07.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video data has become the largest source of data consumed globally. Due to the rapid growth of video applications and boosting demands for higher quality video services, video data volume has been increasing explosively worldwide, which has been the most severe challenge for multimedia computing, transmission and storage. Video coding by compressing videos into a much smaller size is one of the key solutions; however, its development has become saturated to some extent while the compression ratio continuously grows in the last three decades. Machine leaning algorithms, especially those employing deep learning , which are capable of discovering knowledge from unstructured massive data and providing data-driven predictions, provide new opportunities for further upgrading video coding technologies. In this article, we present a review on machine learning based video encoding optimization, aiming to provide researchers with a strong foundation and inspire future developments for data-driven video coding. Firstly, we analyze the representations and redundancies of video data. Secondly, we review the development of video coding standards and key requirements. Subsequently, we present a systemic survey on the recent advances and challenges associated with the machine learning based video coding optimizations from three key aspects, including high efficiency, low complexity and high visual quality. Their workflows, representative schemes, performances, advantages and disadvantages are analyzed in detail. Finally, the challenges and opportunities are identified, which may provide the academic and industrial communities with groundwork and potential directions for future research.},
  archive      = {J_ISCI},
  author       = {Zhang Yun and Kwong Sam and Wang Shiqi},
  doi          = {10.1016/j.ins.2019.07.096},
  journal      = {Information Sciences},
  pages        = {395-423},
  shortjournal = {Inf. Sci.},
  title        = {Machine learning based video coding optimizations: A survey},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The inverse 1-median location problem on uncertain tree
networks with tail value at risk criterion. <em>ISCI</em>, <em>506</em>,
383–394. (<a href="https://doi.org/10.1016/j.ins.2019.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an inverse 1-median location problem on a tree network, the goal is to modify the vertex weights of the underlying tree network at the minimum total cost such that a predetermined vertex becomes the 1-median. This paper investigates the case that the vertex weights and modification costs are considered as uncertain variables. We first obtain a necessary and sufficient condition for the α -1-median on uncertain trees. Based on this condition, we transform the problem into a linear programming model with deterministic constraints. Finally, we consider the proposed model with tail value at risk objective under the weighted l 1 norm and present a solution algorithm for the problem with time complexity of O ( n log n ).},
  archive      = {J_ISCI},
  author       = {Akram Soltanpour and Fahimeh Baroughi and Behrooz Alizadeh},
  doi          = {10.1016/j.ins.2019.08.018},
  journal      = {Information Sciences},
  pages        = {383-394},
  shortjournal = {Inf. Sci.},
  title        = {The inverse 1-median location problem on uncertain tree networks with tail value at risk criterion},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online collaborative filtering with local and global
consistency. <em>ISCI</em>, <em>506</em>, 366–382. (<a
href="https://doi.org/10.1016/j.ins.2019.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative Filtering (CF) is one of the most popular technologies used in online recommendation systems. Most of the existing CF studies focus on the offline algorithms, a major drawback of these algorithms is the lack of ability to use the latest user feedbacks to update the learned model in realtime, due to the high cost of the offline training procedure. In this work, we propose Logo , an online CF algorithm . Our proposed method is based on a hierarchical generative model , with which, we derive a set of local and global consistency constraints for the prediction targets, and eventually obtain the design of the learning algorithm. We conduct comprehensive experiments to evaluate the proposed algorithm, the results show that: (1) Under the online setting, our algorithm achieves notably better prediction results than the benchmark algorithms; (2) Under the offline setting, our algorithm attains comparable accurate prediction results with the best performed competitors; (3) In all the experiments, our algorithm performs tens or even hundreds of times faster than the comparison algorithms.},
  archive      = {J_ISCI},
  author       = {Xiao-Yu Huang and Bing Liang and Wubin Li},
  doi          = {10.1016/j.ins.2019.08.009},
  journal      = {Information Sciences},
  pages        = {366-382},
  shortjournal = {Inf. Sci.},
  title        = {Online collaborative filtering with local and global consistency},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new internal index based on density core for clustering
validation. <em>ISCI</em>, <em>506</em>, 346–365. (<a
href="https://doi.org/10.1016/j.ins.2019.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering validation which is applied to the evaluation of clustering results has been recognized as one of the vital issues for clustering application. Density core, a set of connected maximum local density peaks, can approximately represent the structure of a cluster without being affected by noises. Therefore, a density-core-based clustering validation index (DCVI) with minimum spanning tree (MST) is proposed to solve the problem that noises and arbitrary shapes have great influence on the performance of widely used internal validation measures. As for data sets containing arbitrarily shaped clusters with noises, DCVI can effectively obtain the optimal number of clusters. Moreover, experimental results of both synthetic and real data sets indicate that DCVI outperforms most existing measures.},
  archive      = {J_ISCI},
  author       = {Jiang Xie and Zhong-Yang Xiong and Qi-Zhu Dai and Xiao-Xia Wang and Yu-Fang Zhang},
  doi          = {10.1016/j.ins.2019.08.029},
  journal      = {Information Sciences},
  pages        = {346-365},
  shortjournal = {Inf. Sci.},
  title        = {A new internal index based on density core for clustering validation},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). PGAS: Privacy-preserving graph encryption for accurate
constrained shortest distance queries. <em>ISCI</em>, <em>506</em>,
325–345. (<a href="https://doi.org/10.1016/j.ins.2019.07.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The constrained shortest distance (CSD) query is used to determine the shortest distance between two vertices of a graph while ensuring that the total cost remains lower than a given threshold. The virtually unlimited storage and processing capabilities of cloud computing have enabled the graph owners to outsource their graph data to cloud servers. However, it may introduce privacy challenges that are difficult to address. In recent years, some relevant schemes that support the shortest distance query on the encrypted graph have been proposed. Unfortunately, some of them have unacceptable query accuracy, and some of them leak sensitive information that jeopardizes the graph privacy. In this work, we propose P rivacy-preserving G raph encryption for A ccurate constrained S hortest distance queries, called PGAS . This solution is capable of providing accurate CSD queries and ensures the privacy of the graph data. Besides, we also propose a secure integer comparison protocol and a secure minimum value protocol that realize two kinds of operations on encrypted integers. We provide theoretical security analysis to prove that PGAS achieves CQA-2 Security with less privacy leakage . In addition, the performance analysis and experimental evaluation based on real-world dataset show that PGAS achieves 100\% accuracy with acceptable efficiency.},
  archive      = {J_ISCI},
  author       = {Can Zhang and Liehuang Zhu and Chang Xu and Kashif Sharif and Chuan Zhang and Ximeng Liu},
  doi          = {10.1016/j.ins.2019.07.082},
  journal      = {Information Sciences},
  pages        = {325-345},
  shortjournal = {Inf. Sci.},
  title        = {PGAS: Privacy-preserving graph encryption for accurate constrained shortest distance queries},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PSO image thresholding on images compressed via fuzzy
transforms. <em>ISCI</em>, <em>506</em>, 308–324. (<a
href="https://doi.org/10.1016/j.ins.2019.07.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new multi-level image thresholding method in which a Chaotic Darwinian Particle Swarm Optimization algorithm is applied on images compressed by using Fuzzy Transforms. The method requires a partition of the pixels of the image under several thresholds which are obtained by maximizing a fuzzy entropy. The usage of compressed images produces benefits in terms of execution CPU times. In a pre-processing phase the best compression rate is found by comparing the grey level histograms of the source and compressed images. Comparisons with the classical Darwinian Particle Swarm Optimization multi-level image thresholding algorithm and other meta-heuristic algorithms are presented in terms of quality of the segmented image via PSNR and SSIM.},
  archive      = {J_ISCI},
  author       = {Ferdinando Di Martino and Salvatore Sessa},
  doi          = {10.1016/j.ins.2019.07.088},
  journal      = {Information Sciences},
  pages        = {308-324},
  shortjournal = {Inf. Sci.},
  title        = {PSO image thresholding on images compressed via fuzzy transforms},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiple-parameterization approach for local stabilization
of constrained takagi-sugeno fuzzy systems with nonlinear consequents.
<em>ISCI</em>, <em>506</em>, 295–307. (<a
href="https://doi.org/10.1016/j.ins.2019.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the local stabilization of constrained nonlinear systems with input saturation described by Takagi-Sugeno fuzzy models with nonlinear consequents. To reduce the design conservativeness , we propose a new delayed multiple-parameterization control approach based on a nonquadratic Lyapunov function with multiple delayed fuzzy summations . Both input saturation and state constraints are explicitly taken into account in the control design procedure. This multiple-parameterization condition is given in terms of linear matrix inequalities . Compared to existing results, the new approach offers a unified and concise control framework to design both non-delayed and delayed multidimensional nonlinear fuzzy controllers . Numerical examples are provided to demonstrate the effectiveness of the proposed multiple-parameterization approach in both reducing the design conservativeness and enlarging the estimation of the domain of attraction.},
  archive      = {J_ISCI},
  author       = {Pedro H.S. Coutinho and Rodrigo F. Araújo and Anh-Tu Nguyen and Reinaldo M. Palhares},
  doi          = {10.1016/j.ins.2019.08.008},
  journal      = {Information Sciences},
  pages        = {295-307},
  shortjournal = {Inf. Sci.},
  title        = {A multiple-parameterization approach for local stabilization of constrained takagi-sugeno fuzzy systems with nonlinear consequents},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shot type constraints in UAV cinematography for autonomous
target tracking. <em>ISCI</em>, <em>506</em>, 273–294. (<a
href="https://doi.org/10.1016/j.ins.2019.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past years, camera-equipped Unmanned Aerial Vehicles (UAVs) have revolutionized aerial cinematography, allowing easy acquisition of impressive footage. In this context, autonomous functionalities based on machine learning and computer vision modules are gaining ground. During live coverage of outdoor events, an autonomous UAV may visually track and follow a specific target of interest, under a specific desired shot type, mainly adjusted by choosing appropriate focal length and UAV/camera trajectory relative to the target. However, the selected UAV/camera trajectory and the object tracker requirements (which impose limits on the maximum allowable focal length) affect the range of feasible shot types, thus constraining cinematography planning. Therefore, this paper explores the interplay between cinematography and computer vision in the area of autonomous UAV filming. UAV target-tracking trajectories are formalized and geometrically modeled, so as to analytically compute maximum allowable focal length per scenario, to avoid 2D visual tracker failure. Based on this constraint, formulas for estimating the appropriate focal length to achieve the desired shot type in each situation are extracted, so as to determine shot feasibility. Such rules can be embedded into practical UAV intelligent shooting systems, in order to enhance their robustness by facilitating on-the-fly adjustment of the cinematography plan.},
  archive      = {J_ISCI},
  author       = {Iason Karakostas and Ioannis Mademlis and Nikos Nikolaidis and Ioannis Pitas},
  doi          = {10.1016/j.ins.2019.08.011},
  journal      = {Information Sciences},
  pages        = {273-294},
  shortjournal = {Inf. Sci.},
  title        = {Shot type constraints in UAV cinematography for autonomous target tracking},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Argumentation based reinforcement learning for
meta-knowledge extraction. <em>ISCI</em>, <em>506</em>, 258–272. (<a
href="https://doi.org/10.1016/j.ins.2019.07.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge integration in distributed data mining has received widespread attention that aims to integrate inconsistent information locating on distributed sites. Traditional integration methods become ineffective since they are unable to generate global knowledge, support advanced integration strategy, or make prediction without individual classifiers . In this paper, we propose an argumentation based reinforcement learning method to handle this problem. Inspired by meta-learning, we integrate distributed knowledge and extract meta-knowledge that is agreed-upon knowledge consistent to all the agents. Specifically, two learning stages are introduced: argumentation based learning stage integrates and extracts meta-knowledge, and reinforcement learning stage evaluates and refines meta-knowledge. The two learning stages run alternately to extract global meta-knowledge base, which can be used to make prediction directly. The results from extensive experiments demonstrate that our method can extract refined meta-knowledge with a much satisfied performance.},
  archive      = {J_ISCI},
  author       = {Junyi Xu and Li Yao and Le Li and Ming Ji and Guoming Tang},
  doi          = {10.1016/j.ins.2019.07.094},
  journal      = {Information Sciences},
  pages        = {258-272},
  shortjournal = {Inf. Sci.},
  title        = {Argumentation based reinforcement learning for meta-knowledge extraction},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic multi-client searchable symmetric encryption with
support for boolean queries. <em>ISCI</em>, <em>506</em>, 234–257. (<a
href="https://doi.org/10.1016/j.ins.2019.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of cloud computing , an increasing amount of data is being outsourced to cloud servers, in the meantime, how to search data securely and efficiently has got an unprecedented concern. Searchable symmetric encryption (SSE) that enables keyword-based searches over encrypted data provides an efficient way to this problem. However, the majority of existing SSE schemes focus on single keyword searches in the single-client setting, which limits their wide application in cloud computing . In this paper, we propose a Dynamic Multi-client SSE (DMSSE) scheme with support for boolean queries, by incorporating a client’s authorization information into search tokens and indexes. Our scheme allows a data owner to authorize multiple clients to perform boolean queries over an encrypted database , and limits a client’s search ability to legitimate keywords. Compared with existing MSSE schemes, our DMSSE scheme has the following merits: 1) Non-interactivity . After the grant of search permission, the clients can perform queries on their own without the help of the data owner. 2) Dynamic . The data owner can efficiently update a client’s search permission without affecting other clients. Experimental evaluations conducted on a real data set demonstrate that our DMSSE scheme is practical for use in a large-scale encrypted database.},
  archive      = {J_ISCI},
  author       = {Leilei Du and Kenli Li and Qin Liu and Zhiqiang Wu and Shaobo Zhang},
  doi          = {10.1016/j.ins.2019.08.014},
  journal      = {Information Sciences},
  pages        = {234-257},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multi-client searchable symmetric encryption with support for boolean queries},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-aware link prediction based on strengthened projection
in bipartite networks. <em>ISCI</em>, <em>506</em>, 217–233. (<a
href="https://doi.org/10.1016/j.ins.2019.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional projection models in the bipartite networks involve many node pairs that consist of weak relationships. These node pairs lead to poor quality predictions as well as high computation time. In this paper, to cope with these problems, we firstly propose a novel projection model, which is called “Strengthened Projection Model”. Then, to predict the potential links in the future, we present a new link prediction approach based on the proposed projection model. Thanks to the proposed model, the computation time is shortened, and the high probability predictions are extracted. The majority of the previous works conducted in this area have used the classical proximity measure algorithms that only take into account the current network structure, regardless of when events occur in the network evolution. To overcome these limited methods, in this paper, we also propose a novel proximity measure algorithm that considers the bipartite network evolution. To the best of our knowledge, this is the first attempt that takes into account the time-awareness in bipartite networks. To evaluate the performance of our proposed approach, we conducted experiments on the academic information network. To construct this bipartite network, we collected data from IEEE Xplore. The experimental results show that the success of the proposed method is promising.},
  archive      = {J_ISCI},
  author       = {Serpil Aslan and Buket Kaya},
  doi          = {10.1016/j.ins.2019.08.025},
  journal      = {Information Sciences},
  pages        = {217-233},
  shortjournal = {Inf. Sci.},
  title        = {Time-aware link prediction based on strengthened projection in bipartite networks},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extending general compact querieable representations to GIS
applications. <em>ISCI</em>, <em>506</em>, 196–216. (<a
href="https://doi.org/10.1016/j.ins.2019.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The raster model is commonly used for the representation of images in many domains, and is especially useful in Geographic Information Systems (GIS) to store information about continuous variables of the space (elevation, temperature, etc.). Current representations of raster data are usually designed for external memory or, when stored in main memory, lack efficient query capabilities. In this paper we propose compact representations to efficiently store and query raster datasets in main memory. We present different representations for binary raster data, general raster data and time-evolving raster data. We experimentally compare our proposals with traditional storage mechanisms such as linear quadtrees or compressed GeoTIFF files. Results show that our structures are up to 10 times smaller than classical linear quadtrees , and even comparable in space to non-querieable representations of raster data, while efficiently answering a number of typical queries.},
  archive      = {J_ISCI},
  author       = {Nieves R. Brisaboa and Ana Cerdeira-Pena and Guillermo de Bernardo and Gonzalo Navarro and Óscar Pedreira},
  doi          = {10.1016/j.ins.2019.08.007},
  journal      = {Information Sciences},
  pages        = {196-216},
  shortjournal = {Inf. Sci.},
  title        = {Extending general compact querieable representations to GIS applications},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Individual-dependent feasibility rule for constrained
differential evolution. <em>ISCI</em>, <em>506</em>, 174–195. (<a
href="https://doi.org/10.1016/j.ins.2019.07.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from its efficiency and quick convergence, the feasibility rule (FR) is well-known for its ability to solve constrained optimization problems (COPs). However, it is highly criticized for its heavy preference for constraints. Thus, an individual-dependent feasibility rule (IDFR) was designed by alleviating the preference from two aspects. Some information of constraints, which might be nonsignificant, is depressed. By contrast, some promising information of objective function is leveraged. The extent of information is individual-dependent. To further enhance the diversity, a two-phase diversity strategy was developed. Due to their numerous merits, two differential evolution (DE) operators were selected as components of the search algorithm. By the above process, we proposed a constrained DE (i.e., IDFRDE). To the best of our knowledge, we made the first attempt to improve FR from the individual perspective. IDFR is more robust than FR while keeping the same computational time complexity. However, it would converge slower than FR on some easy COPs. Experiments on three widely used benchmarks show that: 1) IDFRDE outperforms or gets similar results comparing with other known algorithms; 2) IDFR is more effective than FR on complex COPs; 3) both, the search algorithm and the diversity strategy are important to IDFRDE.},
  archive      = {J_ISCI},
  author       = {Bing-Chuan Wang and Yun Feng and Han-Xiong Li},
  doi          = {10.1016/j.ins.2019.07.076},
  journal      = {Information Sciences},
  pages        = {174-195},
  shortjournal = {Inf. Sci.},
  title        = {Individual-dependent feasibility rule for constrained differential evolution},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A collective filtering based content transmission scheme in
edge of vehicles. <em>ISCI</em>, <em>506</em>, 161–173. (<a
href="https://doi.org/10.1016/j.ins.2019.07.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of the ever-increasing vehicular applications and booming Internet services, the requirements of low-latency and high efficient transmission among vehicles become urgent to meet, and their corresponding solutions need to be well investigated. To resolve the above challenges, we propose a fog computing-based content transmission scheme with collective filtering in edge of vehicles. We first provide a system model based on fog-based rode side units by considering location-awareness, content-caching and decentralized computing. Then, a content-caching strategy in RSUs is designed to minimize the downloading latency. Specifically, we model the moving vehicles with the two-dimensional Markov chains , and calculate the probabilities of file caching in RSUs to minimize the latency in file downloading. Each vehicle can also maintain a neighbor list to record the encounters with high similarities, and update it based on the historic and real-time contacts. Finally, we carry on the experiments based on the real-world taxi trajectories in Beijing and Shanghai, China. Simulation results demonstrate the effectiveness of our proposed method.},
  archive      = {J_ISCI},
  author       = {Xiaojie Wang and Yufan Feng and Zhaolong Ning and Xiping Hu and Xiangjie Kong and Bin Hu and Yi Guo},
  doi          = {10.1016/j.ins.2019.07.083},
  journal      = {Information Sciences},
  pages        = {161-173},
  shortjournal = {Inf. Sci.},
  title        = {A collective filtering based content transmission scheme in edge of vehicles},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event-triggered adaptive neural network controller for
uncertain nonlinear system. <em>ISCI</em>, <em>506</em>, 148–160. (<a
href="https://doi.org/10.1016/j.ins.2019.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an event-triggered adaptive controller , consisting of a basic adaptive neural network controller and an event-triggered mechanism, is developed for a class of single-input and single-output high-order nonlinear systems with neural network approximation . Both the static and the dynamic event-triggered mechanisms are proposed in our design, without the input-state stability (ISS) assumption which is needed in most existing results. It is shown that the proposed methods can ensure that the closed loop system is globally stable. The minimal inter-event time internal is lower bounded by a positive number so that no Zeno behavior occurs. Finally, the numerical simulations are presented to illustrate our theory.},
  archive      = {J_ISCI},
  author       = {Hui Gao and Yongduan Song and Changyun Wen},
  doi          = {10.1016/j.ins.2019.08.015},
  journal      = {Information Sciences},
  pages        = {148-160},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered adaptive neural network controller for uncertain nonlinear system},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network traffic forecasting model based on long-term
intuitionistic fuzzy time series. <em>ISCI</em>, <em>506</em>, 131–147.
(<a href="https://doi.org/10.1016/j.ins.2019.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a network traffic forecasting model based on long-term intuitionistic fuzzy time series (LT-IFTS) is proposed. It describes the fuzziness and uncertainty of network flow and improves the traffic forecasting performance. The multi-input multi-output (MIMO) intuitionistic fuzzy time series forecasting model , namely, ( p − q ) IFTS is defined. An intuitionistic fuzzy time series vectors clustering algorithm based on vector variation pattern is given. The cluster centroid in the proposed model is quite different from the traditional method. As a kind of typical time series data , the network flow forecasting system is constructed particularly. Characteristic intuitionistic fuzzy is a practical method to manage the fuzziness and uncertainty of network traffic data. The network traffic data is intuitionistic fuzzified and vector quantized. The time series vectors are gathered based on the improved intuitionistic fuzzy c -means clustering and matched with centroids by coordinate translation. Compared with other traditional forecasting models, the improved FCM clustering algorithm increases discrimination of time series segments. In addition, the long-term scheme improves forecasting efficiency and reduces computational complexity than other single-output models. In experiments, the proposed model and relevant models are implemented on four different scales network traffic dataset from MAWI. The experiment result indicates that the proposed model is with better generalization performance .},
  archive      = {J_ISCI},
  author       = {Fan Xiaoshi and Wang Yanan and Zhang Mengyu},
  doi          = {10.1016/j.ins.2019.08.023},
  journal      = {Information Sciences},
  pages        = {131-147},
  shortjournal = {Inf. Sci.},
  title        = {Network traffic forecasting model based on long-term intuitionistic fuzzy time series},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Containment of rumor spread in complex social networks.
<em>ISCI</em>, <em>506</em>, 113–130. (<a
href="https://doi.org/10.1016/j.ins.2019.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors can propagate at great speed through social networks and produce significant damages. In order to control rumor propagation, spreading correct information to counterbalance the effect of the rumor seems more appropriate than simply blocking rumors by censorship or network disruption. In this paper, a competitive diffusion model , namely Linear Threshold model with One Direction state Transition (LT1DT), is proposed for modeling competitive information propagation of two different types in the same network. The problem of minimizing rumor spread in social networks is explored and a novel heuristic based on diffusion dynamics is proposed to solve this problem under the LT1DT. Experimental analysis on four different networks shows that the novel heuristic outperforms pagerank centrality. By seeding correct information in the proximity of rumor seeds, the novel heuristic performs as well as the greedy approach in scale-free and small-world networks but runs three orders of magnitude faster than the greedy approach .},
  archive      = {J_ISCI},
  author       = {Lan Yang and Zhiwu Li and Alessandro Giua},
  doi          = {10.1016/j.ins.2019.07.055},
  journal      = {Information Sciences},
  pages        = {113-130},
  shortjournal = {Inf. Sci.},
  title        = {Containment of rumor spread in complex social networks},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bidirectional approximate reasoning-based approach for
decision support. <em>ISCI</em>, <em>506</em>, 99–112. (<a
href="https://doi.org/10.1016/j.ins.2019.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rule-based systems are widely applied for real-world decision support, such as policy formation, public health analysis, medical diagnosis, and risk assessment. However, they face significant challenges when the application problem at hand suffers from the “curse of dimensionality” or “sparse knowledge base” . Combination of hierarchical fuzzy rule models and fuzzy rule interpolation offers a potentially efficient and effective approach to dealing with both of these issues simultaneously. In particular, backward fuzzy rule interpolation (B-FRI) facilitates approximate reasoning to be performed given a sparse rule base where rules do not fully cover all observations or the observations are not complete, missing antecedent values in certain available rules. This paper presents a hierarchical bidirectional fuzzy reasoning mechanism by integrating hierarchical rule structures and forward/backward rule interpolation. A computational method is proposed, building on the resulting hierarchical bidirectional fuzzy interpolation to maintain consistency in sparse fuzzy rule bases. The proposed techniques are utilised to address a range of decision support problems, successfully demonstrating their efficacy.},
  archive      = {J_ISCI},
  author       = {Shangzhu Jin and Jun Peng and Zuojin Li and Qiang Shen},
  doi          = {10.1016/j.ins.2019.08.019},
  journal      = {Information Sciences},
  pages        = {99-112},
  shortjournal = {Inf. Sci.},
  title        = {Bidirectional approximate reasoning-based approach for decision support},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting similarities of user friendship networks across
social networks for user identification. <em>ISCI</em>, <em>506</em>,
78–98. (<a href="https://doi.org/10.1016/j.ins.2019.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User identification has been attracting considerable attention from academia. Due to the uniqueness and difficulty of faking friendship networks, some friendship-based methods have been presented to improve the identification performance. However, the information redundancies in k -hop ( k &gt;  1) neighbors and their contributions to user identification have not been fully analyzed in the existing work. Addressing these two issues helps to understand the problem of friendship-based user identification and to propose more effective solutions. In this paper, we first obtain ground-truth friendship networks across three popular social sites; then, we analyze the similarities of k -hop neighbors to fully characterize the information redundancies in the friendship network. We apply these information redundancies in several classifiers to study their contributions to user identification. Furthermore, we apply the friendship-based information redundancies jointly with the display-name-based information redundancies to perform user identification. The experiments show that (1) the similarities related to the 1-hop neighbors contribute to user identification much more than do the other similarities; (2) the information redundancies in the k -hop ( k &gt;  1) neighbors are also very useful for user identification; and (3) jointly applying display-name-based information redundancies can provide better performance and improve the universality of the identification method.},
  archive      = {J_ISCI},
  author       = {Yongjun Li and Zhaoting Su and Jiaqi Yang and Congjie Gao},
  doi          = {10.1016/j.ins.2019.08.022},
  journal      = {Information Sciences},
  pages        = {78-98},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting similarities of user friendship networks across social networks for user identification},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed optimization for a class of uncertain MIMO
nonlinear multi-agent systems with arbitrary relative degree.
<em>ISCI</em>, <em>506</em>, 58–77. (<a
href="https://doi.org/10.1016/j.ins.2019.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is concerned with the distributed optimization problem (DOP) for a class of uncertain multi-input-multi-output (MIMO) nonlinear multi-agent systems with arbitrary relative degree. The target is to design distributed control laws such that the outputs of the agent systems converge to a consensus value and on which the sum of the local cost functions is minimized. By introducing pseudo gradient technique, internal model technique and adaptive control technique, a novel state based distributed control law is firstly constructed. An incremental type Lyapunov function based approach is presented to show that the proposed DOP is solved by the state based control law without requiring the eigenvalue information of Laplacian matrix . By further introducing distributed high-gain observer technique, an output based distributed control law is constructed and by which the DOP is solved under some mild assumption. The proposed control laws are validated on a group of Euler-Lagrange systems, a group of robot manipulators with flexible joints and a group of Chua circuit systems. The simulation results illustrate the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Ranran Li and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2019.08.010},
  journal      = {Information Sciences},
  pages        = {58-77},
  shortjournal = {Inf. Sci.},
  title        = {Distributed optimization for a class of uncertain MIMO nonlinear multi-agent systems with arbitrary relative degree},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A theoretical result of sparse signal recovery via
alternating projection method. <em>ISCI</em>, <em>506</em>, 51–57. (<a
href="https://doi.org/10.1016/j.ins.2019.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing is a technique that can sample compressible signals below the traditional rate. One of fundamental problems in compressive sensing is the sparse signal recovery. Recently, alternating projection method was proposed for this kind of recovery. Two sufficient conditions for the recovery guarantee of the method were also given. In this paper, we establish another sufficient condition for the recovery guarantee of alternating projection method in terms of the restricted isometry constants and singular values of the measurement matrix , it is a useful improvement on one of the existing two conditions. The famous Weyl inequality, Cauchy interlace theorem and partition skills of involved matrices are utilized. The requirement for the measurement matrix is lowered. Thus, this improvement allows more measurement matrices to be used for alternating projection method. This can enhance the applicability of the method.},
  archive      = {J_ISCI},
  author       = {Liu Haifeng and Peng Jigen and Lin Zhipeng},
  doi          = {10.1016/j.ins.2019.08.001},
  journal      = {Information Sciences},
  pages        = {51-57},
  shortjournal = {Inf. Sci.},
  title        = {A theoretical result of sparse signal recovery via alternating projection method},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure properties of collaboration network with tunable
clustering. <em>ISCI</em>, <em>506</em>, 37–50. (<a
href="https://doi.org/10.1016/j.ins.2019.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A collaboration network model with improved triad formation (ITF) step is proposed and denominated as one-mode collaboration network with tunable clustering. We systematically study its structural features and find this network model can much more accurately reflect cooperative relationship in real society. We acquire expression of nodes degree distribution P ( k ) that possesses a power-law form with exponent γ whose range is (1,3]. Expression of clustering coefficient C ( k ) for nodes with degree k is also obtained and composes of a power-law section and a constant section. We verify clustering coefficient of individual nodes increases monotonically with the increase of parameter p that is the probability of ITF step occurring. When specific forms of P ( k ) and C ( k ) are given, the model’s average clustering coefficient C can be derived approximately. Finally, we analytically testify average path length L ( N ) increases with network size N in accordance with logarithmic form . When N is fixed, average path length of entire network decreases with the increase of p . All theoretically predicted results are consistent with simulative experimental results.},
  archive      = {J_ISCI},
  author       = {Long Wang and Guofeng Li and Yinghong Ma and Lu Yang},
  doi          = {10.1016/j.ins.2019.08.002},
  journal      = {Information Sciences},
  pages        = {37-50},
  shortjournal = {Inf. Sci.},
  title        = {Structure properties of collaboration network with tunable clustering},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-resolution face recognition with pose variations via
multilayer locality-constrained structural orthogonal procrustes
regression. <em>ISCI</em>, <em>506</em>, 19–36. (<a
href="https://doi.org/10.1016/j.ins.2019.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real video surveillance scenes, the extracted face regions generally have low-resolution (LR) and are sensitive to pose and illumination variations ; these flaws undoubtedly degrade the subsequent recognition task. To overcome these challenges, we propose an approach named multilayer locality-constrained structural orthogonal Procrustes regression (MLCSOPR). The proposed MLCSOPR not only learns the pose-robust discriminative representation features to reduce the resolution gap between the LR image space and the high-resolution (HR) one but also strengthens the consistency between the LR and HR image space. In particular, several contributions are made in this paper: (i) Inspired by the orthogonal Procrustes problem (OPP), a matrix approximation is exploited to find an optimal correction between two data matrices. (ii) The nuclear norm constraint is applied to the reconstruction error to maintain the structural property. (iii) Based on the abovementioned learned resolution-robust representation features, a linear regression-based classification strategy is adopted to recognize the LR input face images. Experiments on commonly used face databases have shown the effectiveness of the proposed method on cross-resolution face matching with pose variations.},
  archive      = {J_ISCI},
  author       = {Gao Guangwei and Yu Yi and Yang Meng and Chang Heyou and Huang Pu and Yue Dong},
  doi          = {10.1016/j.ins.2019.08.004},
  journal      = {Information Sciences},
  pages        = {19-36},
  shortjournal = {Inf. Sci.},
  title        = {Cross-resolution face recognition with pose variations via multilayer locality-constrained structural orthogonal procrustes regression},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GVFOM: A novel external force for active contour based image
segmentation. <em>ISCI</em>, <em>506</em>, 1–18. (<a
href="https://doi.org/10.1016/j.ins.2019.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The GVF snake is effective on converging into concave areas and being insensitive to initialization. However, it fails to converge to areas with deep and narrow concavities or preserve weak edges. In this paper, a novel external force called gradient vector flow over manifold (GVFOM) is proposed for active contours. The proposed model takes the GVF vector as a 2D manifold embedded into a 4D Euclidean space, leading to the generalization of the Laplacian operator in Euclidean Space to that over manifold, and the two components of the external force are couples with each other to improve the properties of the GVF snake. The GVFOM snake has been tested with different kinds of images, and experimental results and comparison manifest that the GVFOM snake has better performance than the GVF and other state-of-the-art snakes on object separation, deep and narrow concavity convergence, weak edge protection, noise robustness while keeping some desirable properties of the GVF model such as initialization insensitivity and large capture range.},
  archive      = {J_ISCI},
  author       = {Ziyang Zhang and Chenrui Duan and Tao Lin and Shoujun Zhou and Yuanquan Wang and Xuedong Gao},
  doi          = {10.1016/j.ins.2019.08.003},
  journal      = {Information Sciences},
  pages        = {1-18},
  shortjournal = {Inf. Sci.},
  title        = {GVFOM: A novel external force for active contour based image segmentation},
  volume       = {506},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
