<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ARTMED_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="artmed---165">ARTMED - 165</h2>
<ul>
<li><details>
<summary>
(2020). Sleep stage classification for child patients using
DeConvolutional neural network. <em>ARTMED</em>, <em>110</em>, 101981.
(<a href="https://doi.org/10.1016/j.artmed.2020.101981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies from the literature show that the prevalence of sleep disorder in children is far higher than that in adults. Although much research effort has been made on sleep stage classification for adults, children have significantly different characteristics of sleep stages. Therefore, there is an urgent need for sleep stage classification targeting children in particular. Our method focuses on two issues: The first is timestamp-based segmentation (TSS) to deal with the fine-grained annotation of sleep stage labels for each timestamp. Compared to this, popular sliding window approaches unnecessarily aggregate such labels into coarse-grained ones. We utilize DeConvolutional Neural Network (DCNN) that inversely maps features of a hidden layer back to the input space to predict the sleep stage label at each timestamp. Thus, our DCNN can yield better classification performances by considering labels at numerous timestamps. The second issue is the necessity of multiple channels. Different clinical signs, symptoms or other auxiliary examinations could be represented by different Polysomnography (PSG) recordings, so all of them should be analyzed comprehensively. We therefor exploit multivariate time-series of PSG recordings, including 6 electroencephalograms (EEGs) channels, 2 electrooculograms (EOGs) channels (left and right), 1 electromyogram (chin EMG) channel and two leg electromyogram channels. Our DCNN-based method is tested on our SDCP dataset collected from child patients aged from 5 to 10 years old. The results show that our method yields the overall classification accuracy of 84.27% and macro F1-score of 72.51% which are higher than those of existing sliding window-based methods. One of the biggest advantages of our DCNN-based method is that it processes raw PSG recordings and internally extracts features useful for accurate sleep stage classification. We examine whether this is applicable for sleep data of adult patients by testing our method on a well-known public dataset Sleep-EDFX. Our method achieves the average overall accuracy of 90.89% which is comparable to those of state-of-the-art methods without using any hand-crafted features. This result indicates the great potential of our method because it can be generally used for timestamp-level classification on multivariate time-series in various medical fields. Additionally, we provide source codes so that researchers can reproduce the results in this paper and extend our method.},
  archive      = {J_ARTMED},
  author       = {Xinyu Huang and Kimiaki Shirahama and Frédéric Li and Marcin Grzegorzek},
  doi          = {10.1016/j.artmed.2020.101981},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101981},
  shortjournal = {Artif. Intell. Med.},
  title        = {Sleep stage classification for child patients using DeConvolutional neural network},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic multi-agent approach for medical-image
segmentation: Application to tumor segmentation in brain MR images.
<em>ARTMED</em>, <em>110</em>, 101980. (<a
href="https://doi.org/10.1016/j.artmed.2020.101980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to functional or anatomical modalities, medical imaging provides a visual representation of complex structures or activities in the human body. One of the most common processing methods applied to those images is segmentation, in which an image is divided into a set of regions of interest. Human anatomical complexity and medical image acquisition artifacts make segmentation of medical images very complex. Thus, several solutions have been proposed to automate image segmentation. However, most existing solutions use prior knowledge and/or require strong interaction with the user. In this paper, we propose a multi-agent approach for the segmentation of 3D medical images. This approach is based on a set of autonomous, interactive agents that use a modified region growing algorithm and cooperate to segment a 3D image. The first organization of agents allows region seed placement and region growing. In a second organization, agent interaction and collaboration allow segmentation refinement by merging the over-segmented regions. Experiments are conducted on magnetic resonance images of healthy and pathological brains. The obtained results are promising and demonstrate the efficiency of our method.},
  archive      = {J_ARTMED},
  author       = {Mohamed T. Bennai and Zahia Guessoum and Smaine Mazouzi and Stéphane Cormier and Mohamed Mezghiche},
  doi          = {10.1016/j.artmed.2020.101980},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101980},
  shortjournal = {Artif. Intell. Med.},
  title        = {A stochastic multi-agent approach for medical-image segmentation: Application to tumor segmentation in brain MR images},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of breast cancer distant recurrence using natural
language processing and knowledge-guided convolutional neural network.
<em>ARTMED</em>, <em>110</em>, 101977. (<a
href="https://doi.org/10.1016/j.artmed.2020.101977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distant recurrence of breast cancer results in high lifetime risks and low 5-year survival rates. Early prediction of distant recurrent breast cancer could facilitate intervention and improve patients’ life quality. In this study, we designed an EHR-based predictive model to estimate the distant recurrent probability of breast cancer patients. We studied the pathology reports and progress notes of 6,447 patients who were diagnosed with breast cancer at Northwestern Memorial Hospital between 2001 and 2015. Clinical notes were mapped to Concept unified identifiers (CUI) using natural language processing tools. Bag-of-words and pre-trained embedding were employed to vectorize words and CUI sequences. These features integrated with clinical features from structured data were downstreamed to conventional machine learning classifiers and Knowledge-guided Convolutional Neural Network (K-CNN). The best configuration of our model yielded an AUC of 0.888 and an F1-score of 0.5. Our work provides an automated method to predict breast cancer distant recurrence using natural language processing and deep learning approaches. We expect that through advanced feature engineering, better predictive performance could be achieved.},
  archive      = {J_ARTMED},
  author       = {Hanyin Wang and Yikuan Li and Seema A Khan and Yuan Luo},
  doi          = {10.1016/j.artmed.2020.101977},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101977},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prediction of breast cancer distant recurrence using natural language processing and knowledge-guided convolutional neural network},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Autoencoded DNA methylation data to predict breast cancer
recurrence: Machine learning models and gene-weight significance.
<em>ARTMED</em>, <em>110</em>, 101976. (<a
href="https://doi.org/10.1016/j.artmed.2020.101976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most frequent cancer in women and the second most frequent overall after lung cancer. Although the 5-year survival rate of breast cancer is relatively high, recurrence is also common which often involves metastasis with its consequent threat for patients. DNA methylation-derived databases have become an interesting primary source for supervised knowledge extraction regarding breast cancer. Unfortunately, the study of DNA methylation involves the processing of hundreds of thousands of features for every patient. DNA methylation is featured by High Dimension Low Sample Size which has shown well-known issues regarding feature selection and generation. Autoencoders (AEs) appear as a specific technique for conducting nonlinear feature fusion. Our main objective in this work is to design a procedure to summarize DNA methylation by taking advantage of AEs. Our proposal is able to generate new features from the values of CpG sites of patients with and without recurrence. Then, a limited set of relevant genes to characterize breast cancer recurrence is proposed by the application of survival analysis and a pondered ranking of genes according to the distribution of their CpG sites. To test our proposal we have selected a dataset from The Cancer Genome Atlas data portal and an AE with a single-hidden layer. The literature and enrichment analysis (based on genomic context and functional annotation) conducted regarding the genes obtained with our experiment confirmed that all of these genes were related to breast cancer recurrence.},
  archive      = {J_ARTMED},
  author       = {Laura Macías-García and María Martínez-Ballesteros and José María Luna-Romera and José M. García-Heredia and Jorge García-Gutiérrez and José C. Riquelme-Santos},
  doi          = {10.1016/j.artmed.2020.101976},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101976},
  shortjournal = {Artif. Intell. Med.},
  title        = {Autoencoded DNA methylation data to predict breast cancer recurrence: Machine learning models and gene-weight significance},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neural collaborative filtering for unsupervised mitral valve
segmentation in echocardiography. <em>ARTMED</em>, <em>110</em>, 101975.
(<a href="https://doi.org/10.1016/j.artmed.2020.101975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of the mitral valve annulus and leaflets specifies a crucial first step to establish a machine learning pipeline that can support physicians in performing multiple tasks, e.g. diagnosis of mitral valve diseases, surgical planning, and intraoperative procedures. Current methods for mitral valve segmentation on 2D echocardiography videos require extensive interaction with annotators and perform poorly on low-quality and noisy videos. We propose an automated and unsupervised method for the mitral valve segmentation based on a low dimensional embedding of the echocardiography videos using neural network collaborative filtering. The method is evaluated in a collection of echocardiography videos of patients with a variety of mitral valve diseases, and additionally on an independent test cohort. It outperforms state-of-the-art unsupervised and supervised methods on low-quality videos or in the case of sparse annotation.},
  archive      = {J_ARTMED},
  author       = {Luca Corinzia and Fabian Laumer and Alessandro Candreva and Maurizio Taramasso and Francesco Maisano and Joachim M. Buhmann},
  doi          = {10.1016/j.artmed.2020.101975},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101975},
  shortjournal = {Artif. Intell. Med.},
  title        = {Neural collaborative filtering for unsupervised mitral valve segmentation in echocardiography},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supervised classification of bradykinesia in parkinson’s
disease from smartphone videos. <em>ARTMED</em>, <em>110</em>, 101966.
(<a href="https://doi.org/10.1016/j.artmed.2020.101966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Slowness of movement, known as bradykinesia , is the core clinical sign of Parkinson&#39;s and fundamental to its diagnosis. Clinicians commonly assess bradykinesia by making a visual judgement of the patient tapping finger and thumb together repetitively. However, inter-rater agreement of expert assessments has been shown to be only moderate, at best. We propose a low-cost, contactless system using smartphone videos to automatically determine the presence of bradykinesia . We collected 70 videos of finger-tap assessments in a clinical setting (40 Parkinson&#39;s hands, 30 control hands). Two clinical experts in Parkinson&#39;s, blinded to the diagnosis, evaluated the videos to give a grade of bradykinesia severity between 0 and 4 using the Unified Pakinson&#39;s Disease Rating Scale (UPDRS). We developed a computer vision approach that identifies regions related to hand motion and extracts clinically-relevant features. Dimensionality reduction was undertaken using principal component analysis before input to classification models (Naïve Bayes, Logistic Regression , Support Vector Machine) to predict no/slight bradykinesia (UPDRS = 0–1) or mild/moderate/severe bradykinesia (UPDRS = 2–4), and presence or absence of Parkinson&#39;s diagnosis. A Support Vector Machine with radial basis function kernels predicted presence of mild/moderate/severe bradykinesia with an estimated test accuracy of 0.8. A Naïve Bayes model predicted the presence of Parkinson&#39;s disease with estimated test accuracy 0.67. The method described here presents an approach for predicting bradykinesia from videos of finger-tapping tests. The method is robust to lighting conditions and camera positioning. On a set of pilot data, accuracy of bradykinesia prediction is comparable to that recorded by blinded human experts.},
  archive      = {J_ARTMED},
  author       = {Stefan Williams and Samuel D. Relton and Hui Fang and Jane Alty and Rami Qahwaji and Christopher D. Graham and David C. Wong},
  doi          = {10.1016/j.artmed.2020.101966},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101966},
  shortjournal = {Artif. Intell. Med.},
  title        = {Supervised classification of bradykinesia in parkinson’s disease from smartphone videos},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The automation of bias in medical artificial intelligence
(AI): Decoding the past to create a better future. <em>ARTMED</em>,
<em>110</em>, 101965. (<a
href="https://doi.org/10.1016/j.artmed.2020.101965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medicine is at a disciplinary crossroads. With the rapid integration of Artificial Intelligence (AI) into the healthcare field the future care of our patients will depend on the decisions we make now. Demographic healthcare inequalities continue to persist worldwide and the impact of medical biases on different patient groups is still being uncovered by the research community. At a time when clinical AI systems are scaled up in response to the Covid19 pandemic, the role of AI in exacerbating health disparities must be critically reviewed. For AI to account for the past and build a better future, we must first unpack the present and create a new baseline on which to develop these tools. The means by which we move forwards will determine whether we project existing inequity into the future, or whether we reflect on what we hold to be true and challenge ourselves to be better. AI is an opportunity and a mirror for all disciplines to improve their impact on society and for medicine the stakes could not be higher.},
  archive      = {J_ARTMED},
  author       = {Isabel Straw},
  doi          = {10.1016/j.artmed.2020.101965},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101965},
  shortjournal = {Artif. Intell. Med.},
  title        = {The automation of bias in medical artificial intelligence (AI): Decoding the past to create a better future},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting defibrillation success in out-of-hospital cardiac
arrested patients: Moving beyond feature design. <em>ARTMED</em>,
<em>110</em>, 101963. (<a
href="https://doi.org/10.1016/j.artmed.2020.101963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing timing of defibrillation by evaluating the likelihood of a successful outcome could significantly enhance resuscitation. Previous studies employed conventional machine learning approaches and hand-crafted features to address this issue, but none have achieved superior performance to be widely accepted. This study proposes a novel approach in which predictive features are automatically learned. A raw 4s VF episode immediately prior to first defibrillation shock was feed to a 3-stage CNN feature extractor. Each stage was composed of 4 components: convolution, rectified linear unit activation, dropout and max-pooling. At the end of feature extractor, the feature map was flattened and connected to a fully connected multi-layer perceptron for classification. For model evaluation, a 10 fold cross-validation was employed. To balance classes, SMOTE oversampling method has been applied to minority class. The obtained results show that the proposed model is highly accurate in predicting defibrillation outcome (Acc = 93.6 %). Since recommendations on classifiers suggest at least 50 % specificity and 95 % sensitivity as safe and useful predictors for defibrillation decision, the reported sensitivity of 98.8 % and specificity of 88.2 %, with the analysis speed of 3 ms/input signal, indicate that the proposed model possesses a good prospective to be implemented in automated external defibrillators . The learned features demonstrate superiority over hand-crafted ones when performed on the same dataset. This approach benefits from being fully automatic by fusing feature extraction, selection and classification into a single learning model. It provides a superior strategy that can be used as a tool to guide treatment of OHCA patients in bringing optimal decision of precedence treatment. Furthermore, for encouraging replicability, the dataset has been made publicly available to the research community.},
  archive      = {J_ARTMED},
  author       = {Marija D. Ivanović and Julius Hannink and Matthias Ring and Fabio Baronio and Vladan Vukčević and Ljupco Hadžievski and Bjoern Eskofier},
  doi          = {10.1016/j.artmed.2020.101963},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101963},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting defibrillation success in out-of-hospital cardiac arrested patients: Moving beyond feature design},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning with attention supervision for automated
motion artefact detection in quality control of cardiac t1-mapping.
<em>ARTMED</em>, <em>110</em>, 101955. (<a
href="https://doi.org/10.1016/j.artmed.2020.101955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiac magnetic resonance quantitative T1-mapping is increasingly used for advanced myocardial tissue characterisation. However, cardiac or respiratory motion can significantly affect the diagnostic utility of T1-maps, and thus motion artefact detection is critical for quality control and clinically-robust T1 measurements. Manual quality control of T1-maps may provide reassurance, but is laborious and prone to error. We present a deep learning approach with attention supervision for automated motion artefact detection in quality control of cardiac T1-mapping. Firstly, we customised a multi-stream Convolutional Neural Network (CNN) image classifier to streamline the process of automatic motion artefact detection. Secondly, we imposed attention supervision to guide the CNN to focus on targeted myocardial segments. Thirdly, when there was disagreement between the human operator and machine, a second human validator reviewed and rescored the cases for adjudication and to identify the source of disagreement. The multi-stream neural networks demonstrated 89.8% agreement, 87.4% ROC-AUC on motion artefact detection with the human operator in the 2568 T1 maps. Trained with additional supervision on attention, agreements and AUC significantly improved to 91.5% and 89.1%, respectively (p &lt; 0.001). Rescoring of disagreed cases by the second human validator revealed that human operator error was the primary cause of disagreement. Deep learning with attention supervision provides a quick and high-quality assurance of clinical images, and outperforms human operators.},
  archive      = {J_ARTMED},
  author       = {Qiang Zhang and Evan Hann and Konrad Werys and Cody Wu and Iulia Popescu and Elena Lukaschuk and Ahmet Barutcu and Vanessa M. Ferreira and Stefan K. Piechnik},
  doi          = {10.1016/j.artmed.2020.101955},
  journal      = {Artificial Intelligence in Medicine},
  month        = {11},
  pages        = {101955},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning with attention supervision for automated motion artefact detection in quality control of cardiac t1-mapping},
  volume       = {110},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reinforcement learning for intelligent healthcare
applications: A survey. <em>ARTMED</em>, <em>109</em>, 101964. (<a
href="https://doi.org/10.1016/j.artmed.2020.101964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering new treatments and personalizing existing ones is one of the major goals of modern clinical research. In the last decade, Artificial Intelligence (AI) has enabled the realization of advanced intelligent systems able to learn about clinical treatments and discover new medical knowledge from the huge amount of data collected. Reinforcement Learning (RL), which is a branch of Machine Learning (ML), has received significant attention in the medical community since it has the potentiality to support the development of personalized treatments in accordance with the more general precision medicine vision. This report presents a review of the role of RL in healthcare by investigating past work, and highlighting any limitations and possible future contributions.},
  archive      = {J_ARTMED},
  author       = {Antonio Coronato and Muddasar Naeem and Giuseppe De Pietro and Giovanni Paragliola},
  doi          = {10.1016/j.artmed.2020.101964},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101964},
  shortjournal = {Artif. Intell. Med.},
  title        = {Reinforcement learning for intelligent healthcare applications: A survey},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommendations for enhancing the usability and
understandability of process mining in healthcare. <em>ARTMED</em>,
<em>109</em>, 101962. (<a
href="https://doi.org/10.1016/j.artmed.2020.101962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare organizations are confronted with challenges including the contention between tightening budgets and increased care needs. In the light of these challenges, they are becoming increasingly aware of the need to improve their processes to ensure quality of care for patients. To identify process improvement opportunities, a thorough process analysis is required, which can be based on real-life process execution data captured by health information systems. Process mining is a research field that focuses on the development of techniques to extract process-related insights from process execution data, providing valuable and previously unknown information to instigate evidence-based process improvement in healthcare. However, despite the potential of process mining, its uptake in healthcare organizations outside case studies in a research context is rather limited. This observation was the starting point for an international brainstorm seminar. Based on the seminar&#39;s outcomes and with the ambition to stimulate a more widespread use of process mining in healthcare, this paper formulates recommendations to enhance the usability and understandability of process mining in healthcare. These recommendations are mainly targeted towards process mining researchers and the community to consider when developing a new research agenda for process mining in healthcare. Moreover, a limited number of recommendations are directed towards healthcare organizations and health information systems vendors, when shaping an environment to enable the continuous use of process mining.},
  archive      = {J_ARTMED},
  author       = {Niels Martin and Jochen De Weerdt and Carlos Fernández-Llatas and Avigdor Gal and Roberto Gatta and Gema Ibáñez and Owen Johnson and Felix Mannhardt and Luis Marco-Ruiz and Steven Mertens and Jorge Munoz-Gama and Fernando Seoane and Jan Vanthienen and Moe Thandar Wynn and David Baltar Boilève and Jochen Bergs and Mieke Joosten-Melis and Stijn Schretlen and Bart Van Acker},
  doi          = {10.1016/j.artmed.2020.101962},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101962},
  shortjournal = {Artif. Intell. Med.},
  title        = {Recommendations for enhancing the usability and understandability of process mining in healthcare},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble neural network approach detecting pain intensity
from facial expressions. <em>ARTMED</em>, <em>109</em>, 101954. (<a
href="https://doi.org/10.1016/j.artmed.2020.101954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reports on research to design an ensemble deep learning framework that integrates fine-tuned, three-stream hybrid deep neural network ( i.e ., Ensemble Deep Learning Model, EDLM), employing Convolutional Neural Network (CNN) to extract facial image features, detect and accurately classify the pain. To develop the approach, the VGGFace is fine-tuned and integrated with Principal Component Analysis and employed to extract features in images from the Multimodal Intensity Pain database at the early phase of the model fusion. Subsequently, a late fusion, three layers hybrid CNN and recurrent neural network algorithm is developed with their outputs merged to produce image-classified features to classify pain levels. The EDLM model is then benchmarked by means of a single-stream deep learning model including several competing models based on deep learning methods. The results obtained indicate that the proposed framework is able to outperform the competing methods, applied in a multi-level pain detection database to produce a feature classification accuracy that exceeds 89 %, with a receiver operating characteristic of 93 %. To evaluate the generalization of the proposed EDLM model, the UNBC-McMaster Shoulder Pain dataset is used as a test dataset for all of the modelling experiments, which reveals the efficacy of the proposed method for pain classification from facial images. The study concludes that the proposed EDLM model can accurately classify pain and generate multi-class pain levels for potential applications in the medical informatics area, and should therefore, be explored further in expert systems for detecting and classifying the pain intensity of patients, and automatically evaluating the patients’ pain level accurately.},
  archive      = {J_ARTMED},
  author       = {Ghazal Bargshady and Xujuan Zhou and Ravinesh C. Deo and Jeffrey Soar and Frank Whittaker and Hua Wang},
  doi          = {10.1016/j.artmed.2020.101954},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101954},
  shortjournal = {Artif. Intell. Med.},
  title        = {Ensemble neural network approach detecting pain intensity from facial expressions},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skeletal scintigraphy image enhancement based neutrosophic
sets and salp swarm algorithm. <em>ARTMED</em>, <em>109</em>, 101953.
(<a href="https://doi.org/10.1016/j.artmed.2020.101953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several schemes are proposed for enhancing the dark regions of the skeletal scintigraphy image. Nevertheless, most of them are flawed by some performance problems. This paper presents an adaptive scheme based on Salp Swarm algorithm (SSA) and a neutrosophic set (NS) under multi-criteria to enhance the dark regions of the skeletal scintigraphy image efficiently. Enhancing the dark regions is first converted into an optimization problem. The SSA algorithm is used to find the best improvement for each image separately, and then the neutrosophic algorithm is used to find similarity score to each image with adaptive weight coefficients obtained by the SSA algorithm. The proposed algorithm is applied to an Egyptian medical dataset collected from Menoufia University Hospital and it is a no-reference image. The experiments are done using 3 different resolutions 512*512, 256*256, and 128*128 and compared with Gamma Correction, the NS algorithm and the local enhance algorithm. The results demonstrate that the proposed algorithm achieves superior performance in almost criteria fitness function, entropy, eumber of edges, nNaturalness image quality Evaluator, sharpness, sharpness index, and contrast-distorted images using contrast enhancement. The results showed the idea of integration between the falsity membership of the neutrosophic set and the Salp swarm algorithm can be used to Skeletal Scintigraphy enhancement. This paper proved that it can depend on falsity membership of the neutrosophic set in the Image Enhancement field.},
  archive      = {J_ARTMED},
  author       = {Mohammed M. Nasef and Fatma T. Eid and Amr M. Sauber},
  doi          = {10.1016/j.artmed.2020.101953},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101953},
  shortjournal = {Artif. Intell. Med.},
  title        = {Skeletal scintigraphy image enhancement based neutrosophic sets and salp swarm algorithm},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grouping attributes zero-shot learning for tongue
constitution recognition. <em>ARTMED</em>, <em>109</em>, 101951. (<a
href="https://doi.org/10.1016/j.artmed.2020.101951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Chinese Medicine (TCM) considers that the personal constitution determines the occurrence trend and therapeutic effects of certain diseases, which can be recognized by machine learning through tongue images. However, current machine learning methods are confronted with two challenges. First, there are not some larger tongue image databases available. Second, they do not use the domain knowledge of TCM, so that the imbalance of constitution categories cannot be solved. Therefore, this paper proposes a new constitution recognition method based on the zero-shot learning with the knowledge of TCM. To further improve the performance, a new zero-shot learning method is proposed by grouping attributes and learning discriminant latent features, which can better solve the imbalance problem of constitution categories. Experimental results on our constructed databases validate the proposed methods.},
  archive      = {J_ARTMED},
  author       = {Guihua Wen and Jiajiong Ma and Yang Hu and Huihui Li and Lijun Jiang},
  doi          = {10.1016/j.artmed.2020.101951},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101951},
  shortjournal = {Artif. Intell. Med.},
  title        = {Grouping attributes zero-shot learning for tongue constitution recognition},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploiting complex medical data with interpretable deep
learning for adverse drug event prediction. <em>ARTMED</em>,
<em>109</em>, 101942. (<a
href="https://doi.org/10.1016/j.artmed.2020.101942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A variety of deep learning architectures have been developed for the goal of predictive modelling and knowledge extraction from medical records. Several models have placed strong emphasis on temporal attention mechanisms and decay factors as a means to include highly temporally relevant information regarding the recency of medical event occurrence while facilitating medical code-level interpretability. In this study we utilise such models with a large Electronic Patient Record (EPR) data set consisting of diagnoses, medication, and clinical text data for the purpose of adverse drug event (ADE) prediction. The first contribution of this work is an empirical evaluation of two state-of-the-art medical-code based models in terms of objective performance metrics for ADE prediction on diagnosis and medication data. Secondly, as an extension of previous work, we augment an interpretable deep learning architecture to permit numerical risk and clinical text features and demonstrate how this approach yields improved predictive performance compared to the other baselines. Finally, we assess the importance of attention mechanisms in regards to their usefulness for medical code-level and text-level interpretability, which may facilitate novel insights pertaining to the nature of ADE occurrence within the health care domain.},
  archive      = {J_ARTMED},
  author       = {Jonathan Rebane and Isak Samsten and Panagiotis Papapetrou},
  doi          = {10.1016/j.artmed.2020.101942},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101942},
  shortjournal = {Artif. Intell. Med.},
  title        = {Exploiting complex medical data with interpretable deep learning for adverse drug event prediction},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GANs for medical image analysis. <em>ARTMED</em>,
<em>109</em>, 101938. (<a
href="https://doi.org/10.1016/j.artmed.2020.101938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) and their extensions have carved open many exciting ways to tackle well known and challenging medical image analysis problems such as medical image de-noising, reconstruction, segmentation, data simulation, detection or classification. Furthermore, their ability to synthesize images at unprecedented levels of realism also gives hope that the chronic scarcity of labeled data in the medical field can be resolved with the help of these generative models. In this review paper, a broad overview of recent literature on GANs for medical applications is given, the shortcomings and opportunities of the proposed methods are thoroughly discussed, and potential future work is elaborated. We review the most relevant papers published until the submission date. For quick access, essential details such as the underlying method, datasets, and performance are tabulated. An interactive visualization that categorizes all papers to keep the review alive is available at http://livingreview.in.tum.de/GANs_for_Medical_Applications/ .},
  archive      = {J_ARTMED},
  author       = {Salome Kazeminia and Christoph Baur and Arjan Kuijper and Bram van Ginneken and Nassir Navab and Shadi Albarqouni and Anirban Mukhopadhyay},
  doi          = {10.1016/j.artmed.2020.101938},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101938},
  shortjournal = {Artif. Intell. Med.},
  title        = {GANs for medical image analysis},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic prediction engine to prevent chemotherapy-induced
nausea and vomiting. <em>ARTMED</em>, <em>109</em>, 101925. (<a
href="https://doi.org/10.1016/j.artmed.2020.101925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer remains the second major cause of death in the United States over the last decade. Chemotherapy is a core component of nearly every cancer treatment plan. Chemotherapy-Induced Nausea and Vomiting (CINV) are the two most dreadful and unpleasant side-effects of chemotherapy for cancer patients. Several patient-specific factors affect the risk of CINV. However, none of the guidelines consider those factors. Not all of the patients have the similar emetic risk of CINV. Despite the improvements in CINV management, as many as two-thirds of chemotherapy patients still experience some degree of CINV. As a result, physicians use their personal experiences for CINV treatment, which leads to inconsistent managements of CINV. The overall objective of this study is to improve the prevention of CINV using precise, personalized and evidence-based antiemetic treatment before chemotherapy. In CINV prediction, one of the interesting factors is that CINV has two distinct and complex pathophysiologic phases: acute and delayed. In addition, the risk factors and their associations are different for different emetogenic chemotherapies (e.g., low, moderate, and high). There are six contexts considering the combination of phases and emetogenicity levels. This will require the creation of six different models. Instead, our objective was to describe a single framework named “prediction engine” that can perform prediction query without losing the sensitivity to each context. The prediction engine discovers how the patient-related variables and the emetogenecity of chemotherapy are associated with the risk of CINV for each phase. This was a single-center retrospective study. The data were collected by retrospective record review from the electronic medical record system used at the University of Missouri Ellis Fischel Cancer Center. An association rule-based dynamic and context-sensitive Prediction Engine has been developed. Physicians receive feedback about CINV risks of patients from the CINV decision support system based on patient-specific factors. The prediction performance of the system outperformed many popular prediction methods and all the results of CINV risk prediction published in the literature. Best prediction performance was achieved using the rule-ranking approach. The accuracy, sensitivity, and specificity were 87.85 %, 87.54 %, and 88.2 %, respectively. The system used the patient-specific risk factors for making personalized treatment recommendations for CINV. It solved a real clinical problem that will shorten the gap between clinical practices and evidence-based guidelines for CINV management leading to the practice of personalized and precise treatment recommendation, better life quality of patient, and reduced healthcare cost. The approach presented in this article can be applied to any other clinical predictions.},
  archive      = {J_ARTMED},
  author       = {Abu Saleh Mohammad Mosa and Akm Mosharraf Hossain and Illhoi Yoo},
  doi          = {10.1016/j.artmed.2020.101925},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101925},
  shortjournal = {Artif. Intell. Med.},
  title        = {A dynamic prediction engine to prevent chemotherapy-induced nausea and vomiting},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Corrigendum to “a neutrosophic-entropy based adaptive
thresholding segmentation algorithm: A special application in MR images
of parkinson’s disease” [artif intell med 104 (2020) 101838].
<em>ARTMED</em>, <em>109</em>, 101902. (<a
href="https://doi.org/10.1016/j.artmed.2020.101902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.artmed.2020.101902},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101902},
  shortjournal = {Artif. Intell. Med.},
  title        = {Corrigendum to “A neutrosophic-entropy based adaptive thresholding segmentation algorithm: A special application in MR images of parkinson’s disease” [Artif intell med 104 (2020) 101838]},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extracting deep features from short ECG signals for early
atrial fibrillation detection. <em>ARTMED</em>, <em>109</em>, 101896.
(<a href="https://doi.org/10.1016/j.artmed.2020.101896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atrial Fibrillation (AF) at an early stage has a short duration and is sometimes asymptomatic, making it difficult to detect. Although the use of mobile sensing devices has provided the possibility of real-time cardiac detection, it is highly susceptible to the noise signals generated by body movement. Therefore, it is of great importance to study early AF detection for mobile terminals with noise immunity. Extracting effective features is critical to AF detection, but most existing studies used shallow time, frequency or time-frequency energy (TFE) features with weak representation that need to rely on long ECG signals to capture the variation in information and cannot sensitively capture the subtle variation caused by early AF. In addition, most studies only considered the discrimination of AF from normal sinus rhythm (SR) signals, ignoring the interference of noise and other signals. This study proposes three new deep features that can accurately capture the subtle variation in short ECG segments caused by early AF, examines the interference of noise and other signals generated by the mobile terminal and proposes a new feature set for early AF detection. We use six popular classifiers to evaluate the relative effectiveness of the deep features we developed against the features extracted by two conventional time-frequency methods, and the performance of the proposed feature set for detecting early AF. Our study shows that the best results for classifying AF and SR are obtained by Random Forest (RF), with 0.96 F1 score. The best results for classifying four types of signal are obtained by Extreme Gradient Boosting (XGBoost), with overall F1 score 0.88 and the individual F1 score for classifying SR, AF, Other and Noisy with 0.91, 0.90, 0.73, and 0.96, respectively.},
  archive      = {J_ARTMED},
  author       = {Xiaodan Wu and Yumeng Zheng and Chao-Hsien Chu and Zhen He},
  doi          = {10.1016/j.artmed.2020.101896},
  journal      = {Artificial Intelligence in Medicine},
  month        = {9},
  pages        = {101896},
  shortjournal = {Artif. Intell. Med.},
  title        = {Extracting deep features from short ECG signals for early atrial fibrillation detection},
  volume       = {109},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The natural language explanation algorithms for the lung
cancer computer-aided diagnosis system. <em>ARTMED</em>, <em>108</em>,
101952. (<a href="https://doi.org/10.1016/j.artmed.2020.101952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two algorithms for explaining decisions of a lung cancer computer-aided diagnosis system are proposed. Their main peculiarity is that they produce explanations of diseases in the form of special sentences via natural language. The algorithms consist of two parts. The first part is a standard local post-hoc explanation model, for example, the well-known LIME, which is used for selecting important features from a special feature representation of the segmented lung suspicious objects. This part is identical for both algorithms. The second part is a model which aims to connect selected important features and to transform them to explanation sentences in natural language. This part is implemented differently for both algorithms. The training phase of the first algorithm uses a special vocabulary of simple phrases which produce sentences and their embeddings. The second algorithm significantly simplifies some parts of the first algorithm and reduces the explanation problem to a set of simple classifiers. The basic idea behind the improvement is to represent every simple phrase from vocabulary as a class of the “sparse” histograms. An implementation of the second algorithm is shown in detail.},
  archive      = {J_ARTMED},
  author       = {Anna Meldo and Lev Utkin and Maxim Kovalev and Ernest Kasimov},
  doi          = {10.1016/j.artmed.2020.101952},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101952},
  shortjournal = {Artif. Intell. Med.},
  title        = {The natural language explanation algorithms for the lung cancer computer-aided diagnosis system},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A supervised machine learning-based methodology for
analyzing dysregulation in splicing machinery: An application in cancer
diagnosis. <em>ARTMED</em>, <em>108</em>, 101950. (<a
href="https://doi.org/10.1016/j.artmed.2020.101950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deregulated splicing machinery components have shown to be associated with the development of several types of cancer and, therefore, the determination of such alterations can help the development of tumor-specific molecular targets for early prognosis and therapy. Determining such splicing components, however, is not a straightforward task mainly due to the heterogeneity of tumors, the variability across samples, and the fat-short characteristic of genomic datasets. In this work, a supervised machine learning-based methodology is proposed, allowing the determination of subsets of relevant splicing components that best discriminate samples. The methodology comprises three main phases: first, a ranking of features is determined by means of applying feature weighting algorithms that compute the importance of each splicing component; second, the best subset of features that allows the induction of an accurate classifier is determined by means of conducting an effective heuristic search; then the confidence over the induced classifier is assessed by means of explaining the individual predictions and its global behavior. At the end, an extensive experimental study was conducted on a large collection of transcript-based datasets, illustrating the utility and benefit of the proposed methodology for analyzing dysregulation in splicing machinery.},
  archive      = {J_ARTMED},
  author       = {Oscar Reyes and Eduardo Pérez and Raúl M. Luque and Justo Castaño and Sebastián Ventura},
  doi          = {10.1016/j.artmed.2020.101950},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101950},
  shortjournal = {Artif. Intell. Med.},
  title        = {A supervised machine learning-based methodology for analyzing dysregulation in splicing machinery: An application in cancer diagnosis},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EBM+: Advancing evidence-based medicine via two level
automatic identification of populations, interventions, outcomes in
medical literature. <em>ARTMED</em>, <em>108</em>, 101949. (<a
href="https://doi.org/10.1016/j.artmed.2020.101949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidence-Based Medicine (EBM) has been an important practice for medical practitioners. However, as the number of medical publications increases dramatically, it is becoming extremely difficult for medical experts to review all the contents available and make an informative treatment plan for their patients. A variety of frameworks, including the PICO framework which is named after its elements (Population, Intervention, Comparison, Outcome), have been developed to enable fine-grained searches, as the first step to faster decision making. In this work, we propose a novel entity recognition system that identifies PICO entities within medical publications and achieves state-of-the-art performance in the task. This is achieved by the combination of four 2D Convolutional Neural Networks (CNNs) for character feature extraction, and a Highway Residual connection to facilitate deep Neural Network architectures. We further introduce a PICO Statement classifier, that identifies sentences that not only contain all PICO entities but also answer questions stated in PICO. To facilitate this task we also introduce a high quality dataset, manually annotated by medical practitioners. With the combination of our proposed PICO Entity Recognizer and PICO Statement classifier we aim to advance EBM and enable its faster and more accurate practice.},
  archive      = {J_ARTMED},
  author       = {Nikolaos Stylianou and Gerasimos Razis and Dimitrios G. Goulis and Ioannis Vlahavas},
  doi          = {10.1016/j.artmed.2020.101949},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101949},
  shortjournal = {Artif. Intell. Med.},
  title        = {EBM+: Advancing evidence-based medicine via two level automatic identification of populations, interventions, outcomes in medical literature},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). G-forest: An ensemble method for cost-sensitive feature
selection in gene expression microarrays. <em>ARTMED</em>, <em>108</em>,
101941. (<a href="https://doi.org/10.1016/j.artmed.2020.101941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarray gene expression profiling has emerged as an efficient technique for cancer diagnosis, prognosis, and treatment. One of the major drawbacks of gene expression microarrays is the “curse of dimensionality”, which hinders the usefulness of information in datasets and leads to computational instability. In recent years, feature selection techniques have emerged as effective tools to identify disease biomarkers to aid in medical screening and diagnosis. However, the existing feature selection techniques, first, do not suit the rare variance exists in genomic data; and second, do not consider the feature cost (i.e. gene cost). Because ignoring features’ costs may result in high cost gene profiling, this study proposes a new algorithm, called G-Forest, for cost-sensitive feature selection in gene expression microarrays. G-Forest is an ensemble cost-sensitive feature selection algorithm that develops a population of biases for a Random Forest induction algorithm. The G-Forest embeds the feature cost in the feature selection process and allows for simultaneous selection of low-cost and most informative features. In particular, when constructing the initial population, the feature is randomly selected with a probability inversely proportional to its associated cost. The G-Forest was compared with multiple state-of-the-art algorithms. Experimental results showed the effectiveness and robustness of the G-Forest in selecting the least cost and most informative genes. The G-Forest improved accuracy up to 14 % and decreased costs up to 56 % - on average - when compared with the other approaches tested in this article.},
  archive      = {J_ARTMED},
  author       = {Mai Abdulla and Mohammad T. Khasawneh},
  doi          = {10.1016/j.artmed.2020.101941},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101941},
  shortjournal = {Artif. Intell. Med.},
  title        = {G-forest: An ensemble method for cost-sensitive feature selection in gene expression microarrays},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identification of alzheimer’s disease based on wavelet
transformation energy feature of the structural MRI image and NN
classifier. <em>ARTMED</em>, <em>108</em>, 101940. (<a
href="https://doi.org/10.1016/j.artmed.2020.101940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is now difficult to be identified for clinicians, especially, at its prodromal stage, mild cognitive impairment (MCI), because of no obvious clinical symptom and few impacts on daily life at this phase. In addition, energy distribution differences of brain atrophies reflected in structural magnetic resonance imaging (sMRI) images between MCI patients and older healthy controls (HC) are minimal and subtle, which are difficult to be captured by the spatial analysis. In this study, we propose a novel method (namely AD-WTEF) to identify AD and MCI patients from HC subjects by extracting the wavelet transformation energy feature (WTEF) of the sMRI image. AD-WTEF firstly transforms each scan of the preprocessed sMRI image by wavelet to obtain its directional subbands with the same size at different transformation levels. And then, based on the anatomical automatic labeling (AAL) atlas, AD-WTEF constructs a new brain mask to segment the subbands at the same direction and transformation level into different energy regions of interest (EROIs). Thirdly, by averaging coefficients in an EROI, AD-WTEF gets an energy feature, following that energy features of different EROIs are connected to form an energy feature vector for describing the subbands at the same direction and transformation level. As a result, these energy feature vectors are further concatenated to be a WTEF of the sMRI image. Finally, the nearest neighbor (NN) classifier is selected and used for AD identification. Compared with other seven state-of-the-art methods, our AD-WTEF can effectively identify AD patients using the subtle energy distribution differences of sMRI images. Furthermore, experimental results indicate that our AD-WTEF can also find important brain ROIs related to AD.},
  archive      = {J_ARTMED},
  author       = {Jinwang Feng and Shao-Wu Zhang and Luonan Chen and Alzheimer&#39;s Disease Neuroimaging Initiative (ADNI)},
  doi          = {10.1016/j.artmed.2020.101940},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101940},
  shortjournal = {Artif. Intell. Med.},
  title        = {Identification of alzheimer&#39;s disease based on wavelet transformation energy feature of the structural MRI image and NN classifier},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automated ICD-10 code assignment of nonstandard diagnoses
via a two-stage framework. <em>ARTMED</em>, <em>108</em>, 101939. (<a
href="https://doi.org/10.1016/j.artmed.2020.101939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An electronic medical record (EMR) is a rich source of clinical information for medical studies. Each physician usually has his or her own way to describe a patient&#39;s diagnosis. This results in many different ways to describe the same disease, which produces a large number of informal nonstandard diagnoses in EMRs. The Tenth Revision of International Classification of Diseases (ICD-10) is a medical classification list of codes for diagnoses. Automated ICD-10 code assignment of the nonstandard diagnosis is an important way to improve the quality of the medical study. However, manual coding is expensive, time-consuming and inefficient. Moreover, terminology in the standard diagnostic library comprises approximately 23,000 subcategory (6-digit) codes. Classifying the entire set of subcategory codes is extremely challenging. ICD-10 codes in the standard diagnostic library are organized hierarchically, and each category code (3-digit) relates to several or dozens of subcategory (6-digit) codes. Based on the hierarchical structure of the ICD-10 code, we propose a two-stage ICD-10 code assignment framework, which examines the entire category codes (approximately 1900) and searches the subcategory codes under the specific category code. Furthermore, since medical coding datasets are plagued with a training data sparsity issue, we introduce more supervised information to overcome this issue. Compared with the method that searches within approximately 23,000 subcategory codes, our approach requires examination of a considerably reduced number of codes. Extensive experiments show that our framework can improve the performance of the automated code assignment.},
  archive      = {J_ARTMED},
  author       = {Chengjie Mou and Jiangtao Ren},
  doi          = {10.1016/j.artmed.2020.101939},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101939},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated ICD-10 code assignment of nonstandard diagnoses via a two-stage framework},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coarse-to-fine classification for diabetic retinopathy
grading using convolutional neural network. <em>ARTMED</em>,
<em>108</em>, 101936. (<a
href="https://doi.org/10.1016/j.artmed.2020.101936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the most common eye complication of diabetes and one of the leading causes of blindness and vision impairment. Automated and accurate DR grading is of great significance for the timely and effective treatment of fundus diseases. Current clinical methods remain subject to potential time-consumption and high-risk. In this paper, a hierarchically Coarse-to-fine network (CF-DRNet) is proposed as an automatic clinical tool to classify five stages of DR severity grades using convolutional neural networks (CNNs). The CF-DRNet conforms to the hierarchical characteristic of DR grading and effectively improves the classification performance of five-class DR grading, which consists of the following: (1) The Coarse Network performs two-class classification including No DR and DR, where the attention gate module highlights the salient lesion features and suppresses irrelevant background information. (2) The Fine Network is proposed to classify four stages of DR severity grades of the grade DR from the Coarse Network including mild, moderate, severe non-proliferative DR (NPDR) and proliferative DR (PDR). Experimental results show that proposed CF-DRNet outperforms some state-of-art methods in the publicly available IDRiD and Kaggle fundus image datasets. These results indicate our method enables an efficient and reliable DR grading diagnosis in clinic.},
  archive      = {J_ARTMED},
  author       = {Zhan Wu and Gonglei Shi and Yang Chen and Fei Shi and Xinjian Chen and Gouenou Coatrieux and Jian Yang and Limin Luo and Shuo Li},
  doi          = {10.1016/j.artmed.2020.101936},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101936},
  shortjournal = {Artif. Intell. Med.},
  title        = {Coarse-to-fine classification for diabetic retinopathy grading using convolutional neural network},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling imbalanced medical image data: A
deep-learning-based one-class classification approach. <em>ARTMED</em>,
<em>108</em>, 101935. (<a
href="https://doi.org/10.1016/j.artmed.2020.101935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical settings, a lot of medical image datasets suffer from the imbalance problem which hampers the detection of outliers (rare health care events), as most classification methods assume an equal occurrence of classes. In this way, identifying outliers in imbalanced datasets has become a crucial issue. To help address this challenge, one-class classification, which focuses on learning a model using samples from only a single given class, has attracted increasing attention. Previous one-class modeling usually uses feature mapping or feature fitting to enforce the feature learning process. However, these methods are limited for medical images which usually have complex features. In this paper, a novel method is proposed to enable deep learning models to optimally learn single-class-relevant inherent imaging features by leveraging the concept of imaging complexity. We investigate and compare the effects of simple but effective perturbing operations applied to images to capture imaging complexity and to enhance feature learning. Extensive experiments are performed on four clinical datasets to show that the proposed method outperforms four state-of-the-art methods.},
  archive      = {J_ARTMED},
  author       = {Long Gao and Lei Zhang and Chang Liu and Shandong Wu},
  doi          = {10.1016/j.artmed.2020.101935},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101935},
  shortjournal = {Artif. Intell. Med.},
  title        = {Handling imbalanced medical image data: A deep-learning-based one-class classification approach},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Canada protocol: An ethical checklist for the use of
artificial intelligence in suicide prevention and mental health.
<em>ARTMED</em>, <em>108</em>, 101934. (<a
href="https://doi.org/10.1016/j.artmed.2020.101934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Carl-Maria Mörch and Abhishek Gupta and Brian L. Mishara},
  doi          = {10.1016/j.artmed.2020.101934},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101934},
  shortjournal = {Artif. Intell. Med.},
  title        = {Canada protocol: An ethical checklist for the use of artificial intelligence in suicide prevention and mental health},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Realistic hair simulator for skin lesion images: A novel
benchemarking tool. <em>ARTMED</em>, <em>108</em>, 101933. (<a
href="https://doi.org/10.1016/j.artmed.2020.101933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated skin lesion analysis is one of the trending fields that has gained attention among the dermatologists and health care practitioners. Skin lesion restoration is an essential pre-processing step for lesion enhancements for accurate automated analysis and diagnosis by both dermatologists and computer-aided diagnosis tools. Hair occlusion is one of the most popular artifacts in dermatoscopic images. It can negatively impact the skin lesions diagnosis by both dermatologists and automated computer diagnostic tools. Digital hair removal is a non-invasive method for image enhancement for decrease the hair-occlusion artifact in previously captured images. Several hair removal methods were proposed for skin delineation and removal without standardized benchmarking techniques. Manual annotation is one of the main challenges that hinder the validation of these proposed methods on a large number of images or against benchmarking datasets for comparison purposes. In the presented work, we propose a photo-realistic hair simulator based on context-aware image synthesis using image-to-image translation techniques via conditional adversarial generative networks for generation of different hair occlusions in skin images, along with ground-truth mask for hair location. Hair-occluded image is synthesized using the latent structure of any input hair-free image by deep encoding the input image into a latent vector of features. The locations of required hair are highlighted using white pixels on the input image. Then, these deep encoded features are used to reconstruct the synthetic highly realistic hair-occluded image. Besides, we explored using three loss functions including L 1 -norm, L 2 -norm and structural similarity index (SSIM) to maximize the image synthesis visual quality. For the evaluation of the generated samples, the t-SNE feature mapping and Bland–Altman test are used as visualization tools for the experimental results. The results show the superior performance of our proposed method compared to previous methods for hair synthesis with plausible colours and preserving the integrity of the lesion texture. The proposed method can be used to generate benchmarking datasets for comparing the performance of digital hair removal methods. The code is available online at: https://github.com/attiamohammed/realhair .},
  archive      = {J_ARTMED},
  author       = {Mohamed Attia and Mohammed Hossny and Hailing Zhou and Saeid Nahavandi and Hamed Asadi and Anousha Yazdabadi},
  doi          = {10.1016/j.artmed.2020.101933},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101933},
  shortjournal = {Artif. Intell. Med.},
  title        = {Realistic hair simulator for skin lesion images: A novel benchemarking tool},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable step dynamic threshold local binary pattern for
classification of atrial fibrillation. <em>ARTMED</em>, <em>108</em>,
101932. (<a href="https://doi.org/10.1016/j.artmed.2020.101932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed new methods for feature extraction in machine learning-based classification of atrial fibrillation from ECG signal. Our proposed methods improved conventional 1-dimensional local binary pattern method in two ways. First, we proposed a dynamic threshold LBP code generation method for use with 1-dimensional signals, enabling the generated LBP codes to have a more detailed representation of the signal morphological pattern. Second, we introduced a variable step value into the LBP code generation algorithm to better cope with a high sampling frequency input signal without a downsampling process. The proposed methods do not employ computationally expensive processes such as filtering, wavelet transform , up/downsampling, or beat detection, and can be implemented using only simple addition, division, and compare operations. Combining these two approaches, our proposed variable step dynamic threshold local binary pattern method achieved 99.11% sensitivity and 99.29% specificity when used as a feature generation algorithm in support vector machine classification of atrial fibrillation from MIT-BIH Atrial Fibrillation Database dataset. When applied on signals from MIT-BIH Arrhythmia Database, our proposed method achieved similarly good 99.38% sensitivity and 98.97% specificity. Our proposed methods achieved one of the best results among published works in atrial fibrillation classification using the same dataset while using less computationally expensive calculations, without significant performance degradation when applied on signals from multiple databases with different sampling frequencies.},
  archive      = {J_ARTMED},
  author       = {Muhammad Yazid and Mahrus Abdur Rahman},
  doi          = {10.1016/j.artmed.2020.101932},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101932},
  shortjournal = {Artif. Intell. Med.},
  title        = {Variable step dynamic threshold local binary pattern for classification of atrial fibrillation},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Indoor location identification of patients for directing
virtual care: An AI approach using machine learning and knowledge-based
methods. <em>ARTMED</em>, <em>108</em>, 101931. (<a
href="https://doi.org/10.1016/j.artmed.2020.101931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a digitally enabled healthcare setting, we posit that an individual’s current location is pivotal for supporting many virtual care services—such as tailoring educational content towards an individual’s current location, and, hence, current stage in an acute care process; improving activity recognition for supporting self-management in a home-based setting; and guiding individuals with cognitive decline through daily activities in their home. However, unobtrusively estimating an individual’s indoor location in real-world care settings is still a challenging problem. Moreover, the needs of location-specific care interventions go beyond absolute coordinates and require the individual’s discrete semantic location ; i.e., it is the concrete type of an individual’s location (e.g., exam vs. waiting room; bathroom vs. kitchen) that will drive the tailoring of educational content or recognition of activities. We utilized Machine Learning methods to accurately identify an individual’s discrete location, together with knowledge-based models and tools to supply the associated semantics of identified locations. We considered clustering solutions to improve localization accuracy at the expense of granularity; and investigate sensor fusion-based heuristics to rule out false location estimates. We present an AI-driven indoor localization approach that integrates both data-driven and knowledge-based processes and artifacts. We illustrate the application of our approach in two compelling healthcare use cases, and empirically validated our localization approach at the emergency unit of a large Canadian pediatric hospital.},
  archive      = {J_ARTMED},
  author       = {William Van Woensel and Patrice C. Roy and Syed Sibte Raza Abidi and Samina Raza Abidi},
  doi          = {10.1016/j.artmed.2020.101931},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101931},
  shortjournal = {Artif. Intell. Med.},
  title        = {Indoor location identification of patients for directing virtual care: An AI approach using machine learning and knowledge-based methods},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using topological data analysis and pseudo time series to
infer temporal phenotypes from electronic health records.
<em>ARTMED</em>, <em>108</em>, 101930. (<a
href="https://doi.org/10.1016/j.artmed.2020.101930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal phenotyping enables clinicians to better understand observable characteristics of a disease as it progresses. Modelling disease progression that captures interactions between phenotypes is inherently challenging. Temporal models that capture change in disease over time can identify the key features that characterize disease subtypes that underpin these trajectories. These models will enable clinicians to identify early warning signs of progression in specific sub-types and therefore to make informed decisions tailored to individual patients. In this paper, we explore two approaches to building temporal phenotypes based on the topology of data: topological data analysis and pseudo time-series. Using type 2 diabetes data, we show that the topological data analysis approach is able to identify disease trajectories and that pseudo time-series can infer a state space model characterized by transitions between hidden states that represent distinct temporal phenotypes. Both approaches highlight lipid profiles as key factors in distinguishing the phenotypes.},
  archive      = {J_ARTMED},
  author       = {Arianna Dagliati and Nophar Geifman and Niels Peek and John H. Holmes and Lucia Sacchi and Riccardo Bellazzi and Seyed Erfan Sajjadi and Allan Tucker},
  doi          = {10.1016/j.artmed.2020.101930},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101930},
  shortjournal = {Artif. Intell. Med.},
  title        = {Using topological data analysis and pseudo time series to infer temporal phenotypes from electronic health records},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Domain expertise–agnostic feature selection for the analysis
of breast cancer data*. <em>ARTMED</em>, <em>108</em>, 101928. (<a
href="https://doi.org/10.1016/j.artmed.2020.101928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progress in proteomics has enabled biologists to accurately measure the amount of protein in a tumor. This work is based on a breast cancer data set, result of the proteomics analysis of a cohort of tumors carried out at Karolinska Institutet. While evidence suggests that an anomaly in the protein content is related to the cancerous nature of tumors, the proteins that could be markers of cancer types and subtypes and the underlying interactions are not completely known. This work sheds light on the potential of the application of unsupervised learning in the analysis of the aforementioned data sets, namely in the detection of distinctive proteins for the identification of the cancer subtypes, in the absence of domain expertise. In the analyzed data set, the number of samples, or tumors, is significantly lower than the number of features, or proteins; consequently, the input data can be thought of as high-dimensional data. The use of high-dimensional data has already become widespread, and a great deal of effort has been put into high-dimensional data analysis by means of feature selection, but it is still largely based on prior specialist knowledge, which in this case is not complete. There is a growing need for unsupervised feature selection, which raises the issue of how to generate promising subsets of features among all the possible combinations, as well as how to evaluate the quality of these subsets in the absence of specialist knowledge. We hereby propose a new wrapper method for the generation and evaluation of subsets of features via spectral clustering and modularity, respectively. We conduct experiments to test the effectiveness of the new method in the analysis of the breast cancer data, in a domain expertise–agnostic context. Furthermore, we show that we can successfully augment our method by incorporating an external source of data on known protein complexes. Our approach reveals a large number of subsets of features that are better at clustering the samples than the state-of-the-art classification in terms of modularity and shows a potential to be useful for future proteomics research.},
  archive      = {J_ARTMED},
  author       = {Susanna Pozzoli and Amira Soliman and Leila Bahri and Rui Mamede Branca and Sarunas Girdzijauskas and Marco Brambilla},
  doi          = {10.1016/j.artmed.2020.101928},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101928},
  shortjournal = {Artif. Intell. Med.},
  title        = {Domain expertise–agnostic feature selection for the analysis of breast cancer data*},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dealing with confounders and outliers in classification
medical studies: The autism spectrum disorders case study.
<em>ARTMED</em>, <em>108</em>, 101926. (<a
href="https://doi.org/10.1016/j.artmed.2020.101926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) approaches have been widely applied to medical data in order to find reliable classifiers to improve diagnosis and detect candidate biomarkers of a disease. However, as a powerful, multivariate, data-driven approach, ML can be misled by biases and outliers in the training set, finding sample-dependent classification patterns. This phenomenon often occurs in biomedical applications in which, due to the scarcity of the data, combined with their heterogeneous nature and complex acquisition process, outliers and biases are very common. In this work we present a new workflow for biomedical research based on ML approaches, that maximizes the generalizability of the classification. This workflow is based on the adoption of two data selection tools: an autoencoder to identify the outliers and the Confounding Index, to understand which characteristics of the sample can mislead classification. As a study-case we adopt the controversial research about extracting brain structural biomarkers of Autism Spectrum Disorders (ASD) from magnetic resonance images. A classifier trained on a dataset composed by 86 subjects, selected using this framework, obtained an area under the receiver operating characteristic curve of 0.79. The feature pattern identified by this classifier is still able to capture the mean differences between the ASD and Typically Developing Control classes on 1460 new subjects in the same age range of the training set, thus providing new insights on the brain characteristics of ASD. In this work, we show that the proposed workflow allows to find generalizable patterns even if the dataset is limited, while skipping the two mentioned steps and using a larger but not well designed training set would have produced a sample-dependent classifier.},
  archive      = {J_ARTMED},
  author       = {Elisa Ferrari and Paolo Bosco and Sara Calderoni and Piernicola Oliva and Letizia Palumbo and Giovanna Spera and Maria Evelina Fantacci and Alessandra Retico},
  doi          = {10.1016/j.artmed.2020.101926},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101926},
  shortjournal = {Artif. Intell. Med.},
  title        = {Dealing with confounders and outliers in classification medical studies: The autism spectrum disorders case study},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning to find colorectal polyps in colonoscopy: A
systematic literature review. <em>ARTMED</em>, <em>108</em>, 101923. (<a
href="https://doi.org/10.1016/j.artmed.2020.101923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer has a great incidence rate worldwide, but its early detection significantly increases the survival rate. Colonoscopy is the gold standard procedure for diagnosis and removal of colorectal lesions with potential to evolve into cancer and computer-aided detection systems can help gastroenterologists to increase the adenoma detection rate, one of the main indicators for colonoscopy quality and predictor for colorectal cancer prevention. The recent success of deep learning approaches in computer vision has also reached this field and has boosted the number of proposed methods for polyp detection, localization and segmentation. Through a systematic search, 35 works have been retrieved. The current systematic review provides an analysis of these methods, stating advantages and disadvantages for the different categories used; comments seven publicly available datasets of colonoscopy images; analyses the metrics used for reporting and identifies future challenges and recommendations. Convolutional neural networks are the most used architecture together with an important presence of data augmentation strategies, mainly based on image transformations and the use of patches. End-to-end methods are preferred over hybrid methods, with a rising tendency. As for detection and localization tasks, the most used metric for reporting is the recall, while Intersection over Union is highly used in segmentation. One of the major concerns is the difficulty for a fair comparison and reproducibility of methods. Even despite the organization of challenges, there is still a need for a common validation framework based on a large, annotated and publicly available database, which also includes the most convenient metrics to report results. Finally, it is also important to highlight that efforts should be focused in the future on proving the clinical value of the deep learning based methods, by increasing the adenoma detection rate.},
  archive      = {J_ARTMED},
  author       = {Luisa F. Sánchez-Peralta and Luis Bote-Curiel and Artzai Picón and Francisco M. Sánchez-Margallo and J. Blas Pagador},
  doi          = {10.1016/j.artmed.2020.101923},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101923},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning to find colorectal polyps in colonoscopy: A systematic literature review},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of an ontological reasoning to support the
guideline-based management of primary breast cancer patients in the
DESIREE project. <em>ARTMED</em>, <em>108</em>, 101922. (<a
href="https://doi.org/10.1016/j.artmed.2020.101922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The DESIREE project has developed a platform offering several complementary therapeutic decision support modules to improve the quality of care for breast cancer patients. All modules are operating consistently with a common breast cancer knowledge model (BCKM) following the generic entity-attribute-value model. The BCKM is formalized as an ontology including both the data model to represent clinical patient information and the termino-ontological model to represent the application domain concepts. This ontological model is used to describe data semantics and to allow for reasoning at different levels of abstraction. We present the guideline-based decision support module (GL-DSS). Three breast cancer clinical practice guidelines have been formalized as decision rules including evidence levels, conformance levels, and two types of dependency, “refinement” and “complement”, used to build complete care plans from the reconciliation of atomic recommendations. The system has been assessed on 138 decisions previously made without the system and re-played with the system after a washout period on simulated tumor boards (TBs) in three pilot sites. When TB clinicians changed their decision after using the GL-DSS, it was for a better decision than the decision made without the system in 75 % of the cases.},
  archive      = {J_ARTMED},
  author       = {Jacques Bouaud and Sylvia Pelayo and Jean-Baptiste Lamy and Coralie Prebet and Charlotte Ngo and Luis Teixeira and Gilles Guézennec and Brigitte Séroussi},
  doi          = {10.1016/j.artmed.2020.101922},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101922},
  shortjournal = {Artif. Intell. Med.},
  title        = {Implementation of an ontological reasoning to support the guideline-based management of primary breast cancer patients in the DESIREE project},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Continuous blood pressure measurement from one-channel
electrocardiogram signal using deep-learning techniques.
<em>ARTMED</em>, <em>108</em>, 101919. (<a
href="https://doi.org/10.1016/j.artmed.2020.101919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous blood pressure (BP) measurement is crucial for reliable and timely hypertension detection. State-of-the-art continuous BP measurement methods based on pulse transit time or multiple parameters require simultaneous electrocardiogram (ECG) and photoplethysmogram (PPG) signals. Compared with PPG signals, ECG signals are easy to collect using wearable devices. This study examined a novel continuous BP estimation approach using one-channel ECG signals for unobtrusive BP monitoring. A BP model is developed based on the fusion of a residual network and long short-term memory to obtain the spatial-temporal information of ECG signals. The public multiparameter intelligent monitoring waveform database, which contains ECG, PPG, and invasive BP data of patients in intensive care units, is used to develop and verify the model. Experimental results demonstrated that the proposed approach exhibited an estimation error of 0.07 ± 7.77 mmHg for mean arterial pressure (MAP) and 0.01 ± 6.29 for diastolic BP (DBP), which comply with the Association for the Advancement of Medical Instrumentation standard. According to the British Hypertension Society standards, the results achieved grade A for MAP and DBP estimation and grade B for systolic BP (SBP) estimation. Furthermore, we verified the model with an independent dataset for arrhythmia patients. The experimental results exhibited an estimation error of −0.22 ± 5.82 mmHg, −0.57 ± 4.39 mmHg, and −0.75 ± 5.62 mmHg for SBP, MAP, and DBP measurements, respectively. These results indicate the feasibility of estimating BP by using a one-channel ECG signal, thus enabling continuous BP measurement for ubiquitous health care applications.},
  archive      = {J_ARTMED},
  author       = {Fen Miao and Bo Wen and Zhejing Hu and Giancarlo Fortino and Xi-Ping Wang and Zeng-Ding Liu and Min Tang and Ye Li},
  doi          = {10.1016/j.artmed.2020.101919},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101919},
  shortjournal = {Artif. Intell. Med.},
  title        = {Continuous blood pressure measurement from one-channel electrocardiogram signal using deep-learning techniques},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rule-based automatic diagnosis of thyroid nodules from
intraoperative frozen sections using deep learning. <em>ARTMED</em>,
<em>108</em>, 101918. (<a
href="https://doi.org/10.1016/j.artmed.2020.101918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frozen sections provide a basis for rapid intraoperative diagnosis that can guide surgery, but the diagnoses often challenge pathologists. Here we propose a rule-based system to differentiate thyroid nodules from intraoperative frozen sections using deep learning techniques. The proposed system consists of three components: (1) automatically locating tissue regions in the whole slide images (WSIs), (2) splitting located tissue regions into patches and classifying each patch into predefined categories using convolutional neural networks (CNN), and (3) integrating predictions of all patches to form the final diagnosis with a rule-based system. To be specific, we fine-tune the InceptionV3 model for thyroid patch classification by replacing the last fully connected layer with three outputs representing the patch&#39;s probabilities of being benign, uncertain, or malignant. Moreover, we design a rule-based protocol to integrate patches’ predictions to form the final diagnosis, which provides interpretability for the proposed system. On 259 testing slides, the system correctly predicts 95.3% (61/64) of benign nodules and 96.7% (148/153) of malignant nodules, and classify 16.2% (42/259) slides as uncertain, including 19 benign and 16 malignant slides, which are a sufficiently small number to be manually examined by pathologists or fully processed through permanent sections. Besides, the system allows the localization of suspicious regions along with the diagnosis. A typical whole slide image, with 80, 000 × 60, 000 pixels, can be diagnosed within 1 min, thus satisfying the time requirement for intraoperative diagnosis. To the best of our knowledge, this is the first study to apply deep learning to diagnose thyroid nodules from intraoperative frozen sections. The code is released at https://github.com/PingjunChen/ThyroidRule .},
  archive      = {J_ARTMED},
  author       = {Yuan Li and Pingjun Chen and Zhiyuan Li and Hai Su and Lin Yang and Dingrong Zhong},
  doi          = {10.1016/j.artmed.2020.101918},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101918},
  shortjournal = {Artif. Intell. Med.},
  title        = {Rule-based automatic diagnosis of thyroid nodules from intraoperative frozen sections using deep learning},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal tree representation for similarity computation
between medical patients. <em>ARTMED</em>, <em>108</em>, 101900. (<a
href="https://doi.org/10.1016/j.artmed.2020.101900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to compute similarities between patient records in an electronic health record (EHR). This is an important problem because the availability of effective methods for the computation of patient similarity would allow for assistance with and automation of tasks such as patients stratification, medical prognosis and cohort selection, and for unlocking the potential of medical analytics methods for healthcare intelligence. However, health data in EHRs presents many challenges that make the automatic computation of patient similarity difficult; these include: temporal aspects, multivariate, heterogeneous and irregular data, and data sparsity. We propose a new method for EHR data representation called Temporal Tree: a temporal hierarchical representation which, based on temporal co-occurrence, preserves the compound information found at different levels in health data. In addition, this representation is augmented using the doc2vec embedding technique which here is exploited for patient similarity computation. We empirically investigate our proposed method, along with several state-of-the-art benchmarks, on a dataset of real world Intensive Care Unit (ICU) EHRs, for the task of identifying patients with a specific target diagnosis. Our empirical results show that the Temporal Trees representation is significantly better than other traditional and state-of-the-art methods for representing patients and computing their similarities. Temporal trees capture the temporal relationships between medical, hierarchical data: this enables to effectively model the rich information provided within EHRs and thus the identification of similar patients.},
  archive      = {J_ARTMED},
  author       = {Suresh Pokharel and Guido Zuccon and Xue Li and Chandra Prasetyo Utomo and Yu Li},
  doi          = {10.1016/j.artmed.2020.101900},
  journal      = {Artificial Intelligence in Medicine},
  month        = {8},
  pages        = {101900},
  shortjournal = {Artif. Intell. Med.},
  title        = {Temporal tree representation for similarity computation between medical patients},
  volume       = {108},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generic approach for cell segmentation based on gabor
filtering and area-constrained ultimate erosion. <em>ARTMED</em>,
<em>107</em>, 101929. (<a
href="https://doi.org/10.1016/j.artmed.2020.101929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the demand for segmenting different types of cells imaged by microscopes is increased tremendously. The requirements for the segmentation accuracy are becoming stricter. Because of the great diversity of cells, no traditional methods could segment various types of cells with adequate accuracy. In this paper, we aim to propose a generic approach that is capable of segmenting various types of cells robustly and counting the total number of cells accurately. To this end, we utilize the gradients of cells instead of intensity for cell segmentation because the gradients are less affected by the global intensity variations. To improve the segmentation accuracy, we utilize the Gabor filter to increase the intensity uniformity of the gradient image. To get the optimal segmentation, we utilize the slope difference distribution based threshold selection method to segment the Gabor filtered gradient image. At last, we propose an area-constrained ultimate erosion method to separate the connected cells robustly. Twelve types of cells are used to test the proposed approach in this paper. Experimental results showed that the proposed approach is very promising in meeting the strict accuracy requirements for many applications.},
  archive      = {J_ARTMED},
  author       = {Zihao Wang and Zhenzhou Wang},
  doi          = {10.1016/j.artmed.2020.101929},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101929},
  shortjournal = {Artif. Intell. Med.},
  title        = {A generic approach for cell segmentation based on gabor filtering and area-constrained ultimate erosion},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning an expandable EMR-based medical knowledge network
to enhance clinical diagnosis. <em>ARTMED</em>, <em>107</em>, 101927.
(<a href="https://doi.org/10.1016/j.artmed.2020.101927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic medical records (EMRs) contain a wealth of knowledge that can be used to assist doctors in making clinical decisions like disease diagnosis. Constructing a medical knowledge network (MKN) to link medical concepts in EMRs is an effective way to manage this knowledge. The quality of the diagnostic result made by MKN-based clinical decision support system depends on the accuracy of medical knowledge and the completeness of the network. However, collecting knowledge is a long-lasting and cumulative process, which means it’s hard to construct a complete MKN with limited data. This study was conducted with the objective of developing an expandable EMR-based MKN to enhance capabilities in making an initial clinical diagnosis. A network of symptom-indicate-disease knowledge in 992 Chinese EMRs (CEMRs) was manually constructed as Original-MKN, and an incremental expansion framework was applied to it to obtain an expandable MKN based on new CEMRs. The framework was composed by: (1) integrating external knowledge extracted from the medical information websites and (2) mining potential knowledge with new EMRs. The framework also adopts a diagnosis-driven learning method to estimate the effectiveness of each knowledge in clinical practice. Experimental results indicate that our expanded MKN achieves a precision of 0.837 for a recall of 0.719 in clinical diagnosis, which outperforms Original-MKN and four classical machine learning methods. Furthermore, both external medical knowledge and potential medical knowledge benefit MKN expansion and disease diagnosis. The proposed incremental expansion framework sustains the MKN learning new knowledge.},
  archive      = {J_ARTMED},
  author       = {Jing Xie and Jingchi Jiang and Yehan Wang and Yi Guan and Xitong Guo},
  doi          = {10.1016/j.artmed.2020.101927},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101927},
  shortjournal = {Artif. Intell. Med.},
  title        = {Learning an expandable EMR-based medical knowledge network to enhance clinical diagnosis},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection of early stages of alzheimer’s disease based on
MEG activity with a randomized convolutional neural network.
<em>ARTMED</em>, <em>107</em>, 101924. (<a
href="https://doi.org/10.1016/j.artmed.2020.101924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early detection of Alzheimer’s disease can potentially make eventual treatments more effective. This work presents a deep learning model to detect early symptoms of Alzheimer’s disease using synchronization measures obtained with magnetoencephalography. The proposed model is a novel deep learning architecture based on an ensemble of randomized blocks formed by a sequence of 2D-convolutional, batch-normalization and pooling layers. An important challenge is to avoid overfitting, as the number of features is very high (25755) compared to the number of samples (132 patients). To address this issue the model uses an ensemble of identical sub-models all sharing weights, with a final stage that performs an average across sub-models. To facilitate the exploration of the feature space, each sub-model receives a random permutation of features. The features correspond to magnetic signals reflecting neural activity and are arranged in a matrix structure interpreted as a 2D image that is processed by 2D convolutional networks. The proposed detection model is a binary classifier (disease/non-disease), which compared to other deep learning architectures and classic machine learning classifiers, such as random forest and support vector machine, obtains the best classification performance results with an average F1-score of 0.92. To perform the comparison a strict validation procedure is proposed, and a thorough study of results is provided.},
  archive      = {J_ARTMED},
  author       = {Manuel Lopez-Martin and Angel Nevado and Belen Carro},
  doi          = {10.1016/j.artmed.2020.101924},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101924},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detection of early stages of alzheimer’s disease based on MEG activity with a randomized convolutional neural network},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting postoperative non-small cell lung cancer
prognosis via long short-term relational regularization.
<em>ARTMED</em>, <em>107</em>, 101921. (<a
href="https://doi.org/10.1016/j.artmed.2020.101921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is the leading cause of cancer death worldwide. Prognosis of lung cancer plays a crucial role in the clinical decision-making process to optimize the treatment for patients. Most of the existing data-driven prognostic prediction models explore the relations between patient’s characteristics and outcomes at a specific time interval. Although valuable, they neglect the relations between long-term and short-term prognoses and thus may limit the prediction performance. In this study, we present a novel prognostic prediction approach for postoperative NSCLC patients. Specifically, we formulate the learning objective function by exploiting the relations between long-term and short-term prognoses via a long short-term relational regularization. The regularization term is composed of two parts, i.e., the similarities between prognoses measured by patients’ outcomes and the L 2 L2 -norms between the corresponding prognoses’ weight vectors. Based on this regularization, the proposed method can extract critical risk factors that comprehensively consider the long-term and short-term prognoses to facilitate the estimation of clinical risks. We evaluate the proposed model on a clinical dataset containing 693 consecutive postoperative NSCLC patients with more than 5-year follow-up from 2006 to 2015. Our best models achieve 0.743, 0.709, and 0.746 AUCs for 1-year, 3-year, and 5-year survival prediction, 0.696, 0.724, and 0.736 AUCs for 1-year, 3-year, and 5-year recurrence prediction, respectively. The experimental results show the efficiency of our proposed model in improving the performances on 1-year prognostic prediction in comparison with benchmark models. By comparing with the model without the long short-term relational regularization, the proposed model extracts more consistent critical risk factors for both long-term and short-term prognoses and contains fewer unreasonable risk factors under the clinician’s review. We conclude that the proposed model can effectively exploit the relations between long-term and short-term prognoses. And the risk factors recognized by the proposed model have the potentials for further prognostic prediction of postoperative non-small cell lung cancer patients.},
  archive      = {J_ARTMED},
  author       = {Danqing Hu and Shaolei Li and Zhengxing Huang and Nan Wu and Xudong Lu},
  doi          = {10.1016/j.artmed.2020.101921},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101921},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting postoperative non-small cell lung cancer prognosis via long short-term relational regularization},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automated detection of dynamical change in EEG signals based
on a new rhythm measure. <em>ARTMED</em>, <em>107</em>, 101920. (<a
href="https://doi.org/10.1016/j.artmed.2020.101920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated detection of dynamical change in EEG signals has been a long-standing problem in a wide range of clinic applications. It is essential to extract an effective and accurate EEG rhythm indicator that can reflect the dynamical behavior of a given EEG signal. Time-frequency analysis is a promising method to achieve this end, but existing methods still have limitations in real implementation making this kind of methods still progressive until the present day. In this paper, along the line of ongoing research on time-frequency methods, we present a new method based on graph-based modeling. By virtue of this method, an effective and accurate EEG rhythm indicator can be extracted to characterize the dynamical EEG time series. Together with the extracted EEG rhythm indicator, an automatic analysis of continuous monitoring of EEG signal, is developed by means of a null hypothesis testing to inspect whether an EEG change occurs or not during a monitoring period. The proposed framework is applied to both simulated data and real signals respectively to validate its effectiveness. Experimental results, together with theoretical interpretation and discussions, suggest its promising potentials in practice.},
  archive      = {J_ARTMED},
  author       = {Guoliang Lu and Guangyuan Chen and Wei Shang and Zhaohong Xie},
  doi          = {10.1016/j.artmed.2020.101920},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101920},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated detection of dynamical change in EEG signals based on a new rhythm measure},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Near-optimal insulin treatment for diabetes patients: A
machine learning approach. <em>ARTMED</em>, <em>107</em>, 101917. (<a
href="https://doi.org/10.1016/j.artmed.2020.101917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood glycemic control is crucial for minimizing severe side effects in diabetes mellitus. Currently, two opposing treatment approaches exist: in formulaic methods, insulin care is calculated by parameter-based computation (i.e., correction factor, insulin-to-carb ratio, and absorption duration), which are fixed by the medical team based on the history of a tested patient blood glucose levels (BGLs). Alternatively, closed-loop methods test glycemic level via sensors and provide insulin boluses based on sensor data thus ignoring other medical information. Unlike the body, both these systems are reactive – chasing insulin dosage based on fluctuating BGL – resulting in significant fluctuations of glucose values, rather than the relatively flat profile normal to the body&#39;s glycemic control. Extended periods of these fluctuations – particularly high BGLs (hyperglycemia) result in vascular and organ epithelial damage, which increases comorbidities and is ultimately life-threatening. We propose an individualized treatment scheme based on machine learning artificial intelligence, which combines the best of both approaches and is tailored to the individual. We model patient reaction to insulin treatment as Markov decision process (MDP) thus allowing the system to find a unique, individualized and dynamically updating insulin care policy that would lead to flat blood glucose profiles in target areas. We incorporate an individualized “health reward function”, preferably from the medical team, describing a grading scheme of BGL tailored to the patient for even more precise glycemic control. The solution to MDP is found via reinforcement learning, which yields an individualized, optimal insulin care policy. This policy can prevent hypoglycemia, minimize high glucose duration and glycemic fluctuations. It can be further updated as the patient undergoes environmental changes. Significantly, our method provides the care team a constantly updated patient model, allowing them to better understand and support the patient.},
  archive      = {J_ARTMED},
  author       = {Mark Shifrin and Hava Siegelmann},
  doi          = {10.1016/j.artmed.2020.101917},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101917},
  shortjournal = {Artif. Intell. Med.},
  title        = {Near-optimal insulin treatment for diabetes patients: A machine learning approach},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning personalized ADL recognition models from few raw
data. <em>ARTMED</em>, <em>107</em>, 101916. (<a
href="https://doi.org/10.1016/j.artmed.2020.101916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of activities of daily living (ADL) is an essential component of assisted living systems based on actigraphy. This task can nowadays be performed by machine learning models which are able to automatically extract and learn relevant features but, most of time, need to be trained with large amounts of data collected on several users. In this paper, we propose an approach to learn personalized ADL recognition models from few raw data based on a specific type of neural network called matching network . The interest of this few-shot learning approach is three-fold. Firstly, people perform activities their own way and general models may average out important individual characteristics unlike personalized models that could thus achieve better performance. Secondly, gathering large quantities of annotated data from one user is time-consuming and threatens privacy in a medical context. Thirdly, matching networks are by nature weakly dependent on the classes they are trained on and can generalize easily to new activities without needing extra training, thus making them very versatile for real applications. Our results show the effectiveness of the proposed approach compared to general neural network models, even in situations with few training data.},
  archive      = {J_ARTMED},
  author       = {Paul Compagnon and Grégoire Lefebvre and Stefan Duffner and Christophe Garcia},
  doi          = {10.1016/j.artmed.2020.101916},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101916},
  shortjournal = {Artif. Intell. Med.},
  title        = {Learning personalized ADL recognition models from few raw data},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CCAE: Cross-field categorical attributes embedding for
cancer clinical endpoint prediction. <em>ARTMED</em>, <em>107</em>,
101915. (<a href="https://doi.org/10.1016/j.artmed.2020.101915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with advanced cancer are burdened physically and psychologically, so there is an urgent need to pay more attention to their health-related quality of life (HRQOL). With an expected clinical endpoint prediction, over-treatment can be effectively eliminated by the means of palliative care at the right time. This paper develops a deep learning based approach for cancer clinical endpoint prediction based on patient&#39;s electronic health records (EHR). Due to the pervasive existence of categorical information in EHR , it brings unavoidably obstacles to the effective numerical learning algorithms. To address this issue, we propose a novel cross-field categorical attributes embedding (CCAE) model to learn a vectorized representation for cancer patients in attribute-level by orders, in which the strong semantic coupling among categorical variables are well exploited. By transforming the order-dependency modeling into a sequence learning task in an ingenious way, recurrent neural network is adopted to capture the semantic relevance among multi-order representations. Experimental results from the SEER-Medicare EHR dataset have illustrated that the proposed model can achieve competitive prediction performance compared with other baselines.},
  archive      = {J_ARTMED},
  author       = {Youru Li and Zhenfeng Zhu and Haiyan Wu and Silu Ding and Yao Zhao},
  doi          = {10.1016/j.artmed.2020.101915},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101915},
  shortjournal = {Artif. Intell. Med.},
  title        = {CCAE: Cross-field categorical attributes embedding for cancer clinical endpoint prediction},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-stage domain-specific pretraining for improved
detection and localization of barrett’s neoplasia: A comprehensive
clinically validated study. <em>ARTMED</em>, <em>107</em>, 101914. (<a
href="https://doi.org/10.1016/j.artmed.2020.101914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients suffering from Barrett&#39;s Esophagus (BE) are at an increased risk of developing esophageal adenocarcinoma and early detection is crucial for a good prognosis. To aid the endoscopists with the early detection for this preliminary stage of esophageal cancer, this work concentrates on the development and extensive evaluation of a state-of-the-art computer-aided classification and localization algorithm for dysplastic lesions in BE. To this end, we have employed a large-scale endoscopic data set, consisting of 494,355 images, in combination with a novel semi-supervised learning algorithm to pretrain several instances of the proposed neural network architecture. Next, several Barrett-specific data sets that are increasingly closer to the target domain with significantly more data compared to other related work, were used in a multi-stage transfer learning strategy. Additionally, the algorithm was evaluated on two prospectively gathered external test sets and compared against 53 medical professionals. Finally, the model was also evaluated in a live setting without interfering with the current biopsy protocol. Results from the performed experiments show that the proposed model improves on the state-of-the-art on all measured metrics. More specifically, compared to the best performing state-of-the-art model, the specificity is improved by more than 20% points while simultaneously preserving high sensitivity and reducing the false positive rate substantially. Our algorithm yields similar scores on the localization metrics, where the intersection of all experts is correctly indicated in approximately 92% of the cases. Furthermore, the live pilot study shows great performance in a clinical setting with a patient level accuracy, sensitivity, and specificity of 90%. Finally, the proposed algorithm outperforms each individual medical expert by at least 5% and the average assessor by more than 10% over all assessor groups with respect to accuracy.},
  archive      = {J_ARTMED},
  author       = {Joost van der Putten and Jeroen de Groof and Maarten Struyvenberg and Tim Boers and Kiki Fockens and Wouter Curvers and Erik Schoon and Jacques Bergman and Fons van der Sommen and Peter H.N. de With},
  doi          = {10.1016/j.artmed.2020.101914},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101914},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-stage domain-specific pretraining for improved detection and localization of barrett&#39;s neoplasia: A comprehensive clinically validated study},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of things-inspired healthcare system for
urine-based diabetes prediction. <em>ARTMED</em>, <em>107</em>, 101913.
(<a href="https://doi.org/10.1016/j.artmed.2020.101913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Healthcare industry is the leading domain that has been revolutionized by the incorporation of Internet of Things (IoT) technology resulting in smart medical applications. Conspicuously, this study presents an effective system of home-centric Urine-based Diabetes (UbD) monitoring system . Specifically, the proposed system comprises of 4-layers for predicting and monitoring diabetes-oriented urine infection. The system layers including Diabetic Data Acquisition (DDA) layer, Diabetic Data Classification (DDC) layer, Diabetic-Mining and Extraction (DME) layer, and Diabetic Prediction and Decision Making (DPDM) layer allow an individual not exclusively to track his/her diabetes measure on regular basis but the prediction procedure is also accomplished so that prudent steps can be taken at early stages. Additionally, probabilistic measurement of UbD monitoring in terms of Level of Diabetic Infection (LoDI), which is cumulatively quantified as Diabetes Infection Measure (DIM) has been performed for predictive purposes using Recurrent Neural Network (RNN). Moreover, the existence of UbD is visualized based on the Self-Organized Mapping (SOM) procedure. To validate the proposed system, numerous experimental simulations were performed on datasets of 4 individuals. Based on the experimental simulation, enhanced results in terms of temporal delay, classification efficiency, prediction efficiency, reliability and stability were registered for the proposed system in comparison to state-of-the-art decision-making techniques.},
  archive      = {J_ARTMED},
  author       = {Munish Bhatia and Simranpreet Kaur and Sandeep K. Sood and Veerawali Behal},
  doi          = {10.1016/j.artmed.2020.101913},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101913},
  shortjournal = {Artif. Intell. Med.},
  title        = {Internet of things-inspired healthcare system for urine-based diabetes prediction},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian networks in healthcare: Distribution by medical
condition. <em>ARTMED</em>, <em>107</em>, 101912. (<a
href="https://doi.org/10.1016/j.artmed.2020.101912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks (BNs) have received increasing research attention that is not matched by adoption in practice and yet have potential to significantly benefit healthcare. Hitherto, research works have not investigated the types of medical conditions being modelled with BNs, nor whether there are any differences in how and why they are applied to different conditions. This research seeks to identify and quantify the range of medical conditions for which healthcare-related BN models have been proposed, and the differences in approach between the most common medical conditions to which they have been applied. We found that almost two-thirds of all healthcare BNs are focused on four conditions: cardiac, cancer, psychological and lung disorders . We believe there is a lack of understanding regarding how BNs work and what they are capable of, and that it is only with greater understanding and promotion that we may ever realise the full potential of BNs to effect positive change in daily healthcare practice.},
  archive      = {J_ARTMED},
  author       = {Scott McLachlan and Kudakwashe Dube and Graham A Hitman and Norman E Fenton and Evangelia Kyrimi},
  doi          = {10.1016/j.artmed.2020.101912},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101912},
  shortjournal = {Artif. Intell. Med.},
  title        = {Bayesian networks in healthcare: Distribution by medical condition},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining analysis of multi-parametric MR images into a
convolutional neural network: Precise target delineation for vestibular
schwannoma treatment planning. <em>ARTMED</em>, <em>107</em>, 101911.
(<a href="https://doi.org/10.1016/j.artmed.2020.101911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual delineation of vestibular schwannoma (VS) by magnetic resonance (MR) imaging is required for diagnosis, radiosurgery dose planning, and follow-up tumor volume measurement. A rapid and objective automatic segmentation method is required, but problems have been encountered due to the low through-plane resolution of standard VS MR scan protocols and because some patients have non-homogeneous cystic areas within their tumors. In this study, we retrospectively collected multi-parametric MR images from 516 patients with VS; these were extracted from the Gamma Knife radiosurgery planning system and consisted of T1-weighted (T1W), T2-weighted (T2W), and T1W with contrast (T1W + C) images. We developed an end-to-end deep-learning-based method via an automatic preprocessing pipeline. A two-pathway U-Net model involving two sizes of convolution kernel (i.e., 3 × 3 × 1 and 1 × 1 × 3) was used to extract the in-plane and through-plane features of the anisotropic MR images. A single-pathway model that adopted the same architecture as the two-pathway model, but used a kernel size of 3 × 3 × 3, was also developed for comparison purposes. In addition, we used multi-parametric MR images with different image contrasts as the model training input in order to effectively segment tumors with solid as well as cystic parts. The results of the automatic segmentation demonstrated that (1) the two-pathway model outperformed single-pathway model in terms of dice scores (0.90 ± 0.05 versus 0.87 ± 0.07); both of them having been trained using the T1W, T1W + C and T2W anisotropic MR images, (2) the optimal single-parametric two-pathway model (dice score: 0.88 ± 0.06) was then trained using the T1W + C images, and (3) the two-pathway models trained using bi-parametric (T1W + C and T2W) and tri-parametric (T1W, T2W, and T1W + C) images outperformed the model trained using the single-parametric (T1W + C) images (dice scores: 0.89 ± 0.05 and 0.90 ± 0.05, respectively, larger than 0.88 ± 0.06) because it showed improved segmentation of the non-homogeneous parts of the tumors. The proposed two-pathway U-Net model outperformed the single-pathway U-Net model when segmenting VS using anisotropic MR images. The multi-parametric models effectively improved on the defective segmentation obtained using the single-parametric models by separating the non-homogeneous tumors into their solid and cystic parts.},
  archive      = {J_ARTMED},
  author       = {Wei-Kai Lee and Chih-Chun Wu and Cheng-Chia Lee and Chia-Feng Lu and Huai-Che Yang and Tzu-Hsuan Huang and Chun-Yi Lin and Wen-Yuh Chung and Po-Shan Wang and Hsiu-Mei Wu and Wan-Yuo Guo and Yu-Te Wu},
  doi          = {10.1016/j.artmed.2020.101911},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101911},
  shortjournal = {Artif. Intell. Med.},
  title        = {Combining analysis of multi-parametric MR images into a convolutional neural network: Precise target delineation for vestibular schwannoma treatment planning},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automated hematoma segmentation and outcome prediction for
patients with traumatic brain injury. <em>ARTMED</em>, <em>107</em>,
101910. (<a href="https://doi.org/10.1016/j.artmed.2020.101910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traumatic brain injury (TBI) is a major cause of death and disability worldwide. Automated brain hematoma segmentation and outcome prediction for patients with TBI can effectively facilitate patient management. In this study, we propose a novel Multi-view convolutional neural network with a mixed loss to segment total acute hematoma on head CT scans collected within 24 h after the injury. Based on the automated segmentation, the volumetric distribution and shape characteristics of the hematoma were extracted and combined with other clinical observations to predict 6-month mortality. The proposed hematoma segmentation network achieved an average Dice coefficient of 0.697 and an intraclass correlation coefficient of 0.966 between the volumes estimated from the predicted hematoma segmentation and volumes of the annotated hematoma segmentation on the test set. Compared with other published methods, the proposed method has the most accurate segmentation performance and volume estimation. For 6-month mortality prediction, the model achieved an average area under the precision-recall curve (AUCPR) of 0.559 and area under the receiver operating characteristic curve (AUC) of 0.853 using 10-fold cross-validation on a dataset consisting of 828 patients. The average AUCPR and AUC of the proposed model are respectively more than 10% and 5% higher than those of the widely used IMPACT model.},
  archive      = {J_ARTMED},
  author       = {Heming Yao and Craig Williamson and Jonathan Gryak and Kayvan Najarian},
  doi          = {10.1016/j.artmed.2020.101910},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101910},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated hematoma segmentation and outcome prediction for patients with traumatic brain injury},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The four dimensions of contestable AI diagnostics - a
patient-centric approach to explainable AI. <em>ARTMED</em>,
<em>107</em>, 101901. (<a
href="https://doi.org/10.1016/j.artmed.2020.101901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of the explainability of AI decision-making has attracted considerable attention in recent years. In considering AI diagnostics we suggest that explainability should be explicated as ‘effective contestability’. Taking a patient-centric approach we argue that patients should be able to contest the diagnoses of AI diagnostic systems, and that effective contestation of patient-relevant aspect of AI diagnoses requires the availability of different types of information about 1) the AI system’s use of data, 2) the system’s potential biases, 3) the system performance, and 4) the division of labour between the system and health care professionals. We justify and define thirteen specific informational requirements that follows from ‘contestability’. We further show not only that contestability is a weaker requirement than some of the proposed criteria of explainability, but also that it does not introduce poorly grounded double standards for AI and health care professionals’ diagnostics, and does not come at the cost of AI system performance. Finally, we briefly discuss whether the contestability requirements introduced here are domain-specific.},
  archive      = {J_ARTMED},
  author       = {Thomas Ploug and Søren Holm},
  doi          = {10.1016/j.artmed.2020.101901},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101901},
  shortjournal = {Artif. Intell. Med.},
  title        = {The four dimensions of contestable AI diagnostics - a patient-centric approach to explainable AI},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully convolutional attention network for biomedical image
segmentation. <em>ARTMED</em>, <em>107</em>, 101899. (<a
href="https://doi.org/10.1016/j.artmed.2020.101899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we embed two types of attention modules in the dilated fully convolutional network (FCN) to solve biomedical image segmentation tasks efficiently and accurately. Different from previous work on image segmentation through multiscale feature fusion, we propose the fully convolutional attention network (FCANet) to aggregate contextual information at long-range and short-range distances. Specifically, we add two types of attention modules, the spatial attention module and the channel attention module, to the Res2Net network, which has a dilated strategy. The features of each location are aggregated through the spatial attention module, so that similar features promote each other in space size. At the same time, the channel attention module treats each channel of the feature map as a feature detector and emphasizes the channel dependency between any two channel maps. Finally, we weight the sum of the output features of the two types of attention modules to retain the feature information of the long-range and short-range distances, to further improve the representation of the features and make the biomedical image segmentation more accurate. In particular, we verify that the proposed attention module can seamlessly connect to any end-to-end network with minimal overhead. We perform comprehensive experiments on three public biomedical image segmentation datasets, i.e., the Chest X-ray collection, the Kaggle 2018 data science bowl and the Herlev dataset. The experimental results show that FCANet can improve the segmentation effect of biomedical images. The source code models are available at https://github.com/luhongchun/FCANet},
  archive      = {J_ARTMED},
  author       = {Junlong Cheng and Shengwei Tian and Long Yu and Hongchun Lu and Xiaoyi Lv},
  doi          = {10.1016/j.artmed.2020.101899},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101899},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fully convolutional attention network for biomedical image segmentation},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced prediction of hemoglobin concentration in a very
large cohort of hemodialysis patients by means of deep recurrent neural
networks. <em>ARTMED</em>, <em>107</em>, 101898. (<a
href="https://doi.org/10.1016/j.artmed.2020.101898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Erythropoiesis Stimulating Agents (ESAs) have become a standard anemia management tool for End Stage Renal Disease (ESRD) patients. However, dose optimization constitutes an extremely challenging task due to huge inter and intra-patient variability in the responses to ESA administration. Current data-based approaches to anemia control focus on learning accurate hemoglobin prediction models, which can be later utilized for testing competing treatment choices and choosing the optimal one. These methods, despite being proven effective in practice, present several shortcomings which this paper intends to tackle. Namely, they are limited to a small cohort of patients and, even then, they fail to provide suggestions when some strict requirements are not met (such as having a three month history prior to the prediction). Here, recurrent neural networks (RNNs) are used to model whole patient histories, providing predictions at every time step since the very first day. Furthermore, an unprecedented amount of data (∼110,000 patients from many different medical centers in twelve countries, without exclusion criteria) was used to train it, thus allowing it to generalize for every single patient. The resulting model outperforms state-of-the-art Hemoglobin prediction, providing excellent results even when tested on a prospective dataset. Simultaneously, it allows to bring the benefits of algorithmic anemia control to a very large group of patients.},
  archive      = {J_ARTMED},
  author       = {Oscar J. Pellicer-Valero and Isabella Cattinelli and Luca Neri and Flavio Mari and José D. Martín-Guerrero and Carlo Barbieri},
  doi          = {10.1016/j.artmed.2020.101898},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101898},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhanced prediction of hemoglobin concentration in a very large cohort of hemodialysis patients by means of deep recurrent neural networks},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A shape context fully convolutional neural network for
segmentation and classification of cervical nuclei in pap smear images.
<em>ARTMED</em>, <em>107</em>, 101897. (<a
href="https://doi.org/10.1016/j.artmed.2020.101897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pap smear is often employed as a screening test for diagnosing cervical pre-cancerous and cancerous lesions. Accurate identification of dysplastic changes amongst the cervical cells in a Pap smear image is thus essential for rapid diagnosis and prognosis. Manual pathological observations used in clinical practice require exhaustive analysis of thousands of cell nuclei in a whole slide image to visualize the dysplastic nuclear changes which make the process tedious and time-consuming. Automated nuclei segmentation and classification exist but are challenging to overcome issues like nuclear intra-class variability and clustered nuclei separation. To address such challenges, we put forward an application of instance segmentation and classification framework built on an Unet architecture by adding residual blocks, densely connected blocks and a fully convolutional layer as a bottleneck between encoder-decoder blocks for Pap smear images. The number of convolutional layers in the standard Unet has been replaced by densely connected blocks to ensure feature reuse-ability property while the introduction of residual blocks in the same attempts to converge the network more rapidly. The framework provides simultaneous nuclei instance segmentation and also predicts the type of nucleus class as belonging to normal and abnormal classes from the smear images. It works by assigning pixel-wise labels to individual nuclei in a whole slide image which enables identifying multiple nuclei belonging to the same or different class as individual distinct instances. Introduction of a joint loss function in the framework overcomes some trivial cell level issues on clustered nuclei separation. To increase the robustness of the overall framework, the proposed model is preceded with a stacked auto-encoder based shape representation learning model. The proposed model outperforms two state-of-the-art deep learning models Unet and Mask_RCNN with an average Zijdenbos similarity index of 97 % related to segmentation along with binary classification accuracy of 98.8 %. Experiments on hospital-based datasets using liquid-based cytology and conventional pap smear methods along with benchmark Herlev datasets proved the superiority of the proposed method than Unet and Mask_RCNN models in terms of the evaluation metrics under consideration.},
  archive      = {J_ARTMED},
  author       = {Elima Hussain and Lipi B. Mahanta and Chandana Ray Das and Manjula Choudhury and Manish Chowdhury},
  doi          = {10.1016/j.artmed.2020.101897},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101897},
  shortjournal = {Artif. Intell. Med.},
  title        = {A shape context fully convolutional neural network for segmentation and classification of cervical nuclei in pap smear images},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting the causative pathogen among children with
osteomyelitis using bayesian networks – improving antibiotic selection
in clinical practice. <em>ARTMED</em>, <em>107</em>, 101895. (<a
href="https://doi.org/10.1016/j.artmed.2020.101895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infection of bone, osteomyelitis (OM), is a serious bacterial infection in children requiring urgent antibiotic therapy. While biological specimens are often obtained and cultured to guide antibiotic selection, culture results may take several days, are often falsely negative, and may be falsely positive because of contamination by non-causative bacteria. This poses a dilemma for clinicians when choosing the most suitable antibiotic. Selecting an antibiotic which is too narrow in spectrum risks treatment failure; selecting an antibiotic which is too broad risks toxicity and promotes antibiotic resistance. We have developed a Bayesian Network (BN) model that can be used to guide individually targeted antibiotic therapy at point-of-care, by predicting the most likely causative pathogen in children with OM and the antibiotic with optimal expected utility. The BN explicitly models the complex relationship between the unobserved infecting pathogen, observed culture results, and clinical and demographic variables, and integrates data with critical expert knowledge under a causal inference framework. Development of this tool resulted from a multidisciplinary approach, involving experts in infectious diseases, modelling, paediatrics, microbiology, computer science and statistics. The model-predicted prevalence of causative pathogens among children with osteomyelitis were 56 % for Staphylococcus aureus , 17 % for ‘other’ culturable bacteria (like Streptococcus pyogenes ), and 27 % for bacterial pathogens that are not culturable using routine methods (like Kingella kingae ). Log loss cross-validation suggests that the model performance is robust, with the best fit to culture results achieved when data and expert knowledge were combined during parameterisation. AUC values of 0.68 – 0.77 were achieved for predicting culture results of different types of specimens. BN-recommended antibiotics were rated optimal or adequate by experts in 82–98% of 81 cases sampled from the cohort. We have demonstrated the potential use of BNs in improving antibiotic selection for children with OM, which we believe to be generalisable in the development of a broader range of decision support tools. With appropriate validation, such tools might be effectively deployed for real-time clinical decision support, to promote a shift in clinical practice from generic to individually-targeted antibiotic therapy, and ultimately improve the management and outcomes for a range of serious bacterial infections.},
  archive      = {J_ARTMED},
  author       = {Yue Wu and Charlie McLeod and Christopher Blyth and Asha Bowen and Andrew Martin and Ann Nicholson and Steven Mascaro and Tom Snelling},
  doi          = {10.1016/j.artmed.2020.101895},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101895},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting the causative pathogen among children with osteomyelitis using bayesian networks – improving antibiotic selection in clinical practice},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrative blockwise sparse analysis for tissue
characterization and classification. <em>ARTMED</em>, <em>107</em>,
101885. (<a href="https://doi.org/10.1016/j.artmed.2020.101885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topic of sparse representation of samples in high dimensional spaces has attracted growing interest during the past decade. In this work, we develop sparse representation-based methods for classification of clinical imaging patterns into healthy and diseased states. We propose a spatial block decomposition method to address irregularities of the approximation problem and to build an ensemble of classifiers that we expect to yield more accurate numerical solutions than conventional sparse analyses of the complete spatial domain of the images. We introduce two classification decision strategies based on maximum a posteriori probability (BBMAP), or a log likelihood function (BBLL) and an approach to adjusting the classification decision criteria. To evaluate the performance of the proposed approach we used cross-validation techniques on imaging datasets with disease class labels. We first applied the proposed approach to diagnosis of osteoporosis using bone radiographs. In this problem we assume that changes in trabecular bone connectivity can be captured by intensity patterns. The second application domain is separation of breast lesions into benign and malignant categories in mammograms. The object classes in both of these applications are not linearly separable, and the classification accuracy may depend on the lesion size in the second application. Our results indicate that the proposed integrative sparse analysis addresses the ill-posedness of the approximation problem and produces very good class separation for trabecular bone characterization and for breast lesion characterization. Our approach yields higher classification rates than conventional sparse classification and previously published convolutional neural networks (CNNs) that we fine-tuned for our datasets, or utilized for feature extraction. The BBLL technique also produced higher classification rates than learners using hand-crafted texture features, and the Bag of Keypoints, which is a sophisticated patch-based method. Furthermore, our comparative experiments showed that the BBLL function may yield more accurate classification than BBMAP, because BBLL accounts for possible estimation bias.},
  archive      = {J_ARTMED},
  author       = {Keni Zheng and Chelsea E. Harris and Rachid Jennane and Sokratis Makrogiannis},
  doi          = {10.1016/j.artmed.2020.101885},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101885},
  shortjournal = {Artif. Intell. Med.},
  title        = {Integrative blockwise sparse analysis for tissue characterization and classification},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data reduction and data visualization for automatic
diagnosis using gene expression and clinical data. <em>ARTMED</em>,
<em>107</em>, 101884. (<a
href="https://doi.org/10.1016/j.artmed.2020.101884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate diagnoses of specific diseases require, in general, the review of the whole medical history of a patient. Currently, even though many advances have been made for disease monitoring, domain experts are still requested to perform direct analyses in order to get a precise classification, thus implying significant efforts and costs. In this work we present a framework for automated diagnosis based on high-dimensional gene expression and clinical data. Given that high-dimensional data can be difficult to analyze and computationally expensive to process, we first perform data reduction to transform high-dimensional representations of data into a lower dimensional space, yet keeping them meaningful for our purposes. We used then different data visualization techniques to embed complex pieces of information in 2-D images, that are in turn used to perform diagnosis relying on deep learning approaches. Experimental analyses show that the proposed method achieves good performance, featuring a prediction Recall value between 91% and 99%.},
  archive      = {J_ARTMED},
  author       = {Pierangela Bruno and Francesco Calimeri and Alexandre Sébastien Kitanidis and Elena De Momi},
  doi          = {10.1016/j.artmed.2020.101884},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101884},
  shortjournal = {Artif. Intell. Med.},
  title        = {Data reduction and data visualization for automatic diagnosis using gene expression and clinical data},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal matrix completion with locally linear latent
factors for medical applications. <em>ARTMED</em>, <em>107</em>, 101883.
(<a href="https://doi.org/10.1016/j.artmed.2020.101883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regular medical records are useful for medical practitioners to analyze and monitor patient&#39;s health status especially for those with chronic disease . However, such records are usually incomplete due to unpunctuality and absence of patients. In order to resolve the missing data problem over time, tensor-based models have been developed for missing data imputation in recent papers. This approach makes use of the low-rank tensor assumption for highly correlated data in a short-time interval. Nevertheless, when the time intervals are long, data correlation may not be high between consecutive time stamps so that such assumption is not valid. To address this problem, we propose to decompose matrices with missing data over time into their latent factors . Then, the locally linear constraint is imposed on the latent factors for temporal matrix completion. By using three publicly available medical datasets and two medical datasets collected from Prince of Wales Hospital in Hong Kong, experimental results show that the proposed algorithm achieves the best performance compared with state-of-the-art methods.},
  archive      = {J_ARTMED},
  author       = {Andy J. Ma and Jacky C.P. Chan and Frodo K.S. Chan and Pong C. Yuen and Terry C.F. Yip and Yee-Kit Tse and Vincent W.S. Wong and Grace L.H. Wong},
  doi          = {10.1016/j.artmed.2020.101883},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101883},
  shortjournal = {Artif. Intell. Med.},
  title        = {Temporal matrix completion with locally linear latent factors for medical applications},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pulmonary nodule detection on chest radiographs using
balanced convolutional neural network and classic candidate detection.
<em>ARTMED</em>, <em>107</em>, 101881. (<a
href="https://doi.org/10.1016/j.artmed.2020.101881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided detection (CADe) systems play a crucial role in pulmonary nodule detection via chest radiographs (CXRs). A two-stage CADe scheme usually includes nodule candidate detection and false positive reduction. A pure deep learning model, such as faster region convolutional neural network (faster R-CNN), has been successfully applied for nodule candidate detection via computed tomography (CT). The model is yet to achieve a satisfactory performance in CXR, because the size of the CXR is relatively large and the nodule in CXR has been obscured by structures such as ribs. In contrast, the CNN has proved effective for false positive reduction compared to the shallow method. In this paper, we developed a CADe scheme using the balanced CNN with classic candidate detection. First, the scheme applied a multi-segment active shape model to accurately segment pulmonary parenchyma. The grayscale morphological enhancement technique was then used to improve the conspicuity of the nodule structure. Based on the nodule enhancement image, 200 nodule candidates were selected and a region of interest (ROI) was cropped for each. Nodules in CXR exhibit a large variation in density, and rib crossing and vessel tissue usually present similar features to the nodule. Compared to the original ROI image, the nodule enhancement ROI image has potential discriminative features from false positive reduction. In this study, the nodule enhancement ROI image, corresponding segmentation result, and original ROI image were encoded into a red–green–blue (RGB) color image instead of the duplicated original ROI image as input of the CNN (GoogLeNet) for false positive reduction. With the Japanese Society of Radiological Technology database, the CADe scheme achieved high performance of the published literatures (a sensitivity of 91.4 % and 97.1 %, with 2.0 false positives per image (FPs/image) and 5.0 FPs/image, respectively) for nodule cases.},
  archive      = {J_ARTMED},
  author       = {Sheng Chen and Yaqi Han and Jinqiu Lin and Xiangyu Zhao and Ping Kong},
  doi          = {10.1016/j.artmed.2020.101881},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101881},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pulmonary nodule detection on chest radiographs using balanced convolutional neural network and classic candidate detection},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Breast ultrasound region of interest detection and lesion
localisation. <em>ARTMED</em>, <em>107</em>, 101880. (<a
href="https://doi.org/10.1016/j.artmed.2020.101880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current breast ultrasound computer aided diagnosis systems, the radiologist preselects a region of interest (ROI) as an input for computerised breast ultrasound image analysis. This task is time consuming and there is inconsistency among human experts. Researchers attempting to automate the process of obtaining the ROIs have been relying on image processing and conventional machine learning methods. We propose the use of a deep learning method for breast ultrasound ROI detection and lesion localisation. We use the most accurate object detection deep learning framework – Faster-RCNN with Inception-ResNet-v2 – as our deep learning network. Due to the lack of datasets, we use transfer learning and propose a new 3-channel artificial RGB method to improve the overall performance. We evaluate and compare the performance of our proposed methods on two datasets (namely, Dataset A and Dataset B), i.e. within individual datasets and composite dataset. We report the lesion detection results with two types of analysis: (1) detected point (centre of the segmented region or the detected bounding box) and (2) Intersection over Union ( IoU ). Our results demonstrate that the proposed methods achieved comparable results on detected point but with notable improvement on IoU . In addition, our proposed 3-channel artificial RGB method improves the recall of Dataset A. Finally, we outline some future directions for the research.},
  archive      = {J_ARTMED},
  author       = {Moi Hoon Yap and Manu Goyal and Fatima Osman and Robert Martí and Erika Denton and Arne Juette and Reyer Zwiggelaar},
  doi          = {10.1016/j.artmed.2020.101880},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101880},
  shortjournal = {Artif. Intell. Med.},
  title        = {Breast ultrasound region of interest detection and lesion localisation},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method for predicting the progression rate of ALS
disease based on automatic generation of probabilistic causal chains.
<em>ARTMED</em>, <em>107</em>, 101879. (<a
href="https://doi.org/10.1016/j.artmed.2020.101879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal discovery is considered as a major concept in biomedical informatics contributing to diagnosis, therapy, and prognosis of diseases. Probabilistic causality approaches in epidemiology and medicine is a common method for finding relationships between pathogen and disease, environment and disease, and adverse events and drugs. Bayesian Network (BN) is one of the common approaches for probabilistic causality, which is widely used in health-care and biomedical science. Since in many biomedical applications we deal with temporal dataset, the temporal extension of BNs called Dynamic Bayesian network (DBN) is used for such applications. DBNs define probabilistic relationships between parameters in consecutive time points in the form of a graph and have been successfully used in many biomedical applications. In this paper, a novel method was introduced for finding probabilistic causal chains from a temporal dataset with the help of entropy and causal tendency measures. In this method, first, Causal Features Dependency (CFD) matrix is created on the basis of parameters changes in consecutive events of a phenomenon, and then the probabilistic causal graph is constructed from this matrix based on entropy criteria. At the next step, a set of probabilistic causal chains of the corresponding causal graph is constructed by a novel polynomial-time heuristic. Finally, the causal chains are used for predicting the future trend of the phenomenon. The proposed model was applied to the Pooled Resource Open-Access Clinical Trials (PRO-ACT) dataset related to Amyotrophic Lateral Sclerosis (ALS) disease, in order to predict the progression rate of this disease. The results of comparison with Bayesian tree, random forest, support vector regression, linear regression, and multivariate regression show that the proposed algorithm can compete with these methods and in some cases outperforms other algorithms. This study revealed that probabilistic causality is an appropriate approach for predicting the future states of chronic diseases with unknown cause.},
  archive      = {J_ARTMED},
  author       = {M. Ahangaran and M.R. Jahed-Motlagh and B. Minaei-Bidgoli},
  doi          = {10.1016/j.artmed.2020.101879},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101879},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel method for predicting the progression rate of ALS disease based on automatic generation of probabilistic causal chains},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Missing data imputation and synthetic data simulation
through modeling graphical probabilistic dependencies between variables
(ModGraProDep): An application to breast cancer survival.
<em>ARTMED</em>, <em>107</em>, 101875. (<a
href="https://doi.org/10.1016/j.artmed.2020.101875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two common issues may arise in certain population-based breast cancer (BC) survival studies: I) missing values in a survivals’ predictive variable, such as “Stage” at diagnosis, and II) small sample size due to “imbalance class problem” in certain subsets of patients, demanding data modeling/simulation methods. We present a procedure, ModGraProDep, based on graphical modeling (GM) of a dataset to overcome these two issues. The performance of the models derived from ModGraProDep is compared with a set of frequently used classification and machine learning algorithms (Missing Data Problem) and with oversampling algorithms (Synthetic Data Simulation). For the Missing Data Problem we assessed two scenarios: missing completely at random (MCAR) and missing not at random (MNAR). Two validated BC datasets provided by the cancer registries of Girona and Tarragona (northeastern Spain) were used. In both MCAR and MNAR scenarios all models showed poorer prediction performance compared to three GM models: the saturated one (GM.SAT) and two with penalty factors on the partial likelihood (GM.K1 and GM.TEST). However, GM.SAT predictions could lead to non-reliable conclusions in BC survival analysis. Simulation of a “synthetic” dataset derived from GM.SAT could be the worst strategy, but the use of the remaining GMs models could be better than oversampling. Our results suggest the use of the GM-procedure presented for one-variable imputation/prediction of missing data and for simulating “synthetic” BC survival datasets. The “synthetic” datasets derived from GMs could be also used in clinical applications of cancer survival data such as predictive risk analysis.},
  archive      = {J_ARTMED},
  author       = {Mireia Vilardell and Maria Buxó and Ramon Clèries and José Miguel Martínez and Gemma Garcia and Alberto Ameijide and Rebeca Font and Sergi Civit and BreCanSurvCat working group and Rafael Marcos-Gragera and Maria Loreto Vilardell and Marià Carulla and Josep Alfons Espinàs and Jaume Galceran and Angel Izquierdo and Josep Ma Borràs},
  doi          = {10.1016/j.artmed.2020.101875},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101875},
  shortjournal = {Artif. Intell. Med.},
  title        = {Missing data imputation and synthetic data simulation through modeling graphical probabilistic dependencies between variables (ModGraProDep): An application to breast cancer survival},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating expert’s knowledge constraint of time dependent
exposures in structure learning for bayesian networks. <em>ARTMED</em>,
<em>107</em>, 101874. (<a
href="https://doi.org/10.1016/j.artmed.2020.101874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a Bayesian network is a difficult and well known task that has been largely investigated. To reduce the number of candidate graphs to test, some authors proposed to incorporate a priori expert knowledge. Most of the time, this a priori information between variables influences the learning but never contradicts the data. In addition, the development of Bayesian networks integrating time such as dynamic Bayesian networks allows identifying causal graphs in the context of longitudinal data. Moreover, in the context where the number of strongly correlated variables is large (i.e. oncology) and the number of patients low; if a biomarker has a mediated effect on another, the learning algorithm would associate them wrongly and vice versa. In this article we propose a method to use the a priori expert knowledge as hard constraints in a structure learning method for Bayesian networks with a time dependant exposure. Based on a simulation study and an application, where we compared our method to the state of the art PC-algorithm, the results showed a better recovery of the true graphs when integrating hard constraints a priori expert knowledge even for small level of information.},
  archive      = {J_ARTMED},
  author       = {Vahé Asvatourian and Philippe Leray and Stefan Michiels and Emilie Lanoy},
  doi          = {10.1016/j.artmed.2020.101874},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101874},
  shortjournal = {Artif. Intell. Med.},
  title        = {Integrating expert’s knowledge constraint of time dependent exposures in structure learning for bayesian networks},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A case-based ensemble learning system for explainable breast
cancer recurrence prediction. <em>ARTMED</em>, <em>107</em>, 101858. (<a
href="https://doi.org/10.1016/j.artmed.2020.101858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant progress has been achieved in recent years in the application of artificial intelligence (AI) for medical decision support. However, many AI-based systems often only provide a final prediction to the doctor without an explanation of its underlying decision-making process. In scenarios concerning deadly diseases, such as breast cancer, a doctor adopting an auxiliary prediction is taking big risks, as a bad decision can have very harmful consequences for the patient. We propose an auxiliary decision support system that combines ensemble learning with case-based reasoning to help doctors improve the accuracy of breast cancer recurrence prediction. The system provides a case-based interpretation of its prediction, which is easier for doctors to understand, helping them assess the reliability of the system’s prediction and make their decisions accordingly. Our application and evaluation in a case study focusing on breast cancer recurrence prediction shows that the proposed system not only provides reasonably accurate predictions but is also well-received by oncologists.},
  archive      = {J_ARTMED},
  author       = {Dongxiao Gu and Kaixiang Su and Huimin Zhao},
  doi          = {10.1016/j.artmed.2020.101858},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101858},
  shortjournal = {Artif. Intell. Med.},
  title        = {A case-based ensemble learning system for explainable breast cancer recurrence prediction},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A framework to shift basins of attraction of gene regulatory
networks through batch reinforcement learning. <em>ARTMED</em>,
<em>107</em>, 101853. (<a
href="https://doi.org/10.1016/j.artmed.2020.101853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A major challenge in gene regulatory networks (GRN) of biological systems is to discover when and what interventions should be applied to shift them to healthy phenotypes. A set of gene activity profiles, called basin of attraction (BOA), takes this network to a specific phenotype; therefore, a healthy BOA leads the GRN to a healthy phenotype. However, without the complete observability of the genes, it is not possible to identify whether the current BOA is healthy. In this article we investigate external interventions in GRN with partial observability aiming to bring it to healthy BOAs. We propose a new batch reinforcement learning method (BRL), called mSFQI, to define intervention strategies based on the probabilities of the gene activity profiles being in healthy BOAs, which are calculated from a set of previous observed experiences. BRL uses approximation functions and repeated applications of previous experiences to accelerate learning. Results demonstrate that our proposal can quickly shift a partially observable GRN to healthy BOAs, while reducing the number of interventions. In addition, when observability is poor, mSFQI produces better results when the probabilities for a greater amount of previous observations are available.},
  archive      = {J_ARTMED},
  author       = {Cyntia Eico Hayama Nishida and Reinaldo A. Costa Bianchi and Anna Helena Reali Costa},
  doi          = {10.1016/j.artmed.2020.101853},
  journal      = {Artificial Intelligence in Medicine},
  month        = {7},
  pages        = {101853},
  shortjournal = {Artif. Intell. Med.},
  title        = {A framework to shift basins of attraction of gene regulatory networks through batch reinforcement learning},
  volume       = {107},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to identify and treat data inconsistencies when
eliciting health-state utility values for patient-centered decision
making. <em>ARTMED</em>, <em>106</em>, 101882. (<a
href="https://doi.org/10.1016/j.artmed.2020.101882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health utilities express the perceptions patients have on the impact potential adverse events of medical treatments may have on their quality of life. Being able to accurately assess health utilities is crucial when deciding what is the best treatment when multiple and diverse treatment options exist, or when performing a cost / utility analysis. Due to the emotional and other complexities that may exist when such data are elicited, the values of the health utilities may be inaccurate and cause inconsistencies. Existing literature indicates that such inconsistencies may be very frequent. However, no method has been developed for dealing with such inconsistencies in an effective manner. Given a set of health utilities, this paper first explores ways for determining if there are any inconsistencies in their values. It also proposes a number of quadratic optimization approaches to best estimate the actual (and hence unknown) values when a set of initial health utility values are provided by the patient and certain inconsistencies have been detected. This is achieved by readjusting the initial values in a way that is minimal and also satisfies certain consistency requirements. The proposed methods are applied on an illustrative example related to localized prostate cancer. Data from some published studies were used to illustrate how a set of initial values can be analyzed. This analysis aims at readjusting them in a minimal manner that would also satisfy some key numerical constraints pertinent to health utility values. The numerical results and the computational complexities of the proposed models indicate that the proposed approaches are practical as they involve quadratic optimization modeling. These approaches are novel as the problem of addressing numerical inconsistencies in the elicitation process of health utilities has not been addressed adequately. The approaches are also critical in shared decision making and also when performing cost / utility analyses because health utilities play a central role in determining the quality-adjusted life years when making decisions in these healthcare domains.},
  archive      = {J_ARTMED},
  author       = {Evangelos Triantaphyllou and Juri Yanase},
  doi          = {10.1016/j.artmed.2020.101882},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101882},
  shortjournal = {Artif. Intell. Med.},
  title        = {How to identify and treat data inconsistencies when eliciting health-state utility values for patient-centered decision making},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning in generating radiology reports: A survey.
<em>ARTMED</em>, <em>106</em>, 101878. (<a
href="https://doi.org/10.1016/j.artmed.2020.101878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Substantial progress has been made towards implementing automated radiology reporting models based on deep learning (DL). This is due to the introduction of large medical text/image datasets. Generating radiology coherent paragraphs that do more than traditional medical image annotation, or single sentence-based description, has been the subject of recent academic attention. This presents a more practical and challenging application and moves towards bridging visual medical features and radiologist text. So far, the most common approach has been to utilize publicly available datasets and develop DL models that integrate convolutional neural networks (CNN) for image analysis alongside recurrent neural networks (RNN) for natural language processing (NLP) and natural language generation (NLG). This is an area of research that we anticipate will grow in the near future. We focus our investigation on the following critical challenges: understanding radiology text/image structures and datasets, applying DL algorithms (mainly CNN and RNN), generating radiology text, and improving existing DL based models and evaluation metrics. Lastly, we include a critical discussion and future research recommendations. This survey will be useful for researchers interested in DL, particularly those interested in applying DL to radiology reporting.},
  archive      = {J_ARTMED},
  author       = {Maram Mahmoud A. Monshi and Josiah Poon and Vera Chung},
  doi          = {10.1016/j.artmed.2020.101878},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101878},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning in generating radiology reports: A survey},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Upper-limb functional assessment after stroke using mirror
contraction: A pilot study. <em>ARTMED</em>, <em>106</em>, 101877. (<a
href="https://doi.org/10.1016/j.artmed.2020.101877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clinical assessment after stroke depends on the rating scale, usually lack of quantitative feedback such as biomedical signal captured from stroke patients. This study attempts to develop a unified assessment framework for persons after stroke via surface electromyography (sEMG) bias from bilateral limbs, based on four types of selected movements, namely forward lift arm, lateral lift arm, forearm internal/external rotation, forearm pronation/supination. Eleven healthy subjects and six stroke patients are recruited to participate in the experiment to perform the bilateral-mirrored paradigm with six channels of sEMG signals recorded from each of their arms. The linear discriminant analysis (LDA), random forest algorithm (RF) and support vector machine (SVM) are adopted, trained and used for stroke patients qualitative recognition. The bilateral bias diagnosis algorithm (BBDA) is developed to evaluate the stroke severity quantitatively based on the similarity index (SI) of the sEMG. The results reveal that: (1) the sEMG feature bias of bilateral arms for stroke patients is different from that of healthy people; (2) the RF and SVM demonstrate a better performance with an average recognition accuracy of 0.92 ± 0.12 and 0.93 ± 0.12 than LDA (0.84 ± 0.20) in distinguishing stroke patients from healthy subjects; (3) there is a strong positive correlation between SI and the Fugl-Meyer score ( r = 0.93). These research findings indicate that the dominant qualitative assessment after stroke could be complementary by its counterpart quantitative solutions, and stroke rehabilitation could be automated with less involvement of professional therapists.},
  archive      = {J_ARTMED},
  author       = {Yu Zhou and Jia Zeng and Hongze Jiang and Yang Li and Jie Jia and Honghai Liu},
  doi          = {10.1016/j.artmed.2020.101877},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101877},
  shortjournal = {Artif. Intell. Med.},
  title        = {Upper-limb functional assessment after stroke using mirror contraction: A pilot study},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FDSR: A new fuzzy discriminative sparse representation
method for medical image classification. <em>ARTMED</em>, <em>106</em>,
101876. (<a href="https://doi.org/10.1016/j.artmed.2020.101876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in medical image analysis techniques make them essential tools in medical diagnosis. Medical imaging is always involved with different kinds of uncertainties. Managing these uncertainties has motivated extensive research on medical image classification methods, particularly for the past decade. Despite being a powerful classification tool, the sparse representation suffers from the lack of sufficient discrimination and robustness, which are required to manage the uncertainty and noisiness in medical image classification issues. It is tried to overcome this deficiency by introducing a new fuzzy discriminative robust sparse representation classifier, which benefits from the fuzzy terms in its optimization function of the dictionary learning process. In this work, we present a new medical image classification approach, fuzzy discriminative sparse representation (FDSR). The proposed fuzzy terms increase the inter-class representation difference and the intra-class representation similarity. Also, an adaptive fuzzy dictionary learning approach is used to learn dictionary atoms. FDSR is applied on Magnetic Resonance Images (MRI) from three medical image databases. The comprehensive experimental results clearly show that our approach outperforms its series of rival techniques in terms of accuracy, sensitivity, specificity, and convergence speed.},
  archive      = {J_ARTMED},
  author       = {Majid Ghasemi and Manoochehr Kelarestaghi and Farshad Eshghi and Arash Sharifi},
  doi          = {10.1016/j.artmed.2020.101876},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101876},
  shortjournal = {Artif. Intell. Med.},
  title        = {FDSR: A new fuzzy discriminative sparse representation method for medical image classification},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regularized-ncut: Robust and homogeneous functional
parcellation of neonate and adult brain networks. <em>ARTMED</em>,
<em>106</em>, 101872. (<a
href="https://doi.org/10.1016/j.artmed.2020.101872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain network parcellation based on resting-state functional MRI (rs-fMRI) is affected by noise, resulting in spurious small patches and decreased functional homogeneity within each network. Obtaining robust and homogeneous parcellation of neonate brain is more difficult, because neonate rs-fMRI is associated with relatively higher level of noise and no prior knowledge from a functional neonate atlas is available as spatial constraints. To meet these challenges, we developed a novel data-driven Regularized Normalized-cut (RNcut) method. RNcut is formulated by adding two regularization terms, a smoothing term using Markov random fields and a small-patch removal term, to conventional normalized-cut (Ncut) method. The RNcut and competing methods were tested with simulated datasets with known ground truth and then applied to both adult and neonate rs-fMRI datasets. Based on the parcellated networks generated by RNcut, intra-network connectivity was quantified. The test results from simulated datasets demonstrated that the RNcut method is more robust (p &lt; 0.01) to noise and can delineate parcellated functional networks with significantly better (p &lt; 0.01) spatial contiguity and significantly higher (p &lt; 0.01) functional homogeneity than competing methods. Application of RNcut to neonate and adult rs-fMRI dataset revealed distinctive functional brain organization of neonate brains from that of adult brains. Collectively, we developed a novel data-driven RNcut method by integrating conventional Ncut with two regularization terms, generating robust and homogeneous functional parcellation without imposing spatial constraints. A broad range of brain network applications and analyses, especially neonate and infant brain parcellation with noisy and large sample of datasets, can potentially benefit from this RNcut method.},
  archive      = {J_ARTMED},
  author       = {Qinmu Peng and Minhui Ouyang and Jiaojian Wang and Qinlin Yu and Chenying Zhao and Michelle Slinger and Hongming Li and Yong Fan and Bo Hong and Hao Huang},
  doi          = {10.1016/j.artmed.2020.101872},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101872},
  shortjournal = {Artif. Intell. Med.},
  title        = {Regularized-ncut: Robust and homogeneous functional parcellation of neonate and adult brain networks},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Speckle reduction of OCT via super resolution reconstruction
and its application on retinal layer segmentation. <em>ARTMED</em>,
<em>106</em>, 101871. (<a
href="https://doi.org/10.1016/j.artmed.2020.101871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT) is a rapidly developing non-invasive three dimensional imaging approach, and it has been widely used in examination and diagnosis of eye diseases. However, speckle noise are often inherited from image acquisition process, and may obscure the anatomical structure, such as the retinal layers. In this paper, we propose a novel method to reduce the speckle noise in 3D OCT scans, by introducing a new super-resolution approach. It uses a multi-frame fusion mechanism that merges multiple scans for the same scene, and utilizes the movements of sub-pixels to recover missing signals in one pixel, which significantly improves the image quality. To evaluate the effectiveness of the proposed speckle noise reduction method, we have applied it for the application of retinal layer segmentation. Results show that the proposed method has produced promising enhancement performance, and enable deep learning-based methods to obtain more accurate retinal layer segmentation results.},
  archive      = {J_ARTMED},
  author       = {Qifeng Yan and Bang Chen and Yan Hu and Jun Cheng and Yan Gong and Jianlong Yang and Jiang Liu and Yitian Zhao},
  doi          = {10.1016/j.artmed.2020.101871},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101871},
  shortjournal = {Artif. Intell. Med.},
  title        = {Speckle reduction of OCT via super resolution reconstruction and its application on retinal layer segmentation},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph fourier transform of fMRI temporal signals based on an
averaged structural connectome for the classification of neuroimaging.
<em>ARTMED</em>, <em>106</em>, 101870. (<a
href="https://doi.org/10.1016/j.artmed.2020.101870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph signal processing (GSP) is a framework that enables the generalization of signal processing to multivariate signals described on graphs. In this paper, we present an approach based on Graph Fourier Transform (GFT) and machine learning for the analysis of resting-state functional magnetic resonance imaging (rs-fMRI). For each subject, we use rs-fMRI time series to compute several descriptive statistics in regions of interest (ROI). Next, these measures are considered as signals on an averaged structural graph built using tractography of the white matter of the brain, defined using the same ROI. GFT of these signals is computed using the structural graph as a support, and the obtained feature vectors are subsequently benchmarked in a supervised learning setting. Further analysis suggests that GFT using structural connectivity as a graph and the standard deviation of fMRI time series as signals leads to more accurate supervised classification using a world-wide multi-site database known as ABIDE (Autism Brain Imaging Data Exchange) when compared to several other statistical metrics. Moreover, the proposed approach outperforms several approaches, based on using functional connectomes or complex functional network measures as features for classification.},
  archive      = {J_ARTMED},
  author       = {Abdelbasset Brahim and Nicolas Farrugia},
  doi          = {10.1016/j.artmed.2020.101870},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101870},
  shortjournal = {Artif. Intell. Med.},
  title        = {Graph fourier transform of fMRI temporal signals based on an averaged structural connectome for the classification of neuroimaging},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trusted medical image super-resolution method based on
feedback adaptive weighted dense network. <em>ARTMED</em>, <em>106</em>,
101857. (<a href="https://doi.org/10.1016/j.artmed.2020.101857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-resolution (HR) medical images are preferred in clinical diagnoses and subsequent analysis. However, the acquisition of HR medical images is easily affected by hardware devices. As an effective and trusted alternative method, the super-resolution (SR) technology is introduced to improve the image resolution. Compared with traditional SR methods, the deep learning-based SR methods can obtain more clear and trusted HR images. In this paper, we propose a trusted deep convolutional neural network-based SR method named feedback adaptive weighted dense network (FAWDN) for HR medical image reconstruction. Specifically, the proposed FAWDN can transmit the information of the output image to the low-level features by a feedback connection. To explore advanced feature representation and reduce the feature redundancy in dense blocks, an adaptive weighted dense block (AWDB) is introduced to adaptively select the informative features. Experimental results demonstrate that our FAWDN outperforms the state-of-the-art image SR methods and can obtain more clear and trusted medical images than comparative methods.},
  archive      = {J_ARTMED},
  author       = {Lihui Chen and Xiaomin Yang and Gwanggil Jeon and Marco Anisetti and Kai Liu},
  doi          = {10.1016/j.artmed.2020.101857},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101857},
  shortjournal = {Artif. Intell. Med.},
  title        = {A trusted medical image super-resolution method based on feedback adaptive weighted dense network},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ECG-based multi-class arrhythmia detection using
spatio-temporal attention-based convolutional recurrent neural network.
<em>ARTMED</em>, <em>106</em>, 101856. (<a
href="https://doi.org/10.1016/j.artmed.2020.101856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic arrhythmia detection based on electrocardiogram (ECG) is of great significance for early prevention and diagnosis of cardiac diseases. Recently, deep learning methods have been applied to arrhythmia detection and obtained great success. Among them, convolutional neural network (CNN) is an effective method for extracting features due to its local connectivity and parameter sharing. In addition, recurrent neural network (RNN) is another commonly used method, which is applied to process time-series signal. The stacking of both CNN and RNN has been proved to be more effective in multi-class arrhythmia detection. However, these networks ignored the fact that different channels and temporal segments of a feature map extracted from the 12-lead ECG signal contribute differently to cardiac arrhythmia detection, and thus, the classification performance could be greatly improved. To address this issue, spatio-temporal attention-based convolutional recurrent neural network (STA-CRNN) is proposed to focus on representative features along both spatial and temporal axes. STA-CRNN consists of CNN subnetwork, spatio-temporal attention modules and RNN subnetwork. The experiment result shows that, STA-CRNN reaches an average F 1 score of 0.835 in classifying 8 types of arrhythmias and normal rhythm. Compared with the state-of-the-art methods based on the same public dataset, STA-CRNN achieves an obvious improvement on identifying most of arrhythmias. Also, it is demonstrated by visualization that the learned features through STA-CRNN are in line with clinical judgement. STA-CRNN provides a promising method for automatic arrhythmia detection, which has a potential to assist cardiologists in the diagnosis of arrhythmias.},
  archive      = {J_ARTMED},
  author       = {Jing Zhang and Aiping Liu and Min Gao and Xiang Chen and Xu Zhang and Xun Chen},
  doi          = {10.1016/j.artmed.2020.101856},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101856},
  shortjournal = {Artif. Intell. Med.},
  title        = {ECG-based multi-class arrhythmia detection using spatio-temporal attention-based convolutional recurrent neural network},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review on segmentation of knee articular cartilage: From
conventional methods towards deep learning. <em>ARTMED</em>,
<em>106</em>, 101851. (<a
href="https://doi.org/10.1016/j.artmed.2020.101851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we review the state-of-the-art approaches for knee articular cartilage segmentation from conventional techniques to deep learning (DL) based techniques. Knee articular cartilage segmentation on magnetic resonance (MR) images is of great importance in early diagnosis of osteoarthritis (OA). Besides, segmentation allows estimating the articular cartilage loss rate which is utilised in clinical practice for assessing the disease progression and morphological changes. It has been traditionally applied in quantifying longitudinal knee OA progression pattern to detect and assess the articular cartilage thickness and volume. Topics covered include various image processing algorithms and major features of different segmentation techniques, feature computations and the performance evaluation metrics. This paper is intended to provide researchers with a broad overview of the currently existing methods in the field, as well as to highlight the shortcomings and potential considerations in the application at clinical practice. The survey showed that state-of-the-art techniques based on DL outperform the other segmentation methods . The analysis of the existing methods reveals that integration of DL-based algorithms with other traditional model-based approaches has achieved the best results (mean Dice similarity coefficient (DSC) between 85.8% and 90%).},
  archive      = {J_ARTMED},
  author       = {Somayeh Ebrahimkhani and Mohamed Hisham Jaward and Flavia M. Cicuttini and Anuja Dharmaratne and Yuanyuan Wang and Alba G. Seco de Herrera},
  doi          = {10.1016/j.artmed.2020.101851},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101851},
  shortjournal = {Artif. Intell. Med.},
  title        = {A review on segmentation of knee articular cartilage: From conventional methods towards deep learning},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CT window trainable neural network for improving
intracranial hemorrhage detection by combining multiple settings.
<em>ARTMED</em>, <em>106</em>, 101850. (<a
href="https://doi.org/10.1016/j.artmed.2020.101850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Window settings to rescale and contrast stretch raw data from radiographic images such as Computed Tomography (CT), X-ray and Magnetic Resonance images is a crucial step as data pre-processing to examine abnormalities and diagnose diseases. We propose a distant-supervised method for determining automatically the best window settings by attaching a window estimator module (WEM) to a deep convolutional neural network (DCNN)-based lesion classifier and training them in conjunction. Aside from predicting a flexible window setting for each raw image, we statistically identify the top four window settings by calculating the mean and standard deviations for the entire dataset. Images are scaled on each of the top settings estimated by WEM and following lesion classifiers are subsequently trained. We study the effects of only using the flexible window, the single fixed window as either a known default window used by radiologists or an estimated mean value, and two different approaches to combine results from the top window settings to improve the detection of intracranial hemorrhage (ICH) from brain CT images. Experimental results showed that using the top four window settings identified from the window estimator module and combining the results had the best performance.},
  archive      = {J_ARTMED},
  author       = {Manohar Karki and Junghwan Cho and Eunmi Lee and Myong-Hun Hahm and Sang-Youl Yoon and Myungsoo Kim and Jae-Yun Ahn and Jeongwoo Son and Shin-Hyung Park and Ki-Hong Kim and Sinyoul Park},
  doi          = {10.1016/j.artmed.2020.101850},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101850},
  shortjournal = {Artif. Intell. Med.},
  title        = {CT window trainable neural network for improving intracranial hemorrhage detection by combining multiple settings},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of myocardial infarction based on hybrid
feature extraction and artificial intelligence tools by adopting
tunable-q wavelet transform (TQWT), variational mode decomposition (VMD)
and neural networks. <em>ARTMED</em>, <em>106</em>, 101848. (<a
href="https://doi.org/10.1016/j.artmed.2020.101848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular diseases (CVD) is the leading cause of human mortality and morbidity around the world, in which myocardial infarction (MI) is a silent condition that irreversibly damages the heart muscles. Currently, electrocardiogram (ECG) is widely used by the clinicians to diagnose MI patients due to its inexpensiveness and non-invasive nature. Pathological alterations provoked by MI cause slow conduction by increasing axial resistance on coupling between cells. This issue may cause abnormal patterns in the dynamics of the tip of the cardiac vector in the ECG signals. However, manual interpretation of the pathological alternations induced by MI is a time-consuming, tedious and subjective task. To overcome such disadvantages, computer-aided diagnosis techniques including signal processing and artificial intelligence tools have been developed. In this study we propose a novel technique for automatic detection of MI based on hybrid feature extraction and artificial intelligence tools. Tunable quality factor ( Q Q -factor) wavelet transform (TQWT), variational mode decomposition (VMD) and phase space reconstruction (PSR) are utilized to extract representative features to form cardiac vectors with synthesis of the standard 12-lead and Frank XYZ leads. They are combined with neural networks to model, identify and detect abnormal patterns in the dynamics of cardiac system caused by MI. First, 12-lead ECG signals are reduced to 3-dimensional VCG signals, which are synthesized with Frank XYZ leads to build a hybrid 4-dimensional cardiac vector. Second, this vector is decomposed into a set of frequency subbands with a number of decomposition levels by using the TQWT method. Third, VMD is employed to decompose the subband of the 4-dimensional cardiac vector into different intrinsic modes, in which the first intrinsic mode contains the majority of the cardiac vector&#39;s energy and is considered to be the predominant intrinsic mode. It is selected to construct the reference variable for analysis. Fourth, phase space of the reference variable is reconstructed, in which the properties associated with the nonlinear cardiac system dynamics are preserved. Three-dimensional (3D) PSR together with Euclidean distance (ED) has been utilized to derive features, which demonstrate significant difference in cardiac system dynamics between normal (healthy) and MI cardiac vector signals. Fifth, cardiac system dynamics can be modeled and identified using neural networks, which employ the ED of 3D PSR of the reference variable as the input features. The difference of cardiac system dynamics between healthy control and MI cardiac vector is computed and used for the detection of MI based on a bank of estimators. Finally, data sets, which include conventional 12-lead and Frank XYZ leads ECG signal fragments from 148 patients with MI and 52 healthy controls from PTB diagnostic ECG database, are used for evaluation. By using the 10-fold cross-validation style, the achieved average classification accuracy is reported to be 97.98%. Currently, ST segment evaluation is one of the major and traditional ways for the MI detection. However, there exist weak or even undetectable ST segments in many ECG signals. Since the proposed method does not rely on the information of ST waves, it can serve as a complementary MI detection algorithm in the intensive care unit (ICU) of hospitals to assist the clinicians in confirming their diagnosis. Overall, our results verify that the proposed features may satisfactorily reflect cardiac system dynamics, and are complementary to the existing ECG features for automatic cardiac function analysis.},
  archive      = {J_ARTMED},
  author       = {Wei Zeng and Jian Yuan and Chengzhi Yuan and Qinghui Wang and Fenglin Liu and Ying Wang},
  doi          = {10.1016/j.artmed.2020.101848},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101848},
  shortjournal = {Artif. Intell. Med.},
  title        = {Classification of myocardial infarction based on hybrid feature extraction and artificial intelligence tools by adopting tunable-Q wavelet transform (TQWT), variational mode decomposition (VMD) and neural networks},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward development of PreVoid alerting system for nocturnal
enuresis patients: A fuzzy-based approach for determining the level of
liquid encased in urinary bladder. <em>ARTMED</em>, <em>106</em>,
101819. (<a href="https://doi.org/10.1016/j.artmed.2020.101819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preventive and accurate assessment of bladder voiding dysfunctions necessitates measuring the amount of liquid encapsulated within urinary bladder walls in a non-invasive and real-time manner. The real-time monitoring of urine levels helps patients with urological disorders such as Nocturnal Enuresis (NE) by preventing the occurrence of enuresis via a pre-void stage alerting system. Although some advances have been achieved toward developing a non-invasive approach for determining the amount of accumulated urine inside the bladder, there is still a lack of an easy-to-implement technique which is suitable to embed in a wearable pre-warning device. This study aims to develop a machine-learning empowered technique to quantify to what extent an individual&#39;s bladder is filled by observing the filling-voiding pattern of a patient over a training period. In this experiment, a pulse-echo sonar element is used to generate ultrasound pulses while the probe surface is positioned perpendicular to the bladder&#39;s position. From the reflected echoes, four features which show sufficient sensitiveness and therefore could be modulated noticeably by different levels of liquid encased in the bladder, are extracted. The extracted features are then fed into a novel intelligent decision support system– known as FECOC – which is based on hybridization of fuzzy inference systems (FIS) and error correcting output codes (ECOC). The proposed scheme tends to achieve better results when examined in real case studies.},
  archive      = {J_ARTMED},
  author       = {Mahdi Amina and Javad Yazdani and Stefano Rovetta and Francesco Masulli},
  doi          = {10.1016/j.artmed.2020.101819},
  journal      = {Artificial Intelligence in Medicine},
  month        = {6},
  pages        = {101819},
  shortjournal = {Artif. Intell. Med.},
  title        = {Toward development of PreVoid alerting system for nocturnal enuresis patients: A fuzzy-based approach for determining the level of liquid encased in urinary bladder},
  volume       = {106},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy inference model based on triaxial signals for
pronation and supination assessment in parkinson’s disease patients.
<em>ARTMED</em>, <em>105</em>, 101873. (<a
href="https://doi.org/10.1016/j.artmed.2020.101873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the Unified Parkinson Disease Rating Scale supported by the Movement Disorder Society (MDS-UPDRS), is a standardized and widely accepted instrument to rate Parkinson’s disease (PD). This work presents a thorough analysis of item 3.6 of the MDS-UPDRS scale which corresponds to the pronation and supination hand movements. The motivation for this work lies in the objective quantification of motor affectations not covered by the MDS-UPDRS scale such as unsteady oscillations and velocity decrements during the motor exploration. Overall, 12 different bio-mechanical features were quantified based on measurements performed by inertial measurement units (IMUs). After a feature selection process, the selected bio-mechanical features were used as inputs for a fuzzy inference model that predicts the stage of development of the disease in each patient. In addition to this model’s output, the scores of three different expert examiners and the output of a fuzzy inference model which covers affectations strictly attached the MDS-UPDRS guidelines, were also considered to obtain an integrated computational model. The proposed integrated model was incorporated using the Analytic Hierarchy Process (AHP), which gives the novelty of a combined score that helps expert examiners to give a broader assessment of the disease that covers both affectations mentioned in the MDS-UPDRS guidelines and affectations not covered by it in an objective manner.},
  archive      = {J_ARTMED},
  author       = {Alejandro Garza-Rodríguez and Luis Pastor Sánchez-Fernández and Luis Alejandro Sánchez-Pérez and José Juan Carbajal Hernández},
  doi          = {10.1016/j.artmed.2020.101873},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101873},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fuzzy inference model based on triaxial signals for pronation and supination assessment in parkinson’s disease patients},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep neural network for semi-automatic classification of
term and preterm uterine recordings. <em>ARTMED</em>, <em>105</em>,
101861. (<a href="https://doi.org/10.1016/j.artmed.2020.101861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pregnancy is a complex process, and the prediction of premature birth is uncertain. Many researchers are exploring non-invasive approaches to enhance its predictability. Currently, the ElectroHysteroGram (EHG) and Tocography (TOCO) signal are a real-time and non-invasive technology which can be employed to predict preterm birth. For this purpose, sparse autoencoder (SAE) based deep neural network (SAE-based DNN) is developed. The deep neural network has three layers including a stacked sparse autoencoder (SSAE) network with two hidden layers and one final softmax layer. To this end, the bursts of all 26 recordings of the publicly available TPEHGT DS database corresponding to uterine contraction intervals and non-contraction intervals (dummy intervals) were manually segmented. 20 features were extracted by two feature extraction algorithms including sample entropy and wavelet entropy. Afterwards, the SSAE network is adopted to learn high-level features from raw features by unsupervised learning. The softmax layer is added at the top of the SSAE network for classification. In order to verify the effectiveness of the proposed method, this study used 10-fold cross-validation and four indicators to evaluate classification performance. Experimental research results display that the performance of deep neural network can achieve Sensitivity of 98.2%, Specificity of 97.74%, and Accuracy of 97.9% in the publicly TPEHGT DS database. The performance of deep neural network outperforms the comparison models including deep belief networks (DBN) and hierarchical extreme learning machine (H-ELM). Finally, experimental research results reveal that the proposed method could be valid applied to semi-automatic identification of term and preterm uterine recordings.},
  archive      = {J_ARTMED},
  author       = {Lili Chen and Huoyao Xu},
  doi          = {10.1016/j.artmed.2020.101861},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101861},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep neural network for semi-automatic classification of term and preterm uterine recordings},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconstructing the patient’s natural history from electronic
health records. <em>ARTMED</em>, <em>105</em>, 101860. (<a
href="https://doi.org/10.1016/j.artmed.2020.101860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic extraction of a patient’s natural history from Electronic Health Records (EHRs) is a critical step towards building intelligent systems that can reason about clinical variables and support decision making. Although EHRs contain a large amount of valuable information about the patient’s medical care, this information can only be fully understood when analyzed in a temporal context. Any intelligent system should then be able to extract medical concepts, date expressions, temporal relations and the temporal ordering of medical events from the free texts of EHRs; yet, this task is hard to tackle, due to the domain specific nature of EHRs, writing quality and lack of structure of these texts, and more generally the presence of redundant information. In this paper, we introduce a new Natural Language Processing (NLP) framework, capable of extracting the aforementioned elements from EHRs written in Spanish using rule-based methods. We focus on building medical timelines, which include disease diagnosis and its progression over time. By using a large dataset of EHRs comprising information about patients suffering from lung cancer, we show that our framework has an adequate level of performance by correctly building the timeline for 843 patients from a pool of 989 patients, achieving a precision of 0.852.},
  archive      = {J_ARTMED},
  author       = {Marjan Najafabadipour and Massimiliano Zanin and Alejandro Rodríguez-González and Maria Torrente and Beatriz Nuñez García and Juan Luis Cruz Bermudez and Mariano Provencio and Ernestina Menasalvas},
  doi          = {10.1016/j.artmed.2020.101860},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101860},
  shortjournal = {Artif. Intell. Med.},
  title        = {Reconstructing the patient’s natural history from electronic health records},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining incomplete clinical data for the early assessment of
kawasaki disease based on feature clustering and convolutional neural
networks. <em>ARTMED</em>, <em>105</em>, 101859. (<a
href="https://doi.org/10.1016/j.artmed.2020.101859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kawasaki disease (KD) is the leading cause of acquired heart disease in children. Its prompt treatment can effectively lower the risk of severe complications, such as coronary aneurysms. However, accurately diagnosing KD at its early stage is impracticable given its unknown pathogenesis and lack of pathognomonic features. In this study, we investigated data-driven approaches by using a cohort of 10,367 patients extracted from electronic health records for early KD assessment. The incompleteness of clinical data presents group-based missing patterns associated with different clinical assessment measures. To address this problem, we developed a method integrating feature clustering to enable matrix-based representation and convolutional neural networks (CNN) for feature extraction and fusion to explicitly exploit the multi-source data structure. Integrating missing data imputation methods with the proposed method demonstrated superior accuracy (an AUC of 0.97) compared with a number of benchmark methods. The present method shows potential to improve clinical data mining. Our study highlighted the feasible utilization of matrix-based feature representation and CNN-based feature extraction for incomplete clinical data mining to support medical decision-making.},
  archive      = {J_ARTMED},
  author       = {Haolin Wang and Xuhai Tan and Zhilin Huang and Bo Pan and Jie Tian},
  doi          = {10.1016/j.artmed.2020.101859},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101859},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining incomplete clinical data for the early assessment of kawasaki disease based on feature clustering and convolutional neural networks},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining post-surgical care processes in breast cancer
patients. <em>ARTMED</em>, <em>105</em>, 101855. (<a
href="https://doi.org/10.1016/j.artmed.2020.101855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we describe the application of a careflow mining algorithm to detect the most frequent patterns of care in a cohort of 3000 breast cancer patients. The applied method relies on longitudinal data extracted from electronic health records, recorded from the first surgical procedure after a breast cancer diagnosis. Careflows are mined from events data recorded for administrative purposes, including procedures from ICD9 – CM billing codes and chemotherapy treatments. Events data have been pre-processed with Topic Modelling to create composite events based on concurrent procedures. The results of the careflow mining algorithm allow the discovery of electronic temporal phenotypes across the studied population. These phenotypes are further characterized on the basis of clinical traits and tumour histopathology, as well as in terms of relapses, metastasis occurrence and 5-year survival rates. Results are highly significant from a clinical perspective, since phenotypes describe well characterized pathology classes, and the careflows are well matched with existing clinical guidelines. The analysis thus facilitates deriving real-world evidence that can inform clinicians as well as hospital decision makers.},
  archive      = {J_ARTMED},
  author       = {Lorenzo Chiudinelli and Arianna Dagliati and Valentina Tibollo and Sara Albasini and Nophar Geifman and Niels Peek and John H. Holmes and Fabio Corsi and Riccardo Bellazzi and Lucia Sacchi},
  doi          = {10.1016/j.artmed.2020.101855},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101855},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mining post-surgical care processes in breast cancer patients},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Personalized risk prediction for breast cancer pre-screening
using artificial intelligence and thermal radiomics. <em>ARTMED</em>,
<em>105</em>, 101854. (<a
href="https://doi.org/10.1016/j.artmed.2020.101854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the leading cause of cancer deaths among women today. Survival rates in developing countries are around 50%–60% due to late detection. A personalized, accurate risk scoring method can help in targeting the right population for follow-up tests and enables early detection of breast abnormalities. Most of the available risk assessment tools use generic and weakly correlated features like age, weight, height etc. While a personalized risk scoring from screening modalities such as mammography and ultrasound could be helpful, these tests are limited to very few metropolitan hospitals in developing countries due to high capital cost, operational expenses and interpretation expertise needed for a large screening population. We propose and analyze a new personalized risk framework called Thermalytix Risk Score (TRS) to identify a high-risk target population for regular screening and enable early stage breast cancer detection at scale. This technique uses Artificial Intelligence (AI) over thermal images to automatically generate a breast health risk score. This risk score is mainly derived from two sub-scores namely, vascular score and hotspot score. A hotspot score signifies the abnormality seen from irregular asymmetric heat patterns seen on the skin surface, whereas vascular score predicts the presence of asymmetric vascular activity. These scores are generated using machine learning algorithms over medically interpretable parameters that describes the metabolic activity inside the breast tissue and indicate the presence of a possible malignancy even in asymptomatic women. The proposed personalized risk score was tested on 769 subjects in four breast cancer screening facilities. The subjects’ age ranged from 18 to 82 years with a median of around 45 years. Out of the 769 subjects, 185 subjects were diagnosed with a breast malignancy by an expert radiologist after mammography, ultrasound and/or histopathology. Our personalized AI based risk score achieved an area under the receiver-operator curve (AUC) of 0.89 when compared to an age normalized risk score that showed an AUC of 0.68. We also found that if the computed risk score is used to place individuals into four risk groups, the likelihood of malignancy also increases monotonically with the risk grouping level. The proposed AI based personalized risk score uses breast thermal image patterns for risk computation and compares favorably to other generic risk estimation approaches. The proposed risk framework solution is automated, affordable, non-invasive, non-contact and radiation free and works for a wide age range of women from 18 to 82 years, including young women with dense breasts. The proposed score might be further used to assign subjects into one of the four risk groups and provide guidance on the periodicity of screening needed. In addition, the automatically annotated thermal images localizes the potential abnormal regions and might empower the physician to create a better personalized care.},
  archive      = {J_ARTMED},
  author       = {Siva Teja Kakileti and Himanshu J. Madhu and Geetha Manjunath and Leonard Wee and Andre Dekker and Sudhakar Sampangi},
  doi          = {10.1016/j.artmed.2020.101854},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101854},
  shortjournal = {Artif. Intell. Med.},
  title        = {Personalized risk prediction for breast cancer pre-screening using artificial intelligence and thermal radiomics},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the use of pairwise distance learning for brain signal
classification with limited observations. <em>ARTMED</em>, <em>105</em>,
101852. (<a href="https://doi.org/10.1016/j.artmed.2020.101852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing access to brain signal data using electroencephalography creates new opportunities to study electrophysiological brain activity and perform ambulatory diagnoses of neurological disorders. This work proposes a pairwise distance learning approach for schizophrenia classification relying on the spectral properties of the signal. To be able to handle clinical trials with a limited number of observations (i.e. case and/or control individuals), we propose a Siamese neural network architecture to learn a discriminative feature space from pairwise combinations of observations per channel. In this way, the multivariate order of the signal is used as a form of data augmentation, further supporting the network generalization ability. Convolutional layers with parameters learned under a cosine contrastive loss are proposed to adequately explore spectral images derived from the brain signal. The proposed approach for schizophrenia diagnostic was tested on reference clinical trial data under resting-state protocol, achieving 0.95 ± 0.05 accuracy, 0.98 ± 0.02 sensitivity and 0.92 ± 0.07 specificity. Results show that the features extracted using the proposed neural network are remarkably superior than baselines to diagnose schizophrenia (+20pp in accuracy and sensitivity), suggesting the existence of non-trivial electrophysiological brain patterns able to capture discriminative neuroplasticity profiles among individuals. The code is available on Github: https://github.com/DCalhas/siamese_schizophrenia_eeg .},
  archive      = {J_ARTMED},
  author       = {David Calhas and Enrique Romero and Rui Henriques},
  doi          = {10.1016/j.artmed.2020.101852},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101852},
  shortjournal = {Artif. Intell. Med.},
  title        = {On the use of pairwise distance learning for brain signal classification with limited observations},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic segmentation of knee menisci – a systematic
review. <em>ARTMED</em>, <em>105</em>, 101849. (<a
href="https://doi.org/10.1016/j.artmed.2020.101849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) has proved to be an invaluable component of pathogenesis research in osteoarthritis. Nevertheless, the detection of a meniscal lesion from magnetic resonance (MR) images is always challenging for both clinicians and researchers, because the surrounding tissues lead to similar signals within MR measurements, thus being difficult to discriminate. Moreover, the size and shape of osteoarthritic and non-osteoarthritic menisci vary to a large extent between individuals of same features, e.g. height, weight, age, etc. An effective way to visualize the entire volume of knee menisci is to segment the menisci voxels from the MR images, which is also useful to evaluate particular properties quantitatively. However, segmentation is a tedious and time-consuming task, and requires adequate training for being done properly. With the advancement of both MRI technology and computer methods, researchers have developed several algorithms to automate the task of meniscus segmentation of the individual knee during the last two decades. The objective of this systematic review was to present available fully automatic and semi-automatic segmentation methods of the knee meniscus published in different scientific articles according to the PRISMA statement. This review should provide a vivid description of the scientific advancements to clinicians and researchers in this field to help developing novel automated methods for clinical applications.},
  archive      = {J_ARTMED},
  author       = {Muhammed Masudur Rahman and Lutz Dürselen and Andreas Martin Seitz},
  doi          = {10.1016/j.artmed.2020.101849},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101849},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic segmentation of knee menisci – a systematic review},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Early temporal prediction of type 2 diabetes risk condition
from a general practitioner electronic health record: A multiple
instance boosting approach. <em>ARTMED</em>, <em>105</em>, 101847. (<a
href="https://doi.org/10.1016/j.artmed.2020.101847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early prediction of target patients at high risk of developing Type 2 diabetes (T2D) plays a significant role in preventing the onset of overt disease and its associated comorbidities. Although fundamental in early phases of T2D natural history, insulin resistance is not usually quantified by General Practitioners (GPs). Triglyceride-glucose (TyG) index has been proven useful in clinical studies for quantifying insulin resistance and for the early identification of individuals at T2D risk but still not applied by GPs for diagnostic purposes. The aim of this study is to propose a multiple instance learning boosting algorithm (MIL-Boost) for creating a predictive model capable of early prediction of worsening insulin resistance (low vs high T2D risk) in terms of TyG index. The MIL-Boost is applied to past electronic health record (EHR) patients’ information stored by a single GP. The proposed MIL-Boost algorithm proved to be effective in dealing with this task, by performing better than the other state-of-the-art ML competitors ( Recall from 0.70 and up to 0.83). The proposed MIL-based approach is able to extract hidden patterns from past EHR temporal data, even not directly exploiting triglycerides and glucose measurements. The major advantages of our method can be found in its ability to model the temporal evolution of longitudinal EHR data while dealing with small sample size and variability in the observations (e.g., a small variable number of prescriptions for non-hospitalized patients). The proposed algorithm may represent the main core of a clinical decision support system .},
  archive      = {J_ARTMED},
  author       = {Michele Bernardini and Micaela Morettini and Luca Romeo and Emanuele Frontoni and Laura Burattini},
  doi          = {10.1016/j.artmed.2020.101847},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101847},
  shortjournal = {Artif. Intell. Med.},
  title        = {Early temporal prediction of type 2 diabetes risk condition from a general practitioner electronic health record: A multiple instance boosting approach},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vessel structure extraction using constrained minimal path
propagation. <em>ARTMED</em>, <em>105</em>, 101846. (<a
href="https://doi.org/10.1016/j.artmed.2020.101846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimal path method has been widely recognized as an efficient tool for extracting vascular structures in medical imaging. In a previous paper, a method termed minimal path propagation with backtracking (MPP-BT) was derived to deal with curve-like structures such as vessel centerlines. A robust approach termed CMPP (constrained minimal path propagation) is here proposed to extend this work. The proposed method utilizes another minimal path propagation procedure to extract the complete vessel lumen after the centerlines have been found. Moreover, a process named local MPP-BT is applied to handle structure missing caused by the so-called close loop problems. This approach is fast and unsupervised with only one roughly set start point required in the whole process to get the entire vascular structure. A variety of datasets, including 2D cardiac angiography, 2D retinal images and 3D kidney CT angiography, are used for validation. A quantitative evaluation, together with a comparison to recently reported methods, is performed on retinal images for which a ground truth is available. The proposed method leads to specificity (Sp) and sensitivity (Se) values equal to 0.9750 and 0.6591. This evaluation is also extended to 3D synthetic vascular datasets and shows that the specificity (Sp) and sensitivity (Se) values are higher than 0.99. Parameter setting and computation cost are analyzed in this paper.},
  archive      = {J_ARTMED},
  author       = {Guanyu Yang and Tianling Lv and Yunpeng Shen and Shuo Li and Jian Yang and Yang Chen and Huazhong Shu and Limin Luo and Jean-Louis Coatrieux},
  doi          = {10.1016/j.artmed.2020.101846},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101846},
  shortjournal = {Artif. Intell. Med.},
  title        = {Vessel structure extraction using constrained minimal path propagation},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Breast cancer diagnosis from histopathological images using
textural features and CBIR. <em>ARTMED</em>, <em>105</em>, 101845. (<a
href="https://doi.org/10.1016/j.artmed.2020.101845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, breast cancer diagnosis is an extensively researched topic. An effective method to diagnose breast cancer is to use histopathological images. However, extracting features from these images is a challenging task. Thus, we propose a method that uses phylogenetic diversity indexes to characterize images for creating a model to classify histopathological breast images into four classes – invasive carcinoma, in situ carcinoma, normal tissue, and benign lesion. The classifiers used were the most robust ones according to the existing literature: XGBoost, random forest, multilayer perceptron, and support vector machine. Moreover, we performed content-based image retrieval to confirm the classification results and suggest a ranking for sets of images that were not labeled. The results obtained were considerably robust and proved to be effective for the composition of a CADx system to help specialists at large medical centers.},
  archive      = {J_ARTMED},
  author       = {Edson D. Carvalho and Antônio O.C. Filho and Romuere R.V. Silva and Flávio H.D. Araújo and João O.B. Diniz and Aristófanes C. Silva and Anselmo C. Paiva and Marcelo Gattass},
  doi          = {10.1016/j.artmed.2020.101845},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101845},
  shortjournal = {Artif. Intell. Med.},
  title        = {Breast cancer diagnosis from histopathological images using textural features and CBIR},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy support vector machine-based personalizing method to
address the inter-subject variance problem of physiological signals in a
driver monitoring system. <em>ARTMED</em>, <em>105</em>, 101843. (<a
href="https://doi.org/10.1016/j.artmed.2020.101843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiological signals can be utilized to monitor conditions of a driver, but the inter-subject variance of physiological signals can degrade the classification accuracy of the monitoring system. Personalization of the system using the data of a tested subject, called local data, can be a solution, but the acquisition of sufficient local data may not be possible in real situations. Therefore, this paper proposes an effective personalizing method using small-sized local data. The proposed method utilizes a fuzzy support vector machine to allocate higher weight to the local data than to others, and a fuzzy membership is assigned to the training data by analyzing the importance of each datum. Three classification problems for a physiological signal-based driver monitoring system are introduced and utilized to validate the proposed method. The classification accuracy is compared with that of other personalizing methods, and the results show that the proposed method achieves a better accuracy on average, which is 3.46% higher than that of the simple approach using a basic support vector machine , thereby proving its effectiveness. The proposed method can train a personalized classifier with improved accuracy for a tested subject. The advantages of the proposed method can be utilized to develop a practical driver monitoring system.},
  archive      = {J_ARTMED},
  author       = {Minho Choi and Minseok Seo and Jun Seong Lee and Sang Woo Kim},
  doi          = {10.1016/j.artmed.2020.101843},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101843},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fuzzy support vector machine-based personalizing method to address the inter-subject variance problem of physiological signals in a driver monitoring system},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explainable AI meets persuasiveness: Translating reasoning
results into behavioral change advice. <em>ARTMED</em>, <em>105</em>,
101840. (<a href="https://doi.org/10.1016/j.artmed.2020.101840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable AI aims at building intelligent systems that are able to provide a clear, and human understandable, justification of their decisions. This holds for both rule-based and data-driven methods. In management of chronic diseases, the users of such systems are patients that follow strict dietary rules to manage such diseases. After receiving the input of the intake food, the system performs reasoning to understand whether the users follow an unhealthy behavior. Successively, the system has to communicate the results in a clear and effective way, that is, the output message has to persuade users to follow the right dietary rules. In this paper, we address the main challenges to build such systems: (i) the Natural Language Generation of messages that explain the reasoner inconsistency; and, (ii) the effectiveness of such messages at persuading the users. Results prove that the persuasive explanations are able to reduce the unhealthy users’ behaviors.},
  archive      = {J_ARTMED},
  author       = {Mauro Dragoni and Ivan Donadello and Claudio Eccher},
  doi          = {10.1016/j.artmed.2020.101840},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {101840},
  shortjournal = {Artif. Intell. Med.},
  title        = {Explainable AI meets persuasiveness: Translating reasoning results into behavioral change advice},
  volume       = {105},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computerized decision support and machine learning
applications for the prevention and treatment of childhood obesity: A
systematic review of the literature. <em>ARTMED</em>, <em>104</em>,
101844. (<a href="https://doi.org/10.1016/j.artmed.2020.101844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital health interventions based on tools for Computerized Decision Support (CDS) and Machine Learning (ML), which take advantage of new information, sensing and communication technologies, can play a key role in childhood obesity prevention and treatment. We present a systematic literature review of CDS and ML applications for the prevention and treatment of childhood obesity. The main characteristics and outcomes of studies using CDS and ML are demonstrated, to advance our understanding towards the development of smart and effective interventions for childhood obesity care. A search in the bibliographic databases of PubMed and Scopus was performed to identify childhood obesity studies incorporating either CDS interventions, or advanced data analytics through ML algorithms. Ongoing, case, and qualitative studies, along with those not providing specific quantitative outcomes were excluded. The studies incorporating CDS were synthesized according to the intervention’s main technology (e.g., mobile app), design type (e.g., randomized controlled trial), number of enrolled participants, target age of children, participants’ follow-up duration, primary outcome (e.g., Body Mass Index (BMI)), and main CDS feature(s) and their outcomes (e.g., alerts for caregivers when BMI is high). The studies incorporating ML were synthesized according to the number of subjects included and their age, the ML algorithm(s) used (e.g., logistic regression), as well as their main outcome (e.g., prediction of obesity). The literature search identified 8 studies incorporating CDS interventions and 9 studies utilizing ML algorithms, which met our eligibility criteria. All studies reported statistically significant interventional or ML model outcomes (e.g., in terms of accuracy). More than half of the interventional studies (n = 5, 63 %) were designed as randomized controlled trials. Half of the interventional studies (n = 4, 50 %) utilized Electronic Health Records (EHRs) and alerts for BMI as means of CDS. From the 9 studies using ML, the highest percentage targeted at the prognosis of obesity (n = 4, 44 %). In the studies incorporating more than one ML algorithms and reporting accuracy, it was shown that decision trees and artificial neural networks can accurately predict childhood obesity. This review has found that CDS tools can be useful for the self-management or remote medical management of childhood obesity, whereas ML algorithms such as decision trees and artificial neural networks can be helpful for prediction purposes. Further rigorous studies in the area of CDS and ML for childhood obesity care are needed, considering the low number of studies identified in this review, their methodological limitations, and the scarcity of interventional studies incorporating ML algorithms in CDS tools.},
  archive      = {J_ARTMED},
  author       = {Andreas Triantafyllidis and Eleftheria Polychronidou and Anastasios Alexiadis and Cleilton Lima Rocha and Douglas Nogueira Oliveira and Amanda S. da Silva and Ananda Lima Freire and Crislanio Macedo and Igor Farias Sousa and Eriko Werbet and Elena Arredondo Lillo and Henar González Luengo and Macarena Torrego Ellacuría and Konstantinos Votis and Dimitrios Tzovaras},
  doi          = {10.1016/j.artmed.2020.101844},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101844},
  shortjournal = {Artif. Intell. Med.},
  title        = {Computerized decision support and machine learning applications for the prevention and treatment of childhood obesity: A systematic review of the literature},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and processing up-to-dateness of patient
information in probabilistic therapy decision support. <em>ARTMED</em>,
<em>104</em>, 101842. (<a
href="https://doi.org/10.1016/j.artmed.2020.101842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic modeling of a patient&#39;s situation with the goal of providing calculated therapy recommendations can improve the decision making of interdisciplinary teams. Relevant information entities and direct causal dependencies, as well as uncertainty, must be formally described. Possible therapy options, tailored to the patient, can be inferred from the clinical data using these descriptions. However, there are several avoidable factors of uncertainty influencing the accuracy of the inference. For instance, inaccuracy may emerge from outdated information. In general, probabilistic models, e.g. Bayesian Networks can depict the causality and relations of individual information entities, but in general cannot evaluate individual entities concerning their up-to-dateness. The goal of the work at hand is to model diagnostic up-to-dateness, which can reasonably adjust the influence of outdated diagnostic information to improve the inference results of clinical decision models. We analyzed 68 laryngeal cancer cases and modeled the state of up-to-dateness of different diagnostic modalities. All cases were used for cross-validation. 55 cases were used to train the model, 13 for testing. Each diagnostic procedure involved in the decision making process of these cases was associated with a specific threshold for the time the information is considered up-to-date, i.e. reliable. Based on this threshold, outdated findings could be identified and their impact on probabilistic calculations could be reduced. We applied the model for reducing the weight of outdated patient data in the computation of TNM stagings for the 13 test cases and compared the results to the manually derived TNM stagings in the patient files. With the implementation of these weights in the laryngeal cancer model, we increased the accuracy of the TNM calculation from 0.61 (8 out of 13 cases correct) to 0.76 (10 out of 13 cases correct). Decision delay may cause specific patient data to be outdated. This can cause contradictory or false information and impair calculations for clinical decision support. Our approach demonstrates that the accuracy of Bayesian Network models can be improved when pre-processing the patient-specific data and evaluating their up-to-dateness with reduced weights on outdated information.},
  archive      = {J_ARTMED},
  author       = {Jan Gaebel and Hans-Georg Wu and Alexander Oeser and Mario A Cypko and Matthaeus Stoehr and Andreas Dietz and Thomas Neumuth and Stefan Franke and Steffen Oeltze-Jafra},
  doi          = {10.1016/j.artmed.2020.101842},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101842},
  shortjournal = {Artif. Intell. Med.},
  title        = {Modeling and processing up-to-dateness of patient information in probabilistic therapy decision support},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterizing the critical features when personalizing
antihypertensive drugs using spectrum analysis and machine learning
methods. <em>ARTMED</em>, <em>104</em>, 101841. (<a
href="https://doi.org/10.1016/j.artmed.2020.101841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Globally, methods of controlling blood pressure in hypertension patients remain inefficient. The difficulty of prescribing appropriate drugs specific to a patient’s clinical features serves as one of the most important factors. Characterizing the critical drug-related features, just like that of the antibacterial spectrum (where each item is sensitive to the targeted drug’s effectiveness or a specified indication), may help a doctor easily prescribe appropriate drugs by matching a patient’s attributes with drug-related features, and effectiveness of the selected drugs would also be ascertained. In this study, we aimed to apply data mining methods to obtain the clinical characteristics spectrum or important clinical features of five frequently used drugs (Irbesartan, Metoprolol , Felodipine , Amlodipine , and Levamlodipine) for hypertension control by comparing successful and unsuccessful cases. Spectrum analysis based on a statistical method and five algorithms based on machine learning were used to extract the critical clinical features. A visualized relative weight matrix was then achieved by combining the results from the characteristic spectrum and machine learning-based methods. Our results indicated that the five targeted antihypertension agents had different importance orders of the 15 relative clinical features. Clinical analysis showed that the extracted important clinical attributes of the five drugs were both reasonable and meaningful in the selection of hypertension treatment. Therefore, our study provided a data-driven reference for the personalization of clinical antihypertensive drugs.},
  archive      = {J_ARTMED},
  author       = {Liu Chunyu and Liu Ran and Zhou Junteng and Wang Miye and Xu Jing and Su Lan and Zuo Yixuan and Zhang Rui and Feng Yizhou and Wang Chen and Yan Hongmei and Zhang Qing},
  doi          = {10.1016/j.artmed.2020.101841},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101841},
  shortjournal = {Artif. Intell. Med.},
  title        = {Characterizing the critical features when personalizing antihypertensive drugs using spectrum analysis and machine learning methods},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting potential signals of adverse drug events from
prescription data. <em>ARTMED</em>, <em>104</em>, 101839. (<a
href="https://doi.org/10.1016/j.artmed.2020.101839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse drug events (ADEs) may occur and lead to severe consequences for the public, even though clinical trials are conducted in the stage of pre-market. Computational methods are still needed to fulfil the task of pharmacosurveillance. In post-market surveillance, the spontaneous reporting system (SRS) has been widely used to detect suspicious associations between medicines and ADEs. However, the passive mechanism of SRS leads to the hysteresis in ADE detection by SRS based methods, not mentioning the acknowledged problem of under-reporting and duplicate reporting in SRS. Therefore, there is a growing demand for other complementary methods utilising different types of healthcare data to assist with global pharmacosurveillance. Among those data sources, prescription data is of proved usefulness for pharmacosurveillance. However, few works have used prescription data for signalling ADEs. In this paper, we propose a data-driven method to discover medicines that are responsible for a given ADE purely from prescription data. Our method uses a logistic regression model to evaluate the associations between up to hundreds of suspected medicines and an ADE spontaneously and selects the medicines possessing the most significant associations via Lasso regularisation. To prepare data for training the logistic regression model, we adapt the design of the case-crossover study to construct case time and control time windows for the extraction of medicine use information. While the case time window can be readily determined, we propose several criteria to select the suitable control time windows providing the maximum power of comparisons. In order to address confounding situations, we have considered diverse factors in medicine utilisation in terms of the temporal effect of medicine and the frequency of prescription, as well as the individual effect of patients on the occurrence of an ADE. To assess the performance of the proposed method, we conducted a case study with a real-world prescription dataset. Validated by the existing domain knowledge, our method successfully traced a wide range of medicines that are potentially responsible for the ADE. Further experiments were also carried out according to a recognised gold standard, our method achieved a sensitivity of 65.9% and specificity of 96.2%.},
  archive      = {J_ARTMED},
  author       = {Chen Zhan and Elizabeth Roughead and Lin Liu and Nicole Pratt and Jiuyong Li},
  doi          = {10.1016/j.artmed.2020.101839},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101839},
  shortjournal = {Artif. Intell. Med.},
  title        = {Detecting potential signals of adverse drug events from prescription data},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A neutrosophic-entropy based adaptive thresholding
segmentation algorithm: A special application in MR images of
parkinson’s disease. <em>ARTMED</em>, <em>104</em>, 101838. (<a
href="https://doi.org/10.1016/j.artmed.2020.101838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain MR images are composed of three main regions such as gray matter, white matter and cerebrospinal fluid. Radiologists and medical practitioners make decisions through evaluating the developments in these regions. Study of these MR images suffers from two major issues such as: (a) the boundaries of their gray matter and white matter regions are ambiguous and unclear in nature, and (b) their regions are formed with unclear inhomogeneous gray structures. These two issues make the diagnosis of critical diseases very complex. To solve these issues, this study presented a method of image segmentation based on the neutrosophic set (NS) theory and neutrosophic entropy information (NEI). By nature, the proposed method is adaptive to select the threshold value and is entitled as neutrosophic-entropy based adaptive thresholding segmentation algorithm (NEATSA) . In this study, experimental results were provided through the segmentation of Parkinson&#39;s disease (PD) MR images. Experimental results, including statistical analyses showed that NEATSA can segment the main regions of MR images very clearly compared to the well-known methods of image segmentation available in literature of pattern recognition and computer vision domains.},
  archive      = {J_ARTMED},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.artmed.2020.101838},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101838},
  shortjournal = {Artif. Intell. Med.},
  title        = {A neutrosophic-entropy based adaptive thresholding segmentation algorithm: A special application in MR images of parkinson&#39;s disease},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Offline identification of surgical deviations in
laparoscopic rectopexy. <em>ARTMED</em>, <em>104</em>, 101837. (<a
href="https://doi.org/10.1016/j.artmed.2020.101837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to a meta-analysis of 7 studies, the median number of patients with at least one adverse event during the surgery is 14.4%, and a third of those adverse events were preventable. The occurrence of adverse events forces surgeons to implement corrective strategies and, thus, deviate from the standard surgical process . Therefore, it is clear that the automatic identification of adverse events is a major challenge for patient safety . In this paper, we have proposed a method enabling us to identify such deviations. We have focused on identifying surgeons’ deviations from standard surgical processes due to surgical events rather than anatomic specificities. This is particularly challenging, given the high variability in typical surgical procedure workflows. We have introduced a new approach designed to automatically detect and distinguish surgical process deviations based on multi-dimensional non-linear temporal scaling with a hidden semi-Markov model using manual annotation of surgical processes. The approach was then evaluated using cross-validation. The best results have over 90% accuracy. Recall and precision for event deviations, i.e. related to adverse events, are respectively below 80% and 40%. To understand these results, we have provided a detailed analysis of the incorrectly-detected observations. Multi-dimensional non-linear temporal scaling with a hidden semi-Markov model provides promising results for detecting deviations. Our error analysis of the incorrectly-detected observations offers different leads in order to further improve our method. Our method demonstrated the feasibility of automatically detecting surgical deviations that could be implemented for both skill analysis and developing situation awareness-based computer-assisted surgical systems.},
  archive      = {J_ARTMED},
  author       = {Arnaud Huaulmé and Pierre Jannin and Fabian Reche and Jean-Luc Faucheron and Alexandre Moreau-Gaudry and Sandrine Voros},
  doi          = {10.1016/j.artmed.2020.101837},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101837},
  shortjournal = {Artif. Intell. Med.},
  title        = {Offline identification of surgical deviations in laparoscopic rectopexy},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reinforcement learning application in diabetes blood glucose
control: A systematic review. <em>ARTMED</em>, <em>104</em>, 101836. (<a
href="https://doi.org/10.1016/j.artmed.2020.101836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is a computational approach to understanding and automating goal-directed learning and decision-making. It is designed for problems which include a learning agent interacting with its environment to achieve a goal. For example, blood glucose (BG) control in diabetes mellitus (DM), where the learning agent and its environment are the controller and the body of the patient respectively. RL algorithms could be used to design a fully closed-loop controller, providing a truly personalized insulin dosage regimen based exclusively on the patient’s own data. In this review we aim to evaluate state-of-the-art RL approaches to designing BG control algorithms in DM patients, reporting successfully implemented RL algorithms in closed-loop, insulin infusion, decision support and personalized feedback in the context of DM. An exhaustive literature search was performed using different online databases, analyzing the literature from 1990 to 2019. In a first stage, a set of selection criteria were established in order to select the most relevant papers according to the title, keywords and abstract. Research questions were established and answered in a second stage, using the information extracted from the articles selected during the preliminary selection. The initial search using title, keywords, and abstracts resulted in a total of 404 articles. After removal of duplicates from the record, 347 articles remained. An independent analysis and screening of the records against our inclusion and exclusion criteria defined in Methods section resulted in removal of 296 articles, leaving 51 relevant articles. A full-text assessment was conducted on the remaining relevant articles, which resulted in 29 relevant articles that were critically analyzed. The inter-rater agreement was measured using Cohen Kappa test, and disagreements were resolved through discussion. The advances in health technologies and mobile devices have facilitated the implementation of RL algorithms for optimal glycemic regulation in diabetes. However, there exists few articles in the literature focused on the application of these algorithms to the BG regulation problem. Moreover, such algorithms are designed for control tasks as BG adjustment and their use have increased recently in the diabetes research area, therefore we foresee RL algorithms will be used more frequently for BG control in the coming years. Furthermore, in the literature there is a lack of focus on aspects that influence BG level such as meal intakes and physical activity (PA), which should be included in the control problem. Finally, there exists a need to perform clinical validation of the algorithms.},
  archive      = {J_ARTMED},
  author       = {Miguel Tejedor and Ashenafi Zebene Woldaregay and Fred Godtliebsen},
  doi          = {10.1016/j.artmed.2020.101836},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101836},
  shortjournal = {Artif. Intell. Med.},
  title        = {Reinforcement learning application in diabetes blood glucose control: A systematic review},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wearable sensor-based evaluation of psychosocial stress in
patients with metabolic syndrome. <em>ARTMED</em>, <em>104</em>, 101824.
(<a href="https://doi.org/10.1016/j.artmed.2020.101824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of metabolic disorders has increased rapidly as such they become a major health issue recently. Despite the definition of genetic associations with obesity and cardiovascular diseases, they constitute only a small part of the incidence of disease. Environmental and physiological effects such as stress, behavioral and metabolic disturbances, infections, and nutritional deficiencies have now revealed as contributing factors to develop metabolic diseases. This study presents a multivariate methodology for the modeling of stress on metabolic syndrome (MES) patients. We have developed a supporting system to cope with MES patients’ anxiety and stress by means of several biosignals such as ECG, GSR, body temperature, SpO 2 2 , glucose level, and blood pressure that are measured by a wearable device . We employed a neural network model to classify emotions with HRV analysis in the detection of stressor moments. We have accurately recognized the stressful situations using physiological responses to stimuli by utilizing our proposed affective state detection algorithm . We evaluated our system with a dataset of 312 biosignal records from 30 participants and the results showed that our proposed method achieved an average accuracy of 92% and 89% in distinguishing stress level in MES and other groups respectively. Both being the focus of an MES group and others proved to be highly arousing experiences which were significantly reflected in the physiological signal. Exposure to the stress in MES and cardiovascular heart disease patients increases the chronic symptoms. An early stage of comprehensive intervention may reduce the risk of general cardiovascular events in these particular groups. In this context, the use of e-health applications such as our proposed system facilitates these processes.},
  archive      = {J_ARTMED},
  author       = {Fatma Patlar Akbulut and Baris Ikitimur and Aydin Akan},
  doi          = {10.1016/j.artmed.2020.101824},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101824},
  shortjournal = {Artif. Intell. Med.},
  title        = {Wearable sensor-based evaluation of psychosocial stress in patients with metabolic syndrome},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recurrent neural network approach to predicting hemoglobin
trajectories in patients with end-stage renal disease. <em>ARTMED</em>,
<em>104</em>, 101823. (<a
href="https://doi.org/10.1016/j.artmed.2020.101823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most severe form of kidney disease, End-Stage Renal Disease (ESRD) is treated with various forms of dialysis – artificial blood cleansing. Dialysis patients suffer many health burdens including high mortality and hospitalization rates, and symptomatic anemia: a low red blood cell count as indicated by a low hemoglobin (Hgb) level. ESRD-induced anemia is treated, with variable patient response, by erythropoiesis stimulating agents (ESAs): expensive injectable medications typically administered during dialysis sessions. The dosing protocol is typically a population level protocol based on original clinical trials, the use of which often results in Hgb cycling. This cycling phenomenon occurs primarily due to the mismatch in the time between dosing decisions and the time it takes for the effects of a dosing change to be fully realized. In this paper we develop a recurrent neural network approach that uses historic data together with future ESA and iron dosing data to predict the 1, 2, and 3 month Hgb levels of patients with ESRD-induced anemia. The results of extensive experimentation indicate that this approach generates predictions that are clinically relevant: the mean absolute error of the predictions is comparable to estimates of the intra-individual variability of the laboratory test for Hgb.},
  archive      = {J_ARTMED},
  author       = {Benjamin Lobo and Emaad Abdel-Rahman and Donald Brown and Lori Dunn and Brendan Bowman},
  doi          = {10.1016/j.artmed.2020.101823},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101823},
  shortjournal = {Artif. Intell. Med.},
  title        = {A recurrent neural network approach to predicting hemoglobin trajectories in patients with end-stage renal disease},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automated machine learning: Review of the state-of-the-art
and opportunities for healthcare. <em>ARTMED</em>, <em>104</em>, 101822.
(<a href="https://doi.org/10.1016/j.artmed.2020.101822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aims to provide a review of the existing literature in the field of automated machine learning (AutoML) to help healthcare professionals better utilize machine learning models “off-the-shelf” with limited data science expertise. We also identify the potential opportunities and barriers to using AutoML in healthcare, as well as existing applications of AutoML in healthcare. Published papers, accompanied with code, describing work in the field of AutoML from both a computer science perspective or a biomedical informatics perspective were reviewed. We also provide a short summary of a series of AutoML challenges hosted by ChaLearn. A review of 101 papers in the field of AutoML revealed that these automated techniques can match or improve upon expert human performance in certain machine learning tasks, often in a shorter amount of time. The main limitation of AutoML at this point is the ability to get these systems to work efficiently on a large scale, i.e. beyond small- and medium-size retrospective datasets. The utilization of machine learning techniques has the demonstrated potential to improve health outcomes, cut healthcare costs, and advance clinical research. However, most hospitals are not currently deploying machine learning solutions. One reason for this is that health care professionals often lack the machine learning expertise that is necessary to build a successful model, deploy it in production, and integrate it with the clinical workflow. In order to make machine learning techniques easier to apply and to reduce the demand for human experts, automated machine learning (AutoML) has emerged as a growing field that seeks to automatically select, compose, and parametrize machine learning models, so as to achieve optimal performance on a given task and/or dataset. While there have already been some use cases of AutoML in the healthcare field, more work needs to be done in order for there to be widespread adoption of AutoML in healthcare.},
  archive      = {J_ARTMED},
  author       = {Jonathan Waring and Charlotta Lindvall and Renato Umeton},
  doi          = {10.1016/j.artmed.2020.101822},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101822},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automated machine learning: Review of the state-of-the-art and opportunities for healthcare},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel deep mining model for effective knowledge discovery
from omics data. <em>ARTMED</em>, <em>104</em>, 101821. (<a
href="https://doi.org/10.1016/j.artmed.2020.101821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery from omics data has become a common goal of current approaches to personalised cancer medicine and understanding cancer genotype and phenotype. However, high-throughput biomedical datasets are characterised by high dimensionality and relatively small sample sizes with small signal-to-noise ratios. Extracting and interpreting relevant knowledge from such complex datasets therefore remains a significant challenge for the fields of machine learning and data mining. In this paper, we exploit recent advances in deep learning to mitigate against these limitations on the basis of automatically capturing enough of the meaningful abstractions latent with the available biological samples. Our deep feature learning model is proposed based on a set of non-linear sparse Auto-Encoders that are deliberately constructed in an under-complete manner to detect a small proportion of molecules that can recover a large proportion of variations underlying the data. However, since multiple projections are applied to the input signals, it is hard to interpret which phenotypes were responsible for deriving such predictions. Therefore, we also introduce a novel weight interpretation technique that helps to deconstruct the internal state of such deep learning models to reveal key determinants underlying its latent representations. The outcomes of our experiment provide strong evidence that the proposed deep mining model is able to discover robust biomarkers that are positively and negatively associated with cancers of interest. Since our deep mining model is problem-independent and data-driven, it provides further potential for this research to extend beyond its cognate disciplines.},
  archive      = {J_ARTMED},
  author       = {Abeer Alzubaidi and Jonathan Tepper and Ahmad Lotfi},
  doi          = {10.1016/j.artmed.2020.101821},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101821},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel deep mining model for effective knowledge discovery from omics data},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Early detection of sepsis utilizing deep learning on
electronic health record event sequences. <em>ARTMED</em>, <em>104</em>,
101820. (<a href="https://doi.org/10.1016/j.artmed.2020.101820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The timeliness of detection of a sepsis incidence in progress is a crucial factor in the outcome for the patient. Machine learning models built from data in electronic health records can be used as an effective tool for improving this timeliness, but so far, the potential for clinical implementations has been largely limited to studies in intensive care units. This study will employ a richer data set that will expand the applicability of these models beyond intensive care units. Furthermore, we will circumvent several important limitations that have been found in the literature: (1) Model evaluations neglect the clinical consequences of a decision to start, or not start, an intervention for sepsis. (2) Models are evaluated shortly before sepsis onset without considering interventions already initiated. (3) Machine learning models are built on a restricted set of clinical parameters, which are not necessarily measured in all departments. (4) Model performance is limited by current knowledge of sepsis, as feature interactions and time dependencies are hard-coded into the model. In this study, we present a model to overcome these shortcomings using a deep learning approach on a diverse multicenter data set. We used retrospective data from multiple Danish hospitals over a seven-year period. Our sepsis detection system is constructed as a combination of a convolutional neural network and a long short-term memory network. We assess model quality by standard concepts of accuracy as well as clinical usefulness, and we suggest a retrospective assessment of interventions by looking at intravenous antibiotics and blood cultures preceding the prediction time. Results show performance ranging from AUROC 0.856 (3 h before sepsis onset) to AUROC 0.756 (24 h before sepsis onset). Evaluating the clinical utility of the model, we find that a large proportion of septic patients did not receive antibiotic treatment or blood culture at the time of the sepsis prediction, and the model could, therefore, facilitate such interventions at an earlier point in time. We present a deep learning system for early detection of sepsis that can learn characteristics of the key factors and interactions from the raw event sequence data itself, without relying on a labor-intensive feature extraction work. Our system outperforms baseline models, such as gradient boosting, which rely on specific data elements and therefore suffer from many missing values in our dataset.},
  archive      = {J_ARTMED},
  author       = {Simon Meyer Lauritsen and Mads Ellersgaard Kalør and Emil Lund Kongsgaard and Katrine Meyer Lauritsen and Marianne Johansson Jørgensen and Jeppe Lange and Bo Thiesson},
  doi          = {10.1016/j.artmed.2020.101820},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101820},
  shortjournal = {Artif. Intell. Med.},
  title        = {Early detection of sepsis utilizing deep learning on electronic health record event sequences},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feature selection based multivariate time series
forecasting: An application to antibiotic resistance outbreaks
prediction. <em>ARTMED</em>, <em>104</em>, 101818. (<a
href="https://doi.org/10.1016/j.artmed.2020.101818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial resistance has become one of the most important health problems and global action plans have been proposed globally. Prevention plays a key role in these actions plan and, in this context, we propose the use of Artificial Intelligence , specifically Time Series Forecasting techniques, for predicting future outbreaks of Methicillin-resistant Staphylococcus aureus (MRSA). Infection incidence forecasting is approached as a Feature Selection based Time Series Forecasting problem using multivariate time series composed of incidence of Staphylococcus aureus Methicillin-sensible and MRSA infections, influenza incidence and total days of therapy of both of Levofloxacin and Oseltamivir antimicrobials. Data were collected from the University Hospital of Getafe (Spain) from January 2009 to January 2018, using months as time granularity. The main contributions of the work are the following: the applications of wrapper feature selection methods where the search strategy is based on multi-objective evolutionary algorithms (MOEA) along with evaluators based on the most powerful state-of-the-art regression algorithms. The performance of the feature selection methods has been measured using the root mean square error ( RMSE ) and mean absolute error ( MAE ) performance metrics. A novel multi-criteria decision-making process is proposed in order to select the most satisfactory forecasting model, using the metrics previously mentioned, as well as the slopes of model prediction lines in the 1, 2 and 3 steps-ahead predictions. The multi-criteria decision-making process is applied to the best models resulting from a ranking of databases and regression algorithms obtained through multiple statistical tests. Finally, to the best of our knowledge, this is the first time that a feature selection based multivariate time series methodology is proposed for antibiotic resistance forecasting. Final results show that the best model according to the proposed multi-criteria decision making process provides a RMSE = (0.1349, 0.1304, 0.1325) and a MAE = (0.1003, 0.096, 0.0987) for 1, 2, and 3 steps-ahead predictions.},
  archive      = {J_ARTMED},
  author       = {Fernando Jiménez and José Palma and Gracia Sánchez and David Marín and M.D. Francisco Palacios and M.D. Lucía López},
  doi          = {10.1016/j.artmed.2020.101818},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101818},
  shortjournal = {Artif. Intell. Med.},
  title        = {Feature selection based multivariate time series forecasting: An application to antibiotic resistance outbreaks prediction},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient treatment of outliers and class imbalance for
diabetes prediction. <em>ARTMED</em>, <em>104</em>, 101815. (<a
href="https://doi.org/10.1016/j.artmed.2020.101815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from outliers and imbalanced data remains one of the major difficulties for machine learning classifiers. Among the numerous techniques dedicated to tackle this problem, data preprocessing solutions are known to be efficient and easy to implement. In this paper, we propose a selective data preprocessing approach that embeds knowledge of the outlier instances into artificially generated subset to achieve an even distribution. The Synthetic Minority Oversampling TEchnique (SMOTE) was used to balance the training data by introducing artificial minority instances. However, this was not before the outliers were identified and oversampled (irrespective of class). The aim is to balance the training dataset while controlling the effect of outliers. The experiments prove that such selective oversampling empowers SMOTE, ultimately leading to improved classification performance.},
  archive      = {J_ARTMED},
  author       = {Nonso Nnamoko and Ioannis Korkontzelos},
  doi          = {10.1016/j.artmed.2020.101815},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101815},
  shortjournal = {Artif. Intell. Med.},
  title        = {Efficient treatment of outliers and class imbalance for diabetes prediction},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multimodal data analysis of epileptic EEG and rs-fMRI via
deep learning and edge computing. <em>ARTMED</em>, <em>104</em>, 101813.
(<a href="https://doi.org/10.1016/j.artmed.2020.101813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data analysis and large-scale computational capability is entering medicine in an accelerative fashion and has begun to influence investigational work in a variety of disciplines. It is also informing us of therapeutic interventions that will come about with such development. Epilepsy is a chronic brain disorder in which functional changes may precede structural ones and which may be detectable using existing modalities. Functional connectivity analysis using electroencephalography (EEG) and resting state-functional magnetic resonance imaging (rs-fMRI) has provided such meaningful input in cases of epilepsy. By leveraging the potential of autonomic edge computing in epilepsy, we develop and deploy both noninvasive and invasive methods for monitoring, evaluation, and regulation of the epileptic brain. First, an autonomic edge computing framework is proposed for the processing of big data as part of a decision support system for surgical candidacy. Second, a multimodal data analysis using independently acquired EEG and rs-fMRI is presented for estimation and prediction of the epileptogenic network. Third, an unsupervised feature extraction model is developed for EEG analysis and seizure prediction based on a Convolutional deep learning (CNN) structure for distinguishing preictal (pre-seizure) state from non-preictal periods by support vector machine (SVM) classifier. Experimental and simulation results from actual patient data validate the effectiveness of the proposed methods. The combination of rs-fMRI and EEG/iEEG can reveal more information about dynamic functional connectivity. However, simultaneous fMRI and EEG data acquisition present challenges. We have proposed system models for leveraging and processing independently acquired fMRI and EEG data.},
  archive      = {J_ARTMED},
  author       = {Mohammad-Parsa Hosseini and Tuyen X. Tran and Dario Pompili and Kost Elisevich and Hamid Soltanian-Zadeh},
  doi          = {10.1016/j.artmed.2020.101813},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101813},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multimodal data analysis of epileptic EEG and rs-fMRI via deep learning and edge computing},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimisation and control of the supply of blood bags in
hemotherapic centres via markov decision process with discounted arrival
rate. <em>ARTMED</em>, <em>104</em>, 101791. (<a
href="https://doi.org/10.1016/j.artmed.2020.101791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Running a cost-effective human blood transfusion supply chain challenges decision makers in blood services world-wide. In this paper, we develop a Markov decision process with the objective of minimising the overall costs of internal and external collections, storing, producing and disposing of blood bags, whilst explicitly considering the probability that a donated blog bag will perish before demanded. The model finds an optimal policy to collect additional bags based on the number of bags in stock rather than using information about the age of the oldest item. Using data from the literature, we validate our model and carry out a case study based on data from a large blood supplier in South America. The study helped achieve an overall increase of 4.5% in blood donations in one year.},
  archive      = {J_ARTMED},
  author       = {Henrique L.F. Soares and Edilson F. Arruda and Laura Bahiense and Daniel Gartner and Luiz Amorim Filho},
  doi          = {10.1016/j.artmed.2020.101791},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101791},
  shortjournal = {Artif. Intell. Med.},
  title        = {Optimisation and control of the supply of blood bags in hemotherapic centres via markov decision process with discounted arrival rate},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved multi-swarm particle swarm optimizer for
optimizing the electric field distribution of multichannel transcranial
magnetic stimulation. <em>ARTMED</em>, <em>104</em>, 101790. (<a
href="https://doi.org/10.1016/j.artmed.2020.101790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multichannel transcranial magnetic stimulation (mTMS) is a therapeutic method to improve psychiatric diseases, which has a flexible working pattern used to different applications. In order to make the electric field distribution in the brain meet the treatment expectations, we have developed a novel multi-swam particle swarm optimizer (NMSPSO) to optimize the current configuration of double layer coil array. To balance the exploration and exploitation abilities, three novel improved strategies are used in NMSPSO based on multi-swarm particle swarm optimizer. Firstly, a novel information exchange strategy is achieved by individual exchanges between sub-swarms. Secondly, a novel leaning strategy is used to control knowledge dissemination in the population, which not only increases the diversity of the particles but also guarantees the convergence. Finally, a novel mutation strategy is introduced, which can help the population jump out of the local optimum for better exploration ability. The method is examined on a set of well-known benchmark functions and the results show that NMSPSO has better performance than many particle swarm optimization variants. And the superior electric field distribution in mTMS can be obtained by NMSPSO to optimize the current configuration of the double layer coil array.},
  archive      = {J_ARTMED},
  author       = {Hui Xiong and Bowen Qiu and Jinzhen Liu},
  doi          = {10.1016/j.artmed.2020.101790},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {101790},
  shortjournal = {Artif. Intell. Med.},
  title        = {An improved multi-swarm particle swarm optimizer for optimizing the electric field distribution of multichannel transcranial magnetic stimulation},
  volume       = {104},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-world data medical knowledge graph: Construction and
applications. <em>ARTMED</em>, <em>103</em>, 101817. (<a
href="https://doi.org/10.1016/j.artmed.2020.101817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical knowledge graph (KG) is attracting attention from both academic and healthcare industry due to its power in intelligent healthcare applications. In this paper, we introduce a systematic approach to build medical KG from electronic medical records (EMRs) with evaluation by both technical experiments and end to end application examples. The original data set contains 16,217,270 de-identified clinical visit data of 3,767,198 patients. The KG construction procedure includes 8 steps, which are data preparation, entity recognition, entity normalization, relation extraction, property calculation, graph cleaning, related-entity ranking, and graph embedding respectively. We propose a novel quadruplet structure to represent medical knowledge instead of the classical triplet in KG. A novel related-entity ranking function considering probability, specificity and reliability (PSR) is proposed. Besides, probabilistic translation on hyperplanes (PrTransH) algorithm is used to learn graph embedding for the generated KG. A medical KG with 9 entity types including disease, symptom, etc. was established, which contains 22,508 entities and 579,094 quadruplets. Compared with term frequency - inverse document frequency (TF/IDF) method, the normalized discounted cumulative gain (NDCG@10) increased from 0.799 to 0.906 with the proposed ranking function. The embedding representation for all entities and relations were learned, which are proven to be effective using disease clustering. The established systematic procedure can efficiently construct a high-quality medical KG from large-scale EMRs . The proposed ranking function PSR achieves the best performance under all relations, and the disease clustering result validates the efficacy of the learned embedding vector as entity’s semantic representation. Moreover, the obtained KG finds many successful applications due to its statistics-based quadruplet. where N c o m i n Ncomin is a minimum co-occurrence number and R is the basic reliability value. The reliability value can measure how reliable is the relationship between S i and O ij . The reason for the definition is the higher value of N co ( S i, O ij ), the relationship is more reliable. However, the reliability values of the two relationships should not have a big difference if both of their co-occurrence numbers are very big. In our study, we finally set N c o m i n Ncomin = 10 and R = 1 after some experiments. For instance, if co-occurrence numbers of three relationships are 1, 100 and 10000, their reliability values are 1, 2.96 and 5 respectively.},
  archive      = {J_ARTMED},
  author       = {Linfeng Li and Peng Wang and Jun Yan and Yao Wang and Simin Li and Jinpeng Jiang and Zhe Sun and Buzhou Tang and Tsung-Hui Chang and Shenghui Wang and Yuting Liu},
  doi          = {10.1016/j.artmed.2020.101817},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101817},
  shortjournal = {Artif. Intell. Med.},
  title        = {Real-world data medical knowledge graph: Construction and applications},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic computation of mandibular indices in dental
panoramic radiographs for early osteoporosis detection. <em>ARTMED</em>,
<em>103</em>, 101816. (<a
href="https://doi.org/10.1016/j.artmed.2020.101816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new automatic method for detecting specific points and lines (straight and curves) in dental panoramic radiographies (orthopantomographies) is proposed, where the human knowledge is mapped to the automatic system. The goal is to compute relevant mandibular indices (Mandibular Cortical Width, Panoramic Mandibular Index, Mandibular Ratio, Mandibular Cortical Index) in order to detect the thinning and deterioration of the mandibular bone. Data can be stored for posterior massive analysis. Panoramic radiographies are intrinsically complex, including: artificial structures, unclear limits in bony structures, jawbones with irregular curvatures and intensity levels, irregular shapes and borders of the mental foramen, irregular teeth alignments or missing dental pieces. An intelligent sequence of linked imaging segmentation processes is proposed to cope with the above situations towards the design of the automatic segmentation, making the following contributions: (i) Fuzzy K-means classification for identifying artificial structures; (ii) adjust a tangent line to the lower border of the lower jawbone (lower cortex), based on texture analysis, grey scale dilation, binarization and labelling; (iii) identification of the mental foramen region and its centre, based on multi-thresholding, binarization, morphological operations and labelling; (iv) tracing a perpendicular line to the tangent passing through the centre of the mental foramen region and two parallel lines to the tangent, passing through borders on the mental foramen intersected by the perpendicular; (v) following the perpendicular line, a sweep is made moving up the tangent for detecting accumulation of binary points after applying adaptive filtering; (vi) detection of the lower mandible alveolar crest line based on the identification of inter-teeth gaps by saliency and interest points feature description. The performance of the proposed approach was quantitatively compared against the criteria of expert dentists, verifying also its validity with statistical studies based on the analysis of deterioration of bone structures with different levels of osteoporosis. All indices are computed inside two regions of interest, which tolerate flexibility in sizes and locations, making this process robust enough. The proposed approach provides an automatic procedure able to process with efficiency and reliability panoramic X-Ray images for early osteoporosis detection.},
  archive      = {J_ARTMED},
  author       = {Ignacio Aliaga and Vicente Vera and María Vera and Enrique García and María Pedrera and Gonzalo Pajares},
  doi          = {10.1016/j.artmed.2020.101816},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101816},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic computation of mandibular indices in dental panoramic radiographs for early osteoporosis detection},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multicenter random forest model for effective prognosis
prediction in collaborative clinical research network. <em>ARTMED</em>,
<em>103</em>, 101814. (<a
href="https://doi.org/10.1016/j.artmed.2020.101814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of a prognostic prediction model has become an essential aspect of the quality and reliability of the health-related decisions made by clinicians in modern medicine. Unfortunately, individual institutions often lack sufficient samples, which might not provide sufficient statistical power for models. One mitigation is to expand data collection from a single institution to multiple centers to collectively increase the sample size. However, sharing sensitive biomedical data for research involves complicated issues. Machine learning models such as random forests (RF), though they are commonly used and achieve good performances for prognostic prediction, usually suffer worse performance under multicenter privacy-preserving data mining scenarios compared to a centrally trained version. In this study, a multicenter random forest prognosis prediction model is proposed that enables federated clinical data mining from horizontally partitioned datasets. By using a novel data enhancement approach based on a differentially private generative adversarial network customized to clinical prognosis data, the proposed model is able to provide a multicenter RF model with performances on par with—or even better than—centrally trained RF but without the need to aggregate the raw data. Moreover, our model also incorporates an importance ranking step designed for feature selection without sharing patient-level information. The proposed model was evaluated on colorectal cancer datasets from the US and China. Two groups of datasets with different levels of heterogeneity within the collaborative research network were selected. First, we compare the performance of the distributed random forest model under different privacy parameters with different percentages of enhancement datasets and validate the effectiveness and plausibility of our approach. Then, we compare the discrimination and calibration ability of the proposed multicenter random forest with a centrally trained random forest model and other tree-based classifiers as well as some commonly used machine learning methods. The results show that the proposed model can provide better prediction performance in terms of discrimination and calibration ability than the centrally trained RF model or the other candidate models while following the privacy-preserving rules in both groups. Additionally, good discrimination and calibration ability are shown on the simplified model based on the feature importance ranking in the proposed approach. The proposed random forest model exhibits ideal prediction capability using multicenter clinical data and overcomes the performance limitation arising from privacy guarantees. It can also provide feature importance ranking across institutions without pooling the data at a central site. This study offers a practical solution for building a prognosis prediction model in the collaborative clinical research network and solves practical issues in real-world applications of medical artificial intelligence.},
  archive      = {J_ARTMED},
  author       = {Jin Li and Yu Tian and Yan Zhu and Tianshu Zhou and Jun Li and Kefeng Ding and Jingsong Li},
  doi          = {10.1016/j.artmed.2020.101814},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101814},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multicenter random forest model for effective prognosis prediction in collaborative clinical research network},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An incremental explanation of inference in bayesian networks
for increasing model trustworthiness and supporting clinical decision
making. <em>ARTMED</em>, <em>103</em>, 101812. (<a
href="https://doi.org/10.1016/j.artmed.2020.101812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various AI models are increasingly being considered as part of clinical decision-support tools. However, the trustworthiness of such models is rarely considered. Clinicians are more likely to use a model if they can understand and trust its predictions. Key to this is if its underlying reasoning can be explained. A Bayesian network (BN) model has the advantage that it is not a black-box and its reasoning can be explained. In this paper, we propose an incremental explanation of inference that can be applied to ‘hybrid’ BNs, i.e. those that contain both discrete and continuous nodes. The key questions that we answer are: (1) which important evidence supports or contradicts the prediction, and (2) through which intermediate variables does the information flow. The explanation is illustrated using a real clinical case study . A small evaluation study is also conducted.},
  archive      = {J_ARTMED},
  author       = {Evangelia Kyrimi and Somayyeh Mossadegh and Nigel Tai and William Marsh},
  doi          = {10.1016/j.artmed.2020.101812},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101812},
  shortjournal = {Artif. Intell. Med.},
  title        = {An incremental explanation of inference in bayesian networks for increasing model trustworthiness and supporting clinical decision making},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random forest enhancement using improved artificial fish
swarm for the medial knee contact force prediction. <em>ARTMED</em>,
<em>103</em>, 101811. (<a
href="https://doi.org/10.1016/j.artmed.2020.101811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knee contact force (KCF) is an important factor to evaluate the knee joint function for the patients with knee joint impairment. However, the KCF measurement based on the instrumented prosthetic implants or inverse dynamics analysis is limited due to the invasive, expensive price and time consumption. In this work, we propose a KCF prediction method by integrating the Artificial Fish Swarm and the Random Forest algorithm. First, we train a Random Forest to learn the nonlinear relation between gait parameters (input) and contact pressures (output) based on a dataset of three patients instrumented with knee replacement. Then, we use the improved artificial fish group algorithm to optimize the main parameters of the Random Forest based KCF prediction model. The extensive experiments verify that our method can predict the medial knee contact force both before and after the intervention of gait patterns, and the performance outperforms the classical multi-body dynamics analysis and artificial neural network model.},
  archive      = {J_ARTMED},
  author       = {Yean Zhu and Weiyi XU and Guoliang Luo and Haolun Wang and Jingjing Yang and Wei Lu},
  doi          = {10.1016/j.artmed.2020.101811},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101811},
  shortjournal = {Artif. Intell. Med.},
  title        = {Random forest enhancement using improved artificial fish swarm for the medial knee contact force prediction},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantitative knowledge presentation models of traditional
chinese medicine (TCM): A review. <em>ARTMED</em>, <em>103</em>, 101810.
(<a href="https://doi.org/10.1016/j.artmed.2020.101810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern computer technology sheds light on new ways of innovating Traditional Chinese Medicine (TCM). One method that gets increasing attention is the quantitative research method, which makes use of data mining and artificial intelligence technology as well as the mathematical principles in the research on rationales, academic viewpoints of famous doctors of TCM, dialectical treatment by TCM, clinical technology of TCM, the patterns of TCM prescriptions, clinical curative effects of TCM and other aspects. This paper reviews the methods, means, progress and achievements of quantitative research on TCM. In the core database of the Web of Science, &quot;Traditional Chinese Medicine&quot;, &quot;Computational Science&quot; and &quot;Mathematical Computational Biology&quot; are selected as the main retrieval fields, and the retrieval time interval from 1999 to 2019 is used to collect relevant literature. It is found that researchers from China Academy of Chinese Medical Sciences, Zhejiang University, Chinese Academy of Sciences and other institutes have opened up new methods of research on TCM since 2009, with quantitative methods and knowledge presentation models. The adopted tools mainly consist of text mining, knowledge discovery, technologies of the TCM database, data mining and drug discovery through TCM calculation, etc. In the future, research on quantitative models of TCM will focus on solving the heterogeneity and incompleteness of big data of TCM, establishing standardized treatment systems, and promoting the development of modernization and internationalization of TCM.},
  archive      = {J_ARTMED},
  author       = {Xiaoli Chu and Bingzhen Sun and Qingchun Huang and Shouping Peng and Yingyan Zhou and Yan Zhang},
  doi          = {10.1016/j.artmed.2020.101810},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101810},
  shortjournal = {Artif. Intell. Med.},
  title        = {Quantitative knowledge presentation models of traditional chinese medicine (TCM): A review},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalogram based prediction model for respiratory disorders
using optimized convolutional neural networks. <em>ARTMED</em>,
<em>103</em>, 101809. (<a
href="https://doi.org/10.1016/j.artmed.2020.101809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auscultation of the lung is a conventional technique used for diagnosing chronic obstructive pulmonary diseases (COPDs) and lower respiratory infections and disorders in patients. In most of the earlier works, wavelet transforms or spectrograms have been used to analyze the lung sounds. However, an accurate prediction model for respiratory disorders has not been developed so far. In this paper, a pre-trained optimized Alexnet Convolutional Neural Network (CNN) architecture is proposed for predicting respiratory disorders. The proposed approach models the segmented respiratory sound signal into Bump and Morse scalograms from several intrinsic mode functions (IMFs) using empirical mode decomposition (EMD) method. From the extracted intrinsic mode functions, the percentage energy calculated for each wavelet coefficient in the form of scalograms are computed. Subsequently, these scalograms are given as input to the pre-trained optimized CNN model for training and testing. Stochastic gradient descent with momentum (SGDM) and adaptive data momentum (ADAM) optimization algorithms were examined to check the prediction accuracy on the dataset comprising of four classes of lung sounds, normal, crackles (coarse and fine), wheezes (monophonic &amp; polyphonic) and low-pitched wheezes (Rhonchi). On comparison to the baseline method of standard Bump and Morse wavelet transform approach which produced 79.04 % and 81.27 % validation accuracy, an improved accuracy of 83.78 % is achieved by the virtue of scalogram representation of various IMFs of EMD. Hence, the proposed approach achieves significant performance improvement in accuracy compared to the existing state-of- the-art techniques in literature.},
  archive      = {J_ARTMED},
  author       = {S. Jayalakshmy and Gnanou Florence Sudha},
  doi          = {10.1016/j.artmed.2020.101809},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101809},
  shortjournal = {Artif. Intell. Med.},
  title        = {Scalogram based prediction model for respiratory disorders using optimized convolutional neural networks},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of glomerular hypercellularity using
convolutional features and support vector machine. <em>ARTMED</em>,
<em>103</em>, 101808. (<a
href="https://doi.org/10.1016/j.artmed.2020.101808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glomeruli are histological structures of the kidney cortex formed by interwoven blood capillaries, and are responsible for blood filtration. Glomerular lesions impair kidney filtration capability, leading to protein loss and metabolic waste retention. An example of lesion is the glomerular hypercellularity, which is characterized by an increase in the number of cell nuclei in different areas of the glomeruli. Glomerular hypercellularity is a frequent lesion present in different kidney diseases. Automatic detection of glomerular hypercellularity would accelerate the screening of scanned histological slides for the lesion, enhancing clinical diagnosis. Having this in mind, we propose a new approach for classification of hypercellularity in human kidney images. Our proposed method introduces a novel architecture of a convolutional neural network (CNN) along with a support vector machine, achieving near perfect average results on FIOCRUZ data set in a binary classification (lesion or normal). Additionally, classification of hypercellularity sub-lesions was also evaluated, considering mesangial, endocapilar and both lesions, reaching an average accuracy of 82%. Either in binary task or in the multi-classification one, our proposed method outperformed Xception, ResNet50 and InceptionV3 networks, as well as a traditional handcrafted-based method. To the best of our knowledge, this is the first study on deep learning over a data set of glomerular hypercellularity images of human kidney.},
  archive      = {J_ARTMED},
  author       = {Paulo Chagas and Luiz Souza and Ikaro Araújo and Nayze Aldeman and Angelo Duarte and Michele Angelo and Washington L.C. dos-Santos and Luciano Oliveira},
  doi          = {10.1016/j.artmed.2020.101808},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101808},
  shortjournal = {Artif. Intell. Med.},
  title        = {Classification of glomerular hypercellularity using convolutional features and support vector machine},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prognostic factors of rapid symptoms progression in patients
with newly diagnosed parkinson’s disease. <em>ARTMED</em>, <em>103</em>,
101807. (<a href="https://doi.org/10.1016/j.artmed.2020.101807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracking symptoms progression in the early stages of Parkinson’s disease (PD) is a laborious endeavor as the disease can be expressed with vastly different phenotypes, forcing clinicians to follow a multi-parametric approach in patient evaluation, looking for not only motor symptomatology but also non-motor complications, including cognitive decline, sleep problems and mood disturbances. Being neurodegenerative in nature, PD is expected to inflict a continuous degradation in patients’ condition over time. The rate of symptoms progression, however, is found to be even more chaotic than the vastly different phenotypes that can be expressed in the initial stages of PD. In this work, an analysis of baseline PD characteristics is performed using machine learning techniques, to identify prognostic factors for early rapid progression of PD symptoms. Using open data from the Parkinson’s Progression Markers Initiative (PPMI) study, an extensive set of baseline patient evaluation outcomes is examined to isolate determinants of rapid progression within the first two and four years of PD. The rate of symptoms progression is estimated by tracking the change of the Movement Disorder Society-Unified Parkinson&#39;s Disease Rating Scale (MDS‐UPDRS) total score over the corresponding follow-up period. Patients are ranked according to their progression rates and those who expressed the highest rates of MDS-UPDRS total score increase per year of follow-up period are assigned into the rapid progression class, using 5- and 10-quantiles partition. Classification performance against the rapid progression class was evaluated in a per quantile partition analysis scheme and in quantile-independent approach, respectively. The results shown a more accurate patient discrimination with quantile partitioning, however, a much more compact subset of baseline factors is extracted in the latter, making a more suitable for actual interventions in practice. Classification accuracy improved in all cases when using the longer 4-year follow-up period to estimate PD progression, suggesting that a prolonged patient evaluation can provide better outcomes in identifying rapid progression phenotype. Non-motor symptoms are found to be the main determinants of rapid symptoms progression in both follow-up periods, with autonomic dysfunction, mood impairment, anxiety, REM sleep behavior disorders, cognitive decline and memory impairment being alarming signs at baseline evaluation, along with rigidity symptoms, certain laboratory blood test results and genetic mutations.},
  archive      = {J_ARTMED},
  author       = {Kostas M. Tsiouris and Spiros Konitsiotis and Dimitrios D. Koutsouris and Dimitrios I. Fotiadis},
  doi          = {10.1016/j.artmed.2020.101807},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101807},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prognostic factors of rapid symptoms progression in patients with newly diagnosed parkinson’s disease},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed-integer optimization approach to learning association
rules for unplanned ICU transfer. <em>ARTMED</em>, <em>103</em>, 101806.
(<a href="https://doi.org/10.1016/j.artmed.2020.101806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After admission to emergency department (ED), patients with critical illnesses are transferred to intensive care unit (ICU) due to unexpected clinical deterioration occurrence. Identifying such unplanned ICU transfers is urgently needed for medical physicians to achieve two-fold goals: improving critical care quality and preventing mortality. A priority task is to understand the crucial rationale behind diagnosis results of individual patients during stay in ED, which helps prepare for an early transfer to ICU. Most existing prediction studies were based on univariate analysis or multiple logistic regression to provide one-size-fit-all results. However, patient condition varying from case to case may not be accurately examined by such a simplistic judgment. In this study, we present a new decision tool using a mathematical optimization approach aiming to automatically discover rules associating diagnostic features with high-risk outcome (i.e., unplanned transfers) in different deterioration scenarios. We consider four mutually exclusive patient subgroups based on the principal reasons of ED visits: infections, cardiovascular/respiratory diseases, gastrointestinal diseases, and neurological/other diseases at a suburban teaching hospital. The analysis results demonstrate significant rules associated with unplanned transfer outcome for each subgroups and also show comparable prediction accuracy ( &gt; &amp;gt; 70%) compared to state-of-the-art machine learning methods while providing easy-to-interpret symptom-outcome information.},
  archive      = {J_ARTMED},
  author       = {Chun-An Chou and Qingtao Cao and Shao-Jen Weng and Che-Hung Tsai},
  doi          = {10.1016/j.artmed.2020.101806},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101806},
  shortjournal = {Artif. Intell. Med.},
  title        = {Mixed-integer optimization approach to learning association rules for unplanned ICU transfer},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Batch mode active learning on the riemannian manifold for
automated scoring of nuclear pleomorphism in breast cancer.
<em>ARTMED</em>, <em>103</em>, 101805. (<a
href="https://doi.org/10.1016/j.artmed.2020.101805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most prevalent invasive type of cancer among women. The mortality rate of the disease can be reduced considerably through timely prognosis and felicitous treatment planning, by utilizing the computer aided detection and diagnosis techniques. With the advent of whole slide image (WSI) scanners for digitizing the histopathological tissue samples, there is a drastic increase in the availability of digital histopathological images. However, these samples are often unlabeled and hence they need labeling to be done through manual annotations by domain experts and experienced pathologists. But this annotation process required for acquiring high quality large labeled training set for nuclear atypia scoring is a tedious, expensive and time consuming job. Active learning techniques have achieved widespread acceptance in reducing this human effort in annotating the data samples. In this paper, we explore the possibilities of active learning on nuclear pleomorphism scoring over a non-Euclidean framework, the Riemannian manifold. Active learning technique adopted for the cancer grading is in the batch-mode framework, that adaptively identifies the apt batch size along with the batch of instances to be queried, following a submodular optimization framework. Samples for annotation are selected considering the diversity and redundancy between the pair of samples, based on the kernelized Riemannian distance measures such as log-Euclidean metrics and the two Bregman divergences - Stein and Jeffrey divergences. Results of the adaptive Batch Mode Active Learning on the Riemannian metric show a superior performance when compared with the state-of-the-art techniques for breast cancer nuclear pleomorphism scoring, as it makes use of the information from the unlabeled samples.},
  archive      = {J_ARTMED},
  author       = {Asha Das and Madhu S. Nair and David S. Peter},
  doi          = {10.1016/j.artmed.2020.101805},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101805},
  shortjournal = {Artif. Intell. Med.},
  title        = {Batch mode active learning on the riemannian manifold for automated scoring of nuclear pleomorphism in breast cancer},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring the effects of confounders in medical supervised
classification problems: The confounding index (CI). <em>ARTMED</em>,
<em>103</em>, 101804. (<a
href="https://doi.org/10.1016/j.artmed.2020.101804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the years, there has been growing interest in using machine learning techniques for biomedical data processing. When tackling these tasks, one needs to bear in mind that biomedical data depends on a variety of characteristics, such as demographic aspects (age, gender, etc.) or the acquisition technology, which might be unrelated with the target of the analysis. In supervised tasks, failing to match the ground truth targets with respect to such characteristics, called confounders, may lead to very misleading estimates of the predictive performance. Many strategies have been proposed to handle confounders, ranging from data selection, to normalization techniques, up to the use of training algorithm for learning with imbalanced data. However, all these solutions require the confounders to be known a priori. To this aim, we introduce a novel index that is able to measure the confounding effect of a data attribute in a bias-agnostic way. This index can be used to quantitatively compare the confounding effects of different variables and to inform correction methods such as normalization procedures or ad-hoc-prepared learning algorithms. The effectiveness of this index is validated on both simulated data and real-world neuroimaging data.},
  archive      = {J_ARTMED},
  author       = {Elisa Ferrari and Alessandra Retico and Davide Bacciu},
  doi          = {10.1016/j.artmed.2020.101804},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101804},
  shortjournal = {Artif. Intell. Med.},
  title        = {Measuring the effects of confounders in medical supervised classification problems: The confounding index (CI)},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Retraction notice to “diagnosis labeling with
disease-specific characteristics mining” [artif. Intell. Med. 90 (2018)
25–33]. <em>ARTMED</em>, <em>103</em>, 101803. (<a
href="https://doi.org/10.1016/j.artmed.2020.101803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Jun Guo and Xuan Yuan and Xia Zheng and Pengfei Xu and Yun Xiao and Baoying Liu},
  doi          = {10.1016/j.artmed.2020.101803},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101803},
  shortjournal = {Artif. Intell. Med.},
  title        = {Retraction notice to “Diagnosis labeling with disease-specific characteristics mining” [Artif. intell. med. 90 (2018) 25–33]},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gait characteristics and clinical relevance of hereditary
spinocerebellar ataxia on deep learning. <em>ARTMED</em>, <em>103</em>,
101794. (<a href="https://doi.org/10.1016/j.artmed.2020.101794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has always been at the forefront of scientific research. It has also been applied to medical research. Hereditary spinocerebellar ataxia (SCA) is characterized by gait abnormalities and is usually evaluated semi-quantitatively by scales. However, more detailed gait characteristics of SCA and related objective methods have not yet been established. Therefore, the purpose of this study was to evaluate the gait characteristics of SCA patients, as well as to analyze the correlation between gait parameters, clinical scales, and imaging on deep learning. Twenty SCA patients diagnosed by genetic detection were included in the study. Ten patients who were tested via functional magnetic resonance imaging (fMRI) were included in the SCA imaging subgroup. All SCA patients were evaluated with the International Cooperative Ataxia Rating Scale (ICARS) and Scale for the Assessment and Rating of Ataxia (SARA) clinical scales. The gait control group included 16 healthy subjects, and the imaging control group included seven healthy subjects. Gait data consisting of 10 m of free walking of each individual in the SCA group and the gait control group were detected by wearable gait-detection equipment. Stride length, stride time, velocity, supporting-phase percentage, and swinging-phase percentage were extracted as gait parameters. Cerebellar volume and the midsagittal cerebellar proportion in the posterior fossa (MRVD) were calculated according to MR. There were significant differences in stride length, velocity, supporting-phase percentage, and swinging-phase percentage between the SCA group and the gait control group. The stride length and stride velocity of SCA groups were lower while supporting phase was longer than those of the gait control group. SCA group&#39;s velocity was negatively correlated with both the ICARS and SARA scores. The cerebellar volume and MRVD of the SCA imaging subgroup were significantly smaller than those of the imaging control group. MRVD was significantly correlated with ICARS and SARA scores, as well as stride velocity variability. SCA gait parameters were characterized by a reduced stride length, slower walking velocity, and longer supporting phase. Additionally, a smaller cerebellar volume correlated with an increased irregularity in gait. Gait characteristics exhibited considerable clinical relevance to hereditary SCA. We conclude that a combination of gait parameters, ataxia scales, and MRVD may represent more objective markers for clinical evaluations of SCA.},
  archive      = {J_ARTMED},
  author       = {Luya Jin and Wen Lv and Guocan Han and Linhui Ni and Di sun and Xingyue Hu and Huaying Cai},
  doi          = {10.1016/j.artmed.2020.101794},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101794},
  shortjournal = {Artif. Intell. Med.},
  title        = {Gait characteristics and clinical relevance of hereditary spinocerebellar ataxia on deep learning},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Seven pillars of precision digital health and medicine.
<em>ARTMED</em>, <em>103</em>, 101793. (<a
href="https://doi.org/10.1016/j.artmed.2020.101793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ARTMED},
  author       = {Arash Shaban-Nejad and Martin Michalowski and Niels Peek and John S. Brownstein and David L. Buckeridge},
  doi          = {10.1016/j.artmed.2020.101793},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101793},
  shortjournal = {Artif. Intell. Med.},
  title        = {Seven pillars of precision digital health and medicine},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective approach for CT lung segmentation using mask
region-based convolutional neural networks. <em>ARTMED</em>,
<em>103</em>, 101792. (<a
href="https://doi.org/10.1016/j.artmed.2020.101792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision systems have numerous tools to assist in various medical fields, notably in image diagnosis. Computed tomography (CT) is the principal imaging method used to assist in the diagnosis of diseases such as bone fractures, lung cancer, heart disease, and emphysema, among others. Lung cancer is one of the four main causes of death in the world. The lung regions in the CT images are marked manually by a specialist as this initial step is a significant challenge for computer vision techniques. Once defined, the lung regions are segmented for clinical diagnoses. This work proposes an automatic segmentation of the lungs in CT images, using the Convolutional Neural Network (CNN) Mask R-CNN, to specialize the model for lung region mapping, combined with supervised and unsupervised machine learning methods (Bayes, Support Vectors Machine (SVM), K-means and Gaussian Mixture Models (GMMs)). Our approach using Mask R-CNN with the K-means kernel produced the best results for lung segmentation reaching an accuracy of 97.68 ± 3.42% and an average runtime of 11.2 s. We compared our results against other works for validation purposes, and our approach had the highest accuracy and was faster than some state-of-the-art methods.},
  archive      = {J_ARTMED},
  author       = {Qinhua Hu and Luís Fabrício de F. Souza and Gabriel Bandeira Holanda and Shara S.A. Alves and Francisco Hércules dos S. Silva and Tao Han and Pedro P. Rebouças Filho},
  doi          = {10.1016/j.artmed.2020.101792},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101792},
  shortjournal = {Artif. Intell. Med.},
  title        = {An effective approach for CT lung segmentation using mask region-based convolutional neural networks},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comprehensive electrocardiographic diagnosis based on deep
learning. <em>ARTMED</em>, <em>103</em>, 101789. (<a
href="https://doi.org/10.1016/j.artmed.2019.101789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease (CVD) is the leading cause of death worldwide, and coronary artery disease (CAD) is a major contributor. Early-stage CAD can progress if undiagnosed and left untreated, leading to myocardial infarction (MI) that may induce irreversible heart muscle damage, resulting in heart chamber remodeling and eventual congestive heart failure (CHF). Electrocardiography (ECG) signals can be useful to detect established MI, and may also be helpful for early diagnosis of CAD. For the latter especially, the ECG perturbations can be subtle and potentially misclassified during manual interpretation and/or when analyzed by traditional algorithms found in ECG instrumentation. For automated diagnostic systems (ADS), deep learning techniques are favored over conventional machine learning techniques, due to the automatic feature extraction and selection processes involved. This paper highlights various deep learning algorithms exploited for the classification of ECG signals into CAD, MI, and CHF conditions. The Convolutional Neural Network (CNN), followed by combined CNN and Long Short-Term Memory (LSTM) models, appear to be the most useful architectures for classification. A 16-layer LSTM model was developed in our study and validated using 10-fold cross-validation. A classification accuracy of 98.5% was achieved. Our proposed model has the potential to be a useful diagnostic tool in hospitals for the classification of abnormal ECG signals.},
  archive      = {J_ARTMED},
  author       = {Oh Shu Lih and V Jahmunah and Tan Ru San and Edward J Ciaccio and Toshitaka Yamakawa and Masayuki Tanabe and Makiko Kobayashi and Oliver Faust and U Rajendra Acharya},
  doi          = {10.1016/j.artmed.2019.101789},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101789},
  shortjournal = {Artif. Intell. Med.},
  title        = {Comprehensive electrocardiographic diagnosis based on deep learning},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent learning approach for improving ECG signal
classification and arrhythmia analysis. <em>ARTMED</em>, <em>103</em>,
101788. (<a href="https://doi.org/10.1016/j.artmed.2019.101788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of cardiac arrhythmia in minimal time is important to prevent sudden and untimely deaths. The proposed work includes a complete framework for analyzing the Electrocardiogram (ECG) signal. The three phases of analysis include 1) the ECG signal quality enhancement through noise suppression by a dedicated filter combination; 2) the feature extraction by a devoted wavelet design and 3) a proposed hidden Markov model (HMM) for cardiac arrhythmia classification into Normal (N), Right Bundle Branch Block (RBBB), Left Bundle Branch Block (LBBB), Premature Ventricular Contraction (PVC) and Atrial Premature Contraction (APC). The main features extracted in the proposed work are minimum, maximum, mean, standard deviation, and median. The experiments were conducted on forty-five ECG records in MIT BIH arrhythmia database and in MIT BIH noise stress test database. The proposed model has an overall accuracy of 99.7 % with a sensitivity of 99.7 % and a positive predictive value of 100 %. The detection error rate for the proposed model is 0.0004. This paper also includes a study of the cardiac arrhythmia recognition using an IoMT (Internet of Medical Things) approach.},
  archive      = {J_ARTMED},
  author       = {Arun Kumar Sangaiah and Maheswari Arumugam and Gui-Bin Bian},
  doi          = {10.1016/j.artmed.2019.101788},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101788},
  shortjournal = {Artif. Intell. Med.},
  title        = {An intelligent learning approach for improving ECG signal classification and arrhythmia analysis},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method of motor imagery classification using eeg
signal. <em>ARTMED</em>, <em>103</em>, 101787. (<a
href="https://doi.org/10.1016/j.artmed.2019.101787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A subject of extensive research interest in the Brain Computer Interfaces (BCIs) niche is motor imagery (MI), where users imagine limb movements to control the system. This interest is owed to the immense potential for its applicability in gaming, neuro-prosthetics and neuro-rehabilitation, where the user’s thoughts of imagined movements need to be decoded. Electroencephalography (EEG) equipment is commonly used for keeping track of cerebrum movement in BCI systems. The EEG signals are recognized by feature extraction and classification. The current research proposes a Hybrid-KELM (Kernel Extreme Learning Machine) method based on PCA (Principal Component Analysis) and FLD (Fisher&#39;s Linear Discriminant) for MI BCI classification of EEG data. The performance and results of the method are demonstrated using BCI competition dataset III, and compared with those of contemporary methods. The proposed method generated an accuracy of 96.54%.},
  archive      = {J_ARTMED},
  author       = {K. Venkatachalam and A. Devipriya and J. Maniraj and M. Sivaram and A. Ambikapathy and Iraj S Amiri},
  doi          = {10.1016/j.artmed.2019.101787},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101787},
  shortjournal = {Artif. Intell. Med.},
  title        = {A novel method of motor imagery classification using eeg signal},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ADHD classification by dual subspace learning using
resting-state functional connectivity. <em>ARTMED</em>, <em>103</em>,
101786. (<a href="https://doi.org/10.1016/j.artmed.2019.101786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most common neurobehavioral diseases in school-age children, Attention Deficit Hyperactivity Disorder (ADHD) has been increasingly studied in recent years. But it is still a challenge problem to accurately identify ADHD patients from healthy persons. To address this issue, we propose a dual subspace classification algorithm by using individual resting-state Functional Connectivity (FC). In detail, two subspaces respectively containing ADHD and healthy control features, called as dual subspaces, are learned with several subspace measures, wherein a modified graph embedding measure is employed to enhance the intra-class relationship of these features. Therefore, given a subject (used as test data) with its FCs, the basic classification principle is to compare its projected component energy of FCs on each subspace and then predict the ADHD or control label according to the subspace with larger energy. However, this principle in practice works with low efficiency, since the dual subspaces are unstably obtained from ADHD databases of small size. Thereby, we present an ADHD classification framework by a binary hypothesis testing of test data. Here, the FCs of test data with its ADHD or control label hypothesis are employed in the discriminative FC selection of training data to promote the stability of dual subspaces. For each hypothesis, the dual subspaces are learned from the selected FCs of training data. The total projected energy of these FCs is also calculated on the subspaces. Sequentially, the energy comparison is carried out under the binary hypotheses. The ADHD or control label is finally predicted for test data with the hypothesis of larger total energy. In the experiments on ADHD-200 dataset, our method achieves a significant classification performance compared with several state-of-the-art machine learning and deep learning methods, where our accuracy is about 90 % for most of ADHD databases in the leave-one-out cross-validation test.},
  archive      = {J_ARTMED},
  author       = {Ying Chen and Yibin Tang and Chun Wang and Xiaofeng Liu and Li Zhao and Zhishun Wang},
  doi          = {10.1016/j.artmed.2019.101786},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101786},
  shortjournal = {Artif. Intell. Med.},
  title        = {ADHD classification by dual subspace learning using resting-state functional connectivity},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of machine learning on patient care: A systematic
review. <em>ARTMED</em>, <em>103</em>, 101785. (<a
href="https://doi.org/10.1016/j.artmed.2019.101785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the expanding use of machine learning (ML) in fields such as finance and marketing, its application in the daily practice of clinical medicine is almost non-existent. In this systematic review, we describe the various areas within clinical medicine that have applied the use of ML to improve patient care. A systematic review was performed in accordance with the PRISMA guidelines using Medline(R), EBM Reviews, Embase, Psych Info, and Cochrane Databases, focusing on human studies that used ML to directly address a clinical problem. Included studies were published from January 1, 2000 to May 1, 2018 and provided metrics on the performance of the utilized ML tool. A total of 1909 unique publications were reviewed, with 378 retrospective articles and 8 prospective articles meeting inclusion criteria. Retrospective publications were found to be increasing in frequency, with 61 % of articles published within the last 4 years. Prospective articles comprised only 2 % of the articles meeting our inclusion criteria. These studies utilized a prospective cohort design with an average sample size of 531. The majority of literature describing the use of ML in clinical medicine is retrospective in nature and often outlines proof-of-concept approaches to impact patient care. We postulate that identifying and overcoming key translational barriers, including real-time access to clinical data, data security, physician approval of “black box” generated results, and performance evaluation will allow for a fundamental shift in medical practice, where specialized tools will aid the healthcare team in providing better patient care.},
  archive      = {J_ARTMED},
  author       = {David Ben-Israel and W. Bradley Jacobs and Steve Casha and Stefan Lang and Won Hyung A. Ryu and Madeleine de Lotbiniere-Bassett and David W. Cadotte},
  doi          = {10.1016/j.artmed.2019.101785},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101785},
  shortjournal = {Artif. Intell. Med.},
  title        = {The impact of machine learning on patient care: A systematic review},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic segmentation with DenseNets for carotid artery
ultrasound plaque segmentation and CIMT estimation. <em>ARTMED</em>,
<em>103</em>, 101784. (<a
href="https://doi.org/10.1016/j.artmed.2019.101784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The measurement of carotid intima media thickness (CIMT) in ultrasound images can be used to detect the presence of atherosclerotic plaques. Usually, the CIMT estimation strategy is semi-automatic, since it requires: (1) a manual examination of the ultrasound image for the localization of a region of interest (ROI), a fast and useful operation when only a small number of images need to be measured; and (2) an automatic delineation of the CIM region within the ROI. The existing efforts for automating the process have replicated the same two-step structure, resulting in two consecutive independent approaches. In this work, we propose a fully automatic single-step approach based on semantic segmentation that allows us to segment the plaque and to estimate the CIMT in a fast and useful manner for large data sets of images. Our single-step approach is based on densely connected convolutional neural networks (DenseNets) for semantic segmentation of the whole image. It has two remarkable characteristics: (1) it avoids ROI definition, and (2) it captures multi-scale contextual information in the complete image interpretation, due to the concatenation of feature maps carried out in DenseNets. Once the input image is segmented, a straightforward method for CIMT estimation and plaque detection is applied. The proposed method has been validated with a large data set (REGICOR) of more than 8000 images, corresponding to two territories of the carotid artery: common carotid artery (CCA) and bulb. Among them, a subset of 331 images has been used to evaluate the performance of semantic segmentation (≈90% for train, ≈10% for test). The experimental results demonstrated that our method outperforms other deep models and shallow approaches found in the literature. In particular, our CIMT estimation reaches a correlation coefficient of 0.81, and a CIMT mean error of 0.02 and 0.06 mm in CCA and Bulb images, respectively. Furthermore, the accuracy for plaque detection is 96.45% and 78.09% in CCA and Bulb, respectively. To test the generalization power, the method has also been tested with another data set (NEFRONA) that includes images acquired with different equipment. The validation carried out demonstrates that the proposed method is accurate and objective for both plaque detection and CIMT measurement. Moreover, the robustness and generalization capacity of the method have been proven with two different data sets.},
  archive      = {J_ARTMED},
  author       = {Maria del Mar Vila and Beatriz Remeseiro and Maria Grau and Roberto Elosua and Àngels Betriu and Elvira Fernandez-Giraldez and Laura Igual},
  doi          = {10.1016/j.artmed.2019.101784},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101784},
  shortjournal = {Artif. Intell. Med.},
  title        = {Semantic segmentation with DenseNets for carotid artery ultrasound plaque segmentation and CIMT estimation},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Topic-informed neural approach for biomedical event
extraction. <em>ARTMED</em>, <em>103</em>, 101783. (<a
href="https://doi.org/10.1016/j.artmed.2019.101783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial step of biological event extraction , event trigger identification has attracted much attention in recent years. Deep representation methods, which have the superiorities of less feature engineering and end-to-end training, show better performance than statistical methods . While most deep learning methods have been done on sentence-level event extraction, there are few works taking document context into account, losing potentially informative knowledge that is beneficial for trigger detection. In this paper, we propose a variational neural approach for biomedical event extraction, which can take advantage of latent topics underlying documents. By adopting a joint modeling manner of topics and events, our model is able to produce more meaningful and event-indicative words compare to prior topic models. In addition, we introduce a language model embeddings to capture context-dependent features. Experimental results show that our approach outperforms various baselines in a commonly used multi-level event extraction corpus.},
  archive      = {J_ARTMED},
  author       = {Junchi Zhang and Mengchi Liu and Yue Zhang},
  doi          = {10.1016/j.artmed.2019.101783},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101783},
  shortjournal = {Artif. Intell. Med.},
  title        = {Topic-informed neural approach for biomedical event extraction},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fusion framework to extract typical treatment patterns
from electronic medical records. <em>ARTMED</em>, <em>103</em>, 101782.
(<a href="https://doi.org/10.1016/j.artmed.2019.101782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic Medical Records (EMRs) contain temporal and heterogeneous doctor order information that can be used for treatment pattern discovery. Our objective is to identify “right patient”, “right drug”, “right dose”, “right route”, and “right time” from doctor order information. We propose a fusion framework to extract typical treatment patterns based on multi-view similarity Network Fusion (SNF) method. The multi-view SNF method involves three similarity measures: content-view similarity, sequence-view similarity and duration-view similarity. An EMR dataset and two metrics were utilized to evaluate the performance and to extract typical treatment patterns. Experimental results on a real-world EMR dataset show that the multi-view similarity network fusion method outperforms all the single-view similarity measures and also outperforms the existing similarity measure methods. Furthermore, we extract and visualize typical treatment patterns by clustering analysis. The extracted typical treatment patterns by combining doctor order content, sequence, and duration views can provide data-driven guidelines for artificial intelligence in medicine and help clinicians make better decisions in clinical practice.},
  archive      = {J_ARTMED},
  author       = {Jingfeng Chen and Leilei Sun and Chonghui Guo and Yanming Xie},
  doi          = {10.1016/j.artmed.2019.101782},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101782},
  shortjournal = {Artif. Intell. Med.},
  title        = {A fusion framework to extract typical treatment patterns from electronic medical records},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-planar 3D breast segmentation in MRI via deep
convolutional neural networks. <em>ARTMED</em>, <em>103</em>, 101781.
(<a href="https://doi.org/10.1016/j.artmed.2019.101781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Dynamic Contrast Enhanced-Magnetic Resonance Imaging (DCE-MRI) has demonstrated to be a valid complementary diagnostic tool for early detection and diagnosis of breast cancer. However, without a CAD (Computer Aided Detection) system, manual DCE-MRI examination can be difficult and error-prone. The early stage of breast tissue segmentation, in a typical CAD, is crucial to increase reliability and reduce the computational effort by reducing the number of voxels to analyze and removing foreign tissues and air. In recent years, the deep convolutional neural networks (CNNs) enabled a sensible improvement in many visual tasks automation, such as image classification and object recognition. These advances also involved radiomics, enabling high-throughput extraction of quantitative features, resulting in a strong improvement in automatic diagnosis through medical imaging. However, machine learning and, in particular, deep learning approaches are gaining popularity in the radiomics field for tissue segmentation. This work aims to accurately segment breast parenchyma from the air and other tissues (such as chest-wall) by applying an ensemble of deep CNNs on 3D MR data. The novelty, besides applying cutting-edge techniques in the radiomics field, is a multi-planar combination of U-Net CNNs by a suitable projection-fusing approach, enabling multi-protocol applications. The proposed approach has been validated over two different datasets for a total of 109 DCE-MRI studies with histopathologically proven lesions and two different acquisition protocols. The median dice similarity index for both the datasets is 96.60 % (±0.30 %) and 95.78 % (±0.51 %) respectively with p &lt; 0.05, and 100% of neoplastic lesion coverage.},
  archive      = {J_ARTMED},
  author       = {Gabriele Piantadosi and Mario Sansone and Roberta Fusco and Carlo Sansone},
  doi          = {10.1016/j.artmed.2019.101781},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101781},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-planar 3D breast segmentation in MRI via deep convolutional neural networks},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Medical knowledge embedding based on recursive neural
network for multi-disease diagnosis. <em>ARTMED</em>, <em>103</em>,
101772. (<a href="https://doi.org/10.1016/j.artmed.2019.101772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representation of knowledge based on first-order logic captures the richness of natural language and supports multiple probabilistic inference models. Although symbolic representation enables quantitative reasoning with statistical probability, it is difficult to utilize with machine learning models as they perform numerical operations. In contrast, knowledge embedding ( i.e., high-dimensional and continuous vectors) is a feasible approach to complex reasoning that can not only retain the semantic information of knowledge, but also establish the quantifiable relationship among embeddings. In this paper, we propose a recursive neural knowledge network (RNKN), which combines medical knowledge based on first-order logic with a recursive neural network for multi-disease diagnosis. After the RNKN is efficiently trained using manually annotated Chinese Electronic Medical Records (CEMRs), diagnosis-oriented knowledge embeddings and weight matrixes are learned. The experimental results confirm that the diagnostic accuracy of the RNKN is superior to those of four machine learning models, four classical neural networks and Markov logic network. The results also demonstrate that the more explicit the evidence extracted from CEMRs, the better the performance. The RNKN gradually reveals the interpretation of knowledge embeddings as the number of training epochs increases.},
  archive      = {J_ARTMED},
  author       = {Jingchi Jiang and Huanzheng Wang and Jing Xie and Xitong Guo and Yi Guan and Qiubin Yu},
  doi          = {10.1016/j.artmed.2019.101772},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101772},
  shortjournal = {Artif. Intell. Med.},
  title        = {Medical knowledge embedding based on recursive neural network for multi-disease diagnosis},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-context CNN ensemble for small lesion detection.
<em>ARTMED</em>, <em>103</em>, 101749. (<a
href="https://doi.org/10.1016/j.artmed.2019.101749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel method for the detection of small lesions in digital medical images. Our approach is based on a multi-context ensemble of convolutional neural networks (CNNs), aiming at learning different levels of image spatial context and improving detection performance. The main innovation behind the proposed method is the use of multiple-depth CNNs, individually trained on image patches of different dimensions and then combined together. In this way, the final ensemble is able to find and locate abnormalities on the images by exploiting both the local features and the surrounding context of a lesion. Experiments were focused on two well-known medical detection problems that have been recently faced with CNNs: microcalcification detection on full-field digital mammograms and microaneurysm detection on ocular fundus images. To this end, we used two publicly available datasets, INbreast and E-ophtha. Statistically significantly better detection performance were obtained by the proposed ensemble with respect to other approaches in the literature, demonstrating its effectiveness in the detection of small abnormalities.},
  archive      = {J_ARTMED},
  author       = {B. Savelli and A. Bria and M. Molinara and C. Marrocco and F. Tortorella},
  doi          = {10.1016/j.artmed.2019.101749},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101749},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-context CNN ensemble for small lesion detection},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-resolution convolutional networks for chest x-ray
radiograph based lung nodule detection. <em>ARTMED</em>, <em>103</em>,
101744. (<a href="https://doi.org/10.1016/j.artmed.2019.101744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is the leading cause of cancer death worldwide. Early detection of lung cancer is helpful to provide the best possible clinical treatment for patients. Due to the limited number of radiologist and the huge number of chest x-ray radiographs (CXR) available for observation, a computer-aided detection scheme should be developed to assist radiologists in decision-making. While deep learning showed state-of-the-art performance in several computer vision applications, it has not been used for lung nodule detection on CXR. In this paper, a deep learning-based lung nodule detection method was proposed. We employed patch-based multi-resolution convolutional networks to extract the features and employed four different fusion methods for classification. The proposed method shows much better performance and is much more robust than those previously reported researches. For publicly available Japanese Society of Radiological Technology (JSRT) database, more than 99% of lung nodules can be detected when the false positives per image (FPs/image) was 0.2. The FAUC and R-CPM of the proposed method were 0.982 and 0.987, respectively. The proposed approach has the potential of applications in clinical practice.},
  archive      = {J_ARTMED},
  author       = {Xuechen Li and Linlin Shen and Xinpeng Xie and Shiyun Huang and Zhien Xie and Xian Hong and Juan Yu},
  doi          = {10.1016/j.artmed.2019.101744},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101744},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-resolution convolutional networks for chest X-ray radiograph based lung nodule detection},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comprehensive analysis of rule formalisms to represent
clinical guidelines: Selection criteria and case study on antibiotic
clinical guidelines. <em>ARTMED</em>, <em>103</em>, 101741. (<a
href="https://doi.org/10.1016/j.artmed.2019.101741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The over-use of antibiotics in clinical domains is causing an alarming increase in bacterial resistance, thus endangering their effectiveness as regards the treatment of highly recurring severe infectious diseases. Whilst Clinical Guidelines ( CGs ) focus on the correct prescription of antibiotics in a narrative form, Clinical Decision Support Systems ( CDSS ) operationalize the knowledge contained in CGs in the form of rules at the point of care. Despite the efforts made to computerize CGs , there is still a gap between CG s and the myriad of rule technologies (based on different logic formalisms) that are available to implement CDSS s in real clinical settings. To help CDSS designers to determine the most suitable rule-based technology (medical-oriented rules, production rules and semantic web rules) with which to model knowledge from CGs for the prescription of antibiotics. We propose a framework of criteria for this purpose that is extensible to more generic CGs. Our proposal is based on the identification of core technical requirements extracted from both literature and the analysis of CGs for antibiotics, establishing three dimensions for analysis: language expressivity, interoperability and industrial aspects. We present a case study regarding the John Hopkins Hospital (JHH) Antibiotic Guidelines for Urinary Tract Infection (UTI ), a highly recurring hospital acquired infection. We have adopted our framework of criteria in order to analyse and implement these CGs using various rule technologies: HL7 Arden Syntax , general-purpose Production Rules System (Drools), HL7 standard Rule Interchange Format (RIF ), Semantic Web Rule Language ( SWRL ) and SParql Inference Notation (SPIN) rule extensions (implementing our own ontology for UTI ). We have identified the main criteria required to attain a maintainable and cost-affordable computable knowledge representation for CGs. We have represented the JHH UTI CGs knowledge in a total of 12 Arden Syntax MLMs , 81 Drools rules and 154 ontology classes, properties and individuals. Our experiments confirm the relevance of the proposed set of criteria and show the level of compliance of the different rule technologies with the JHH UTI CGs knowledge representation. The proposed framework of criteria may help clinical institutions to select the most suitable rule technology for the representation of CGs in general, and for the antibiotic prescription domain in particular, depicting the main aspects that lead to Computer Interpretable Guidelines (CIGs), such as Logic expressivity ( Open /C losed World Assumption, Negation-As-Failure), Temporal Reasoning and Interoperability with existing HIS and clinical workflow. Future work will focus on providing clinicians with suggestions regarding new potential steps for CG s, considering process mining approaches and CGs Process Workflows, the use of HL7 FHIR for HIS interoperability and the representation of Knowledge-as- a-Service (KaaS) .},
  archive      = {J_ARTMED},
  author       = {Natalia Iglesias and Jose M. Juarez and Manuel Campos},
  doi          = {10.1016/j.artmed.2019.101741},
  journal      = {Artificial Intelligence in Medicine},
  month        = {3},
  pages        = {101741},
  shortjournal = {Artif. Intell. Med.},
  title        = {Comprehensive analysis of rule formalisms to represent clinical guidelines: Selection criteria and case study on antibiotic clinical guidelines},
  volume       = {103},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of artificial intelligence in medicine:
Status analysis and development suggestions. <em>ARTMED</em>,
<em>102</em>, 101780. (<a
href="https://doi.org/10.1016/j.artmed.2019.101780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The general public’s attitudes, demands, and expectations regarding medical AI could provide guidance for the future development of medical AI to satisfy the increasing needs of doctors and patients. The objective of this study is to investigate public perceptions, receptivity, and demands regarding the implementation of medical AI. An online questionnaire was designed to investigate the perceptions, receptivity, and demands of general public regarding medical AI between October 13 and October 30, 2018. The distributions of the current achievements, public perceptions, receptivity, and demands among individuals in different lines of work (i.e., healthcare vs non-healthcare) and different age groups were assessed by performing descriptive statistics. The factors associated with public receptivity of medical AI were assessed using a linear regression model. In total, 2,780 participants from 22 provinces were enrolled. Healthcare workers accounted for 54.3 % of all participants. There was no significant difference between the healthcare workers and non-healthcare workers in the high proportion (99 %) of participants expressing acceptance of AI (p = 0.8568), but remarkable distributional differences were observed in demands (p &lt; 0.001 for both demands for AI assistance and the desire for AI improvements) and perceptions (p &lt; 0.001 for safety, validity, trust, and expectations). High levels of receptivity (approximately 100 %), demands (approximately 80 %), and expectations (100 %) were expressed among different age groups. The receptivity of medical AI among the non-healthcare workers was associated with gender, educational qualifications, and demands and perceptions of AI. There was a very large gap between current availability of and public demands for intelligence services (p &lt; 0.001). More than 90 % of healthcare workers expressed a willingness to devote time to learning about AI and participating in AI research. The public exhibits a high level of receptivity regarding the implementation of medical AI. To date, the achievements have been rewarding, and further advancements are required to satisfy public demands. There is a strong demand for intelligent assistance in many medical areas, including imaging and pathology departments, outpatient services, and surgery. More contributions are imperative to facilitate integrated and advantageous implementation in medical AI.},
  archive      = {J_ARTMED},
  author       = {Yifan Xiang and Lanqin Zhao and Zhenzhen Liu and Xiaohang Wu and Jingjing Chen and Erping Long and Duoru Lin and Yi Zhu and Chuan Chen and Zhuoling Lin and Haotian Lin},
  doi          = {10.1016/j.artmed.2019.101780},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101780},
  shortjournal = {Artif. Intell. Med.},
  title        = {Implementation of artificial intelligence in medicine: Status analysis and development suggestions},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced deep learning approach for brain cancer MRI
images classification using residual networks. <em>ARTMED</em>,
<em>102</em>, 101779. (<a
href="https://doi.org/10.1016/j.artmed.2019.101779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is the second leading cause of death after cardiovascular diseases. Out of all types of cancer, brain cancer has the lowest survival rate. Brain tumors can have different types depending on their shape, texture, and location. Proper diagnosis of the tumor type enables the doctor to make the correct treatment choice and help save the patient&#39;s life. There is a high need in the Artificial Intelligence field for a Computer Assisted Diagnosis (CAD) system to assist doctors and radiologists with the diagnosis and classification of tumors. Over recent years, deep learning has shown an optimistic performance in computer vision systems. In this paper, we propose an enhanced approach for classifying brain tumor types using Residual Networks. We evaluate the proposed model on a benchmark dataset containing 3064 MRI images of 3 brain tumor types (Meningiomas, Gliomas, and Pituitary tumors). We have achieved the highest accuracy of 99% outperforming the other previous work on the same dataset.},
  archive      = {J_ARTMED},
  author       = {Sarah Ali Abdelaziz Ismael and Ammar Mohammed and Hesham Hefny},
  doi          = {10.1016/j.artmed.2019.101779},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101779},
  shortjournal = {Artif. Intell. Med.},
  title        = {An enhanced deep learning approach for brain cancer MRI images classification using residual networks},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting dementia with routine care EMR data.
<em>ARTMED</em>, <em>102</em>, 101771. (<a
href="https://doi.org/10.1016/j.artmed.2019.101771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our aim is to develop a machine learning (ML) model that can predict dementia in a general patient population from multiple health care institutions one year and three years prior to the onset of the disease without any additional monitoring or screening. The purpose of the model is to automate the cost-effective, non-invasive, digital pre-screening of patients at risk for dementia. Towards this purpose, routine care data, which is widely available through Electronic Medical Record (EMR) systems is used as a data source. These data embody a rich knowledge and make related medical applications easy to deploy at scale in a cost-effective manner. Specifically, the model is trained by using structured and unstructured data from three EMR data sets: diagnosis, prescriptions, and medical notes. Each of these three data sets is used to construct an individual model along with a combined model which is derived by using all three data sets. Human-interpretable data processing and ML techniques are selected in order to facilitate adoption of the proposed model by health care providers from multiple institutions. The results show that the combined model is generalizable across multiple institutions and is able to predict dementia within one year of its onset with an accuracy of nearly 80% despite the fact that it was trained using routine care data. Moreover, the analysis of the models identified important predictors for dementia. Some of these predictors (e.g., age and hypertensive disorders) are already confirmed by the literature while others, especially the ones derived from the unstructured medical notes, require further clinical analysis.},
  archive      = {J_ARTMED},
  author       = {Zina Ben Miled and Kyle Haas and Christopher M. Black and Rezaul Karim Khandker and Vasu Chandrasekaran and Richard Lipton and Malaz A. Boustani},
  doi          = {10.1016/j.artmed.2019.101771},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101771},
  shortjournal = {Artif. Intell. Med.},
  title        = {Predicting dementia with routine care EMR data},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evidence of the benefits, advantages and potentialities of
the structured radiological report: An integrative review.
<em>ARTMED</em>, <em>102</em>, 101770. (<a
href="https://doi.org/10.1016/j.artmed.2019.101770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structured report is a new trend for the preparation and manipulation of radiological examination reports. The structuring of the radiological report data can bring many benefits and advantages over other existing methodologies. Research and studies about the structured radiological report are highly relevant in clinical and academic subjects, improving medical practice, reducing unobserved problems by radiologists, improving reporting practices and medical diagnoses. Exposing the benefits, advantages and potential of the structured radiological report is important in encouraging the acceptance and implementation of this method by radiology professionals who are still somewhat resistant. The present review highlights the factors that contribute to the consolidation of adopting the structured radiology report methodology, addressing a variety of studies focused on the structuring of the radiological report. This integrative review of the literature is proposed by searching publications and journals databases (CAPES – Coordination of Improvement of Higher-Level Personnel, SciELO – Scientific Electronic Library Online, and PubMed – Publisher Medline) to develop a complete and unified understanding of the subject, so that it becomes a major part of evidence-based initiatives.},
  archive      = {J_ARTMED},
  author       = {Douglas M. Rocha and Lourdes M. Brasil and Janice M. Lamas and Glécia V.S. Luz and Simônides S. Bacelar},
  doi          = {10.1016/j.artmed.2019.101770},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101770},
  shortjournal = {Artif. Intell. Med.},
  title        = {Evidence of the benefits, advantages and potentialities of the structured radiological report: An integrative review},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully-automated deep learning-powered system for DCE-MRI
analysis of brain tumors. <em>ARTMED</em>, <em>102</em>, 101769. (<a
href="https://doi.org/10.1016/j.artmed.2019.101769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) plays an important role in diagnosis and grading of brain tumors. Although manual DCE biomarker extraction algorithms boost the diagnostic yield of DCE-MRI by providing quantitative information on tumor prognosis and prediction, they are time-consuming and prone to human errors. In this paper, we propose a fully-automated, end-to-end system for DCE-MRI analysis of brain tumors. Our deep learning-powered technique does not require any user interaction, it yields reproducible results, and it is rigorously validated against benchmark and clinical data. Also, we introduce a cubic model of the vascular input function used for pharmacokinetic modeling which significantly decreases the fitting error when compared with the state of the art, alongside a real-time algorithm for determination of the vascular input region. An extensive experimental study, backed up with statistical tests, showed that our system delivers state-of-the-art results while requiring less than 3 min to process an entire input DCE-MRI study using a single GPU.},
  archive      = {J_ARTMED},
  author       = {Jakub Nalepa and Pablo Ribalta Lorenzo and Michal Marcinkiewicz and Barbara Bobek-Billewicz and Pawel Wawrzyniak and Maksym Walczak and Michal Kawulok and Wojciech Dudzik and Krzysztof Kotowski and Izabela Burda and Bartosz Machura and Grzegorz Mrukwa and Pawel Ulrych and Michael P. Hayball},
  doi          = {10.1016/j.artmed.2019.101769},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101769},
  shortjournal = {Artif. Intell. Med.},
  title        = {Fully-automated deep learning-powered system for DCE-MRI analysis of brain tumors},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved fuzzy set-based multifactor dimensionality
reduction for detecting epistasis. <em>ARTMED</em>, <em>102</em>,
101768. (<a href="https://doi.org/10.1016/j.artmed.2019.101768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epistasis identification is critical for determining susceptibility to human genetic diseases. The rapid development of technology has enabled scalability to make multifactor dimensionality reduction (MDR) measurements an effective calculation tool that achieves superior detection. However, the classification of high-risk (H) or low-risk (L) groups in multidrug resistance operations calls for extensive research. In this study, an improved fuzzy sigmoid (FS) method using the membership degree in MDR (FSMDR) was proposed for solving the limitations of binary classification. The FS method combined with MDR measurements yielded an improved ability to distinguish similar frequencies of potential multifactor genotypes. We compared our results with other MDR-based methods and FSMDR achieved superior detection rates on simulated data sets. The results indicated that the fuzzy classifications can provide insight into the uncertainty of H/L classification in MDR operation. FSMDR successfully detected significant epistasis of coronary artery disease in the Wellcome Trust Case Control Consortium data set.},
  archive      = {J_ARTMED},
  author       = {Cheng-Hong Yang and Li-Yeh Chuang and Yu-Da Lin},
  doi          = {10.1016/j.artmed.2019.101768},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101768},
  shortjournal = {Artif. Intell. Med.},
  title        = {An improved fuzzy set-based multifactor dimensionality reduction for detecting epistasis},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SemBioNLQA: A semantic biomedical question answering system
for retrieving exact and ideal answers to natural language questions.
<em>ARTMED</em>, <em>102</em>, 101767. (<a
href="https://doi.org/10.1016/j.artmed.2019.101767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering (QA), the identification of short accurate answers to users questions written in natural language expressions, is a longstanding issue widely studied over the last decades in the open-domain. However, it still remains a real challenge in the biomedical domain as the most of the existing systems support a limited amount of question and answer types as well as still require further efforts in order to improve their performance in terms of precision for the supported questions. Here, we present a semantic biomedical QA system named SemBioNLQA which has the ability to handle the kinds of yes/no, factoid, list, and summary natural language questions. This paper describes the system architecture and an evaluation of the developed end-to-end biomedical QA system named SemBioNLQA, which consists of question classification, document retrieval, passage retrieval and answer extraction modules. It takes natural language questions as input, and outputs both short precise answers and summaries as results. The SemBioNLQA system, dealing with four types of questions, is based on (1) handcrafted lexico-syntactic patterns and a machine learning algorithm for question classification, (2) PubMed search engine and UMLS similarity for document retrieval, (3) the BM25 model, stemmed words and UMLS concepts for passage retrieval, and (4) UMLS metathesaurus, BioPortal synonyms, sentiment analysis and term frequency metric for answer extraction. Compared with the current state-of-the-art biomedical QA systems, SemBioNLQA, a fully automated system, has the potential to deal with a large amount of question and answer types. SemBioNLQA retrieves quickly users’ information needs by returning exact answers (e.g., “yes”, “no”, a biomedical entity name, etc.) and ideal answers (i.e., paragraph-sized summaries of relevant information) for yes/no, factoid and list questions, whereas it provides only the ideal answers for summary questions. Moreover, experimental evaluations performed on biomedical questions and answers provided by the BioASQ challenge especially in 2015, 2016 and 2017 (as part of our participation), show that SemBioNLQA achieves good performances compared with the most current state-of-the-art systems and allows a practical and competitive alternative to help information seekers find exact and ideal answers to their biomedical questions. The SemBioNLQA source code is publicly available at https://github.com/sarrouti/sembionlqa .},
  archive      = {J_ARTMED},
  author       = {Mourad Sarrouti and Said Ouatik El Alaoui},
  doi          = {10.1016/j.artmed.2019.101767},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101767},
  shortjournal = {Artif. Intell. Med.},
  title        = {SemBioNLQA: A semantic biomedical question answering system for retrieving exact and ideal answers to natural language questions},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electroencephalogram based communication system for locked
in state person using mentally spelled tasks with optimized network
model. <em>ARTMED</em>, <em>102</em>, 101766. (<a
href="https://doi.org/10.1016/j.artmed.2019.101766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to growth in population, Individual persons with disabilities are increasing daily. To overcome the disability especially in Locked in State (LIS) due to Spinal Cord Injury (SCI), we planned to design four states moving robot from four imagery tasks signals acquired from three electrode systems by placing the electrodes in three positions namely T1, T3 and FP1. At the time of the study we extract the features from Continuous Wavelet Transform (CWT) and trained with Optimized Neural Network model to analyze the features. The proposed network model showed the highest performances with an accuracy of 93.86 % then that of conventional network model. To confirm the performances we conduct offline test. The offline test also proved that new network model recognizing accuracy was higher than the conventional network model with recognizing accuracy of 97.50 %. To verify our result we conducted Information Transfer Rate (ITR), from this analysis we concluded that optimized network model outperforms the other network models like conventional ordinary Feed Forward Neural Network, Time Delay Neural Network and Elman Neural Networks with an accuracy of 21.67 bits per sec. By analyzing classification performances, recognizing accuracy and Information Transformation Rate (ITR), we concluded that CWT features with optimized neural network model performances were comparably greater than that of normal or conventional neural network model and also the study proved that performances of male subjects was appreciated compared to female subjects.},
  archive      = {J_ARTMED},
  author       = {Xu Xiaoxiao and Luo Bin and S. Ramkumar and S. Saravanan and M. Sundar Prakash Balaji and S. Dhanasekaran and J. Thimmiaraja},
  doi          = {10.1016/j.artmed.2019.101766},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101766},
  shortjournal = {Artif. Intell. Med.},
  title        = {Electroencephalogram based communication system for locked in state person using mentally spelled tasks with optimized network model},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DESIGN AND DEVELOPMENT OF HUMAN COMPUTER INTERFACE USING
ELECTROOCULOGRAM WITH DEEP LEARNING. <em>ARTMED</em>, <em>102</em>,
101765. (<a href="https://doi.org/10.1016/j.artmed.2019.101765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s life assistive devices were playing significant role in our life to communicate with others. In that modality Human Computer Interface (HCI) based Electrooculogram (EOG) playing vital part. By using this method we can able to overcome the conventional methods in terms of performance and accuracy. To overcome such problem we analyze the EOG signal from twenty subjects to design nine states EOG based HCI using five electrodes system to measure the horizontal and vertical eye movements. Signals were preprocessed to remove the artifacts and extract the valuable information from collected data by using band power and Hilbert Huang Transform (HHT) and trained with Pattern Recognition Neural Network (PRNN) to classify the tasks. The classification results of 92.17% and 91.85% were shown for band power and HHT features using PRNN architecture. Recognition accuracy was analyzed in offline to identify the possibilities of designing HCI. We compare the two feature extraction techniques with PRNN to analyze the best method for classifying the tasks and recognizing single trail tasks to design the HCI. Our experimental result confirms that for classifying as well as recognizing accuracy of the collected signals using band power with PRNN shows better accuracy compared to other network used in this study. We compared the male subjects performance with female subjects to identify the performance. Finally we compared the male as well as female subjects in age group wise to identify the performance of the system. From that we concluded that male performance was appreciable compared with female subjects as well as age group between 26 to 32 performance and recognizing accuracy were high compared with other age groups used in this study.},
  archive      = {J_ARTMED},
  author       = {Geer Teng and Yue He and Hengjun Zhao and Dunhu Liu and Jin Xiao and S. Ramkumar},
  doi          = {10.1016/j.artmed.2019.101765},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101765},
  shortjournal = {Artif. Intell. Med.},
  title        = {DESIGN AND DEVELOPMENT OF HUMAN COMPUTER INTERFACE USING ELECTROOCULOGRAM WITH DEEP LEARNING},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep supervised learning with mixture of neural networks.
<em>ARTMED</em>, <em>102</em>, 101764. (<a
href="https://doi.org/10.1016/j.artmed.2019.101764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Network (DNN), as a deep architectures, has shown excellent performance in classification tasks . However, when the data has different distributions or contains some latent non-observed factors, it is difficult for DNN to train a single model to perform well on the classification tasks . In this paper, we propose mixture model based on DNNs (MoNNs), a supervised approach to perform classification tasks with a gating network and multiple local expert models. We use a neural network as a gating function and use DNNs as local expert models. The gating network split the heterogeneous data into several homogeneous components. DNNs are combined to perform classification tasks in each component. Moreover, we use EM (Expectation Maximization) as an optimization algorithm . Experiments proved that our MoNNs outperformed the other compared methods on determination of diabetes, determination of benign or malignant breast cancer, and handwriting recognition. Therefore, the MoNNs can solve the problem of data heterogeneity and have a good effect on classification tasks.},
  archive      = {J_ARTMED},
  author       = {Yaxian Hu and Senlin Luo and Longfei Han and Limin Pan and Tiemei Zhang},
  doi          = {10.1016/j.artmed.2019.101764},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101764},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep supervised learning with mixture of neural networks},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). State recognition of decompressive laminectomy with multiple
information in robot-assisted surgery. <em>ARTMED</em>, <em>102</em>,
101763. (<a href="https://doi.org/10.1016/j.artmed.2019.101763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decompressive laminectomy is a common operation for treatment of lumbar spinal stenosis. The tools for grinding and drilling are used for fenestration and internal fixation, respectively. The state recognition is one of the main technologies in robot-assisted surgery, especially in tele-surgery, because surgeons have limited perception during remote-controlled robot-assisted surgery. The novelty of this paper is that a state recognition system is proposed for the robot-assisted tele-surgery. By combining the learning methods and traditional methods, the robot from the slave-end can think about the current operation state like a surgeon, and provide more information and decision suggestions to the master-end surgeon, which aids surgeons work safer in tele-surgery. For the fenestration, we propose an image-based state recognition method that consists a U-Net derived network, grayscale redistribution and dynamic receptive field assisting in controlling the grinding process to prevent the grinding-bit from crossing the inner edge of the lamina to damage the spinal nerves. For the internal fixation, we propose an audio and force-based state recognition method that consists signal features extraction methods, LSTM-based prediction and information fusion assisting in monitoring the drilling process to prevent the drilling-bit from crossing the outer edge of the vertebral pedicle to damage the spinal nerves. Several experiments are conducted to show the reliability of the proposed system in robot-assisted surgery.},
  archive      = {J_ARTMED},
  author       = {Yu Sun and Li Wang and Zhongliang Jiang and Bing Li and Ying Hu and Wei Tian},
  doi          = {10.1016/j.artmed.2019.101763},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101763},
  shortjournal = {Artif. Intell. Med.},
  title        = {State recognition of decompressive laminectomy with multiple information in robot-assisted surgery},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clinical decision support systems for triage in the
emergency department using intelligent systems: A review.
<em>ARTMED</em>, <em>102</em>, 101762. (<a
href="https://doi.org/10.1016/j.artmed.2019.101762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency Departments’ (ED) modern triage systems implemented worldwide are solely based upon medical knowledge and experience. This is a limitation of these systems, since there might be hidden patterns that can be explored in big volumes of clinical historical data. Intelligent techniques can be applied to these data to develop clinical decision support systems (CDSS) thereby providing the health professionals with objective criteria. Therefore, it is of foremost importance to identify what has been hampering the application of such systems for ED triage. The objective of this paper is to assess how intelligent CDSS for triage have been contributing to the improvement of quality of care in the ED as well as to identify the challenges they have been facing regarding implementation. We applied a standard scoping review method with the manual search of 6 digital libraries, namely: ScienceDirect, IEEE Xplore, Google Scholar, Springer, MedlinePlus and Web of Knowledge. Search queries were created and customized for each digital library in order to acquire the information. The core search consisted of searching in the papers’ title, abstract and key words for the topics “triage”, “emergency department”/“emergency room” and concepts within the field of intelligent systems. From the review search, we found that logistic regression was the most frequently used technique for model design and the area under the receiver operating curve (AUC) the most frequently used performance measure. Beside triage priority, the most frequently used variables for modelling were patients’ age, gender, vital signs and chief complaints. The main contributions of the selected papers consisted in the improvement of a patient&#39;s prioritization, prediction of need for critical care, hospital or Intensive Care Unit (ICU) admission, ED Length of Stay (LOS) and mortality from information available at the triage. In the papers where CDSS were validated in the ED, the authors found that there was an improvement in the health professionals’ decision-making thereby leading to better clinical management and patients’ outcomes. However, we found that more than half of the studies lacked this implementation phase. We concluded that for these studies, it is necessary to validate the CDSS and to define key performance measures in order to demonstrate the extent to which incorporation of CDSS at triage can actually improve care.},
  archive      = {J_ARTMED},
  author       = {Marta Fernandes and Susana M. Vieira and Francisca Leite and Carlos Palos and Stan Finkelstein and João M.C. Sousa},
  doi          = {10.1016/j.artmed.2019.101762},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101762},
  shortjournal = {Artif. Intell. Med.},
  title        = {Clinical decision support systems for triage in the emergency department using intelligent systems: A review},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modular cluster based collaborative recommender system for
cardiac patients. <em>ARTMED</em>, <em>102</em>, 101761. (<a
href="https://doi.org/10.1016/j.artmed.2019.101761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few years, hospitals have been collecting a large amount of health related digital data for patients. This includes clinical test reports, treatment updates and disease diagnosis. The information extracted from this data is used for clinical decisions and treatment recommendations. Among health recommender systems, collaborative filtering technique has gained a significant success. However, traditional collaborative filtering algorithms are facing challenges such as data sparsity and scalability, which leads to a reduction in system accuracy and efficiency. In a clinical setting, the recommendations should be accurate and timely. In this paper, an improvised collaborative filtering technique is proposed, which is based on clustering and sub-clustering. The proposed methodology is applied on a supervised set of data for four different types of cardiovascular diseases including angina, non-cardiac chest pain, silent ischemia, and myocardial infarction. The patient data is partitioned with respect to their corresponding disease class, which is followed by k-mean clustering, applied separately on each disease partition. A query patient once directed to the correct disease partition requires to get similarity scores from a reduced sub-cluster, thereby improving the efficiency of the system. Each disease partition has a separate process for recommendation, which gives rise to modularization and helps in improving scalability of the system. The experimental results demonstrate that the proposed modular clustering based recommender system reduces the spatial search domain for a query patient and the time required for providing accurate recommendations. The proposed system improves upon the accuracy of recommendations as demonstrated by the precision and recall values. This is significant for health recommendation systems particularly for those related to cardiovascular diseases.},
  archive      = {J_ARTMED},
  author       = {Anam Mustaqeem and Syed Muhammad Anwar and Muhammad Majid},
  doi          = {10.1016/j.artmed.2019.101761},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101761},
  shortjournal = {Artif. Intell. Med.},
  title        = {A modular cluster based collaborative recommender system for cardiac patients},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective evolutionary design of antibiotic
treatments. <em>ARTMED</em>, <em>102</em>, 101759. (<a
href="https://doi.org/10.1016/j.artmed.2019.101759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antibiotic resistance is one of the major challenges we face in modern times. Antibiotic use, especially their overuse, is the single most important driver of antibiotic resistance. Efforts have been made to reduce unnecessary drug prescriptions, but limited work is devoted to optimising dosage regimes when they are prescribed. The design of antibiotic treatments can be formulated as an optimisation problem where candidate solutions are encoded as vectors of dosages per day. The formulation naturally gives rise to competing objectives, as we want to maximise the treatment effectiveness while minimising the total drug use, the treatment duration and the concentration of antibiotic experienced by the patient. This article combines a recent mathematical model of bacterial growth including both susceptible and resistant bacteria, with a multi-objective evolutionary algorithm in order to automatically design successful antibiotic treatments. We consider alternative formulations combining relevant objectives and constraints. Our approach obtains shorter treatments, with improved success rates and smaller amounts of drug than the standard practice of administering daily fixed doses. These new treatments consistently involve a higher initial dose followed by lower tapered doses.},
  archive      = {J_ARTMED},
  author       = {Gabriela Ochoa and Lee A. Christie and Alexander E. Brownlee and Andrew Hoyle},
  doi          = {10.1016/j.artmed.2019.101759},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101759},
  shortjournal = {Artif. Intell. Med.},
  title        = {Multi-objective evolutionary design of antibiotic treatments},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ophthalmic diagnosis using deep learning with fundus images
– a critical review. <em>ARTMED</em>, <em>102</em>, 101758. (<a
href="https://doi.org/10.1016/j.artmed.2019.101758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An overview of the applications of deep learning for ophthalmic diagnosis using retinal fundus images is presented. We describe various retinal image datasets that can be used for deep learning purposes. Applications of deep learning for segmentation of optic disk, optic cup, blood vessels as well as detection of lesions are reviewed. Recent deep learning models for classification of diseases such as age-related macular degeneration, glaucoma, and diabetic retinopathy are also discussed. Important critical insights and future research directions are given.},
  archive      = {J_ARTMED},
  author       = {Sourya Sengupta and Amitojdeep Singh and Henry A. Leopold and Tanmay Gulati and Vasudevan Lakshminarayanan},
  doi          = {10.1016/j.artmed.2019.101758},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101758},
  shortjournal = {Artif. Intell. Med.},
  title        = {Ophthalmic diagnosis using deep learning with fundus images – a critical review},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skin cancer diagnosis based on optimized convolutional
neural network. <em>ARTMED</em>, <em>102</em>, 101756. (<a
href="https://doi.org/10.1016/j.artmed.2019.101756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of skin cancer is very important and can prevent some skin cancers, such as focal cell carcinoma and melanoma. Although there are several reasons that have bad impacts on the detection precision. Recently, the utilization of image processing and machine vision in medical applications is increasing. In this paper, a new image processing based method has been proposed for the early detection of skin cancer. The method utilizes an optimal Convolutional neural network (CNN) for this purpose. In this paper, improved whale optimization algorithm is utilized for optimizing the CNN. For evaluation of the proposed method, it is compared with some different methods on two different datasets. Simulation results show that the proposed method has superiority toward the other compared methods.},
  archive      = {J_ARTMED},
  author       = {Ni Zhang and Yi-Xin Cai and Yong-Yong Wang and Yi-Tao Tian and Xiao-Li Wang and Benjamin Badami},
  doi          = {10.1016/j.artmed.2019.101756},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101756},
  shortjournal = {Artif. Intell. Med.},
  title        = {Skin cancer diagnosis based on optimized convolutional neural network},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Signal identification system for developing rehabilitative
device using deep learning algorithms. <em>ARTMED</em>, <em>102</em>,
101755. (<a href="https://doi.org/10.1016/j.artmed.2019.101755">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paralyzed patients were increasing day by day. Some of the neurodegenerative diseases like amyotrophic lateral sclerosis, Brainstem Leison, Stupor and Muscular dystrophy affect the muscle movements in the body. The affected persons were unable to migrate. To overcome from their problem they need some assistive technology with the help of bio signals. Electrooculogram (EOG) based Human Computer Interaction (HCI) is one of the technique used in recent days to overcome such problem. In this paper we clearly check the possibilities of creating nine states HCI by our proposed method. Signals were captured through five electrodes placed on the subjects face around the eyes. These signals were amplified with ADT26 bio amplifier, filtered with notch filter, and processed with reference power and band power techniques to extract features to detect the eye movements and mapped with Time Delay Neural Network to classify the eye movements to generate control signal to control external hardware devices. Our experimental study reports that maximum average classification of 91.09% for reference power feature and 91.55%-for band power feature respectively. The obtained result confirms that band power features with TDNN network models shows better performance than reference features for all subjects. From this outcome we conclude that band power features with TDNN network models was more suitable for classifying the eleven difference eye movements for individual subjects. To validate the result obtained from this method we categorize the subjects in age wise to check the accuracy of the system. Single trail analysis was conducted in offline to identify the recognizing accuracy of the proposed system. The result summarize that band power features with TDNN network models exceed the reference power with TDNN network model used in this study. Through the outcome we conclude that that band power features with TDNN network was more suitable for designing EOG based HCI in offline mode.},
  archive      = {J_ARTMED},
  author       = {Wenping Tang and Aiqun Wang and S. Ramkumar and Radeep Krishna Radhakrishnan Nair},
  doi          = {10.1016/j.artmed.2019.101755},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101755},
  shortjournal = {Artif. Intell. Med.},
  title        = {Signal identification system for developing rehabilitative device using deep learning algorithms},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized artificial neural network based performance
analysis of wheelchair movement for ALS patients. <em>ARTMED</em>,
<em>102</em>, 101754. (<a
href="https://doi.org/10.1016/j.artmed.2019.101754">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals with neurodegenerative attacks loose the entire motor neuron movements. These conditions affect the individual actions like walking, speaking impairment and totally make the person in to locked in state (LIS). To overcome the miserable condition the person need rehabilitation devices through a Brain Computer Interfaces (BCI) to satisfy their needs. BMI using Electroencephalogram (EEG) receives the mental thoughts from brain and converts into control signals to activate the exterior communication appliances in the absence of biological channels. To design the BCI, we conduct our study with three normal male subjects, three normal female subjects and three ALS affected individuals from the age of 20–60 with three electrode systems for four tasks. One Dimensional Local Binary Patterns (LBP) technique was applied to reduce the digitally sampled features collected from nine subjects was treated with Grey wolf optimization Neural Network (GWONN) to classify the mentally composed words. Using these techniques, we compared the three types of subjects to identify the performances. The study proves that subjects from normal male categories performance was maximum compared with the other subjects. To assess the individual performance of the subject, we conducted the recognition accuracy test in offline mode. From the accuracy test also, we obtained the best performance from the normal male subjects compared with female and ALS subjects with an accuracy of 98.33 %, 95.00 % and 88.33 %. Finally our study concludes that patients with ALS attack need more training than that of the other subjects.},
  archive      = {J_ARTMED},
  author       = {Li Kai and S. Ramkumar and J. Thimmiaraja and S. Diwakaran},
  doi          = {10.1016/j.artmed.2019.101754},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101754},
  shortjournal = {Artif. Intell. Med.},
  title        = {Optimized artificial neural network based performance analysis of wheelchair movement for ALS patients},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence and the future of psychiatry:
Insights from a global physician survey. <em>ARTMED</em>, <em>102</em>,
101753. (<a href="https://doi.org/10.1016/j.artmed.2019.101753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Futurists have predicted that new autonomous technologies, embedded with artificial intelligence (AI) and machine learning (ML), will lead to substantial job losses in many sectors disrupting many aspects of healthcare. Mental health appears ripe for such disruption given the global illness burden, stigma, and shortage of care providers. To characterize the global psychiatrist community’s opinion regarding the potential of future autonomous technology (referred to here as AI/ML) to replace key tasks carried out in mental health practice. Cross sectional, random stratified sample of psychiatrists registered with Sermo, a global networking platform open to verified and licensed physicians. We measured opinions about the likelihood that AI/ML tools would be able to fully replace – not just assist – the average psychiatrist in performing 10 key psychiatric tasks. Among those who considered replacement likely, we measured opinions about how many years from now such a capacity might emerge. We also measured psychiatrist’s perceptions about whether benefits of AI/ML would outweigh the risks. Survey respondents were 791 psychiatrists from 22 countries representing North America, South America, Europe and Asia-Pacific. Only 3.8 % of respondents felt it was likely that future technology would make their jobs obsolete and only 17 % felt that future AI/ML was likely to replace a human clinician for providing empathetic care. Documenting and updating medical records (75 %) and synthesizing information (54 %) were the two tasks where a majority predicted that AI/ML could fully replace human psychiatrists. Female- and US-based doctors were more uncertain that the benefits of AI would outweigh risks than male- and non-US doctors, respectively. Around one in 2 psychiatrists did however predict that their jobs would be substantially changed by AI/ML. Our findings provide compelling insights into how physicians think about AI/ML which in turn may help us better integrate technology and reskill doctors to enhance mental health care.},
  archive      = {J_ARTMED},
  author       = {P. Murali Doraiswamy and Charlotte Blease and Kaylee Bodner},
  doi          = {10.1016/j.artmed.2019.101753},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101753},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence and the future of psychiatry: Insights from a global physician survey},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial plant optimization algorithm to detect heart rate
&amp; presence of heart disease using machine learning. <em>ARTMED</em>,
<em>102</em>, 101752. (<a
href="https://doi.org/10.1016/j.artmed.2019.101752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cardiovascular diseases are prevalent becoming the leading cause of death; more than half of the cardiovascular diseases are due to Coronary Heart Disease (CHD) which generates the demand of predicting them timely so that people can take precautions or treatment before it becomes fatal. For serving this purpose a Modified Artificial Plant Optimization (MAPO) algorithm has been proposed which can be used as an optimal feature selector along with other machine learning algorithms to predict the heart rate using the fingertip video dataset which further predicts the presence or absence of Coronary Heart Disease in an individual at the moment. Initially, the video dataset has been pre-processed, noise is filtered and then MAPO is applied to predict the heart rate with a Pearson correlation and Standard Error Estimate of 0.9541 and 2.418 respectively. The predicted heart rate is used as a feature in other two datasets and MAPO is again applied to optimize the features of both datasets. Different machine learning algorithms are then applied to the optimized dataset to predict values for presence of current heart disease. The result shows that MAPO reduces the dimensionality to the most significant information with comparable accuracies for different machine learning models with maximum dimensionality reduction of 81.25%. MAPO has been compared with other optimizers and outperforms them with better accuracy.},
  archive      = {J_ARTMED},
  author       = {Prerna Sharma and Krishna Choudhary and Kshitij Gupta and Rahul Chawla and Deepak Gupta and Arun Sharma},
  doi          = {10.1016/j.artmed.2019.101752},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101752},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial plant optimization algorithm to detect heart rate &amp; presence of heart disease using machine learning},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A methodology based on multiple criteria decision analysis
for combining antibiotics in empirical therapy. <em>ARTMED</em>,
<em>102</em>, 101751. (<a
href="https://doi.org/10.1016/j.artmed.2019.101751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current situation of critical progression in resistance to more effective antibiotics has forced the reuse of old highly toxic antibiotics and, for several reasons, the extension of the indications of combined antibiotic therapy as alternative options to broad spectrum empirical mono-therapy. A key aspect for selecting an appropriate and adequate antimicrobial therapy is that prescription must be based on local epidemiology and knowledge since many aspects, such as prevalence of microorganisms and effectiveness of antimicrobials, change from hospitals, or even areas and services within a single hospital. Therefore, the selection of combinations of antibiotics requires the application of a methodology that provides objectivity, completeness and reproducibility to the analysis of the detailed microbiological, epidemiological, pharmacological information on which to base a rational and reasoned choice. We proposed a methodology for decision making that uses a multiple criteria decision analysis (MCDA) to support the clinician in the selection of an efficient combined empiric therapy. The MCDA includes a multi-objective constrained optimization model whose criteria are the maximum efficacy of therapy, maximum activity, the minimum activity overlapping, the minimum use of restricted antibiotics, the minimum toxicity of antibiotics and the activity against the most prevalent and virulent bacteria. The decision process can be defined in 4 steps: (1) selection of clinical situation of interest, (2) definition of local optimization criteria, (3) definition of constraints for reducing combinations, (4) manual sorting of solutions according to patient&#39;s clinical conditions, and (5) selection of a combination. In order to show the application of the methodology to a clinical case, we carried out experiments with antibiotic susceptibility tests in blood samples taken during a five years period at a university hospital. The validation of the results consists of a manual review of the combinations and experiments carried out by an expert physician that has explained the most relevant solutions proposed according to current clinical knowledge and their use. We show that with the decision process proposed, the physician is able to select the best combined therapy according to different criteria such as maximum efficacy, activity and minimum toxicity. A method for the recommendation of combined antibiotic therapy developed on the basis of a multi-objective optimization model may assist the physicians in the search for alternatives to the use of broad-spectrum antibiotics or restricted antibiotics for empirical therapy. The decision proposed can be easily reproduced for any local epidemiology and any different clinical settings.},
  archive      = {J_ARTMED},
  author       = {Manuel Campos and Fernando Jimenez and Gracia Sanchez and Jose M. Juarez and Antonio Morales and Bernardo Canovas-Segura and Francisco Palacios},
  doi          = {10.1016/j.artmed.2019.101751},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101751},
  shortjournal = {Artif. Intell. Med.},
  title        = {A methodology based on multiple criteria decision analysis for combining antibiotics in empirical therapy},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of fetal weight at varying gestational age in the
absence of ultrasound examination using ensemble learning.
<em>ARTMED</em>, <em>102</em>, 101748. (<a
href="https://doi.org/10.1016/j.artmed.2019.101748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstetric ultrasound examination of physiological parameters has been mainly used to estimate the fetal weight during pregnancy and baby weight before labour to monitor fetal growth and reduce prenatal morbidity and mortality. However, the problem is that ultrasound estimation of fetal weight is subject to population’s difference, strict operating requirements for sonographers, and poor access to ultrasound in low-resource areas. Inaccurate estimations may lead to negative perinatal outcomes. This study aims to predict fetal weight at varying gestational age in the absence of ultrasound examination within a certain accuracy. We consider that machine learning can provide an accurate estimation for obstetricians alongside traditional clinical practices, as well as an efficient and effective support tool for pregnant women for self-monitoring. We present a robust methodology using a data set comprising 4212 intrapartum recordings. The cubic spline function is used to fit the curves of several key characteristics that are extracted from ultrasound reports. A number of simple and powerful machine learning algorithms are trained, and their performance is evaluated with real test data. We also propose a novel evaluation performance index called the intersection-over-union (loU) for our study. The results are encouraging using an ensemble model consisting of Random Forest, XGBoost, and LightGBM algorithms. The experimental results show the loU between predicted range of fetal weight at any gestational age that is given by the ensemble model and ultrasound respectively. The machine learning based approach applied in our study is able to predict, with a high accuracy, fetal weight at varying gestational age in the absence of ultrasound examination.},
  archive      = {J_ARTMED},
  author       = {Yu Lu and Xianghua Fu and Fangxiong Chen and Kelvin K.L. Wong},
  doi          = {10.1016/j.artmed.2019.101748},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101748},
  shortjournal = {Artif. Intell. Med.},
  title        = {Prediction of fetal weight at varying gestational age in the absence of ultrasound examination using ensemble learning},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using multi-layer perceptron with laplacian edge detector
for bladder cancer diagnosis. <em>ARTMED</em>, <em>102</em>, 101746. (<a
href="https://doi.org/10.1016/j.artmed.2019.101746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the urinary bladder cancer diagnostic method which is based on Multi-Layer Perceptron and Laplacian edge detector is presented. The aim of this paper is to investigate the implementation possibility of a simpler method (Multi-Layer Perceptron) alongside commonly used methods, such as Deep Learning Convolutional Neural Networks, for the urinary bladder cancer detection. The dataset used for this research consisted of 1997 images of bladder cancer and 986 images of non-cancer tissue. The results of the conducted research showed that using Multi-Layer Perceptron trained and tested with images pre-processed with Laplacian edge detector are achieving AUC AUC value up to 0.99. When different image sizes are compared it can be seen that the best results are achieved if 50 × 50 50×50 and 100 × 100 100×100 images were used.},
  archive      = {J_ARTMED},
  author       = {Ivan Lorencin and Nikola Anđelić and Josip Španjol and Zlatan Car},
  doi          = {10.1016/j.artmed.2019.101746},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101746},
  shortjournal = {Artif. Intell. Med.},
  title        = {Using multi-layer perceptron with laplacian edge detector for bladder cancer diagnosis},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Disease phenotype synonymous prediction through network
representation learning from PubMed database. <em>ARTMED</em>,
<em>102</em>, 101745. (<a
href="https://doi.org/10.1016/j.artmed.2019.101745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synonym mapping between phenotype concepts from different terminologies is difficult because terminology databases have been developed largely independently. Existing maps of synonymous phenotype concepts from different terminology databases are highly incomplete, and manually mapping is time consuming and laborious. Therefore, building an automatic method for predictive mapping of synonymous phenotypes is of special importance. We propose a classifier-based phenotype mapping prediction model (CPM) to predict synonymous relationships between phenotype concepts from different terminology databases. The model takes network semantic representations of phenotypes as input and predicts synonymous relationships by training binary classifiers with a voting strategy. We compared the performance of the CPM with a similarity-based phenotype mapping prediction model (SPM), which predicts mapping based on the ranked cosine similarity of candidate mapping concepts. Based on a network representation N2V-TFIDF, with a majority voting strategy method MV, the CPM achieved accuracy of 0.943, which was 15.4% higher than that of the SPM using the cosine similarity method (0.789) and 23.8% higher than that of the SSDTM method (0.724) proposed in our previous work.},
  archive      = {J_ARTMED},
  author       = {Shiwen Ma and Kuo Yang and Ning Wang and Qiang Zhu and Zhuye Gao and Runshun Zhang and Baoyan Liu and Xuezhong Zhou},
  doi          = {10.1016/j.artmed.2019.101745},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101745},
  shortjournal = {Artif. Intell. Med.},
  title        = {Disease phenotype synonymous prediction through network representation learning from PubMed database},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pressure injury image analysis with machine learning
techniques: A systematic review on previous and possible future methods.
<em>ARTMED</em>, <em>102</em>, 101742. (<a
href="https://doi.org/10.1016/j.artmed.2019.101742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pressure injuries represent a tremendous healthcare challenge in many nations. Elderly and disabled people are the most affected by this fast growing disease. Hence, an accurate diagnosis of pressure injuries is paramount for efficient treatment. The characteristics of these wounds are crucial indicators for the progress of the healing. While invasive methods to retrieve information are not only painful to the patients but may also increase the risk of infections, non-invasive techniques by means of imaging systems provide a better monitoring of the wound healing processes without causing any harm to the patients. These systems should include an accurate segmentation of the wound, the classification of its tissue types, the metrics including the diameter, area and volume, as well as the healing evaluation. Therefore, the aim of this survey is to provide the reader with an overview of imaging techniques for the analysis and monitoring of pressure injuries as an aid to their diagnosis, and proof of the efficiency of Deep Learning to overcome this problem and even outperform the previous methods. In this paper, 114 out of 199 papers retrieved from 8 databases have been analyzed, including also contributions on chronic wounds and skin lesions.},
  archive      = {J_ARTMED},
  author       = {Sofia Zahia and Maria Begoña Garcia Zapirain and Xavier Sevillano and Alejandro González and Paul J. Kim and Adel Elmaghraby},
  doi          = {10.1016/j.artmed.2019.101742},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101742},
  shortjournal = {Artif. Intell. Med.},
  title        = {Pressure injury image analysis with machine learning techniques: A systematic review on previous and possible future methods},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic detection of epileptic seizure based on
approximate entropy, recurrence quantiﬁcation analysis and convolutional
neural networks. <em>ARTMED</em>, <em>102</em>, 101711. (<a
href="https://doi.org/10.1016/j.artmed.2019.101711">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is the most common neurological disorder in humans. Electroencephalogram is a prevalent tool for diagnosing the epileptic seizure activity in clinical, which provides valuable information for understanding the physiological mechanisms behind epileptic disorders. Approximate entropy and recurrence quantification analysis are nonlinear analysis tools to quantify the complexity and recurrence behaviors of non-stationary signals, respectively. Convolutional neural networks are powerful class of models. In this paper, a new method for automatic epileptic electroencephalogram recordings based on the approximate entropy and recurrence quantification analysis combined with a convolutional neural network were proposed. The Bonn dataset was used to assess the proposed approach. The results indicated that the performance of the epileptic seizure detection by approximate entropy and recurrence quantification analysis is good (all of the sensitivities, specificities and accuracies are greater than 80%); especially the sensitivity, specificity and accuracy of the recurrence rate achieved 92.17%, 91.75% and 92.00%. When combines the approximate entropy and recurrence quantification analysis features with convolutional neural networks to automatically differentiate seizure electroencephalogram from normal recordings, the classification result can reach to 98.84%, 99.35% and 99.26%. Thus, this makes automatic detection of epileptic recordings become possible and it would be a valuable tool for the clinical diagnosis and treatment of epilepsy.},
  archive      = {J_ARTMED},
  author       = {Xiaozeng Gao and Xiaoyan Yan and Ping Gao and Xiujiang Gao and Shubo Zhang},
  doi          = {10.1016/j.artmed.2019.101711},
  journal      = {Artificial Intelligence in Medicine},
  month        = {1},
  pages        = {101711},
  shortjournal = {Artif. Intell. Med.},
  title        = {Automatic detection of epileptic seizure based on approximate entropy, recurrence quantiﬁcation analysis and convolutional neural networks},
  volume       = {102},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
