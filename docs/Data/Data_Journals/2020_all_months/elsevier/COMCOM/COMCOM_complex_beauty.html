<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comcom---623">COMCOM - 623</h2>
<ul>
<li><details>
<summary>
(2020). Blockchain-based mobility-aware offloading mechanism for fog
computing services. <em>COMCOM</em>, <em>164</em>, 261–273. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile users could offload some computations from the mobile devices to the nearby geo-distributed Fog servers which are provided by Fog computing infrastructure to release the computation workloads, and therefore improve quality of experience for themselves. However, mobile users may mistakenly offload their computations to the Fog servers which have been injected by some attackers, and these compromised Fog servers would possibly establish man-in-the-middle attack during the offloading procedure, and therefore induce privacy leaking and security issues. Meanwhile, as most of mobile users have natural mobility features, there still needs mobility-aware offloading technique for improving the offloading efficiency. Also, for Fog computing provider, to charge service fees for offloading service in a distributed fashion is necessary for providing geo-distributed offloading service. All of these challenges above motivate us to bring blockchain technique into Fog computing so as to verify authenticity of each Fog server. Hence, we propose a new B lockchain-based M obility-aware O ffloading (i.e., BMO) mechanism in this paper and we modeled the offloading problem in our proposed environment. Concretely, our BMO constantly maintains a set of candidate authorized Fog servers by leveraging blockchain , and the offloading decision could be made in a real-time fashion in mobile devices according to mobility prediction of users. Experimental results have demonstrated the feasibility and efficiency of BMO.},
  archive      = {J_COMCOM},
  author       = {Wanchun Dou and Wenda Tang and Bowen Liu and Xiaolong Xu and Qiang Ni},
  doi          = {10.1016/j.comcom.2020.10.007},
  journal      = {Computer Communications},
  pages        = {261-273},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain-based mobility-aware offloading mechanism for fog computing services},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectrum-aware cross-layered routing protocol for cognitive
radio ad hoc networks. <em>COMCOM</em>, <em>164</em>, 249–260. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive radio network has been proposed as a promising technology to satisfy the manifold requirements of future generation (5G) wireless system by intelligently accessing the underutilized channel of a primary user. However, due to the heterogeneity in channel propagation characteristics , intermittent availability of licensed channel, recurrent hand-offs, and need of a protection to primary users, finding a successful route is more challenging. Also, incorporation of opportunistic spectrum access in cognitive radio network requires a potential spectrum management functions across the network layers. Hence, a cross-layered channel assignment algorithm and routing algorithm is proposed for a cognitive radio ad hoc network which can overcome above-mentioned challenges and provide a stable path for routing of data packets. A novel metric, for the probability of successful transmission of a channel is derived by considering channel statistics, sensing periodicity of the cognitive user, and time-varying channel quality. Also, the number of available channels and their characteristics is considered for the selection of a next-hop node with an aim to avoid the one-hop neighbors located in the PU transmission range. The proposed routing protocol is simulated in ns-2 and compared with the existing similar protocols. The performance shows that the proposed algorithm performs better in terms of throughput, end-to-end delay, number of spectrum hand-offs, and interference to the primary user in a significant manner.},
  archive      = {J_COMCOM},
  author       = {Rashmi Naveen Raj and Ashalatha Nayak and M. Sathish Kumar},
  doi          = {10.1016/j.comcom.2020.10.011},
  journal      = {Computer Communications},
  pages        = {249-260},
  shortjournal = {Comput. Commun.},
  title        = {Spectrum-aware cross-layered routing protocol for cognitive radio ad hoc networks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed task offloading strategy to low load base
stations in mobile edge computing environment. <em>COMCOM</em>,
<em>164</em>, 240–248. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the limited computing resources and battery capacity of existing mobile devices , it cannot meet the requirements of low load base station group for computing capacity and delay, and the emergence of mobile edge computing (MEC) technology provides the possibility for it. Therefore, a distributed task unloading strategy to low load base station group under MEC environment is proposed. Firstly, the communication resource, computing resource and task queue of low load base station group are modeled to quantify the energy cost in the process of task unloading. Then, the game theory is introduced, and the potential game model is used to solve the problem of distributed task unloading. The target function of energy optimization based on delay limitation is transformed into the potential game equation, and the mobile device selects MEC nodes according to the game results to calculate the unloading. Finally, based on the MATLAB platform, the algorithm is simulated, and the results show that the proposed potential game equation can converge to the Nash equilibrium . Compared with other algorithms, the proposed distributed task unloading algorithm can effectively save the energy consumption of task unloading.},
  archive      = {J_COMCOM},
  author       = {Yihong Li and Congshi Jiang},
  doi          = {10.1016/j.comcom.2020.10.021},
  journal      = {Computer Communications},
  pages        = {240-248},
  shortjournal = {Comput. Commun.},
  title        = {Distributed task offloading strategy to low load base stations in mobile edge computing environment},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robustness analytics to data heterogeneity in edge
computing. <em>COMCOM</em>, <em>164</em>, 229–239. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning is a framework that jointly trains a model with complete knowledge on a remotely placed centralized server, but without the requirement of accessing the data stored in distributed machines. Some work assumes that the data generated from edge devices are identically and independently sampled from a common population distribution. However, such ideal sampling may not be realistic in many contexts. Also, models based on intrinsic agency, such as active sampling schemes, may lead to highly biased sampling. So an imminent question is how robust Federated Learning is to biased sampling? In this work 1 , we experimentally investigate two such scenarios. First, we study a centralized classifier aggregated from a collection of local classifiers trained with data having categorical heterogeneity. Second, we study a classifier aggregated from a collection of local classifiers trained by data through active sampling at the edge. We present evidence in both scenarios that Federated Learning is robust to data heterogeneity when local training iterations and communication frequency are appropriately chosen.},
  archive      = {J_COMCOM},
  author       = {Jia Qian and Lars Kai Hansen and Xenofon Fafoutis and Prayag Tiwari and Hari Mohan Pandey},
  doi          = {10.1016/j.comcom.2020.10.020},
  journal      = {Computer Communications},
  pages        = {229-239},
  shortjournal = {Comput. Commun.},
  title        = {Robustness analytics to data heterogeneity in edge computing},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint link-level and network-level reconfiguration for urban
mmWave wireless backhaul networks. <em>COMCOM</em>, <em>164</em>,
215–228. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid densification of small cells in 5G and beyond cellular networks , deploying wired high-bandwidth connections to every small cell base station (BS) is difficult, particularly in older metropolitan areas where infrastructure for fiber deployment is lacking. For this reason, mmWave wireless backhaul has been proposed as a cost-effective and flexible alternative that has the potential to support the high data rates needed to accommodate backhaul traffic demands. To address the robustness of such networks, we investigate a novel relay-assisted backhaul architecture, where a number of small-cell BSs and relays are deployed, e.g. on the lampposts of urban streets. In this scenario, the interconnected logical links constitute a mesh network, which offers opportunities for both link-level and network-level reconfiguration to overcome blockages and/or node failures. We present two joint link-network level reconfiguration schemes for recovery after exceptional events. One prioritizes relay path (link-level) reconfiguration and uses alternate network-level paths only if necessary. The other splits traffic on both reconfigured logical links and backup network paths to improve throughput. Through simulation, the reconfiguration schemes are shown to not only provide near-optimal backhaul survivability but to also maintain high network throughput across a range of scenarios for urban mmWave backhaul networks . The schemes are also validated to significantly outperform existing purely link-level and purely network-level reconfiguration schemes.},
  archive      = {J_COMCOM},
  author       = {Yuchen Liu and Qiang Hu and Douglas M. Blough},
  doi          = {10.1016/j.comcom.2020.10.010},
  journal      = {Computer Communications},
  pages        = {215-228},
  shortjournal = {Comput. Commun.},
  title        = {Joint link-level and network-level reconfiguration for urban mmWave wireless backhaul networks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Result return aware offloading scheme in vehicular edge
networks for IoT. <em>COMCOM</em>, <em>164</em>, 201–214. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of microprocessor technology, massive IoT devices are deployed in smart cities which promotes numerous supervisory control and data acquisition (SCADA) systems to accomplish the key issue. The emergence of computation intensive and delay sensitive applications makes it quite a challenge for IoT devices in SCADA systems with very weak computing capacity. Vehicular edge computing (VEC) is a new computing paradigm with great potential of enhancing SCADA system performance by offloading applications from the resource-constrained SCADA system to lightweight and ubiquitous VEC servers. In this paper, we propose a solution to exploit the load of IoT devices offloaded to VEC server only through vehicles by three steps. Firstly, the tasks from SCADA system are loaded via vehicles; Secondly, vehicles offload task to VEC servers; Finally, the vehicle returns the result to SCADA system. We establish this problem as integrating offloading to VEC servers with load balancing, and returning the result to SCADA system with less cost. A Joint Selection decision, Computation resource and Return result (JSCR) scheme is proposed to solve the problem. First, we propose to integrate the load balance with the tasks offload problem to efficiently complete task and further formulate the problem as a mix-integer non-linear programming problem. Then, we decouple the problem as two subproblems and develop a low complexity algorithm to jointly optimize Selection decision, Computation resource allocation and Return result. Finally, we conducted extensive simulation experiments. The results illustrate that the proposed algorithm exhibits fast convergence speed and demonstrates the superior performance. Specifically, the proposed JSCR scheme improves the system utility by 15.81\% and load balancing efficiency by 27.5\%.},
  archive      = {J_COMCOM},
  author       = {Wei Huang and Kaoru Ota and Mianxiong Dong and Tian Wang and Shaobo Zhang and Jinhuan Zhang},
  doi          = {10.1016/j.comcom.2020.10.019},
  journal      = {Computer Communications},
  pages        = {201-214},
  shortjournal = {Comput. Commun.},
  title        = {Result return aware offloading scheme in vehicular edge networks for IoT},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An energy efficient cluster head selection approach for
performance improvement in network-coding-based wireless sensor networks
with multiple sinks. <em>COMCOM</em>, <em>164</em>, 188–200. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limited power source of sensors is the main constraint of Wireless Sensor Networks (WSNs); therefore, some energy management techniques are required. Network coding and topology control techniques have received extensive attention to decrease energy consumption and improve network performance. Although, combining these two techniques in WSNs can reduce energy consumption efficiently, their main drawback is the computation time, which grows exponentially by increasing nodes; this is not a convenient case for large-scale networks. In this paper, we utilize clustering method as a well-known topology control technique to overcome the mentioned drawback. The initial probability of cluster head selection is critical in distributed clustering algorithms . The results show that finding an appropriate probability provides a robust and fast alternative for the optimization approaches that are sensitive to the initial guess. Hence, we determine a near-optimal probability for cluster head selection to reach the maximum efficiency in the energy consumption. This probability is specified in terms of the number of nodes in the network and the distance of each node from its nearest neighbor provided that the neighbor lies within an angle of the source–destination axis. Our clustering method is based on learning automata and a sleep–awake mechanism to improve results. Accordingly, a routing algorithm along with an optimization problem is developed, which is called inter cluster subgraph selection. Simulation results show that the proposed approach is suitable for large-scale WSNs. Moreover, we demonstrate that the performance of the proposed approach, in terms of energy consumption and network lifetime, is more beneficial as compared to some existing algorithms.},
  archive      = {J_COMCOM},
  author       = {Saeed Doostali and Seyed Morteza Babamir},
  doi          = {10.1016/j.comcom.2020.10.014},
  journal      = {Computer Communications},
  pages        = {188-200},
  shortjournal = {Comput. Commun.},
  title        = {An energy efficient cluster head selection approach for performance improvement in network-coding-based wireless sensor networks with multiple sinks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on computers and communications.
<em>COMCOM</em>, <em>164</em>, 185–187. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Rodolfo W.L. Coutinho and Michela Meo},
  doi          = {10.1016/j.comcom.2020.08.018},
  journal      = {Computer Communications},
  pages        = {185-187},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on computers and communications},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-reservoirs EEG signal feature sensing and recognition
method based on generative adversarial networks. <em>COMCOM</em>,
<em>164</em>, 177–184. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG emotion recognition is one of the interesting and challenging tasks in the research based emotion human–computer interface system. In this paper, a multi-reservoirs feature coding continuous label fusion semi-supervised Generative Adversarial Networks (MCLFS-GAN) is proposed by using permutation phase transfer entropy as the EEG signal feature. Firstly, the obtained features are encapsulated in time series, and then the features are sent into multi-reservoirs according to the division of brain intra, brain interval or frequency band. After convolution optimization, the feature expression with time sequence relationship is obtained. The generic representation between the features and pseudo effective feature expression are iteratively learned in encoder E and generator G in the generative adversarial way. In addition, the continuous fusion for class intra tags can help to form continuous differences between classes. The experimental results show that the accuracy for the four classification is 81.32\% and 54.87\% respectively by using SAP and LOSO in DEAP database. Compared with other models, this algorithm can effectively improve the recognition performance.},
  archive      = {J_COMCOM},
  author       = {Yindong Dong and Fuji Ren},
  doi          = {10.1016/j.comcom.2020.10.004},
  journal      = {Computer Communications},
  pages        = {177-184},
  shortjournal = {Comput. Commun.},
  title        = {Multi-reservoirs EEG signal feature sensing and recognition method based on generative adversarial networks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VLA-CR: A variable action-set learning automata-based
cognitive routing protocol for IoT. <em>COMCOM</em>, <em>164</em>,
162–176. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is a heterogeneous, mixed, and uncertain ubiquitous network , which has significantly affected the concept of wireless networking. A large number of wireless devices have connected through the IoT and shared large amounts of data. So, efficient routing and forwarding data packets from the wireless devices toward gateways, which have connected to the Internet, is one of the most important issues in IoT. This paper has focused on routing and forwarding data packets in IoT. Firstly, a learning automata-based cognitive framework has been applied to integrate cognition into IoT; because current IoT lacks intelligence and cannot satisfy the increasing application performance requirements, and also adding cognition into IoT equips it with a brain and high level intelligence. Then, a new routing and forwarding protocol, which benefits from cross-layer optimization between routing and Media Access Control (MAC) layer protocols, has been proposed. In the proposed protocol a network of variable action-set learning automata establishes a route between source nodes and a corresponding gateway, by making a directed acyclic graph toward the gateway. Then, using a set of learning automata , MAC layer protocol parameters are configured to properly forward data packets hop by hop. The proposed protocol has been named VLA-CR ( V ariable Action-set L earning A utomata-based C ognitive R outing Protocol). Based on Martingale theorem, the convergence of VLA-CR has been proved. Finally, extensive simulation experiments have been conducted to show the performance of the proposed protocol. Simulation results show the superiority of VLA-CR over several existing routing protocol in terms of end-to-end reliability, end-to-end delay, power consumption , and routing time.},
  archive      = {J_COMCOM},
  author       = {Soulmaz Gheisari},
  doi          = {10.1016/j.comcom.2020.10.015},
  journal      = {Computer Communications},
  pages        = {162-176},
  shortjournal = {Comput. Commun.},
  title        = {VLA-CR: A variable action-set learning automata-based cognitive routing protocol for IoT},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of things and augmented reality in the age of 5G.
<em>COMCOM</em>, <em>164</em>, 158–161. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things is a system in which computing equipment, machinery, and digital machines are related to each other. It has a universal unique identification code (UID) and the ability to transmit data through the network without the need for human-to-human or human-to-device interaction. Augmented reality technology is a technology that ingeniously integrates virtual information with the real world, which uses computer-generated text, images, three-dimensional models, music, video and other virtual information to simulate and apply them to the real world, these two kinds of information are mutually exclusive and supplement to achieve “enhancement” of the real world. In the past few decades, people have made great efforts on the Internet of Things, which makes it possible or accessible to be applied in various fields, including home robotics, intelligent cities and Augmented Reality (AR). Therefore, these applications have captured the attention and enhanced aspirations of researchers in fields of machine vision, computer graphics and computer vision.},
  archive      = {J_COMCOM},
  author       = {Zhihan Lv and Jaime Lloret and Houbing Song},
  doi          = {10.1016/j.comcom.2020.08.019},
  journal      = {Computer Communications},
  pages        = {158-161},
  shortjournal = {Comput. Commun.},
  title        = {Internet of things and augmented reality in the age of 5G},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study of LoRaWAN protocol performance for IoT applications
in smart agriculture. <em>COMCOM</em>, <em>164</em>, 148–157. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of Internet of Things (IoT) is becoming increasingly common in agribusiness to increase food production capacity for the expanding global population. Recently, low-power wide-area networks (LPWANs) have been used in the development of IoT applications that require low power consumption and low data transmission rates . LoRaWAN is considered the most suitable communication network for LPWANs for IoT applications in smart agriculture. In this paper, we present an in-depth study of the performance of the LoRaWAN communication network in the context of an IoT application for a pilot farm. We consider several scenarios and analyze simulation results by using Network Simulator 3. We then propose a mathematical model that precisely predicts the successful packet delivery rate for this type of network considering the number of nodes and the transmission interval duration. Finally, we validate the results of our model by comparing them with other simulation results under different scenarios.},
  archive      = {J_COMCOM},
  author       = {Badreddine Miles and El-Bay Bourennane and Samia Boucherkha and Salim Chikhi},
  doi          = {10.1016/j.comcom.2020.10.009},
  journal      = {Computer Communications},
  pages        = {148-157},
  shortjournal = {Comput. Commun.},
  title        = {A study of LoRaWAN protocol performance for IoT applications in smart agriculture},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient non-segregated routing for reconfigurable
demand-aware networks. <em>COMCOM</em>, <em>164</em>, 138–147. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more networks are becoming reconfigurable : not just the routing can be programmed, but the physical layer itself as well. Various technologies enable this programmability , ranging from optical circuit switches to beamformed wireless connections and free-space optical interconnects . Existing reconfigurable network topologies are typically hybrid in nature, consisting of static and a reconfigurable links. However, even though the static and reconfigurable links form a joint structure, routing policies are artificially segregated and hence do not fully exploit the network resources: the state of the art is to route large elephant flows on direct reconfigurable links, whereas the remaining traffic is left to the static network topology . Recent work showed that such artificial segregation is inefficient, but did not provide the tools to actually leverage the benefits on non-segregated routing. In this paper, we provide several algorithms which take advantage of non-segregated routing, by jointly optimizing topology and routing. We compare our algorithms to segregated routing policies and also evaluate their performance in workload-driven simulations, based on real-world traffic traces. We find that our algorithms do not only outperform segregated routing policies, in various settings, but also come close to the optimal solution, computed by a integer linear program formulation, also presented in this paper. Finally, we also provide insights into the complexity of the underlying combinatorial optimization problem , by deriving approximation hardness results.},
  archive      = {J_COMCOM},
  author       = {Thomas Fenz and Klaus-Tycho Foerster and Stefan Schmid and Anaïs Villedieu},
  doi          = {10.1016/j.comcom.2020.10.003},
  journal      = {Computer Communications},
  pages        = {138-147},
  shortjournal = {Comput. Commun.},
  title        = {Efficient non-segregated routing for reconfigurable demand-aware networks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the dynamics of valley times and its application to
bulk-transfer scheduling. <em>COMCOM</em>, <em>164</em>, 124–137. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periods of low load have been used for the scheduling of non-interactive tasks since the early stages of computing. Nowadays, the scheduling of bulk transfers—i.e., large-volume transfers without precise timing, such as database distribution, resources replication or backups—stands out among such tasks, given its direct effect on both the performance and billing of networks. Through visual inspection of traffic-demand curves of diverse points of presence (PoP), either a network, link, Internet service provider or Internet exchange point, it becomes apparent that low-use periods of bandwidth demands occur at early morning, showing a noticeable convex shape. Such observation led us to study and model the time when such demands reach their minimum, on what we have named valley time of a PoP, as an approximation to the ideal moment to carry out bulk transfers. After studying and modeling single-PoP scenarios both temporally and spatially seeking homogeneity in the phenomenon, as well as its extension to multi-PoP scenarios or paths—a meta-PoP constructed as the aggregation of several single PoPs—, we propose a final predictor system for the valley time. This tool works as an oracle for scheduling bulk transfers, with different versions according to time scales and the desired trade-off between precision and complexity. The evaluation of the system, named VTP , has proven its usefulness with errors below an hour on estimating the occurrence of valley times, as well as errors around 10\% in terms of bandwidth between the prediction and actual valley traffic.},
  archive      = {J_COMCOM},
  author       = {David Muelas and José Luis García-Dorado and Sergio Albandea and Jorge E. López de Vergara and Javier Aracil},
  doi          = {10.1016/j.comcom.2020.09.015},
  journal      = {Computer Communications},
  pages        = {124-137},
  shortjournal = {Comput. Commun.},
  title        = {On the dynamics of valley times and its application to bulk-transfer scheduling},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing a LoWPAN convergence layer for the information
centric internet of things. <em>COMCOM</em>, <em>164</em>, 114–123. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-power Internet of Things (IoT) introduces lossy radio links with ultra-constrained frame sizes and high transmission cost for each byte. Information Centric Networking (ICN) is considered a promising communication technology in this regime, as it increases reliability by ubiquitous caching and eases transmission efforts by hop-wise forwarding. Common ICN layers such as NDN, however, were designed for fixed network infrastructure and require an adaptation layer to the constrained wireless—as the common Internet Protocol does. In this paper, we design and evaluate such an ICN convergence layer for low power lossy links that (1) augments the NDN stateful forwarding plane with a highly efficient name eliding, (2) devises stateless compression schemes for standard NDN use cases with utile data encodings, (3) adapts NDN packets to the small MTU size of IEEE 802.15.4, and (4) generates compatibility with 6LoWPAN so that IPv6 and NDN can coexist on the same LoWPAN links. Our findings indicate that stateful compression can reduce the size of NDN data packets by more than 70\% in realistic examples, while packet fragmentation operates in a predictable way even for high fragment numbers. Our experiments show that for common use cases ICNLoWPAN saves 33\% of transmission resources over NDN, and about 20\% over 6LoWPAN.},
  archive      = {J_COMCOM},
  author       = {Cenk Gündoğan and Peter Kietzmann and Thomas C. Schmidt and Matthias Wählisch},
  doi          = {10.1016/j.comcom.2020.10.002},
  journal      = {Computer Communications},
  pages        = {114-123},
  shortjournal = {Comput. Commun.},
  title        = {Designing a LoWPAN convergence layer for the information centric internet of things},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-user boolean searchable encryption supporting fast
ranking in mobile clouds. <em>COMCOM</em>, <em>164</em>, 100–113. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile cloud computing has become an important technology for mobile services . It overcomes physical limitations of mobile devices towards flexible and scalable mobile services . When using mobile clouds, people usually upload and store their data in cloud servers, and access the data through mobile devices from anywhere. As the privacy of the sensitive data is the major concern of users, the data is often encrypted before storing in cloud servers. However, the flexibility using the data is thereby affected, such as a Boolean search over the encrypted data , or ranking search results. To address these problems, in this paper we first propose a novel multi-user Boolean keyword search scheme (MBKSS) to achieve a rapid Boolean query outcome, while eliminating query interactions between users and the data owner. To rank search results and protect the privacy of relevance scores between files and keywords, we design a new homomorphic cryptosystem with partial decryption, which could be used as a basis for constructing a fast ranking search protocol (FRSP). A comprehensive security analysis shows that the proposed MBKSS and FRSP can achieve secure Boolean search and ranking. The experimental results demonstrate that the proposed MBKSS and FRSP are efficient and suitable for mobile devices.},
  archive      = {J_COMCOM},
  author       = {Zehong Chen and Fangguo Zhang and Peng Zhang and Hanbang Zhao},
  doi          = {10.1016/j.comcom.2020.09.009},
  journal      = {Computer Communications},
  pages        = {100-113},
  shortjournal = {Comput. Commun.},
  title        = {Multi-user boolean searchable encryption supporting fast ranking in mobile clouds},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 5G network-oriented hierarchical distributed cloud computing
system resource optimization scheduling and allocation. <em>COMCOM</em>,
<em>164</em>, 88–99. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the core technology of the next generation mobile communication system , the development of 5G key technologies needs to be able to efficiently and effectively support massive data services . Aiming at the impact of massive data traffic on mobile communication networks in 5G communication systems , this paper proposes a 5G-oriented hierarchical distributed cloud service mobile communication system architecture. The model consists of a cloud access layer, a distributed micro-cloud system, and a core cloud data center . The distributed micro cloud system consists of multiple micro clouds that are deployed to the edge of the network. The service content in the core cloud data center can be deployed and cached to the local micro cloud server in advance to reduce repeated redundant transmission of user requested content in the network. Aiming at the problem of how to determine the migration object when dynamically optimizing the resource structure, a heuristic function-based dynamic optimization algorithm for cloud resources is proposed. The experimental results show that the dynamic expansion algorithm of cloud resources based on dynamic programming ideas can better improve the performance of virtual resources, and the dynamic optimization algorithm of cloud resources based on heuristic functions can effectively and quickly optimize the resource structure, thereby improving the operating efficiency of user virtual machine groups. An efficient resource allocation scheme based on cooperative Q (Quality) learning is proposed. The environmental knowledge obtained by the base station learning and exchanging information is used for distributed resource block allocation. This resource allocation scheme can obtain the optimal resource allocation strategy in a short learning time, and can terminate the learning process at any time according to the delay requirements of different services. Compared with traditional resource allocation schemes, it can effectively improve system throughput.},
  archive      = {J_COMCOM},
  author       = {Guang Zheng and Hao Zhang and Yanling Li and Lei Xi},
  doi          = {10.1016/j.comcom.2020.10.005},
  journal      = {Computer Communications},
  pages        = {88-99},
  shortjournal = {Comput. Commun.},
  title        = {5G network-oriented hierarchical distributed cloud computing system resource optimization scheduling and allocation},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FoT-stream: A fog platform for data stream analytics in IoT.
<em>COMCOM</em>, <em>164</em>, 77–87. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has developed infrastructures and applications that generate large amounts of data. These data are usually yielded as streams, characterized for being continuous and infinite, and presenting the peculiarity of modifying their behavior over time. Due to the large capacity of storage, data processing, and provisioning of resources, such data are generally processed/analyzed in Cloud Computing environments . Although those environments provide IoT infrastructure with adequate scalability and resource-centric features, the distance between devices and the cloud can impose limitations to achieve low latency in data traffic. In order to maintain scalability, achieve low latency, and reduce data traffic between the IoT devices and the Cloud, the Fog Computing was proposed, providing resource availability at the edge of the network. Although Fog Computing establishes resource availability at the edge of the network, the technologies/techniques currently used for IoT data processing and analysis may not be sufficient to support the continuous and unlimited streams that IoT platforms and applications produce. In addition, data stream applications at Fog must be supported by the computationally limited devices. Therefore, aiming at taking advantage of Fog Computing and resolve the gap of the data stream in IoT environments, this work presents a new platform called FoT-Stream designed to process and analyze, in real-time, data stream from the Internet of Things in Fog. The main advantage of using our approach is the possibility of reducing the amount of data transmitted on the network infrastructure, which allows, as a consequence, to perform an online data modeling , by detecting changes in data behavior, and a reduction of the Internet usage. Our results in a real-world scenario emphasize FoT-Stream considerably reduces the latency and amount of data traffic in IoT environments without affecting the system throughput.},
  archive      = {J_COMCOM},
  author       = {Brenno M. Alencar and Ricardo A. Rios and Cleber Santana and Cássio Prazeres},
  doi          = {10.1016/j.comcom.2020.10.001},
  journal      = {Computer Communications},
  pages        = {77-87},
  shortjournal = {Comput. Commun.},
  title        = {FoT-stream: A fog platform for data stream analytics in IoT},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Congestion-aware WiFi offload algorithm for 5G heterogeneous
wireless networks. <em>COMCOM</em>, <em>164</em>, 69–76. (<a
href="https://doi.org/10.1016/j.comcom.2020.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First, the key technologies of 5G heterogeneous wireless networks are introduced. Based on the 5G heterogeneous network fusion architecture, heterogeneous network technologies are used to achieve the integration between different access networks, so that they can cooperate with each other, coordinate interference, and improve spectrum resources. Utilization and transmission efficiency; At the same time, an enhanced ADNSF congestion-aware WiFi(WIreless FIdelity) offloading system suitable for 5G networks is proposed. The congestion-aware WiFi offloading system can obtain network status information in real time. Analyzed the shortcomings of 3GPP’s existing congestion-aware WiFi offload strategy, combined with the user-centric network characteristics of 5G, proposed a congestion-aware WiFi offload algorithm, and modeled the access strategy as the effective capacity In the non-cooperative game model, a distributed algorithm and a dynamic value algorithm are designed respectively to maximize network utility. Simulation shows that the proposed distributed algorithm doubles the total effective capacity of the network compared to the device full activation scheme; compared with the distributed algorithm, the proposed dynamic value algorithm improves the total effective capacity of the network. This algorithm can effectively improve user satisfaction and achieve fine management of congested WiFi offloads},
  archive      = {J_COMCOM},
  author       = {Shen Han},
  doi          = {10.1016/j.comcom.2020.10.006},
  journal      = {Computer Communications},
  pages        = {69-76},
  shortjournal = {Comput. Commun.},
  title        = {Congestion-aware WiFi offload algorithm for 5G heterogeneous wireless networks},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing efficient communication infrastructure in
post-disaster situations with limited availability of network resources.
<em>COMCOM</em>, <em>164</em>, 54–68. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the aftermath of a large-scale disaster, such as an earthquake, existing telecommunication (e.g., cellular towers) and other public infrastructures (e.g., power lines, roads, etc.) are often severely damaged. This prevents the seamless exchange of situational awareness and rescue/relief based information between the volunteers, shelter points, and the coordination center. A temporary communication infrastructure utilizing smartphones, communication towers, drones, smart badges, etc., commonly referred to as network resources , can be formed, which promises to bridge the communication gap between various stakeholders in the disaster area and enable timely information exchange between them. However, the efficacy of such networks is often challenged by the limited availability of network resources in the disaster area. To address this issue, in this paper, we propose to design, develop, and test a novel strategy that intelligently deploys the limited network resources in the disaster area, and thus, creates an efficient temporary communication infrastructure in such resource-constrained post-disaster situations. We formulate the network resource deployment (ResDep) problem as an integer linear programming optimization problem and show that it is NP-Hard. Next, we propose a near-optimal polynomial-time heuristic solution for solving it. Our extensive simulation study on top of ONE simulator and proof-of-concept pilot deployment study, both based on our university, National Institute of Technology — Durgapur, India, reveal that the proposed heuristic performs nearly as well as that of the optimal solution (computed using Gurobi optimizer), and outperforms its variant and baseline approaches when compared in terms of end-to-end network latency and message delivery.},
  archive      = {J_COMCOM},
  author       = {Krishnandu Hazra and Vijay K. Shah and Simone Silvestri and Vaneet Aggarwal and Sajal K. Das and Subrata Nandi and Sujoy Saha},
  doi          = {10.1016/j.comcom.2020.09.019},
  journal      = {Computer Communications},
  pages        = {54-68},
  shortjournal = {Comput. Commun.},
  title        = {Designing efficient communication infrastructure in post-disaster situations with limited availability of network resources},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning for intelligent IoT: Opportunities, challenges
and solutions. <em>COMCOM</em>, <em>164</em>, 50–53. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation wireless networks have to be robust and self-sustained. Internet of things (IoT) is reshaping the technological adaptation in the daily life of human beings. IoT applications are highly diverse, and they range from critical applications like smart city, health-based industries, to industrial IoT. Machine learning (ML) techniques are integrated into IoT to make the network efficient and autonomous. Deep learning (DL) is one of the types of ML, and it is computationally complex and expensive. One of the challenges is to merge deep learning methods with IoT to overall improve the efficiency of the IoT applications. An amalgamation of these techniques, maintaining a balance between computational cost and efficiency is crucial for next-generation IoT networks. In consideration of the requirements of ML and IoT and seamless integration demands overhauling the whole communication stack from physical layer to application layer. Hence, the applications build on top of modified stack will be significantly benefited, and It also makes it easy to widely deploy the network.},
  archive      = {J_COMCOM},
  author       = {Yousaf Bin Zikria and Muhammad Khalil Afzal and Sung Won Kim and Andrea Marin and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2020.08.017},
  journal      = {Computer Communications},
  pages        = {50-53},
  shortjournal = {Comput. Commun.},
  title        = {Deep learning for intelligent IoT: Opportunities, challenges and solutions},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An offloading strategy with soft time windows in mobile edge
computing. <em>COMCOM</em>, <em>164</em>, 42–49. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task offloading is a core function of mobile edge computing to make up shortage of energy in mobile terminal. Scholars deploy techniques including cloud servers to improve offloading process with hard time window constraints, as there is strict deadline, which is exclusive to the flexibility of users facing task time-out. To increase the flexibility, this paper examines the time-varying features of users’ tolerance as the soft time windows perform. Pay of task processing varies because of completion time, which is a combinatorial optimization problem . This paper proposes a Hybrid Genetic Algorithm and Biogeography-Based Optimization (HGABBO) offloading algorithm. The experiments show that the proposed algorithm is effective to multitask processes and outperforms the Artificial Fish algorithm and Ant System algorithm.},
  archive      = {J_COMCOM},
  author       = {Zhenchun Wei and Jie Pan and Zengwei Lyu and Junyi Xu and Lei Shi and Juan Xu},
  doi          = {10.1016/j.comcom.2020.09.011},
  journal      = {Computer Communications},
  pages        = {42-49},
  shortjournal = {Comput. Commun.},
  title        = {An offloading strategy with soft time windows in mobile edge computing},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Privacy-preserving searchable encryption in the intelligent
edge computing. <em>COMCOM</em>, <em>164</em>, 31–41. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intelligent edge computing , the private data of users are partly or entirely outsourced to the intelligent edge nodes for processing. To enforce security and privacy on edge network, data owners encrypt their private data and outsource it. It is particularly important to carry out efficient search and update on encrypted data . In this paper, we propose a searchable scheme to solve these problems on the intelligent edge network. Specially, we first propose S-HashMap index structure to make data update efficiently and safely while promising multi-keyword fuzzy ciphertext retrieval. Secondly, to measure the similarity between the query vector and the index nodes, we utilize the secure k-nearest neighbor to calculate the Euclidean distance . In addition to eliminating the necessity of pre-defined dictionaries, we achieve efficient multi-keyword fuzzy search and index updating without increasing search complexity. At the same time, this paper makes a thorough theoretical analysis and simulation of the proposed scheme. Compared with other schemes, we demonstrate that our scheme has better security and efficiency.},
  archive      = {J_COMCOM},
  author       = {Qi Chen and Kai Fan and Kuan Zhang and Haoyang Wang and Hui Li and Yingtang Yang},
  doi          = {10.1016/j.comcom.2020.09.012},
  journal      = {Computer Communications},
  pages        = {31-41},
  shortjournal = {Comput. Commun.},
  title        = {Privacy-preserving searchable encryption in the intelligent edge computing},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Server-aided searchable encryption in multi-user setting.
<em>COMCOM</em>, <em>164</em>, 25–30. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Searchable encryption schemes allow users to search encrypted data containing some keyword without decrypting the data. It protects the data privacy of data owners, meanwhile facilitates efficient data access in secure cloud storage service . Most of the existing schemes only considered the single-user setting, in which a user uploads his encrypted data and later performs searches on it. However, the majority of databases in practice do not only serve one user; instead, they support write operations by multiple data owners and search operations by some authorized users. There exists the following issues in existing multi-user searchable encryption schemes. First, some schemes allow only one data owner to write to the encrypted database ; second, a number of schemes may require the data owner to interact with the authorized users to distribute secret keys; third, some other schemes cannot efficiently support the search authorization revocation on users, and do not achieve the trapdoor unlinkability. In this paper, we address these issues by proposing a server-aided searchable encryption scheme in multi-user setting. In our scheme, the data owners only need to know the public key of an administration server to generate the searchable ciphertext , regardless of the number of authorized users. Furthermore, our scheme is shown to be semantically secure against outside keyword guessing attacks. Finally, the performance analyses and comparisons with some existing schemes demonstrate that our scheme achieves better performance.},
  archive      = {J_COMCOM},
  author       = {Lixue Sun and Chunxiang Xu and Chuang Li and Yuhui Li},
  doi          = {10.1016/j.comcom.2020.09.018},
  journal      = {Computer Communications},
  pages        = {25-30},
  shortjournal = {Comput. Commun.},
  title        = {Server-aided searchable encryption in multi-user setting},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A mathematical framework for measuring network flexibility.
<em>COMCOM</em>, <em>164</em>, 13–24. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of networking research, increased flexibility of new system architecture proposals, protocols, or algorithms is often stated to be a competitive advantage over its existing counterparts. However, this advantage is usually claimed only on an argumentative level and neither formally supported nor thoroughly investigated due to the lack of a unified flexibility framework. As we will show in this paper, the flexibility achieved by a system implementation can be measured, which consequently can be used to make different networking solutions quantitatively comparable with each other. The idea behind our mathematical model is to relate network flexibility to the achievable subset of the set of all possible demand changes, and to use measure theory to quantify it. As increased flexibility might come with additional system complexity and cost, our framework provides a cost model which measures how expensive it is to operate a flexible system. The introduced flexibility framework contains different normalization strategies to provide intuitive meaning to the network flexibility value as well, and also provides guidelines for generating demand changes with (non-)uniform demand utilities. Finally, our network flexibility framework is applied on two different use-cases, and the benefits of a quantitative flexibility analysis compared to pure intuitive arguments are demonstrated.},
  archive      = {J_COMCOM},
  author       = {Péter Babarczi and Markus Klügel and Alberto Martínez Alba and Mu He and Johannes Zerwas and Patrick Kalmbach and Andreas Blenk and Wolfgang Kellerer},
  doi          = {10.1016/j.comcom.2020.09.014},
  journal      = {Computer Communications},
  pages        = {13-24},
  shortjournal = {Comput. Commun.},
  title        = {A mathematical framework for measuring network flexibility},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial noise aided scheme to secure UAV-assisted
internet of things with wireless power transfer. <em>COMCOM</em>,
<em>164</em>, 1–12. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of massive Internet of Things (IoT) devices poses research challenges especially in unmanned aerial vehicles(UAV)-assisted IoT. In particular, the limited battery capacity not only restricts the life time of UAV-assisted IoT but also brings security vulnerabilities since computation-complex cryptographic algorithms cannot be adopted in UAV-assisted IoT systems. In this paper, artificial noise and wireless power transfer technologies are integrated to secure communications in UAV-assisted IoT (particularly in secret key distribution). We present the artificial noise aided scheme to secure UAV-assisted IoT communications by letting UAV gateway transfer energy to a number of helpers who will generate artificial noise to interfere with the eavesdroppers while the legitimate nodes can decode the information by canceling additive artificial noise. We introduce the eavesdropping probability and the security rate to validate the effectiveness of our proposed scheme. We further formulate an eavesdropping probability constrained security rate maximization problem to investigate the optimal power allocation . Moreover, analytical and numerical results are provided to obtain some useful insights, and to demonstrate the effect of crucial parameters (e.g., the transmit power, the main channel gain) on the eavesdropping probability, the security rate, and the optimal power allocation .},
  archive      = {J_COMCOM},
  author       = {Qubeijian Wang and Hong-Ning Dai and Xuran Li and Mahendra K. Shukla and Muhammad Imran},
  doi          = {10.1016/j.comcom.2020.09.017},
  journal      = {Computer Communications},
  pages        = {1-12},
  shortjournal = {Comput. Commun.},
  title        = {Artificial noise aided scheme to secure UAV-assisted internet of things with wireless power transfer},
  volume       = {164},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accurate mathematical modeling and solution of TCP
congestion window size distribution. <em>COMCOM</em>, <em>163</em>,
195–201. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The congestion window size distribution is important in TCP as it reveals the statistical variation of the sending rate . It also quantifies the network congestion conditions. A semi-Markov model is used to develop an accurate mathematical framework for solving for TCP congestion window size. The new model improves on the accuracy of a widely accepted mathematical model in the literature for the congestion window size distribution. The correct statistics of a sum of weighted exponential random variables are identified and incorporated into the new mathematical model. Simulation results from both Matlab and NS2 demonstrate the accuracy of the new model. In one example, the new model predicts that 97.5\% of congestion windows will have length less than 82 whereas the previous accepted model predicts 97.5\% of the windows will have sizes less than 72, and hence the previous model can lead to buffer and caching requirement estimates that are too small when designing practical networks.},
  archive      = {J_COMCOM},
  author       = {Gan Luan and Norman C. Beaulieu},
  doi          = {10.1016/j.comcom.2020.09.010},
  journal      = {Computer Communications},
  pages        = {195-201},
  shortjournal = {Comput. Commun.},
  title        = {Accurate mathematical modeling and solution of TCP congestion window size distribution},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep neural network compression algorithm based on
knowledge transfer for edge devices. <em>COMCOM</em>, <em>163</em>,
186–194. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation and storage capacity of the edge device are limited, which seriously restrict the application of deep neural network in the device. Toward to the intelligent application of the edge device, we introduce the deep neural network compression algorithm based on knowledge transfer, a three-stage pipeline: lightweight, multi-level knowledge transfer and pruning that reduce the network depth, parameter and operation complexity of the deep learning neural networks . We lighten the neural networks by using a global average pooling layer instead of a fully connected layer and replacing a standard convolution with separable convolutions. Next, the multi-level knowledge transfer minimizes the difference between the output of the ”student network” and the ”teacher network” in the middle and logits layer, increasing the supervised information when training the ”student network”. Lastly, we prune the network by cutting off the unimportant convolution kernels with a global iterative pruning strategy. The experiment results show that the proposed method improve the efficiency up to 30\% than the knowledge distillation method in reducing the loss of classification performance. Benchmarked on GPU (Graphics Processing Unit) server, Raspberry Pi 3 and Cambricon-1A, the parameters of the compressed network after using our knowledge transfer and pruning method have achieved more than 49.5 times compression and the time efficiency of a single feedforward operation has been improved more than 3.2 times.},
  archive      = {J_COMCOM},
  author       = {Yanming Chen and Chao Li and Luqi Gong and Xiang Wen and Yiwen Zhang and Weisong Shi},
  doi          = {10.1016/j.comcom.2020.09.016},
  journal      = {Computer Communications},
  pages        = {186-194},
  shortjournal = {Comput. Commun.},
  title        = {A deep neural network compression algorithm based on knowledge transfer for edge devices},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A query based information search in an individual’s small
world of social internet of things. <em>COMCOM</em>, <em>163</em>,
176–185. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the consolidation of Social Network and the Internet of Things (IoT) acquiring appreciation and consideration among researchers due to its immense and adaptable behavior. Social Internet of Things (SIoT) comprehends the adequacy to support the inventive applications and network services with adept and persuasive demeanors. The author’s exertion for this research provides the subsistence to the SIoT amelioration Currently, the SIoT technique proven to be competent, but the exponential growth of heterogeneous smart devices may arise a challenging scenario. Searching the right object, service, or best path to the informative nodes in such highly convoluted networks is always a challenging task. This research strengthen the SIoT paradigm by consolidating the properties of the individual’s Small World. In addition, this research also advises a Smart Social Agent (SSA) to minimize the human intervention. The absolute objective of this paper is two-fold, (i) transformation of SIoT network into Individual’s Small World SIoT network, (ii) searching the right information efficiently by exploiting SSA. To accomplish the goal we have proposed an efficient Query based Searching algorithm which exploits Service Oriented properties of Individual’s Small World SIoT network and searches information. First result shows the significant alleviation in the network complexity, reduces the average path length, and network diameter. Eventually, it improves the network scalability and navigability. While second result shows that the proposed Query based searching algorithm proves to be efficient with its mean execution time not more than 2.66 ms for complete network on two different machines. Whereas, for Individual’s small world network the mean execution time is not more than 2.47 ms for both machine.},
  archive      = {J_COMCOM},
  author       = {Abdul Rehman and Anand Paul and Awais Ahmad},
  doi          = {10.1016/j.comcom.2020.08.027},
  journal      = {Computer Communications},
  pages        = {176-185},
  shortjournal = {Comput. Commun.},
  title        = {A query based information search in an individual’s small world of social internet of things},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prevention of hello flood attack in IoT using combination of
deep learning with improved rider optimization algorithm.
<em>COMCOM</em>, <em>163</em>, 162–175. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT are prone to vulnerabilities as a result of a lack of centralized management, dynamic topologies , and predefined boundary. There are diverse attacks that affect the performance of IoT network. Flooding attack is a DoS attack that brings down the network by flooding with a huge count of HELLO packets, routed to a destination that does not exist. The main intent of this paper is to develop a novel robust model for detecting and preventing HELLO flooding attacks using optimized deep learning approach. In this proposed research model, the steps like Cluster head selection, k-paths generation, HELLO flooding attack detection and prevention, and optimal shortest path selection are employed. Once after the random cluster head selection and k-paths generation, few Route Discovery Frequency Vectors like Route Discover Time and Inter Route Discovery Time of each node is determined for detecting the HELLO flooding attack. Initially, a threshold function is used to match with the computed Received Signal Strength (RSS) of each node to detect the stranger node. Further, the HELLO flood attack is confirmed by the optimized Deep Belief Network (DBN), which is removed from the network subsequently. Once after securing the network, the shortest route path selection is done optimally by the improved meta-heuristic algorithm. Here, improved Rider Optimization Algorithm (ROA) termed as Bypass-Linked Attacker Update-based ROA (BAU-ROA) is used for performing the optimal DBN as well as optimal shortest path selection. The objective constraints like node trust, distance between the nodes, delay of transmission, and packet loss ratio are considered for performing the optimal shortest path selection. Finally, the experimental evaluation of various performance measures validates the fruitful performance of the proposed model. Based on the analysis, the const function of proposed BAU-ROA is 28.1\% superior to D-DHOA, 34.1\% superior to DHOA, and 39.2\% superior to WOA at 5th iteration. When considering the 10th iteration, the developed BAU-ROA is 12.2\% superior to DHOA, 19.3\% superior to D-DHOA, 28.1\% superior to ROA, and 39.2\% superior to WOA.},
  archive      = {J_COMCOM},
  author       = {T. Aditya Sai Srinivas and S.S. Manivannan},
  doi          = {10.1016/j.comcom.2020.03.031},
  journal      = {Computer Communications},
  pages        = {162-175},
  shortjournal = {Comput. Commun.},
  title        = {Prevention of hello flood attack in IoT using combination of deep learning with improved rider optimization algorithm},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Impact of injection attacks on sensor-based continuous
authentication for smartphones. <em>COMCOM</em>, <em>163</em>, 150–161.
(<a href="https://doi.org/10.1016/j.comcom.2020.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the relevance of smartphones for accessing personalized services in smart cities, Continuous Authentication (CA) mechanisms are attracting attention to avoid impersonation attacks. Some of them leverage Data Stream Mining (DSM) techniques applied over sensorial information . Injection attacks can undermine the effectiveness of DSM-based CA by fabricating artificial sensorial readings.The goal of this paper is to study the impact of injection attacks in terms of accuracy and immediacy to illustrate the time the adversary remains unnoticed. Two well-known DSM techniques (K-Nearest Neighbours and Hoeffding Adaptive Trees) and three data sources (location, gyroscope and accelerometer) are considered due to their widespread usage Results show that even if the attacker does not previously know anything about the victim, a significant attack surface arises – 1.35 min are needed, in the best case, to detect the attack on gyroscope and accelerometer and 7.27 min on location data. Moreover, we show that the type of sensor at stake and configuration settings may have a dramatic effect on countering this threat.},
  archive      = {J_COMCOM},
  author       = {Lorena Gonzalez-Manzano and Upal Mahbub and Jose M. de Fuentes and Rama Chellappa},
  doi          = {10.1016/j.comcom.2020.08.022},
  journal      = {Computer Communications},
  pages        = {150-161},
  shortjournal = {Comput. Commun.},
  title        = {Impact of injection attacks on sensor-based continuous authentication for smartphones},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reversible data hiding exploiting huffman encoding with dual
images for IoMT based healthcare. <em>COMCOM</em>, <em>163</em>,
134–149. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous technological progressions and huge investments are made for the realization of the various goals in the Internet of Things (IoT) driven networks. Internet of Medical Things (IoMT) being a part of IoT has made human living smarter. It is revolutionizing the healthcare industry and is providing a smarter healthcare framework to the people. The generic IoMT framework consists of the major components i.e., data acquisition, communication gateways, and servers. Once the data is acquired, it is sent over the insecure channel where its authentication is essential before diagnosis. In this work, a dual image reversible data hiding technique with high capacity is proposed for IoMT based networks. First of all, the acquired secret data is preprocessed using the Huffman encoding strategy. Once Huffman coding is applied, a codebook of ‘d’ bits is generated for encoding the converted decimal values using indices. The value of these indices is divided into 2 parts and embedded into two visually similar images to obtain dual stego images . The scheme has provided a very high payload while maintaining good perceptual quality . The results obtained depict significant improvement compared to the state-of-the-art. The scheme provides an average (percentage) improvement in embedding capacity by 33.2\%, with the improvisation of Peak Signal to Noise (PSNR) Ratio by 1.32\%. The average value of the Structural Similarity Index (SSIM) is found to be 0.8873. The scheme is computationally efficient which makes it a better candidate to be used in IoMT driven networks.},
  archive      = {J_COMCOM},
  author       = {Solihah Gull and Shabir A. Parah ( Ph.D. ) and Khan Muhammad},
  doi          = {10.1016/j.comcom.2020.08.023},
  journal      = {Computer Communications},
  pages        = {134-149},
  shortjournal = {Comput. Commun.},
  title        = {Reversible data hiding exploiting huffman encoding with dual images for IoMT based healthcare},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on continuous authentication methods in internet of
things environment. <em>COMCOM</em>, <em>163</em>, 109–133. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT environment merges the digital and physical universes and enabling them to communicate real-time data It is crucial to constantly ensure that the user is not impersonated which brings a particular type of authentication known as continuous authentication . Therefore, this survey is primary attempt to present an overview about continuous authentication methods in IoT environment, where Blockchain-related solutions provided in this context is also discussed. Subsequently, we overview IoT environment and classify IoT attacks based on its layers with the corresponding proposed countermeasures . Next, we identify a number of open issues that must be taken into account when developing authentication schemes for IoT. We further contribute to this survey by providing a comprehensive analysis of designing continuous authentication process . Besides, we highlight the primary advantages of continuous authentication over the static authentication scheme. In this context, we review relevant works that have proposed Blockchain-based solution to strength the security of IoT systems. We further contribute to present, analyze, and compare user-related IoT-based continuous authentication solutions. Also, we present the solutions that integrate Blockchain . Finally, several research directions and open challenges are identified.},
  archive      = {J_COMCOM},
  author       = {Fatimah Hussain Al-Naji and Rachid Zagrouba},
  doi          = {10.1016/j.comcom.2020.09.006},
  journal      = {Computer Communications},
  pages        = {109-133},
  shortjournal = {Comput. Commun.},
  title        = {A survey on continuous authentication methods in internet of things environment},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new GSO based method for SDN controller placement.
<em>COMCOM</em>, <em>163</em>, 91–108. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of wide area networks (WANs) and software defined networking (SDN), reducing the communication delays experienced by the network devices is an important challenge whose solution requires a careful placement of controllers to decrease the end-to-end latencies. Although the majority of studies focusing on the controller placement problem (CPP) only consider the switch–controller propagation delays and inter-controller latencies, the controllers’ capacity needs to be addressed for lowering the end-to-end delays. While the controllers with a variety of processing rates, number of ports, and costs are available in the market, Internet Service Providers (ISPs) need to consider the affordability and capability of compensating their needs by maximizing the use of their networks’ resources. To propose a solution for this important problem, we consider the Knapsack 0–1problem and formulate the Garter Snake Optimization Capacitated Controller Placement Problem (GSOCCPP), a meta-heuristic algorithm, with new iterations and temperate mating conditions to solve the CPP. This algorithm uses a reasonable amount of computation time to obtain the minimum delays. A number of Topology-Zoo datasets are analyzed with a variety of small to large scale data plane nodes to evaluate the GSOCCPP algorithm based on different controllers’ capacities. The simulation results demonstrate that, in addition to outperforming similar meta-heuristic and clustering algorithms such as the Firefly Algorithm , Particle Swarm Optimization , and the k -means++, our newly proposed GSOCCPP algorithm is successful in achieving the lowest execution time among the analyzed algorithms. Furthermore, this proposed solution has a more efficient memory consumption compared to other algorithms for controller placement in different network topologies .},
  archive      = {J_COMCOM},
  author       = {Sahand Torkamani-Azar and Mohsen Jahanshahi},
  doi          = {10.1016/j.comcom.2020.09.004},
  journal      = {Computer Communications},
  pages        = {91-108},
  shortjournal = {Comput. Commun.},
  title        = {A new GSO based method for SDN controller placement},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of data mining technology in alarm analysis of
communication network. <em>COMCOM</em>, <em>163</em>, 84–90. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with the continuous development of science and technology, the social demand for the network is more and more, and with the continuous expansion of the network scale, the complexity of the network is increasing day by day. How to locate the fault accurately and quickly from a large number of alarm information has become a problem. To solve this problem, we must use computer technology to study the automatic analysis technology of alarm correlation. Therefore, this paper applies data mining technology to communication network alarm analysis, and based on fuzzy theory, it can accurately describe the relationship between network alarm and fault reason, and combines data mining technology with fuzzy theory to form the network alarm correlation analysis method of fuzzy association rule mining . On this basis, in order to mine the fuzzy association rules of the fuzzy alarm database directly and avoid the interference in the process of converting the alarm database to the transaction database, this paper proposes a dynamic time window fuzzy association rule mining algorithm. Through the simulation analysis, compared with the traditional data mining technology, the fuzzy association rules mining method combined with the fuzzy theory has better performance, and the further proposed dynamic time window fuzzy association rules mining algorithm greatly improves the accuracy of the association rules confidence, and has good application performance in the network alarm correlation analysis.},
  archive      = {J_COMCOM},
  author       = {Qun Zheng and Yaofeng Li and Jie Cao},
  doi          = {10.1016/j.comcom.2020.08.012},
  journal      = {Computer Communications},
  pages        = {84-90},
  shortjournal = {Comput. Commun.},
  title        = {Application of data mining technology in alarm analysis of communication network},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing of fog based FBCMI2E model using machine learning
approaches for intelligent communication systems. <em>COMCOM</em>,
<em>163</em>, 65–83. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work discusses the evolution of communication models and technological aspects for developing inclusive platforms. The paper gives illustrations and graphical presentations about components of the inclusive platform. An inclusive platform consists of fog devices that can collect the fitness data, geospatial data and mobile call details from the people who are in need of help from the government agencies. The paper discusses the controversies around the definition and qualification of the informal economy as well as presents a simulated scenario. The case presented here gives an insight on how fog devices and data mining can be used for bringing people into main fold of the economy. The inclusiveness index of the person is computed on the basis of four aspects. The first aspect is the fitness, the second is his inner social circle, third is her/his reliability to remain in a place, and last is call analysis. While computing the fitness index, it was found that Naive Bayes (NB) algorithm has the maximum accuracy with respect to K-Nearest Neighbors (KNN), Decision Tree (DT) and Linear Discriminant Analysis (LDA). For computing inner social circle, Louvain algorithm helped to compute stability and strength of socio-economic ties of the individual. For geospatial and call analysis, insights from knowledge discovery algorithm such as FP-Growth helped to arrive at decision to qualify the person for inclusive program. The paper ends with details on how to automate the inclusiveness index computation using neural network . The research indicates that energy is the key constraint for implementing such programs. Hence, a theoretical analysis about energy efficiency is also explained in the paper.},
  archive      = {J_COMCOM},
  author       = {Simar Preet Singh and Anju Sharma and Rajesh Kumar},
  doi          = {10.1016/j.comcom.2020.09.005},
  journal      = {Computer Communications},
  pages        = {65-83},
  shortjournal = {Comput. Commun.},
  title        = {Designing of fog based FBCMI2E model using machine learning approaches for intelligent communication systems},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low complexity resource allocation algorithms for chunk
based OFDMA multi-user networks with max–min fairness. <em>COMCOM</em>,
<em>163</em>, 51–64. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the resource allocation problem in orthogonal frequency division multiple access networks with multiple users. Different from most works that perform resource allocation based on each subcarrier , we consider the subcarriers are grouped into chunks due to simplicity of implementation. The objective is to maximize the users’ minimal transmission rate by adjusting the transmission power allocation and chunk allocation while taking into account several important constraints. The problem is formulated as a mixed integer nonlinear programming problem, which is generally hard to solve. By binary relaxation, the problem is transformed to be a convex problem . By exploiting the special structure of the relaxed problem, a barrier method based fast algorithm is proposed. To achieve binary chunk allocation, a low complexity suboptimal algorithm is proposed further. When the number of chunks is less than the number of users, it is necessary to consider the joint admission control and resource allocation problem . To solve this problem, a fast algorithm based on bisection search and Hungarian method is designed. Simulations are carried out to validate the superior performance of the proposed algorithms in terms of the users’ minimal transmission rate and running time comparing with benchmark algorithms under different conditions.},
  archive      = {J_COMCOM},
  author       = {Yanyan Shen and Xiaoxia Huang and Bo Yang and Shuqiang Wang},
  doi          = {10.1016/j.comcom.2020.09.003},
  journal      = {Computer Communications},
  pages        = {51-64},
  shortjournal = {Comput. Commun.},
  title        = {Low complexity resource allocation algorithms for chunk based OFDMA multi-user networks with max–min fairness},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Controller placements for latency minimization of both
primary and backup paths in SDNs. <em>COMCOM</em>, <em>163</em>, 35–50.
(<a href="https://doi.org/10.1016/j.comcom.2020.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined networking (SDN) is a revolutionary network architecture that separates the network control layer from the underlying equipment. Multiple controllers form a logically centralized control layer in large-scale networks, which raises the controller placement problem. Most of the research on latency-oriented controller placement optimized the delay between switches and controllers assuming the network is reliable. However, the network is subject to link failures. In this paper, we formulate a novel multi-objective SDN controller placement problem with the aim to minimize the switch-to-controller communication delay for both the cases without link failure and with single-link-failure. We propose an efficient metaheuristic-based Reliability-Aware and Latency-Oriented controller placement algorithm (RALO) for multi-objective multiple controller placements. The algorithm constructs an initial feasible solution by a greedy method with network partition , then repeatedly generates new solutions with variable neighborhood search . Once a new solution is generated, the algorithm decides whether to accept the new solution as a non-dominated solution to the problem and performs update operation on the Pareto optimal solution set. Meanwhile, to avoid falling into the local optimum, the algorithm also performs perturbation and destruction operations on the current solution. We finally conduct experiments through simulations on 8 real network topologies and two kinds of generated networks conforming to ER (Erdos–Renyi) random model and small-world model. Experimental results demonstrate that the proposed algorithm can achieve a competitive performance of switch-to-controller latencies in both the cases without link failure and with single-link failure, and the accumulated delay of primary and backup paths between the controllers and the switches. The Pareto optimal solution set provided by algorithm RALO allows network administrators with flexible choices to strike a trade-off between the switch-to-controller delay of primary and backup paths.},
  archive      = {J_COMCOM},
  author       = {Yuqi Fan and Lunfei Wang and Xiaohui Yuan},
  doi          = {10.1016/j.comcom.2020.09.001},
  journal      = {Computer Communications},
  pages        = {35-50},
  shortjournal = {Comput. Commun.},
  title        = {Controller placements for latency minimization of both primary and backup paths in SDNs},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FIS-RGSO: Dynamic fuzzy inference system based reverse
glowworm swarm optimization of energy and coverage in green mobile
wireless sensor networks. <em>COMCOM</em>, <em>163</em>, 12–34. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In mobile wireless sensor networks , energy consumption and area coverage are two well-known optimization problems . An efficient and restricted sensor movement is essential so that redundant area coverage, as well as consumed energy, can be reduced to mitigate these two issues in mobile wireless sensor networks . To make equilibrium between energy consumption and the total area coverage by the sensor nodes is a difficult task. In this context, optimized path planning for sensor movement is crucial to reach the target. The article presents a Dynamic Fuzzy Inference System Based Reverse Glowworm Swarm Optimization (FIS-RGSO) of energy and coverage in smart green mobile wireless sensor networks. The objective of this article is to achieve minimum energy consumption by the sensors through their optimum movements so that sensors can cover maximum area and increase their lifetime. The proposed approach improves the sustainability and performance of green sensor networks in terms of a lifetime and energy-efficiency by implementing restricted and organized sensor movements based on the decision taken by the Fuzzy Inference System , which leads to minimum energy consumption and less distance traversing. The simulation results reveal that our proposed model reduces the consumed energy in a range of 5\%–45\% as compared with the existing method in reverse glowworm swarm optimization (RGSO) algorithm. The total distance covered by the sensors is also minimized by almost 7\%–62\% as compared with the existing one. The proposed method has experimented extensively and the result shows it performs better than the existing one in terms of the total number of live sensors that exist after execution. Therefore, the proposed methodology is realized as an energy-efficient model in wireless sensor networks that proliferate network lifetime.},
  archive      = {J_COMCOM},
  author       = {Aparajita Chowdhury and Debashis De},
  doi          = {10.1016/j.comcom.2020.09.002},
  journal      = {Computer Communications},
  pages        = {12-34},
  shortjournal = {Comput. Commun.},
  title        = {FIS-RGSO: Dynamic fuzzy inference system based reverse glowworm swarm optimization of energy and coverage in green mobile wireless sensor networks},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward accurate clock drift modeling in wireless sensor
networks simulation. <em>COMCOM</em>, <em>163</em>, 1–11. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The protocols used in Wireless Sensor Networks are subject to very strict temporal synchronization constraints. Radio Duty Cycle (RDC) protocols in particular are characterized by their very high synchronization accuracy requirements. In these protocols, synchronization errors are primarily caused by the natural clock drift observed in real nodes. The impact of the clock drift on the desynchronization issues can be investigated by the use of low-level node simulators. In this paper, we show the limitation of the COOJA simulator to evaluate the impact of the clock drift. We show that its current mote execution model does not faithfully reproduce the requested clock drift. We identify the root cause of these inaccuracies and present a new algorithm that is able to precisely reproduce any requested clock drifts in simulation. On the basis of our understanding, we build a mathematical model of the clock drift error allowing previous authors to estimate the error caused by clock drift inaccuracies in their studies and its impact on their results. To demonstrate the new algorithm, we consider a well-documented RDC protocol issue where the clock drift would cause periodic communication blackouts. This phenomenon was observed on real nodes, but was previously impossible to reproduce by simulation. Our new algorithm not only allows to reproduce the blackouts but also provides additional insights that help to confirm the initial analysis of the phenomenon. Finally, we use our algorithm to implement dynamic clock drift models to simulate the behavior of a clock drift evolving through time. We illustrate this using our linear model to push a RDC protocol to its limits.},
  archive      = {J_COMCOM},
  author       = {David Hauweele and Bruno Quoitin},
  doi          = {10.1016/j.comcom.2020.08.025},
  journal      = {Computer Communications},
  pages        = {1-11},
  shortjournal = {Comput. Commun.},
  title        = {Toward accurate clock drift modeling in wireless sensor networks simulation},
  volume       = {163},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Corrigendum to “analysis and implementation of novel rice
golomb coding algorithm for wireless sensor networks” [comput. Commun.
150 (2020) 463–471]. <em>COMCOM</em>, <em>162</em>, 227. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {S. Kalaivani and C. Tharini},
  doi          = {10.1016/j.comcom.2020.09.008},
  journal      = {Computer Communications},
  pages        = {227},
  shortjournal = {Comput. Commun.},
  title        = {Corrigendum to “Analysis and implementation of novel rice golomb coding algorithm for wireless sensor networks” [Comput. commun. 150 (2020) 463–471]},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on wearable medical devices for healthcare
measurements. <em>COMCOM</em>, <em>162</em>, 225–226. (<a
href="https://doi.org/10.1016/j.comcom.2020.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Wei Wei and Jinsong Wu and Chunsheng Zhu},
  doi          = {10.1016/j.comcom.2020.09.007},
  journal      = {Computer Communications},
  pages        = {225-226},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on wearable medical devices for healthcare measurements},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FogAuthChain: A secure location-based authentication scheme
in fog computing environments using blockchain. <em>COMCOM</em>,
<em>162</em>, 212–224. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing is an emerging computing paradigm which expands cloud-based computing services near the network edge. With this new computing paradigm , new challenges arise in terms of security and privacy. These concerns are due to the distributed ownership of Fog devices. Because of the large scale distributed nature of devices at the Fog layer, secure authentication for communication among these devices is a major challenge. The traditional authentication methods (password-based, certificate-based and biometric-based) are not directly applicable due to the unique architecture and characteristics of the Fog. Moreover, the traditional authentication methods consume significantly more computation power and incur high latency, and this does not meet the key requirements of the Fog. To fill this gap, this article proposes a secure decentralised location-based device to device (D2D) authentication model in which Fog devices can mutually authenticate each other at the Fog layer by using Blockchain . We considered an Ethereum Blockchain platform for the Fog device registration, authentication, attestation and data storage. We presented the overall system architecture , various participants and their transactions and message interaction between the participants. We validated the proposed model by comparing it with the existing method; results showed that the proposed authentication mechanism was efficient and secure. From the performance evaluation, it was found that the proposed method is computationally efficient and secure in a highly distributed Fog network.},
  archive      = {J_COMCOM},
  author       = {Abdullah Al-Noman Patwary and Anmin Fu and Sudheer Kumar Battula and Ranesh Kumar Naha and Saurabh Garg and Aniket Mahanti},
  doi          = {10.1016/j.comcom.2020.08.021},
  journal      = {Computer Communications},
  pages        = {212-224},
  shortjournal = {Comput. Commun.},
  title        = {FogAuthChain: A secure location-based authentication scheme in fog computing environments using blockchain},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A security integration model for private data of intelligent
mobile communication based on edge computing. <em>COMCOM</em>,
<em>162</em>, 204–211. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a security integration model of mobile intelligent private data for edge computing . According to the characteristics of the heterogeneous network of edge computing networks, the network is layered according to the mobile intelligent private data structure . The homomorphism encryption algorithm is adopted to enable private data to be transmitted and stored in the form of ciphertext on the edge network and the mobile terminal. The encryption model ensures that the device data is not peeped by malicious attackers. Besides, the application layer system model is designed to enable service providers to integrate their hardware resources and provide a unified edge computing solution for different data owners. The experiment evaluated its encryption performance and system availability. An edge network security defense model based on a mean-field game is established, and an edge network security defense algorithm is proposed. Based on the study of the relationship between the individual edge network equipment’s optimal defense strategy and the overall edge network’s optimal defense strategy, the individual cost of the edge network equipment is analyzed by proving the existence of the edge network equipment balance. The optimal conditions between the overall cost of the edge network are given under this condition. The simulation results showed that for large-scale edge network devices, the model realized the unity of the optimal defense strategies of the individual edge network devices and the entire edge network, and effectively reduces the consumption of computing resources of the edge network devices Because all migration strategies allow all devices to migrate their computing tasks to MBS, leading to severe uplink and downlink congestion, wireless transmission energy consumption has increased dramatically. The energy consumption of migration calculation is higher than that of local calculation.},
  archive      = {J_COMCOM},
  author       = {Xiang Chen},
  doi          = {10.1016/j.comcom.2020.08.026},
  journal      = {Computer Communications},
  pages        = {204-211},
  shortjournal = {Comput. Commun.},
  title        = {A security integration model for private data of intelligent mobile communication based on edge computing},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized multi-UAV cooperative path planning under the
complex confrontation environment. <em>COMCOM</em>, <em>162</em>,
196–203. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging technology, multi-UAV collaboration is widely used in military and civil applications, including regional surveillance, remote sensing, target strike, etc. As a key step in the implementation of multi-UAV cooperative missions, path planning aims to generate near-optimal paths that satisfy certain constraints, ensure that each UAV can reach the mission area quickly and reduce the probability of being captured and destroyed by the antagonism side. In this paper, we design an optimized multi-UAV cooperative path planning method under the complex confrontation environment. Firstly, the threat model is designed based on the actual situation. Combining the threat and fuel consumption criteria, under the constraints of time and space, a multi-constraint objective optimization model is established. Following this, an improved grey wolf optimizer algorithm is used to solve the optimization model. Based on the characteristics of the multi-UAV cooperative path planning , the algorithm is improved in three aspects: population initialization, decay factor updating, and individual position updating. The simulation results demonstrate that the proposed algorithm is effective in generating paths for multi-UAV cooperative path planning and has the advantages of a lower path cost and faster convergence speed as compared to the other algorithms tested in this work.},
  archive      = {J_COMCOM},
  author       = {Cheng Xu and Ming Xu and Chanjuan Yin},
  doi          = {10.1016/j.comcom.2020.04.050},
  journal      = {Computer Communications},
  pages        = {196-203},
  shortjournal = {Comput. Commun.},
  title        = {Optimized multi-UAV cooperative path planning under the complex confrontation environment},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A secure edge monitoring approach to unsupervised energy
disaggregation using mean shift algorithm in residential buildings.
<em>COMCOM</em>, <em>162</em>, 187–195. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to Intrusive Load Monitoring which uses smart power meters at each level to be monitored, Non-Intrusive Load Monitoring (NILM) is an ingenious way that relies on signal readings at a single point to deduce the share of the devices that have contributed to the overall load. This reliable technique that guarantees the safety and privacy of individual users has recently become an increasingly popular topic, as it turns out to be a major solution to assist household users in the process of obtaining details of their electricity consumption. The detailed consumption promotes better management of the electrical power on the consumer side by helping to eliminate any waste of energy. In this paper, an edge gateway has been implemented to safely monitor the overall load in a smart energy system . A load separation method has been introduced based on events detected on a low-frequency power signal, which allows the consumption profile of On/Off and multi-state devices to be generated without relying on the knowledge of the cardinality of these devices Following the extraction of significant features contained in the aggregate signal, an appliance profile recognition approach is presented based on the non-parametric Mean Shift algorithm. The ability of the proposed method to learn and deduce devices profile is validated using the Reference Energy Disaggregation Dataset (REDD). The experimental results show that the proposed approach is efficient in detecting events of binary state and finite state appliances.},
  archive      = {J_COMCOM},
  author       = {Qi Liu and Francis Mawuli Nakoty and Xueyan Wu and Raphael Anaadumba and Xiaodong Liu and Yonghong Zhang and Lianyong Qi},
  doi          = {10.1016/j.comcom.2020.08.024},
  journal      = {Computer Communications},
  pages        = {187-195},
  shortjournal = {Comput. Commun.},
  title        = {A secure edge monitoring approach to unsupervised energy disaggregation using mean shift algorithm in residential buildings},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BC-RAN: Cloud radio access network enabled by blockchain for
5G. <em>COMCOM</em>, <em>162</em>, 179–186. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud radio access network (C-RAN) supports the explosion of Internet of Things (IoT) applications and the demand for massive access in 5G networks . However, centralized access of trustless operators causes severe malicious insider threats, such as maliciously tamper and accidentally delete data. Blockchain , a traceable and non-tamper distributed ledger maintained by all nodes, has been considered as a feasible method to overcome these threats, while the size of the blockchain network is limited by practical byzantine fault tolerance (PBFT) consensus algorithm where the participants, the nodes who participate in consensus algorithm , bring heavy communication traffic. In this paper, we first propose a C-RAN enabled by blockchain (BC-RAN) for 5G with PeerTrust-based PBFT (Trust-PBFT) consensus algorithm to prevent the malicious insider threats and scale up the size of the blockchain network. We also propose a tri-chain structure of blockchain to divide transactions into three categories for storage to facilitate traceability. The algorithm calculates the trust value of each node, and those with high trust values will be elected to be the participants of PBFT. Simultaneously, due to the introduction of PeerTrust, another benefit is to improve the fault tolerance performance efficiently. Besides, an adjustment mechanism is designed-newly and implemented in the algorithm to impede effects produced by the malicious nodes in the blockchain network. Finally, several simulation experiments are designed to evaluate and compare the fault-tolerance performance and scalability of Trust-PBFT.},
  archive      = {J_COMCOM},
  author       = {Wei Tong and Xuewen Dong and Yulong Shen and Jiawei Zheng},
  doi          = {10.1016/j.comcom.2020.08.020},
  journal      = {Computer Communications},
  pages        = {179-186},
  shortjournal = {Comput. Commun.},
  title        = {BC-RAN: Cloud radio access network enabled by blockchain for 5G},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). An efficient and practical certificateless signcryption
scheme for wireless body area networks. <em>COMCOM</em>, <em>162</em>,
169–178. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area networks (WBANs) is a critical research focus at present, providing a reliable and smart healthcare system to monitor the physical condition of the patient. Only the authorized user can access the WBANs since the collected data is very personal and sensitive. In this paper, we present a certificateless signcryption scheme based on RSA and then design an efficient data access control scheme for WBANs using the proposed signcryption scheme. The system does not have the certificate management and the key escrow problems. The most striking one is that it is based only on the widely used RSA cryptosystem without the bilinear pairing , which is advantageous to its realization in industry. The analysis shows that the scheme is secure in the random oracle model and simultaneously satisfies confidentiality, authentication , integrity, non-repudiation, and public ciphertext verification. Besides, it has reasonable computational and communication costs. To our knowledge, this is the first certificateless signcryption scheme based on RSA to date.},
  archive      = {J_COMCOM},
  author       = {Xiaoguang Liu and Ziqing Wang and Yalan Ye and Fagen Li},
  doi          = {10.1016/j.comcom.2020.08.014},
  journal      = {Computer Communications},
  pages        = {169-178},
  shortjournal = {Comput. Commun.},
  title        = {An efficient and practical certificateless signcryption scheme for wireless body area networks},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical design of hash functions for IPv6 using
multi-objective genetic programming. <em>COMCOM</em>, <em>162</em>,
160–168. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hash functions are widely used in high-speed network traffic measurement. A hash function of high quality is supposed to meet the requirements of collision free and fast execution. Existing works have already developed methods to generate hash functions for IPv4 data, while IPv6 data with much longer addresses and different data characteristics may decline the effectiveness of those methods. In this paper, we present a practical design of hash functions for IPv6 measurement, based on the entropy analysis of IPv6 network data and an automated method of multi-objective genetic programming (GP). Considering our specific application of hash functions, we use three fitness functions as the optimization objectives , including active flow estimation, uniformity and seed avalanche effect, among which the active flow estimation is the main objective as the specific measurement task. In implementation of multi-objective GP, we adopted a strategy to limit the hash functions to shorter execution time than other hash functions by advanced experimental investigation. Experiments were conducted to construct hash functions for WIDE IPv6 network data. The results show that our generated hash functions have high usability on different evaluation criteria. It indicates that our generated hash functions are superior in active flow estimation and execution time and could compete with state of art hash functions in terms of uniformity and generating independent hash values for data structures like Bloom Filter.},
  archive      = {J_COMCOM},
  author       = {Ying Hu and Guang Cheng and Yongning Tang and Feng Wang},
  doi          = {10.1016/j.comcom.2020.08.013},
  journal      = {Computer Communications},
  pages        = {160-168},
  shortjournal = {Comput. Commun.},
  title        = {A practical design of hash functions for IPv6 using multi-objective genetic programming},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Servicing delay sensitive pervasive communication through
adaptable width channelization for supporting mobile edge computing.
<em>COMCOM</em>, <em>162</em>, 152–159. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last fifteen years, wireless local area networks (WLANs) have been populated on large variety of pervasive devices hosting heterogeneous applications. Pervasive edge computing has accelerated more distributed network applications for these devices, eliminating the round-trip to help in achieving zero latency dream. However, These applications require significantly variable data rates for effective functioning, especially in pervasive computing . The static bandwidth of frequency channelization in current WLANs strictly restricts the maximum achievable data rate by a network station. This static behavior spawns two major drawbacks: under-utilization of scarce spectrum resources and less support to delay sensitive applications such as voice and video.To this point, if the computing is moved to the edge of WLANs to reduce the frequency of communications, the pervasive devices can be provided with better services during the communication and networking. Thus, we aim to distribute spectrum resources among pervasive devices based upon delay sensitivity of applications while simultaneously maintain the fair channel access semantics of medium access control (MAC) layer of WLANs. Henceforth, ultra-low latency, efficiency and reliability of spectrum resources can be assured. In this paper, two novel algorithms have been proposed for adaptive channelization to offer rational distribution of spectrum resources among pervasive edge nodes based on their bandwidth requirement and assorted ambient conditions. The proposed algorithms have been implemented on a real test bed of commercially available universal software radio peripheral (USRP) devices. Thorough investigations have been carried out to enumerate the effect of dynamic bandwidth channelization on parameters such as medium utilization, achievable throughput, service delay, channel access fairness and bit error rate. The achieved empirical results demonstrate that we can optimally enhance the network wide throughput by almost 30\% by using channels of adaptable bandwidths.},
  archive      = {J_COMCOM},
  author       = {Abid Hussain and Muddesar Iqbal and Sohail Sarwar and Muhammad Safyan and Zia ul Qayyum and Honghao Gao and Xinheng Wang},
  doi          = {10.1016/j.comcom.2020.07.027},
  journal      = {Computer Communications},
  pages        = {152-159},
  shortjournal = {Comput. Commun.},
  title        = {Servicing delay sensitive pervasive communication through adaptable width channelization for supporting mobile edge computing},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Locally private frequency estimation of physical symptoms
for infectious disease analysis in internet of medical things.
<em>COMCOM</em>, <em>162</em>, 139–151. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency estimation of physical symptoms for peoples is the most direct way to analyze and predict infectious diseases. In Internet of medical Things (IoMT), it is efficient and convenient for users to report their physical symptoms to hospitals or disease prevention departments by various mobile devices . Unfortunately, it usually brings leakage risk of these symptoms since data receivers may be untrusted. As a strong metric for health privacy, local differential privacy (LDP) requires that users should perturb their symptoms to prevent the risk. However, the widely-used data structure called sketch for frequency estimation does not satisfy the specified requirement. In this paper, we firstly define the problem of frequency estimation of physical symptoms under LDP. Then, we propose four different protocols, i.e., CMS-LDP , FCS-LDP , CS-LDP and FAS-LDP to solve the above problem. Next, we demonstrate that the designed protocols satisfy LDP and unbiased estimation. We also present two approaches to implement the key component (i.e., universal hash functions) of protocols. Finally, we conduct experiments to evaluate four protocols on two real-world datasets, representing two different distributions of physical symptoms. The results show that CMS-LDP and CS-LDP have relatively optimal utility for frequency estimation of physical symptoms in IoMT.},
  archive      = {J_COMCOM},
  author       = {Xiaotong Wu and Mohammad Reza Khosravi and Lianyong Qi and Genlin Ji and Wanchun Dou and Xiaolong Xu},
  doi          = {10.1016/j.comcom.2020.08.015},
  journal      = {Computer Communications},
  pages        = {139-151},
  shortjournal = {Comput. Commun.},
  title        = {Locally private frequency estimation of physical symptoms for infectious disease analysis in internet of medical things},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beyond socket options: Towards fully extensible linux
transport stacks. <em>COMCOM</em>, <em>162</em>, 118–138. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Transmission Control Protocol (TCP) is one of the most important protocols in today’s Internet. It was designed to be extensible for various use cases. A client can propose to use an extension over a given TCP connection by sending a TCP option that identifies this extension. In practice, deploying a TCP extension is difficult as the maintainers of client stacks often wait until servers implement a given extension and server maintainers look at clients in the same manner. It often takes several years if not a decade to actually deploy a TCP option widely. Our goal is to support experimenting and deploying new TCP options in a quick, simple, and efficient way. This includes inserting new TCP options at the sender side and parsing them at the receiver side. The implementation and the interface should be simple, generic, and introduce as few changes to the kernel code as possible. In this paper, we focus on the Linux TCP stack since it is one of the most widely used TCP stacks, given its utilization on many servers and Android devices. For this purpose, we leverage the extended Berkeley Packet Filter (eBPF), which is a recently developed in-kernel infrastructure to enable high performance and safe programmability to the Linux kernel space. Multipath TCP (MPTCP) is a major TCP extension that enables more capabilities and has richer semantics than regular TCP. We implemented a similar methodology in the Linux MPTCP stack to support new use-cases through custom MPTCP options. Moreover, an eBPF-based framework for user-defined path managers is also proposed, given that subflow management is an important task in Multipath TCP.},
  archive      = {J_COMCOM},
  author       = {Viet-Hoang Tran and Olivier Bonaventure},
  doi          = {10.1016/j.comcom.2020.07.036},
  journal      = {Computer Communications},
  pages        = {118-138},
  shortjournal = {Comput. Commun.},
  title        = {Beyond socket options: Towards fully extensible linux transport stacks},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smart lightweight privacy preservation scheme for
IoT-based UAV communication systems. <em>COMCOM</em>, <em>162</em>,
102–117. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV) has extensively been practiced in the military and civilian surveillance systems that access sensitive data over the cellular networks . However, channel insecurity and battery limitation may not protect the aerial coverage area. Thus, sensitive information gathered through aerial vehicles causes security threats. To manage the security issues, Smart Internet of Drone (S-IoD) have been evolved to use Intelligent Personal Assistant (IPA) as a software agent while monitoring and observing areas of interest. The current state-of-the-art technologies provide ubiquitous communication to enable several Internet of Things (IoT) paradigms. It achieves a feature of a decision support system that allows the smart interaction and communication between real-time entities. IPA offers smart interaction with other smart real-time entities to gain the user’s knowledge and awareness. This paper presents an S-IoD framework for a UAV environment that independently collects sensible information. In order to reduce the computation cost of the authentication protocol , a lightweight privacy-preserving scheme (L-PPS) is introduced. The proposed L-PPS is constructive to provide the robustness between the IoT devices with a valid authentication period. To demonstrate the security and performance efficiencies, the formal verification was performed using a verification tool, Scyther, and a random oracle model . In addition, the proposed L-PPS introduces a secret token and dynamic user authentication to speed up the authentication process between the communication entities. Importantly, the authentication session of L-PPS does not use any complex cryptographic operations , whereby it has less computation and communication costs to meet the standard constraints of surveillance systems. Moreover, the obtained simulation analysis proves that the proposed L-PPS achieves better quality metrics than other authentication schemes in the literature.},
  archive      = {J_COMCOM},
  author       = {B.D. Deebak and Fadi Al-Turjman},
  doi          = {10.1016/j.comcom.2020.08.016},
  journal      = {Computer Communications},
  pages        = {102-117},
  shortjournal = {Comput. Commun.},
  title        = {A smart lightweight privacy preservation scheme for IoT-based UAV communication systems},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy-preserving model training architecture for
intelligent edge computing. <em>COMCOM</em>, <em>162</em>, 94–101. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence and increasing data generated by end devices, the traditional cloud-centric data processing is gradually replaced by intelligent edge computing to achieve faster and nearer service via breaking the limit of network bandwidth and communication delay. However, training machine learning (ML) models on end devices is severely resource-constrained; besides, the privacy protection and continuous improvement of ML models are challenging. To address these problems, we propose an ML model training architecture to achieve intelligent edge computing in a novel cloud-edge-device cooperative manner, which is consisted of two phases: (1) the cooperative federated pre-training phase between the cloud and edge server is inspired by federated learning , coming with an incentive mechanism for fair reward allocation according to the contribution of edge servers for pre-training the model; (2) the privacy-preserving model segmentation training phase between the edge server and device leverages homomorphic encryption to realize model improvement and protection on end devices while transferring a large amount of computation to edge servers. Extensive simulations based on synthetic and real-world data demonstrate the effectiveness and feasibility of our proposed framework.},
  archive      = {J_COMCOM},
  author       = {Xidi Qu and Qin Hu and Shengling Wang},
  doi          = {10.1016/j.comcom.2020.07.045},
  journal      = {Computer Communications},
  pages        = {94-101},
  shortjournal = {Comput. Commun.},
  title        = {Privacy-preserving model training architecture for intelligent edge computing},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum and classical genetic algorithms for multilevel
segmentation of medical images: A comparative study. <em>COMCOM</em>,
<em>162</em>, 83–93. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a multilevel segmentation methods of medical images based on the classical and quantum genetic algorithms . The Genetic Algorithm (GA) uses a binary coding while the Quantum Genetic Algorithm (QGA) uses the qubit encoding of individuals. The two evolutionary algorithms are employed to maximize efficiently Rényi, Masi and Shannon entropies for the purpose of multi-objects segmentation of medical images. The Particle Swarm Optimization algorithm (PSO) was also used for comparison reasons. The segmentation quality of the nine proposed approaches is assessed by means of the prevailing indices PSNR , SSIM and FSIM. The numerical results and the comparative study were carried out on a sample of twenty medical images. It was shown that the QGA outpaces the GA, and the PSO outperforms significantly the both algorithms in the optimization task . Finally, it was found that the Rényi entropy is more suitable for the purpose of medical image multilevel thresholding.},
  archive      = {J_COMCOM},
  author       = {Inès Hilali-Jaghdam and Anis Ben Ishak and S. Abdel-Khalek and Amani Jamal},
  doi          = {10.1016/j.comcom.2020.08.010},
  journal      = {Computer Communications},
  pages        = {83-93},
  shortjournal = {Comput. Commun.},
  title        = {Quantum and classical genetic algorithms for multilevel segmentation of medical images: A comparative study},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerating on-device DNN inference during service outage
through scheduling early exit. <em>COMCOM</em>, <em>162</em>, 69–82. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid development of edge computing enables us to process a wide variety of intelligent applications at the edge, such as real-time video analytics . However, edge computing could suffer from service outage caused by the fluctuated wireless connection or congested computing resource. During the service outage, the only choice is to process the deep neural network (DNN) inference at the local mobile devices . The obstacle is that due to the limited resource, it may not be possible to complete inference tasks on time. Inspired by the recently developed early exit of DNNs, where we can exit DNN at earlier layers to shorten the inference delay by sacrificing an acceptable level of accuracy, we propose to adopt such mechanism to process inference tasks during the service outage. The challenge is how to obtain the optimal schedule with diverse early exit choices. To this end, we formulate an optimal scheduling problem with the objective to maximize a general overall utility. However, the problem is in the form of integer programming , which cannot be solved by a standard approach. We therefore prove the Ordered Scheduling structure, indicating that a frame arrived earlier must be scheduled earlier. Such structure greatly decreases the searching space for an optimal solution. Then, we propose the Scheduling Early Exit (SEE) algorithm based on dynamic programming , to solve the problem optimally with polynomial computational complexity . Finally, we conduct trace-driven simulations and real-world experiment to compare SEE with two benchmarks. The result shows that the utility gain of SEE can outperform the benchmarks by 50.9\% in the simulation and by 57.79\% in the real-world experiment.},
  archive      = {J_COMCOM},
  author       = {Zizhao Wang and Wei Bao and Dong Yuan and Liming Ge and Nguyen H. Tran and Albert Y. Zomaya},
  doi          = {10.1016/j.comcom.2020.08.005},
  journal      = {Computer Communications},
  pages        = {69-82},
  shortjournal = {Comput. Commun.},
  title        = {Accelerating on-device DNN inference during service outage through scheduling early exit},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). COLiDeR: A cross-layer protocol for two-path relaying.
<em>COMCOM</em>, <em>162</em>, 59–68. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present COLiDeR, the first PHY/MAC cross-layer protocol for practical two-path relaying using off-the-shelf half-duplex radios. It relies on three main contributions. First, based on an off-line performance comparison, COLiDeR selects the best interference management technique for a radio to handle two overlapping signals depending on the measured channel conditions. Then, considering the real decoding capacities of the nodes, COLiDeR introduces a dynamic relaying strategy with the objective of achieving high throughput while reducing decoding failures . This includes a light-weight protocol for the source to evaluate the channel state, a state-machine modeled approach driven by the source for switching between the defined scheduling schemes and an optional power adaptation mechanism for reducing the packet losses . Finally, COLiDeR comes with an adapted scheduling mechanism that aims to integrate two path-relaying in multi-hop wireless networks. Experiments on a 4-USRP testbed show that COLiDeR delivers between 80\%–95\% of the relaying performance of an ideal full-duplex radio while incurring negligible decoding failures. Just as important, large-scale simulations show that COLiDeR improves network throughput in multihop topologies by over 20\% compared to traditional interference-free transmissions.},
  archive      = {J_COMCOM},
  author       = {Raphaël Naves and Gentian Jakllari and Hicham Khalifé and Vania Conan and André-Luc Beylot},
  doi          = {10.1016/j.comcom.2020.07.037},
  journal      = {Computer Communications},
  pages        = {59-68},
  shortjournal = {Comput. Commun.},
  title        = {COLiDeR: A cross-layer protocol for two-path relaying},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Malware propagation model in wireless sensor networks under
attack–defense confrontation. <em>COMCOM</em>, <em>162</em>, 51–58. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important security problem faced by wireless sensor networks (WSNs) is malware propagation. Traditional malware propagation models take less consideration of the impact of the attack and defense processes on malware propagation results. We analyzed the micro-mechanism of malware propagation in WSNs from the perspective of the game theory, established the attack–defense game model of WSNs, derived the mixed Nash equilibrium solution of the game model, and derived the contagion probability of malwares according to the mixed Nash equilibrium strategy of both sides in the game, thus establishing the malware propagation model in WSNs. From the analysis of the theoretical model, we deduced the relationship between the steady-state infection ratio and the game parameters and obtained the conditions for the long-term existence of malwares. In addition, we simulated the propagation process of malwares in WSNs with cellular automaton and the simulation results verified the correctness of the theoretical model. The results have theoretical guiding significance for suppressing the propagation of malwares in WSNs.},
  archive      = {J_COMCOM},
  author       = {Haiping Zhou and Shigen Shen and Jianhua Liu},
  doi          = {10.1016/j.comcom.2020.08.009},
  journal      = {Computer Communications},
  pages        = {51-58},
  shortjournal = {Comput. Commun.},
  title        = {Malware propagation model in wireless sensor networks under attack–defense confrontation},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Diagnosis of heart diseases by a secure internet of health
things system based on autoencoder deep neural network. <em>COMCOM</em>,
<em>162</em>, 31–50. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective of this study is to introduce a secure IoHT system, which acts as a clinical decision support system with the diagnosis of cardiovascular diseases. In this sense, it was emphasized that the accuracy rate of diagnosis (classification) can be improved via deep learning algorithms, by needing no hybrid-complex models, and a secure data processing can be achieved with a multi-authentication and Tangle based approach. In detail, heart sounds were classified with Autoencoder Neural Networks (AEN) and the IoHT system was built for supporting doctors in real-time. For developing the diagnosis infrastructure by the AEN, PASCAL B-Training and Physiobank-PhysioNet A-Training heart sound datasets were used accordingly. For the PASCAL dataset, the AEN provided a diagnosis-classification performance with the accuracy of 100\%, sensitivity of 100\%, and the specificity of 100\% whereas the rates were respectively 99.8\%, 99.65\%, and 99.13\% for the PhysioNet dataset. It was seen that the findings by the developed AEN based solution were better than the alternative solutions from the literature. Additionally, usability of the whole IoHT system was found positive by the doctors, and according to the 479 real-case applications, the system was able to achieve accuracy rates of 96.03\% for normal heart sounds, 91.91\% for extrasystole, and 90.11\% for murmur. In terms of security approach, the system was also robust against several attacking methods including synthetic data impute as well as trying to penetrating to the system via central system or mobile devices .},
  archive      = {J_COMCOM},
  author       = {Omer Deperlioglu and Utku Kose and Deepak Gupta and Ashish Khanna and Arun Kumar Sangaiah},
  doi          = {10.1016/j.comcom.2020.08.011},
  journal      = {Computer Communications},
  pages        = {31-50},
  shortjournal = {Comput. Commun.},
  title        = {Diagnosis of heart diseases by a secure internet of health things system based on autoencoder deep neural network},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating visually coherent encrypted images with
reversible data hiding in wavelet domain by fusing chaos and pairing
function. <em>COMCOM</em>, <em>162</em>, 12–30. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For secure transmission of digital images, existing cryptographic algorithms transform coherent visual information into a noise-like appearance prompting an adversary of the presence of a possible cipher. This paper proposes an algorithm that produces a visually coherent and meaningful cipher image. The proposed algorithm consists of a permutation-substitution subroutine to obtain a partial cipher. The Arnold-3D map does the permutation, and a delayed logistic map performs the substitution in this subroutine. The hiding of this partial cipher is done in the reference image using an integer wavelet transform . The pixels of the partial cipher are embedded in the four sub-bands of the decomposed reference image as 4 to 1-pixel encoding using Cantor-like pairing function. In addition to the lossless encryption scheme , the integer nature of all the sub-bands in the wavelet decomposition and the invertible pairing function facilitates the perfect reconstruction of the reference image. One of the significant novelty of this work lies in the subtle use of simple pairing functions, which prohibits the unnecessary increase in the size of the cipher, thereby reducing the storage and transmission costs.},
  archive      = {J_COMCOM},
  author       = {Farhan Musanna and Sanjeev Kumar},
  doi          = {10.1016/j.comcom.2020.08.008},
  journal      = {Computer Communications},
  pages        = {12-30},
  shortjournal = {Comput. Commun.},
  title        = {Generating visually coherent encrypted images with reversible data hiding in wavelet domain by fusing chaos and pairing function},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TOT: Trust aware opportunistic transmission in cognitive
radio social internet of things. <em>COMCOM</em>, <em>162</em>, 1–11.
(<a href="https://doi.org/10.1016/j.comcom.2020.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Social Internet of Things (SIoT), which represents inseparable relationships between humans and devices, has become a hot research topic in wireless networks. As more heterogeneous devices will be connected, a higher frequency spectrum becomes a requirement. The cognitive radio (CR) technology can improve spectrum utilization in an opportunistic communication manner. However, dynamic spectrum availability and heterogeneous devices complicate routing design in CR-SIoT. Opportunistic routing (OR) can mitigate the drawbacks for routing design of cognitive radio social internet of things, CR-SIoT, by leveraging the broadcast nature of wireless channels; and thereby enhance the network performance. In this work, we propose an energy and trust aware OR in CR-SIoT, which jointly considers energy efficiency, trust and social features. In the proposed scheme, we exploit a new routing metric for selecting forwarding candidates based on optimal stopping theory and use network coding for the data transmission between trusted nodes for multiple types of flows in CR-SIoT. In addition, we propose a game-theoretic approach to allocate the trusted channel for CR-SIoT which is based on expected network gain. Extensive simulation results show that the proposed secure OR protocol performs better than existing routing protocols in CR-SIoT in terms of average energy cost per bit, packet delivery ratio (PDR), network lifetime, average delay, throughput and expected cost of routing.},
  archive      = {J_COMCOM},
  author       = {Xinghan Wang and Xiaoxiong Zhong and Li Li and Sheng Zhang and Renhao Lu and Tingting Yang},
  doi          = {10.1016/j.comcom.2020.08.007},
  journal      = {Computer Communications},
  pages        = {1-11},
  shortjournal = {Comput. Commun.},
  title        = {TOT: Trust aware opportunistic transmission in cognitive radio social internet of things},
  volume       = {162},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Artificial intelligence aware and security-enhanced
traceback technique in mobile edge computing. <em>COMCOM</em>,
<em>161</em>, 375–386. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor network, as one component of mobile edge computing (MEC), is a promising platform to provide services for users. With the development of artificial intelligence (AI) applications, the integration of mobile edge computing and AI unlocks unlimited possibilities in people’s daily lives. However, AI techniques and mechanisms specifically designed for the devices and servers operating in the mobile edge computing environment face secure challenge. To improve the security of wireless network, a security-enhanced traceback (SET) scheme is proposed. Firstly, the network is divided into three areas, nodes in different areas adopt different marking probability. Nodes in the area far from the sink adopt higher marking probability, nodes in the area nearest to the sink adopt lower marking probability to save energy. Secondly, the marking tuple of data packets is not only stored in nodes, but also is migrated to nodes far from the sink to balance the storage space of nodes. The results of both theoretical analysis and extensive experimental simulations indicate that the network performance of SET scheme is better than the existing traceback scheme.},
  archive      = {J_COMCOM},
  author       = {Yuxin Liu and Tian Wang and Shaobo Zhang and Xuxun Liu and Xiao Liu},
  doi          = {10.1016/j.comcom.2020.08.006},
  journal      = {Computer Communications},
  pages        = {375-386},
  shortjournal = {Comput. Commun.},
  title        = {Artificial intelligence aware and security-enhanced traceback technique in mobile edge computing},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flexible functional split for cost-efficient c-RAN.
<em>COMCOM</em>, <em>161</em>, 368–374. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose flexible functional split schemes for a multi-tier C-RAN architecture based on the concept of virtual remote radio heads (V-RRHs), aiming at optimizing the resource utilization while reducing the overall cost of BBU pool. A V-RRH consists of a digital unit (DU) that hosts a few baseband (BB) processing functionalities and a radio unit (RU) with RF functionality. Specifically, three types of V-RRHs differing in the number of BB processing function slices are considered in three functional split options. We aim at finding the optimal functional split option for each task and thus allocate the appropriate function slice block (FSB) of BBU pool for it. The issue of optimally allocating FSBs to tasks is normalized as a zero–one (0–1) packing problem which is NP-complete. To solve the 0–1 packing problem , we divide it into three stages and solve them by a pure integer non-linear programming (PINLP) model. Numerical results show that the proposed flexible functional split strategies comprehensively outperform the existing C-RAN and D-RAN schemes in terms of the overall cost.},
  archive      = {J_COMCOM},
  author       = {Haoran Mei and Limei Peng},
  doi          = {10.1016/j.comcom.2020.07.029},
  journal      = {Computer Communications},
  pages        = {368-374},
  shortjournal = {Comput. Commun.},
  title        = {Flexible functional split for cost-efficient C-RAN},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensing network security prevention measures of BIM smart
operation and maintenance system. <em>COMCOM</em>, <em>161</em>,
360–367. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of network scale and the increasing complexity of attack methods, traditional network security protection equipment has been unable to cope with large-scale network security detection and protection. However, most current operation and maintenance systems cannot reasonably evaluate and predict network security. In order to be able to evaluate and prevent the network security of the bridge BIM intelligent operation and maintenance system under the background of big data, this paper uses the KDD Cup99 data set and the network attack data in the bridge BIM network environment to simulate the method proposed in this paper. The comparison results verify that the network security risk perception method proposed in this paper can realize network security risk perception more accurately and efficiently. This paper proposes a data mining method based on Bayesian network algorithm to evaluate the risk value of the bridge BIM intelligent operation and maintenance system. During the period from 0 to 110 min, the network risk value increased from 0.003 to 0.91. It can be seen that with the deepening of the attack phase, the degree of network risk will also increase. This paper uses the detection rate, false negative rate, false positive rate, AUC and other indicators to conduct simulation experiments on the data prediction-based network security risk prediction algorithm and comparison algorithm proposed in this paper. Simulation experiments show that under the four simulation experiment environments (pl = pe = 0.01/0.15, n = 20/50), the AUC of this scheme is increased by 0.018, 0.053, 0.008 and 0.11, respectively. The proposed algorithms are better than the comparison algorithms.},
  archive      = {J_COMCOM},
  author       = {Yu Peng and Xinrong Liu and Ming Li and Zheng Li and Tao Hu and Yangjun Xiao and Sheng Zhang and Luyu Zhang and Pengwei Wang and Chengwu Ming and Xiaobo Mi},
  doi          = {10.1016/j.comcom.2020.07.039},
  journal      = {Computer Communications},
  pages        = {360-367},
  shortjournal = {Comput. Commun.},
  title        = {Sensing network security prevention measures of BIM smart operation and maintenance system},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of latency-aware flow allocation in NGFI
networks. <em>COMCOM</em>, <em>161</em>, 344–359. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The next generation fronthaul interface (NGFI) architecture has been specified recently in the IEEE P1914.1 standard for packet-based fronthaul transport networks. NGFI is a flexible and cost-effective solution developed for meeting stringent latency and throughput requirements of future centralized and virtualized radio access networks (C-RAN/vRAN) in the 5th generation mobile networks (5G). NGFI allows for splitting baseband processing functions of a radio frequency signal between radio unit (RU), distributed unit (DU), and central unit (CU), where each of these elements may be located at a different site of the network. In the NGFI network, the radio data to be processed is transmitted between the RU, DU, and CU in the form of packets and routed by means of packet switches over a common packet-based fronthaul transport network. In this paper, we address a basic optimization problem in an NGFI network that concerns allocation of transmission resources in network links for the RU–DU and DU–CU data flows assuming quality of service (QoS) requirements related to maximal latency of these flows. To formulate the latency-aware flow allocation (LFA) optimization problem , we apply the mixed integer programming (MIP) approach. To generate solutions to larger LFA problem instances, we develop a meta-heuristic algorithm. To account for latency constraints in both MIP and meta-heuristic, we make use of a worst-case latency estimation model. The results of numerical experiments run in three network topologies for different network instances show the effectiveness of the meta-heuristic method, when compared to the MIP approach. These results also allow us to assess the performance of the NGFI network considered.},
  archive      = {J_COMCOM},
  author       = {Mirosław Klinkowski},
  doi          = {10.1016/j.comcom.2020.07.044},
  journal      = {Computer Communications},
  pages        = {344-359},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of latency-aware flow allocation in NGFI networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of base station density and user transmission
power in multi-tier heterogeneous cellular systems. <em>COMCOM</em>,
<em>161</em>, 334–343. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a loss minimization issue is proposed, which includes both cost of user power consumption and base station (BS) deployment. A multi-tier heterogeneous network (HetNet) is considered and modeled with random geometry of Poisson point process (PPP). BSs and users are distributed randomly following PPP with the specific densities. Cutoff threshold ( ρ k ρk ) as the average received power at the k th tier BS is proposed to model uplink channels. The k th tier user transmission power is formulated through a channel inversion power control. Tier Selection Probability indicating the possibility of a user accessing a certain tier is derived. Bias ( B k Bk ) is proposed to change the k th tier Tier Selection Probability . Thus, an operator is able to change bias based on nearby environment and communication status. Also, Truncated Outage Probability and signal-to-interference ratio (SINR) Outage Probability are derived, which represents a connection failure status. Truncated outage results from insufficient power supply at users and SINR outage results from poor communication environment. Genetic algorithm (GA) is introduced to determine the trade off between outage constraints and the loss minimization issue. Simulation shows that, when equipped with equal bias, multi-tier network has smaller Truncated Outage Probability but larger SINR Outage Probability than single-tier network. On the contrary, with different bias, Truncated Outage Probability in multi-tier is larger than the single-tier case and SINR Outage Probability in multi-tier is less than that in single-tier. A considerable loss reduction can be witnessed in both cases.},
  archive      = {J_COMCOM},
  author       = {Zhixin Liu and Heng Zhu and Yazhou Yuan and Yi Yang and Kit Yan Chan},
  doi          = {10.1016/j.comcom.2020.08.001},
  journal      = {Computer Communications},
  pages        = {334-343},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of base station density and user transmission power in multi-tier heterogeneous cellular systems},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PacketUsher: Exploiting DPDK to accelerate compute-intensive
packet processing. <em>COMCOM</em>, <em>161</em>, 324–333. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many compute-intensive network applications such as application-layer traffic generator , Deep Packet Inspection(DPI) and web servers are widely deployed on commodity PC for the reason of flexibility and cheap price. However, how to improve their performance on general purpose OS is challenging due to the high packet I/O related overheads. This paper presents PacketUsher, a high-performance packets processing framework to remove these performance bottlenecks . In building PacketUsher, we constructed a DPDK wrapper as the underlying packet I/O engine to accelerate packet transmission , and utilized the strategies of zero copy, batch processing and parallelism to improve packet processing. Through RFC2544 benchmark, we demonstrate that DPDK wrapper has excellent packets transmission capability. As a case study of PacketUsher, we design and implement a commercial application-layer traffic generator . The experiment results show that the FPS (Flow Per Second) value of our traffic generator over PacketUsher is more than 4 times of that over standard Linux platform . By comparison, the FPS value over PacketUsher is about 3 times of that over existing methods (Netmap and PF_RING).},
  archive      = {J_COMCOM},
  author       = {Qingqing Ren and Liang Zhou and Zhijun Xu and Yujun Zhang and Lei Zhang},
  doi          = {10.1016/j.comcom.2020.07.040},
  journal      = {Computer Communications},
  pages        = {324-333},
  shortjournal = {Comput. Commun.},
  title        = {PacketUsher: Exploiting DPDK to accelerate compute-intensive packet processing},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A taxonomy of blockchain-enabled softwarization for secure
UAV network. <em>COMCOM</em>, <em>161</em>, 304–323. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advancements in unmanned aerial vehicles (UAVs) upsurges its usages in commercial and civilian applications such as surveillance, rescue, and crowdsensing. UAVs are vulnerable to being destroyed, lost, or stolen in case of security breaches of its network. The network management of UAVs is a crucial task due to its high mobility, which necessitates UAV network softwarization. Then, it becomes indispensable that allows the separation of control functions (i.e., control plane data) from hardware for smooth execution of complex operations. Further, UAV uses the Internet (an open channel) for communication in its complex system that raises a network security concern. The well-known softwarization techniques, i.e., software-defined networking (SDN) and network function virtualization (NFV) can be used to accomplish the secure network services on less expense. Conversely, these softwarization techniques may suffer from various threats like access control, user authentication , controller hijacking, and many more attack. The existing solutions are using a centralized system, which is having a single point of failure issue and vulnerable to security threats. Motivated from these facts, we present a comprehensive and systematic survey on the blockchain-based softwarization for a secure UAV network. Then, we propose a blockchain-enabled UAV softwarization architecture for secure communication and network management. It provides dynamic, flexible, and on-the-fly decision capabilities for communication services over the UAV network. Eventually, we analyzed the open research issues and challenges for future research directions in this emerging area.},
  archive      = {J_COMCOM},
  author       = {Aparna Kumari and Rajesh Gupta and Sudeep Tanwar and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.07.042},
  journal      = {Computer Communications},
  pages        = {304-323},
  shortjournal = {Comput. Commun.},
  title        = {A taxonomy of blockchain-enabled softwarization for secure UAV network},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A taxonomy of AI techniques for 6G communication networks.
<em>COMCOM</em>, <em>161</em>, 279–303. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With 6G flagship program launched by the University of Oulu, Finland, for full future adaptation of 6G by 2030, many institutes worldwide have started to explore various issues and challenges in 6G communication networks. 6G offers ultra high-reliable and massive ultra-low latency while opening the doors for many applications currently not viable by today’s 4G and 5G communication standards. The current 5G technology has security and privacy issues which makes its usage in limited applications. In such an environment, we believe that AI can offer efficient solutions for the aforementioned issues having low communication overhead cost. Keeping focus on all these issues, in this paper, we presented a comprehensive survey on AI-enabled 6G communication technology, which can be used in wide range of future applications. In this article, we explore how AI can be integrated into different applications such as object localization , UAV communication, surveillance, security and privacy preservation etc. Finally, we discussed a use case that shows the adoption of AI techniques in intelligent transport system.},
  archive      = {J_COMCOM},
  author       = {Karan Sheth and Keyur Patel and Het Shah and Sudeep Tanwar and Rajesh Gupta and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.07.035},
  journal      = {Computer Communications},
  pages        = {279-303},
  shortjournal = {Comput. Commun.},
  title        = {A taxonomy of AI techniques for 6G communication networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary game theoretical model for stable femtocells’
clusters formation in HetNets. <em>COMCOM</em>, <em>161</em>, 266–278.
(<a href="https://doi.org/10.1016/j.comcom.2020.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Femtocell deployment is one of the key solutions to achieve the high data rate of the fifth generation mobile communication. Nevertheless, dense femtocell networks face several challenging tasks such as interference control and resource management. In this paper, we address the problem of resource allocation for heterogeneous networks (HetNets), namely dense femtocell networks, by forming stable clusters using an evolutionary game where femtocells learn from the environment and make their decisions considering the achieved payoff. In the literature, clustering has been proposed to organize network topologies by joining nodes (e.g. femtocells) with similar behaviors into logical groups. We focus on cluster stability that is important to obtain good network performance but can be difficult to achieve especially in ultra-dense and heterogeneous networks. In order to guarantee the cluster stability, we use the replicator dynamics that find the evolutionary equilibrium of the evolutionary game. Thus, by guaranteeing cluster stability the network performance is improved and the computational complexity is reduced. In addition, Particle Swarm Optimization (PSO) is used for the resource allocation algorithm that runs locally within each cluster owing to the fact that PSO has been proved to find a satisfying near-optimal solution while having the advantage of speeding up the optimization process. We run simulations for non-dense and dense femtocell networks taking into account two scenarios: fixed public users and public users that keep mobility such as pedestrians or cyclists. Simulation results show that the proposed solution is able to enhance the network throughput, to provide higher subscribers satisfaction, and to reduce the co-tier interference in dense femtocell networks.},
  archive      = {J_COMCOM},
  author       = {Katty Rohoden and Rebeca Estrada and Hadi Otrok and Zbigniew Dziong},
  doi          = {10.1016/j.comcom.2020.07.041},
  journal      = {Computer Communications},
  pages        = {266-278},
  shortjournal = {Comput. Commun.},
  title        = {Evolutionary game theoretical model for stable femtocells’ clusters formation in HetNets},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wearable bracelets with variable sampling frequency for
measuring multiple physiological parameter of human. <em>COMCOM</em>,
<em>161</em>, 257–265. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the acceleration of modernization and the marked improvement in the quality of life, more and more people pay attention to their own health. Sports health has become the first choice for most people because of its natural and healthy way. Therefore, devices with step counting functions such as smart bracelets and smart phones came into being. This paper proposes a design method for measuring the human body’s multiple physiological parameters with multiple sampling frequencies. It collects three physiological parameters of blood oxygen saturation, exercise energy consumption and body temperature of a sports human body. At the same time, in order to improve the endurance of a healthy bracelet, a variable sampling frequency scheme is designed using the BP neural network algorithm, and all physical health information can be determined according to the heart rate frequency. STM32 combined with host computer is used to verify the design method. It can monitor real-time human physiological parameters and conduct a comprehensive assessment of human health recording changes in human health information. Through the system test and analysis of the experimental results, it is verified that the physiological data collected has higher accuracy based on improving the endurance.},
  archive      = {J_COMCOM},
  author       = {Jian Hu and Junjie Wang and Hangqi Xie},
  doi          = {10.1016/j.comcom.2020.07.043},
  journal      = {Computer Communications},
  pages        = {257-265},
  shortjournal = {Comput. Commun.},
  title        = {Wearable bracelets with variable sampling frequency for measuring multiple physiological parameter of human},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain based integrated security measure for reliable
service delegation in 6G communication environment. <em>COMCOM</em>,
<em>161</em>, 248–256. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sixth generation (6G) communication environment is unfolded in the recent years in order to provide high throughput less latency services for the mobile users. This environment encloses a variety of heterogeneous resources and communication standards to ensure seamless availability of services. In this open environment, security is a concerning issue due to heterogeneous standard integration and access delegations. This paper introduces blockchain-based integrated security measure (BISM) for providing secure access control and privacy preserving for the resources and the users. The access control process relies on the states of the virtualized resources at different time instances and the privacy preserving relies on longevity of service responses. The access delegation and denial is decided by the changeover of the states of the resources as aided by the Q-learning procedure for improving the service related performance. This performance for access control and privacy is verified using the metrics true positives , access denial and success ratio, access time and modification, memory utilization and time complexity.},
  archive      = {J_COMCOM},
  author       = {Gunasekaran Manogaran and Bharat S. Rawal and Vijayalakshmi Saravanan and Priyan Malarvizhi Kumar and Oscar Sanjuán Martínez and Rubén González Crespo and Carlos Enrique Montenegro-Marin and Sujatha Krishnamoorthy},
  doi          = {10.1016/j.comcom.2020.07.020},
  journal      = {Computer Communications},
  pages        = {248-256},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain based integrated security measure for reliable service delegation in 6G communication environment},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A solution to MPTCP’s inefficiencies under the incast
problem for data center networks. <em>COMCOM</em>, <em>161</em>,
238–247. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years several multipath data transport mechanisms, such as MPTCP and XMP, have been introduced to effectively exploit the path diversity of data center networks (DCNs). However, these multipath schemes have not been widely deployed in DCNs. We argue that two key factors among others impeded their adoption: TCP incast and minimum window syndrome . First, these mechanisms are ill-suited for workloads with a many-to-one communication pattern, commonly found in DCNs, causing frequent TCP incast collapses. Second, the syndrome we discover for the first time, results in 2-5 times lower throughput for single-path flows than multipath flows, thus severely violating network fairness. To effectively tackle these problems, we propose AMP: an adaptive multipath congestion control mechanism that quickly detects the onset of these problems and transforms its multipath flow into a single-path flow. Once these problems disappear, AMP safely reverses this transformation and continues its data transmission via multiple paths. Our evaluation results under a diverse set of scenarios in a fat-tree topology with realistic workloads demonstrate that AMP is robust to the TCP incast problem and improves network fairness between multipath and single-path flows significantly with little performance loss.},
  archive      = {J_COMCOM},
  author       = {Morteza Kheirkhah and Myungjin Lee},
  doi          = {10.1016/j.comcom.2020.07.034},
  journal      = {Computer Communications},
  pages        = {238-247},
  shortjournal = {Comput. Commun.},
  title        = {A solution to MPTCP’s inefficiencies under the incast problem for data center networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of hybrid crowdsensing systems with
stateful CrowdSenSim 2.0 simulator. <em>COMCOM</em>, <em>161</em>,
225–237. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) has become a popular paradigm for data collection in urban environments. In MCS systems, a crowd supplies sensing information for monitoring phenomena through mobile devices . Depending on the degree of involvement of users, MCS systems can be participatory, opportunistic or hybrid, which combines strengths of above approaches. Typically, a large number of participants is required to make a sensing campaign successful which makes impractical to build and deploy large testbeds to assess the performance of MCS phases like data collection, user recruitment, and evaluating the quality of information. Simulations offer a valid alternative. In this paper, we focus on hybrid MCS and extend CrowdSenSim 2.0 in order to support such systems. Specifically, we propose an algorithm for efficient re-route users that would offer opportunistic contribution towards the location of sensitive MCS tasks that require participatory-type of sensing contribution. We implement such design in CrowdSenSim 2.0, which by itself extends the original CrowdSenSim by featuring a stateful approach to support algorithms where the chronological order of events matters, extensions of the architectural modules, including an additional system to model urban environments, code refactoring , and parallel execution of algorithms.},
  archive      = {J_COMCOM},
  author       = {Federico Montori and Luca Bedogni and Claudio Fiandrino and Andrea Capponi and Luciano Bononi},
  doi          = {10.1016/j.comcom.2020.07.021},
  journal      = {Computer Communications},
  pages        = {225-237},
  shortjournal = {Comput. Commun.},
  title        = {Performance evaluation of hybrid crowdsensing systems with stateful CrowdSenSim 2.0 simulator},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An emulation-based evaluation of TCP BBRv2 alpha for wired
broadband. <em>COMCOM</em>, <em>161</em>, 212–224. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Google published the first release of the Bottleneck Bandwidth and Round-trip Time (BBR) congestion control algorithm in 2016. Since then, BBR has gained a widespread attention due to its ability to operate efficiently in the presence of packet loss and in scenarios where routers are equipped with small buffers. These characteristics were not attainable with traditional loss-based congestion control algorithms such as CUBIC and Reno. BBRv2 is a recent congestion control algorithm proposed as an improvement to its predecessor, BBRv1. Preliminary work suggests that BBRv2 maintains the high throughput and the bounded queueing delay properties of BBRv1. However, the literature has been missing an evaluation of BBRv2 under different network conditions. This paper presents an experimental evaluation of BBRv2 Alpha (v2alpha-2019-07-28) on Mininet, considering alternative active queue management (AQM) algorithms, routers with different buffer sizes, variable packet loss rates and round-trip times (RTTs), and small and large numbers of TCP flows. Emulation results show that BBRv2 tolerates much higher random packet loss rates than loss-based algorithms but slightly lower than BBRv1. The results also confirm that BBRv2 has better coexistence with loss-based algorithms and lower retransmission rates than BBRv1, and that it produces low queuing delay even with large buffers. When a Tail Drop policy is used with large buffers, an unfair bandwidth allocation is observed among BBRv2 and CUBIC flows. Such unfairness can be reduced by using advanced AQM schemes such as FQ-CoDel and CAKE. Regarding fairness among BBRv2 flows, results show that using small buffers produces better fairness, without compromising high throughput and link utilization. This observation applies to BBRv1 flows as well, which suggests that rate-based model-based algorithms work better with small buffers. BBRv2 also enhances the coexistence of flows with different RTTs, mitigating the RTT unfairness problem noted in BBRv1. Lastly, the paper presents the advantages of using TCP pacing with a loss-based algorithm, when the rate is manually configured a priori. Future algorithms could set the pacing rate using explicit feedback generated by modern programmable switches.},
  archive      = {J_COMCOM},
  author       = {Elie F. Kfoury and Jose Gomez and Jorge Crichigno and Elias Bou-Harb},
  doi          = {10.1016/j.comcom.2020.07.018},
  journal      = {Computer Communications},
  pages        = {212-224},
  shortjournal = {Comput. Commun.},
  title        = {An emulation-based evaluation of TCP BBRv2 alpha for wired broadband},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security analysis of indistinguishable obfuscation for
internet of medical things applications. <em>COMCOM</em>, <em>161</em>,
202–211. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful cryptographic primitive , indistinguishable obfuscation has been widely used to protect data privacy on the Internet of Medical Things (IoMT) systems. Basically, the cryptographic technique protects data privacy using a function to obfuscate medical applications to perform outputs computationally indistinguishable. The state-of-the-art obfuscation technique (GGH13) utilizes a variant of the multilinear map to enhance security. However, in such schemes, it can be observed that noise lies in each element of the matrix, which means the matrix is a full rank matrix with a probability of almost 1 and results that it is unable to establish the relationship between the matrix determinant and rank. In this paper, we propose an attack to break such obfuscator. Specifically, we use approximate eigenvalues to remove the influence of noise on the matrix eigenvalues and build a specific relationship between the determinant and matrix rank. Our analysis shows the structural weakness of the state-of-the-art indistinguishable obfuscation mechanism, and we further discuss the future direction to resolve such privacy issues for IoMT applications.},
  archive      = {J_COMCOM},
  author       = {Zhengjun Jing and Chunsheng Gu and Yong Li and Mengshi Zhang and Guangquan Xu and Alireza Jolfaei and Peizhong Shi and Chenkai Tan and Xi Zheng},
  doi          = {10.1016/j.comcom.2020.07.033},
  journal      = {Computer Communications},
  pages        = {202-211},
  shortjournal = {Comput. Commun.},
  title        = {Security analysis of indistinguishable obfuscation for internet of medical things applications},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended analysis of age of information threshold
violations. <em>COMCOM</em>, <em>161</em>, 191–201. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a scenario where a monitor is interested in the freshest possible update from a remote sensor. The monitor also seeks to minimize the number of updates that exceed a certain freshness threshold, beyond which, the information is deemed to be too old. Previous work has presented results for First Come First Served (FCFS) systems. However, it has been shown that Last Come First Served (LCFS) with preemption is more effective in terms of average Age of Information (AoI); we therefore study an M/G/1 LCFS system with preemption. The generality of the busy time distribution gives the advantage of applicability on any distribution inside the model. For example, one can use a deterministic distribution to study a TDMA system, a gamma distribution to model a routing network, or a more complicated distribution to study a CSMA access scheme. We find a general procedure to derive the exact expression of the outage update probability — i.e. the portion of time updates have information older than a certain threshold. We compare different busy time distributions to the ones already present in literature for equivalent FCFS systems, showing the benefit of using the former discipline. We further study how the variance of the busy time distribution affects the update outage probability . We find two instances of the busy time distribution, where at low thresholds and low loads, higher variance gives an advantage in terms of update outage probability. First, we compare the M/D/1 LCFS with preemption against the M/ Γ Γ /1 LCFS with preemption and let the variance of the busy time of the latter vary, while maintaining the same average busy time for both systems. We further compare various M/ H 2 H2 /1 LCFS with preemption with different coefficient of variation and same expected value, thus covering a wider spectrum of variation of the busy time.},
  archive      = {J_COMCOM},
  author       = {Antonio Franco and Björn Landfeldt and Ulf Körner},
  doi          = {10.1016/j.comcom.2020.07.038},
  journal      = {Computer Communications},
  pages        = {191-201},
  shortjournal = {Comput. Commun.},
  title        = {Extended analysis of age of information threshold violations},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperative and efficient content caching and distribution
mechanism in 5G network. <em>COMCOM</em>, <em>161</em>, 183–190. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers encoding caching and collaborative distribution issues jointly, and proposes a collaborative and efficient content caching and distribution mechanism; and based on the proposed scheme, an energy consumption model is established from the perspective of content caching and content distribution to optimize Energy efficiency of content caching and content distribution. In addition, this paper proposes a cache placement algorithm based on heuristic greedy algorithm to solve this energy efficiency optimization problem by optimizing cache placement. Finally, the simulation results show the performance of the scheme. This paper proposes a content clustering distribution scheme for the problems of random user distribution and limited cache. This solution uses the user’s media cloud and communication technology to complete the distribution of video content. In addition, the use of an efficient adaptive media cloud clustering mechanism and a minimized hops algorithm has enabled the reasonable deployment of 5G network caches based on the popularity of video content and user distribution. The simulation results show that the system content request response time is shortened by 50\%, which effectively reduce the impact of content popularity changes on system performance. This paper analyses the important performance indicators such as cache hit rate , optimal communication radius, and maximum link access in 5G networks for multi-layer popular multimedia content distribution in response to the heterogeneity and transmission interference problems for 5G networks in 5G communications. Under the premise of noise ratio and signal-to-interference ratio threshold, related service link selection and scheduling algorithms is further proposed obtaining simulation results that approximate theoretical analysis, which effectively reduces the number of interference by 40\% and improves the system throughput by 10\%.},
  archive      = {J_COMCOM},
  author       = {Ying Sai and Dong-zhu Fan and Meng-yang Fan},
  doi          = {10.1016/j.comcom.2020.07.030},
  journal      = {Computer Communications},
  pages        = {183-190},
  shortjournal = {Comput. Commun.},
  title        = {Cooperative and efficient content caching and distribution mechanism in 5G network},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spam transaction attack detection model based on GRU and
WGAN-div. <em>COMCOM</em>, <em>161</em>, 172–182. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Spam Transaction attack is a kind of hostile attack activity specifically targeted against a Cryptocurrency Network. Traditional network intrusion detection methods lack the capability of automatic feature extraction for spam transaction attacks, and thus the detection efficiency is low. Worse still, these kinds of attack methods and the key intrusion behaviour process are usually concealed and submerged into a large number of normal data packages; therefore, the captured threat test samples are too small, which easily leads to insufficient training of detection model, low detection accuracy rate, and high false alarm rate . In this paper, a spam transaction intrusion detection model based on GRU(Gated Recurrent Unit) is proposed, which takes advantage of the excellent features of deep learning and uses repeated and multilevel learning to perform automatic feature extraction for network intrusion behaviour. The model has extremely high learning ability and massive data processing ability. Moreover, it has a quicker and more accurate spam transaction attack detection ability than traditional intrusion detection algorithms. Additionally, a generation method of spam transaction-samples based on WGAN-div is proposed, which obtains new samples by learning training samples and solves the problems of insufficient original samples and unbalanced samples. A series of experiments were performed to verify the proposed models. The proposed models can distinguish between normal and abnormal transaction behaviours with an accuracy reaching to 99.86\%. The experimental results indicate that the proposed models in this paper have higher efficiency and accuracy in detecting spam transaction attacks, which provides a novel and better idea for research of spam transaction attack detection systems.},
  archive      = {J_COMCOM},
  author       = {Jin Yang and Tao Li and Gang Liang and YunPeng Wang and TianYu Gao and FangDong Zhu},
  doi          = {10.1016/j.comcom.2020.07.031},
  journal      = {Computer Communications},
  pages        = {172-182},
  shortjournal = {Comput. Commun.},
  title        = {Spam transaction attack detection model based on GRU and WGAN-div},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). N-sanitization: A semantic privacy-preserving framework for
unstructured medical datasets. <em>COMCOM</em>, <em>161</em>, 160–171.
(<a href="https://doi.org/10.1016/j.comcom.2020.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction and rapid growth of the Internet of Medical Things (IoMT), a subset of the Internet of Things (IoT) in the medical and healthcare systems, has brought numerous changes and challenges to current medical and healthcare systems. Healthcare organizations share data about patients with research organizations for various medical discoveries. Releasing such information is a tedious task since it puts the privacy of patients at risk with the understanding that textual health documents about an individual contains specific sensitive terms that need to be sanitized before such document can be released. Recent approaches improved the utility of protected output by substituting sensitive terms with appropriate “generalizations” that are retrieved from several medical and general-purpose knowledge bases (KBs). However, these approaches perform unnecessary sanitization by anonymizing the negated assertions, e.g., AIDS-negative. This paper proposes a semantic privacy framework that effectively sanitizes the sensitive and semantically related terms in healthcare documents. The proposed model effectively identifies the negated assertions (e.g., AIDS-negative) before the sanitization process in IoMT which further improves the utility of sanitized documents. Moreover, besides considering the sensitive medical findings, we also incorporated state-of-the-art metrics, i.e., Protected Health Information (PHI), as defined in the privacy rules such as Health Insurance Portability and Accountability Act (HIPAA), Informatics for Integrating Biology &amp; the Bedside (i2b2), and Materialize Interactive Medical Image Control System (MIMICS). The proposed approach is evaluated on real clinical data provided by i2b2. On average the detection (for both PHI’s and medical findings) accuracy is improved with Precision, Recall and F-measure score at 21\%, 51\%, and 54\% respectively. The overall improved data utility of our proposed model is 8\% as compared to C-sanitized and 25\% when comparing it with a simple reduction approach. Experimental results show that our approach effectively manages the privacy and utility trade-off as compared to its counterparts.},
  archive      = {J_COMCOM},
  author       = {Celestine Iwendi and Syed Atif Moqurrab and Adeel Anjum and Sangeen Khan and Senthilkumar Mohan and Gautam Srivastava},
  doi          = {10.1016/j.comcom.2020.07.032},
  journal      = {Computer Communications},
  pages        = {160-171},
  shortjournal = {Comput. Commun.},
  title        = {N-sanitization: A semantic privacy-preserving framework for unstructured medical datasets},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning distributed communication and computation in the
IoT. <em>COMCOM</em>, <em>161</em>, 150–159. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In distributed, cooperative Internet of Things (IoT) settings, sensing devices must communicate in a resource-aware fashion to achieve a diverse set of tasks, (i.e., event detection, image classification). In such settings, we continue to see a shift from reliance on cloud-centric to edge-centric architectures for data processing, inference and actuation . Distributed edge inference techniques address real-time, connectivity, network bandwidth and latency challenges in spatially distributed IoT applications. Achieving efficient, resource-aware communication in such systems is a longstanding challenge. Many current approaches require complex, hand-engineered communication protocols. In this paper, we present a novel scalable, data-driven and communication-efficient Convolutional Recurrent Neural Network (C-RNN) framework for distributed tasks. We provide empirical and systematic analyses of model convergence, node scalability, computation-cost and communication-cost based on dynamic network graphs. Further to this, we show that our framework is able to solve distributed image classification tasks via automatically learned communication.},
  archive      = {J_COMCOM},
  author       = {Prince Abudu and Andrew Markham},
  doi          = {10.1016/j.comcom.2020.07.001},
  journal      = {Computer Communications},
  pages        = {150-159},
  shortjournal = {Comput. Commun.},
  title        = {Learning distributed communication and computation in the IoT},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Moving target defense controller of mobile system based on
openflow sensor security scheme. <em>COMCOM</em>, <em>161</em>, 142–149.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a sensor security and defense scheme based on Openflow in mobile Internet of Things system. Adopting the flexible network characteristics of the Openflow network structure, at the network level of the mobile internet of things system, the goal of protecting the sensor devices, routers, switches and other devices in the mobile internet of things system is achieved by simultaneously carrying out the double random digital transformation of the network IP address and the data transmission ports of the cross-region Openflow exchange equipment through each sensor device in the mobile internet of things system and each router device in the data transmission process. Compared with the existing security defense technology of mobile IoT system, this technical solution is compatible and relatively easy to deploy, and can protect the whole system data transmission of mobile IOT system. In the initial stage of network system sniffing, such as hacker attack, the maximum extent of active security protection is provided to the mobile Internet of Things system carrying public network data by hiding sensor information.},
  archive      = {J_COMCOM},
  author       = {Xin Niu and Jiazhong Lu},
  doi          = {10.1016/j.comcom.2020.05.004},
  journal      = {Computer Communications},
  pages        = {142-149},
  shortjournal = {Comput. Commun.},
  title        = {Moving target defense controller of mobile system based on openflow sensor security scheme},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A staged adaptive firefly algorithm for UAV charging
planning in wireless sensor networks. <em>COMCOM</em>, <em>161</em>,
132–141. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A staged adaptive firefly algorithm (SAFA) is proposed in this paper. Firstly, the attraction model is improved to promote the convergence of the algorithm in the case of small algorithm complexity . Secondly, three adaptive adjustment functions of parameters are established according to the actual conditions of convergence and iteration. Because of the new attraction model, SAFA has better population diversity at the early stage of iteration and can carry out adaptive balance and adjustment of global and local optimization at the late stage of iteration. Because of three adaptive adjustment functions of parameters, SAFA has better randomness and non-repeatability of parameters, so it has stronger global convergence ability. To verify the performance, SAFA algorithm is compared with other four algorithms in testing six standard functions and unmanned aerial vehicle (UAV) charging path planning for wireless sensor network in this paper. A large number of experimental results show that the precision and convergence speed of SAFA is higher than that of the other four algorithms.},
  archive      = {J_COMCOM},
  author       = {Linhui Cheng and Luo Zhong and Xiao Zhang and Jiaxu Xing},
  doi          = {10.1016/j.comcom.2020.07.019},
  journal      = {Computer Communications},
  pages        = {132-141},
  shortjournal = {Comput. Commun.},
  title        = {A staged adaptive firefly algorithm for UAV charging planning in wireless sensor networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource provisioning for IoT services in the fog computing
environment: An autonomic approach. <em>COMCOM</em>, <em>161</em>,
109–131. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent years, the Internet of Things (IoT) services has been increasingly applied to promote the quality of the human life and this trend is predicted to stretch for into future. With the recent advancements in IoT technology, fog computing is emerging as a distributed computing model to support IoT functionality. Since the IoT services will experience workload fluctuations over time, it is important to automatically provide the proper number of sufficient fog resources to address the workload changes of IoT services to avoid the over- or under-provisioning problems, meeting the QoS requirements at the same time. In this paper, an efficient resource provisioning approach is presented. This approach is inspired by autonomic computing model using Bayesian learning technique to make decisions about the increase and decrease in the dynamic scaling fog resources to accommodate the workload from IoT services in the fog computing environment. Also, we design an autonomous resource provisioning framework based on the generic fog environment three-tier architecture. Finally, we validate the effectiveness of our solution under three workload traces. The simulation results indicate that the proposed solution reduces the total cost and delay violation, and increases the fog node utilization compared with the other methods.},
  archive      = {J_COMCOM},
  author       = {Masoumeh Etemadi and Mostafa Ghobaei-Arani and Ali Shahidinejad},
  doi          = {10.1016/j.comcom.2020.07.028},
  journal      = {Computer Communications},
  pages        = {109-131},
  shortjournal = {Comput. Commun.},
  title        = {Resource provisioning for IoT services in the fog computing environment: An autonomic approach},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ProgLab: Programmable labels for QoS provisioning on
software defined networks. <em>COMCOM</em>, <em>161</em>, 99–108. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the quality of service of an end-to-end connection, current network solutions are mostly dependable on the differentiation between different classes of traffic. The Software-defined networking (SDN) architecture has emerged to offer network programmability , giving to network operators a programmatic control over their network. In SDN, network devices are programmed in many ways, having a standard, open, and vendor-agnostic interface, e.g., OpenFlow , enabling the control plane to instruct the forwarding behavior of network devices from different vendors. In this paper, we introduce the Programmable Labels (ProgLab) approach to support traffic differentiation with QoS guarantees as a low-cost alternative built over an SDN architecture. The idea relies on the simplification of a packet-forwarding operation which relies on the remainder of a division, instead of classical table lookup method. ProgLab computes programmable label at the control plane by solving a congruence system from Residue Number System and the co-prime numbers assigned to the switches in the path of an end-to-end connection. Such label has a meaning within this network that expresses the entire route, addressing the respective traffic class at each switch’s logical queue along the path. ProgLab approach has been implemented through the P4 language and evaluated through an emulation-based evaluation. The experiments demonstrated the feasibility of ProgLab and showed its ability in providing QoS differentiation on demand.},
  archive      = {J_COMCOM},
  author       = {Wallas Froes and Lucas Santos and Leobino N. Sampaio and Magnos Martinello and Alextian Liberato and Rodolfo S. Villaca},
  doi          = {10.1016/j.comcom.2020.07.026},
  journal      = {Computer Communications},
  pages        = {99-108},
  shortjournal = {Comput. Commun.},
  title        = {ProgLab: Programmable labels for QoS provisioning on software defined networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benchmarking open source NFV MANO systems: OSM and ONAP.
<em>COMCOM</em>, <em>161</em>, 86–98. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing trend in softwarization and virtualization of network functions and systems, NFV management and orchestration (MANO) solutions are being developed to meet the agile and flexible management requirements of virtualized network services in the 5G era and beyond. In this regard, ETSI ISG NFV has specified a standard MANO system that is used as a reference by vendors as well as open-source MANO projects. These MANO systems are inherently very complex and have a direct impact on the overall performance of NFV systems. However, unlike traditional networking functions and systems, there are no well-defined test methods and KPIs based on which the performance of the NFV-MANO system can be tested, validated and benchmarked. Given the absence of formal MANO specific evaluation techniques based on which the performance and features of a MANO system can be quantified, and compared against, we introduce in this paper a formal benchmarking methodology and KPIs for MANO systems. For illustration purposes, we analyze and compare the performance of the two most popular open-source NFV MANO projects, namely ONAP and OSM, using a complex open-source virtual customer premises equipment (vCPE) VNF. Our results show the current features support, performance to be expected and gaps to be covered in future releases.},
  archive      = {J_COMCOM},
  author       = {Girma M. Yilma and Zarrar F. Yousaf and Vincenzo Sciancalepore and Xavier Costa-Perez},
  doi          = {10.1016/j.comcom.2020.07.013},
  journal      = {Computer Communications},
  pages        = {86-98},
  shortjournal = {Comput. Commun.},
  title        = {Benchmarking open source NFV MANO systems: OSM and ONAP},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient unmanned aerial vehicle scanning approach
with node clustering in opportunistic networks. <em>COMCOM</em>,
<em>161</em>, 76–85. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The opportunistic networks are challenging due to their inherent characteristics of intermittent and unreliable communication between nodes. In order to alleviate the communication issues, the unmanned aerial vehicles (UAVs) can be used for delivering packets within the opportunistic networks . This paper investigates how to leverage the UAVs in Unmanned Aerial Vehicle aided Opportunistic Networks (UAON). The UAVs are considered responsible for relaying the messages generated by the nodes on the ground. The simulation study is conducted on the real-world datasets of the nodes moving around Orlando and Korea Advanced Institute of Science &amp; Technology (KAIST). Our proposed approach, State-based Campus Routing (SCR) with Density-based spatial clustering of applications with noise (DBSCAN), meander, random, and random spiral scanning approaches, as well as SCR and Epidemic protocols without UAV usage, have been evaluated on both datasets. The simulation metrics included the success rate, the message delay, the number of packets sent, and the distance traveled by the UAVs. SCR with DBSCAN and meander scan approaches were also tested with two UAVs using the Orlando dataset. Furthermore, spiral density and message creation frequency parameters were evaluated for SCR with DBSCAN protocol on North Carolina State University (NCSU) dataset. The simulation results showed improvements in terms of message delay and success rate when the UAVs were used in an opportunistic network setting. The proposed approach showed around 12\% less total number of packets sent by the UAVs and the nodes. Similarly, the message delay distributions of the SCR with the DBSCAN achieve 90\% of the message delay results, whereas the message delay distributions of random scanning form only 70\% in less than an hour.},
  archive      = {J_COMCOM},
  author       = {Salih Safa Bacanli and Damla Turgut},
  doi          = {10.1016/j.comcom.2020.07.010},
  journal      = {Computer Communications},
  pages        = {76-85},
  shortjournal = {Comput. Commun.},
  title        = {Energy-efficient unmanned aerial vehicle scanning approach with node clustering in opportunistic networks},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Are mobility management solutions ready for 5G and beyond?
<em>COMCOM</em>, <em>161</em>, 50–75. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabling users to move to different geographical locations within a network and still be able to maintain their connectivity and most essentially, continuity of service, is what makes any wireless network ubiquitous. Whilst challenging, modern day wireless networks, such as 3GPP-LTE, provision satisfactory mobility management (MM) performance. However, it is estimated that the number of mobile subscriptions will approximately touch 9 billion and the amount of data traffic will expand by 5 times in 2024 as compared to 2018. Further, it is expected that this trend of exponential growth will be maintained well into the future. To cope with such an exponential increase in cellular traffic and users alongside a burgeoning demand for higher Quality of Service (QoS), the future networks are expected to be highly dense and heterogeneous. This will severely challenge the existing MM solutions and ultimately render them ineffective as they will not be able to provide the required reliability, flexibility, and scalability. Consequently, to serve the 5G and beyond 5G networks, a new perspective to MM is required. Hence, in this article we present a novel discussion of the functional requirements from MM strategies for these networks. We then provide a detailed discussion on whether the existing mechanisms conceived by standardization bodies such as IEEE, IETF, 3GPP (including the newly defined 5G standards) and ITU, and other academic and industrial research efforts meet these requirements. We accomplish this via a novel qualitative assessment, wherein we evaluate each of the discussed mechanisms on their ability to satisfy the reliability, flexibility and scalability criteria for future MM strategies. We then present a study detailing the research challenges that exist in the design and implementation of MM strategies for 5G and beyond networks. Further, we chart out the potential MM solutions and the associated capabilities they offer to tackle the persistent challenges. We conclude this paper with a vision for the 5G and beyond MM mechanisms.},
  archive      = {J_COMCOM},
  author       = {Akshay Jain and Elena Lopez-Aguilera and Ilker Demirkol},
  doi          = {10.1016/j.comcom.2020.07.016},
  journal      = {Computer Communications},
  pages        = {50-75},
  shortjournal = {Comput. Commun.},
  title        = {Are mobility management solutions ready for 5G and beyond?},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliable uplink transmissions for NOMA-based industrial
wireless networks with guaranteed real-time performance.
<em>COMCOM</em>, <em>161</em>, 41–49. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability is vital for ultra-reliability low-latency transmission applications in Industrial Wireless Networks (IWNs). The power-domain Non-Orthogonal Multiple Access (NOMA) technology can support multiple parallel transmissions, and has been thought of as one of the most powerful candidate radio access technology for the next-generation IWNs. However, it suffers from low transmission reliability because of the high interferences caused by parallel transmissions in power-domain NOMA. In this paper, given the real-time performance requirements, we consider a single-hop network supporting 2-Successive Interference Cancellation, and study how to maximize the reliabilities of uplink transmissions by the joint user pairing and power allocation . We show that the problem is solvable in polynomial time by an optimal algorithm with complexity of O ( n l o g n ) O(nlogn) , where n n is the number of users. The performance evaluations reveal that the transmission reliabilities will increase exponentially with the linear degradation of the guaranteed real-time performance.},
  archive      = {J_COMCOM},
  author       = {Chaonong Xu and Jianxiong Wu and Chao Li},
  doi          = {10.1016/j.comcom.2020.07.023},
  journal      = {Computer Communications},
  pages        = {41-49},
  shortjournal = {Comput. Commun.},
  title        = {Reliable uplink transmissions for NOMA-based industrial wireless networks with guaranteed real-time performance},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BSV-PAGS: Blockchain-based special vehicles priority access
guarantee scheme. <em>COMCOM</em>, <em>161</em>, 28–40. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic jams often occur, with the increasing number of private cars. Special vehicles (e.g. police cars, ambulances and fire trucks) often encounter traffic jams when carrying out emergency tasks, which may lead to unexpected consequences (e.g. causing serious damage to our routine and property). In order to ensure that special vehicles can quickly pass through crowded road and arrive at the accident scene in time, this paper proposes a blockchain-based special vehicles priority access guarantee scheme (BSV-PAGS). In BSV-PAGS, we introduce blockchain into the Internet of Things (IoT), and construct a decentralized distributed edge node network based on blockchian, which guarantees the information sharing among the edge nodes as well as processing the data efficiently. The intelligent terminal device will upload the special vehicle information to the edge node in the blockchain , and then the uploaded information will sync to each edge node through the information sharing smart contract , realizing the information sharing among the edge nodes. In addition, we use machine learning method (e.g. Bag of Visual Words and Support Vector Machine) to design and train special vehicle detectors to improve the recognition accuracy of special vehicles. We design a special vehicle priority access smart contract to achieve real-time scheduling of vehicles and ultimately ensure the priority of special vehicles. Then, we carried out a security analysis of BSV-PAGS. Finally, we test a large number of simulation experiments based on Ethereum clients. The experimental results show that our scheme is feasible and effective.},
  archive      = {J_COMCOM},
  author       = {Yue Wang and Jiguo Yu and Biwei Yan and Guijuan Wang and Zhiguang Shan},
  doi          = {10.1016/j.comcom.2020.07.012},
  journal      = {Computer Communications},
  pages        = {28-40},
  shortjournal = {Comput. Commun.},
  title        = {BSV-PAGS: Blockchain-based special vehicles priority access guarantee scheme},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of collaborative resource allocation for mobile
edge computing. <em>COMCOM</em>, <em>161</em>, 19–27. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to realize the collaborative resource allocation optimization of mobile edge computing (MEC) and reduce the delay of edge server in the transmission process, based on software-defined network (SDN) technology, two optimal edge server deployment schemes of Enumeration-Based Optimal Edge Server Placement Algorithm (EOESPA) and Ranking-based Near-optimal Edge Server Placement Algorithm (RNOESPA) are proposed. Performance comparison experiment simulation is conducted with K-Means cluster algorithm (KMCA) to verify the minimum access delay of edge server under different conditions. After the deployment of edge servers, three collaborative resource allocation optimization algorithms of Optimal Enumeration Service Deployment Algorithm (OESDA), Latency Aware Heuristic Service Deployment Algorithm (LAHSDA), and Clustering Enhanced Heuristic Service Deployment Algorithm (CEHSDA) are proposed, and simulation experiments are carried out to verify the performance of the proposed algorithm under different conditions. The results show that, under different conditions, when the number of deployments increases from 1 to 4, the average access delay of EOESPA can be at least 1ms, and the average access delay obtained by RNOESPA is close to the best performance obtained by EOESPA and better than that obtained by KMCA. When the number of network nodes increases to 50, the minimum average access delay obtained by RNOESPA is closer to the optimal value, which is about 1.42ms. The same performance is shown in relation to the average number of requests, the number of mobile devices , and the average access delay. Among the three collaborative resource allocation optimization algorithms , the minimum average response delay obtained by LAHSDA is close to the optimal average response delay obtained by OESDA, but all of them are lower than CEHSDA, and CEHSDA has the best performance in minimizing the total allocation cost. When the number of service types increases to 8, the total service configuration cost of CEHSDA is about 0.89. It can be concluded that by optimizing the deployment of the edge server, the collaborative optimal allocation of its resources can be realized.},
  archive      = {J_COMCOM},
  author       = {Zhihan Lv and Liang Qiao},
  doi          = {10.1016/j.comcom.2020.07.022},
  journal      = {Computer Communications},
  pages        = {19-27},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of collaborative resource allocation for mobile edge computing},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep robust cramer shoup delay optimized fully homomorphic
for IIOT secured transmission in cloud computing. <em>COMCOM</em>,
<em>161</em>, 10–18. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several sensors obtain data during industrial outturn and send this collected data to the cloud server via Internet communication. Due to the reason that a cloud server is not an entirely trusted entity, data authenticity has to be provided prior to outsource to the cloud server, so that only authorized users or devices can access those authentic data from distinct topography areas. Hence, a strong privacy preservation mechanism is required during data collection. In addition, the data latency and network delay involved in communication should also be observed. In order to robust privacy preservation , Robust Cramer Shoup Delay Optimized Fully Homomorphic (RCS-DOFH) is proposed. This method includes three steps. First to minimize the communication overhead and time, Kullback–Leibler divergence is used in the Robust Cramer Shoup Decryption (RCSD) mechanism. Next, to minimize the data latency and network delay, Delay Optimized Fully Homomorphic Encryption (DOFHE) mechanism is designed. In this mechanism, delivery delay is calculated between the base station and IIoT device signal Finally, privacy preserving deep learning using RCSD and DOFHE is presented for privacy preserved secure data transmission. At first, RCSD mechanism is utilized to decrypt private generated signals along with its weight parameters. Then, the encryption is performed by using DOFHE mechanism. After that, activation function over the encryption region is determined. By this way, the proposed RCS-DOFH method achieves secure data transmission with minimum latency and network delay. The comparison of the RCS-DOFH method is provided and experiments conducted on SECOM dataset showed that the proposed method outperforms other conventional methods.},
  archive      = {J_COMCOM},
  author       = {Qizhong Li and Yizheng Yue and Zhongqi Wang},
  doi          = {10.1016/j.comcom.2020.06.017},
  journal      = {Computer Communications},
  pages        = {10-18},
  shortjournal = {Comput. Commun.},
  title        = {Deep robust cramer shoup delay optimized fully homomorphic for IIOT secured transmission in cloud computing},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cognitive model to predict human interest in smart
environments. <em>COMCOM</em>, <em>161</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the idea of smart cities has made several strides forward in literature. Work has hypothesize that the combination of Artificial Intelligence , Cloud Computing , and High powered computers will make technology more human-centric, even, the idea that smart cities will be able to understand the thought process of a human being seems very much likely today. This paper is along this line of thought. In particular, we try to present a method to model the cognitive state of human interest . This is done to take one more step towards the realization of a smart cognitive city. An approach which is Subjective–Objective in nature is presented to model the computation of activity inspired by interest. Based on activity, human latent state values are indirectly deduced. Inspiration is drawn from Physics and interest is modeled upon the Ornstein–Uhlenbeck (OU) process. Concepts of Adaptive filtering are used to formulate an evolving transformation function that automatically and adaptively models the conversion of interest into activity. Particle filter is employed to provide an elucidation which is computationally feasible. To validate the viability of the method, experimentation is performed with real datasets.},
  archive      = {J_COMCOM},
  author       = {Tanveer Ahmed and Rishav Singh and Anil K. Pandey and Sanjay K. Singh},
  doi          = {10.1016/j.comcom.2020.07.007},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {A cognitive model to predict human interest in smart environments},
  volume       = {161},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum to “performance optimization of IoT based
biological systems using deep learning” [computer communications 155
(2020) 24–31]. <em>COMCOM</em>, <em>160</em>, 863. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Omer Irshad and Muhammad Usman Ghani Khan and Razi Iqbal and Shakila Basheer and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2020.08.004},
  journal      = {Computer Communications},
  pages        = {863},
  shortjournal = {Comput. Commun.},
  title        = {Corrigendum to “Performance optimization of IoT based biological systems using deep learning” [Computer communications 155 (2020) 24–31]},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on data distribution in industrial and
pervasive internet. <em>COMCOM</em>, <em>160</em>, 860–862. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Theofanis P. Raptis and Georgios Z. Papadopoulos and Archan Misra and Salil S. Kanhere},
  doi          = {10.1016/j.comcom.2020.08.003},
  journal      = {Computer Communications},
  pages        = {860-862},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on data distribution in industrial and pervasive internet},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on mobile information centric networking.
<em>COMCOM</em>, <em>160</em>, 858–859. (<a
href="https://doi.org/10.1016/j.comcom.2020.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Carlos T. Calafate and Chaker Abdelaziz Kerrache and Marica Amadeo and Yusheng Ji and Syed Hassan Ahmed},
  doi          = {10.1016/j.comcom.2020.08.002},
  journal      = {Computer Communications},
  pages        = {858-859},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on mobile information centric networking},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel control topology with obstacle detection using
RDPSO–GBA in mobile AD-HOC network. <em>COMCOM</em>, <em>160</em>,
847–857. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MANET plays an irreplaceable task by providing quality aware broadcast routing technique for small infrastructure-less field of application. Depending upon arising interference, transmission power of individual node can be done by Ant Colony Optimization (ACO) algorithm. In addition, nodes probability link connectivity is estimated by using Bayesian pursuit (BPST) algorithm that determines probability to control adjustment in nodes power. In this paper, proposed to control topology with obstacle detection using RDPSO–GBA (Robotic Darwin Particle Swarm Optimization–Graph Based Algorithm) in mobile ad hoc network. The robotics DPSO is to be represented with the help of the multiple swarms of various testing results when each swarm particularly operates an ordinary PSO method with various set of rules which are governing the gather of swarms. In the graph based algorithm, the nodes are to be presented in the MANET which has been separated into the two various classes that is leaders and the followers. The leader has the base node and the explorer node and the follower has the autonomous robots which provide the communication broadcasting. The simulation and result shows that there is the analysis of the various performances which is compared with conventional methods.},
  archive      = {J_COMCOM},
  author       = {R. Vinoba and M. Vijayaraj},
  doi          = {10.1016/j.comcom.2020.03.002},
  journal      = {Computer Communications},
  pages        = {847-857},
  shortjournal = {Comput. Commun.},
  title        = {Novel control topology with obstacle detection using RDPSO–GBA in mobile AD-HOC network},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security definitions, entropy measures and constructions for
implicitly detecting data corruption. <em>COMCOM</em>, <em>160</em>,
815–846. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss security definitions, entropy measures and cryptographic constructions associated with the recently proposed implicit data integrity methodology. Such methodology is applied in order to detect data corruption without producing, storing or verifying mathematical summaries of the content such as Message Authentication Codes (MACs) or checksums. The main idea is that, whereas typical user data demonstrate patterns such as repeated bytes or words, decrypted data resulting from corrupted ciphertexts no longer demonstrate such patterns. Thus, by checking the entropy of decrypted ciphertexts , corruption can be possibly detected. The paper expands on earlier contributions, arguing for the need of a new notion of security based on the assumption that it is computationally difficult for an adversary to corrupt some ciphertext so that the resulting plaintext demonstrates specific patterns. A second contribution of the paper is a proposal for a new entropy measure that is applicable to short messages. The entropy measure we propose is called “pattern entropy index” and can be efficiently computed for messages that can be as small as 64 bytes. Third, we extend the security analysis of the known cryptographic construction called IVP (Integrity Via Preprocessing). We show that IVP supports implicit data integrity and is secure in input perturbing and oracle replacing adversary models . The cryptographic strength of IVP is 32.169 bits, which is sufficient for defending against online data corruption and content replay attacks. Computationally, IVP is much lighter than other authenticated encryption approaches requiring only two additional encryption rounds in the critical path of a 128-bit block cipher such as AES .},
  archive      = {J_COMCOM},
  author       = {Michael Kounavis and David Durham and Sergej Deutsch and Ken Grewal},
  doi          = {10.1016/j.comcom.2020.05.022},
  journal      = {Computer Communications},
  pages        = {815-846},
  shortjournal = {Comput. Commun.},
  title        = {Security definitions, entropy measures and constructions for implicitly detecting data corruption},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved migration scheme to achieve the optimal service
time for the active jobs in 5G cloud environment. <em>COMCOM</em>,
<em>160</em>, 807–814. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the emerging technologies, cloud computing plays a vital role in the current business world. Through its various deployment models ‘n’ number of vendors of the IT industry utilizes cloud computing to achieve their business deals. Though the usage of cloud increases day by day, there are some major challenges in the cloud computing such as load balancing issues, device utilization and energy optimization . In this paper, load balancing issues are addressed through the proposed Server Distinction based on the Corresponding Active Weights of the Jobs (SDCAW) algorithm. The proposed algorithm concentrates on the live migration of the active jobs among the virtual machines in the cloud environment. The algorithm itself contains an instruction queue where the active jobs are stored and scheduled based on the procedure. Many existing systems concentrated only on migration of non-active jobs in the cloud environment. The proposed algorithm has been compared with the existing systems and produces optimal solution for the cloud environment by minimizing the makespan of the environment.},
  archive      = {J_COMCOM},
  author       = {M. Vinoth Kumar and R. Saravana Ram and Saravana Balaji B. and B. Amutha and M. Kowsigan},
  doi          = {10.1016/j.comcom.2020.06.014},
  journal      = {Computer Communications},
  pages        = {807-814},
  shortjournal = {Comput. Commun.},
  title        = {An improved migration scheme to achieve the optimal service time for the active jobs in 5G cloud environment},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vehicle communication network in intelligent transportation
system based on internet of things. <em>COMCOM</em>, <em>160</em>,
799–806. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of modern cities, relatively backward traffic management methods, inadequate road planning and construction, and the surge in car ownership, the problem of “urban traffic congestion” has become a problem faced by modern urban management. Intelligent Transportation System (ITS) is gradually becoming the research direction for solving the problem of traffic congestion in various countries around the world. Based on the above background, the purpose of this article is to study the vehicle communication network in the intelligent transportation system based on the Internet of Things . This paper uses OPNET Modeler software to build a vehicle movement model. OPNET Modeler uses a layered network simulation method. From the perspective of the protocol, the node module complies with the OSI standard of the open system interconnection model . From bottom to top, it is the physical layer , MAC layer, ARP layer, IP encapsulation layer, IP layer, TCP layer, and service layer. In a multi-hop scenario of vehicle self-organizing network in an intelligent transportation system based on the Internet of Things , simulation experiments show that when the vehicle is running at low speed, the wireless network coverage problem of the vehicle self-organizing network on the ground, especially In terms of the design and configuration of the roadside unit, the distance of the roadside unit should be maintained between 500 m and 600 m. At this time, the overall performance of the vehicle self-organizing network is stable. AODV protocol is superior to DSR protocol in terms of throughput, average network delay, routing load, packet loss rate , and average routing hops, and is more suitable for network communication needs.},
  archive      = {J_COMCOM},
  author       = {Hong Zhang and Xinxin Lu},
  doi          = {10.1016/j.comcom.2020.03.041},
  journal      = {Computer Communications},
  pages        = {799-806},
  shortjournal = {Comput. Commun.},
  title        = {Vehicle communication network in intelligent transportation system based on internet of things},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mobile fog computing security: A user-oriented smart attack
defense strategy based on DQL. <em>COMCOM</em>, <em>160</em>, 790–798.
(<a href="https://doi.org/10.1016/j.comcom.2020.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each fog node interacts with data from multiple end-users in mobile fog computing (MFC) networks. Malicious users can use a variety of programmable wireless devices to launch different modes of smart attacks such as impersonation attack, jamming attack, and eavesdropping attack between fog servers and legitimate users. The existing research in MFC lacks in the contributions of defense of smart attack and also requires in the discussions of subjective decision making by participants. Therefore, we propose a smart attack defense scheme for authorized users in MFC in this paper. First, we construct a static zero-sum game model between smart attackers and legitimate users based on prospect theory. Second, the double Q-learning (DQL) is proposed to restrain the attack motive of smart attackers in the dynamic environment. The proposed DQL method generates the optimum defense choice of legitimate users against smart attacks so that they can efficiently determine whether to use only physical layer security (PLS) to avoid those smart attacks. We use our scheme to contrast with the basic schemes, i.e., Q-learning scheme, the Sarsa scheme, and the greedy strategy . Experiment results prove that the proposed scheme can enhance the utility of legitimate users, restrain the attack motive of smart attackers, and further provide better security protection in the MFC environment.},
  archive      = {J_COMCOM},
  author       = {Shanshan Tu and Muhammad Waqas and Yuan Meng and Sadaqat Ur Rehman and Iftekhar Ahmad and Anis Koubaa and Zahid Halim and Muhammad Hanif and Chin-Chen Chang and Chengjie Shi},
  doi          = {10.1016/j.comcom.2020.06.019},
  journal      = {Computer Communications},
  pages        = {790-798},
  shortjournal = {Comput. Commun.},
  title        = {Mobile fog computing security: A user-oriented smart attack defense strategy based on DQL},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A knowledge-based query tree with shortcutting and
couple-resolution for RFID tag identification. <em>COMCOM</em>,
<em>160</em>, 779–789. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Radio Frequency Identification (RFID) systems, the reader identifies tags through communications over a shared wireless channel. However, when multiple tags transmit their IDs simultaneously, their signals collide, thereby prolonging the identification delay. However, in some applications, the RFID system has the availability of a database containing the IDs of all the tags that may possibly appear. The present study proposes a novel knowledge-based Query Tree with Shortcutting and Couple Resolution (QTSC) protocol for reducing the identification delay in RFID systems with such a database. In the proposed protocol, a knowledge-based query tree is first constructed to store the queries required to identify all the possible tags in the database. Then, at identifying appearing tags, the tags actually appear among possible tags, shortcutting and couple-resolution techniques are employed to skip redundant queries in the query tree and transmit two ID prefixes simultaneously within the same slot, respectively. The simulation results show that compared to the existing knowledge-based protocols, Knowledge Query Tree (KQT) and Heuristic Query Tree (HQT) protocols, QTSC reduces the identification delay by 60.5\% and 39.0\%, respectively.},
  archive      = {J_COMCOM},
  author       = {Zelalem Legese Hailemariam and Yuan-Cheng Lai and Riyanto Jayadi and Yen-Hung Chen and Sheng-Chi Huang},
  doi          = {10.1016/j.comcom.2020.06.025},
  journal      = {Computer Communications},
  pages        = {779-789},
  shortjournal = {Comput. Commun.},
  title        = {A knowledge-based query tree with shortcutting and couple-resolution for RFID tag identification},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An architecture for adaptive task planning in support of
IoT-based machine learning applications for disaster scenarios.
<em>COMCOM</em>, <em>160</em>, 769–778. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of the Internet of Things (IoT) in conjunction with edge computing has recently opened up several possibilities for several new applications. Typical examples are Unmanned Aerial Vehicles (UAV) that are deployed for rapid disaster response, photogrammetry, surveillance, and environmental monitoring. To support the flourishing development of Machine Learning assisted applications across all these networked applications, a common challenge is the provision of a persistent service, i.e., a service capable of consistently maintaining a high level of performance, facing possible failures. To address these service resilient challenges, we propose APRON , an edge solution for distributed and adaptive task planning management in a network of IoT devices, e.g., drones. Exploiting Jackson’s network model, our architecture applies a novel planning strategy to better support control and monitoring operations while the states of the network evolve. To demonstrate the functionalities of our architecture, we also implemented a deep-learning based audio-recognition application using the APRON NorthBound interface, to detect human voices in challenged networks. The application’s logic uses Transfer Learning to improve the audio classification accuracy and the runtime of the UAV-based rescue operations.},
  archive      = {J_COMCOM},
  author       = {Alessio Sacco and Matteo Flocco and Flavio Esposito and Guido Marchetto},
  doi          = {10.1016/j.comcom.2020.07.011},
  journal      = {Computer Communications},
  pages        = {769-778},
  shortjournal = {Comput. Commun.},
  title        = {An architecture for adaptive task planning in support of IoT-based machine learning applications for disaster scenarios},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A joint optimization scheme for task offloading and resource
allocation based on edge computing in 5G communication networks.
<em>COMCOM</em>, <em>160</em>, 759–768. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of 5G communication networks and the popularization of intelligent terminals, the computing resource intensive characteristic of various new applications poses a severe challenge to the task processing ability of intelligent terminals. In order to improve the efficiency of task processing, a joint optimization scheme for task offloading and resource allocation based on edge computing in 5G communication networks is proposed. Firstly, combining edge computing and Device-to-Device communication technologies, we propose three modes for processing computationally intensive tasks based on multi-user network system model for 5G edge networks, including local computing, fog node computing, edge node computing. Then, the corresponding time delay model, task execution model and offloading energy consumption computing model are constructed for these three computing modes. Finally, the problem of computing task offloading is transformed into a joint optimization problem of time delay and energy consumption, including optimization problems such as CPU frequency, offloading decision, transmission bandwidth allocation and power allocation of offloading users. Besides, the interior point method is utilized to solve this problem. Simulation platform is used to demonstrate the performance of our proposed scheme. The experimental results show that the scheme can effectively reduce the time delay and energy consumption of terminal tasks, which improves the efficiency of task processing and the experience quality of end users.},
  archive      = {J_COMCOM},
  author       = {Shi Yang},
  doi          = {10.1016/j.comcom.2020.07.008},
  journal      = {Computer Communications},
  pages        = {759-768},
  shortjournal = {Comput. Commun.},
  title        = {A joint optimization scheme for task offloading and resource allocation based on edge computing in 5G communication networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 6G technology based advanced virtual multi-purpose embedding
algorithm to solve far-reaching network effects. <em>COMCOM</em>,
<em>160</em>, 749–758. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, network virtualization is an essential technology that aims to resolve shortcomings including network ossification of the current design of the Internet. The Internet’s tremendous success have adopted digital business growth and increased competition for bandwidth in communication. Ultra-high-definition videos and vehicle systems require rapid bandwidth rates and increase network connection capacity, respectively. The rapid advancement of network virtualization and 6G technologies is driven by high bandwidth and high speed parallel communication. This innovation often introduces new link allocation problems to existing substrate networks in a network virtualization environment. In order to solve this far-reaching network effects, this paper proposes an Advanced Virtual Multi-Purpose Network Embedding Algorithm (AVMPNEA) through the fuzzy C-mean clustering, which is a learning algorithm. The clustering integrally evaluates the topological node structure, the latency and the related bandwidth between the nodes. The Nodes that enhance the longevity are used for selected mapping. The experimental result shows that the proposed AVMPNEA is outperformed in comparison with other traditional methods with high throughput , low latency and reduced energy consumption. Hence, it improves the throughput and the long-term application support.},
  archive      = {J_COMCOM},
  author       = {Aldosary Saad and Mohammed Al-Ma’aitah and Ayed Alwadain},
  doi          = {10.1016/j.comcom.2020.07.025},
  journal      = {Computer Communications},
  pages        = {749-758},
  shortjournal = {Comput. Commun.},
  title        = {6G technology based advanced virtual multi-purpose embedding algorithm to solve far-reaching network effects},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Target detection in SAR images using bayesian saliency and
morphological attribute profiles. <em>COMCOM</em>, <em>160</em>,
738–748. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Synthetic Aperture Radar (SAR) images have become a considerable and vital application in the optical satellite images due to their ability of function in all kinds of weather situations. In synthetic aperture radar (SAR) images Target detection is a demanding task to check presence of targets in images and to exactly locate that target. This paper propose a process for the detection of automatic target in SAR images which has three different steps, that is super pixel segmentation , Morphological attribute profiles and Bayesian Saliency Map. In first stage the SAR input image is then segmented into small regions by super pixels after that the clustering procedure is followed. In the second stage Bayesian saliency map is used to highpoint the clear objects including target and shadow. In the third stage the morphological attribute profile is used to suppress the shadow and highlight the target. The experiment results on MSTAR dataset are compared with some popular existing algorithms (Super pixel CFAR, local CFAR, PR, Global CFAR, MS, BS) which will proves that the proposed mechanism is effective and robust.},
  archive      = {J_COMCOM},
  author       = {A. Shakin Banu and P. Vasuki and S. Md Mansoor Roomi},
  doi          = {10.1016/j.comcom.2020.03.018},
  journal      = {Computer Communications},
  pages        = {738-748},
  shortjournal = {Comput. Commun.},
  title        = {Target detection in SAR images using bayesian saliency and morphological attribute profiles},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of the navigation system through the fusion of IMU
and wheeled encoders. <em>COMCOM</em>, <em>160</em>, 730–737. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots must autonomously navigate in structured environments. In this paper, we proposed a new navigation system for mobile robots, where lost-cost components were used to complete accurate navigation tasks . To accomplish the navigation task, we designed and validated a set of algorithms for obstacle avoidance and estimation of the robot pose. The proposed navigation system consists of three main modules: local occupancy map generation, extended Kalman filter (EKF)-based localization and modified obstacle avoidance algorithm. The system initially performed visual feature point tracking followed by feature point classification using an inverse perspective transformation for obstacle detection . When the estimated obstacle position is provided, a local obstacle avoidance algorithm is activated to generate motion commands for safe navigation . When the local occupancy map is generated, a modified artificial potential field based on boundary detection is developed for navigation through an indoor environment. Moreover, we proposed a strategy to localize a mobile robot using an IMU, a camera and wheel encoders. The EKF is adopted to reduce the sensor noise and bias. Experiments demonstrate that our navigation system is useful and can significantly benefit other reactive navigations.},
  archive      = {J_COMCOM},
  author       = {Shibing Yu and Zhen Jiang},
  doi          = {10.1016/j.comcom.2020.07.009},
  journal      = {Computer Communications},
  pages        = {730-737},
  shortjournal = {Comput. Commun.},
  title        = {Design of the navigation system through the fusion of IMU and wheeled encoders},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information processing in internet of things using big data
analytics. <em>COMCOM</em>, <em>160</em>, 718–729. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With innovation in persistent technologies, such as wearable sensor gadgets, sensor devices, and wireless ad-hoc communication networks connect everyday life things to the Internet, normally referred to as Internet of Things (IoT). IoT is observed as an active entity for design and development of smart and context awareness services and applications in the area of business, science and engineering discipline. These applications and services could vigorously respond to the surroundings transformation and users’ preference. Developing a scalable system for data analysis, processing and mining of enormous real world based datasets has turned into one of the demanding problems that faces both system research scholars and data management research scholars. Employing big data analytics with IoT technologies is one of the ways for handling the timely analyzing information (i.e., data, events) streams. In this paper, we propose an integrated approach that coalesce IoT systems with big data tools into a holistic platform for real-time and continuous data monitoring and processing. We propose Fog assisted IoT based Smart and real time healthcare information processing (SRHIP) system in which large amounts of data generated by IoT sensor devices are offloaded at Fog cloud form data analytics and processing with minimum delay. The processed data is then transferred to a centralized cloud system for further analysis and storage. In this work, we introduce a Fog-assisted model with big data environment for data analytic of real time data with remote monitoring and discuss our plan for evaluating its efficacy in terms of several performance metrics such as transmission cost, storage cost, accuracy, specificity, sensitivity and F-measure. The proposed SRHIP system needs less transmission cost of 40.10\% in comparison to SPPDA, 100\% fewer bytes are compromised in comparison to GCEDA. Our proposed system data size reduction of 60\% reduction due to proposed compression scheme in comparison to other benchmark strategies that offer 40\% of reduction.},
  archive      = {J_COMCOM},
  author       = {Chaomin Li},
  doi          = {10.1016/j.comcom.2020.06.020},
  journal      = {Computer Communications},
  pages        = {718-729},
  shortjournal = {Comput. Commun.},
  title        = {Information processing in internet of things using big data analytics},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep reinforcement learning-based resource allocation
strategy for energy harvesting-powered cognitive machine-to-machine
networks. <em>COMCOM</em>, <em>160</em>, 706–717. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine-to-Machine (M2M) communication is a promising technology that may realize the Internet of Things (IoTs) in future networks. However, due to the features of massive devices and concurrent access requirement, it will cause performance degradation and enormous energy consumption. Energy Harvesting-Powered Cognitive M2M Networks (EH-CMNs) as an attractive solution is capable of alleviating the escalating spectrum deficient to guarantee the Quality of Service (QoS) meanwhile decreasing the energy consumption to achieve Green Communication (GC) became an important research topic. In this paper, we investigate the resource allocation problem for EH-CMNs underlaying cellular uplinks. We aim to maximize the energy efficiency of EH-CMNs with consideration of the QoS of Human-to-Human (H2H) networks and the available energy in EH-devices. In view of the characteristic of EH-CMNs, we formulate the problem to be a decentralized Discrete-time and Finite-state Markov Decision Process (DFMDP), in which each device acts as agent and effectively learns from the environment to make allocation decision without the complete and global network information. Owing to the complexity of the problem, we propose a Deep Reinforcement Learning (DRL)-based algorithm to solve the problem. Numerical results validate that the proposed scheme outperforms other schemes in terms of average energy efficiency with an acceptable convergence speed.},
  archive      = {J_COMCOM},
  author       = {Yi-Han Xu and Yong-Bo Tian and Prosper Komla Searyoh and Gang Yu and Yueh-Tiam Yong},
  doi          = {10.1016/j.comcom.2020.07.015},
  journal      = {Computer Communications},
  pages        = {706-717},
  shortjournal = {Comput. Commun.},
  title        = {Deep reinforcement learning-based resource allocation strategy for energy harvesting-powered cognitive machine-to-machine networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDN orchestration to combat evolving cyber threats in
internet of medical things (IoMT). <em>COMCOM</em>, <em>160</em>,
697–705. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Medical Things (IoMT) is now worth a billion dollar market. While offering enormous benefit, the prevalent and open environment of IoMT ecosystem can be a potential target of varied evolving cyber threats and attacks. Further, extensive connectivity of IoMT devices and their dynamic massive heterogeneous communication can create a new attack surface for sophisticated multivector malware attacks. There is a dire need to protect the forthcoming IoMT industrial revolution from varied evolving cyber threats and attacks. The authors propose a hybrid DL-driven SDN-enabled IoMT framework leveraging Convolutional Neural Network (CNN) and Cuda Deep Neural Network Long Short Term Memory (cuDNNLSTM) for a timely and efficient detection of sophisticated multivector malware botnets . For comprehensive evaluation, a state-of-the-art IoMT dataset and standard performance metrics have been employed. For verification purpose, we compare our proposed framework with our constructed hybrid DL-driven architectures and benchmark algorithms. Our proposed technique outperforms in terms of detection accuracy and testing efficiency. Finally, we also perform 10-fold cross validation to utterly show unbiased results.},
  archive      = {J_COMCOM},
  author       = {Shahzana Liaqat and Adnan Akhunzada and Fatema Sabeen Shaikh and Athanasios Giannetsos and Mian Ahmad Jan},
  doi          = {10.1016/j.comcom.2020.07.006},
  journal      = {Computer Communications},
  pages        = {697-705},
  shortjournal = {Comput. Commun.},
  title        = {SDN orchestration to combat evolving cyber threats in internet of medical things (IoMT)},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HD video transmission of multi-rotor unmanned aerial vehicle
based on 5G cellular communication network. <em>COMCOM</em>,
<em>160</em>, 688–696. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In UAV (Unmanned Aerial Vehicle) mission scenarios for aerial reconnaissance and aerial photography, wireless video backhaul is one of the essential functions. In recent years, with the rapid development of UAV in the military and civilian fields, mobile high-quality video backhaul has become a trend. This paper analyzes the hardware structure and software architecture of the UAV HD video wireless transmission model. The overall model is described from three levels of hardware, software, and link interface , and its software architecture is analyzed. Aiming at the high-frequency and large-bandwidth transmission system under 5G small cells, the influence of new channel characteristics on physical layer parameters is analyzed, and the frame structure design parameters such as subcarrier spacing and cyclic prefix are optimized. Considering the low throughput rate in multi-hop wireless networks, this paper innovatively proposes a slide mode based on frame rate adjustment. The simulation results show that the revised throughput prediction value has higher accuracy than the traditional method, and the bit rate adjustment is timely and can maintain a certain stability. Combining the advantages of the high and low bit rate schemes, the continuous video transmission is maintained while providing higher quality.},
  archive      = {J_COMCOM},
  author       = {Qi Yang and Jong Hoon Yang},
  doi          = {10.1016/j.comcom.2020.07.024},
  journal      = {Computer Communications},
  pages        = {688-696},
  shortjournal = {Comput. Commun.},
  title        = {HD video transmission of multi-rotor unmanned aerial vehicle based on 5G cellular communication network},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The characteristics of rumor spreaders on twitter: A
quantitative analysis on real data. <em>COMCOM</em>, <em>160</em>,
674–687. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a dozen of rumors on Twitter to find new insights in user characteristics and macro patterns in the process of rumor spreading. The collection and curation of data has left us with 12 rumor datasets out of 56,852 tweets from 43,919 users. The analysis over data shows users with lower ratio of following-to-follower are more probable to spark the rumor diffusion while users with the higher ratio are those who keep the flame alive. Furthermore, most users participate in the process of rumor spreading only once which implies the nature of rumor spreading is not a recurrent activity. However, among those users who engage with multi posts, the extreme change of state from rumor spreader to anti-rumor spreader happens to users with higher ratio of following-to-follower. We discuss these findings by employing the theory of planned behavior. Finally, analyzing the process of rumor spreading at the macro level revealed the existence of two distinctive patterns. Further investigations showed the extent of time gap between the beginning of rumor and anti-rumor diffusion plays the major role in emerging of these patterns. This phenomenon is explained by the shift in subjective norm toward rumors on social media.},
  archive      = {J_COMCOM},
  author       = {Amirhosein Bodaghi and Jonice Oliveira},
  doi          = {10.1016/j.comcom.2020.07.017},
  journal      = {Computer Communications},
  pages        = {674-687},
  shortjournal = {Comput. Commun.},
  title        = {The characteristics of rumor spreaders on twitter: A quantitative analysis on real data},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection of algorithmically-generated domains: An
adversarial machine learning approach. <em>COMCOM</em>, <em>160</em>,
661–673. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain name detection techniques are widely used to detect Algorithmically Generated Domain names (AGD) applied by Botnets . A major difficulty with these algorithms is to detect those generated names which are meaningful. In this way, Command and Control (C2) servers are detected. Machine learning techniques have been of great use to generalize the attributes of the meaningful names, generated algorithmically. To resist such techniques, the distribution of characters is used as a basis to generate meaningful domain names. Such techniques are called adversarial attacks attempting to fool machine learning methods. However, our experiments with more than 252757 samples show that in addition to character distribution of domain names, randomness property and pronounceability attributes are of great use to detect such meaningful names. Using these additional attributes, we have been able to identify malicious domain names with an accuracy of 98.19\%.},
  archive      = {J_COMCOM},
  author       = {Mohammadhadi Alaeiyan and Saeed Parsa and Vinod P. and Mauro Conti},
  doi          = {10.1016/j.comcom.2020.04.033},
  journal      = {Computer Communications},
  pages        = {661-673},
  shortjournal = {Comput. Commun.},
  title        = {Detection of algorithmically-generated domains: An adversarial machine learning approach},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-performance flow classification using hybrid clusters
in software defined mobile edge computing. <em>COMCOM</em>,
<em>160</em>, 643–660. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Edge Computing (MEC) provides different storage and computing capabilities within the access range of mobile devices . This moderates the burden of offloading compute/storage-intensive processes of the mobile devices to the centralized cloud data centers . As a result, the network latency is reduced and the quality of service provided for the mobile end users is improved. Different applications benefit from the large-scale deployments of MEC servers. However, the considerable complexity of managing large scale deployments of the sheer number of applications for the millions of mobile devices is a challenge. Recently, Software Defined Networking (SDN) is leveraged to resolve the problem by providing unified and programmable interfaces for managing network devices. Most of the current SDN packet processing services are tightly dependent on the packet classification service. This primary service classifies any incoming packet based on matching a set of specific fields of its header against a flow table. Acceleration of this basic process considerably increases the performance of the SDN-based MEC. In this paper, the hierarchical tree algorithm, which is a packet classification method, is parallelized using popular platforms on a cluster of Graphics Processing Units (GPUs), a cluster of Central Processing Units (CPUs), and a hybrid cluster. The best scenario for the parallel implementation of this algorithm on the CPU cluster is that which combines OpenMP and MPI . In this case, the throughput of the classifier is 4.2 million packets per second (MPPS). On the GPU cluster, two different scenarios have been used. In the first scenario, the global memory is used to store the rules and the Hierarchical-trie of the classifier while in the second scenario we break the filter set in a way that the resulting Hierarchical-trie of each subset could be stored in the shared memory of GPU. According to the results, although the first GPU cluster scenario achieves a throughput of 29.19 MPPS and a speedup 58 times as great as the serial mode, the second scenario is 12 times faster due to using the shared memory. The best performance, however, belongs to the hybrid cluster mode. The hybrid cluster achieves a throughput of 30.59 which is 1.4 MPPS more than the GPU cluster.},
  archive      = {J_COMCOM},
  author       = {Mahdi Abbasi and Azad Shokrollahi and Mohammad R. Khosravi and Varun G. Menon},
  doi          = {10.1016/j.comcom.2020.07.002},
  journal      = {Computer Communications},
  pages        = {643-660},
  shortjournal = {Comput. Commun.},
  title        = {High-performance flow classification using hybrid clusters in software defined mobile edge computing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fog computing based hybrid deep learning framework in
effective inspection system for smart manufacturing. <em>COMCOM</em>,
<em>160</em>, 636–642. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most sensors have been taken up, which resulted in a massive data size, with the continuously growing IoT (Internet of Things) devices and communications infrastructure in development. The inspection of the manufacturer to identify product defects is one of the most common examples. In order to develop an effective inspection system with greater precision, this paper has been proposed a Fog Computing based Hybrid Deep-Learning Framework (FC-HDLF), that can find possible defective products. Since a large number of assembly lines can occur in a single factory, one of the main problems is how these data are processed in real-time. The system can handle incredibly large amounts of data by discharging the load from the central servers to the fog nodes. In this paper, there are two obvious advantages. Next, the Convolutional Neural Network (CNN) model is adapted to the fog computing environment, which improves its calculation performance considerably. The other is that a model of control is built that can display the form and extent of the defect simultaneously. A decision-making framework for multi-agents is built to ensure a production process architecture to optimize production processes.},
  archive      = {J_COMCOM},
  author       = {Shih-Yang Lin and Yun Du and Po-Chang Ko and Tzu-Jung Wu and Ping-Tsan Ho and V. Sivakumar and Rama subbareddy},
  doi          = {10.1016/j.comcom.2020.05.044},
  journal      = {Computer Communications},
  pages        = {636-642},
  shortjournal = {Comput. Commun.},
  title        = {Fog computing based hybrid deep learning framework in effective inspection system for smart manufacturing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NMTLAT: A new robust mobile multi-target localization and
tracking scheme in marine search and rescue wireless sensor networks
under byzantine attack. <em>COMCOM</em>, <em>160</em>, 623–635. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After a shipwreck (ship collision, explosion, disappearance, etc.), people rely on the marine search and rescue wireless sensor networks (MSR-WSNs) as one key weapon to locate and track drowning targets to save lives and assets. However, due to the complex and dynamic ocean environment, marine sensors could be captured by malicious attackers and then become Byzantine sensors. Byzantine sensors may tamper with the actual sensor data at a fixed or time-varying probability and transmit it to the data fusion center (DFC), which renders the normal localization and tracking function of the search and rescue system downgrade or even fail. To address this issue, we develop a New robust marine mobile Multi-Target LocAlization and Tracking scheme called NMTLAT by eliminating abnormal measurement data from the initial measurement data. NMTLAT works in several steps. By analyzing and mining sensors data and behavior, we firstly employ the information entropy of the system composed of a single sensor and their neighbor sensors to develop an efficient dynamic threshold based Byzantine node identification method. After migrating Byzantine sensors, the DFC utilizes sensor-aware and preprocessed marine data of the beacon or honest sensors to complete target localization and trajectory tracking. Specifically, NMTLAT consists of a novel distributed and cooperative multi-target localization and tracking algorithm using both received signal strength indication (RSSI) and priori information of sensors location. NMTLAT employs the importance sampling method to approximate the posterior probability distribution of the sensors and targets location. Furthermore, when the marine target is outside MSR-WSNs coverage, a piecewise function is utilized to characterize the likelihood of finding a drowning target in the search and rescue sea area. Finally, the Lyapunov’s second stability theorem is adopted to measure the stability of the NMTLAT. Our extensive simulation experiments validate that the NMTLAT performance is superior to existing solutions in various marine search and rescue scenarios.},
  archive      = {J_COMCOM},
  author       = {Jiangfeng Xian and Huafeng Wu and Xiaojun Mei and Yuanyuan Zhang and Huixing Chen and Jun Wang},
  doi          = {10.1016/j.comcom.2020.06.034},
  journal      = {Computer Communications},
  pages        = {623-635},
  shortjournal = {Comput. Commun.},
  title        = {NMTLAT: A new robust mobile multi-target localization and tracking scheme in marine search and rescue wireless sensor networks under byzantine attack},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal multi-part mobile computation offloading with hard
deadline constraints. <em>COMCOM</em>, <em>160</em>, 614–622. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers mobile computation offloading when concurrent local execution (CLE) is used to enforce task execution time constraints. This mechanism can ensure that hard task deadlines are satisfied regardless of any randomness induced by the wireless channel, network or cloud servers. In this type of system, mobile device energy may be reduced by segmenting a task upload into multiple parts, rather than doing a conventional contiguous task upload. The paper uses this mechanism to adapt to changes in channel conditions during the offload. Unlike the contiguous task offload case however, the upload initiation times of each part must be determined dynamically. This is done while ensuring that hard task deadlines are always satisfied. In this paper, the multi-part computation offloading case is considered. In multi-part offloading, the task to be offloaded is partitioned into K K upload parts before any offload initiation decisions are made. In this case, current channel state information is incorporated into the offload decisions, and the system must always satisfy a hard task execution time constraint using concurrent local execution. The paper considers the case for Markovian wireless channels. A provably energy-optimal online computation offloading algorithm (MuliOpt) is introduced for multi-part offloading. MultiOpt is shown to be optimal using Markovian decision process stopping theory. Since the computational complexity of MultiOpt can be significant, simpler and more computationally efficient heuristics, which also respect the hard task execution deadline, may be used. The paper introduces two such heuristics, the Immediate Offloading, and Multi Threshold algorithms . The mobile energy use of MultiOpt is compared to these heuristics, as well as to local execution without offloading and an offline energy bound. Simulation results show that MultiOpt performs significantly better when compared to the proposed heuristics, as well as when K K increases.},
  archive      = {J_COMCOM},
  author       = {Arvin Hekmati and Peyvand Teymoori and Terence D. Todd and Dongmei Zhao and George Karakostas},
  doi          = {10.1016/j.comcom.2020.07.014},
  journal      = {Computer Communications},
  pages        = {614-622},
  shortjournal = {Comput. Commun.},
  title        = {Optimal multi-part mobile computation offloading with hard deadline constraints},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive delay-constrained resource allocation in mobile
edge computing for internet of things communications networks.
<em>COMCOM</em>, <em>160</em>, 607–613. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traffic burden at each node in Internet-of-Things (IoT) communication networks becomes prohibitively high especially when involving exhaustive computation. Mobile edge computing (MEC) makes this complicated computation feasible while alleviates the traffic burden by providing the corresponding node with powerful computing resources through wireless transmission between the node and the MEC for offloading computation . However, the transmission via the varying wireless channel requires considerable energy consumption and imposes delay. In this paper, we study the trade-off between the energy consumption and the delay performance in IoT network due to the offloading computation and the wireless communication . An optimization problem involving the offloading ratio for MEC as unknown parameter is established by minimizing the total energy consumption subject to a delay constraint. The problem is then solved by analyzing the convexity of the cost function and the constraint. Moreover, the scaling law of both energy cost and delay performance of IoT networks is investigated with respect to the number of nodes employing the MEC. It is discovered that the delay performance decreases in the logarithm with increasing the number of nodes while the energy cost grows linearly with the increase of the number of nodes. Numerical simulations verifying the performances of the proposed method in the studied IoT networks with MEC are provided.},
  archive      = {J_COMCOM},
  author       = {Juan Zhao and Xiaolong Xu and Wei-Ping Zhu},
  doi          = {10.1016/j.comcom.2020.06.031},
  journal      = {Computer Communications},
  pages        = {607-613},
  shortjournal = {Comput. Commun.},
  title        = {Adaptive delay-constrained resource allocation in mobile edge computing for internet of things communications networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IOT platform of one-key for help APP and environment
portfolio risk identification algorithm based on MIT. <em>COMCOM</em>,
<em>160</em>, 596–606. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper designs and invents internet of things platform of One-Key for Help APP based on the mobile intelligent terminal (MIT) for the risk response of one-key for help, information for help, SMS for assistance, phone for support, map phone for advantage, voice message for help and video for aid. For Government Emergency Rescue Department (GERD), the platform is preset with China’s 110 police system, 119 fire alarm system , 120 emergency center system, 122 traffic incident system, as well as the government emergency rescue department(GERD), social public welfare rescue organizations(SPWRO), families and friends’ call for help, and is designed emergency call for help and rescue methods according to the regional scope such as nearby people, communities, cities, provinces and the whole country, to realize the call for help from individual to government, groups, kinship, region, etc.. This paper also defines single-risk identification, multiple risk environment and designs the risk identification &amp; one-key for help algorithm. The One-Key for Help APP of IOT platform is applied for an actual case The APP platform can be used in several country or region and any city or village around the world. The One-Key for Help APP platform can be used in any country or region and any city or village in the world. A person only needs to register the APP and becomes used no matter what individual is in, wherever there is a mobile Internet, the concerned individual can use the One-Key for Help APP platform to send out the emergency information to their respective family, friends or GERD when they are in distress at any point of time. The APP has advanced functions and simple operation, which has scientific guidance and practical value for preventing all kinds of social emergencies.},
  archive      = {J_COMCOM},
  author       = {Sulin Pang},
  doi          = {10.1016/j.comcom.2020.06.023},
  journal      = {Computer Communications},
  pages        = {596-606},
  shortjournal = {Comput. Commun.},
  title        = {IOT platform of one-key for help APP and environment portfolio risk identification algorithm based on MIT},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Continuous health monitoring of sportsperson using IoT
devices based wearable technology. <em>COMCOM</em>, <em>160</em>,
588–595. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, wearable techniques are widely used in the Internet of Things (IoT). The discussed IoT devices are used in various applications such as smart home, security management, education institutions and so on. Among the various application, IoT devices are used widely in health care application for reducing the risk factors. So, in this paper, introduces the wearable sensors based on the Internet of Things (WS-IoT) for sports person continuous health monitoring system . The goal of this paper is to define the health clinics for sports medicine and performance services of the sports team to further the use of the technology to help athletes return to play in different fields of sport. With the help of wearable tracking devices to collect the health details and track the exercise records. To analyze and monitoring sports person health effective optimization machine learning techniques are introduced. The created system efficiency is evaluated using experimental results and discussion.},
  archive      = {J_COMCOM},
  author       = {Wang Huifeng and Seifedine Nimer Kadry and Ebin Deni Raj},
  doi          = {10.1016/j.comcom.2020.04.025},
  journal      = {Computer Communications},
  pages        = {588-595},
  shortjournal = {Comput. Commun.},
  title        = {Continuous health monitoring of sportsperson using IoT devices based wearable technology},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An energy harvesting solution for computation offloading in
fog computing networks. <em>COMCOM</em>, <em>160</em>, 577–587. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog Computing is a promising networking paradigm enabling the nodes at the edge to share computational and storage resources. Being pervasively distributed, Fog Nodes are often battery powered and, for this reason, an efficient energy management should be considered to prolong network lifetime. In this paper, we introduce a smart energy management solution able to exploit information about the predicted harvested and consumed energy by Fog Nodes, equipped with small solar panels. The smart energy management is applied on a cluster based Fog Computing environment where computation offloading operations are performed. In the experimental section the effect of the smart energy management is explored in terms of network lifetime by considering variable battery size and Fog Nodes density in a realistic solar-panel harvesting-model and Fog Nodes setting.},
  archive      = {J_COMCOM},
  author       = {Arash Bozorgchenani and Simone Disabato and Daniele Tarchi and Manuel Roveri},
  doi          = {10.1016/j.comcom.2020.06.032},
  journal      = {Computer Communications},
  pages        = {577-587},
  shortjournal = {Comput. Commun.},
  title        = {An energy harvesting solution for computation offloading in fog computing networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of cooperative eigenvalue spectrum
sensing GLRT under different impulsive noise environments in cognitive
radio. <em>COMCOM</em>, <em>160</em>, 567–576. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the performance evaluation of a centralized cooperative spectrum sensing scheme under the effect of different impulsive noise environments; the generalized likelihood ratio test (GLRT). Impulsive noise (IN) is considered the most prevailing factor for the deterioration of any communication system performance. We propose weighting sample fusion schemes. The likelihood ratio test (LRT) closed-form expression is analyzed to obtain the optimal weighting solution according to the Neyman–Pearson lemma. Although LRT is an optimal solution, it is not possible in practical considerations due to its reliance on the knowledge of primary users and noise powers. Hence, three blind empirical maximum likelihood estimation (MLE) approximation weighting schemes are designed. The four weighting sample fusion schemes are proposed to control the combination of the samples received at the fusion center (FC) to confer robustness for the sample fusion against the influence of IN severe conditions. Different configurations of IN conditions and system parameters are conducted to study the influence of IN on the spectrum sensing performance. Simulation results show an interesting performance of our proposed schemes compared with the conventional GLRT method. The study also discusses the fact that IN is not considered as a severe problem when we take into account the appropriate mitigation method to reduce the IN effects.},
  archive      = {J_COMCOM},
  author       = {Walid K. Ghamry and Suzan Shukry},
  doi          = {10.1016/j.comcom.2020.06.033},
  journal      = {Computer Communications},
  pages        = {567-576},
  shortjournal = {Comput. Commun.},
  title        = {Performance evaluation of cooperative eigenvalue spectrum sensing GLRT under different impulsive noise environments in cognitive radio},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimal policy for joint compression and transmission
control in delay-constrained energy harvesting IoT devices.
<em>COMCOM</em>, <em>160</em>, 554–566. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-efficient communication remains one of the key requirements of the Internet of Things (IoT) platforms. The concern on energy consumption can be mitigated by exploiting technical ploys to reduce the volume of data for transmission (e.g., via sensing data compression) as well as by resorting to technological advancements (e.g., energy harvesting). However, these mitigating measures carry their own cost, which is the additional complexity of control and optimization in the digital communication chain. In particular, compression ratio is another control knob that needs adjusting besides the usual transmission parameters. Also, with the random and sporadic nature of the harvested energy, the goal shifts from mere energy conservation to judicious consumption of the renewable energy in a foresighted manner. In this paper, we assume an energy-harvesting IoT device that is tasked with (loss-lessly) compressing and reporting delay-constrained sensing events to an IoT gateway over a time-varying wireless channel. We are interested in computing an optimal policy for joint compression and transmission control adaptive to the node’s energy availability, transmission buffer length, as well as its wireless channel conditions. We cast the problem as a Constrained Markov Decision Process (CMDP), and propose a two-timescale model-free reinforcement learning (RL) algorithm that is able to shape the optimal control policy in the absence of the statistical knowledge of the underlying system dynamics . Exhaustive simulation experiments are conducted to investigate the convergence of the learning algorithm, to explore the impacts of different system parameters (such as: the rate of sensing events, the energy arrival rate, and battery capacity) on the performance of the proposed policy, as well as to compare against some baseline schemes.},
  archive      = {J_COMCOM},
  author       = {Vesal Hakami and Seyedakbar Mostafavi and Nastooh Taheri Javan and Zahra Rashidi},
  doi          = {10.1016/j.comcom.2020.07.005},
  journal      = {Computer Communications},
  pages        = {554-566},
  shortjournal = {Comput. Commun.},
  title        = {An optimal policy for joint compression and transmission control in delay-constrained energy harvesting IoT devices},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse representation for network traffic recovery.
<em>COMCOM</em>, <em>160</em>, 547–553. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovery of the normal and anomalous traffic of origin–destination (OD) flow is important for network management and security tasks. However, in practice it is challenging since flow-level measurements are hard to obtain. This paper proposes a new scheme that recovers the traffic matrix – including normal and anomalous traffic – from only link counts and a small subset of OD flow counts by taking advantage of signal sparse property. We first study that normal and anomalous traffic can be sparsely represented in wavelet and time domain, respectively. Then a convex program with the ℓ 1 ℓ1 norm as the optimization objective is formulated to estimate both the normal and anomalous components of the traffic matrix . We conduct numerical experiments with real Internet data, demonstrating that the novel scheme achieves better estimation accuracy.},
  archive      = {J_COMCOM},
  author       = {XiaoBo Fan and Xiaobo Xu},
  doi          = {10.1016/j.comcom.2020.07.003},
  journal      = {Computer Communications},
  pages        = {547-553},
  shortjournal = {Comput. Commun.},
  title        = {Sparse representation for network traffic recovery},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized wireless channel allocation in hybrid data center
network based on IEEE 802.11ad. <em>COMCOM</em>, <em>160</em>, 534–546.
(<a href="https://doi.org/10.1016/j.comcom.2020.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive adoption of Cloud services is entailing a tremendous traffic transiting over data center networks (DCNs). Despite the impressive wired throughput, DCNs are suffering from network congestion . To deal with such resource limitation, first, we put forward a novel Hybrid Data Center Network (HDCN) architecture, based on CISCO’s Massively Scalable Data Center (MSDC) model. HDCN enables high throughput wireless (IEEE 802.11ad) and wired (IEEE 802.3) transmissions. Second, we focus on one-hop inter-rack communications in HDCN and propose a novel wireless channel assignment algorithm. Our goal is to maximize the total throughput over the wireless and/or wired infrastructure. We formulate the problem as a minimum graph coloring . To address this NP-hard problem, we propound two novel i) exact and ii) heuristic wireless channel assignment algorithms in HDCN denoted respectively by GC-HDCN and GH-GC-HDCN . The latter make use of i) column generation and ii) branch and price optimization schemes to resolve the Integer Linear Programming assignment problem while reducing computation time. Based on extensive simulations with QualNet simulator considering the full network protocol stack, the results obtained for both: i) uniform and ii) real Facebook’s workload, show that our proposals outperform the related prominent strategies in terms of latency and throughput.},
  archive      = {J_COMCOM},
  author       = {Boutheina Dab and Ilhem Fajjari and Nadjib Aitsaadi},
  doi          = {10.1016/j.comcom.2020.06.024},
  journal      = {Computer Communications},
  pages        = {534-546},
  shortjournal = {Comput. Commun.},
  title        = {Optimized wireless channel allocation in hybrid data center network based on IEEE 802.11ad},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fog-inspired smart home environment for domestic animal
healthcare. <em>COMCOM</em>, <em>160</em>, 521–533. (<a
href="https://doi.org/10.1016/j.comcom.2020.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domestic veterinary care is contemplated as one of the significant domains of the healthcare industry . Conspicuously, this research presents a Smart Home-based healthcare monitoring framework for domesticated animals in real-time. The research work employs the Internet of Things (IoT)-based data acquisition in the ambient environment of the home. Acquired IoT-data is pre-processed for feature extraction over the Fog–Cloud computing platform. Moreover, a temporal data granule is formulated using the Temporal Data mining technique, which is used to quantify healthcare vulnerability in terms of Scale of Health Adversity (SoHA) and Temporal Adversity Estimate (TAE). Based on this, a Multi-scaled Long Short Term Memory (M-LSTM) based vulnerability prediction is performed for preventive veterinary healthcare services . Moreover, a fog-assisted real-time alert generation module is presented in the proposed framework to notify the concerned veterinary doctor in the case of a medical emergency. To validate the proposed framework, the experimental simulations are performed over challenging dataset comprising of nearly 34,120 instances. Results show that the presented framework is able to register enhanced performance in comparison to several state-of-the-art decision-making techniques in terms of Temporal Effectiveness, Classification Efficiency, Prediction Efficacy, and System Stability.},
  archive      = {J_COMCOM},
  author       = {Munish Bhatia and Sandeep K. Sood and Ankush Manocha},
  doi          = {10.1016/j.comcom.2020.07.004},
  journal      = {Computer Communications},
  pages        = {521-533},
  shortjournal = {Comput. Commun.},
  title        = {Fog-inspired smart home environment for domestic animal healthcare},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A performance-aware dynamic scheduling algorithm for
cloud-based IoT applications. <em>COMCOM</em>, <em>160</em>, 512–520.
(<a href="https://doi.org/10.1016/j.comcom.2020.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has been employed for supporting storage and handling of Internet of Things (IoT) data. There is an increasing demand for IoT framework to provide services with fast processing time and less delay to offer latency sensitivity real-time applications like disaster management in smart homes. IoT process is mostly comprised of scheduling techniques that makes it hard to self-adapt, self-configure to respond with performance aware on environment changes. Existing scheduling techniques of IoT applications are not based on allocating tasks through sleep modes, which unavoidably lead to more power consumption and longer time delays . Consenting sensor devices and applying separate queueing to a sensor device that varies differently in their capabilities are increasingly significant. In this work, a dynamic management framework for IoT devices in cloud (DMFIC) algorithm is proposed to evaluate and schedule requests and sensor data, which allow coordinating huge data with high time-based resolution in a cost-effectual manner through anticipating various queues for sending an appropriate notification to users. A smart home application was used to demonstrate the proposed framework. The experimental result shows that the DMFIC algorithm gives an average of 5\% higher processing time and 0.2\% less delay compared to other IoT services and can efficiently manage sensor data in cloud.},
  archive      = {J_COMCOM},
  author       = {Sanjeevi Pandiyan and T. Samraj Lawrence and Sathiyamoorthi V. and Manikandan Ramasamy and Qian Xia and Ya Guo},
  doi          = {10.1016/j.comcom.2020.06.016},
  journal      = {Computer Communications},
  pages        = {512-520},
  shortjournal = {Comput. Commun.},
  title        = {A performance-aware dynamic scheduling algorithm for cloud-based IoT applications},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SSGRU: A novel hybrid stacked GRU-based traffic volume
prediction approach in a road network. <em>COMCOM</em>, <em>160</em>,
502–511. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a potential solution to relieve traffic congestions and help build a more safe traffic system, traffic flow prediction methods are given much attention in recent years. In previous studies, it can be found the machine learning (ML)-based methods are widely used in volume predictions of single roads. However, when applied in a more complicated road network , they usually show low efficiency and need to pay higher computing costs. To solve this problem, an innovative ML-based model, named Selected Stacked Gated Recurrent Units model (SSGRU), is proposed in this paper, which is mainly in allusion to road network traffic flow. There are mainly two parts in this model: one is used to do spatial pattern mining based on linear regression coefficients , and the other one includes a stacked gated recurrent unit (SGRU), which is essential for multi-road traffic flow prediction . As the basic unit, a simple tree structure is adopted to approximate the given road network. Particularly, we implemented our model into both suburban and urban traffic contexts, to prove its high adaptability. The whole evaluation process is based on seven different traffic volume data sets recorded at the 15-min interval, chosen from the England Highways. The results show that our model has higher accuracy than others when applied to a multi-road input infrastructure for all road scenarios.},
  archive      = {J_COMCOM},
  author       = {Peng Sun and Azzedine Boukerche and Yanjie Tao},
  doi          = {10.1016/j.comcom.2020.06.028},
  journal      = {Computer Communications},
  pages        = {502-511},
  shortjournal = {Comput. Commun.},
  title        = {SSGRU: A novel hybrid stacked GRU-based traffic volume prediction approach in a road network},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of wireless sensor network based improved immune
gene algorithm in airport floating personnel positioning.
<em>COMCOM</em>, <em>160</em>, 494–501. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on wireless sensor network(WSN) and the moving characteristics of airport passengers, this paper presents an improved WSN algorithm for airport passenger positioning. At first, this research bases on wireless sensor network . Then, the improved WSN algorithm is optimized and solved. Finally, the simulation data of airport passengers is tested. The result shows that the algorithm is superior to traditional. It has more accurate positioning, can meet the need of positioning for public places with high passenger flow rate like airports, and thus is of practical value.},
  archive      = {J_COMCOM},
  author       = {Hean Liu and Kim Yong Ki},
  doi          = {10.1016/j.comcom.2020.04.036},
  journal      = {Computer Communications},
  pages        = {494-501},
  shortjournal = {Comput. Commun.},
  title        = {Application of wireless sensor network based improved immune gene algorithm in airport floating personnel positioning},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards trustworthy internet of things: A survey on trust
management applications and schemes. <em>COMCOM</em>, <em>160</em>,
475–493. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advancement in technology with the proliferation of new wireless communication protocols gave rise to the new era of ubiquitous computing , called Internet of Things (IoT). IoT facilitates connectivity between various heterogeneous physical devices through the internet to advantage users with intelligent and more advanced services. Effective utilization of these services demands a secure system where one can rely on the source of the information together with the received information. Trust Management (TM) is a crucial aspect of security that aims to maintain reliability in a system by ensuring the secure exchange of information. Using the concept of local and global perception about the reputation, TM measures the degree of trust on the system’s entities and endeavors to reduce risk and uncertainty in the system. For IoT, TM paves the way to accomplish various decision-making tasks, like reliable service composition, secure routing, device authentication , access control, etc. However, design and deployment of TM for IoT are hindered by the inherent characteristics of IoT systems that demand to be addressed. In this paper, we identified various applications of TM and examined issues in the design and deployment of TM for IoT. A clear vision towards TM system , explaining the different phases involved in the process of managing the trust, is presented. Furthermore, an exhaustive survey on various TM schemes developed for IoT with their applicability and addressing issues is provided. The survey is conducted considering direct observations and indirect recommendations based distributed, semi-distributed, and centralized schemes along with the review on blockchain technology-based schemes for trust management in IoT. In addition to that, a comparative study of the existing schemes based on the various system measures like computation model, input attributes, evaluation tool, and performance metrics examining their strengths and weaknesses is given. Finally, the paper highlights open research challenges investigated by the survey to present future direction for the researchers.},
  archive      = {J_COMCOM},
  author       = {Avani Sharma and Emmanuel S. Pilli and Arka P. Mazumdar and Poonam Gera},
  doi          = {10.1016/j.comcom.2020.06.030},
  journal      = {Computer Communications},
  pages        = {475-493},
  shortjournal = {Comput. Commun.},
  title        = {Towards trustworthy internet of things: A survey on trust management applications and schemes},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge-centric delegation of authorization for constrained
devices in the internet of things. <em>COMCOM</em>, <em>160</em>,
464–474. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access management poses a significant challenge within the Internet of Things (IoT) given the constrained capabilities in terms of computing, memory, storage, bandwidth and energy available for most of the low-cost devices and things embedded in the physical world. In this scenario, Edge Computing can be considered a powerful opportunity to solve authorization issues, deploying edge devices near IoT constrained things capable of performing as logical intermediaries or brokers between them and cloud resources, services or applications. This work proposes an edge-centric delegation of authorization for constrained devices (without cryptographic capabilities) based on well-known and extensively used specifications and protocols such as OAuth 2.0 and CoAP (Constrained Application Protocol). The proposed solution is based on three different roles allowing constrained devices automated enrolment, authorized access to resources deployed in the cloud and roaming. Furthermore, the proposed solution is validated and assessed using a real smart farming case study.},
  archive      = {J_COMCOM},
  author       = {Elías Grande and Marta Beltrán},
  doi          = {10.1016/j.comcom.2020.06.029},
  journal      = {Computer Communications},
  pages        = {464-474},
  shortjournal = {Comput. Commun.},
  title        = {Edge-centric delegation of authorization for constrained devices in the internet of things},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MAC protocols for unmanned aerial vehicle ecosystems: Review
and challenges. <em>COMCOM</em>, <em>160</em>, 443–463. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deployment of multiple small-Unmanned Aerial Vehicles (UAVs) in various applications has gained considerable attention from researchers and business organizations. Recent studies on UAV networks show paramount magnification in the calibre of interest to deploy UAVs in both military and civilian sectors. Despite salutary in deployment, UAVs face a crucial challenge in radio allocation, timing control, and channel access. Majority of these issues are due to inefficient Medium Access Control (MAC) protocols as most of the applications with UAVs use subsisting MAC protocols, which are only congruous for traditional networks. The MAC protocols for existing networks face an issue of applicability to UAV-based communication network due to the requirements of highly dynamic and mobile scenarios. This paper tries to highlight such issues and challenges and presents a detailed review of the MAC protocols applicable for UAV-based communication ecosystems. Moreover, mechanisms to fit the existing protocols into UAV scenarios are additionally discussed along with key technologies and standards. Finally, the article provides future challenges about UAV communications.},
  archive      = {J_COMCOM},
  author       = {Sahil Vashisht and Sushma Jain and Gagangeet Singh Aujla},
  doi          = {10.1016/j.comcom.2020.06.011},
  journal      = {Computer Communications},
  pages        = {443-463},
  shortjournal = {Comput. Commun.},
  title        = {MAC protocols for unmanned aerial vehicle ecosystems: Review and challenges},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Securing internet of medical things with friendly-jamming
schemes. <em>COMCOM</em>, <em>160</em>, 431–442. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMT)-enabled e-healthcare can complement traditional medical treatments in a flexible and convenient manner. However, security and privacy become the main concerns of IoMT due to the limited computational capability, memory space and energy constraint of medical sensors, leading to the in-feasibility for conventional cryptographic approaches, which are often computationally-complicated. In contrast to cryptographic approaches, friendly jamming (Fri-jam) schemes will not cause extra computing cost to medical sensors, thereby becoming potential countermeasures to ensure security of IoMT. In this paper, we present a study on using Fri-jam schemes in IoMT. We first analyze the data security in IoMT and discuss the challenges. We then propose using Fri-jam schemes to protect the confidential medical data of patients collected by medical sensors from being eavesdropped. We also discuss the integration of Fri-jam schemes with various communication technologies, including beamforming , Simultaneous Wireless Information and Power Transfer (SWIPT) and full duplexity. Moreover, we present two case studies of Fri-jam schemes in IoMT. The results of these two case studies indicate that the Fri-jam method will significantly decrease the eavesdropping risk while leading to no significant influence on legitimate transmission.},
  archive      = {J_COMCOM},
  author       = {Xuran Li and Hong-Ning Dai and Qubeijian Wang and Muhammad Imran and Dengwang Li and Muhammad Ali Imran},
  doi          = {10.1016/j.comcom.2020.06.026},
  journal      = {Computer Communications},
  pages        = {431-442},
  shortjournal = {Comput. Commun.},
  title        = {Securing internet of medical things with friendly-jamming schemes},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Industrial internet of things for smart manufacturing
applications using hierarchical trustful resource assignment.
<em>COMCOM</em>, <em>160</em>, 423–430. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manufacturing industry undergoes a new age with major changes taking place on several fronts. Companies devoted to digital transformation take their future plants inspired by the Internet of Things (IoT). The IoT is a worldwide network of interrelated physical devices,which is an essential component of the internet, including sensors, actuators, smart apps, computers, mechanical machines, and people. The effective allocation of the computing resources and the carrier is critical in the industrial internet of Things (IIoT) for smart production systems. Indeed, the existing assignment method in the smart production system cannot guarantee that resources meet the inherently complex and volatile requirements of the user are timely. Many research results on resource allocations in auction formats which have been implemented to consider the demand and real-time supply for smart development resources, but safety privacy and trust estimation issues related to these outcomes are not actively discussed. The paper proposes a Hierarchical Trustful Resource Assignment (HTRA) and Trust Computing algorithm (TCA) based on Vickrey–Clarke–Groves (VGCs) in the computer carriers necessary resources to communicate wirelessly among IIoT devices and gateways, and the allocation of CPU resources for processing information at the CPC. Finally, experimental findings demonstrate that when the IIoT equipment and gateways are effective, the utilities of each participant are improved.},
  archive      = {J_COMCOM},
  author       = {Xiaoxiao Xu and Mingdan Han and Senthil Murugan Nagarajan and Prathik Anandhan},
  doi          = {10.1016/j.comcom.2020.06.004},
  journal      = {Computer Communications},
  pages        = {423-430},
  shortjournal = {Comput. Commun.},
  title        = {Industrial internet of things for smart manufacturing applications using hierarchical trustful resource assignment},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Service architecture of IoT terminal connection based on
blockchain identity authentication system. <em>COMCOM</em>,
<em>160</em>, 411–422. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things is a highly integrated and integrated application of information technology that can better meet the needs of people’s development. With the popularity of the Internet of Things , the number of Internet of Things devices has increased, and the communication between devices and devices has become more complicated. Because the Internet of Things has some common problems with the Internet, a more effective, secure and trusted IoT platform has become the focus of many research scholars. Blockchain , as a decentralized, non-tamperable and highly credible technology, fits well with the development trend of networking. Identity authentication is an important part of the service architecture and can effectively solve the security in the Internet of Things. Hidden dangers. Therefore, in view of the low efficiency and lack of security in the traditional IoT server architecture , this paper proposes a blockchain-based networked identity authentication system . Firstly, according to the characteristics of the blockchain, the key technologies of the blockchain are briefly explained. Then, the overall design scheme design, the user end system design and the equipment end system design of the identity authentication system. Finally, the experimental platform is built, and the functional testing of the blockchain platform, device and client is carried out respectively The throughput of the system is obtained by the block rate and the outbound time of the blockchain under the condition of the privacy blockchain. The memory usage and the corresponding traffic consumption during the process of creating the wallet and data upload are analyzed to verify the stability of the system and to verify the rationality of the IoT identity authentication system based on the blockchain.},
  archive      = {J_COMCOM},
  author       = {Jui-Chan Huang and Ming-Hung Shu and Bi-Min Hsu and Chien-Ming Hu},
  doi          = {10.1016/j.comcom.2020.06.027},
  journal      = {Computer Communications},
  pages        = {411-422},
  shortjournal = {Comput. Commun.},
  title        = {Service architecture of IoT terminal connection based on blockchain identity authentication system},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The 5G communication technology-oriented intelligent
building system planning and design. <em>COMCOM</em>, <em>160</em>,
402–410. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the irreplaceable advantages of 5G communication technology, there is no need to carry out complex bridge and wiring works in the construction of the network structure of smart buildings It is convenient and flexible to install, easy to expand and transform. This paper uses the special advantages of 5G-communication technology to apply 5G communication technology to intelligent buildings. This article first designs different subsystems based on different functions. Then, the local area networks composed of various subsystems distributed in the building are connected together through a 5G network. Finally, the basic centralized topology is adopted, and the building automatic control system installed in the public facilities in the middle of the plant is used as the network centre to communicate with each sub local area network through the bridge of 5G. In this paper, through the centralized monitoring and unified management of the distributed subsystems, and using the same monitoring interface to manage the different subsystems on a platform, the ultimate cost-effective system integration solution is finally achieved with the least investment optimal performance.},
  archive      = {J_COMCOM},
  author       = {Yan Zhou and Liyuan Li},
  doi          = {10.1016/j.comcom.2020.06.022},
  journal      = {Computer Communications},
  pages        = {402-410},
  shortjournal = {Comput. Commun.},
  title        = {The 5G communication technology-oriented intelligent building system planning and design},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). KATE: Kalman trust estimator for internet of drones.
<em>COMCOM</em>, <em>160</em>, 388–401. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Kalman Trust Estimator (KATE) to check misbehaviour by the drones in Internet of Drones. Internet of Drones is a Flying Ad Hoc Networks connected to internet is a wireless mobile network of energy constrained devices deployed in a high multidimensional free space. This leads to small neighbourhoods and high temporal variation of drone density. IoD is characterized by drones possessed or controlled by different owners that form the network. A legitimate drone may be made to act selfishly to further interests of its owners or may be compromised to act so. This warrants establishment of trust in a drone to accept the veracity of the messages or sensed information sent by it. Earlier, several trust models have been proposed to achieve secure and reliable internode communications. They often detect drones as malicious by merging the previously formed direct and indirect trust values but do not consider the impact of old trust values on the current trust values. The trust values stored over the internet last for longer duration. Hence, for old transactions, they turn vague with time, especially when only sporadic interactions has occurred. KATE promotes the exchange of only correct messages with reduced delay. It simultaneously combines the direct and indirect trust values among the drones in two different contexts. It attaches the state transition variable and the importance factor to the direct and indirect trust values during trust estimation. Weighted fused decision values is used in decision-making based on the estimated trust values. Our simulations show the efficiency of KATE in terms of high decision accuracy in minimal rounds of trust estimation.},
  archive      = {J_COMCOM},
  author       = {Arpita Bhargava and Shekhar Verma},
  doi          = {10.1016/j.comcom.2020.04.027},
  journal      = {Computer Communications},
  pages        = {388-401},
  shortjournal = {Comput. Commun.},
  title        = {KATE: Kalman trust estimator for internet of drones},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On spectrum and energy efficient survivable multipath
routing in off-line elastic optical network. <em>COMCOM</em>,
<em>160</em>, 375–387. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel integrated approach for designing survivable off-line Elastic Optical Network (EON) to minimize energy consumption and spectrum requirement. Single link failure recovery is ensured by applying multipath based routing and spectrum allocation (RSA). The RSA problem to minimize spectrum utilization is a NP-Hard one. Integer Linear Programming model is formulated for survivable multipath RSA (SM-ILP) to obtain the optimal solution for a small sized network. As the solution of SM-ILP gets intractable with the growth of the network size, two heuristics based on Greedy Algorithm (SM-GR) and Genetic Algorithm (SM-GA) are also developed to obtain near optimal solution for large-sized networks. Simulation studies have been carried out to evaluate the performance of the heuristics, and the results are compared with that obtained by solving the ILP formulation for small problem size. It is observed that for the considered simulation set up, proposed heuristics provide solution with variation of at most 6.77\% for energy consumption and 3.71\% for spectrum utilization to the optimal solution. Execution of those heuristics with different parameters on two large-sized networks NSFNET and COST-239 reveals that SM-GA outperforms SM-GR while aiming to minimize spectrum and power consumption jointly as well as spectrum utilization only whereas SM-GR performs better than SM-GA while minimizing power consumption only.},
  archive      = {J_COMCOM},
  author       = {Joy Halder and Tamaghna Acharya and Monish Chatterjee and Uma Bhattacharya},
  doi          = {10.1016/j.comcom.2020.06.018},
  journal      = {Computer Communications},
  pages        = {375-387},
  shortjournal = {Comput. Commun.},
  title        = {On spectrum and energy efficient survivable multipath routing in off-line elastic optical network},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Precise localization for achieving next-generation
autonomous navigation: State-of-the-art, taxonomy and future prospects.
<em>COMCOM</em>, <em>160</em>, 351–374. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving full autonomy in navigation is a complicated problem. The most widely used solution takes up the modular framework for sensing and information processing such as perception, mapping, control, planning and decision making. However, this approach misses the capability of environmental understanding. Hence, to achieve full autonomy in navigation a computing model with self-learning capability inspired by biological intelligence such as memorizing, inferring and experience update is essential for dynamic and noisy environments . Recent advanced sensing, communication and hardware miniaturization technologies achieved few autonomous operations in commercial systems but the full autonomy has not been attained yet. In this paper, the effect of precise and accurate localization for autonomous navigation technologies is extensively studied and the problems and limitations of the related algorithms are analyzed. The major limitations for precise localization are computational complexity , sensor noise and communication delays. These limitations further reduce perception and planning capabilities of autonomous navigation systems. From this study, the future prospects are outlined to achieve a higher level of autonomy by precise localization.},
  archive      = {J_COMCOM},
  author       = {Rathin Chandra Shit},
  doi          = {10.1016/j.comcom.2020.06.007},
  journal      = {Computer Communications},
  pages        = {351-374},
  shortjournal = {Comput. Commun.},
  title        = {Precise localization for achieving next-generation autonomous navigation: State-of-the-art, taxonomy and future prospects},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on resource allocation of vocal music teaching
system based on mobile edge computing. <em>COMCOM</em>, <em>160</em>,
342–350. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to allocate vocal teaching system resources plays an important role in improving the performance of vocal teaching systems. With the development of mobile edge computing , the calculation and storage of resource data can be adapted to the operating needs of vocal teaching systems. This study proposes a method of system resource allocation based on power iteration and sets the throughput of the unloading process as an objective function and realizes the optimal allocation of normal power by iterative optimization. At the same time, in view of the low energy efficiency and resource utilization of edge servers, a heterogeneous network based on edge servers is proposed to find the optimal strategy based on ensuring the Nash equilibrium point. In addition, in order to verify the performance of the algorithm in this paper, a comparative experiment is performed by designing simulation experiments. The results show that the method proposed in this paper has certain effects and strong practicability, which can provide theoretical references for subsequent related research.},
  archive      = {J_COMCOM},
  author       = {Jian Sun},
  doi          = {10.1016/j.comcom.2020.05.016},
  journal      = {Computer Communications},
  pages        = {342-350},
  shortjournal = {Comput. Commun.},
  title        = {Research on resource allocation of vocal music teaching system based on mobile edge computing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real time auxiliary data mining method for wireless
communication mechanism optimization based on internet of things system.
<em>COMCOM</em>, <em>160</em>, 333–341. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of Internet of things (IoT) system and satellite wireless communication technology is the main means of the application of IoT technology. Due to the limitation of the objective conditions of wireless communication technology, there are many problems in its application. So it is imperative to optimize its communication mechanism. This paper analyzes the characteristics and key technologies of wireless communication according to the IoT. Proposed a data mining algorithm based on multi tree, optimized the wireless communication mechanism based on the IoT in real time. And the data mining algorithm is verified by building a system and experimental verification. The results show that the data mining algorithm has good performance. Among the similar data mining algorithms, it is better to optimize the wireless communication mechanism based on the IoT, and has certain practicability and reference.},
  archive      = {J_COMCOM},
  author       = {Lin Li},
  doi          = {10.1016/j.comcom.2020.06.021},
  journal      = {Computer Communications},
  pages        = {333-341},
  shortjournal = {Comput. Commun.},
  title        = {Real time auxiliary data mining method for wireless communication mechanism optimization based on internet of things system},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud computing model for big data processing and
performance optimization of multimedia communication. <em>COMCOM</em>,
<em>160</em>, 326–332. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the technical aspects of big data processing of multimedia communication are deeply studied. Firstly, we propose a cloud implementation method of radial basis function neural network which is based on Map-Reduce on cloud computing cluster. Secondly, in order to meet the needs of big data processing of multimedia communication , the map-Reduce-based error back-propagation algorithm is trained to effectively map the effective mapping mechanism of multi-layer neural networks. For a cloud algorithm on a cloud computing cluster and a serial algorithm on a single processor, the time required to implement the algorithm is theoretically derived, and the cloud algorithm and performance parameters (acceleration ratio) on the cloud cluster are evaluated, the optimal number and minimum number of data nodes). Finally, the experimental results show that compared with the existing algorithms, the cloud algorithm proposed in this paper has better acceleration speed, faster convergence speed and fewer iterations.},
  archive      = {J_COMCOM},
  author       = {Zhicheng Zhou and Liang Zhao},
  doi          = {10.1016/j.comcom.2020.06.015},
  journal      = {Computer Communications},
  pages        = {326-332},
  shortjournal = {Comput. Commun.},
  title        = {Cloud computing model for big data processing and performance optimization of multimedia communication},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A provably secure and efficient anonymous mutual
authentication and key agreement protocol for wearable devices in WBAN.
<em>COMCOM</em>, <em>160</em>, 311–325. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless body area networks (WBAN) is a novel paradigm that is gaining popularity in a scenario of current wireless communication systems. It plays an essential role in healthcare applications like remote monitoring of health data. For instance, the crucial and confidential data about the condition of the patient’s physical health can be gathered and transferred through WBAN. Therefore, authentication and session key-agreements are integral security concerns for wearable sensors in WBAN. Moreover, as the wearable devices are resource-constraints, there is a need to develop a lightweight protocol to ensure authenticity, confidentiality, and integrity of the information. Li et al. presented an anonymous mutual authentication protocol to establish a session-key among wearable sensor nodes and the local hub node. However, after an in-depth analysis, we found that their scheme is susceptible to an intermediate node capture attack, and sensor node/hub node impersonation with intermediate node capture attacks. The scheme also does not provide anonymity with unlinkable sessions. This paper proposes a new anonymous mutual authentication and key agreement protocol in WBAN to overcome the security weaknesses in Li et al.’s protocol. The proposed protocol uses only basic symmetric cryptosystems like simple XOR and cryptographic hash functions ; hence, it is efficient and lightweight. The validity and the correctness of the proposed protocol are evaluated using BAN-Logic, Real-Or-Random (ROR) model, and the broadly accepted AVISPA tool. The performance comparison of the proposed protocol with the existing related protocols shows the efficiency regarding communication and computational complexities . Hence, it is suitable to be used in real-life applications.},
  archive      = {J_COMCOM},
  author       = {Ankur Gupta and Meenakshi Tripathi and Aakar Sharma},
  doi          = {10.1016/j.comcom.2020.06.010},
  journal      = {Computer Communications},
  pages        = {311-325},
  shortjournal = {Comput. Commun.},
  title        = {A provably secure and efficient anonymous mutual authentication and key agreement protocol for wearable devices in WBAN},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Experimental vs. Simulation analysis of LoRa for vehicular
communications. <em>COMCOM</em>, <em>160</em>, 299–310. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa, a Low Power Wide Area Network (LPWAN) technology, demands reduced network infrastructure to cover a large area, with low power consumption . In the context of vehicular communications , LoRa has the potential to support monitoring and cooperative navigation applications, where small amounts of data can be transmitted asynchronously through the network. Nevertheless, the literature lacks evaluations of LoRa in the context of vehicular communications . Thus, in this paper we analyze the performance of this technology operating in an urban mobility environment, using LoRa terminal devices embarked on vehicles and a LoRa receiver unit, acting as infrastructure. Moreover, we evaluate the equivalence between experimental and simulated results, obtained from the communication link between the LoRa module inside a vehicle and a LoRa receiver comparing to those produced by NS-3 simulations. Three metrics of interest are evaluated: Packet Delivery Ratio (PDR), Packet Inter-Reception (PIR) time, and Received Signal Strength Indicator (RSSI). Field experiments are performed at the campus of the Federal University of Rio de Janeiro (UFRJ), Brazil . Results revealed that all the metrics evaluated in the simulated experiments are consistent with the results of the real experiments, however, we concluded that the model can be improved by looking for a stronger correlation with real experiments.},
  archive      = {J_COMCOM},
  author       = {Fernando M. Ortiz and Thales T. de Almeida and Ana E. Ferreira and Luís Henrique M.K. Costa},
  doi          = {10.1016/j.comcom.2020.06.006},
  journal      = {Computer Communications},
  pages        = {299-310},
  shortjournal = {Comput. Commun.},
  title        = {Experimental vs. simulation analysis of LoRa for vehicular communications},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). OntoBestFit: A best-fit occurrence estimation strategy for
RDF driven faceted semantic search. <em>COMCOM</em>, <em>160</em>,
284–298. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As Web 2.0 is transforming into a more systematized Semantic Web, there is an urgent need for semantic compliant techniques for web search . In this paper, the OntoBestFit has been proposed which is an RDF driven approach for minimizing ambiguity in search results and increasing the diversity of results, thereby solving both the context irrelevance and the serendipity problem. OntoBestFit focuses on harvesting RDF from standardized industry scale Semantic Wikis and transforming it into an intermediate dyadic structure, which makes it suitable for heterogeneous real-world domains. The approach focuses on deriving an RDF prioritization vector from a Term-Frequency Matrix and a Term co-occurrence Matrix formulated from the reduced dyadic RDF entities over a corpus of web pages to yield Query Indicator terms. The incorporation of dynamic query expansion by generating query facets from the Domain Ontologies and Query Indicator terms using the best-fit occurrence estimation algorithm has made this approach novel. The best-fit occurrence estimation algorithm is based on the adaptation of Simpson’s Diversity Index to compute the reduced and highly appropriate semantically similar domain ontologies based on domain richness computation, to increase the diversity in search results. Also, an Enriched Adaptive Pointwise Mutual Information measure has been proposed to compute the semantic similarity. OntoBestFit yields an average accuracy of 94.91\% with a very low False Discovery Rate of 0.07, with a response time of 0.28 ms which is the best in class semantic search strategy in the era of Semantic Web.},
  archive      = {J_COMCOM},
  author       = {Gerard Deepak and A. Santhanavijayan},
  doi          = {10.1016/j.comcom.2020.06.013},
  journal      = {Computer Communications},
  pages        = {284-298},
  shortjournal = {Comput. Commun.},
  title        = {OntoBestFit: A best-fit occurrence estimation strategy for RDF driven faceted semantic search},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bandwidth abstraction and instantiation under closed-loop
latency constraint for tactile slice based on martingale theory.
<em>COMCOM</em>, <em>160</em>, 274–283. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The closed-loop latency quality of service (QoS) provisioning for tactile services is a pending problem. Based on martingale theory, this paper studies the bandwidth abstraction and service rate instantiation under closed-loop latency constraint for the tactile slice. The demanded bandwidth for arrivals is abstracted by considering the complex features of arrival traffic. The uplink delay is mapped into the analysis of downlink queuing system , which enables the closed-loop latency analysis. A martingale analytical framework is proposed so that the precise delay performance for downlink with bursty arrivals can be evaluated. We construct a Backlog Martingale process for the buffer backlog. A stopping time event that considers uplink and downlink jointly is defined under the closed-loop latency QoS constraint. Leveraging stopping time theory, a tight bound of delay violation probability is derived to guide the bandwidth abstraction. Service rates are instantiated by activating RRHs to form a dynamic MIMO system. Simulation results verify the effectiveness of the proposed strategy.},
  archive      = {J_COMCOM},
  author       = {Baozhu Yu and Xuefen Chi and Hongliang Sun},
  doi          = {10.1016/j.comcom.2020.06.008},
  journal      = {Computer Communications},
  pages        = {274-283},
  shortjournal = {Comput. Commun.},
  title        = {Bandwidth abstraction and instantiation under closed-loop latency constraint for tactile slice based on martingale theory},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart city oriented ecological sensitivity assessment and
service value computing based on intelligent sensing data processing.
<em>COMCOM</em>, <em>160</em>, 263–273. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important means to promote the territorial spatial planning system, the control of rural ecological space at watershed scale is of great significance for rural revitalization aimed at sustainable development and ecological environmental protection. Taking Sanshui River Basin in Xunyi as the research area, the paper applies the redline zoning method which integrates ecological sensitivity with ecosystem service, and collects remote sensing image data, DEM data, soil data, and also ecological environment characteristics and human activity intensity factors for a comprehensive analysis on the ecological function zone, ecological corridor and rural settlement in the river basin. The ultimate objective of the research is to propose a rural ecological space control system centered around “regionalization-network-stationing”. As suggested by the research results, in Sanshui River Basin, the area of suitable development zone, ecological control buffer zone, and ecological conservation zone is 467.35 km 2 , 538.86 km 2 and 317.34 km 2 , accounting for 35.31\%, 40.74\% and 23.95\% of the basin respectively; a basin rural ecological corridor network structure featuring “one core, one vertical line and three horizontal lines” has been constituted; approximately 387 villages are based in suitable construction development zone, 169 in ecological control buffer zone, and 82 in ecological conservation zone. The research is expected to provide scientific evidence for sustainable rural development and rational use of ecological environmental resources in Sanshui River Basin, afford specific technical support to territorial spatial planning, and reinforce space control scientificity and practicability.},
  archive      = {J_COMCOM},
  author       = {Yaqiong Duan and Lingda Zhang and Xiaoyang Fan and Quanhua Hou and Xinmeng Hou},
  doi          = {10.1016/j.comcom.2020.06.009},
  journal      = {Computer Communications},
  pages        = {263-273},
  shortjournal = {Comput. Commun.},
  title        = {Smart city oriented ecological sensitivity assessment and service value computing based on intelligent sensing data processing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of system outage probability in underlay cognitive
two-way amplify-and-forward relay networks. <em>COMCOM</em>,
<em>160</em>, 253–262. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several works have studied relaying in cognitive radio networks in terms of outage probability . The main challenge in such works is finding a mathematical expression for this performance metric under different system models. This expression can be employed in studying and designing more related systems. In this paper, we consider an underlay cognitive communication system , where each of the primary and secondary networks has two communicating nodes. The secondary nodes communicate, in two directions, through a relay node that employs half-duplex amplify-and-forward relaying scheme. In our study, we presumed having free-space path loss over the channels between the primary and secondary nodes as well as having Nakagami-m fading over the channels between the secondary nodes. To the best of our knowledge, there are no prior works which are similar to ours. In particular, we thoroughly study the proposed model and mathematically derive the outage probability for the whole two-way system in the secondary network under different communication schemes: two time slots, three time slots and four time slots schemes. To verify our mathematical derivations, we conduct thorough simulations under different scenarios. Interestingly, the simulation results show the correctness of our derivation.},
  archive      = {J_COMCOM},
  author       = {Raed T. Al-Zubi and Mohannad T. Abu Issa and Ahmad A. Zghoul and Khalid A. Darabkh and Yazid M. Khattabi},
  doi          = {10.1016/j.comcom.2020.06.001},
  journal      = {Computer Communications},
  pages        = {253-262},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of system outage probability in underlay cognitive two-way amplify-and-forward relay networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncovering spatiotemporal and semantic aspects of tourists
mobility using social sensing. <em>COMCOM</em>, <em>160</em>, 240–252.
(<a href="https://doi.org/10.1016/j.comcom.2020.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tourism favors more economic activities, employment, revenues and plays a significant role in development; thus, the improvement of this activity is a strategic task. In this work, we show how social sensing can be used to understand the key characteristics of the behavior of tourists and residents. We observe distinct behavioral patterns in those classes, considering the spatial and temporal dimensions, where cultural and regional aspects might play an important role. Besides, we investigate how tourists move and the factors that influence their movements in London, New York, Rio de Janeiro and Tokyo. In addition, we propose a new approach based on a topic model that enables the automatic identification of mobility pattern themes, ultimately leading to a better understanding of users’ profiles. The applicability of our results is broad, helping to provide better applications and services in the tourism segment.},
  archive      = {J_COMCOM},
  author       = {Ana P.G. Ferreira and Thiago H. Silva and Antonio A.F. Loureiro},
  doi          = {10.1016/j.comcom.2020.06.005},
  journal      = {Computer Communications},
  pages        = {240-252},
  shortjournal = {Comput. Commun.},
  title        = {Uncovering spatiotemporal and semantic aspects of tourists mobility using social sensing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient and SDN-enabled routing algorithm for
wireless body area networks. <em>COMCOM</em>, <em>160</em>, 228–239. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Body Area Networks (WBANs) are one of the special branches of Wireless Sensor Networks (WSNs) that attract attention in various disciplines such as health, engineering, biology, and computers. Also, WBANs are an important research area that can contribute to human life and health in many ways. The Software-Defined Networking (SDN) approach is a solution that can make simpler, flexible, manageable, and more efficient the heterogeneous and complex network structures, such as WBANs. In the Software-Defined WBAN (SD-WBAN) architecture, it is of great importance to extend the network lifetime due to the limited energy of the sensor nodes and the routing process is one of the most important energy consumption processes of SD-WBANs. For an effective and efficient routing approach, service quality requirement parameters, for example, throughput, energy efficiency, end-to-end delay, and packet transmission rates need to be considered. In this study, a new energy-efficient and SDN-enabled routing algorithm (ESR-W) has been developed with the use of the Fuzzy-based Dijkstra technique. So, the most appropriate route determination is performed with a central and reactive (on-demand) approach among many SD-WBAN users. SNR , battery level and hop count metrics are used for routing decisions. In order to compare ESR-W with existing protocols AODV and SDNRouting, extensive scenarios and simulations have been performed in the Riverbed Modeler simulation software. According to the results, ESR-W has been observed very successful compared to other protocols in terms of throughput, end-to-end delay, packet transmission rate, and energy consumption.},
  archive      = {J_COMCOM},
  author       = {Murtaza Cicioğlu and Ali Çalhan},
  doi          = {10.1016/j.comcom.2020.06.003},
  journal      = {Computer Communications},
  pages        = {228-239},
  shortjournal = {Comput. Commun.},
  title        = {Energy-efficient and SDN-enabled routing algorithm for wireless body area networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A secure authentication scheme with forward secrecy for
industrial internet of things using rabin cryptosystem. <em>COMCOM</em>,
<em>160</em>, 215–227. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a non-negligible subset of IoT, which focuses on solving special requirements in industrial applications. In IIoT environments, remote monitoring based on wireless sensor networks (WSNs) is an important application instance, which facilitates the user like professional to manage the factory remotely. The sensitive data collected from industrial sensor nodes is very important for real-time decisions. Since the user and the industrial sensor nodes communicate over insecure communication channels, the transmitted information may be intercepted and altered easily by a malicious adversary , and any modifications on these parameters may have negative effect on decisions. Therefore, there is a great need to design a secure authentication scheme to protect the transmitted information from unauthorized access. Most of the existing schemes reported in the literature are vulnerable to various known attacks, especially the inability to provide forward secrecy between gateway node and the sensor nodes. In allusion to the above problems, in this paper, we propose a new secure authentication scheme with forward secrecy for IIoT systems, in which Rabin cryptosystem is employed and the password verification table is avoided. The rigorous formal proof and heuristic analysis demonstrate that the proposed scheme provides the desired security and functional features. Compared with nine related schemes, the proposed scheme achieves a delicate balance between security and efficiency, and it is more suitable for realistic scenarios.},
  archive      = {J_COMCOM},
  author       = {Mengxia Shuai and Ling Xiong and Changhui Wang and Nenghai Yu},
  doi          = {10.1016/j.comcom.2020.06.012},
  journal      = {Computer Communications},
  pages        = {215-227},
  shortjournal = {Comput. Commun.},
  title        = {A secure authentication scheme with forward secrecy for industrial internet of things using rabin cryptosystem},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green resource allocation and energy management in
heterogeneous small cell networks powered by hybrid energy.
<em>COMCOM</em>, <em>160</em>, 204–214. (<a
href="https://doi.org/10.1016/j.comcom.2020.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In heterogeneous networks (HetNets), how to improve spectrum efficiency is a crucial issue. Meanwhile increased energy consumption inspires network operators to deploy renewable energy sources as assistance to traditional electricity. Based on above aspects, we allow base stations (BSs) to share their licensed spectrum resource with each other and adjust transmission power to adapt to the renewable energy level. Considering the sharing fairness among BSs, we formulate a multi-person bargaining problem as a stochastic optimization problem . We divide the optimization problem into three parts: data rate control, resource allocation and energy management . An online dynamic control algorithm is proposed to control admission rate and resource allocation to maximize the transmission and sharing profits with the least grid energy consumption. Simulation results investigate the time-varying data control and energy management of BSs and demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_COMCOM},
  author       = {Qiaoni Han and Bo Yang and Nan Song and Yuwei Li and Ping Wei},
  doi          = {10.1016/j.comcom.2020.06.002},
  journal      = {Computer Communications},
  pages        = {204-214},
  shortjournal = {Comput. Commun.},
  title        = {Green resource allocation and energy management in heterogeneous small cell networks powered by hybrid energy},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fastest adaptive estimation algorithms for topological
structure errors in smart grid networks. <em>COMCOM</em>, <em>160</em>,
197–203. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with traditional wired networks, wireless sensor networks(WSN) have the characteristics of low cost and rapid deployment, and also guarantee the same level of fault tolerance as wired networks. The WSN can also monitor the operating status of the power grid in real time, collect physical information such as related parameters, and provide more comprehensive and complete power grid operation data as a reference basis for smart grid operation and related management personnel, and complete the diagnosis, monitoring and power statistics of smart grid equipment The rapid construction of the data communication network has become a key technology to effectively solve the problems of difficult optimization management and high cost and economic benefits in the smart grid. This paper discusses the application of WSNs in smart grids from two aspects. Firstly, construct a WSN topology that complies with the smart grid architecture , and establish a real-time routing mechanism that meets the requirements of smart distribution network communication reliability; secondly, propose a fastest adaptive algorithm for the fault of the WSN topology in the smart grid . The proposed adaptive routing mechanism has certain advantages in node energy consumption, which reduces energy consumption by nearly 4\% compared to the directional diffusion method and the LEACH algorithm. Therefore, the algorithm is more suitable for the adaptation of WSN topology, and the method can Improve the life cycle of sensor nodes and networks.},
  archive      = {J_COMCOM},
  author       = {Huihong Xu},
  doi          = {10.1016/j.comcom.2020.05.042},
  journal      = {Computer Communications},
  pages        = {197-203},
  shortjournal = {Comput. Commun.},
  title        = {Fastest adaptive estimation algorithms for topological structure errors in smart grid networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Testing and fingerprinting the physical layer of wireless
cards with software-defined radios. <em>COMCOM</em>, <em>160</em>,
186–196. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many performance characteristics of wireless devices are fundamentally influenced by their vendor-specific physical layer implementation. Yet, characterizing the physical layer behavior of wireless devices usually requires complex testbeds with expensive equipment, making such behavior inaccessible and opaque to the end user, and complex to perform for wireless researchers. In this work, we propose and implement a new testbed architecture for software-defined radio-based wireless device performance benchmarking. The testbed allows tight control of timing events, at a microsecond time granularity , and is capable of accessing and measuring physical layer protocol features of real wireless devices, which allows to fingerprint the device type with high accuracy. Using the testbed, we measure the receiver sensitivity and signal capture behavior of Wi-Fi devices from different vendors. We identify marked differences in their performance, including a variation of as much as 20 dB in their receiver sensitivity. We further assess the response of the devices to truncated packets and show that this procedure can be employed to fingerprint device types with high consistency in both wired and wireless lab setups using only commodity SDR equipment.},
  archive      = {J_COMCOM},
  author       = {Johannes K. Becker and Stefan Gvozdenovic and Liangxiao Xin and David Starobinski},
  doi          = {10.1016/j.comcom.2020.05.031},
  journal      = {Computer Communications},
  pages        = {186-196},
  shortjournal = {Comput. Commun.},
  title        = {Testing and fingerprinting the physical layer of wireless cards with software-defined radios},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wake-up radio-based data forwarding for green wireless
networks. <em>COMCOM</em>, <em>160</em>, 172–185. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents G-WHARP , for Green Wake-up and HARvesting-based energy-Predictive forwarding, a wake-up radio-based forwarding strategy for wireless networks equipped with energy harvesting capabilities ( green wireless networks ). Following a learning-based approach, G-WHARP blends energy harvesting and wake-up radio technology to maximize energy efficiency and obtain superior network performance. Nodes autonomously decide on their forwarding availability based on a Markov Decision Process (MDP) that takes into account a variety of energy-related aspects, including the currently available energy and that harvestable in the foreseeable future. Solution of the MDP is provided by a computationally light heuristic based on a simple threshold policy , thus obtaining further computational energy savings . The performance of G-WHARP is evaluated via GreenCastalia simulations, where we accurately model wake-up radios, harvestable energy, and the computational power needed to solve the MDP. Key network and system parameters are varied, including the source of harvestable energy, the network density, wake-up radio data rate and data traffic. We also compare the performance of G-WHARP to that of two state-of-the-art data forwarding strategies, namely GreenRoutes and CTP-WUR . Results show that G-WHARP limits energy expenditures while achieving low end-to-end latency and high packet delivery ratio . Particularly, it consumes up to 34\% and 59\% less energy than CTP-WUR and GreenRoutes , respectively.},
  archive      = {J_COMCOM},
  author       = {Georgia Koutsandria and Valerio Di Valerio and Dora Spenza and Stefano Basagni and Chiara Petrioli},
  doi          = {10.1016/j.comcom.2020.05.046},
  journal      = {Computer Communications},
  pages        = {172-185},
  shortjournal = {Comput. Commun.},
  title        = {Wake-up radio-based data forwarding for green wireless networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementing a blockchain-based local energy market:
Insights on communication and scalability. <em>COMCOM</em>,
<em>160</em>, 158–171. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer-to-peer (P2P) energy markets are gaining interest in the energy sector as a means to increase the share of decentralised energy resources (DER), thus fostering a clean, resilient and decentralised supply of energy. Various reports have touted P2P energy markets as ideal use case for blockchain-technology, as it offers advantages such as fault-tolerant operation, trust delegation, immutability, transparency, resilience, and automation. However, relatively little is known about the influence of hardware and communication infrastructure limitations on blockchain systems in real-life applications. In this article, we demonstrate the implementation of a real-world blockchain managed microgrid in Walenstadt, Switzerland. The 37 participating households are equipped with 75 special smart-metres that include single board computers (SBC) that run their own, application-specific private blockchain. Using the field-test setup, we provide an empirical evaluation of the feasibility of a Byzantine fault tolerant blockchain system. Furthermore, we artificially throttle bandwidth between nodes to simulate how the bandwidth of communication infrastructure impacts its performance. We find that communication networks with a bandwidth smaller than 1000 kbit/s – which includes WPAN , LoRa, narrowband IoT , and narrowband PLC – lead to insufficient throughput of the operation of a blockchain-managed microgrid . While larger numbers of validators may provide higher decentralisation and fault-tolerant operation, they considerably reduce throughput. The results from the field-test in the Walenstadt microgrid show that the blockchain running on the smart-metre SBCs can provide a maximum throughput of 10 transactions per second. The blockchain throughput halts almost entirely if the system is run by more than 40 validators. Based on the field test, we provide simplified guidelines for utilities or grid operators interested in implementing local P2P markets based on BFT systems.},
  archive      = {J_COMCOM},
  author       = {Arne Meeuw and Sandro Schopfer and Anselma Wörner and Verena Tiefenbeck and Liliane Ableitner and Elgar Fleisch and Felix Wortmann},
  doi          = {10.1016/j.comcom.2020.04.038},
  journal      = {Computer Communications},
  pages        = {158-171},
  shortjournal = {Comput. Commun.},
  title        = {Implementing a blockchain-based local energy market: Insights on communication and scalability},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning to upgrade internet information security and
protection strategy in big data era. <em>COMCOM</em>, <em>160</em>,
150–157. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, we are in a typical information age, and network and information security systems are facing severe challenges. However, there is currently no suitable method for the detailed analysis and protection of Internet information security. In order to analyze Internet security information more accurately, we proposed an improved KPCA (Kernel Principle Component Analysis) algorithm within the context of the big data era and in view of the shortcomings and disadvantages of the KPCA feature extraction algorithm. The proposed algorithm not only retains its performance ability, but also improves the subsequent classification ability. This paper uses the KDDCUP99 security audit data set to simulate network intrusions , and the data set used network information data resources within a total of 9 weeks. The training data set contains a total of 7 weeks of data information, and the other 2 weeks of data information are used as a validation data set. The training data set contains a total of 5 million records of network security information, while the verification data set contains 2 million records. The experimental results show that for the network intrusion classification test, the improved algorithm is more efficient, convenient, and faster than the traditional KPCA one. Furthermore, the simulation results also show that the proposed algorithm has achieved a very high degree of accuracy and improvement in terms of “accuracy rate,” “false alarm rate,” and “missing alarm rate.”},
  archive      = {J_COMCOM},
  author       = {Junjun Guo and Le Wang},
  doi          = {10.1016/j.comcom.2020.05.043},
  journal      = {Computer Communications},
  pages        = {150-157},
  shortjournal = {Comput. Commun.},
  title        = {Learning to upgrade internet information security and protection strategy in big data era},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective feature engineering for DNN using hybrid
PCA-GWO for intrusion detection in IoMT architecture. <em>COMCOM</em>,
<em>160</em>, 139–149. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The entire computing paradigm is changed due to the technological advancements in Information and Communication Technology (ICT). Due to these advancements, various new communication channels are being introduced, out of which the Internet of Things (IoT) plays a significant role. The Internet of Medical Things (IoMT) is a special category of IoT in which the medical devices communicate with each other for sharing sensitive data. These advancements help the healthcare industry to have better contact and care towards their patients. But they too have certain drawbacks since there are so many security and privacy issues like replay, man-in-the-middle, impersonation, privileged-insider, remote hijacking, password guessing , denial of service (DoS) attacks and malware attacks. When the sensitive data is being attacked by any of these attacks, there is a chance of losing the authorized data to the attacker or getting altered due to which the data is not available for the authorized users and customers. Machine learning algorithms are widely used in the Intrusion Detection System (IDS) for detecting and classifying the attacks at the network and host level in a dynamic manner. Many supervised and unsupervised algorithms have been designed by researchers from the area of machine learning and data mining to identify the reliable detection of an anomaly. However, the main challenge in the IDS models are changed in dynamic and random behavior of malicious attacks and designing a scalable solution that can handle this behavior. The rapid change in network behavior and the fast evolution of various attacks paved the way for evaluating various datasets that are generated over the years and to design different dynamic approaches. In this paper, a deep neural network (DNN) is used to develop effective and efficient IDS in the IoMT environment to classify and predict unforeseen cyberattacks. The network parameter are preprocessed, optimized and tuned by hyperparameter selection methods. A comprehensive analysis of experiments in DNN with other machine learning algorithms are compared on the benchmark intrusion detection dataset. Through rigorous testing, it has proved that the proposed DNN model performs better than the existing machine learning approaches with an increase in accuracy by 15\% and decreases in time complexity by 32\%, which helps in faster alerts to avoid post effects of intrusion in sensitive cloud data storage.},
  archive      = {J_COMCOM},
  author       = {Swarna Priya R.M. and Praveen Kumar Reddy Maddikunta and Parimala M. and Srinivas Koppu and Thippa Reddy Gadekallu and Chiranji Lal Chowdhary and Mamoun Alazab},
  doi          = {10.1016/j.comcom.2020.05.048},
  journal      = {Computer Communications},
  pages        = {139-149},
  shortjournal = {Comput. Commun.},
  title        = {An effective feature engineering for DNN using hybrid PCA-GWO for intrusion detection in IoMT architecture},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence driven wireless network remote
monitoring based on diffie–hellman parameter method. <em>COMCOM</em>,
<em>160</em>, 132–138. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote monitoring of wireless networks based on artificial intelligence can build sensitive anomaly recognition mechanisms, automated event analysis engines and accurate global operation and maintenance capabilities for wireless network defense. Firstly, a simple camera is used to realize real-time acquisition and wireless transmission of video signals based on software-based MPEG-4 compression coding method. The self-developed ActiveX control with video decoding function is embedded in the webpage to realize real-time dynamic display of video information in the computer browser of the monitoring terminal. Secondly, in order to realize the intelligent control of wireless network, the research based on the reverse motion degree posture planning is carried out. The DH parameter method is used to establish the linkage coordinate system of wireless network remote monitoring, and the kinematics formula is derived. The geometric analysis method is used to calculate the motion trajectory of remote monitoring, accurately locate the various angles of remote monitoring and obtain the best motion path. Based on the Pm angle control method of fuzzy neural network , the RBF neural network , fuzzy control the combination of control and Pm control, using the self-learning ability of the neural network and the fuzzy reasoning is ability of fuzzy control. The end effector was adjusted to the target position. Finally, the established mathematical model was simulated by MATLAB, and the characteristics of wireless network remote monitoring were verified.},
  archive      = {J_COMCOM},
  author       = {Junyan Zhou},
  doi          = {10.1016/j.comcom.2020.05.047},
  journal      = {Computer Communications},
  pages        = {132-138},
  shortjournal = {Comput. Commun.},
  title        = {Artificial intelligence driven wireless network remote monitoring based on Diffie–Hellman parameter method},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensors for internet of medical things: State-of-the-art,
security and privacy issues, challenges and future directions.
<em>COMCOM</em>, <em>160</em>, 111–131. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health is wealth. Thus, it is very important to keep it healthy all the time for sustenance of human livelihood. Last decade has witnessed a number of digital developments, including sensors, microcontrollers , communication paradigm, and smarter societal need. Internet of Things (IoT) has pushed the human race toward harnessing of truly digitized e-healthcare services mainly by relying over the biosensors. Biosensors play most crucial role in IoT when question of e-healthcare comes into the scene. A range of sensors are available in market that help people to monitor daily fitness, blood glucose level and many smart home-based diagnostics. However, lack of proper categorization of such sensors has led to create problems like delay in government approval, gap in patient–doctor​ relationship, increased social inertia toward using the sensors in accordance to regular life style. To mitigate these issues, this work presents a systematic review on existing IoT-based sensors and IoT-market cap originated sensor-systems for taxonomically representation. We present comparative analysis among the reviewed sensors. We further present security and privacy issues associated with the sensor data and ways to mitigate them. We also discuss about futuristic plans to enhance current scenario. We further elaborate on how such intervention could be beneficial or problematic for society. We can conclude that IoT-based sensors upon certain fixation in terms of categorization and proper orientation can be very useful to make a smarter human society.},
  archive      = {J_COMCOM},
  author       = {Partha Pratim Ray and Dinesh Dash and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.05.029},
  journal      = {Computer Communications},
  pages        = {111-131},
  shortjournal = {Comput. Commun.},
  title        = {Sensors for internet of medical things: State-of-the-art, security and privacy issues, challenges and future directions},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A wearable blood oxygen saturation monitoring system based
on bluetooth low energy technology. <em>COMCOM</em>, <em>160</em>,
101–110. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic monitoring of blood oxygen saturation value is an important method for the prevention and treatment of chronic cardiovascular disease. In order to meet the design requirements of wearable mobile medical, this paper uses the main controller to read, filter, and calculate pulse rate and blood oxygen value, and saturate the pulse signal and blood oxygen through the Bluetooth low-power module. The degree value and pulse rate value are transmitted to the Android smartphone, and the APP on the Android phone side manages the user’s physiological parameters and establishes a personal health file. Monitoring of blood oxygen saturation in a dynamic environment can be affected by severe motion disturbances. Aiming at this problem, this paper proposes a new adaptive cancellation algorithm based on adaptive filtering . Based on the interference analysis of the photoelectric volume pulse wave signal in a dynamic environment, this paper uses the envelope information of the PPG (Photoplethysmography) signal to extract the AC component of the photoelectric volume pulse wave signal, and construct interference-related signals as reference signals and perform adaptive filtering to suppress motion interference. The adaptive cancellation algorithm proposed in this paper performs digital signal processing on the collected original information and analyzes the calculation results. Comparing the calculated results with those of the DST (Discrete Saturation Transform) signal extraction technology, the effectiveness of the algorithm in eliminating motion interference is verified, and the anti-interference ability and time complexity of the algorithm under severe motion are verified.},
  archive      = {J_COMCOM},
  author       = {Qingguo Chen and Liqin Tang},
  doi          = {10.1016/j.comcom.2020.05.041},
  journal      = {Computer Communications},
  pages        = {101-110},
  shortjournal = {Comput. Commun.},
  title        = {A wearable blood oxygen saturation monitoring system based on bluetooth low energy technology},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Remaining useful life prediction based on state assessment
using edge computing on deep learning. <em>COMCOM</em>, <em>160</em>,
91–100. (<a href="https://doi.org/10.1016/j.comcom.2020.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent industrial production has recently emerged as an important trend for application of the Industrial Internet of Things (IIoT) in edge computing . This study applied remote edge devices and edge servers, preprocessing the signal sensor, through covert data to cloud storage, and loaded the data to propose several deep learning methods to assess the status of aircraft engines in operation, and to classify stages of operational degradation so as to predict the functional remaining lifespan of components. The predicted results are transmitted to a cloud-based server for monitoring and maintenance.},
  archive      = {J_COMCOM},
  author       = {Hsin-Yao Hsu and Gautam Srivastava and Hsin-Te Wu and Mu-Yen Chen},
  doi          = {10.1016/j.comcom.2020.05.035},
  journal      = {Computer Communications},
  pages        = {91-100},
  shortjournal = {Comput. Commun.},
  title        = {Remaining useful life prediction based on state assessment using edge computing on deep learning},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PARTH: A two-stage lightweight mutual authentication
protocol for UAV surveillance networks. <em>COMCOM</em>, <em>160</em>,
81–90. (<a href="https://doi.org/10.1016/j.comcom.2020.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAVs are being widely deployed in security and surveillance applications around the world. Due to deployment in remote environments and also due to limited resources on these devices, they are susceptible to device capture and physical tampering attacks. This heightens the risk of sensitive data stored in the UAVs to be captured by adversaries. To address this issue, a two-stage lightweight mutual authentication protocol is presented in this paper, well suited to SDN-backed multi UAV networks deployed in surveillance areas. Formal security proof of the protocol is presented to highlight its security features. We also compare our protocol with other state-of-the-art works in terms of computation latency and resilience against known security attacks.},
  archive      = {J_COMCOM},
  author       = {Tejasvi Alladi and Vinay Chamola and Naren and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.05.025},
  journal      = {Computer Communications},
  pages        = {81-90},
  shortjournal = {Comput. Commun.},
  title        = {PARTH: A two-stage lightweight mutual authentication protocol for UAV surveillance networks},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Signal frequency domain analysis and sensor fault diagnosis
based on artificial intelligence. <em>COMCOM</em>, <em>160</em>, 71–80.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement bias or drift often occurs after long-term use of the sensor. Measuring faults will inevitably mislead the control system, making the goal of advanced control strategies impossible. To this end, this paper proposes an artificial intelligence diagnosis method based on wavelet neural network for the diagnosis of sensor faults. Wavelet analysis is used to extract the frequency domain features of the data, and then the neural network is used to diagnose the frequency domain characteristic data of the signal. On this basis, the data of a single sensor signal is used for self-diagnosis. The advantages of wavelet analysis in extracting signal characteristics and the advantages of neural network in feature learning and discrimination are comprehensively utilized. Based on the correlation of sensor signals, this paper proposes a joint information diagnosis method. To determine the correlation of sensor signals, models based on energy balance and flow-pressure balance were established. The simulation results show that the method can effectively diagnose the fault of the sensor in the multi-sensor system.},
  archive      = {J_COMCOM},
  author       = {Daming Li and Zhiming Cai and Bin Qin and Lianbing Deng},
  doi          = {10.1016/j.comcom.2020.05.034},
  journal      = {Computer Communications},
  pages        = {71-80},
  shortjournal = {Comput. Commun.},
  title        = {Signal frequency domain analysis and sensor fault diagnosis based on artificial intelligence},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Allocation algorithm of CPS communication resources based on
cooperative game. <em>COMCOM</em>, <em>160</em>, 63–70. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the communication rate of the cyber–physical fusion system, and at the same time guarantee the quality of system demand of each user, a CPS (Cyber–Physical Systems) communication resource allocation algorithm based on cooperative game was first proposed. The resource allocation process of the orthogonal frequency division multiple access network downlink in CPS is modeled as a cooperative game among multiple users, and the Pareto optimality among users is achieved by solving the Nash bargaining solution . Secondly, this paper studies the cooperative task assignment of communication resources for actuators in CPS execution network, and proposes a feasible task assignment method of communication resources based on K–M algorithm. Simulation experiments show that the task allocation result obtained by this method is better than that of auction method, and the algorithm running time can also meet the limit of actual demand. Finally, in consideration of the control center’s need for fine control of the actuator, this paper studies the wireless resource allocation problem between a control center and the actuator, and maximizes the control effect of the actuator as the daily standard, and proposes a dynamic Joint allocation scheme of subchannels and power. Simulation results show that the proposed scheme can maintain a high level of control effect even when the transmission power of the control center is small, which effectively saves the energy consumption of the control center.},
  archive      = {J_COMCOM},
  author       = {Jin Zhao and Qiuxia Dong},
  doi          = {10.1016/j.comcom.2020.05.038},
  journal      = {Computer Communications},
  pages        = {63-70},
  shortjournal = {Comput. Commun.},
  title        = {Allocation algorithm of CPS communication resources based on cooperative game},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytical and simulation tools for optical camera
communications. <em>COMCOM</em>, <em>160</em>, 52–62. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of LED-to-camera communication opens the door to a wide range of use cases and applications, with diverse requirements in terms of quality of service. However, while analytical models and simulation tools exist for all the major radio communication technologies, the only way of currently evaluating the performance of a network mechanism over LED-to-camera is to implement and test it. Our work aims to fill this gap by proposing a Markov–modulated Bernoulli process to model the wireless channel in LED-to-camera communications, which is shown to closely match experimental results. Based on this model, we develop and validate CamComSim , the first network simulator for LED-to-camera communications.},
  archive      = {J_COMCOM},
  author       = {Alexis Duque and Razvan Stanica and Herve Rivano and Adrien Desportes},
  doi          = {10.1016/j.comcom.2020.05.036},
  journal      = {Computer Communications},
  pages        = {52-62},
  shortjournal = {Comput. Commun.},
  title        = {Analytical and simulation tools for optical camera communications},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Priority-based data transmission using selective decision
modes in wearable sensor based healthcare applications. <em>COMCOM</em>,
<em>160</em>, 43–51. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, wearable sensor technology plays an important role in observing the physiological vitals from human body and providing support for analyzing the health conditions. It is a combination of communication technology and sensing system to view and collect the changes of vital signs in human body. Data collection and analyzing are important task for health monitoring and diagnosis in medical applications. Transmitting data in open wireless communication medium is a crucial process to ensure the reliability of medical data analysis. In this paper, the proposed method focusing on the priority-based data transmission using selective decision mode for achieving successful data delivery is presented. Congestion mitigation and perfect queuing are the selective decision modes to avoid data losses and reduce dissemination time. Depending on the rate of congestion and priority of the data sensed, transmission is balanced using queuing or delivery as modeled in the decision mode. The comparative analysis results prove the consistency of the proposed method by improving queue utilization and success rate by 37.18\% and 3.67\% and reducing the average delay by 23.69\% respectively, for the varying transmission intervals.},
  archive      = {J_COMCOM},
  author       = {Abdulmonem Alsiddiky and Waleed Awwad and Khalid bakarman and H. Fouad and Azza S. Hassanein and Ahmed M. Soliman},
  doi          = {10.1016/j.comcom.2020.05.039},
  journal      = {Computer Communications},
  pages        = {43-51},
  shortjournal = {Comput. Commun.},
  title        = {Priority-based data transmission using selective decision modes in wearable sensor based healthcare applications},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of network topology and deployment mode of 5G
wireless access network. <em>COMCOM</em>, <em>160</em>, 34–42. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the characteristics of high-density and random deployment of 5G cellular networks , through efficient network-level deployment methods, the network can quickly and efficiently adapt to large-scale dynamic changes in user traffic. Aiming at the need for 5G systems to meet the requirements of high-speed mobile environment communications, this paper deeply studies the factors that affect communication quality in mobile scenarios and their relationships. Based on this, around the content transmission and distribution of information, a 5G mobile communication network architecture based on content-centric network technology is proposed. To meet the deployment requirements of cross-domain VNF (Virtual Network Function) during the deployment phase, in order to solve the problem that the existing cross-domain deployment algorithms do not take into account node computing resources and link bandwidth resources, this paper proposes a DPSO-K (Discrete Particle Swarm Optimization—Kruskal) 5G cross-domain virtual network function deployment method. Compared with the traditional method, the overall cost is reduced, and the cost is least affected by the number of data fields. In different practical scenarios, the resource reduction gain of the strategy is evaluated. Simulation results verify the impact of different system parameters on the energy efficiency of the network. The results show that this method has obvious advantages in optimizing the energy spectrum efficiency of randomly deployed networks.},
  archive      = {J_COMCOM},
  author       = {Zhiliang Liu and Zengzhi Zou},
  doi          = {10.1016/j.comcom.2020.05.045},
  journal      = {Computer Communications},
  pages        = {34-42},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of network topology and deployment mode of 5G wireless access network},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent routing method based on network partition.
<em>COMCOM</em>, <em>160</em>, 25–33. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New routing strategies are urgently needed to control exploding traffic and provide precise routing for the next-generation complex network. Traditional routing methods cannot satisfy its routing requirements of this complex traffic control situation. One of the important reasons is that it does not consider learning from traffic features. Using deep learning method to predict routing path is an emerging and promising solution, however, the existing deep learning-based methods in network traffic control field still have some disadvantages, such as low routing accuracy, high routing time complexity and need large data set to train complex deep learning system. To solve these problems, this paper proposes a block-based deep learning intelligent routing strategy (DLBR strategy), which divides the network into multiple sub-blocks according to a recursive partition method and uses three deep learning models to train and test them. Experiments show that the proposed network DLBR strategy has the ability to combine with different deep learning intelligent structures, and achieves higher accuracy and lower time complexity under the training of smaller training data.},
  archive      = {J_COMCOM},
  author       = {Zheheng Rao and Yanyan Xu and Shaoming Pan},
  doi          = {10.1016/j.comcom.2020.05.040},
  journal      = {Computer Communications},
  pages        = {25-33},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent routing method based on network partition},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). “DRL + FL”: An intelligent resource allocation model based
on deep reinforcement learning for mobile edge computing.
<em>COMCOM</em>, <em>160</em>, 14–24. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of a large number of computation-intensive and time-sensitive applications, smart terminal devices with limited resources can only run the model training part of most intelligent applications in the cloud, so a large amount of training data needs to be uploaded to the cloud. This is an important cause of core network communication congestion and poor Quality-of-Experience (QoE) of user. As an important extension and supplement of cloud computing , Mobile Edge Computing (MEC) sinks computing and storage resources from the cloud to the vicinity of User Mobile Devices (UMDs), greatly reducing service latency and alleviating the burden on core networks. However, due to the high cost of edge servers deployment and maintenance, MEC also has the problems of limited network resources and computing resources, and the edge network environment is complex and mutative. Therefore, how to reasonably allocate network resources and computing resources in a changeable MEC environment has become a great aporia. To combat this issue, this paper proposes an intelligent resource allocation model “DRL + FL”. Based on this model, an intelligent resource allocation algorithm DDQN-RA based on the emerging DRL algorithm framework DDQN is designed to adaptively allocate network and computing resources. At the same time, the model integrates the FL framework with the mobile edge system to train DRL agents in a distributed way. This model can well solve the problems of uploading large amounts of training data via wireless channels, Non-IID and unbalance of training data when training DRL agents, restrictions on communication conditions, and data privacy. Experimental results show that the proposed “DRL + FL” model is superior to the traditional resource allocation algorithms SDR and LOBO and the intelligent resource allocation algorithm DRLRA in three aspects: minimizing the average energy consumption of the system, minimizing the average service delay, and balancing resource allocation.},
  archive      = {J_COMCOM},
  author       = {Nanliang Shan and Xiaolong Cui and Zhiqiang Gao},
  doi          = {10.1016/j.comcom.2020.05.037},
  journal      = {Computer Communications},
  pages        = {14-24},
  shortjournal = {Comput. Commun.},
  title        = {“DRL + FL”: An intelligent resource allocation model based on deep reinforcement learning for mobile edge computing},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotion-controlled spectrum mobility scheme for efficient
syntactic interoperability in cognitive radio-based unmanned vehicles.
<em>COMCOM</em>, <em>160</em>, 1–13. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collision is a key factor to be considered in the design of a communication system for unmanned vehicles, especially when they do extreme surveillance. Collisions can be avoided by establishing efficient vehicle-2-vehicle (V2V) and vehicle-2-infrastructure (V2I) communications through the Internet of Vehicles (IoV). Recently, software defined cognitive radio (CR) based IoV has emerged as a potential technology for efficient communications among unmanned vehicles. However, spectrum mobility is a challenge for keeping CR-based networks interoperable and has not been sufficiently investigated in the existing research. In our previous work, the cognitive-radio Site (CR_Site) has been proposed as an in-vehicle CR-device which can be utilized to establish an efficient IoV system. However, the CR_Site is not capable of resolving the spectrum mobility challenge in high-speed unmanned IoV systems. Therefore, in this paper we introduce an emotion-inspired cognitive agent (EIC_Agent) for spectrum mobility in CR_Site. The agent is equipped with a novel emotion-controlled spectrum mobility scheme that achieves efficient syntactic interoperability among unmanned vehicles. For efficient spectrum mobility, a probabilistic and deterministic finite automaton using a fear factor is proposed. Moreover, we performed a quantitative computation of different fear intensity levels with the help of fuzzy logic. We tested the system using active data from different GSM service providers on the Mangla-Mirpur road. The results are supplemented by extensive simulation experiments, which validate the proposed scheme for a CR-based high-speed unmanned vehicle network. Finally, we compare the proposed scheme with the existing state-of-the-art, demonstrating the superiority of the proposed EIC-agent-based spectrum mobility scheme within a CR-based IoV system.},
  archive      = {J_COMCOM},
  author       = {Faisal Riaz and M. Mazhar Rathore and Adnan Sohail and Naeem Iqbal Ratyal and Samia Abid and Samina Khalid and Tehmina Shehryar and Adil Waheed},
  doi          = {10.1016/j.comcom.2020.05.033},
  journal      = {Computer Communications},
  pages        = {1-13},
  shortjournal = {Comput. Commun.},
  title        = {Emotion-controlled spectrum mobility scheme for efficient syntactic interoperability in cognitive radio-based unmanned vehicles},
  volume       = {160},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive and distributed traffic management system using
vehicular ad-hoc networks. <em>COMCOM</em>, <em>159</em>, 317–330. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic Management Systems become an important challenge for large cities due to the constant growth of vehicles. As the road mesh does not increase as well as the number of vehicles in the streets, technological solutions for the traffic congestion rise as alternative and easy-to-use applications. This work presents the ON -DEMAND: An adaptive and Distributed Traffic Management System using VANETS. The proposed solution is based on V2V communication and the local view of traffic congestion. During its displacement in a road, the vehicle monitors its traveled distance and the expected one considering a free-flow traffic condition. The difference between these measurements is used to classify a contention factor, i.e., the vehicle perception on the road traffic condition. Each vehicle uses the contention factor to classify the overall congestion level and this information is proactively disseminated to its vicinity considering an adaptive approach. In the case a vehicle does not have the necessary traffic information to estimate alternative routes, it executes a reactive traffic information knowledge discovery. The proposed solution is compared with three literature solutions, named DIVERT, PANDORA and s-NRR. Our results showed that ON -DEMAND presents better results regarding network and traffic congestion metrics.},
  archive      = {J_COMCOM},
  author       = {Thiago S. Gomides and Robson E. De Grande and Allan M. de Souza and Fernanda S.H. Souza and Leandro A. Villas and Daniel L. Guidoni},
  doi          = {10.1016/j.comcom.2020.05.027},
  journal      = {Computer Communications},
  pages        = {317-330},
  shortjournal = {Comput. Commun.},
  title        = {An adaptive and distributed traffic management system using vehicular ad-hoc networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault diagnosis method of sensors in building structural
health monitoring system based on communication load optimization.
<em>COMCOM</em>, <em>159</em>, 310–316. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The building structure maintenance and safety monitoring system has become an important guarantee of building structure safety. The service life of conventional large-scale buildings is usually fixed in hundreds of years, while the sensor life of the corresponding structural health monitoring (SHM) system can only be maintained in more than ten years or even shorter. Therefore, it is very important and significant to identify and detect the sensor fault of the building SHM system in time and effectively. Based on the communication load optimization technology, this paper will control and optimize the communication load and energy efficiency of a large number of sensor devices, so that the whole monitoring system network has the advantages of small flow and large amount of connected data. At the same time, according to the generalized quasi natural analogy test principle, a sensor fault self diagnosis method is proposed, so as to further quickly realize the detection system sensor fault and fault channel determination. Based on this, the sensor fault detection algorithm of the communication load optimization based building SHM system proposed in this paper is applied to the structure safety monitoring of a large building. The experimental results show that the diagnosis results of this method are accurate and consistent with the actual situation.},
  archive      = {J_COMCOM},
  author       = {Kai Yan and Yao Zhang and Yan Yan and Cheng Xu and Shuai Zhang},
  doi          = {10.1016/j.comcom.2020.05.026},
  journal      = {Computer Communications},
  pages        = {310-316},
  shortjournal = {Comput. Commun.},
  title        = {Fault diagnosis method of sensors in building structural health monitoring system based on communication load optimization},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource scheduling of green communication network for large
sports events based on edge computing. <em>COMCOM</em>, <em>159</em>,
299–309. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of large-scale sports events requires strong support from the network foundation. At the same time, network resource scheduling in the era of big data not only determines the operating efficiency of communication network systems, but also plays an important role in effectively reducing greenhouse gas emissions. In order to improve the green energy-saving effect of large-scale sports events network operation, this study analyzes the operation process of its network system and uses the time slot method to perform task routing decision processing. Moreover, this research uses Lyapunov’s optimization technology for algorithm design and algorithm construction for service chain cache and routing problems. In addition, this study combines large-scale sports event communication networks to conduct controlled trial design and performs algorithm performance analysis through simulation analysis. The research shows that the algorithm proposed in this paper can obtain a solution with better performance and can provide theoretical references for subsequent related research.},
  archive      = {J_COMCOM},
  author       = {Bin Zhang and Dexu Chen},
  doi          = {10.1016/j.comcom.2020.04.051},
  journal      = {Computer Communications},
  pages        = {299-309},
  shortjournal = {Comput. Commun.},
  title        = {Resource scheduling of green communication network for large sports events based on edge computing},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on analysis method of event importance and fault
model in space fault network. <em>COMCOM</em>, <em>159</em>, 289–298.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To study the event importance and their role in the system fault evolution process (SFEP), and the possibility of fault mode, the analysis methods of event importance and possibility of fault mode are proposed. This paper is the series of research in related fields including four methods. The event importance in fault process to fault evolution is studied from fault mode. Change to Field theory is used to study the relationships between events in the fault process to judge the event importance. For the structure of space fault network (SFN), the possibility of fault mode is studied. Based on some events have occurred, the potential possibility of fault mode is studied. At the same time, some examples are given to illustrate the use and processes of these methods. These methods can study the event importance and the characteristics of fault occurrence in SFEP within the framework of SFN. The methods are suitable for computer information storage and data processing, and are suitable for intelligent analysis and data processing of SFEP, and enrich the theory of SFN},
  archive      = {J_COMCOM},
  author       = {Shasha Li and Tiejun Cui},
  doi          = {10.1016/j.comcom.2020.05.030},
  journal      = {Computer Communications},
  pages        = {289-298},
  shortjournal = {Comput. Commun.},
  title        = {Research on analysis method of event importance and fault model in space fault network},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic strain signal monitoring and calibration with neural
network based on hierarchical orthogonal artificial bee colony.
<em>COMCOM</em>, <em>159</em>, 279–288. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic strain monitoring system is an important means to reflect the deformation and evolution of the structure in the field of traffic and transportation visually. The exact measurement of dynamic strain measurement system is inseparable from the traceability system of high-precision strain gauge . In this paper, the resistance strain monitoring system installed on the web surface of the main girder box of Jiujiang bridge is calibrated online by using the parallel method at a similar location. By means of dynamic strain measurement system calibration sample signal feature extraction, put forward online calibration method based on neural network algorithm for dynamic strain signaler, move the noise of passive nonlinear signal under the circumstance of incentives, set up and designed a calibration method of HOABC-NN for dynamic signal analysis of on-line monitoring system. After verification, it is found that the algorithm is superior to the traditional neural network training method, the calibration precision is improved obviously, and can support the dynamic strain of bridge monitoring system online calibration},
  archive      = {J_COMCOM},
  author       = {Lu Peng and Genqiang Jing and Zhu Luo and Liye Zhang and Maowei He and Zibin Wang and Xin Yuan},
  doi          = {10.1016/j.comcom.2020.05.028},
  journal      = {Computer Communications},
  pages        = {279-288},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic strain signal monitoring and calibration with neural network based on hierarchical orthogonal artificial bee colony},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure-augmented knowledge graph embedding for sparse
data with rule learning. <em>COMCOM</em>, <em>159</em>, 271–278. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, knowledge graphs have received considerable attention because of their ability to express rich information and their potential for use in knowledge-based reasoning. For example, they can assist in-depth knowledge discovery related to user associations, switching policies, and traffic content in mobile services . Knowledge graph embeddings project the entities and relations of knowledge graphs into vectors that are dense and low dimensional, thus allowing the complex semantic information and relations between these entities to be measured efficiently. However, traditional knowledge graph embedding methods consider only direct facts, making it difficult to achieve reasonable embedding learning of entities and relations when faced with sparse data. To settle this issue, this paper proposes a novel knowledge graph embedding method based on tensor decomposition combined with rule learning . First, rules are inferred and scored based on the initial embeddings of entities and relations. Then, new triples for sparse entities are inferred from rules with high scores. Finally, these new triples are iteratively embedded into the model. Experimental results obtained on the WN18 and FB15k datasets indicate that the proposed model achieves significantly better performance than other state-of-the-art knowledge graph embedding models when faced with sparse data.},
  archive      = {J_COMCOM},
  author       = {Feng Zhao and Haoran Sun and Langjunqing Jin and Hai Jin},
  doi          = {10.1016/j.comcom.2020.05.017},
  journal      = {Computer Communications},
  pages        = {271-278},
  shortjournal = {Comput. Commun.},
  title        = {Structure-augmented knowledge graph embedding for sparse data with rule learning},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed and low-overhead traffic congestion control
protocol for vehicular ad hoc networks. <em>COMCOM</em>, <em>159</em>,
258–270. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of new technologies and transportation modes is a crucial component for improving urban mobility. For instance, researchers have shown that vehicular networks are a promising technology to monitor and reduce traffic jams. Nevertheless, most of these solutions rely on costly external infrastructures , such as roadside units or cellular networks . In this work, we propose DisTraC, a protocol for vehicular ad hoc networks. DisTraC is a traffic congestion control protocol of low communication overhead that aims to reduce the average travel time of vehicles by using vehicle-to-vehicle (V2V) communication. The protocol is independent of external infrastructures as uses only V2V communication. Simulation results show that DisTraC outperforms other solutions published in the literature both in terms of communication overhead and capability to reduce traffic congestion.},
  archive      = {J_COMCOM},
  author       = {Roniel S. de Sousa and Azzedine Boukerche and Antonio A.F. Loureiro},
  doi          = {10.1016/j.comcom.2020.05.032},
  journal      = {Computer Communications},
  pages        = {258-270},
  shortjournal = {Comput. Commun.},
  title        = {A distributed and low-overhead traffic congestion control protocol for vehicular ad hoc networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Virtual tube storage scheme for supporting mobile sink
groups in wireless sensor networks. <em>COMCOM</em>, <em>159</em>,
245–257. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on mobile sink groups such as platoons in battlefields and firefights in disaster areas have been actively studied as a challenged and interesting issue in wireless sensor networks . For supporting mobile sink groups, the formation of effective data storage is one of the important design factors for energy-efficient and reliable data delivery to them by considering their mobility. Various data storage schemes have been proposed for mobile sink groups and they are usually categorized into two approaches: a point-based storage one and an area-based storage one. The point-based storage approach is very efficient when a mobile sink group has a small number of member sinks or it has a large-scale group region. On the other hand, the area-based storage approach only when a mobile sink group has a large number of member sink and it has a small-scale group region. In other words, these two approaches are suitable only for special cases of mobile sinks groups. Thus, this paper proposes a Virtual Tube Storage (VTS) scheme for efficiently supporting general cases of mobile sink groups in wireless sensor networks . We first present design principles of data storage and data dissemination. Then, we describe the method to efficiently construct a virtual tube storage based on the design principle of data storage. Next, we describe the process to disseminate data from a source node to a mobile sink group via the virtual tube storage based on the design principle of data dissemination. Simulation results verify that the proposed scheme achieves better performance than the existing point-based storage and area-based storage schemes in terms of energy-efficiency and reliable data dissemination.},
  archive      = {J_COMCOM},
  author       = {Yongbin Yim and Hee-Sook Mo and Cheonyong Kim and Sang-Ha Kim and Victor C.M. Leung and Euisin Lee},
  doi          = {10.1016/j.comcom.2020.05.024},
  journal      = {Computer Communications},
  pages        = {245-257},
  shortjournal = {Comput. Commun.},
  title        = {Virtual tube storage scheme for supporting mobile sink groups in wireless sensor networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decentralized adaptive indoor positioning protocol using
bluetooth low energy. <em>COMCOM</em>, <em>159</em>, 231–244. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous indoor positioning research has mainly been focused on using Wi-Fi and RFID. In recent years, researchers began to study using Bluetooth 4.0 and Bluetooth Low Energy (BLE) for indoor positioning purposes. In general, positioning techniques based on received signal strength indicator (RSSI), such as signal propagation and fingerprint, are commonly used in wireless/mobile networks. These techniques have certain limitations and tradeoff in terms of accuracy, ease of implementation and practical application/deployment. For example, both methods require a training process before deployment. In this paper, we present a decentralized BLE-based positioning protocol that does not require training before deployment. The training process can automatically be done on the fly by the anchor nodes . While the anchor nodes are broadcasting, they also scan for signals emitted by other anchors. This collaborative communication process exchanges location information and signal strength measurements between each anchor. This process builds a signal-to-distance reference list for the target node to estimate physical distance in a more accurate way. Experimentation in a real indoor environment shows that the proposed collaborative positioning method can achieve an error of 1.5 meters on average. This is generally applicable for most indoor positioning applications for locating people. Furthermore, its implementation is simple and practical, because it does not require training before positioning estimation and is adaptive to environmental changes.},
  archive      = {J_COMCOM},
  author       = {Yik Him Ho and Henry C.B. Chan},
  doi          = {10.1016/j.comcom.2020.04.041},
  journal      = {Computer Communications},
  pages        = {231-244},
  shortjournal = {Comput. Commun.},
  title        = {Decentralized adaptive indoor positioning protocol using bluetooth low energy},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rapid sensing-based emergency detection: A sequential
approach. <em>COMCOM</em>, <em>159</em>, 222–230. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upsurge of smart devices has enabled the realization of safe, efficient smart cities that improve the quality of life of their citizens. A prevalent class of smart city services that are attracting increasing attention are Smart Emergency Response and Management (SERM) systems, where sensing paradigms such as crowd sensing and IoT-centric sensing are employed to facilitate the detection of, and response to a crisis situation. In this paper, we study the detection of an abnormal change in a monitored variable through crowd sensed and heterogeneous data , where the change is suggestive of an emergency situation. We formulate our problem as a sequential change-point detection problem, where the underlying distribution of the variable changes at an unknown time. We aim to detect the change-point with minimal delay, subject to a false alarm constraint. We utilize Shiryaev’s test to construct two variants of the solution depending on the structure of the received data contributions and mobility of participating sensing elements. We conduct simulations experiments to show the performance of these variants in terms of the delay-false alarm trade-off in different scenarios.},
  archive      = {J_COMCOM},
  author       = {Rawan F. El Khatib and Nizar Zorba and Hossam S. Hassanein},
  doi          = {10.1016/j.comcom.2020.04.060},
  journal      = {Computer Communications},
  pages        = {222-230},
  shortjournal = {Comput. Commun.},
  title        = {Rapid sensing-based emergency detection: A sequential approach},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-sensor detection and control network technology based
on parallel computing model in robot target detection and recognition.
<em>COMCOM</em>, <em>159</em>, 215–221. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotics technology has become an interdisciplinary comprehensive information processing technology, and the analysis ability of unmanned robots has become an important factor to measure the intelligence of robots. On the basis of introducing the theory of multi-sensor information and the correlation of robot target detection and recognition, this paper focuses on the application of support vector machine in multi-sensor target recognition. A fusion method based on evidence theory and support vector machine is applied to target recognition, and the computational efficiency is improved by parallel computing model. The recognition performance of the traditional BP neural network and the algorithm is studied by simulation. The simulation results show that the improved algorithm has a high recognition rate under arbitrary noise, especially in large noise. The effectiveness of the improved algorithm in target detection and recognition is illustrated. At the same time, the simulation results also show that the parallel computing mode has been effectively improved.},
  archive      = {J_COMCOM},
  author       = {Pengcheng Wei and Bo Wang},
  doi          = {10.1016/j.comcom.2020.05.006},
  journal      = {Computer Communications},
  pages        = {215-221},
  shortjournal = {Comput. Commun.},
  title        = {Multi-sensor detection and control network technology based on parallel computing model in robot target detection and recognition},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PARS-SR: A scalable flow forwarding scheme based on segment
routing for massive giant connections in 5G networks. <em>COMCOM</em>,
<em>159</em>, 206–214. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 5G networks with SDN architecture, the traffic explosion and the rising of diverse service requirements lead to many challenges for 5G core networks on flexibility and scalability. In order to achieve high-speed forwarding of traffic and diversified transmission requirements in the 5G era, combined with SDN and Segment Routing, we propose a scalable flow forwarding scheme called Segment Routing based on Path Aggregation and Rule sharing (PARS-SR) to solve SDN switch flow table resource shortage problem. Traditional OpenFlow-based or MPLS-based flow forwarding scheme may lead to performance degradation due to flow-table overflowed or heavy MPLS label load incurred. PARS-SR exploits SDN, Segment Routing and intelligent path encoding algorithm to achieve a trade-off between flow table resource and MPLS label load. The proposed PARS-SR can learn the flow path information online to implement path aggregation and rule sharing by aggregating a large number of flows into a small number of flow entries based on the coincidence degree of the flow path. To find the optimal flow path aggregation scheme, we present an intelligent encoding algorithm to maximize the overall cost saving. The simulation results show that PARS-SR can effectively reduce both the number of flow entries and the MPLS label load of the packet.},
  archive      = {J_COMCOM},
  author       = {Ziyong Li and Yuxiang Hu and Tao Hu and Ruiqi Ma},
  doi          = {10.1016/j.comcom.2020.05.014},
  journal      = {Computer Communications},
  pages        = {206-214},
  shortjournal = {Comput. Commun.},
  title        = {PARS-SR: A scalable flow forwarding scheme based on segment routing for massive giant connections in 5G networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive approach for optimizing controller placement
in software-defined networks. <em>COMCOM</em>, <em>159</em>, 198–205.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-Defined Networks (SDNs) are characterized by dividing a network architecture in a data plane (i.e., any packet-relaying nodes like switches or routers) and a control plane, where specialized controllers assign forwarding decisions to the underlying data plane, and must do so in a very short timeframe. Thus, controllers play a key role in SDNs and the Controller Placement Problem (CPP) becomes a critical issue, affecting network delays and synchronization. If there are significant propagation delays between controllers and nodes, or among controllers, their ability to quickly react to network events is affected, degrading reliability. In this work, we propose a comprehensive mathematical formalization of the CPP, which constrains propagation latency and controller capacity, and determines simultaneously the minimum number of controllers, their location and the assignment of nodes to each, while keeping a balanced load distribution among controllers. As CPP is NP-hard, a heuristic approach is also presented. Simulations for 60 network scenarios show that this approach obtains balanced and resilient solutions, in negligible time, which are proven to be optimal or near optimal for 90\% of the evaluated cases.},
  archive      = {J_COMCOM},
  author       = {G. Schütz and J.A. Martins},
  doi          = {10.1016/j.comcom.2020.05.008},
  journal      = {Computer Communications},
  pages        = {198-205},
  shortjournal = {Comput. Commun.},
  title        = {A comprehensive approach for optimizing controller placement in software-defined networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cache efficient value iteration using clustering and
annealing. <em>COMCOM</em>, <em>159</em>, 186–197. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value Iteration (VI) is a powerful, though time consuming, approach to solve Markov Decision Processes (MDPs). Existing algorithms for VI incur a large number of cache misses. Motivated by the observation that, on modern computers, the cost of a cache miss is two to three orders of magnitude more than that of an arithmetic operation , we explore the possibility of improving the performance of VI by reducing the number of cache misses, possibly at the expense of increasing the number of arithmetic operations. Cache efficiency is obtained by performing VI on partitions of the MDP state space that fit in the lowest level cache of the computational platform on which the code is to run. Further performance improvement, motivated by the use of MDP partitions, is obtained using a clustering scheme to construct the partitions and an annealing schedule to converge to the target accuracy. We demonstrate experimentally that incorporating partitioning, clustering, and annealing into state-of-the-art VI software result in speedups of up to a factor of 8.1 on our computational platforms.},
  archive      = {J_COMCOM},
  author       = {Anuj Jain and Sartaj Sahni},
  doi          = {10.1016/j.comcom.2020.04.058},
  journal      = {Computer Communications},
  pages        = {186-197},
  shortjournal = {Comput. Commun.},
  title        = {Cache efficient value iteration using clustering and annealing},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Association stability and handoff latency tradeoff in dense
IEEE 802.11 networks: A case study. <em>COMCOM</em>, <em>159</em>,
175–185. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association instability is a common phenomenon in dense networks. The decision of whether or not to perform a handoff between access points in an infrastructured IEEE 802.11 network is taken exclusively by the wireless client stations. Even without mobility, static client devices may decide to migrate to another access point with the goal of improving performance. However, the criteria used to perform handoffs are not defined by the IEEE 802.11 standard and, thus, are dependent on specific vendor implementations. In this paper, we use data from a real large scale network and run experiments to demonstrate that such implementations are commonly deficient, resulting in high levels of association instability in dense environments . By analyzing the implementation used by the most common devices and conducting comparative tests in a real network, we were able to conclude that this instability, known as the “ping-pong effect”, results from the direct usage of RSSI samples which are highly variable. Also, we conclude that, despite being effective, common solutions for the ping-pong effect can cause additional delay to the handoff process, which is undesirable. Finally, we analyze the behavior of RSSI in indoor environments showing that its time series presents multimodal distribution. We argue that the findings presented in this study can help develop more stable handoff algorithms for dense wireless networks.},
  archive      = {J_COMCOM},
  author       = {Helga D. Balbi and Diego Passos and Ricardo C. Carrano and Luiz C.S. Magalhães and Célio V.N. Albuquerque},
  doi          = {10.1016/j.comcom.2020.04.059},
  journal      = {Computer Communications},
  pages        = {175-185},
  shortjournal = {Comput. Commun.},
  title        = {Association stability and handoff latency tradeoff in dense IEEE 802.11 networks: A case study},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Geo-distributed efficient deployment of containers with
kubernetes. <em>COMCOM</em>, <em>159</em>, 161–174. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software containers are changing the way applications are designed and executed. Moreover, in the last few years, we see the increasing adoption of container orchestration tools, such as Kubernetes , to simplify the management of multi-container applications. Kubernetes includes simple deployment policies that spread containers on computing resources located in the cluster and automatically scale them out or in based on some cluster-level metrics. As such, Kubernetes is not well-suited for deploying containers in a geo-distributed computing environment and dealing with the dynamism of application workload and computing resources. To tackle the problem, in this paper we present ge-kube (Geo-distributed and Elastic deployment of containers in Kubernetes), an orchestration tool that relies on Kubernetes and extends it with self-adaptation and network-aware placement capabilities. Ge-kube introduces flexible and decentralized control loops that can be easily equipped with different deployment policies . Specifically, we propose a two-step control loop, in which a model-based reinforcement learning approach dynamically controls the number of replicas of individual containers on the basis of the application response time , and a network-aware placement policy allocates containers on geo-distributed computing resources. To address the placement issue, we propose an optimization problem formulation and a network-aware heuristic, which explicitly take into account the non-negligible network delays among computing resources so to satisfy Quality of Service requirements of latency-sensitive applications. Using a surrogate CPU-intensive application and a real application (i.e., Redis), we conducted an extensive set of experiments, which show the benefits arising from the combination of elasticity and placement policies, as well as the advantages of using network-aware placement solutions.},
  archive      = {J_COMCOM},
  author       = {Fabiana Rossi and Valeria Cardellini and Francesco Lo Presti and Matteo Nardelli},
  doi          = {10.1016/j.comcom.2020.04.061},
  journal      = {Computer Communications},
  pages        = {161-174},
  shortjournal = {Comput. Commun.},
  title        = {Geo-distributed efficient deployment of containers with kubernetes},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving the security of multi-party quantum key agreement
with five-qubit brown states. <em>COMCOM</em>, <em>159</em>, 155–160.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secure quantum key agreement schemes should satisfy four security features, namely correctness, security, privacy, and fairness. Recently, Cai et al. (2018) used five-qubit Brown states to propose an efficient and flexible multi-party quantum key agreement scheme. We review and analyze the security of their protocol and we prove its inability to secure the private information of participants against a proposed strategy of collusion attacks. Also, we suggest a simple solution to close the loophole in Cai et al.’s protocol.},
  archive      = {J_COMCOM},
  author       = {Ahmed Elhadad and Safia Abbas and Hussein Abulkasim and Safwat Hamad},
  doi          = {10.1016/j.comcom.2020.05.021},
  journal      = {Computer Communications},
  pages        = {155-160},
  shortjournal = {Comput. Commun.},
  title        = {Improving the security of multi-party quantum key agreement with five-qubit brown states},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smartphone perspective on computation offloading—a survey.
<em>COMCOM</em>, <em>159</em>, 133–154. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computation offloading has emerged as one of the promising approaches to address the issues of restricted resources, leading to poor user experiences on smartphones in terms of battery life and performance when executing CPU intensive tasks. Meanwhile, an entire research domain has been initiated around this topic and several concepts have been studied touching both the smartphone and the cloud side. In this paper, we develop a categorization of fundamental aspects regarding computation offloading in heterogeneous cloud computing from the perspective of smartphone applications . We refer to heterogeneity in terms of the multitude of smartphone applications , the various uplink channels, and the variety of cloud solutions. We also survey state-of-the-art solutions for the identified categories. Finally, we conclude with a summary of the most important research challenges in making computation offloading reality.},
  archive      = {J_COMCOM},
  author       = {Quang-Huy Nguyen and Falko Dressler},
  doi          = {10.1016/j.comcom.2020.05.001},
  journal      = {Computer Communications},
  pages        = {133-154},
  shortjournal = {Comput. Commun.},
  title        = {A smartphone perspective on computation offloading—A survey},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis and design of robust guaranteed cost active queue
management. <em>COMCOM</em>, <em>159</em>, 124–132. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a simple Linear Matrix Inequality (LMI) condition for the design of stabilizing control for a class of systems whose dynamics is similar to the TCP/AQM process based on the guaranteed cost approach. Furthermore, by analyzing the cost function, an optimization procedure is derived. Then, by solving the problem, according to the optimization procedure , the controller gain guarantees a less bound of the cost function and the asymptotic stability of the system subjected to the uncertainties. Moreover, the simplest implementation procedure to overcome the implementation constraint is proposed. Finally, the engineering relevance of the theory has been evaluated with different realistic scenarios in NS3 and shows that the Guaranteed Cost Controller (GCC) scheme provides the best performance.},
  archive      = {J_COMCOM},
  author       = {Sadek Belamfedel Alaoui and El Houssaine Tissir and Noreddine Chaibi},
  doi          = {10.1016/j.comcom.2020.05.009},
  journal      = {Computer Communications},
  pages        = {124-132},
  shortjournal = {Comput. Commun.},
  title        = {Analysis and design of robust guaranteed cost active queue management},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-armed bandits for decentralized AP selection in
enterprise WLANs. <em>COMCOM</em>, <em>159</em>, 108–123. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi densification leads to the existence of multiple overlapping coverage areas, which allows user stations (STAs) to choose between different Access Points (APs). The standard WiFi association method makes STAs select the AP with the strongest signal, which in many cases leads to underutilization of some APs while overcrowding others. To mitigate this situation, Reinforcement Learning techniques such as Multi-Armed Bandits (MABs) can be used to dynamically learn the optimal mapping between APs and STAs, and so redistribute the STAs among the available APs accordingly. This is an especially challenging problem since the network response observed by a given STA depends on the behavior of the others. Therefore, it is very difficult to predict without a global view of the network. In this paper, we focus on solving this problem in a decentralized way, where STAs independently explore the different APs inside their coverage range, and select the one that better satisfy their needs. To do it, we propose a novel approach called Opportunistic ε ε -greedy with Stickiness that halts the exploration when a suitable AP is found, only resuming the exploration after several unsatisfactory association rounds. With this approach, we reduce significantly the network response dynamics, improving the ability of the STAs to find a solution faster, as well as achieving a more efficient use of the network resources. We show that to use MABs efficiently in the considered scenario, we need to keep the exploration rate of the STAs low, as a high exploration rate leads to high variability in the network, preventing the STAs from properly learning. Moreover, we investigate how the characteristics of the scenario (position of the APs and STAs, mobility of the STAs, traffic loads, and channel allocation strategies) impact on the learning process, as well as on the achievable system performance. We also show that all STAs in the network improve their performance even when only a few STAs participate in the search for a better AP (i.e., implement the proposed solution). We study a case where stations arrive progressively to the system, showing that the considered approach is also suitable in such a non-stationary set-up. Finally, we compare our MABs-based approach to a load-aware AP selection mechanism, which serves us to illustrate the potential gains and drawbacks of using MABs.},
  archive      = {J_COMCOM},
  author       = {Marc Carrascosa and Boris Bellalta},
  doi          = {10.1016/j.comcom.2020.05.023},
  journal      = {Computer Communications},
  pages        = {108-123},
  shortjournal = {Comput. Commun.},
  title        = {Multi-armed bandits for decentralized AP selection in enterprise WLANs},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green communication in IoT networks using a hybrid
optimization algorithm. <em>COMCOM</em>, <em>159</em>, 97–107. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been a huge surge in the Internet of Things (IoT) applications in recent years. The sensor nodes in the IoT network generate data continuously that directly affects the longevity of the network. Even though the potential of IoT applications are immense, there are numerous challenges like security, privacy, load balancing, storage, heterogeneity of devices, and energy optimization that have to be addressed. Of those, the energy utilization of the network is of importance and has to be optimized. Several factors like residual energy , temperature, the load of Cluster Head (CH), number of alive nodes, and cost function affect the energy consumption of sensor nodes . In this paper, a hybrid Whale Optimization Algorithm-Moth Flame Optimization (MFO) is designed to select optimal CH, which in turn optimizes the aforementioned factors. The performance of the proposed work is then evaluated with existing algorithms with respect to the energy-specific factors. The results obtained prove that the proposed method outperforms existing approaches.},
  archive      = {J_COMCOM},
  author       = {Praveen Kumar Reddy Maddikunta and Thippa Reddy Gadekallu and Rajesh Kaluri and Gautam Srivastava and Reza M. Parizi and Mohammad S. Khan},
  doi          = {10.1016/j.comcom.2020.05.020},
  journal      = {Computer Communications},
  pages        = {97-107},
  shortjournal = {Comput. Commun.},
  title        = {Green communication in IoT networks using a hybrid optimization algorithm},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An energy-efficient topology control algorithm for
optimizing the lifetime of wireless ad-hoc IoT networks in 5G and B5G.
<em>COMCOM</em>, <em>159</em>, 83–96. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless ad-hoc IoT (WAIoT) is promising in providing connections for a considerable amount of devices in the next generation (5G and beyond 5G) networks. A challenge in WAIoT networks is that most network nodes are not stable due to the limited power supply (such as a battery). In this paper, we focus on balancing node residual energy and node degree to prolong the network lifetime. We first present a statistic-based algorithm (named ED-index) for evaluating the network topology and further develop an energy-efficient topology control algorithm (named EDTC). The EDTC algorithm leverages the maximum spanning tree algorithm to build a robust backbone topology and utilizes the proposed ED-index algorithm to re-introduce some edges to the topology. We also present a graph convolutional network (GCN) based algorithm to imitate the initial EDTC algorithm through learning. In the random communication experiment, the proposed EDTC algorithm achieves two times the network lifetime than the state-of-the-art. Moreover, the GCN-based EDTC algorithm saves around 99\% optimization time than the initial EDTC algorithm when the number of network nodes is 100.},
  archive      = {J_COMCOM},
  author       = {Peizhi Yan and Salimur Choudhury and Fadi Al-Turjman and Ibrhaim Al-Oqily},
  doi          = {10.1016/j.comcom.2020.05.010},
  journal      = {Computer Communications},
  pages        = {83-96},
  shortjournal = {Comput. Commun.},
  title        = {An energy-efficient topology control algorithm for optimizing the lifetime of wireless ad-hoc IoT networks in 5G and B5G},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AdPS: Adaptive priority scheduling for data services in
heterogeneous vehicular networks. <em>COMCOM</em>, <em>159</em>, 71–82.
(<a href="https://doi.org/10.1016/j.comcom.2020.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data service scheduling is paramount in realization of Intelligent Transportation System (ITS). ITS services recon upon real-time information sharing among vehicular network components. To provide real time information services in vehicular networks, numerous challenges are imposed due to unique characteristics of such networks. For efficient information dissemination , there is a prime requirement of an adaptive scheduling algorithm for approximate vehicular dynamics information. In this work, a Dedicated Short Range Communication (DSRC) based vehicular communication model has been used for efficient data services in heterogeneous traffic environment. A novel Adaptive Priority data Service scheduling (AdPS) algorithm has been proposed to provide real-time data services, which is based on fuzzy logic request deadline estimation and request prioritization. The prioritized requests has been stored in multilevel queues according to the urgency of requests to provide simultaneous access. The proposed algorithm has been simulated for different traffic scenarios for a real city environment and its performance has been analyzed at different traffic instances. The proposed protocol ensures the real time service scheduling which provides fairness among the users.},
  archive      = {J_COMCOM},
  author       = {Abhilasha Sharma and Lalit Kumar Awasthi},
  doi          = {10.1016/j.comcom.2020.05.013},
  journal      = {Computer Communications},
  pages        = {71-82},
  shortjournal = {Comput. Commun.},
  title        = {AdPS: Adaptive priority scheduling for data services in heterogeneous vehicular networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A collaborative caching strategy for content-centric enabled
wireless sensor networks. <em>COMCOM</em>, <em>159</em>, 60–70. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Content-Centric Networking (CCN) is an efficient traffic handling technology by accessing content with its name instead of its physical location and achieving in-network caching. Indeed, CCN caching ensures high content availability, network traffic reduction, and low retrieval latency which reduces congestion and improves end-to-end delay. Moreover, it could greatly improve the efficiency of content delivery in Wireless Sensor Networks (WSNs). In this article, we propose to exploit this feature to enable CCN in WSN environments. The CCN architecture enables the content caching on each sensor-node in WSN and several research studies have been devoted to the caching management issue in such a context. However, caching the content on all the nodes is not a good strategy in terms of resource utilization. It is, therefore, necessary to determine where to cache and how to handle it in order to optimize the resources while realizing a high-interest satisfaction rate. Thus, our objective is to study existing caching strategies and propose a novel one that takes into account the node centrality and its distance from the source of the content. Through extensive simulations, we examine the performance of our scheme under different configurations and demonstrate how it outperforms the traditional caching strategies such as LCE (Leave Copy Everywhere) and LCD (Leave Copy Down).},
  archive      = {J_COMCOM},
  author       = {Ghada Jaber and Rahim Kacimi},
  doi          = {10.1016/j.comcom.2020.05.018},
  journal      = {Computer Communications},
  pages        = {60-70},
  shortjournal = {Comput. Commun.},
  title        = {A collaborative caching strategy for content-centric enabled wireless sensor networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information-centric networking solutions for the internet of
things: A systematic mapping review. <em>COMCOM</em>, <em>159</em>,
37–59. (<a href="https://doi.org/10.1016/j.comcom.2020.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the similarity between the data-driven nature of sensor and actuator networks enabling the Internet of Things (IoT) and the data-oriented model of Information-Centric Networks (ICN), recent research began investigating ICN-based IoT systems. This paper provides a thorough systematic mapping review of such research with the aim to identify their strengths, weaknesses, and open-research issues. Thus, after introducing the IoT ecosystem, its main requirements, existing IP-based solutions, and their limitations, the survey investigates the ICN-IoT associations that have been proposed in the recent literature. To do so, a new taxonomy that captures the fundamental aspects of ICN-based IoT solutions is introduced along with a multidimensional framework that provides a comprehensive multi-criteria analysis of the reviewed research. This paper also summarizes the main observations learned from the analysis and draws recommendations about open research issues that require the attention of the community. Such issues include limited standardization efforts, hybrid ICN/IP deployments, push-based communications, efficient caching schemes, and QoS solutions.},
  archive      = {J_COMCOM},
  author       = {Adel Djama and Badis Djamaa and Mustapha Reda Senouci},
  doi          = {10.1016/j.comcom.2020.05.003},
  journal      = {Computer Communications},
  pages        = {37-59},
  shortjournal = {Comput. Commun.},
  title        = {Information-centric networking solutions for the internet of things: A systematic mapping review},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint resource block and power allocation through
distributed learning for energy efficient underlay D2D communication
with rate guarantee. <em>COMCOM</em>, <em>159</em>, 26–36. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel distributed energy efficient joint resource block (RB) and discrete transmit power allocation scheme for an underlay device-to-device (D2D) network. In addition to minimizing the total transmit power of the D2D tier, the proposed scheme also ensures the rate constraints for all the cellular user equipments (CUEs) and D2D pairs. D2D pairs learn the RB and transmit power to be used by playing a game in Satisfaction Form (SF). The Efficient Satisfaction Equilibrium (ESE) of the game is shown to be the RB and discrete transmit power allocation with the lowest aggregate transmit power, in the case when the rate requirements of all the D2D pairs can be satisfied with non-zero transmit powers; else, the game is shown to converge to the K-Person Satisfaction Point (K-PSP), where the largest subset of D2D pairs are satisfied. The base station (BS) then decides to reject or accommodate the D2D pairs to ensure the rate constraints of the CUEs. The proposed scheme is established to be equivalent to the deferred acceptance (DA) algorithm applied to a many-to-one matching game. We exploit this equivalence to investigate the stability and optimality of the solution. The performance of the proposed scheme is evaluated and compared with existing schemes in the literature.},
  archive      = {J_COMCOM},
  author       = {Susan Dominic and Lillykutty Jacob},
  doi          = {10.1016/j.comcom.2020.05.005},
  journal      = {Computer Communications},
  pages        = {26-36},
  shortjournal = {Comput. Commun.},
  title        = {Joint resource block and power allocation through distributed learning for energy efficient underlay D2D communication with rate guarantee},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource allocation and location decision of a UAV-relay for
reliable emergency indoor communication. <em>COMCOM</em>, <em>159</em>,
15–25. (<a href="https://doi.org/10.1016/j.comcom.2020.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, unmanned aerial vehicle (UAV) as a half-duplex decode-and-forward (DF) relay constructs a reliable link between the indoor user and the outdoor base station (BS) in an emergency scenario. During the outdoor–indoor signal propagation , the signal passing through the wall accelerates signal fading makes the signal fading model for outdoor communication not applicable to outdoor–indoor communication and increases the outage probability of the link. We propose an outdoor–indoor signal fading model and derive a closed expression of the outage probability . In order to minimize the outage probability and ensure that each link has the same outage probability, we made a decision-making scheme and designed a location optimization-power allocation-bandwidth allocation fairness (LPB-fairness) algorithm. The decision-making scheme iteratively optimizes two sub-problems: location optimization and power-bandwidth allocation. The simulation results show that reasonable location optimization, power allocation and bandwidth allocation can ensure the minimum outage probability, and the gaps of outage probability between relay links are within 1\%.},
  archive      = {J_COMCOM},
  author       = {Jian Cui and Bo Hu and Shanzhi Chen},
  doi          = {10.1016/j.comcom.2020.05.019},
  journal      = {Computer Communications},
  pages        = {15-25},
  shortjournal = {Comput. Commun.},
  title        = {Resource allocation and location decision of a UAV-relay for reliable emergency indoor communication},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recruitment algorithms for vehicular sensor networks.
<em>COMCOM</em>, <em>159</em>, 9–14. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular crowdsensing allows the rapid, predictable movement of vehicles, as well as their wide variety of sensors, to gather sensing data in crowdsensing applications. Recruitment algorithms are used to select a subset of participants in an area that will provide the most complete coverage. In this paper, we explore two variations of the vehicular recruitment problem. In the first problem, which we refer to as the priority based vehicle recruitment problem, we consider coverage areas in which subsets must be covered. In the multisensor variation, we consider coverage areas which require different types of sensors, in which participating vehicles have one or more sensor types onboard. For each, we implement a mixed integer programming model which returns optimal solutions, as well as a heuristic for obtaining approximate solutions. In the unbudgeted priority vehicular recruitment performance evaluation, our heuristic on average obtains only 0.05\% lower utility at 1.78\% higher recruitment cost. In the budgeted runs, our heuristic obtains on average only 0.02\% lower utility at 0.59\% higher recruitment costs. In the unbudgeted multisensor vehicular recruitment performance evaluation, our heuristic obtains only 0.04\% lower utility at 1.10\% higher recruitment cost, and in the budgeted runs we obtain 11.33\% lower utility at 0.27\% higher recruitment cost.},
  archive      = {J_COMCOM},
  author       = {Fabio Campioni and Salimur Choudhury and Usman Tariq and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2020.05.012},
  journal      = {Computer Communications},
  pages        = {9-14},
  shortjournal = {Comput. Commun.},
  title        = {Recruitment algorithms for vehicular sensor networks},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Point-by-point feature extraction of artificial intelligence
images based on the internet of things. <em>COMCOM</em>, <em>159</em>,
1–8. (<a href="https://doi.org/10.1016/j.comcom.2020.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the rapid development of artificial intelligence in the Internet of Things , the establishment of the Internet of Things can promote rapid progress in the field of artificial intelligence . Traditional image detection methods use wavelet energy algorithms to divide background and edge noise, with poor resolution and low image detection accuracy. A series of problems such as slow detection speed and lack of image depth analysis exists. Aiming at the disadvantages of traditional methods, this study proposes the design of an artificial intelligence image detection system based on the Internet of Things, and uses intelligent artificial pixel feature collection technology to extract point-by-point feature of the image. This paper introducing artificial intelligence learning algorithms to the wheel detection in the workshop under the Internet of Things system, which can not only solve the problem of poor feature anti-interference and poor robustness in the traditional method, but also has important significance for the secondary development of the wheel detection system. The neural network can be used to classify wheel images while integrating other detection requirements, such as wheel defect detection and wheel number identification. The rich data resources and processing capabilities of the Internet of Things to perform feature analysis and feedback on the collected image pixels are utilized. The artificial intelligence of image synthesis module performs image conversion processing on the signal processes the feedback signal. The analysis results can complete image detection and complete artificial intelligence images. Through simulation experiments, it is proved that the design of artificial intelligence image detection system based on the Internet of Things has the advantages of high image detection rate, high recognition accuracy, stable operation, and efficient processing. The design idea has good application value.},
  archive      = {J_COMCOM},
  author       = {Chengcheng Mo and Wei Sun},
  doi          = {10.1016/j.comcom.2020.05.015},
  journal      = {Computer Communications},
  pages        = {1-8},
  shortjournal = {Comput. Commun.},
  title        = {Point-by-point feature extraction of artificial intelligence images based on the internet of things},
  volume       = {159},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A software-defined caching scheme for the internet of
things. <em>COMCOM</em>, <em>158</em>, 178–188. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting Content-Centric Networking (CCN) caching capabilities in which contents are cached on intermediate nodes can be beneficial in IoT as it can decrease the latency, reduce required transmission hops, limit traffic load on the content producer and improves availability. This article presents a new scheme for caching the contents in IoT environments. In the proposed method, devices are grouped into clusters where the cluster heads act as the cache controller . Additionally, we consider a global SDN/Cache controller (GSCC), which is responsible for orchestrating cache decisions in the whole IoT network. Such a centrally managed caching system increases the efficiency of resource usage in the IoT network. In the proposed scheme, the decision about caching the content is made in three steps: 1) determining the value of content and make decisions about caching it, 2) determining the candidate cluster, and 3) selecting candidate nodes for caching the content. In each step, several metrics are taken into account, and Multi-Criteria Decision Making (MCDM) approaches such as Analytical Hierarchy Process (AHP) and TOPSIS are used to select the best option based on considered criteria. Simulation results show that our proposed caching method can achieve an average cache hit rate of 72\% and decreases the average hop count of content retrievals by 42\%. Moreover, our results confirm the superiority of our algorithm over some existing methods in terms of different evaluation metrics .},
  archive      = {J_COMCOM},
  author       = {Sahand Khodaparas and Abderrahim Benslimane and Saleh Yousefi},
  doi          = {10.1016/j.comcom.2020.05.002},
  journal      = {Computer Communications},
  pages        = {178-188},
  shortjournal = {Comput. Commun.},
  title        = {A software-defined caching scheme for the internet of things},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling IPv6 adoption from biological evolution.
<em>COMCOM</em>, <em>158</em>, 166–177. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The transition from IPv4 to IPv6 has become inevitable and urgent. However, Google’s statistics present that the actual adoption of IPv6 has been disappointing. Multiple stakeholders are reluctant to replace IPv4 with IPv6, for they have neither the certain future nor the clear technical guideline. Therefore, we propose a novel method to investigate the dynamical competition process between IPv4 and IPv6 through a biological analogy. Some biological concepts are applied to our novel model (i.e. IPv6 adoption dynamic model). This mode systematically quantifies IPv6 adoption and the dynamic process of IPv6 transition. We apply real measured data to our modeling system. The applied results can not only predict and prove whether IPv6 transition will succeed, but also seek precise technical guidelines on various transition mechanisms. Modeling IPv6 adoption from biological evolution is an initial attempt. This method can serve as an approximate guide to the technical design and policy decision of IPv6 transition.},
  archive      = {J_COMCOM},
  author       = {Dujuan Gu and Jinhe Su and Yibo Xue and Dongsheng Wang and Jun Li and Ze Luo and Baoping Yan},
  doi          = {10.1016/j.comcom.2020.02.081},
  journal      = {Computer Communications},
  pages        = {166-177},
  shortjournal = {Comput. Commun.},
  title        = {Modeling IPv6 adoption from biological evolution},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A-CAFDSP: An adaptive-congestion aware fibonacci sequence
based data scheduling policy. <em>COMCOM</em>, <em>158</em>, 141–165.
(<a href="https://doi.org/10.1016/j.comcom.2020.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s modern era, the multi-path communication paradigm is becoming prominent in supporting multi-media applications due to its dazzling features of improved network’s resilience, reliability, and performance. Specifically, wireless (environments) networks are intended to become typically reliant on the idea of multi-pathing for efficient traffic balancing which ultimately helps in achieving good performance. Although single-path communication is a promising paradigm for supporting multi-media applications but because of its incompetence in providing significant fault-tolerance demands, it is unable to satisfy the good Quality of Service (QoS) and Quality of Experience (QoE) requirements for such applications. Hence, traffic allocation and provisioning in the Mobile Ad-hoc Networks (MANETs) environment, considering the dynamic and dissimilar wireless channel characteristics of paths’ and inadequate offered resources (i.e., buffer) in nodes over those paths’, is a challenging job. Nevertheless, current works on traffic allocation addresses the data scheduling provision without considering the dissimilar wireless channel characteristics and background traffic of paths’ respectively. To address the problem of abrupt data scheduling policy, we propose, a novel Adaptive-Congestion Aware Fibonacci Sequence based Data Scheduling Policy (A-CAFDSP) which takes care of each path’s data carrying capacity, dissimilar characteristics and background traffic intensity respectively and ultimately makes data scheduling adaptation decisions to select the efficient paths for concurrent transmissions. Indeed, A-CAFDSP includes the paradigm to concurrently distribute the data packets over multiple available network paths using Fibonacci sequence wisely and regulate the traffic of each available network path individually. Moreover, current works simply adopts and have evaluated their approach on the idealized propagation (radio) prototype without considering fading effects. However, we have evaluated our proposed method in fading environment and all the competent multiple available paths are within the interference ranges of each other hence, the inter-flow interference does exist in our simulation, which certainly gives us the correct idea that how our proposed method works in realistic wireless environment. The simulation results indicate that the performance of A-CAFDSP is better than existing conventional (single-path) and multi-path approaches in terms of average throughput, packet delivery ratio (PDR) and normalized load.},
  archive      = {J_COMCOM},
  author       = {Varun Kumar Sharma and Lal Pratap Verma and Mahesh Kumar and Ranesh Kumar Naha and Aniket Mahanti},
  doi          = {10.1016/j.comcom.2020.04.047},
  journal      = {Computer Communications},
  pages        = {141-165},
  shortjournal = {Comput. Commun.},
  title        = {A-CAFDSP: An adaptive-congestion aware fibonacci sequence based data scheduling policy},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New objective QoE models for evaluating ABR algorithms in
DASH. <em>COMCOM</em>, <em>158</em>, 126–140. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As users become more demanding with regards to the consumption of multimedia content , the importance of measuring their level of satisfaction is growing. The difficulty in terms of time and resources for assessing the Quality of Experience (QoE) has popularized the use of objective QoE models, which try to emulate human behavior regarding the playback of multimedia streaming . Some objective QoE models existing in the literature are based on the bitrate. However, the PSNR (Peak Signal-to-Noise Ratio) or VMAF (Video Multimethod Assessment Fusion) have been proved to be metrics with a closer relationship with the QoE than the bitrate. This paper proposes three new models to measure the QoE analytically in DASH (Dynamic Adaptive Streaming over HTTP) video services. The first is based on the bitrate of the displayed video segments, whereas the second and the third are based on the PSNR and VMAF of each video segment, respectively. The proposed models are compared to the ITU-T standard P.1203 as well as the bitrate-based QoE model proposed by Yin et al. Moreover, the paper presents a subjective study, which confirms the validity of the proposed models. The models are validated by using different DASH adaptation algorithms . In this sense, this paper also presents a DASH ABR (Adaptive Bitrate Streaming) algorithm called Look Ahead, which takes into account the inherent bitrate variability of the video encoding process in order to calculate, in real time, the appropriate quality level that minimizes the number of stalls during the playback.},
  archive      = {J_COMCOM},
  author       = {Ismael de Fez and Román Belda and Juan Carlos Guerri},
  doi          = {10.1016/j.comcom.2020.05.011},
  journal      = {Computer Communications},
  pages        = {126-140},
  shortjournal = {Comput. Commun.},
  title        = {New objective QoE models for evaluating ABR algorithms in DASH},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). “One-click-dialling” design principles and an intelligent
recognition algorithm based on a mobile intelligent terminal.
<em>COMCOM</em>, <em>158</em>, 116–125. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the implementation of “one-click-dialling” (OCD) based on a mobile intelligent terminal. The design principles of OCD are elucidated for the first time and the concepts of multi-layer mapping, polysemy function, and getting value, etc . are proposed. By analysing a bijection between the mobile phone card and the dialling phone, it innovatively studies two different situations about local OCD and remote roaming OCD. It constructs a functional mapping relation of OCD and establishes the functional mapping relationships in local OCD and in remote roaming OCD, respectively. It is used for recognising which city (or region) the user is in. Furthermore, the paper studies an intelligent recognition algorithm of OCD and uses it for implementing intelligent dialling. The innovative method is applied to the emergency rescue calls of existing government, society, enterprises, and individuals in China, such as 110, 119, 120, 122, government emergency office, social rescue organisations, insurance companies, emergency rescue companies starting with 400, other emergency rescue institutions, etc . The research allows users to call a certain country, no matter which city (or region) they are in when dialling, so they do not waste dialling the emergency rescue department on an intelligent mobile using one-by-one for dialling. The user can directly click the call buttons on the OCD system which have pre-designated the telephone numbers of the locate emergency rescue institution for OCD. The research has practical significance for those interested in social security management.},
  archive      = {J_COMCOM},
  author       = {Sulin Pang and Zhijian Li},
  doi          = {10.1016/j.comcom.2020.04.052},
  journal      = {Computer Communications},
  pages        = {116-125},
  shortjournal = {Comput. Commun.},
  title        = {“One-click-dialling” design principles and an intelligent recognition algorithm based on a mobile intelligent terminal},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time video stabilization via camera path correction and
its applications to augmented reality on edge devices. <em>COMCOM</em>,
<em>158</em>, 104–115. (<a
href="https://doi.org/10.1016/j.comcom.2020.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of edge devices such as mobile phones, i n the past decade, many videos have appeared on the professional video website and they are easy to retrieve. However, most of the videos captured by mobile cameras are jittery, and even motion blurred. These low-quality videos may affect the experience of users. Thus, the problem that how to eliminate the jittery issues, and make unstable video became stable one is very urgent. To enhance the stability of low-quality video, in this paper, we propose a novel method for video stabilization. The proposed method is called SimpleStab, and consists of motion estimation, trajectory smoothing, and compositing image. The SimpleStab is not only able to process offline videos but also can deal with live video streaming due to the novel architecture. We conduct a comprehensive experiment on the benchmarking dataset and make comparison with the state-of-the-art approaches. Experimental results show that the performance of SimpleStab is superior to the state-of-the-art methods.},
  archive      = {J_COMCOM},
  author       = {Mingwei Cao and Liping Zheng and Wei Jia and Xiaoping Liu},
  doi          = {10.1016/j.comcom.2020.05.007},
  journal      = {Computer Communications},
  pages        = {104-115},
  shortjournal = {Comput. Commun.},
  title        = {Real-time video stabilization via camera path correction and its applications to augmented reality on edge devices},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IOT and cloud computing based parallel implementation of
optimized RBF neural network for loader automatic shift control.
<em>COMCOM</em>, <em>158</em>, 95–103. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key issues in automatic shift control of V-type cyclical loaders is determining how to find the best gear for the current conditions according to a certain mapping relation , but this complex and nonlinear mapping is difficult to express by a mathematical relation. However, to solve such nonlinear problems , a radial basis function (RBF) neural network is the best choice. In this paper, a certain type of wheel loader is taken as the research object, and an RBF neural network algorithm based on an improved genetic algorithm (GA) optimization is proposed. The global search ability of the GA is improved by adaptively adjusting the crossover probability and mutation probability. The RBF neural network expansion coefficient is optimized by an improved GA. Using industrial IOT technology, an optimized RBF neural network based on Map-Reduce on a cloud computing cluster is designed. The diesel engine computer and transmission computer on the loader are integrated to achieve dual-processor distributed parallel data processing and calculation. Then the loader automatic variable speed control algorithm model of improved GA optimized RBF neural network based on IOT cloud computing is established. The network model is trained and simulated using real vehicle automatic shift test data. The simulation results show that the improved GA-RBF neural network algorithm can achieve a correct recognition rate of 97.92\%. The error matrix norm reaches the minimum value when the algorithm is iterated to the 17th generation. The improved algorithm has the advantages of a high gear recognition rate, fast convergence speed and strong real-time shift performance and is an effective new shift control method . The test results show that the shift boost time is less than 0.15 s and has a certain gradient. Compared with the manual shift process performed in the past, some improvements are achieved in the optimal shift time, shift response speed and shift quality. Compared with the traditional single computer based on serial training RBF neural network learning algorithm, whether it is Great progress has been made in convergence speed, training time, recognition rate, and data processing capabilities. Through the simulation and test, the validity of the intelligent shift control method of the improved GA optimized RBF neural network based on IOT cloud computing is verified. It has better engineering application value.},
  archive      = {J_COMCOM},
  author       = {Guanghua Wu and Wenxing Ma and Chunbao Liu and Songlin Wang},
  doi          = {10.1016/j.comcom.2020.04.053},
  journal      = {Computer Communications},
  pages        = {95-103},
  shortjournal = {Comput. Commun.},
  title        = {IOT and cloud computing based parallel implementation of optimized RBF neural network for loader automatic shift control},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Suppressed k-anonymity multi-factor authentication based
schmidt-samoa cryptography for privacy preserved data access in cloud
computing. <em>COMCOM</em>, <em>158</em>, 85–94. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security and privacy-preservation is a significant problem to be solved in the cloud when accessing data services . The existing authentication technique verifies the client identity using single authentication factor . But, the performance of conventional single factor authentication technique is not efficient since the client’s sensitive information is highly intrusive and exposed to third parties. In order to overcome these limitations, a novel multifactor authentication called Suppressed K-Anonymity Multi-Factor Authentication Based Schmidt-Samoa Cryptography (SKMA-SC) technique is proposed. The SKMA-SC technique comprises three key processes namely registration, authentication and data access. During the registration phase, the clients register their personal identification information’s and securely stores it in the cloud server (CS) with support of suppression method. This helps for SKMA-SC technique to preserve the client sensitive information’s from adversaries or third parties in a cloud environment. During the authentication phase, SKMA-SC technique validates the identity of clients by considering multifactor such as password, one-time token and conditional attributes. At last in the data access phase, SKMA-SC technique allows the clients to get requested data services when she or he is authorized by performing Schmidt-Samoa data encryption/decryption process . From that, SKMA-SC technique avoids illegal access from the unauthorized party over insecure communications in a cloud environment with a lower amount of time. Result analysis of SKMA-SC technique is carried out with the metrics authentication accuracy (AA), computational complexity (CC) and privacy-preserving rate (PPR) with different number of clients and cloud data. The experimental result proves that SKMA-SC technique enhances the PPR and lessens the CC of authentication as evaluated with state-of-the-art works.},
  archive      = {J_COMCOM},
  author       = {K. Mohana Prabha and P. Vidhya Saraswathi},
  doi          = {10.1016/j.comcom.2020.04.057},
  journal      = {Computer Communications},
  pages        = {85-94},
  shortjournal = {Comput. Commun.},
  title        = {Suppressed K-anonymity multi-factor authentication based schmidt-samoa cryptography for privacy preserved data access in cloud computing},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource scheduling for piano teaching system of internet of
things based on mobile edge computing. <em>COMCOM</em>, <em>158</em>,
73–84. (<a href="https://doi.org/10.1016/j.comcom.2020.04.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective operation of the piano teaching system of the Internet of Things requires the effective support of virtualization technology. In particular, on the basis that the edge computing standards and systems are not yet mature, the resource scheduling problem of edge computing needs to be studied from the actual point of view. In order to improve the effective operation of the piano teaching system of Internet of Things , this study analyzes the resource scheduling of delay-sensitive applications, sets the resource scheduling mode based on the space–time difference of the edge container load in a multi-cluster environment, and proposes a cross-cluster scheduling strategy. Simultaneously, this study uses simulation experiments to analyze the performance of the strategy proposed in this paper. The research results show that the strategy proposed in this paper can perform delay-insensitive application scheduling during system operation, achieve multi-cluster collaborative scheduling goals, and make the load between clusters more balanced.},
  archive      = {J_COMCOM},
  author       = {Yu Xia},
  doi          = {10.1016/j.comcom.2020.04.056},
  journal      = {Computer Communications},
  pages        = {73-84},
  shortjournal = {Comput. Commun.},
  title        = {Resource scheduling for piano teaching system of internet of things based on mobile edge computing},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis and research on network security and privacy
security in ubiquitous electricity internet of things. <em>COMCOM</em>,
<em>158</em>, 64–72. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large-scale power outages caused by cyberattacks have occurred frequently, and the information security situation has become increasingly severe. Network security in the power and energy fields is directly related to the power supply and power security, and it should not be underestimated. The present research work focuses on the analysis of network security and privacy security in the ubiquitous electric IoT environment. This article explains the concepts and architecture of network security in the ubiquitous electric Internet of Things (IoT) environment. Based on the analysis of the ubiquitous electric IoT network development trends and technical requirements, this study proposes smart meters and acquisitions suitable for smart grid information acquisition systems. Lightweight two-way device authentication protocol . The protocol is based on the shared security key and random numbers to authenticate the identity of both parties in the communication. The security key embedded in the chip of the device is used to determine the legitimacy of the identity of the access device, avoids the use of third-party services such as certificates, and effectively preventing man-in-the-middle attacks and repeated. The launch of attacks ensures the reliability of the system. The experiments in present work show that the time-consuming time of lightweight data encryption and decryption XOR is 1/2 of the time of a typical DES algorithm, and 1/900 of the time of an RSA algorithm. The efficiency is significantly better than DES and RSA, which is consistent with industrial control systems . Need for timely communication.},
  archive      = {J_COMCOM},
  author       = {Rui Hou and Guowen Ren and Chunlei Zhou and Hongxuan Yue and Huan Liu and Jiayue Liu},
  doi          = {10.1016/j.comcom.2020.04.019},
  journal      = {Computer Communications},
  pages        = {64-72},
  shortjournal = {Comput. Commun.},
  title        = {Analysis and research on network security and privacy security in ubiquitous electricity internet of things},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Channel allocation and ultra-reliable communication in CRNs
with heterogeneous traffic and retrials: A dependability theory-based
analysis. <em>COMCOM</em>, <em>158</em>, 51–63. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current research efforts on Fifth Generation (5G) of wireless communication systems have identified the need for large extent improvements in accessibility and reliability of communication services. In this respect, Cognitive Radio (CR) has been envisioned as a key 5G enabler that allows dynamic spectrum access without causing interference to licensed (primary) users and can tackle the challenge of ultra reliable communication. Channel failures, which are generally caused due to hardware and software failure and/or due to intrinsic features such as fading and shadowing, can easily result in network performance degradation . In cognitive radio networks (CRNs), the connections of unlicensed (secondary) users are inherently vulnerable to breaks due to channel failures as well as licensed users’ arrivals. To explore the advantages of channel reservation and retrial phenomenon on performance improvement in error-prone channels, we propose and analyze dynamic spectrum access (DSA) scheme by also taking balking and reneging behavior into account. Moreover, since 5G networks should comprise heterogeneous applications that may have different Quality of Service (QoS), thus the present study facilitates the arrival of heterogeneous secondary users with access privilege variations. In addition, most previous works have studied the stationary performance of CRNs, however, those may not be adequate in practice, notably when the time horizon of operations is finite. This paper investigates the transient dynamics from the perspectives of dependability theory in CRNs. Furthermore, the whole system is modeled using a multi-dimensional continuous time Markov chain (CTMC) and numerical results illustrate the potential of the proposed scheme to achieve major gains in the performance of error-prone CRNs.},
  archive      = {J_COMCOM},
  author       = {Shruti and Rakhee Kulshrestha},
  doi          = {10.1016/j.comcom.2020.04.055},
  journal      = {Computer Communications},
  pages        = {51-63},
  shortjournal = {Comput. Commun.},
  title        = {Channel allocation and ultra-reliable communication in CRNs with heterogeneous traffic and retrials: A dependability theory-based analysis},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource provisioning towards OPEX optimization in
horizontal edge federation. <em>COMCOM</em>, <em>158</em>, 39–50. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy consumption is a key performance metric in multi-access edge computing (MEC) system. Therefore, minimizing consumed energy cost is critically essential. The 5G networks deal with edge computing resources so that the operator would face with power supply limitation. Therefore, it may not be able to provide sufficient resources to ever-increasing user’s requests. One way to compensate such limitation is to form horizontal edge federation ( HEF ) so that all participant can share the resource capacities as well as request workloads. Energy efficient and ultra-low latency HEF involves the setting of critical factor in each participant: offloading ratios. The decided offloading ratios must provide satisfactory service level to meet latency and physical resource types capacity constraints demanded by requests. Our proposed problem is an energy efficient operational cost ( e-OPEX ) optimization problem . In this paper, we formulate it as a mixed integer linear program and demonstrate that the problem is NP-hard and proposed a federated multidimensional fractional knapsack based algorithm ( FMFK ) as our approach. The result shows that the horizontal edge federation based on the FMFK performs better and saves the more e-OPEX as well as serving more input requests compare with the non-federation approach. The experimental results show that our approach save about 40\% of e-OPEX specially for high latency sensitive application requests in hotspot zone. It shows around 50\% e-OPEX saving in the case of high computation unit cost compare with non-federation approach.},
  archive      = {J_COMCOM},
  author       = {Hojjat Baghban and Ching-Yao Huang and Ching-Hsien Hsu},
  doi          = {10.1016/j.comcom.2020.04.009},
  journal      = {Computer Communications},
  pages        = {39-50},
  shortjournal = {Comput. Commun.},
  title        = {Resource provisioning towards OPEX optimization in horizontal edge federation},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent algorithm of geotechnical test data based on
internet of things. <em>COMCOM</em>, <em>158</em>, 32–38. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the geotechnical engineering geological survey industry, geotechnical test data is the basic data for analyzing and evaluating geotechnical engineering geology, forming reports, graphics, and survey reports. It plays an important role in the calculation of the bearing capacity, deformation calculation and physical and mechanical characteristics of the foundation soil. The purpose of this article is to solve the problems of tedious, inefficient and error-prone data collection, processing and analysis of geotechnical test data in the geotechnical and geological surveying industry of geotechnical engineering. By using the BP neural algorithm and selecting the intelligent algorithm, the SVM is used to solve the sample problem. The algorithm establishes an intelligent algorithm for geotechnical test data based on the Internet of Things . Then take the geological characteristics of the Ganjiang River Basin as an example, analyze the geotechnical test data to verify the feasibility of the intelligent algorithm for data analysis. The research results show that the algorithm realizes the automatic collection and processing of geotechnical test data, reduces the tester’s workload and the influence of human factors on the test results, makes up for the shortcomings of traditional acquisition algorithm hardware fixation, and solves the problem of simultaneous multitasking. Difficult problems have promoted the development of innovative experiments.},
  archive      = {J_COMCOM},
  author       = {Yawei Ma and Guihong Guo},
  doi          = {10.1016/j.comcom.2020.04.028},
  journal      = {Computer Communications},
  pages        = {32-38},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent algorithm of geotechnical test data based on internet of things},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge caching and computing in 5G for mobile augmented
reality and haptic internet. <em>COMCOM</em>, <em>158</em>, 24–31. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying cache and computing resources in 5G mobile communication networks is considered an important way to reduce network transmission delay and redundant content transmission, improve content distribution efficiency and network computing processing capabilities. Through the construction of 5G user experience models for mobile augmented reality and tactile internet, the subjective expected experience of 5G users in mobile augmented reality applications is investigated. Based on the experimental results, the composition of mobile augmented reality, and the factors that affect 5G user, mobile 5G user experience model for augmented reality is as a design goal for mobile augmented reality. And research on mobile edge cloud computing powered by renewable energy. Based on the analysis of renewable energy, a 5G user computing task delay and power grid power consumption minimization model was established. It is decomposed into two sub-problems of computational resource allocation and task placement using alternating optimization. The sub-problems of computing tasks under renewable energy supply are obtained by solving the sub-problems. The experimental results show that the offload mode proposed in this paper is superior to the other two modes when the processing ratio before and after the task is less than 1, and the user contact frequency is greater than 0.0014. At the same time, it is obtained that the service node with higher mobility and larger computing power is allocated. The more workload, the more energy can be reduced in the network, thereby improving the performance of the system.},
  archive      = {J_COMCOM},
  author       = {Yuan Cheng},
  doi          = {10.1016/j.comcom.2020.04.054},
  journal      = {Computer Communications},
  pages        = {24-31},
  shortjournal = {Comput. Commun.},
  title        = {Edge caching and computing in 5G for mobile augmented reality and haptic internet},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Sparse code multiple access for downlink multiple access of
5G wireless networks. <em>COMCOM</em>, <em>158</em>, 17–23. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile data traffic as the two main forces for the development of future communications, mobile Internet and Internet of Things give the fifth generation of mobile communications (5G) unlimited possibilities and prospects. A large number of mobile device access and shortage of spectrum resources are also issues that 5G needs to face. Based on the understanding of wireless communication multiple access, a low complexity FPGA implementation solution based on 5G wireless communication sparse code multiple access system is proposed, and the synthesizable Verilog language is used in QuarLusII and ModelSim platforms. The integrated design of the circuit and the FPGA verification are completed, and the results prove that the design is complete and can be used in practice. In the scenario of downlink multiple access, a high-performance blind detection algorithm based on sparsity constraints is also proposed. Considering the sparsity of the system, a corresponding mathematical model is established, and a probability parameter is used to characterize the sparsity of the system, thereby approaching the maximum posterior probability detection performance. In addition, using the sparsity of the system, we developed a constrained detection and derived a priori metric, thereby reducing complexity. Through verification, the performance of the blind detection algorithm proposed in this paper can approach MAP detection, and has significant gains in performance and complexity compared to traditional SD algorithms.},
  archive      = {J_COMCOM},
  author       = {Linsheng Zhang},
  doi          = {10.1016/j.comcom.2020.04.022},
  journal      = {Computer Communications},
  pages        = {17-23},
  shortjournal = {Comput. Commun.},
  title        = {Sparse code multiple access for downlink multiple access of 5G wireless networks},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal data offloading via an ADMM algorithm in mobile ad
hoc cloud with malicious resource providers. <em>COMCOM</em>,
<em>158</em>, 10–16. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offloading has been widely adopted as an effective technique to overcome the processing and computation limitation in mobile networks. In this paper, a utility maximization model of mobile ad hoc environment with some malicious resource providers (RPs) is built. The price incentive mechanism obtained by solving the model can effectively promote RPs to share their idle resources to resource buyer (RB). To identify the malicious RPs, the mechanism of identification and processing the inaccurate data is designed and completed by RB. Combined with this mechanism, we propose a distributed optimization algorithm based on modified alternating direction method of multipliers (ADMM) algorithm to realize the maximum utility of the overall system. Finally, through comparative analysis, the simulation results verify the feasibility of the proposed distributed optimization algorithm and the necessity of identifying malicious RPs.},
  archive      = {J_COMCOM},
  author       = {Zongyao Wang and Xue Feng and Hongbo Zhu and Changping Liu},
  doi          = {10.1016/j.comcom.2020.04.040},
  journal      = {Computer Communications},
  pages        = {10-16},
  shortjournal = {Comput. Commun.},
  title        = {Optimal data offloading via an ADMM algorithm in mobile ad hoc cloud with malicious resource providers},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient network path reconfiguration for industrial
field data. <em>COMCOM</em>, <em>158</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy efficiency and reliability are vital design requirements of recent industrial networking solutions. Increased energy consumption, poor data access rates and unpredictable end-to-end data access latencies are catastrophic when transferring high volumes of critical industrial data in strict temporal deadlines. These requirements might become impossible to meet later on, due to node failures, or excessive degradation of the performance of wireless links . In this paper, we focus on maintaining the network functionality required by the industrial, best effort, low-latency applications after such events, by sacrificing latency guarantees to improve energy consumption and reliability. We avoid continuously recomputing the network configuration centrally, by designing an energy efficient, local and distributed path reconfiguration method. Specifically, given the operational parameters required by the applications, our method locally reconfigures the data distribution paths, when a network node fails. Additionally, our method also regulates the return to an operational state of nodes that have been offline in the past. We compare the performance of our method through simulations to the performance of other state of the art protocols and we demonstrate performance gains in terms of energy consumption, data delivery success rate, and in some cases, end-to-end data access latency. We conclude by providing some emerging key insights which can lead to further performance improvements.},
  archive      = {J_COMCOM},
  author       = {Theofanis P. Raptis and Andrea Passarella and Marco Conti},
  doi          = {10.1016/j.comcom.2020.04.048},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient network path reconfiguration for industrial field data},
  volume       = {158},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Precise localization of RFID tags using hyperbolic and
hologram composite localization algorithm. <em>COMCOM</em>,
<em>157</em>, 451–460. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thousands of items are stored in libraries, archives and supermarkets, it usually takes a long time to find what we want in thousands of items. How to achieve precise localization is particularly important. We present a fine-grained Radio Frequency Identification (RFID) positioning method to help us find the items we want. In order to achieve high-precision positioning of RFID tags, we propose Hyperbolic and Hologram Composite (HHC) localization algorithm, which determines the positioning candidate set by hyperbolic intersection, thereby reducing the positioning delay, and then use the holographic positioning to filter the candidate set. We use multi-frequency holography positioning technology to reduce the influence of the reader’s own inaccurate positioning, and use multipath suppression technology to reduce the interference of multipath in the environment, finally achieves higher precision positioning. The experimental results show that the average calculation time of one positioning of our HHC positioning system is 10.3 ms, and 90\% of the positioning error margin is below 4.8 cm, which realizes high-precision and low-delay positioning.},
  archive      = {J_COMCOM},
  author       = {Fangfang Xue and Jumin Zhao and Dengao Li},
  doi          = {10.1016/j.comcom.2020.04.013},
  journal      = {Computer Communications},
  pages        = {451-460},
  shortjournal = {Comput. Commun.},
  title        = {Precise localization of RFID tags using hyperbolic and hologram composite localization algorithm},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart city oriented remote sensing image fusion methods
based on convolution sampling and spatial transformation.
<em>COMCOM</em>, <em>157</em>, 444–450. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the existing problem of losing spatial details and spectral information in remote sensing image fusion, a method of remote sensing image fusion based on convolution sampling transformation is proposed. Firstly, two images to be fused are convoluted, sampled, filtered hierarchically, and decomposed into different sub-images at different levels. Next, those sub-images are fused according to the corresponding locations, and then reconstructed to be a fused image. For images with more complex terrains and objects, the requirements for spatial details and spectral information are higher. So we propose to further transform the fused image and panchromatic image in space. The first component of the former is replaced by that of the latter. Finally, the fused image is obtained after performing inverse transformation. The experimental results show that the fusion effect of two proposed methods is better than that of traditional image fusion algorithms , such as PCA transform, HIS transform, wavelet transform and so on. Compared with the previous method, the latter method has higher resolution but less spectral information in the case of more complex terrains and objects for two proposed methods. They are effective remote sensing image fusion methods.},
  archive      = {J_COMCOM},
  author       = {Shulei Wu and Huandong Chen},
  doi          = {10.1016/j.comcom.2020.04.010},
  journal      = {Computer Communications},
  pages        = {444-450},
  shortjournal = {Comput. Commun.},
  title        = {Smart city oriented remote sensing image fusion methods based on convolution sampling and spatial transformation},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart traffic monitoring system using unmanned aerial
vehicles (UAVs). <em>COMCOM</em>, <em>157</em>, 434–443. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road traffic accidents are one of the leading causes of deaths and injuries in the word resulting in the not only loss of precious human lives but also affect the economic resources. According to the World Health Organization (WHO), over 1.35 million people are killed, and over 50 million are injured due to road accidents throughout the world. Unfortunately, as compared to other developing countries with the same ratio of vehicle possession, in Saudi Arabia, the fatalities and injuries are much higher. Every year around 7000–9000 people die, and over 39000 serious injuries occur in road accidents. There is at least one accident happens every minute in Saudi Arabia. To decrease the road traffic accidents , fatalities, and injuries caused by them, the Saudi Ministry of Interior came up with new rules, regulations, and hefty fines. Also, they introduced a new traffic system called the SAHER system. Still, due to the static nature and other limitations of the system, the drivers found loopholes and ways to deceive the system to avoid the fines and not being caught by the system. The most common violation includes excess speed, abrupt deceleration, and distracted driving . In this paper, we propose a smart traffic surveillance system based on Unmanned Aerial Vehicle (UAV) using 5G technology. This traffic monitoring system covers the existing limitations of the SAHER system deployed in KSA. By overcoming the existing limitations and loopholes of the SAHER system, it is observed that the number of accidents and fatalities can be decreased. The projected results show that those violations when to overcome, the number of accidents per year falls to 299,317 leading to 4,868 deaths and 33,199 injuries for 1 st st year, and in the next five years the number of deaths and will be decreased to 3,745 and injuries to 16,600 based on the current data available. We aim the system will further reduce the number of accidents and fatalities and injuries caused by it.},
  archive      = {J_COMCOM},
  author       = {Navid Ali Khan and N.Z. Jhanjhi and Sarfraz Nawaz Brohi and Raja Sher Afgun Usmani and Anand Nayyar},
  doi          = {10.1016/j.comcom.2020.04.049},
  journal      = {Computer Communications},
  pages        = {434-443},
  shortjournal = {Comput. Commun.},
  title        = {Smart traffic monitoring system using unmanned aerial vehicles (UAVs)},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic stone’s blind source separation with
application to channel estimation and multi-node identification in MIMO
IoT green communication and multimedia systems. <em>COMCOM</em>,
<em>157</em>, 423–433. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By the increasing growth of the Internet of Things (IoT) which provides interconnection and communications between electronic devices and corresponding sensors, a large volume of data is exchanged by multi-input multi-output (MIMO) telecommunication systems . In the case of IoT, reducing the data volume by removing the data redundancy results in more green communication by less power consumption for data transmission and less required storage memory. An approach to avoid the pilot data thus having less redundant data is using blind techniques . This research work presents an improvement to Stone’s blind source separation (BSS) precision, robustness, and computation load and its application to blind MIMO IoT interference channel estimation, multi-nodes IoT data detection, separation and identification in a MIMO-OFDM IoT network. Stone’s BSS is based on complexity conjecture indicating the independent sources have higher predictability than the mixtures. The presented improvement to Stone’s BSS is by a probabilistic modification to the short-term predictability merit by acquiring the prediction coefficients proportional to probability weights which follow a super Gaussian distribution assumption for sources. The probabilistic modification to Stone’s BSS (P-Stone) makes it maximally compatible with a pre-specified probability distribution model, and thereof the signal recovery is not only due to predictability maximization, but it is also inherent to increasing non-gaussianity which results in more independent recoveries, and less dependent on serial dependency of sources. Despite the Stone’s BSS, the proposed merit function does not need any long-term predictor; thus, it achieves around fifty times lower complexity load using just short-term predictors. The superiority of P-Stone to Stone BSS, AMUSE, and SOBI as well-known second-order techniques has been statistically evaluated and clarified through the experiments over MIMO-IoT networks of different combinations. As well, the comparative analysis over multimedia mixtures of music, speech, and images demonstrates its efficiency dominance.},
  archive      = {J_COMCOM},
  author       = {Mahdi Khosravy and Neeraj Gupta and Nilesh Patel and Nilanjan Dey and Naoko Nitta and Noboru Babaguchi},
  doi          = {10.1016/j.comcom.2020.04.042},
  journal      = {Computer Communications},
  pages        = {423-433},
  shortjournal = {Comput. Commun.},
  title        = {Probabilistic stone’s blind source separation with application to channel estimation and multi-node identification in MIMO IoT green communication and multimedia systems},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A method for determining parameter weight early warning
model based on reinforcement learning. <em>COMCOM</em>, <em>157</em>,
417–422. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problem of low efficiency of early warning in public security emergencies, this paper proposes a method for determining parameter weight in public events early warning model which was based on reinforcement learning . Firstly, using the calibrated conflict early warning label, using reinforcement learning algorithm to build the public early warning event model; secondly, through iterative training to obtain the arrival path of the agent to the abnormal sequence, that is, the public early warning event; finally, by analyzing the weight parameters in the neural network , to determine the early warning event. Simulation showed that under this algorithm, convergence happened when the number of steps was in the range from 500 to 800, 37.5\% smaller than that when using the original data. This result of the experiment demonstrated that this method greatly improved the efficiency of early warning for public incidents.},
  archive      = {J_COMCOM},
  author       = {Meiyu Sun ( Doctor )},
  doi          = {10.1016/j.comcom.2020.04.044},
  journal      = {Computer Communications},
  pages        = {417-422},
  shortjournal = {Comput. Commun.},
  title        = {A method for determining parameter weight early warning model based on reinforcement learning},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on CLPKC-IDPKC cross-domain identity authentication
for IoT environment. <em>COMCOM</em>, <em>157</em>, 410–416. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the distribution of IoT nodes and the characteristics of information transmission, the traditional cross-domain signature scheme cannot meet the requirements of real-time information confidentiality in the IoT . Based on this, this paper proposes a cross-domain based on CLPKC and IDPKC . Signcryption authentication mechanism, which is based on the computational Diffie–Hellman problem (CDHP, Computational Diffie–Hellman problem) and the modification of Diffie–Hellman (mICDH, modification Inverse Computational Diffie–Hellman) under the random oracle model Under the assumption of the problem, the scheme satisfies confidentiality, is not styling and anonymity. The scheme has a fast computing speed, realizes fast identity authentication under the premise of satisfying data confidentiality , and supports different encryption system environments in which the communication parties are located, which is more suitable for the actual communication characteristics of the IoT environment.},
  archive      = {J_COMCOM},
  author       = {Quan Liu and Bei Gong and Zhenhu Ning},
  doi          = {10.1016/j.comcom.2020.04.043},
  journal      = {Computer Communications},
  pages        = {410-416},
  shortjournal = {Comput. Commun.},
  title        = {Research on CLPKC-IDPKC cross-domain identity authentication for IoT environment},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High concurrency massive data collection algorithm for IoMT
applications. <em>COMCOM</em>, <em>157</em>, 402–409. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The symbiotic development of machine learning (ML) and artificial intelligence (AI) is amplifying the value of the Internet of Medical Things (IoMT). Doctors are able to reach actionable conclusions faster and more reliably when dealing with large volumes of streaming data from networked medical devices. However the Internet of Things (IoT) or sensor network has a large number of base stations transmitting data to the data center server, the data center server will face challenges in collecting, parsing , and processing data. Based on the existing technical solutions, when the number of wireless sensor network base stations is large, the data collection of the IoMT system will have a concurrent bottleneck, which will cause the data collection failure and have a catastrophic impact on the application of the IoMT. This paper proposes a highly concurrent and massive data collect algorithm for IoMT applications. This algorithm uses the principle of separation of reception and processing, distributed parallel processing and multi-threading technology, and combines the highly concurrent data transmission channel provided by TCP/IP to provide a set of independent data receiving components. This component receives the data of the IoT base station, and then simply processes the data and puts it into the distributed message system to complete the sensor data receiving function. It also provides a data processing cluster. Each node of the cluster starts multiple data processing unit, each data processing unit separately obtains sensor data from the distributed message system, processes the data, and delivers the processing results to the application. The experimental results show that the algorithm proposed in this paper has a high ability of parallel collection of IoMT data.},
  archive      = {J_COMCOM},
  author       = {Jianhua Peng and Ken Cai and Xiaojing Jin},
  doi          = {10.1016/j.comcom.2020.04.045},
  journal      = {Computer Communications},
  pages        = {402-409},
  shortjournal = {Comput. Commun.},
  title        = {High concurrency massive data collection algorithm for IoMT applications},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust control algorithm and simulation of networked control
systems. <em>COMCOM</em>, <em>157</em>, 394–401. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The network control system has low cost, resource sharing, remote operation and control,it also has high diagnostic capabilities and is easy to install and maintain. This can effectively reduce the weight and volume of the system, and increase the flexibility and reliability of the system. Therefore, it is widely used in equipment manufacturing, industrial automation, aerospace and medical care. However, the introduction of the network has brought a lot of new uncertainties, such as packet loss , delay, etc., which pose new challenges to the classic control problem. Therefore, this study combines the robust control theory to reasonably model the network control system. By introducing various performance indicators, the robustness and stability of the system are studied in coordination, and the internal relationship between performance indicators and network factors is established. This study also focuses on reducing the conservativeness of the results, and proposes new stability conditions and controller design methods for networked control systems . By using an improved time-delay system analysis method to derive the sufficient conditions for the existence of robust guaranteed-performance controllers, the parameters of the sub-optimal performance controller parameters are solved by the algorithm.},
  archive      = {J_COMCOM},
  author       = {Zhouping Yin and Keming Yu and Yuanzhi Wang},
  doi          = {10.1016/j.comcom.2020.04.046},
  journal      = {Computer Communications},
  pages        = {394-401},
  shortjournal = {Comput. Commun.},
  title        = {Robust control algorithm and simulation of networked control systems},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Behavioral feature recognition of multi-task compressed
sensing with fusion relevance in the internet of things environment.
<em>COMCOM</em>, <em>157</em>, 381–393. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of electronic and communication technologies, wireless sensors have been widely used. Human behavior recognition based on micro-inertial sensor is an important application of the Internet of Things , and it has received increasing attention. This paper first introduces the theory of compressed sensing and sparse representation to solve the problem of sensor behavior classification. Aiming at the problem of multi-sensor behavior recognition, an effective result fusion method is proposed. By analyzing the multi-task behavior recognition process, the residual model is introduced to effectively integrate the multi-task results and fully exploit the data information. Secondly, in view of the fact that the characteristics of sensor behavior recognition mostly use the time–frequency domain characteristics of digital signal processing , this paper proposes an association feature. In a multi-sensor system, there is a correlation between sensor data at different locations according to human behavior characteristics . The combination of different position sensor information better reflects the human motion characteristics. This feature can effectively mine the potential information in the existing data and improve the behavior recognition rate. Finally, in order to enhance the robustness of the wearable sensing behavior recognition system, the system structure is optimized and analyzed, and the fusion problem of multi-sensor nodes is further studied. In the established decision fusion framework, the adaptive logarithmic optimization pool is used to make decision fusion for the classification posterior probability output of each node, and finally the class of behavior is discriminated. The experimental results show that the proposed method can effectively improve the performance of behavior recognition.},
  archive      = {J_COMCOM},
  author       = {Zhiyong Sun and Junyong Ye and Tongqing Wang and Shijian Huang and Jin Luo},
  doi          = {10.1016/j.comcom.2020.04.012},
  journal      = {Computer Communications},
  pages        = {381-393},
  shortjournal = {Comput. Commun.},
  title        = {Behavioral feature recognition of multi-task compressed sensing with fusion relevance in the internet of things environment},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GROSE: Optimal group size estimation for broadcast proxy
re-encryption. <em>COMCOM</em>, <em>157</em>, 369–380. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose GROSE — a scheme to determine the optimal group size of the receiver in Broadcast Proxy Re-encryption. GROSE uses the Rubinstein–Ståhl bargaining approach, so that both the sender and the receiver are mutually benefited and the total payoff increases. Proxy re-encryption is an important scheme to send cloud data securely to another user. For secured sharing of data to more than one users, the concept of broadcast proxy re-encryption was introduced. However, it poses an overhead on the receiver, if the receiver group is large, as each of the receivers in the group has to calculate the additional expensive algebraic operations , which linearly increases with the number of users in the receiver group. We model the problem using a bargaining perspective, and address it as the Rubinstein–Ståhl bargaining game for finite version of the game and then extend it to the infinite horizon version of it. We define the payoff of the sender and the receiver, and discuss how the payoff depends on different factors. Finally, we implement GROSE and compare it with the previously proposed schemes to depict the efficiency of GROSE. It is observed that GROSE is more efficient than the traditional proxy re-encryption and broadcast proxy re-encryption schemes.},
  archive      = {J_COMCOM},
  author       = {Sumana Maiti and Sudip Misra},
  doi          = {10.1016/j.comcom.2020.03.052},
  journal      = {Computer Communications},
  pages        = {369-380},
  shortjournal = {Comput. Commun.},
  title        = {GROSE: Optimal group size estimation for broadcast proxy re-encryption},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications and theoretical challenges in environmental
emergency issues alerting system on IoT intelligence. <em>COMCOM</em>,
<em>157</em>, 361–368. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario, the Internet of Things (IoT) based intelligent environments is considered as an active research area of research for the environmental emergency management system . Further, the highly important task of IoT assisted system has been developed to manage emergencies and support various systems during awareness situations in today’s world. The integration of these techniques will ensure that our lives are safer in response to disasters, emergencies or weapon attacks. In this paper, an IoT based emergency response system (IoT-ERS) solution has been proposed to safeguard people from emergencies based on real-time data. The proposed solution informs individuals and discusses an application that utilizes Smartphone information from the crowds and offers a suggestion for secured data retrieval during emergencies. Two possible instances are taken into consideration as listed as follows, (i) an emergency management and (ii) an essential application for data routing. Based on the outcomes, the experimental results show promising outcomes when compared to previous methods which have been firmly discussed in this research.},
  archive      = {J_COMCOM},
  author       = {Qi Wu},
  doi          = {10.1016/j.comcom.2020.03.030},
  journal      = {Computer Communications},
  pages        = {361-368},
  shortjournal = {Comput. Commun.},
  title        = {Applications and theoretical challenges in environmental emergency issues alerting system on IoT intelligence},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-layer energy optimization in cooperative MISO wireless
sensor networks. <em>COMCOM</em>, <em>157</em>, 351–360. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative multi-input single-output (CMISO) is proved to be higher energy saving in long distance communication than single-input single-output (SISO) based on the physical layer energy consumption model , thus this technique applied in wireless sensor networks for reducing energy consumption has become a hot issue. However, CMISO needs depend on MAC layer protocol to control signals synchronization among all cooperative nodes and pilot symbols transmission for channel gain estimation at receiver, both of which increase additional energy overhead. Meanwhile, all the cooperative nodes which listen to the contention-based channel in the backoff time at the MAC layer also consume a lot of energy. Therefore, the conclusions derived only from the physical layer energy consumption model may be impractical without considering the neighboring nodes’ interference and additional MAC layer overhead. It is unknown whether CMISO is higher energy efficiency than SISO at the MAC layer. In our paper, a MAC protocol for CMISO is designed, and based on this protocol a cross-layer energy consumption model is proposed. This cross-layer model considers not only transmitting power and circuit power, but also additional energy overhead in listening to the channel, transmitting pilot symbols, control frames, etc. With the model, minimum energy consumption is derived at the different parameters such as contention window , number of cooperative nodes, radius of a cluster and constellation size. At the same time, our numerical results prove that CMISO saves about 27\% energy consumption compared with SISO at the MAC layer. Since our results run under the heavy traffic environment with the highest transmission collision probability , we reasonably believe that CMISO communication will achieve better energy efficiency than SISO in ordinary traffic scenarios.},
  archive      = {J_COMCOM},
  author       = {Zhihua Lin and Guang Li and Jianqing Li},
  doi          = {10.1016/j.comcom.2020.04.034},
  journal      = {Computer Communications},
  pages        = {351-360},
  shortjournal = {Comput. Commun.},
  title        = {Cross-layer energy optimization in cooperative MISO wireless sensor networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monitoring of human body running training with wireless
sensor based wearable devices. <em>COMCOM</em>, <em>157</em>, 343–350.
(<a href="https://doi.org/10.1016/j.comcom.2020.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid pace of today’s society, work pressure, less exercise time, people began to pay more attention to their health. Walking and running have become the first choice of moderate exercise for many young people. The recognition of human running state based on wireless acceleration sensor will play an increasingly important role in the fields of motion detection, energy consumption evaluation and health care. It is of great significance to develop and design a kind of wearable multi-functional wireless sensor which can monitor the running state of human body. In this paper, a wearable human body monitoring system based on wireless acceleration sensor technology is proposed for real-time monitoring of daily running volume of human body. Hardware and upper computer design: stm32f405 is used as the main control chip, and ma8451q is used to collect human motion data. In this paper, aiming at the problem that three kinds of motion states of human body are easy to be confused and difficult to distinguish, based on the in-depth study of the complex structure mode and self similarity characteristics of non-stationary acceleration signal, a method of human body motion state recognition based on single fractal and multi fractal is proposed. In this method, the fractal dimension and the generalized dimension are used as the feature variables, and the correlation judgment method is used to distinguish and recognize different motion states. Experiments show the validity and feasibility of single fractal and multifractal in walking and going up and down three kinds of motion state recognition. On the basis of multifractal motion state recognition, this paper combines fractal theory with wavelet multiresolution analysis , and proposes a matrix fractal human motion state recognition method based on wavelet transform . The fractal matrix based on wavelet transform quantifies the fractal characteristics of the component signals of walking and going up and down in different wavelet scales, and then describes the complexity and self similarity of the original acceleration signals. Experimental results show that the average recognition rate of walking, jogging and fast running can reach over 93\% under the premise of less prior information.},
  archive      = {J_COMCOM},
  author       = {Jie Ren and Fuyu Guan and Ming Pang and Shuangling Li},
  doi          = {10.1016/j.comcom.2020.04.015},
  journal      = {Computer Communications},
  pages        = {343-350},
  shortjournal = {Comput. Commun.},
  title        = {Monitoring of human body running training with wireless sensor based wearable devices},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Research on real-time reliability evaluation of CPS system
based on machine learning. <em>COMCOM</em>, <em>157</em>, 336–342. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the reliability of CPS software system and proposes a real-time evaluation method of CPS software reliability based on machine learning . First, use complex networks to identify key points in the network topology of the CPS software system. Unsupervised learning classification by fast density clustering algorithm to classify the importance of nodes can be effectively applied to the importance evaluation of nodes in CPS software system and support the planning of CPS software system Secondly, a real-time CPS reliability automatic online evaluation method is proposed. This method uses machine learning ideas to build an evaluation framework, design an online queuing algorithm , and implement real-time online analysis and evaluation of CPS reliability. Preventive measures ensure that the system operates normally and without interruption, which greatly improves system reliability. Finally, simulation results verify the effectiveness of the evaluation method and its broad application prospects.},
  archive      = {J_COMCOM},
  author       = {Hechuang Wang},
  doi          = {10.1016/j.comcom.2020.04.039},
  journal      = {Computer Communications},
  pages        = {336-342},
  shortjournal = {Comput. Commun.},
  title        = {Research on real-time reliability evaluation of CPS system based on machine learning},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel class based searching algorithm in small world
internet of drone network. <em>COMCOM</em>, <em>157</em>, 329–335. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Drones (IoD) is a new area which is based on incorporation of social networks into Internet of Things (IoT). In near future the social network of IoT devices is expected to be highly convoluted due to the exponential growth of heterogeneous smart devices. Searching the right objects and services in optimal time through best path will be a challenging task. Information searching techniques in IoD need efficient schemes and innovative research. The Small World phenomenon reveals some alluring facts and has been motivating many researchers to understand the behavior of social networks. Inspired by information searching mechanisms in drone networks, an information searching algorithm which exploits rating of services in IoD, is proposed in this work. Results show that the proposed information searching algorithm proves to be efficient with its mean execution time not over than 2.5 ms on two different machines.},
  archive      = {J_COMCOM},
  author       = {Abdul Rehman and Anand Paul and Awais Ahmad and Gwanggil Jeon},
  doi          = {10.1016/j.comcom.2020.03.040},
  journal      = {Computer Communications},
  pages        = {329-335},
  shortjournal = {Comput. Commun.},
  title        = {A novel class based searching algorithm in small world internet of drone network},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable hybrid MAC strategy for traffic-differentiated
IoT-enabled intra-vehicular networks. <em>COMCOM</em>, <em>157</em>,
320–328. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of Internet of Things-enabled Intra-Vehicular Wireless Sensor Networks (IoT-IVWSNs) relying on IEEE 802.15.4 standard has generated a massive amount of wireless data traffic and put a great pressure in the network functionalities . Along this trend, the existing medium-access control (MAC) protocol struggles to keep up with the unprecedented demand of vehicle monitoring sensors simultaneously emitting data, which can lead to packet collisions, severe network congestion and lost of time-critical data, due to the inflexible characteristics of the protocol. In order to mitigate these issues, this work proposes an enhanced MAC scheme that is scalable to account for diverse sensor-traffic quality of services. The hybrid scheme aims to effectively combine two procedures, namely history- and priority-based MAC, to allocate appropriate network resources for smooth transmission flow from multiple sensors. History-based MAC exploits historical contention data to optimize a near-future contention window that aims to minimize packet collision and expedite the average data delivery. Priority-based MAC assigns priority based on the time-criticality of the sensing data, which is subsequently being used to schedules network resources. Numerical results show the desirable performance of the hybrid scheme for IoT-IVWSNs in comparison to the existing MAC and sole history-based or priority-based strategies in the context of packet delivery ratio and transmission delay.},
  archive      = {J_COMCOM},
  author       = {Md. Arafatur Rahman and A. Taufiq Asyhari and Ibnu Febry Kurniawan and Md Jahan Ali and M.M. Rahman and Mahima Karim},
  doi          = {10.1016/j.comcom.2020.04.035},
  journal      = {Computer Communications},
  pages        = {320-328},
  shortjournal = {Comput. Commun.},
  title        = {A scalable hybrid MAC strategy for traffic-differentiated IoT-enabled intra-vehicular networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Service modeling for opportunistic edge computing systems
with feature engineering. <em>COMCOM</em>, <em>157</em>, 308–319. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex and opportunistic environment in which edge computing systems operate, poses a fundamental challenge for online edge system orchestration , resource provisioning and real-time responsiveness in response to user movement. Such a challenge needs to addressed throughout the edge system lifecycle, starting from the software development methodologies. In this paper, we propose a novel development process for modeling opportunistic edge computing services, which rely on (i) ETSI MEC reference architecture and Opportunistic Internet of Things Service modeling for the early stage of system analysis and design, i.e. domain model and service metamodel; and on (ii) feature engineering for evaluating those opportunistic aspects with data analysis. To address the identified opportunistic properties, at the service design phase we construct (both automatically and through domain expertise) Opportunistic Feature Vectors for Edge, containing the numerical representations of those properties. Such vectors enable further data analysis and machine learning techniques in the development of distributed, effective and efficient edge computing systems. Lastly, we exemplify the integrated process with a microservice-based user mobility management service, based on a real-world data set, for online analysis in MEC systems.},
  archive      = {J_COMCOM},
  author       = {Teemu Leppänen and Claudio Savaglio and Giancarlo Fortino},
  doi          = {10.1016/j.comcom.2020.04.011},
  journal      = {Computer Communications},
  pages        = {308-319},
  shortjournal = {Comput. Commun.},
  title        = {Service modeling for opportunistic edge computing systems with feature engineering},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). BleRPC: A plug-and-play RPC framework over BLE.
<em>COMCOM</em>, <em>157</em>, 298–307. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a framework, called bleRPC, for people to enhance the ability of their home set-top boxes to control nearby IoT devices. The blePRC supported set-top boxes would implement common components and associated interfaces, such that IoT device vendors could develop application services for IoT devices, and users could deploy these services on their set-top boxes and control related IoT devices with their smartphones via Bluetooth Low Energy (BLE) technology, thereby eliminating the need to install several vendor-specific gateways at home. As BLE technology is designed for device-to-device communication, the bleRPC framework provides a means for a service in a bleRPC supported set-top box to distinguish between remote applications in the same user smartphone. Consequently, this study also contributes to providing application-level authentication and access control mechanisms for BLE-based service. This study implements the bleRPC framework on the Android TV platform, which is one of the state-of-the-art set-top box platforms. In terms of practicability, proof-of-concept experiments are conducted to demonstrate the performance of the proposed framework.},
  archive      = {J_COMCOM},
  author       = {Shi-Cho Cha and Kuo-Hui Yeh and Zi-Jia Huang},
  doi          = {10.1016/j.comcom.2020.04.017},
  journal      = {Computer Communications},
  pages        = {298-307},
  shortjournal = {Comput. Commun.},
  title        = {BleRPC: A plug-and-play RPC framework over BLE},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TWPalo: Through-the-wall passive localization of moving
human with wi-fi. <em>COMCOM</em>, <em>157</em>, 284–297. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, we have witnessed a booming growth of Wi-Fi-based indoor localization systems that can locate the user without requiring the user to hold or wear any device. To foster a broad range of real-world based applications via these systems, the localization under the through-the-wall scenario (TTW) needs to be addressed, which is of great challenge. Based on the in-depth understanding of human induced reflection conveyed by Wi-Fi channel state information (CSI), we propose TWPalo, a through-the-wall device-free localization system. To achieve this goal, a three-dimensional joint parameter estimation algorithm is proposed to estimate the time of flight (ToF), angle of arrival (AoA), and Doppler frequency shift (DFS) of the propagation path . Then, by iterating joint parameter estimation, channel reconstruction, and cancellation, an innovative algorithm is proposed to separate the CSI of each propagation path and obtain the parameters of subtle human induced reflection (HIR), which could be overwhelmed by strong propagation paths, under the TTW scenario. At last, TWPalo translates the obtained AoA and ToF of subtle HIR into the locations of the human behind the wall. Extensive experimental evaluation validates the great performance of TWPalo in terms of parameter estimation and localization, under typical indoor TTW scenarios of glass and concrete wall.},
  archive      = {J_COMCOM},
  author       = {Jiacheng Wang and Zengshan Tian and Xiaolong Yang and Mu Zhou},
  doi          = {10.1016/j.comcom.2020.04.030},
  journal      = {Computer Communications},
  pages        = {284-297},
  shortjournal = {Comput. Commun.},
  title        = {TWPalo: Through-the-wall passive localization of moving human with wi-fi},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exploratory study of congestion control techniques in
wireless sensor networks. <em>COMCOM</em>, <em>157</em>, 257–283. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congestion is one of the pervasive issues for Wireless Sensor Networks(WSNs) because of its bounded resources with respect to data processing, storage, transmission capacity and most importantly energy supply. A multitude of survey operations have been carried out over the previous decade to investigate and address multiple congestion-oriented problems and issues that are still unresolved. Various review articles published in the literature concentrated mainly on classical techniques for congestion control such as traffic-based, resource-based, and hybrid techniques, etc. In this survey article, an attempt has been made to present a systematic review of recent efforts assisted at refining the congestion control methodologies in WSNs by considering classical approaches as well as soft computing based approaches. It is a practicable idea to take a holistic view and study both approaches together. Finally, this article discusses design difficulties, various optimization models and future directions for the mechanism of congestion control in the domain of wireless sensor networks.},
  archive      = {J_COMCOM},
  author       = {Divya Pandey and Vandana Kushwaha},
  doi          = {10.1016/j.comcom.2020.04.032},
  journal      = {Computer Communications},
  pages        = {257-283},
  shortjournal = {Comput. Commun.},
  title        = {An exploratory study of congestion control techniques in wireless sensor networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of wireless communication using high-altitude
platforms for extended coverage and capacity. <em>COMCOM</em>,
<em>157</em>, 232–256. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an up-to-date review of wireless communications service provisioning from High-Altitude Platforms (HAPs) in rural or remote areas exploiting cellular radio spectrum. With a recent International Telecommunication Union (ITU) report showing that as much as 74\% of the population in Africa, most of which are living in rural areas, do not have access to broadband, this paper focuses on the potential of using HAPs for wireless communication in rural communities as an alternative to terrestrial systems . Considering the typically low user densities in rural areas and the benefits of HAP coverage maximization while ensuring harmless coexistence with terrestrial systems , the paper explores the possibility of extending the achievable wireless coverage from a HAP. This takes into consideration the coexistence of a HAP with terrestrial systems using intelligent techniques to dynamically manage radio resources and mitigate interference. Studies have shown that efficient intelligent radio resource and topology management can mitigate inter-system interference and ensure coexistence with improved system performance. Potential techniques for coverage extension such as exploiting the spatial characteristics of array antennas , radio environment maps (REMs) and device-to-device (D2D) communications are discussed. Generally, this paper presents a comprehensive review of significant HAP related studies.},
  archive      = {J_COMCOM},
  author       = {Steve Chukwuebuka Arum and David Grace and Paul Daniel Mitchell},
  doi          = {10.1016/j.comcom.2020.04.020},
  journal      = {Computer Communications},
  pages        = {232-256},
  shortjournal = {Comput. Commun.},
  title        = {A review of wireless communication using high-altitude platforms for extended coverage and capacity},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). User recommendation method based on joint probability matrix
decomposition in CPS networks. <em>COMCOM</em>, <em>157</em>, 221–231.
(<a href="https://doi.org/10.1016/j.comcom.2020.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of the Internet, various virtual communities continue to emerge, and the phenomenon of user groups working together is gradually increasing. People begin to pay more attention to group-oriented recommendation. Most of existing group recommendation methods are improved on the memory-based collaborative filtering recommendation method, or think that the members of the group are independent of each other, ignoring the impact of association among the members of the group on the results of group recommendation. In this paper, a group recommendation method based on joint probability matrix decomposition is proposed to better model the group recommendation problem. Firstly, the user-plus-person group information is used to calculate the correlation between users. Secondly, the user correlation matrix is integrated into the process of probability matrix decomposition to get the individual prediction score. Finally, the group-to-item prediction score is obtained by using the common synthesis strategy in group-oriented recommendation problem. Furthermore, the proposed method is compared with existing group recommendation methods. Experiments on CiteULike dataset show that the proposed method achieves better recommendation results in accuracy, recall and other evaluation indicators.},
  archive      = {J_COMCOM},
  author       = {Zhe Yao and Kun Gao},
  doi          = {10.1016/j.comcom.2020.03.044},
  journal      = {Computer Communications},
  pages        = {221-231},
  shortjournal = {Comput. Commun.},
  title        = {User recommendation method based on joint probability matrix decomposition in CPS networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Presentation and interaction of internet of things data
based on augmented reality. <em>COMCOM</em>, <em>157</em>, 213–220. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, AR (Augmented Reality) technology has gradually entered people’s horizons and has become a research hotspot in the field of image processing . At the same time, the mobility and interactivity of AR have also been valued. This paper studies the interaction technology in the AR scene, and proposes a scheme to detect the user’s gaze at the cone perspective. The Leapmotion body sensor was used for gesture extension, and the hardware connection and data transmission scheme of Leapmotion and Holo Lens was designed. Based on the three input modes of sight, gesture and voice, the interaction logic between the user and the system in the AR scene is designed. The network of the Internet of Things is dominated by wireless sensor networks (Wireless Sensor Networks). This paper studies the problem of congestion in wireless sensor network sensing data transmission. WSNs nodes need to transmit the sensed data or preprocessed sensed data to sink nodes. When the data packets (or packets) received by a sensor node exceed its upper limit for forwarding or processing data packets, the excess data packets need to be buffered. When the memory of cached packets is full, excess packets are discarded, causing buffer overflows and causing node-level congestion. This paper proposes an energy balance strategy based on feedback control . The feedback control algorithm is used to adjust the node’s transmit power to realize the redistribution of node load in the network, solve the problem of node energy imbalance in wireless sensor networks , and further extend the sensor network.},
  archive      = {J_COMCOM},
  author       = {Kai Li and Wei Sun},
  doi          = {10.1016/j.comcom.2020.04.037},
  journal      = {Computer Communications},
  pages        = {213-220},
  shortjournal = {Comput. Commun.},
  title        = {Presentation and interaction of internet of things data based on augmented reality},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Condition monitoring of power transmission and
transformation equipment based on industrial internet of things
technology. <em>COMCOM</em>, <em>157</em>, 204–212. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Internet of Things (IoT) technology is an advanced and emerging information based technology and it possesses avast development potential. The application of IoT technology in power system is beneficial for the intelligent transformation of the power system . The power system provides a vast application space for the IoT technology. The purpose of this paper is to strongly promote the application and deployment process of the IoT in various industries and play a long-term important role in promoting the informatization transformation of China’s industry. This paper studies the state monitoring system of power transmission and transformation equipment based on panoramic data and introduces the information model into the IoT of power transmission and transformation equipment. According to the equipment panorama information required by the life cycle management of power transmission a comprehensive panorama information modeling scheme is proposed for smart substation equipment , and the network performance is monitored through simulation analysis. In particular, the end-to-end delay of the application layer changed greatly, with a decrease of 0.015 s. This study provides a reference for the development of state monitoring system of power transmission and transformation equipment in China.},
  archive      = {J_COMCOM},
  author       = {Jindong Zhao and Xingzuo Yue},
  doi          = {10.1016/j.comcom.2020.04.008},
  journal      = {Computer Communications},
  pages        = {204-212},
  shortjournal = {Comput. Commun.},
  title        = {Condition monitoring of power transmission and transformation equipment based on industrial internet of things technology},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient and secure content dissemination architecture for
content centric network using ECC-based public key infrastructure.
<em>COMCOM</em>, <em>157</em>, 187–203. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Initially, Internet was designed with the goal of sharing resources. With the recent technological advancement and huge information need, Internet has gradually shifted from resource sharing mode to information sharing mode. To meet the demands of current Internet usage pattern, content centric network (CCN) is envisaged as a clean-slate Internet architecture. This paper proposes secure content dissemination architecture for CCN using elliptic curve cryptography based public key infrastructure (ECC-PKI). The proposed scheme restores the current business model of the Internet by decoupling the encrypted content from its access control specifications while maintaining the in-network content caching mechanism of the CCN. In the proposed security architecture, content will be securely communicated between each pair of entities of CCN using ECC-based protocols. While designing proposed protocols our main aim is to minimize the computation and communication cost and to increase the performance, efficiency and security. Finally, a formal security verification using well known AVISPA simulator and BAN logic concludes that the proposed scheme is secure against the existing relevant cryptographic attacks .},
  archive      = {J_COMCOM},
  author       = {Sharmistha Adhikari and Sangram Ray and Mohammad S. Obaidat and G.P. Biswas},
  doi          = {10.1016/j.comcom.2020.04.024},
  journal      = {Computer Communications},
  pages        = {187-203},
  shortjournal = {Comput. Commun.},
  title        = {Efficient and secure content dissemination architecture for content centric network using ECC-based public key infrastructure},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quality estimation of CPS network link based on
non-uniformly sampling period. <em>COMCOM</em>, <em>157</em>, 179–186.
(<a href="https://doi.org/10.1016/j.comcom.2020.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber Physical System (CPS) is a fusion system integrating computing, communication and control functions with information task processing as the core. CPS needs real-time, highly efficient and reliable communication links to complete the dynamic feedback and control between the physical world and the information world effectively. Affected by many factors, the link quality of wireless communication environment is nonlinear randomness. Meanwhile, the sampled data of the system is non period signal. This study described it as a class of non-uniformly sampled nonlinear systems . Based on the Hierarchical Principle method, a stochastic gradient algorithm is proposed for non-uniformly sampled data nonlinear system. The algorithm can estimate the quality of CPS network link successfully. The results shows the validity of the algorithm, which can effectively guarantee quality of links and accomplish good dynamic feedback and control of the system.},
  archive      = {J_COMCOM},
  author       = {Ranran Liu and Hongxiang Xu and Enxing Zheng and Yifeng Jiang and Shan Chang},
  doi          = {10.1016/j.comcom.2020.04.029},
  journal      = {Computer Communications},
  pages        = {179-186},
  shortjournal = {Comput. Commun.},
  title        = {Quality estimation of CPS network link based on non-uniformly sampling period},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimising message broadcasting in opportunistic networks.
<em>COMCOM</em>, <em>157</em>, 162–178. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Message Broadcasting in Opportunistic Networks is based on the opportunity of establishing contacts among mobiles nodes for message exchange. Nevertheless, as the amount of information transmitted in a contact is limited by the transmission speed and the contact duration, large messages are less likely to be exchanged, and thus their diffusion is severely limited. Furthermore, these failed transmissions can also lead to an important waste of network resources, since the message transmission is aborted when the contact ends and the message needs to be transmitted again in the next contact. Therefore, in this paper we study the impact that contact duration has on the broadcast of messages, showing that splitting a large message into smaller parts can improve its diffusion. Based on this idea, we propose an extension of the epidemic protocol called Xpread . The efficiency of this protocol mainly depends on how the original message is partitioned. Thus, in order to evaluate the impact and the efficiency of the partition scheme, we have developed an analytical model based on Population Processes , showing that a fixed size partition is the best option, while also providing a simple expression to obtain the optimal size. The Xpread has been evaluated exhaustively using four different mobiles traces, comprising both pedestrian and vehicular scenarios . The results show that the diffusion of large messages is improved up to four times with a slight reduction in the delivery time and overhead, minimising also message forwarding failures.},
  archive      = {J_COMCOM},
  author       = {Leonardo Chancay-García and Enrique Hernández-Orallo and Pietro Manzoni and Anna Maria Vegni and Valeria Loscrí and Juan Carlos Cano and Carlos T. Calafate},
  doi          = {10.1016/j.comcom.2020.04.031},
  journal      = {Computer Communications},
  pages        = {162-178},
  shortjournal = {Comput. Commun.},
  title        = {Optimising message broadcasting in opportunistic networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent early structural health prognosis with nonlinear
system identification for RFID signal analysis. <em>COMCOM</em>,
<em>157</em>, 150–161. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical state of non-linear processes includes these characteristics such as multivariable, strong coupling, multiple vibration sources, large signal noise , and various random factors. The intrinsic relationship and overall consistency optimization of the characteristic factor direction paths of multi-source matrix signals are a new research hotspot in multi-source dynamic characteristic signal identification. A intelligent fault diagnosis and prognosis method based on NARMAX-FRF and PCA is proposed in this paper. This method can be widely used in industrial system fault diagnosis . This system solves many basic key problems, including identifying a non-linear model from a detected system, accurately solving the frequency response function, extracting a representative frequency domain from the frequency response function, and applying extracted system frequency domain features for large-scale structural health assessment. In order to verify the performance of the NARMAX_FRF and PCA method for nonlinear defect signal analysis, the experiment of intelligent RFID system of corrosion monitoring and the TOFD experimental system are analyzed for the structural health monitoring in this paper. The set of samples in the experiment of intelligent RFID system of corrosion monitoring consists of coated and uncoated mild steel plates, which have a patch that has been exposed to the environment for different durations to create different levels of corrosion. The results show the effectiveness and robustness of the proposed method.},
  archive      = {J_COMCOM},
  author       = {Hanxin Chen and Yongting Chen and Liu Yang},
  doi          = {10.1016/j.comcom.2020.04.026},
  journal      = {Computer Communications},
  pages        = {150-161},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent early structural health prognosis with nonlinear system identification for RFID signal analysis},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A driving intention prediction method based on hidden markov
model for autonomous driving. <em>COMCOM</em>, <em>157</em>, 143–149.
(<a href="https://doi.org/10.1016/j.comcom.2020.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a mixed-traffic scenario where both autonomous vehicles and human-driving vehicles exist, a timely prediction of driving intentions of nearby human-driving vehicles is essential for the safe and efficient driving of an autonomous vehicle. In this paper, a driving intention prediction method based on hidden Markov model (HMM) is proposed for autonomous vehicles. HMMs representing different driving intentions are trained and tested with field collected data from a flyover. When training the models, either discrete or continuous characterization of the mobility features of vehicles is applied. Experimental results show that the proposed method performs better than the logistic regression (LR) method, and the HMMs trained with the continuous characterization of mobility features can give a higher prediction accuracy when they are used for predicting driving intentions. Moreover, when the surrounding traffic of the vehicle is taken into account, the performances of the proposed prediction method are further improved.},
  archive      = {J_COMCOM},
  author       = {Shiwen Liu and Kan Zheng and Long Zhao and Pingzhi Fan},
  doi          = {10.1016/j.comcom.2020.04.021},
  journal      = {Computer Communications},
  pages        = {143-149},
  shortjournal = {Comput. Commun.},
  title        = {A driving intention prediction method based on hidden markov model for autonomous driving},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization strategies for the selection of mobile edges in
hybrid crowdsensing architectures. <em>COMCOM</em>, <em>157</em>,
132–142. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication infrastructures are rapidly evolving to support 5G enabling lower latency, high reliability, and scalability of the network and of the service provisioning. An important element of the 5G vision is Multi-access Edge Computing (MEC), that leverages the availability of powerful and low-cost middle boxes, i.e., MEC nodes, statically deployed at suitable edges of the network to extend the centralized cloud backbone. At the same time, after almost a decade of research, Mobile CrowdSensing (MCS) has established the technology able to collect sensing data on the environment by using personal devices, usually smartphones, as powerful sensing-and-communication platforms. Even though, mutual benefits due to the integration of MEC and Mobile CrowdSensing (MCS) are still largely unexplored. In this paper, we address and analyze the potential of the synergic use of MCS and MEC by thoroughly assessing various strategies for the selection of both traditional Fixed MEC (FMEC) edges as well as human-enabled Mobile MEC (M 2 EC) edges to support the collection of mobile CrowdSensing data. Collected results quantitatively show the effectiveness of the proposed optimization strategies in elastically scaling the load at edge nodes according to runtime provisioning needs.},
  archive      = {J_COMCOM},
  author       = {Dimitri Belli and Stefano Chessa and Antonio Corradi and Luca Foschini and Michele Girolami},
  doi          = {10.1016/j.comcom.2020.04.006},
  journal      = {Computer Communications},
  pages        = {132-142},
  shortjournal = {Comput. Commun.},
  title        = {Optimization strategies for the selection of mobile edges in hybrid crowdsensing architectures},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized data storage algorithm of IoT based on cloud
computing in distributed system. <em>COMCOM</em>, <em>157</em>, 124–131.
(<a href="https://doi.org/10.1016/j.comcom.2020.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing Internet of Things(IoT) uses cloud computing data access storage algorithms, that is, the hash algorithm has defects of low data processing efficiency and low fault tolerance rate. Therefore, HDFS is introduced to optimize cloud computing data access storage algorithms. HDFS is first used to optimize the data access storage architecture according to problems of data access storage architecture in the Internet of Things , in which factors of data access storage distribution in the IoT are fully considered, and hash values are used to optimize the configuration of data access information storage locations, so that data access storage distribution strategy can be optimized. Then, the topology of the IoT is optimized, and data block size is also optimized with effect algorithm. Finally, the design of file storage is optimized. Through simulation experiments, it is proved that the optimized cloud storage method has obvious performance advantages in file read and write speed as well as memory usage. Compared with the traditional hash algorithm , optimization algorithm proposed in the paper greatly improves file upload and download efficiency, data processing efficiency and fault tolerance rate, which fully demonstrates that the proposed cloud computing data access storage optimization algorithm is more superior.},
  archive      = {J_COMCOM},
  author       = {Mingzhe Wang and Qiuliang Zhang},
  doi          = {10.1016/j.comcom.2020.04.023},
  journal      = {Computer Communications},
  pages        = {124-131},
  shortjournal = {Comput. Commun.},
  title        = {Optimized data storage algorithm of IoT based on cloud computing in distributed system},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-dimensional quality-driven service recommendation with
privacy-preservation in mobile edge environment. <em>COMCOM</em>,
<em>157</em>, 116–123. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advance of mobile edge computing (MEC), the number of edge services running on mobile devices grows explosively. In this situation, it is becoming a necessity to recommend the most suitable edge services to a mobile user from massive candidates, based on the historical quality of service (QoS) data. However, historical QoS is a kind of private data for users, which needs to be protected from privacy disclosure . Currently, researchers often use the Locality-Sensitive Hashing (LSH) technique to achieve the goal of privacy-aware recommendations. However, existing LSH-based methods are only applied to the recommendation scenarios with a single QoS dimension (e.g., response time or throughput ), without considering the multi-dimensional QoS (e.g., response time and throughput ) ensemble, which narrow the application scope of LSH in privacy-preserving recommendations significantly. Considering this drawback, this paper proposes a multi-dimensional quality ensemble-driven recommendation approach named Rec LSH-TOPSIS based on LSH and TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) techniques. First, the traditional single-dimensional LSH recommendation approach is extended to be a multi-dimensional one, through which we can obtain a set of candidate services that a user may prefer. Second, we use TOPSIS technique to rank the derived multiple candidate services and return the user an optimal one. At last, a case study is presented to illustrate the feasibility of our proposal to make privacy-preserving edge service recommendations with multiple QoS dimensions.},
  archive      = {J_COMCOM},
  author       = {Weiyi Zhong and Xiaochun Yin and Xuyun Zhang and Shancang Li and Wanchun Dou and Ruili Wang and Lianyong Qi},
  doi          = {10.1016/j.comcom.2020.04.018},
  journal      = {Computer Communications},
  pages        = {116-123},
  shortjournal = {Comput. Commun.},
  title        = {Multi-dimensional quality-driven service recommendation with privacy-preservation in mobile edge environment},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-source social media data sentiment analysis using
bidirectional recurrent convolutional neural networks. <em>COMCOM</em>,
<em>157</em>, 102–115. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subjectivity detection in the text is essential for sentiment analysis , which requires many techniques to perceive unanticipated means of communication. Few accomplishments adapted to capture the syntactic , semantic, and contextual sentimental information via distributed word representations (DWRs) 1 . This paper, concatenating the DWRs through a weighted mechanism on Recurrent Neural Network (RNN) variants joint with Convolutional Neural network (CNN) distinctively involving weighted attentive pooling (WAP) 2 . Whereas, CNNs with traditional pooling operations comprise many layers merely able to capture enough features. Our considerations empower the sentiment analysis over DWRs contains Word2vec, FastText, and GloVe to produce dense efficient concatenated representation (DECR) 3 to hold long term dependencies on a single RNN layer acquired by Parts of Speech Tagging (POS) explicitly with verbs, adverbs, and noun only. Then use these representations gained in a way, inputted to CNN contain single convolution layer engaging WAP on multi-source social media data to handle the issues of syntactic and semantic regularities as well as out of vocabulary (OOV) words. Experimentations demonstrate that DWRs together with proposed concatenation qualified in resolving the mentioned issues by moderate hyper-parameter configurations. Our architecture devoid of stacking multiple layers achieved modest accuracy of 89.67\% by DECR-Bi-GRU-CNN (WAP) on IMDB as compared to random initialization 81.11\% on SST.},
  archive      = {J_COMCOM},
  author       = {Fazeel Abid and Chen Li and Muhammad Alam},
  doi          = {10.1016/j.comcom.2020.04.002},
  journal      = {Computer Communications},
  pages        = {102-115},
  shortjournal = {Comput. Commun.},
  title        = {Multi-source social media data sentiment analysis using bidirectional recurrent convolutional neural networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable fingerprint-based angle-of-arrival machine
learning approach for cellular mobile radio localization.
<em>COMCOM</em>, <em>157</em>, 92–101. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well-known that the performance of radio frequency fingerprinting is strongly dependent on the variation of the received strength signal indicator (RSSI), that can be caused by devices which came from different vendors (or even the same) and by changes of environment (from outdoor to indoor, for example). Given that, we propose an innovative and scalable fingerprint-based localization technique using the mobile user horizontal angle to estimate its position. Performance of traditional fingerprinting based on RSSI and of our proposal are compared under different scenarios (number of base stations), environments (outdoor, indoor, and indoor–outdoor), and presence/absence of noise. Numerical results show that the proposed method presents smaller error predictions for most of environments and scenarios investigated. In addition, our proposal is less sensitive to environment changing (from outdoor to indoor) and more stable when applied in indoor or outdoor environments, considering scenarios with fewer base stations (cellular networks in suburban or rural regions) and less data for training (less costly drive-tests performed by telecom operators).},
  archive      = {J_COMCOM},
  author       = {Robson D.A. Timoteo and Daniel C. Cunha},
  doi          = {10.1016/j.comcom.2020.04.014},
  journal      = {Computer Communications},
  pages        = {92-101},
  shortjournal = {Comput. Commun.},
  title        = {A scalable fingerprint-based angle-of-arrival machine learning approach for cellular mobile radio localization},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic underground space security monitoring based on
BIM. <em>COMCOM</em>, <em>157</em>, 85–91. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional underground space safety monitoring is ineffective as data continuity is weak, systematic and random errors are prominent, data quantification is difficult, data stability is scarce (especially in bad weather), and it is difficult to guarantee human safety. In this study, BIM technology and multi-data wireless sensor network transmission protocol, cloud computing platform are introduced into engineering monitoring, real-time online monitoring equipment, cloud computing platform and other hardware and software are developed, and corresponding online monitoring system for structural safety is developed to realize online monitoring and early diagnosis of underground space safety. First, the shape of the underground space, the surrounding environment, and various monitoring points are modeled using BIM. Then, the monitoring data collected from sensors at the engineering site are transmitted to the cloud via wireless transmission. Data information management is then realized via cloud computing, and an actual state-change trend and security assessment is provided. Finally, 4D technology (i.e., 3D model + time axis) that leverages a deformation chromatographic nephogram is used to facilitate managers to view deformation and safety of their underground spaces. To overcome past shortcomings, this system supports the management of basic engineering project data and storage of historical data. Furthermore, the system continuously reflects the fine response of each monitoring item under various working conditions all day, which has significant theoretical value and application.},
  archive      = {J_COMCOM},
  author       = {Xuesong Zhang},
  doi          = {10.1016/j.comcom.2020.03.051},
  journal      = {Computer Communications},
  pages        = {85-91},
  shortjournal = {Comput. Commun.},
  title        = {Automatic underground space security monitoring based on BIM},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent power monitoring of building equipment based on
internet of things technology. <em>COMCOM</em>, <em>157</em>, 76–84. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of intelligent buildings , problems such as difficulties in system integration , poor scalability, and difficulties in coordinated operation across systems have emerged. The development of the Internet of Things technology has provided new ideas for solving these problems. This paper proposes an intelligent building architecture based on the Internet of Things technology . The data aggregation of the indoor electrical Internet of Things and public facilities integration system forms building big data, and provides decision support for building operation and maintenance management through a variety of data analysis algorithms. This paper analyzes and discusses the determination of monitoring objects, the selection and placement of monitoring points in the smart power monitoring system . By building an experimental platform, system function debugging is performed. After several experiments, the power supply device based on intelligent monitoring designed in this paper achieved the expected goal. The system was verified through experiments to realize the collection of power supply parameters, and compared with the actual data, the accuracy can meet the requirements of the monitoring system. When the power supply is abnormal, the power can be cut off in time, which effectively protects the safety of the system and confirms the feasibility of the scheme.},
  archive      = {J_COMCOM},
  author       = {Lei Yu and Babar Nazir and Yinling Wang},
  doi          = {10.1016/j.comcom.2020.04.016},
  journal      = {Computer Communications},
  pages        = {76-84},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent power monitoring of building equipment based on internet of things technology},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep neural networks based model for uninterrupted marine
environment monitoring. <em>COMCOM</em>, <em>157</em>, 64–75. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, there is a massive increase in population and hence increase in societal development. Concerning environmental change as a result of development in society and the economy, the marine environment plays a significant role in global climatic change. Hence recent Information and Communication Technologists are attracted towards monitoring the marine environment. Various marine monitoring systems are developed in the past few years. Out of these, the Internet of Things (IoT) plays a significant role. In IoT based Marine monitoring systems, various sensors are deployed in the real-time environment for monitoring and measuring various physical parameters. These sensors work on battery power. When the battery drains, there is a possibility of interruption in the monitoring activity until the battery is replaced. This research paper focuses on developing a prediction model for predicting the life of battery well ahead and alert the technologists so that the monitoring will not be interrupted using Principal Component Analysis (PCA) and Deep Neural Network (DNN). The model is evaluated using raw data collected from a real-time marine monitoring system which is deployed at Chicago Park District along the beach water. The results obtained are compared and analyzed with the widely used state of art techniques namely Linear Regression and XGBoost . The results show that the proposed PCA based DNN Prediction Model outperforms the other techniques by an increase of 12\% in accuracy and 30\% in reduction of time complexity.},
  archive      = {J_COMCOM},
  author       = {Thippa Reddy G. and Swarna Priya R.M. and Parimala M. and Chiranji Lal Chowdhary and Praveen Kumar Reddy M. and Saqib Hakak and Wazir Zada Khan},
  doi          = {10.1016/j.comcom.2020.04.004},
  journal      = {Computer Communications},
  pages        = {64-75},
  shortjournal = {Comput. Commun.},
  title        = {A deep neural networks based model for uninterrupted marine environment monitoring},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TMSE: A topology modification strategy to enhance the
robustness of scale-free wireless sensor networks. <em>COMCOM</em>,
<em>157</em>, 53–63. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scale-free wireless sensor networks (WSNs) are tolerant to random attacks but vulnerable to malicious attacks . With the increase of cyber-attacks, improving the survivability and robustness is critical to scale-free WSNs. This paper introduces a scale-free topology evolution mechanism (SFTEM) for WSNs, and the evolution model considers the fault probability of nodes as well as the communication range. Then, a new topology modification strategy for enhancing the robustness of scale-free WSNs is presented, namely TMSE. Different from previous works, we consider different types of malicious attack into the algorithm design , making the TMSE more resistant to realistic attacks. Besides, TMSE consists of two operations, in which the high degree operation (HDO) changes the network connections among high degree nodes base on the probability of being attacked, and the degree associativity operation (DAO) transforms the network topology into the onion-like structure using its degree–degree correlation. Meanwhile, all the nodes modified by TMSE maintain the node degree, thus the final topology preserves scale-free properties. Simulation results demonstrate that the network topology generated by SFTEM has the scale-free characteristics, and its robustness can be effectively improved by TMSE, compared to the existing algorithms.},
  archive      = {J_COMCOM},
  author       = {Shihong Hu and Guanghui Li},
  doi          = {10.1016/j.comcom.2020.04.007},
  journal      = {Computer Communications},
  pages        = {53-63},
  shortjournal = {Comput. Commun.},
  title        = {TMSE: A topology modification strategy to enhance the robustness of scale-free wireless sensor networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Wireless network signal monitoring based on LAN packet
capture and protocol analysis on grid programming. <em>COMCOM</em>,
<em>157</em>, 45–52. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a kind of network technology with super wide coverage and obvious transmission rate advantage, wireless network has become the most widely used network technology in people’s daily life. However, when information is transmitted and exchanged in wireless networks, information blocking often occurs, which restrains the transmission rate. Therefore, the signal monitoring technology in wireless network is of great practical significance. This paper will focus on the breakthrough of wireless WLAN packet capture and protocol analysis technology in computer communication technology, and use the grid programming method to analyze the implementation process of the whole system function module. Based on this technology, a wireless network detection system is developed in VC + + 7 environment, and the algorithm flow chart is given. Finally, the system designed in this paper will be tested on Linux platform . The experimental results show that the wireless network signal monitoring technology proposed in this paper can monitor the operation of wireless network in real time. The corresponding detection accuracy error is controlled at about 1\%, and the corresponding detection accuracy can reach about 60\% in different signal background.},
  archive      = {J_COMCOM},
  author       = {Qunying Chen},
  doi          = {10.1016/j.comcom.2020.04.001},
  journal      = {Computer Communications},
  pages        = {45-52},
  shortjournal = {Comput. Commun.},
  title        = {Wireless network signal monitoring based on LAN packet capture and protocol analysis on grid programming},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving scheme with identity traceable property
for smart grid. <em>COMCOM</em>, <em>157</em>, 38–44. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart city is a hot aim, and is organized gradually in many developed countries. People can understand the variation of city clearly via the collected data from sensors and RFID chips all over the city. As one of the most important applications for smart city, smart grid is a popular technology which has been already used in some developed countries. Wireless circumstance is the main way for the transmission data in collection process, and it is undoubtedly insecure. The problems that protecting the consumption data in smart grid and tracking some special users simultaneously are still open issues. We propose a novel scheme for smart grid involving three kinds of entities: Smart Meters (SMs), Electricity Utilities (EUs), and a Trustful Anchor (TA). In this scheme, SM encrypts the periodical consumptions and its identity, and sends the information to the relative electricity utility, and then EU can get the consumptions of smart meters in its scope. If necessary, TA may disclose the identities of the special smart meters. The security of this scheme is illustrated by formal proof and security property analysis. After expressions of performance and network simulation, it is easy to see that our scheme is suitable for practicality.},
  archive      = {J_COMCOM},
  author       = {Fan Wu and Xiong Li and Lili Xu and Saru Kumari},
  doi          = {10.1016/j.comcom.2020.03.047},
  journal      = {Computer Communications},
  pages        = {38-44},
  shortjournal = {Comput. Commun.},
  title        = {A privacy-preserving scheme with identity traceable property for smart grid},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensitivity analysis of censoring data from component
failure analysis and reliability evaluation for the aviation internet of
things. <em>COMCOM</em>, <em>157</em>, 28–37. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things is booming in the aviation industry, thus proper collection and analysis methods for fault data could support the realization of intelligent maintenance support and management of components. Failure of aeronautical equipment is typically described by a Weibull distribution . Here we carry out a sensitivity analysis using an objective Bayesian method to investigate the effect of descriptive statistics on reliability evaluations of random right censored aeronautical equipment failure data. We design a multiple Markov chain algorithm with censoring rate- and sample size-dependent variables. The algorithm estimates the scale and shape parameters of a Weibull distribution , with prior information of a large variance gamma distribution , for different censoring rates and sample sizes. Estimation deviations can be evaluated by mean time between failures , and by the mean and the variation factor of the distribution parameter. The numerical results show that, in a Weibull distribution, the estimation accuracy of an objective Bayesian method is acceptable when the sample size is more than 10 or the censoring rate less than 0.5. Otherwise, a better reliability evaluation method for small samples and high censoring rates should be explored.},
  archive      = {J_COMCOM},
  author       = {Chao Wang and Jilian Guo and Anwei Shen},
  doi          = {10.1016/j.comcom.2020.04.003},
  journal      = {Computer Communications},
  pages        = {28-37},
  shortjournal = {Comput. Commun.},
  title        = {Sensitivity analysis of censoring data from component failure analysis and reliability evaluation for the aviation internet of things},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical modeling of security impact analysis of
communication network based on monte carlo algorithm. <em>COMCOM</em>,
<em>157</em>, 20–27. (<a
href="https://doi.org/10.1016/j.comcom.2020.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the analysis of the current security impact of communication networks, this paper introduces a traditional mathematical model of information security impact. Based on this, further combining the importance of effective implementation of security protection, based on the sequential Monte Carlo localization algorithm , a novel The new positioning method can increase the reliability of the anchor box , optimize the sampling area, and improve the positioning accuracy of the node during the acquisition of the anchor box during the prediction stage by integrating the RSSI principle and the centroid principle. An improved model is for the analysis of the security impact of communication networks based on Monte Carlo algorithm. Although this algorithm increases the positioning complexity to a certain extent, the entire calculation process consumes less energy and the optimization effect is obvious. This model is based on the quantitative analysis of communication network security threats, communication network combat methods, network security attributes, and network security adversarial attributes. It uses fuzzy mathematical theory and adaptive weighting algorithms to effectively communicate in the case of effective security protection The impact of network security was quantitatively analyzed and modeled. The simulation results based on Monte Carlo method prove the validity of the model in this paper. Simulation results show that compared with the traditional MCB positioning algorithm , this algorithm can effectively improve the positioning accuracy.},
  archive      = {J_COMCOM},
  author       = {Chong Tian and Xiqiu Hu},
  doi          = {10.1016/j.comcom.2020.04.005},
  journal      = {Computer Communications},
  pages        = {20-27},
  shortjournal = {Comput. Commun.},
  title        = {Mathematical modeling of security impact analysis of communication network based on monte carlo algorithm},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Latency and energy-aware provisioning of network slices in
cloud networks. <em>COMCOM</em>, <em>157</em>, 1–19. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern network services are constantly increasing their requirements in terms of bandwidth, latency and cost efficiency. To satisfy these requirements, the concept of network slicing has been introduced in the context of next-generation 5G networks . However, to successfully provision resources to slices, a complex optimization problem must be addressed to allocate resources over a cloud network, i.e., a distributed computing infrastructure interconnected through high-capacity network links. In this study, we propose two new latency and energy-aware optimization models for provisioning 5G slices in cloud networks comprising both distributed computing and network resources. The proposed approaches differ from other existing solutions since we conduct our studies with respect to the end-to-end latency. Relevant models of latency and energy consumption are proposed based on a comprehensive review of the state-of-the-art. To effectively solve those optimization problems, a configurable heuristic is also proposed and investigated over different network topologies . Performance of the proposed heuristic is compared against near-optimal solutions. Moreover, we assess the importance of matching between resource provisioning algorithms and architectural assumptions related to 5G network slices and a proper problem modeling.},
  archive      = {J_COMCOM},
  author       = {Piotr Borylo and Massimo Tornatore and Piotr Jaglarz and Nashid Shahriar and Piotr Chołda and Raouf Boutaba},
  doi          = {10.1016/j.comcom.2020.03.050},
  journal      = {Computer Communications},
  pages        = {1-19},
  shortjournal = {Comput. Commun.},
  title        = {Latency and energy-aware provisioning of network slices in cloud networks},
  volume       = {157},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy protection-based incentive mechanism for mobile
crowdsensing. <em>COMCOM</em>, <em>156</em>, 201–210. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile crowdsensing (MCS) has been an emerging technology thanks to the smart devices which are capable of sensing and computing to achieve large-scale, complex sensing tasks by cooperation. However, large-scale deployment might be impeded due to that fact that the participant may face the risk of privacy leakage , and if they are not compensated favorably, they may not be willing to contribute sensing capability. To overcome the above challenges, we propose an incentive mechanism for privacy-preserving mobile crowdsensing. More specifically, we introduce a trusted third party and combine partially blind signature, which can effectively reduce the correlation between participants and data and the number of interactions between users and task platform, so as to achieve high level participant privacy . In addition, considering data quality, we define some concepts including data quality relevance, user credit, location relevance and user utility, and design a C redit-based I ncentive M echanism (CIM) based on marginal benefit density and credit, in order to obtain the maximum benefit of a task platform under given budget. Extensive simulations are carried out to show that the proposed incentive mechanism achieves superior performance compared with state-of-the-art solutions. To the existing multi-stage incentive solutions, our proposed solution can achieve higher-quality data at the expense of less time efficiency.},
  archive      = {J_COMCOM},
  author       = {Dan Tao and Tin-Yu Wu and Shaojun Zhu and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2020.03.027},
  journal      = {Computer Communications},
  pages        = {201-210},
  shortjournal = {Comput. Commun.},
  title        = {Privacy protection-based incentive mechanism for mobile crowdsensing},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A delay-aware coverage metric for bus-based sensor networks.
<em>COMCOM</em>, <em>156</em>, 192–200. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding sensors in urban buses is a promising strategy to deploy city-wide wireless sensor networks . By taking advantage of the mobility of buses, it is possible to achieve extended spatial coverage with fewer sensors as compared to a static setup. The trade-offs are that urban buses only cover part of the city, and that the frequency of the buses, and consequently of the data collection, is inhomogeneous across the city. Depending on the communication technology, buses may be unable to deliver the collected data on time. In this paper, we propose a coverage metric that takes into account the delivery delays of sensed data and the frequency at which a given region is sensed. The metric indicates, for a given time window, the proportion of streets that can be sensed under the requirements of an application. We apply the metric to more than 19 million GPS coordinates of 5,706 buses in Rio de Janeiro, mapping the coverage achieved for different application needs during a week. We build an abacus relating the coverage to different application requirements. We also calculate the coverage of a scenario only with static sensors. We show, among several observations, that bus-based sensing increases the coverage of applications by up to 7.6 times, in the worst case analyzed, when compared to a pure static scenario.},
  archive      = {J_COMCOM},
  author       = {Pedro Cruz and Rodrigo S. Couto and Luís Henrique M.K. Costa and Anne Fladenmuller and Marcelo Dias de Amorim},
  doi          = {10.1016/j.comcom.2020.03.043},
  journal      = {Computer Communications},
  pages        = {192-200},
  shortjournal = {Comput. Commun.},
  title        = {A delay-aware coverage metric for bus-based sensor networks},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DST-HRS: A topic driven hybrid recommender system based on
deep semantics. <em>COMCOM</em>, <em>156</em>, 183–191. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RS) provide customized suggestion to users for specific item across the bulk of identical data such as media recommendations, electronic commerce web pages &amp; social networks. RSs are being developed using the methods such as Collaborative Filtering (CF) and Contents Based Filtering (CB). However, CF suffers from sparseness problem wherein user-to-item data is sparse and CB filtering depends on feature extraction methods for item descriptions that require knowledge of content semantics and context of RS. In order to deal with the sparsity problem, various matrix factorization techniques embedded with pre-processed auxiliary information are used. On the other hand, currently employed techniques of feature extraction lack in deep semantics of items textual information as they individually cover either the semantic details or topic information. This paper proposes a hybrid RS model called Deep Semantic based Topic driven Hybrid RS (DST-HRS) that employs item description semantics influenced by its topics information. The proposed model extracts the embeddings by capturing the semantics of textual information and incorporates topic details into it. It further integrates these embeddings into Probabilistic Matrix Factorization (PMF), thus efficiently exploiting the semantics of items textual information such as reviews, synopsis, comments, plots etc to overcome the sparseness issue. The proposed DST-HRS can easily be deployed with lesser computation and time complexity. The model is validated on freely available datasets including Amazon Instant Video (AIV) and Movielens (1M &amp; 10M). The validation exhibited a better performance with respect to sparse ratings of user-to-item as compared to the state-of-the-art.},
  archive      = {J_COMCOM},
  author       = {Zafran Khan and Naima Iltaf and Hammad Afzal and Haider Abbas},
  doi          = {10.1016/j.comcom.2020.02.068},
  journal      = {Computer Communications},
  pages        = {183-191},
  shortjournal = {Comput. Commun.},
  title        = {DST-HRS: A topic driven hybrid recommender system based on deep semantics},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ELC: Edge linked caching for content updating in
information-centric internet of things. <em>COMCOM</em>, <em>156</em>,
174–182. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of things (IoT) has enabled every thing around us to have an Internet connection. In the future, IoT will generate more content than any other network. It is estimated that about 27 billion Internet enabled devices will connect to the Internet. For IoT, the current IP-based architecture, also known as Host-centric architecture, is not suitable. Therefore, a clean slate architecture is required to provide solutions to the problem. The researchers have recently proposed an appropriate architecture for this purpose, known as Information-Centric Network (ICN). ICN would potentially become the future Internet architecture as it has the ability to manage this huge number of IoT devices and their content. ICN’s in-network caching functionality is very useful for IoT, as it reduces the overhead of the publisher with respect to content access. This paper proposes an IoT caching strategy based on ICN that will effectively cache IoT data as well as update and evict content based on its freshness values.},
  archive      = {J_COMCOM},
  author       = {Hamid Asmat and Ikram Ud Din and Fasee Ullah and Muhammad Talha and Murad Khan and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2020.03.049},
  journal      = {Computer Communications},
  pages        = {174-182},
  shortjournal = {Comput. Commun.},
  title        = {ELC: Edge linked caching for content updating in information-centric internet of things},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). HMMs based masquerade detection for network security on with
parallel computing. <em>COMCOM</em>, <em>156</em>, 168–173. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Masquerade detection is currently an active research topic in the field of network security . This paper presents a novel method for detecting masquerade attacks based on hidden Markov models (HMMs), which applies to host-based intrusion detection systems using Unix or Linux shell commands as audit data. The method employs multiple command sequences of different lengths to represent the behavioral patterns of a legitimate user and constructs a specific HMM to characterize the normal behavior profile of the user. Moreover, the adaptability and precision of user profiling are definitely taken into account. During training, the parameters of the HMM are calculated by parallel computing that is less computationally expensive than the classic Baum–Welch algorithm. At the detection stage, the occurrence probabilities of short state sequences are first computed to analyze behavior deviations that may indicate masquerade attacks, and two alternative decision schemes can be used to classify the monitored user’s behavior as normal or anomalous. The method addresses both detection accuracy and computational efficiency and is especially suitable for online detection. Our study empirically demonstrates the promising performance of the method.},
  archive      = {J_COMCOM},
  author       = {Jia Liu and Miyi Duan and Wenfa Li and Xinguang Tian},
  doi          = {10.1016/j.comcom.2020.03.048},
  journal      = {Computer Communications},
  pages        = {168-173},
  shortjournal = {Comput. Commun.},
  title        = {HMMs based masquerade detection for network security on with parallel computing},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal arrangement of structural sensors in soft rock
tunnels based industrial IoT applications. <em>COMCOM</em>,
<em>156</em>, 159–167. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of China’s economy, many civil engineering structures such as high-rise buildings, bridges, dams and tunnel have increased rapidly. Sensor optimization layout, as an important technology of Structural Health Monitoring (SHM), has become one of the research hotspots in related fields and disciplines. Due to the limitations of civil engineering structures and real economic conditions, it is not possible to place sensors on all structural degrees of freedom. Therefore, it is of great theoretical and practical significance to study the optimal layout of sensors for civil engineering . The optimal layout of the sensor is to evaluate and monitor the civil engineering structure through a reasonably arranged limited sensor, which is a combinatorial optimization problem . At present, the algorithms for solving this problem are traditional optimization algorithms , sequence methods and intelligent optimization algorithms . Both traditional optimization algorithms and sequence methods can only obtain suboptimal solutions, which cannot guarantee the accuracy of sensor placement. In view of this, this paper proposes a sensor optimization arrangement based on the intelligent algorithm emerging in recent years. This paper introduces several common intelligent optimization algorithms, and proposes a hybrid intelligent algorithm combining Genetic Algorithm (GA) and Particle Swarm Optimization (PSO) algorithm. By comparing and analyzing the convergence of each algorithm, the results show that the hybrid algorithm has certain advantages over the single intelligent algorithm. In this paper, the hybrid intelligent algorithm is used to optimize the arrangement of the sensor. The experimental results show that the optimal layout of the sensor has certain rationality and feasibility.},
  archive      = {J_COMCOM},
  author       = {Chao Lin and Cheng-lin Zhang and Jie-hua Chen},
  doi          = {10.1016/j.comcom.2020.03.037},
  journal      = {Computer Communications},
  pages        = {159-167},
  shortjournal = {Comput. Commun.},
  title        = {Optimal arrangement of structural sensors in soft rock tunnels based industrial IoT applications},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interference minimization algorithms for fifth generation
and beyond systems. <em>COMCOM</em>, <em>156</em>, 145–158. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {5G and beyond (5G+) systems promise to provide better real-time services, efficient spectrum utilization, energy efficiency, and enhanced coverage. An ultra-dense small cells (SCs) network is an exceptional approach to serve these requirements; however, comes with the undesirable price ofsystem interference. Therefore, achieving a target data rate with minimal total system interference is a key research problem facing this generation. This paper utilizes the concept of associating SCs with network flying platforms (NFPs) such as unmanned balloons, drones, unmanned aerial vehicles (UAVs) . Each of these act as hubs between the core network and SCs. The association problem of SCs with NFPs is investigated while taking into consideration the following constraints: the number of NFP links, the NFP’s maximum bandwidth , whether a target data rate is maintained, etc. The goal of this work is to study the association problem of SCs with NFPs in order to achieve a minimized total interference. Two variants are discussed in this research. These are NP-hard problems that can be solved numerically using Integer Linear Programming to obtain the optimal solution. The first variant minimizes total interference while satisfying each SC data rate target and the second variant is to minimize the total interference while maintaining the system total sum rate target. We propose the bipartite matching and local search based algorithms to obtain sub-optimal solutions with reduced complexity. Integer linear programming based solution is examined to compare the performance of the proposed solutions. Simulation results show lower interference levels which approaching the derived bound with minimum total interference.},
  archive      = {J_COMCOM},
  author       = {Huda Y. AlSheyab and Salimur Choudhury and Ebrahim Bedeer and Salama S. Ikki},
  doi          = {10.1016/j.comcom.2020.03.046},
  journal      = {Computer Communications},
  pages        = {145-158},
  shortjournal = {Comput. Commun.},
  title        = {Interference minimization algorithms for fifth generation and beyond systems},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A probabilistic comparison-based fault diagnosis for hybrid
faults in mobile networks. <em>COMCOM</em>, <em>156</em>, 131–144. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis has always been vital to providing a high level of dependability in systems. The comparison approach is one of the most prevalent diagnosis techniques that offers a simple and yet practical way to identify faulty nodes in a system. Even though several comparison-based diagnostic models have already been introduced, the majority of them only diagnose permanent faults in static networks. Nowadays, intermittent faults and dynamic systems are more challenging to diagnose and become more common. This paper, first, proposes a novel comparison-based diagnostic model that deals with hybrid fault model in mobile networks. Both the diagnosable systems and faults under the proposed model have been characterized. Second, this paper proposes an efficient fault diagnosis protocol for hybrid faults in mobile networks. The proposed protocol employs a network coding technique to exchange the diagnosis messages so that it can provide a correct diagnosis with a higher probability of completeness. The correctness and complexity proofs of the proposed protocol are presented, and they show the viability of the proposed diagnostic model and protocol for hybrid faults in mobile networks. Besides, we study and analyse the performance of the proposed protocol under various fault and system parameters using OMNeT++ simulation. The simulation results show that our protocol can diagnose hybrid faults in mobile networks with high accuracy and less overhead.},
  archive      = {J_COMCOM},
  author       = {Hazim Jarrah and Peter H.J. Chong and Chris Rapson and Nurul I. Sarkar and Jairo Gutierrez},
  doi          = {10.1016/j.comcom.2020.03.042},
  journal      = {Computer Communications},
  pages        = {131-144},
  shortjournal = {Comput. Commun.},
  title        = {A probabilistic comparison-based fault diagnosis for hybrid faults in mobile networks},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Classification method of CO2 hyperspectral remote sensing
data based on neural network. <em>COMCOM</em>, <em>156</em>, 124–130.
(<a href="https://doi.org/10.1016/j.comcom.2020.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the dimension reduction of hyperspectral remote sensing image , a new neural network method is used to classify the hyperspectral remote sensing image of carbon dioxide in detail. Firstly, the Kernel Principal Component Analysis (KPCA) and Genetic Algorithms (GA) are used to reduce the dimension of hyperspectral remote sensing images; secondly, the traditional remote sensing image classification methods (ISODATA, SVM), traditional neural networks (BP), and new neural networks are used to classify the hyperspectral remote sensing images. Finally, noise assessment method based on local mean and local standard deviation (LMLSD) of spectral image is used to evaluate the classification accuracy . In addition, hyperspectral remote sensing images are dimensionality reduction. Secondly, the comparison between the traditional remote sensing image classification method and the new neural network method is analyzed. Finally, a new neural network method is applied to classify hyperspectral remote sensing images.},
  archive      = {J_COMCOM},
  author       = {Le Zhang and Jinsong Wang and Zhiyong An},
  doi          = {10.1016/j.comcom.2020.03.045},
  journal      = {Computer Communications},
  pages        = {124-130},
  shortjournal = {Comput. Commun.},
  title        = {Classification method of CO2 hyperspectral remote sensing data based on neural network},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance improvement of massive MIMO system under rapid
user mobility conditions. <em>COMCOM</em>, <em>156</em>, 112–123. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the uplink and downlink performance of single cell Massive multiple-input multiple-output (MIMO) system under channel varying conditions due to rapid user mobility. During uplink, the mobile users transmit orthogonal pilot sequences to the base station for channel state information (CSI) estimation prior to data transmission. During downlink, the base station sends orthogonal pilots to the users for estimating the downlink channel before data transmission. In both the cases, the signal to interference and noise ratio (SINR) and mean spectral efficiency are evaluated using suitable numerical analysis. The overall spectral efficiency maximization problem is found to be convex optimization problem consisting of various linear functions and quadratic expressions. By using primal decomposition, the convex problem is transformed into two sub-problems based on frame utilization and resource allocation. For efficient convergence of the sub-problems, a joint resource allocation and user scheduling (JRAUS) algorithm based on resource allocation scheme for frame allotment and user scheduling with matching techniques is proposed. Finally, the simulation results revealed the performance improvement of Massive MIMO network by the use of the proposed JRUAS algorithmic procedure under various conditions.},
  archive      = {J_COMCOM},
  author       = {Satyasen Panda},
  doi          = {10.1016/j.comcom.2020.03.038},
  journal      = {Computer Communications},
  pages        = {112-123},
  shortjournal = {Comput. Commun.},
  title        = {Performance improvement of massive MIMO system under rapid user mobility conditions},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local mutual exclusion algorithm using fuzzy logic for
flying ad hoc networks. <em>COMCOM</em>, <em>156</em>, 101–111. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Local Mutual Exclusion (LME) problem is a variant of classical Mutual Exclusion (ME) problem and can be considered as an extension of dining philosopher problem . In LME, no two neighboring nodes can enter the critical section (CS) simultaneously, whereas two non-neighboring nodes can be in their CS simultaneously. The resource allocation problem in Flying Ad hoc Networks (FANETs), is relatively an unexplored area despite having several potential applications. The present paper proposes LME problem for FANETs and provides a leader-based algorithm named as Request Collector Local Mutual Exclusion (RCLME) for the same. To the best of our information, LME problem is introduced first time in Flying Ad hoc Networks. The striking feature of the proposed algorithm is the introduction of a fuzzy logic-based leader election that considers the node speed, node direction, link quality, and the distance from the resource. The correctness proof of the RCLME algorithm has been presented. The simulation results show that RCLME algorithm significantly outperforms other related algorithms available in the literature; specially, when the number of nodes is large. The use of fuzzy logic and request collector improves the efficiency, fault tolerating capacity and ability to handle volatility.},
  archive      = {J_COMCOM},
  author       = {Ashish Khanna and Joel J.P.C. Rodrigues and Naman Gupta and Abhishek Swaroop and Deepak Gupta},
  doi          = {10.1016/j.comcom.2020.03.036},
  journal      = {Computer Communications},
  pages        = {101-111},
  shortjournal = {Comput. Commun.},
  title        = {Local mutual exclusion algorithm using fuzzy logic for flying ad hoc networks},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource allocation solution for sensor networks using
improved chaotic firefly algorithm in IoT environment. <em>COMCOM</em>,
<em>156</em>, 91–100. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that the location of the secondary base station affects the interference between the primary and secondary systems directly and the reasonable allocation of channel resources, an Internet of Things (IoT) sensor network resource allocation scheme using an improved chaotic firefly algorithm is proposed. This solution builds a multi-objective optimization model based on interference analysis of the working scenario of the cognitive radio . The goal is to protect the primary user’s normal activity to maximize the throughput of the secondary system and maximize the number of users that can be covered by the secondary base station . Because the multi-objective model is a non-linear convex optimization problem , the paper uses an improved chaotic firefly algorithm to solve it. Chaos algorithm is introduced into the firefly algorithm. By perturbing individuals, the convergence speed is accelerated and the probability of local optimization is reduced. The algorithm can efficiently obtain the optimal solution while reducing the complexity of the problem. The simulation results show that the method proposed in this paper can optimize the performance of the secondary system while guaranteeing the priority of the primary user. And it is superior to several advanced algorithms.},
  archive      = {J_COMCOM},
  author       = {Zhiyong Wang and Dong Liu and Alireza Jolfaei},
  doi          = {10.1016/j.comcom.2020.03.039},
  journal      = {Computer Communications},
  pages        = {91-100},
  shortjournal = {Comput. Commun.},
  title        = {Resource allocation solution for sensor networks using improved chaotic firefly algorithm in IoT environment},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Explore emission reduction strategy and evolutionary
mechanism under central environmental protection inspection system for
multi-agent based on evolutionary game theory. <em>COMCOM</em>,
<em>156</em>, 77–90. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the deteriorating environmental pollution, China has formulated a series of environmental regulation policies. However, political centralization and economic decentralization have subjected the local governments (LGs) to the dual constraints of environmental protection and economic development during the implementation of environmental regulation, which has resulted in the failure of conventional environmental regulation. To this end, the central government (CG) has established a central environmental protection inspection system (CEPIS). However, the existing literature has insufficiently studied the role and policy tools of the CG for inspecting the LGs and the polluting enterprises (PEs) to implement environmental regulation, and lacked systematic analysis of the strategic interactions and policy effects caused by CEPIS. Evolutionary game theory (EGT) provides a powerful tool with which to unpack the interactive strategies of Multi-Agent in China. By exploring the evolution of different participants’ behavior and their evolutionary stable strategy (ESS), EGT enables a robust, quantitative analysis of this three-party game. Simultaneously, some numerical examples serve to verify the theoretical results and support four key insights. First, the selection of environmental strategies manifests in a dynamic process of constant adjustment and optimization. Second, the whole evolutionary game system can converge on an ideal state under certain conditions. Third, increasing the investments in the special transfer payments of environmental protection, expanding the scale of emissions trading market, and improving the emission reduction benefits can motivate the PEs to reduce their emissions and the LGs to perform their duties. Fourth, in some scenarios, simply increasing the political penalties for the LGs fails to motivate the LGs to perform their duties. This research can provide the evolutionary mechanism and broaden our understanding of relationship between environmental regulation and emission reduction strategies. Related implications are finally proposed, which can offer valuable guidance on reforming the environmental regulation and improve market outcomes in China.},
  archive      = {J_COMCOM},
  author       = {Dashuang Chong and Na Sun},
  doi          = {10.1016/j.comcom.2020.02.086},
  journal      = {Computer Communications},
  pages        = {77-90},
  shortjournal = {Comput. Commun.},
  title        = {Explore emission reduction strategy and evolutionary mechanism under central environmental protection inspection system for multi-agent based on evolutionary game theory},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the identification and management of vehicle
behaviour based on internet of things technology. <em>COMCOM</em>,
<em>156</em>, 68–76. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The behaviour analysis of the electric vehicle is helpful to grasp the running condition , improve the running efficiency and ensure the safe operation of the vehicle. With the development of Internet of things (IoT) technology, it has become a reality to monitor and analyse the car behaviour. By analysing the functional requirements of the electric vehicle behaviour analysis management system , this paper designs behaviour analysis management system of electric vehicle based on the Internet of things technology . Firstly, the basic structure of the electric vehicle behaviour analysis management system based on the Internet of things technology is constructed, and then the deep network data mining model based on Hadoop is established to analyse the vehicle behaviour. The simulation results verify the reliability of the system. In addition, compared with the traditional support vector machine algorithm, this algorithm can effectively deal with massive data and improve the prediction accuracy by 9.76\%. Compared with other deep learning algorithms , it can improve the prediction accuracy by 3.64\%.},
  archive      = {J_COMCOM},
  author       = {Xueli Feng and Jie Hu},
  doi          = {10.1016/j.comcom.2020.03.035},
  journal      = {Computer Communications},
  pages        = {68-76},
  shortjournal = {Comput. Commun.},
  title        = {Research on the identification and management of vehicle behaviour based on internet of things technology},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis of SIIT implementations: Testing and
improving the methodology. <em>COMCOM</em>, <em>156</em>, 54–67. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the viability of the throughput and frame loss rate benchmarking procedures of RFC 8219 is tested by executing them to examine the performance of three free software SIIT (also called stateless NAT64) implementations: Jool, TAYGA, and map646. An important methodological problem of the two tested benchmarking procedures is pointed out: they use improper timeout setting. A solution of individually checking the timeout for each frame is proposed to get more reasonable results, and its feasibility is demonstrated. The unreliability of the results caused by the lack of requirement for repeated tests is also pointed out, and the need for relevant number of tests is demonstrated. The possibility of an optional non-zero frame loss acceptance criterion for throughput measurement is also discussed. The benchmarking measurements are performed using two different computer hardware, and all relevant results are disclosed and compared. The performance of the kernel based Jool was found to scale up well with the number of active CPU cores and Jool also significantly outperformed the two other SIIT implementations, which work in the user space.},
  archive      = {J_COMCOM},
  author       = {Gábor Lencse and Keiichi Shima},
  doi          = {10.1016/j.comcom.2020.03.034},
  journal      = {Computer Communications},
  pages        = {54-67},
  shortjournal = {Comput. Commun.},
  title        = {Performance analysis of SIIT implementations: Testing and improving the methodology},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep reinforcement learning and LSTM for optimal renewable
energy accommodation in 5G internet of energy with bad data tolerant.
<em>COMCOM</em>, <em>156</em>, 46–53. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the high penetration of large scale distributed renewable energy generations , there is a serious curtailment of wind and solar energy in 5G internet of energy. A reasonable assessment of large scale renewable energy grid-connected capacities under random scenarios is critical to promote the efficient utilization of renewable energy and improve the stability of power systems . To assure the authenticity of the data collected by the terminals and describe data characteristics precisely are crucial problems in assessing the accommodation capability of renewable energy. To solve these problems, in this paper, we propose an L-DRL algorithm based on deep reinforcement learning (DRL) to maximize renewable energy accommodation in 5G internet of energy. LSTM as a bad data tolerant mechanism provides real state value for the solution of accommodation strategy, which ensures the accurate assessment of renewable energy accommodation capacity. DDPG is used to obtain optimal renewable energy accommodation strategies in different scenarios. In the numerical results, based on real meteorological data , we validate the performance of the proposed algorithm. Results show considering the energy storage system and demand response mechanism can improve the capacity of renewable energy accommodation in 5G internet of energy.},
  archive      = {J_COMCOM},
  author       = {Lin Lin and Xin Guan and Benran Hu and Jun Li and Ning Wang and Di Sun},
  doi          = {10.1016/j.comcom.2020.03.024},
  journal      = {Computer Communications},
  pages        = {46-53},
  shortjournal = {Comput. Commun.},
  title        = {Deep reinforcement learning and LSTM for optimal renewable energy accommodation in 5G internet of energy with bad data tolerant},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The technology of intelligent recognition for drilling
formation based on neural network with conjugate gradient optimization
and remote wireless transmission. <em>COMCOM</em>, <em>156</em>, 35–45.
(<a href="https://doi.org/10.1016/j.comcom.2020.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem that drilling data is disturbed by environment noise, which affects the accuracy of stratum identification based on expert experience. Due to the impact of drilling environment and limited resources of drilling experts, experienced experts have been unable to visit the site in person to guide the site in the form of one-to-one. Firstly, the paper introduces remote wireless acquisition system for drilling formation intelligent identification. Secondly, because the drilling data is disturbed by environmental noise, the quality control algorithm of drilling sequence data is applied to eliminate the noise interference of original data. Finally, conjugate gradient optimization BP (CG-BP) neural network model is established to achieve accurate identification of formations. The results show that the error of CG-BP neural network model is 67.1\% less than that of BP neural network model in formation identification, and the convergence speed is fast in data training. The prediction accuracy is high in data prediction and the accuracy of formation identification is greatly improved. It has the value of field popularization and application.},
  archive      = {J_COMCOM},
  author       = {Jijun Zhang and Haibo Liang and Zhiwei Chen},
  doi          = {10.1016/j.comcom.2020.03.033},
  journal      = {Computer Communications},
  pages        = {35-45},
  shortjournal = {Comput. Commun.},
  title        = {The technology of intelligent recognition for drilling formation based on neural network with conjugate gradient optimization and remote wireless transmission},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving mobile ad hoc networks using hybrid IP-information
centric networking. <em>COMCOM</em>, <em>156</em>, 25–34. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routing protocols for Mobile Ad hoc NETworks (MANETs) constitute a research area with numerous evolved and well-investigated solutions that typically still rely on IP. Although IP-based protocols for MANETs can effectively handle network changes, thus enhancing connectivity while offering scalability, they lack support for advanced communication paradigms, which would enable richer applications and improve network goodput. Information-Centric Networking (ICN) is an inter-networking paradigm that natively supports functions that can enhance the performance of MANETs, such as multicast, multisource communication, and on-path caching. However, ICN raises significant scalability and feasibility concerns in the presence of intense node mobility. In this paper, we propose a hybrid architecture that combines the best of both worlds: it uses IP for maintaining network topology and it relies on ICN for content lookup and dissemination. To this end, we adapt the Named-Data Networking (NDN) ICN architecture to use legacy IP MANET routing protocols, such as Babel. Using a prototype implementation of our design and the Mininet Wi-Fi network emulator , we experimentally investigate the performance of our hybrid design in several scenarios, finding that the data delivery to network traffic ratio is increased up to 250\% and 300\% compared to pure NDN and IP solutions, respectively.},
  archive      = {J_COMCOM},
  author       = {Yiannis Thomas and Nikos Fotiou and Stavros Toumpis and George C. Polyzos},
  doi          = {10.1016/j.comcom.2020.03.029},
  journal      = {Computer Communications},
  pages        = {25-34},
  shortjournal = {Comput. Commun.},
  title        = {Improving mobile ad hoc networks using hybrid IP-information centric networking},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient on-demand spectrum sensing in sensor-aided
cognitive radio networks. <em>COMCOM</em>, <em>156</em>, 11–24. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectrum Sensing as a Service (SSaS) has recently emerged as a promising solution to realize dynamic spectrum access networks (aka, cognitive radio networks (CRNs)). This paradigm relies on a dedicated infrastructure wireless sensor network , operated by a spectrum sensing service provider S 3 P entity, for spectrum monitoring. Wireless users which are interested in knowing the status of a given spectrum band make a request to the S 3 P to perform that monitoring on its behalf. In this work, we study the problem of optimizing the selection of sensors needed to serve a given request such that the total cost (consumed energy) is minimized. We consider a spatial and temporal scheduling problem, in which, the energy levels at sensors, the maximum transmission range of secondary user (SUs), and the required monitoring time are taken into account. The problem is formulated as an Integer Linear Program (ILP). Then a sub-optimal greedy algorithm is proposed with two variations. Thorough evaluation shows that the proposed algorithm performs very well with respect to the optimal solution. Finally, results illustrate that the first algorithm variation is better in terms of energy cost, and the second variation allows for serving requests with a lower number of nodes.},
  archive      = {J_COMCOM},
  author       = {Osameh M. Al-Kofahi and Hisham M. Almasaeid and Haithem Al-Mefleh},
  doi          = {10.1016/j.comcom.2020.03.032},
  journal      = {Computer Communications},
  pages        = {11-24},
  shortjournal = {Comput. Commun.},
  title        = {Efficient on-demand spectrum sensing in sensor-aided cognitive radio networks},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Drone-surveillance for search and rescue in natural
disaster. <em>COMCOM</em>, <em>156</em>, 1–10. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing capability of drones and requirements to monitor remote areas, drone surveillance is becoming popular. In case of natural disaster, it can scan the wide affected-area quickly and make the search and rescue (SAR) faster to save more human lives. However, using autonomous drone for search and rescue is least explored and require attention of researchers to develop efficient algorithms in autonomous drone surveillance . To develop an automated application using recent advancement of deep-learning, dataset is the key. For this, a substantial amount of human detection and action detection dataset is required to train the deep-learning models. As dataset of drone surveillance in SAR is not available in literature, this paper proposes an image dataset for human action detection for SAR. Proposed dataset contains 2000 unique images filtered from 75,000 images. It contains 30000 human instances of different actions. Also, in this paper various experiments are conducted with proposed dataset, publicly available dataset, and stat-of-the art detection method. Our experiments shows that existing models are not adequate for critical applications such as SAR, and that motivates us to propose a model which is inspired by the pyramidal feature extraction of SSD for human detection and action recognition Proposed model achieves 0.98mAP when applied on proposed dataset which is a significant contribution. In addition, proposed model achieve 7\% higher mAP value when applied to standard Okutama dataset in comparison with the state-of-the-art detection models in literature.},
  archive      = {J_COMCOM},
  author       = {Balmukund Mishra and Deepak Garg and Pratik Narang and Vipul Mishra},
  doi          = {10.1016/j.comcom.2020.03.012},
  journal      = {Computer Communications},
  pages        = {1-10},
  shortjournal = {Comput. Commun.},
  title        = {Drone-surveillance for search and rescue in natural disaster},
  volume       = {156},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on cryptocurrencies and blockchains for
distributed systems. <em>COMCOM</em>, <em>155</em>, 266. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Stefano Ferretti ( Guest Editors ) and Gabriele D’Angelo},
  doi          = {10.1016/j.comcom.2020.03.028},
  journal      = {Computer Communications},
  pages        = {266},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on cryptocurrencies and blockchains for distributed systems},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure multi-cloud virtual network embedding.
<em>COMCOM</em>, <em>155</em>, 252–265. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern network virtualization platforms enable users to specify custom topologies and arbitrary addressing schemes for their virtual networks. These platforms have, however, been targeting the data center of a single provider, which is insufficient to support (critical) applications that need to be deployed across multiple trust domains, while enforcing diverse security requirements. This paper addresses this limitation by presenting a novel solution for the central resource allocation problem of network virtualization — the virtual network embedding, which aims to find efficient mappings of virtual network requests onto the substrate network . We improve over the state-of-the-art by considering security as a first-class citizen of virtual networks, while enhancing the substrate infrastructure with resources from multiple cloud providers . Our solution enables the definition of flexible policies in three core elements: on the virtual links, where alternative security compromises can be explored ( e.g. , encryption); on the virtual switches, supporting various degrees of protection and redundancy if necessary; and on the substrate infrastructure, extending it across multiple clouds, including public and private facilities, with their inherently diverse trust levels associated. We propose an optimal solution to this problem formulated as a Mixed Integer Linear Program (MILP). The results of our evaluation give insight into the trade-offs associated with the inclusion of security demands into network virtualization. In particular, they provide evidence that enhancing the user’s virtual networks with security does not preclude high acceptance rates and an efficient use of resources, and allows providers to increase their revenues.},
  archive      = {J_COMCOM},
  author       = {Max Alaluna and Luís Ferrolho and José Rui Figueira and Nuno Neves and Fernando M.V. Ramos},
  doi          = {10.1016/j.comcom.2020.03.023},
  journal      = {Computer Communications},
  pages        = {252-265},
  shortjournal = {Comput. Commun.},
  title        = {Secure multi-cloud virtual network embedding},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). D2D communication mode selection and resource allocation in
5G wireless networks. <em>COMCOM</em>, <em>155</em>, 244–251. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficient allocation of resources in the scenario of densely distributed mobile terminals in 5G networks , this paper proposes a resource allocation algorithm based on D2D communication mode selection. First, group D2D users according to their location distribution. Then, according to the priority order of communication needs, users are assigned modes, and the resource allocation is optimized by comparing the signal-to-noise ratio in orthogonal mode, multiplex mode, and cellular mode The simulation analysis of the throughput in the single-cell multi-user scenario shows that the algorithm can achieve the goal of allocating the best communication mode and resources for users with the maximum throughput output as a criterion.},
  archive      = {J_COMCOM},
  author       = {Gang Hou and Lizhu Chen},
  doi          = {10.1016/j.comcom.2020.03.025},
  journal      = {Computer Communications},
  pages        = {244-251},
  shortjournal = {Comput. Commun.},
  title        = {D2D communication mode selection and resource allocation in 5G wireless networks},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of dead beat controller using particle swarm
optimization for software defined network. <em>COMCOM</em>,
<em>155</em>, 235–243. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Renewable energy sources is largely adopted for generation of electrical energy and various methodologies have been proposed in this area This paper focuses on analysis, design and implementation of DC/DC buck–boost converter towards producing the hybrid prototype, consisting of 3kW PV and 3.2 kW PMSG using wind energy conversion system . Particle Swarm Optimization algorithm is employed for regulation of the output voltage generated. To extract maximum power, PSO algorithm is adopted for hybrid renewable energy sources which are considered as NP hard problem. To eliminate the harmonics and to have maximum electrical power delivered to the grid on polynomial time , the single phase or three phase sinusoidal pulse width modulation (SPWM) inverter has been employed with PQ control strategy using metaheuristic based approximation . The proposed PSO technique produces a steady state DC link voltage of 400 V with reduced harmonic distortion using LC filter. Further, the application of capacitor bank arrangement reduces the ripples present in the output voltage variations. The simulation outcomes prove the efficiency of the proposed model along its measurements.},
  archive      = {J_COMCOM},
  author       = {S. Malathi and K. Elango},
  doi          = {10.1016/j.comcom.2020.02.064},
  journal      = {Computer Communications},
  pages        = {235-243},
  shortjournal = {Comput. Commun.},
  title        = {Implementation of dead beat controller using particle swarm optimization for software defined network},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monitoring area coverage optimization algorithm based on
nodes perceptual mathematical model in wireless sensor networks.
<em>COMCOM</em>, <em>155</em>, 227–234. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of microelectronics technology, wireless communication technology and sensor technology, micro-structured sensors that can sense and communicate at the same time have emerged. This tiny device can sense all kinds of information in the surrounding environment, collect it to the sink node, and then transmit it to the data center . Wireless sensor networks are widely used in civil, industrial, agricultural, military and other fields. In order to meet the demand of monitoring area coverage effect, this paper firstly analyzes the research status of wireless sensor networks at home and abroad, points out the main problems existing in the current research process, and establishes a reasonable mathematical model according to the research status. Secondly, to solve the problem of poor coverage effect of existing algorithms, a monitoring area coverage optimization algorithm based on perceived probability around nodes is proposed. By designing a reasonable scheme of moving nodes, the algorithm can gradually disperse the nodes and improve the coverage effect in the monitoring area. Finally, the simulation results show that the algorithm has a good performance, which can reduce the moving distance of nodes, improve the coverage of the network and prolong the service time of the whole network.},
  archive      = {J_COMCOM},
  author       = {Qiangyi Li and Ningzhong Liu},
  doi          = {10.1016/j.comcom.2019.12.040},
  journal      = {Computer Communications},
  pages        = {227-234},
  shortjournal = {Comput. Commun.},
  title        = {Monitoring area coverage optimization algorithm based on nodes perceptual mathematical model in wireless sensor networks},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault management frameworks in wireless sensor networks: A
survey. <em>COMCOM</em>, <em>155</em>, 205–226. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are composed of a set of sensor nodes , widely spread out across the area and gather information. Some sensor nodes may develop a fault due to various reasons such as environmental effects. Since the occurrence of faults should not affect the desired function and functionality of network, fault management is vital to improve fault tolerance . Here, we classify faults based on their behavior, durability, and the components of network. Then the components of fault management and the challenges of fault management frameworks are represented. Also, other frameworks are analyzed to define their major challenges including energy consumption, fault detection accuracy, delay, the scalability and overhead of network. Other papers have classified fault management frameworks into centralized, distributed, and hierarchical, but we suggest a new classification based on the performance of management of each framework and the number of involved nodes. Next, frameworks have been analyzed and evaluated according to their major challenges. The analyses have provided a chance to offer more accurate and effective fault management frameworks with minimum energy consumption, delay, and overhead.},
  archive      = {J_COMCOM},
  author       = {Elham Moridi and Majid Haghparast and Mehdi Hosseinzadeh and Somaye Jafarali Jassbi},
  doi          = {10.1016/j.comcom.2020.03.011},
  journal      = {Computer Communications},
  pages        = {205-226},
  shortjournal = {Comput. Commun.},
  title        = {Fault management frameworks in wireless sensor networks: A survey},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Construction of information network vulnerability threat
assessment model for CPS risk assessment. <em>COMCOM</em>, <em>155</em>,
197–204. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber physical systems (CPS) has been hailed as the next future of computing by integrating information technology into physical systems to increase their capabilities. Information network is an organic part of CPS, and vulnerability threat assessment of information network is one of the important bases of CPS risk assessment. In view of the limitation of general information network vulnerability threat assessment technology, this paper proposes an information network vulnerability threat assessment model based on dynamic attack and defence game. Firstly, a risk assessment model suitable for CPS is constructed based on the actual control scheduling of information system. At the same time, considering the constraint conditions of both sides, including the quantity of available resources, rational allocation of resources, cost-effectiveness and the number of attacked nodes, a more perfect information network vulnerability threat assessment model is established. Then, on this basis, the dynamic attack and defence game function and game solution steps are designed to realize the quantitative assessment of information network vulnerability threat of CPS risk assessment. Finally, a simulation test based on IEEE 34-node information network system is carried out to verify the effectiveness of the proposed method.},
  archive      = {J_COMCOM},
  author       = {Juxia Xiong and Jinzhao Wu},
  doi          = {10.1016/j.comcom.2020.03.026},
  journal      = {Computer Communications},
  pages        = {197-204},
  shortjournal = {Comput. Commun.},
  title        = {Construction of information network vulnerability threat assessment model for CPS risk assessment},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UAV-enabled data acquisition scheme with directional
wireless energy transfer for internet of things. <em>COMCOM</em>,
<em>155</em>, 184–196. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low power Internet of Things (IoT) is suffering from two limitations: battery-power limitation of IoT nodes and inflexibility of infrastructure-node deployment. In this paper, we propose an Unmanned Aerial Vehicle (UAV)-enabled data acquisition scheme with directional wireless energy transfer (WET) to overcome the limitations of low power IoT. The main idea of the proposed scheme is to employ a UAV to serve as both a data collector and an energy supplier. The UAV first transfers directional wireless energy to an IoT node which then sends back the data packets to the UAV by using the harvested energy. Meanwhile, we minimize the overall energy consumption under conditions of balanced energy supply and limited overall time. Moreover, we derive the optimal values of WET time and data transmission power. After analysing the feasibility of the optimal WET time and data transmission, we design an allocation scheme based on the feasible ranges of data size level and channel-fading degree. The numerical results show the feasibility and adaptability of our allocation scheme against the varied values of multiple system parameters. We further extend our scheme to the multi-node scenario by re-designing energy beamforming and adopting multi-access mechanisms. Moreover, we also analyse the mobility of UAVs in the proposed scheme.},
  archive      = {J_COMCOM},
  author       = {Yalin Liu and Hong-Ning Dai and Hao Wang and Muhammad Imran and Xiaofen Wang and Muhammad Shoaib},
  doi          = {10.1016/j.comcom.2020.03.020},
  journal      = {Computer Communications},
  pages        = {184-196},
  shortjournal = {Comput. Commun.},
  title        = {UAV-enabled data acquisition scheme with directional wireless energy transfer for internet of things},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quality of service provisioning in named data networking via
PIT entry reservation and PIT replacement policy. <em>COMCOM</em>,
<em>155</em>, 166–183. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named Data Networking (NDN) is a promising candidate of Future Internet Architecture (FIA) designed to solve many long-standing issues in current IP architecture such as security, mobility, and content distribution inefficiency. Pending Interest Table (PIT) is one of the essential building blocks of NDN, which is used in the successful delivery of data packets to the requesters. It helps to achieve intrinsic advantages such as anonymity, interest aggregation, multi-cast delivery, multi-path forwarding, and security. NFD (NDN Forwarding Daemon) currently does not constrain the size of PIT. Over-allocation of PIT does not contribute to network performance improvement rather helps in performance degradation . Therefore, there is a need to restrict PIT size. However, in the presence of bursty traffic , PIT may turn out to be full, and new incoming Interest packets may get dropped. In this case, NDN faces a new challenge to achieve Quality of Service (QoS) under bursty traffic . This paper presents two simple schemes to solve this problem via PIT entry reservation and PIT entry replacement policy. We present analytical models of both the schemes using Continuous Time Markov Chain (CTMC). We derive blocking and forced termination probability of Interest packets as performance metrics. The accuracy of the models is validated through simulation results.},
  archive      = {J_COMCOM},
  author       = {Madhurima Buragohain and Sukumar Nandi},
  doi          = {10.1016/j.comcom.2020.03.021},
  journal      = {Computer Communications},
  pages        = {166-183},
  shortjournal = {Comput. Commun.},
  title        = {Quality of service provisioning in named data networking via PIT entry reservation and PIT replacement policy},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The intelligent vehicle target recognition algorithm based
on target infrared features combined with lidar. <em>COMCOM</em>,
<em>155</em>, 158–165. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent vehicle target detection system can sense and recognize the surrounding pedestrians, vehicles and other objects through sensors, which is the basis for achieving intelligent vehicle unmanned driving. The laser imaging radar actively emits laser light and receives its reflected echo, which can form an angle-angle-distance-intensity image, making it easier to realize target recognition. The combination of the lidar and the infrared characteristics of the target can obtain more information and improve target recognition and anti-interference ability. In order to achieve fast and accurate moving target detection in a complex battlefield environment, this paper studies lidar imaging and target infrared features, as well as intelligent vehicle target detection, and proposes a target recognition method that combines target infrared features and lidar. Compensation makes it difficult to describe the disadvantages of moving targets in a single source data. The experimental results show that the laser and infrared fusion detection algorithm does not increase the complexity of the algorithm, which greatly improves the adaptability and robustness of the vehicle target detection algorithm , and improves the accuracy of the measurement detection algorithm.},
  archive      = {J_COMCOM},
  author       = {Wanyi Zhang and Xiuhua Fu and Wei Li},
  doi          = {10.1016/j.comcom.2020.03.013},
  journal      = {Computer Communications},
  pages        = {158-165},
  shortjournal = {Comput. Commun.},
  title        = {The intelligent vehicle target recognition algorithm based on target infrared features combined with lidar},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient task scheduling and physiological
assessment in disaster management using UAV-assisted networks.
<em>COMCOM</em>, <em>155</em>, 150–157. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) and unmanned aerial vehicles (UAVs) together can significantly enhance the performance of disaster management systems . UAVs can collect massive heterogeneous data from disaster-affected areas using fifth-generation (5G)/beyond 5G networks and this data can be analyzed to get the information required by the first responders such as marking the boundary of the affected area, identifying the infrastructure damaged and the roads blocked, and the health situation of people living in that area. This paper presents an overview of different platforms (UAVs-based, IoT-based, and IoT, coupled with UAVs) for disaster management. We propose an energy-efficient task scheduling scheme for data collection by UAVs from the ground IoT network. The focus is to optimize the path taken by the UAVs to minimize energy consumption. We also analyze the vital signs data collected by UAVs for people in disaster-affected areas and apply the decision tree classification algorithm to determine their health risk status. The risk status will enable the first responders to decide the areas which need the most immediate help Simulation results compare the effectiveness of our proposed scheduling scheme with the traditional approach used for data collection. Also, we present the results of our predicted risk status compared with the risk status calculated through the National Early Warning Score 2 (NEWS2) method.},
  archive      = {J_COMCOM},
  author       = {Waleed Ejaz and Arslan Ahmed and Aliza Mushtaq and Mohamed Ibnkahla},
  doi          = {10.1016/j.comcom.2020.03.019},
  journal      = {Computer Communications},
  pages        = {150-157},
  shortjournal = {Comput. Commun.},
  title        = {Energy-efficient task scheduling and physiological assessment in disaster management using UAV-assisted networks},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A secure authentication scheme framework for mobile-sinks
used in the internet of drones applications. <em>COMCOM</em>,
<em>155</em>, 143–149. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the last decade, communication technologies have evolved rapidly, and this caused significant advancements for Internet of Things (IoT) applications and services. Unmanned aerial vehicles (UAVs), popularly known as drones, has attracted the interest of researches because of their fundamental attributes such as mobility, flexibility, reliability and energy efficiency in wireless networks. Similar to wireless sensor networks (WSNs) and other remote sensing applications, these devices are generally not designed with integrated security mechanisms. Furthermore, the existing solutions in which the main focus is on drone communication security are quite limited in the literature. Since the UAVs have the potential to handle very sensitive data, the exchange of information over wireless channels can cause serious exposures. The authentication schemes to be employed should be handled with care because of the limited resources and energy available with the sensor nodes . The existing enabling UAV technologies have restricted authentication privileges for their interaction with WSNs. In this paper, UAVs which can act like mobile-sinks are considered and existing work on WSN-UAV environment authentication is extended. A secure authentication framework using elliptic-curve crypto-systems is presented. The proposed framework is evaluated to ensure it is resilient to significant well-known potential attacks related with data confidentiality , mutual authentication, password guessing , and key impersonation.},
  archive      = {J_COMCOM},
  author       = {Yoney Kirsal Ever},
  doi          = {10.1016/j.comcom.2020.03.009},
  journal      = {Computer Communications},
  pages        = {143-149},
  shortjournal = {Comput. Commun.},
  title        = {A secure authentication scheme framework for mobile-sinks used in the internet of drones applications},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy aware decision stump linear programming boosting node
classification based data aggregation in WSN. <em>COMCOM</em>,
<em>155</em>, 133–142. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collection is a considerable operation in Wireless sensor network (WSN) to minimize the energy dissipation of sensor nodes and thereby increasing the network lifetime. A lot of research works have been designed for data gathering in WSN. A multi-mobile agent itinerary planning based energy and fault aware data aggregation and zone-based energy-aware data collection routing protocol was introduced to obtain better energy usage and data delivery in WSN. However, data aggregation accuracy was not increased and energy consumption during data aggregation was not reduced. In order to overcome such limitations, an Energy Aware Decision Stump Linear Programming Boosting Node Classification based Data Aggregation (EADSLPBNC-DA) Model is proposed. Initially, residual energy for every sensor node is calculated for performing the node classification. After that, linear programming boosting classification (LPBC) model is applied in EADSLPBNC-DA Model which increased the margin between the training samples (i.e., sensor nodes) of different classes. The LPBC model constructs a strong classifier by combining number of weak decision stump result. Subsequently, strong classifier in EADSLPBNC-DA Model accurately classifies each input sensor node as higher energy or lower energy node which reduced the misclassification error. Then, the lesser energy sensor nodes in WSN transmit the data packets to the neighboring higher energy sensor nodes through calculating the distance by Manhattan distance formula. Finally, the sink node gathers the data packets from the higher energy sensor nodes. As a result, EADSLPBNC-DA Model attains energy efficient data collection in WSN. Experimental evaluation of EADSLPBNC-DA Model is carried out on factors such as energy consumption, delay, data aggregation accuracy, network lifetime and data aggregation time with respect to number of sensor nodes and number of data packets. From the simulation results, proposed EADSLPBNC-DA Model significantly reduces the energy consumption by 22\%, delay by 35\% and data aggregation time by 28\% when compared to the existing techniques. In addition, the data aggregation accuracy and network lifetime gets increased by 13\% and 10\% respectively compared to state-of-the-art works.},
  archive      = {J_COMCOM},
  author       = {S. Kokilavani Sankaralingam and Sathish Kumar. N. and A.S. Narmadha},
  doi          = {10.1016/j.comcom.2020.02.062},
  journal      = {Computer Communications},
  pages        = {133-142},
  shortjournal = {Comput. Commun.},
  title        = {Energy aware decision stump linear programming boosting node classification based data aggregation in WSN},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum to “link quality and energy utilization based
preferable next hop selection routing for wireless body area networks”
[comput. Commun. 149 (2020) 382–392]. <em>COMCOM</em>, <em>155</em>,
132. (<a href="https://doi.org/10.1016/j.comcom.2019.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {K.N. Qureshi and S. Din and G. Jeon and F. Piccialli},
  doi          = {10.1016/j.comcom.2019.12.031},
  journal      = {Computer Communications},
  pages        = {132},
  shortjournal = {Comput. Commun.},
  title        = {Corrigendum to “Link quality and energy utilization based preferable next hop selection routing for wireless body area networks” [Comput. commun. 149 (2020) 382–392]},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards predictive analysis of android vulnerability using
statistical codes and machine learning for IoT applications.
<em>COMCOM</em>, <em>155</em>, 125–131. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the Internet of Things (IoT) technology is used for several applications for exchanging information among various devices. The intelligent IoT based system utilizes an Android operating system because it is also primarily used in mobile devices . One of the main problems for different IoT applications is associated with android vulnerability is its complicated and large size. To overcome the main issue of IoT, the existing studies have proposed several effective prediction models using machine learning algorithms and software metrics. In this paper, we are focused on conducting android vulnerability prediction analysis using machine learning for intelligent IoT applications. We conducted an empirical investigation for examining security risk prediction of 1406 Android applications with varying levels of risk using a metric set of 21 static code metrics and 6 machine learning (ML) techniques. It is observed from results that ML algorithms have different performances for predicting security risks. RF algorithm performs better for Android applications of all risk levels. By analyzing the findings of the conducted empirical study, it is suggested that developers may consider object-oriented metrics and RF algorithm in the software development process for android based intelligent IoT systems.},
  archive      = {J_COMCOM},
  author       = {Jianfeng Cui and Lixin Wang and Xin Zhao and Hongyi Zhang},
  doi          = {10.1016/j.comcom.2020.02.078},
  journal      = {Computer Communications},
  pages        = {125-131},
  shortjournal = {Comput. Commun.},
  title        = {Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deployment and optimization of wireless network node
deployment and optimization in smart cities. <em>COMCOM</em>,
<em>155</em>, 117–124. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Followed by digital cities and smart cities, another advanced form of information city has emerged, namely smart cities. Such kind of city is integrated with informationization, industrialization and urbanization. Smart cities belong to the fusion of multiple information technologies such as the Internet of Things technology and cloud computing technology. Smart city is the use of various sensors and wireless networks, communication technologies to achieve information interaction. The use of cloud computing and big data effectively integrate information is to make comprehensive decisions on various data to achieve comprehensive coordination of city operation management and industrial development. In the wireless city infrastructure of smart cities, the deployment of network nodes directly affects the quality of network services . The problem can be attributed to the deployment of appropriate ordinary AP nodes as access nodes of wireless terminals on a given geometric plane. The deployment of special nodes as gateways will aggregate the traffic of ordinary nodes into the wired network Taking the wireless mesh network as an example, it is proposed to determine the deployment location and number of AP nodes based on the statistics of regional human traffic, and the gateway node deployment problem is seen as a geometric K -center problem. Taking the minimum path length between the node and the gateway as the optimization goal, an adaptive particle swarm optimization (APSO) algorithm is proposed to solve the gateway node deployment position. In the APSO algorithm, improved strategies such as random adjustment of inertia weights, adaptive change of learning factors, and neighborhood search are introduced. A new calculation method of the fitness function is designed to make the algorithm easier to obtain the optimal solution. Simulation results show that, compared with GA algorithm and K -means algorithm, the improved particle swarm algorithm has a stable solution effect, strong robustness, and can obtain a smaller coverage radius, thereby improving the network service quality.},
  archive      = {J_COMCOM},
  author       = {Weiqiang Wang},
  doi          = {10.1016/j.comcom.2020.03.022},
  journal      = {Computer Communications},
  pages        = {117-124},
  shortjournal = {Comput. Commun.},
  title        = {Deployment and optimization of wireless network node deployment and optimization in smart cities},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Management of industrial communications slices: Towards the
application driven networking concept. <em>COMCOM</em>, <em>155</em>,
104–116. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the performance problems that many business critical applications are experiencing, network vendors and Network Service Providers (NSP) are reconsidering the integration of some form of application awareness in the way their networks forward user traffic. Their ultimate goal is to devise new network service models that are dedicated and customized to applications while efficiently using network resources. Even if this approach is not new and has been already followed with a mitigated success two decades ago, the emergence of software-Defined networking and network virtualization coupled with DPI (Deep Packet Inspection) pave the way for the investigation of new approaches/solutions towards application aware/driven networks. This is exactly the motivations of this work whose objective is to propose an Application Driven Network (ADN) that provides services to a specific type of applications, i.e. Dynamic Data Distribution Service (DDS) based applications. Considered as one of the leading connectivity standard for industrial IoT communications, focusing on DDS allows a fine-grained description of applications’ traffic and needs. With this information as input, the proposed ADN is able to provision network services that stick to application needs while using network resources efficiently. This paper sketches the general architecture of such ADN by describing its main components, their requirements as well as their algorithms. This solution has been implemented, prototyped and applied to a DDS based distributed interactive simulation application.},
  archive      = {J_COMCOM},
  author       = {Slim Abdellatif and Pascal Berthou and Thierry Villemur and Francklin Simo},
  doi          = {10.1016/j.comcom.2020.02.057},
  journal      = {Computer Communications},
  pages        = {104-116},
  shortjournal = {Comput. Commun.},
  title        = {Management of industrial communications slices: Towards the application driven networking concept},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple contents offloading mechanism in AI-enabled
opportunistic networks. <em>COMCOM</em>, <em>155</em>, 93–103. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of mobile devices and the emergence of 5G applications, the burden of cellular and the use of the licensed band have enormous challenges. In order to solve this problem, opportunity communication is regarded as a potential solution. It can use unlicensed bands to forward content to users under delay-tolerance constraints, as well as reduce cellular data traffic. Since opportunity communication is easily interrupted when User Equipment (UE) is moving, we adopt Artificial Intelligence (AI) to predict the location of the mobile UE. Then, the meta-heuristic algorithm is used to allocate multiple contents. In addition, deep learning-based methods almost need a lot of training time. Based on real-time requirements of the network, we propose AI-enabled opportunistic networks architecture, combined with Mobile Edge Computing (MEC) to implement edge AI applications . The simulation results show that the proposed multiple contents offloading mechanism can reduce cellular data traffic through UE location prediction and cache allocation.},
  archive      = {J_COMCOM},
  author       = {Wei-Che Chien and Shih-Yun Huang and Chin-Feng Lai and Han-Chieh Chao and M. Shamim Hossain and Ghulam Muhammad},
  doi          = {10.1016/j.comcom.2020.02.084},
  journal      = {Computer Communications},
  pages        = {93-103},
  shortjournal = {Comput. Commun.},
  title        = {Multiple contents offloading mechanism in AI-enabled opportunistic networks},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient SG-DACM framework for data integrity with user
revocation in role based multiuser cloud environment. <em>COMCOM</em>,
<em>155</em>, 84–92. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contemporary world activates with a enormous data that are stored and managed in the cloud server. For every cloud environment, there will be multi-users to access the data and group managers (GM) to regulate it. The major concern that evolved out of the cloud environment is to provide data security. Unfortunately with the recurrent changes, providing access control for the multiuser membership is the challenge and ensuring the data integrity in the cloud becomes a tedious task. Especially in the role-based user control, the revocation generates high computational and communication overheads . For handling these issues, a novel Sign crypto Group Data Access Control Mechanism (SG-DACM) framework has been proposed based on the user’s role. It involves three significant processes: 1. Random Bit Signcryption Generation (RBSG), that generate the digital signature to fortify the mechanism of group access and monitor the user revocation activities. 2. Factorial Prime Based Data Control (FPBDC) for preserving the data integrity through the cryptic mechanism. 3. Efficient Storage Retrieval (ESR) is performed for making the storage and retrieval of the processed data efficiently. The proposed framework is assessed for its performance metrics and related with the existing models. The outcome revealed that there was a reduction in communication and computation overheads. It is evident that the SG-DACM framework is efficient for the issues concerning the revoked users in the cloud environment.},
  archive      = {J_COMCOM},
  author       = {K. Ambika and M. Balasingh Moses},
  doi          = {10.1016/j.comcom.2020.03.006},
  journal      = {Computer Communications},
  pages        = {84-92},
  shortjournal = {Comput. Commun.},
  title        = {An efficient SG-DACM framework for data integrity with user revocation in role based multiuser cloud environment},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unmanned aerial vehicle for internet of everything:
Opportunities and challenges. <em>COMCOM</em>, <em>155</em>, 66–83. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advances in information and communication technology (ICT) have further extended Internet of Things (IoT) from the sole “things” aspect to the omnipotent role of “intelligent connection of things”. Meanwhile, the concept of internet of everything (IoE) is presented as such an omnipotent extension of IoT. However, the IoE realization meets critical challenges including the restricted network coverage and the limited resource of existing network technologies. Recently, Unmanned Aerial Vehicles (UAVs) have attracted significant attentions attributed to their high mobility, low cost, and flexible deployment. Thus, UAVs may potentially overcome the challenges of IoE. This article presents a comprehensive survey on opportunities and challenges of UAV-enabled IoE. We first present three critical expectations of IoE: (1) scalability requiring a scalable network architecture with ubiquitous coverage, (2) intelligence requiring a global computing plane enabling intelligent things, (3) diversity requiring provisions of diverse applications. Thereafter, we review the enabling technologies to achieve these expectations and discuss four intrinsic constraints of IoE (i.e., coverage constraint, battery constraint, computing constraint, and security issues). We then present an overview of UAVs. We next discuss the opportunities brought by UAV to IoE. Additionally, we introduce a UAV-enabled IoE (Ue-IoE) solution by exploiting UAVs’s mobility, in which we show that Ue-IoE can greatly enhance the scalability, intelligence and diversity of IoE. Finally, we outline the future directions in Ue-IoE.},
  archive      = {J_COMCOM},
  author       = {Yalin Liu and Hong-Ning Dai and Qubeijian Wang and Mahendra K. Shukla and Muhammad Imran},
  doi          = {10.1016/j.comcom.2020.03.017},
  journal      = {Computer Communications},
  pages        = {66-83},
  shortjournal = {Comput. Commun.},
  title        = {Unmanned aerial vehicle for internet of everything: Opportunities and challenges},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logistics industry monitoring system based on wireless
sensor network platform. <em>COMCOM</em>, <em>155</em>, 58–65. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of the logistics industry , the relevant technology is becoming more mature, the system is increasingly perfect, and the accuracy requirements for the logistics monitoring system are becoming higher and higher. Traditional logistics monitoring is usually manually recorded, which not only wastes manpower and is inefficient, but also cannot meet the current scale and intelligent development requirements of the logistics industry . The purpose of this article is to study modern logistics monitoring systems based on sensor networks and big data. Based on the in-depth study of three technologies of sensor network, big data and logistics technology, this article integrates the entire warehousing and distribution logistics process , and builds a monitoring system framework combining sensor network and big data based on the wireless sensor network software and hardware platform. Combining the two key methods studied in this paper, the information management process of traditional logistics operations such as outbound and inbound, warehousing positioning and monitoring, and distribution monitoring management are implemented, and the monitoring system is tested on this basis. The test results prove that this system has certain deployment reference significance and practical application value, and can help to improve the informationization and intelligence level of logistics management to a certain extent. In this paper, by simulating 250 concurrent users, the server CPU usage is 56.37\%, the server memory usage is 57.13\%, and the response time is 1944 ms.},
  archive      = {J_COMCOM},
  author       = {Jingjing Jiang and Haiwen Wang and Xiangwei Mu and Sheng Guan},
  doi          = {10.1016/j.comcom.2020.03.016},
  journal      = {Computer Communications},
  pages        = {58-65},
  shortjournal = {Comput. Commun.},
  title        = {Logistics industry monitoring system based on wireless sensor network platform},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SIR analysis for non-uniform HetNets with joint decoupled
association and interference management. <em>COMCOM</em>, <em>155</em>,
48–57. (<a href="https://doi.org/10.1016/j.comcom.2020.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In heterogeneous cellular networks (HetNets), fractional power control (FPC) is used in uplink (UL) transmission to improve signal-to-interference ratio (SIR) by compensating path loss. However, employing FPC results in a significant co-channel UL interference (UL-I) as a result of increased users’ transmit power. Moreover, macro base station (MBS) edge users make the situation exacerbate by transmitting with even higher power to compensate path loss and, thus, render FPC highly unsuitable in HetNets. In this paper, we aim to decrease severe UL-I and, thus, leverage FPC in HetNets. Hence, we propose non-uniform HetNets (NUHs) where small base stations (SBSs)’ deployment near MBS is avoided by using Poisson hole process (PHP). NUHs provide: (i) improved coverage due to coverage-oriented SBS distribution, and (ii) lower MBS-interference (MBS-I) as the SBSs are only deployed in coverage edge area of MBS. In conjunction with NUH, we employ decoupled association (DeCA), in contrast to coupled association (CA), to improve UL SIR. NUH along with DeCA provide lower UL-I and MBS-I due to reduced interference and improved UL SIR. Additionally, to efficiently utilize the radio resources, we employ reverse frequency allocation (RFA) to mitigate inter-cells-interference (ICI). We compare CA with DeCA in different network scenarios. Results indicate that the employment of DeCA leads to improved UL coverage, as compared with CA, due to effective mitigation of UL-I, MBS-I, and ICI. Moreover, the results indicate significant improvement in UL coverage for the SIR threshold values greater than 0 dB. Furthermore, the results show that a higher value of FPC compensation factor improves the coverage performance.},
  archive      = {J_COMCOM},
  author       = {Ziaul Haq Abbas and Muhammad Sajid Haroon and Ghulam Abbas and Fazal Muhammad},
  doi          = {10.1016/j.comcom.2020.03.015},
  journal      = {Computer Communications},
  pages        = {48-57},
  shortjournal = {Comput. Commun.},
  title        = {SIR analysis for non-uniform HetNets with joint decoupled association and interference management},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Urban expressway parallel pattern recognition based on
intelligent IOT data processing for smart city. <em>COMCOM</em>,
<em>155</em>, 40–47. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the sustained and rapid development of the social economy and the rapid growth of urban vehicles, urban expressway has developed rapidly. As the roadmap of urban traffic, the urban expressway has a relatively high and stable driving speed, and also bears a large amount of urban traffic. However, in recent years, with the expansion of the city scale, the congestion of urban expressways has become increasingly severe. In various areas of the merged area, due to various factors such as mismatched traffic capacity and reduced driving speed, it is easy to cause deterioration of road conditions in a short period of time and cause more secondary accidents. In order to reduce the incidence of expressway traffic accidents and to avoid as much as possible the casualties and property losses caused by accidents, Intelligent Transportation Systems (ITS) supported by information technology, data communication transmission technology, control technology and traffic engineering were introduced. With the rise of artificial intelligence and the continuous development of ITS, the video acquisition methods of real-time traffic flow data and the image recognition ability of video sequences continue to improve, providing theoretical basis and technical support for the research of urban expressway parallel pattern recognition. Aiming at the shortcomings of traditional pattern recognition methods, such as weak anti-interference to complex traffic environment and low correct recognition rate, this paper studies the pattern recognition method based on image processing , and selects the fuzzy C-means clustering in the currently used clustering methods (FCM) algorithm Because the FCM algorithm cannot obtain the global optimal solution and need to determine the number of cluster categories in advance, this paper uses ReliefF algorithm and Particle Swarm Optimization (PSO) to compare the feature weight and number of clusters of traditional FCM algorithm. Make improvements. Through the experimental analysis of the acquired video images, the results show that the improved FCM algorithm based on the proposed method has better real-time and accuracy in the application of urban expressway parallel pattern recognition.},
  archive      = {J_COMCOM},
  author       = {Zhendong Liu and Hongfei Jia and Yanxia Wang},
  doi          = {10.1016/j.comcom.2020.03.014},
  journal      = {Computer Communications},
  pages        = {40-47},
  shortjournal = {Comput. Commun.},
  title        = {Urban expressway parallel pattern recognition based on intelligent IOT data processing for smart city},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security information transmission algorithms for IoT based
on cloud computing. <em>COMCOM</em>, <em>155</em>, 32–39. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the traditional cloud computing-based information transmission mechanisms and IOT’s problems of large errors and low security, a heterogeneous integrated network resource management algorithm based on information security transmission is proposed. The algorithm adopts the advantages of information security transmission technology to collect resources in heterogeneous integrated network, then improves resource management algorithms and finally establishes a resource management algorithm model based on information security transmission, thereby implement the management process of heterogeneous integrated network resources. Through experimental demonstration and analysis methods, the effectiveness of the resource management algorithm is determined, which can reduce resource management errors and can improve security performance and management accuracy in the resource management process. In addition, the paper also introduces main data encryption technology and discusses the intelligent collection process of the Internet of Things(IoT), which is the technology background of the presented algorithm.},
  archive      = {J_COMCOM},
  author       = {Li Ding and Zhongsheng Wang and Xiaodong Wang and Dong Wu},
  doi          = {10.1016/j.comcom.2020.03.010},
  journal      = {Computer Communications},
  pages        = {32-39},
  shortjournal = {Comput. Commun.},
  title        = {Security information transmission algorithms for IoT based on cloud computing},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Performance optimization of IoT based biological systems
using deep learning. <em>COMCOM</em>, <em>155</em>, 24–31. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of sensors and high-throughput technologies has resulted in an exponential growth of big biological data. Various distributed biological systems have been deployed for big biological data analytics and providing consolidated information to its end users. Performance optimization plays a significant role while making these systems interactive and responsive. Current performance optimization techniques consider no or fewer history data of the system’s functional context while optimizing performance, especially at cache, persistence and computation levels. In this paper, an intelligent multi-agent-based performance optimization approach is proposed that addresses the performance issues at these three levels. Based on the internet of things (IoT) and deep learning paradigm, the proposed approach blends state-of-the-art probabilistic, recurrent neural network and long short term memory models to intelligently predict the upcoming behavior and optimization needs of the system. It intelligently persists and migrates biological data objects among different distributed system nodes. We deployed the proposed performance optimization approach and showed significant performance gain in comparison with existing approaches.},
  archive      = {J_COMCOM},
  author       = {Omer Irshad and Muhammad Usman Ghani Khan and Razi Iqbal and Shakila Basheer and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2020.02.059},
  journal      = {Computer Communications},
  pages        = {24-31},
  shortjournal = {Comput. Commun.},
  title        = {Performance optimization of IoT based biological systems using deep learning},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced anonymous models for microdata release based on
sensitive levels partition. <em>COMCOM</em>, <em>155</em>, 9–23. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depending on the inherent characteristic of sensitive attributes, even those existing enhanced anonymous models still permit the private information to be disclosed or have other limitations so far, such as skewness attacks or sensitive attacks. Based on this, three novel enhanced anonymous models, i.e., ( p , α i s g ) (p,αisg) -sensitive k k -anonymity model, ( p + , α i s g ) (p+,αisg) -sensitive k k -anonymity model and ( p i + , α i s g ) (pi+,αisg) -sensitive k k -anonymity model, are proposed to improve the privacy preservation by fully considering the sensitivity of different sensitive values on the sensitive attribute so as to realize better personalized privacy preservation . Different from the traditional methods, which basically quantify the sensitive level of the specific sensitive value focusing on user-defined classification approaches , the sensitivity of different sensitive values based on self-information is fully considered to obtain sensitive levels partition (SLP) so as to achieve better privacy by designing SLP from qualitative status towards quantitative status in our models. The conception of identical sensitive group (ISG), which is generated from the idea of hierarchical clustering method by using SLP algorithm, is introduced to design the anonymous models for better defending against sensitive attacks. In this case, the sensitive values with the most similar sensitivity are most likely clustered in the same ISG. Moreover, the frequency of each ISG is confined to no more than the specific personalized threshold α i s g αisg in any equivalence class without ending up with “one size for all” restrictions. Here, higher sensitive of ISG should be assigned a lower frequency constraint for resisting sensitive attacks so as to achieve better privacy. Then, two clustering algorithms are devised by using the idea of bottom-up greedy methods. Experiment results based on two real-world datasets show that our three anonymous models can effectively protect data privacy and enhance data security and practicality with certain information loss.},
  archive      = {J_COMCOM},
  author       = {Haina Song and Nan Wang and Jinkao Sun and Tao Luo and Jianfeng Li},
  doi          = {10.1016/j.comcom.2020.02.083},
  journal      = {Computer Communications},
  pages        = {9-23},
  shortjournal = {Comput. Commun.},
  title        = {Enhanced anonymous models for microdata release based on sensitive levels partition},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Industrial control systems: Cyberattack trends and
countermeasures. <em>COMCOM</em>, <em>155</em>, 1–8. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is generally understood that an attacker with limited resources would not be able to carry out targeted attacks on Industrial Control Systems . Breaking this general notion, we present case studies of major attacks on Industrial Control Systems (ICSs) in the last 20 years. The attacks chosen are the most prominent ones in terms of the economic loss inflicted, the potential to damage physical equipment and to cause human casualties. For each of these attacks, we describe the attack methodology used and suggest possible solutions to prevent such attacks. We analyze each case study to provide a better insight into the development of future cybersecurity techniques for ICSs. Finally, we suggest some recommendations on the best practices for protecting ICSs.},
  archive      = {J_COMCOM},
  author       = {Tejasvi Alladi and Vinay Chamola and Sherali Zeadally},
  doi          = {10.1016/j.comcom.2020.03.007},
  journal      = {Computer Communications},
  pages        = {1-8},
  shortjournal = {Comput. Commun.},
  title        = {Industrial control systems: Cyberattack trends and countermeasures},
  volume       = {155},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent approach for dynamic network traffic
restriction using MAC address verification. <em>COMCOM</em>,
<em>154</em>, 559–564. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are spread all throughout the world, usually found in homes, organizations, governments, etc. Due to the exponential growth in the deployment of networks, this field has become a prime target for attackers. A spoofing attack is a very common type of attack on a network. It may sound simple, but it is a complex technique involving impersonation and gaining access to restricted information. Some spoofing attacks complicate scenarios by launching other attackers using spoofed computers. Networks are usually unable to identify spoofing attacks since the hackers who attack can forge the MAC address of their device to impersonate another device on the network resulting in an advanced level of ARP spoofing thereby exposing the vulnerability of the network. This becomes really tricky when the attack is done in the address of a company’s network. Several techniques exist to detect MAC spoofing such as Sequence Number Analysis, Radio Signal strength based detection, and Hop based detection. But all these techniques wrongly classify malicious user to be authenticated ones at times costing the authenticity of the valuable legitimate users. In this paper, a design of an address verification technique to detect threats by using multiplicative increase and additive decrease algorithm based on network localization with the support of Port Scanning, OS fingerprinting and Route Tracing algorithms has been discussed. This eliminates the chance of a legitimate user getting penalized during the traffic restriction resulting in a more trustworthy and a more intelligent network.},
  archive      = {J_COMCOM},
  author       = {M. Anathi and K. Vijayakumar},
  doi          = {10.1016/j.comcom.2020.02.021},
  journal      = {Computer Communications},
  pages        = {559-564},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent approach for dynamic network traffic restriction using MAC address verification},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized evolutionary algorithm and supervised ACO
mechanism to mitigate attacks and improve performance of adhoc network.
<em>COMCOM</em>, <em>154</em>, 551–558. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization is the procedure of discovering optimal solution or results under particular circumstances. Typically, optimization is utilized for maximization or minimization of values of functions; it can be local or global optima. Discovering exact solutions to the issues is NP-hard. This type of complicated issue needs exponential quantities of computation power as well as item and quantity of decision parameters rise. For overcoming the issues, research scholars have suggested Evolutionary Algorithm (EA) protocols as a way for searching near-optimal solutions. In this work, Ant Colony Optimization (ACO) is used combined with the power of faith on effective factors in distance of trustworthy optimum routing in WSN. ACO has its basis in the foraging behavior of ants who look for the shortest route between then nest and the food source. The energy efficient node random trust based on routing network is designed in a safe and random routing mode that reveals all fingerprints and useful load distribution. The details are combined with confidence choices, using a modified ACO algorithm. The ACO application, makes this method a stronger and faster with a metaheuristic algorithm compared with the other routing methodologies. Modified ACO method, exercise as a parameter for calculating the energy levels of terminals used fitness route planning its organization. Proposed work shows improvement in the network performance under Dos and DDoS attack in terms of amount of data loss, data delay.},
  archive      = {J_COMCOM},
  author       = {J. Sathya Priya and K. Saravanan and A.R. Sathyabama},
  doi          = {10.1016/j.comcom.2020.02.070},
  journal      = {Computer Communications},
  pages        = {551-558},
  shortjournal = {Comput. Commun.},
  title        = {Optimized evolutionary algorithm and supervised ACO mechanism to mitigate attacks and improve performance of adhoc network},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An energy-aware drone trajectory planning scheme for
terrestrial sensors localization. <em>COMCOM</em>, <em>154</em>,
542–550. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Employing GPS-equipped drones to act as mobile anchors is a popular solution for terrestrial sensors positioning in a generic environment. Researchers have proposed several approaches, usually to reduce estimated locations error and increase localization coverage, though no efficient solution has been presented for energy conservation of the drone. Drones, such as the commercial quadcopters, have limited power supply and cannot fly long. Any localization algorithm should consider the energy constraints beside the performance indicators. Furthermore, there is no suggested strategy to mitigate the error of Received Signal Strength (RSS)-based distance measurements in the existing solutions. In this paper, we propose a novel scheme to plan the drone trajectory, called the “Weighted Energy-aware Trajectory with Adaptive Radius ( WETAR )”. The proposed scheme employs Linear Programming (LP) for trajectory planning in the presence of the sensors with given estimative regions which are acquired in a range-free pre-localization phase. It also specifies candidate waypoints, which are the projection of aerial anchor points on the ground, and assign weights to them based on two criteria: quality of the beacons that the sensors would receive and their coverage ratio. We assume that sensors utilize a range-based localization algorithm on the basis of RSS measurements. Simulation results show that the WETAR as an aerial anchor guiding mechanism, guides the drone effectively and reduces localization time, saves the drone energy, and improves the location error as well as the localization coverage.},
  archive      = {J_COMCOM},
  author       = {Sahar Kouroshnezhad and Ali Peiravi and Mohammad Sayad Haghighi and Alireza Jolfaei},
  doi          = {10.1016/j.comcom.2020.02.055},
  journal      = {Computer Communications},
  pages        = {542-550},
  shortjournal = {Comput. Commun.},
  title        = {An energy-aware drone trajectory planning scheme for terrestrial sensors localization},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy and delay efficient fog computing using caching
mechanism. <em>COMCOM</em>, <em>154</em>, 534–541. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing has emerged as an extension to the existing cloud infrastructure for providing latency-aware and highly scalable services to geographically distributed end devices. The addition of the fog layer in the cloud computing paradigm helps to improve the quality of service (QoS) in time-critical and delay-sensitive applications. Due to the continuous increase in the deployment of fog networks at large scale, energy efficiency is a significant issue in the fog computing paradigm to reduce the service cost and to protect the environment. A plethora of research has been conducted to reduce energy consumption in fog computing, majorly, focusing on the scheduling of incoming jobs to improve energy efficiency. However, node-level mechanisms have largely been neglected. Cache placement is a critical issue in fog networks for efficient content distribution to clients, which requires simultaneous consideration of many factors including quality of network connection, the demand for contents, and users’ activities. In this paper, a popularity-based caching mechanism in content delivery fog networks is proposed. In this context, two energy-aware mechanisms, i.e., content filtration and load balancing, have been applied. In the proposed approach, popular contents are found using random distribution and these contents are categorized into three classes. After finding the file popularity, an active fog node is selected based on the number of neighbors, energy level, and operational power. Further, the popular content is cached on the active node using a filtration mechanism. Moreover, a load-balancing algorithm is proposed to increase the overall system efficiency in the cached fog network. The evaluation of the proposed approach exhibits promising results in terms of energy consumption and latency. The proposed scheme consumes 92.6\% and 82.7\% less energy in comparison to without caching and simple caching mechanisms, respectively. Similarly, an improvement of 85.29\% and 67.4\% in delay has also been noticed while using advance caching against the without caching and simple caching techniques, respectively.},
  archive      = {J_COMCOM},
  author       = {Muzammil Hussain Shahid and Ahmad Raza Hameed and Saif ul Islam and Hasan Ali Khattak and Ikram Ud Din and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.comcom.2020.03.001},
  journal      = {Computer Communications},
  pages        = {534-541},
  shortjournal = {Comput. Commun.},
  title        = {Energy and delay efficient fog computing using caching mechanism},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperative comodule discovery for swarm-intelligent drone
arrays. <em>COMCOM</em>, <em>154</em>, 528–533. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a method for discovering comodules from a drone array. Herein, a comodule represents a frequent connection pattern among drones and their connected targets (e.g., mobile phones and end users) — Frequent connections among drone-to-drone (D2D) and drone-to-target (D2T) patterns. In the Internet of Drones (IoD), where sensing and communications become a major task, it is important to explore the cooperative components (i.e., subgraphs or comodules) of the network because data streams frequently flow through those components. Once a comodule is found, the control center can notify the drones along with their connected targets to process data in a cooperative mode. However, it is difficult to extract comodules since the topology of the IoD is fluid. Additionally, the targets connected to the IoD could be dynamic and mobile. To effectively discover comodules while considering mobile targets at the same time, this study proposes regularized self-organizing sparse network factorization. It jointly decomposes a connection network formed by a drone array and its connected targets into basis and coefficient matrices . Comodules can be explored by examining those matrices. Experiments were carried out on open Call Data Records and a drone array. The results show that the proposed method generated less divergence and higher tightness between the nodes of a comodule than the baseline did.},
  archive      = {J_COMCOM},
  author       = {Hsin Chuang and Kuan-Lin Hou and Seungmin Rho and Bo-Wei Chen},
  doi          = {10.1016/j.comcom.2020.02.077},
  journal      = {Computer Communications},
  pages        = {528-533},
  shortjournal = {Comput. Commun.},
  title        = {Cooperative comodule discovery for swarm-intelligent drone arrays},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New-flow based DDoS attacks in SDN: Taxonomy, rationales,
and research challenges. <em>COMCOM</em>, <em>154</em>, 509–527. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined Networking (SDN) is an emerging technology that revolves around the fundamental notion of setting up a network with a decoupled control plane and data plane. It brings numerous benefits such as improved network manageability, flexibility, and programmability to measure up to the enormous demands of future networking. However, it also comes with security concerns that are intrinsically present in SDN’s architecture. In classic SDN, a switch acts as a forwarding device that has to forward a packet towards the centralized controller for every new flow that comes into the network. Out of this design philosophy, a new-flow based distributed denial-of-service (DDoS) attack is born, which presents this internal flow-based policy as a critical security vulnerability to confiscate the scarce resources of the control plane and data plane in an SDN network. In this paper, we propose a classification of such security vulnerabilities exposed by SDN architecture and leveraged by a new-flow based DDoS attack. We also provide an analysis of the latest developments made in recent years on DDoS detection and mitigation research works to overcome these security vulnerabilities. Finally, we discuss SDN security-related research challenges that can be valuable for the research community and academics for carrying out further research and investigation.},
  archive      = {J_COMCOM},
  author       = {Maninder Pal Singh and Abhinav Bhandari},
  doi          = {10.1016/j.comcom.2020.02.085},
  journal      = {Computer Communications},
  pages        = {509-527},
  shortjournal = {Comput. Commun.},
  title        = {New-flow based DDoS attacks in SDN: Taxonomy, rationales, and research challenges},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FCO — fuzzy constraints applied cluster optimization
technique for wireless AdHoc networks. <em>COMCOM</em>, <em>154</em>,
501–508. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient energy utilization in wireless adhoc networks is always an open issue. To achieve energy efficiency, clustering technique would be an optimal one. In clustering technique using advanced optimization methods will provide expected results. By considering this, in this research work fuzzy constraints based cluster optimization technique is proposed. This technique considers fuzzy parameters namely device energy, device position, device movement/speed and device hop-count for calculating the fitness value of the nodes. Based on the value cluster head selection happens. This technique is enhanced to handle uncertainty conditions like cluster head failure, topology changes and energy depletion of the cluster head. The proposed technique is compared with four existing systems and the comparison results illustrates that the proposed technique is more optimal than compared LEACH, MPO, EDC, TCACWCA.},
  archive      = {J_COMCOM},
  author       = {Amin Salih Mohammed and Saravana Balaji B and Saleem Basha M S and Asha P N and Venkatachalam K},
  doi          = {10.1016/j.comcom.2020.02.079},
  journal      = {Computer Communications},
  pages        = {501-508},
  shortjournal = {Comput. Commun.},
  title        = {FCO — fuzzy constraints applied cluster optimization technique for wireless AdHoc networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy optimization of the configurable service portfolio
for IoT systems. <em>COMCOM</em>, <em>154</em>, 491–500. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of the Internet of Things technology has promoted the continuous improvement of information technology in various fields such as industry, military and transportation. And communication and information exchange through the Internet, with the ability to sense, so smart devices came into being. First, this article proposes an IoT service framework that encapsulates each function of a smart device in an IoT environment into a service that is aggregated into a service class based on the similarity of its functions. Secondly, based on the particle swarm optimization algorithm, the correct service combination is recommended for the service chain. The gray correlation degree evaluation method is used to serve configurable resources, and the combined energy scheme is used for multi-objective comprehensive evaluation. Among them, the configurable service combination plan is evaluated from four aspects: service resource cost, planned completion time, overdue time and resource idle rate. The experimental results show that the particle swarm optimization algorithm can obtain a relatively good IoT service combination, which has better performance than genetic algorithms and ant colony algorithms, and can maintain the load balance of smart devices in load balancing, thereby effectively extending the entire network Life cycle.},
  archive      = {J_COMCOM},
  author       = {Xiaojing Zhu},
  doi          = {10.1016/j.comcom.2020.03.008},
  journal      = {Computer Communications},
  pages        = {491-500},
  shortjournal = {Comput. Commun.},
  title        = {Energy optimization of the configurable service portfolio for IoT systems},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy enhancement using multiobjective ant colony
optimization with double q learning algorithm for IoT based cognitive
radio networks. <em>COMCOM</em>, <em>154</em>, 481–490. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is the efficient wireless communication in the modern era, energy efficiency is the primary issue that focuses mainly on the Cognitive network. Most of the CR networks are focusing on battery powdered to predominantly utilize the data dissipated in terms of spectrum sharing , dynamic spectrum access , routing and spectrum allocation. The clustering and data aggregation are the best efforts technique to enhance the energy modeling. Multiobjective Ant colony optimization (MOACO)and greedy based optimization proposed with Deep Reinforcement Learning with Double Q-learning algorithm. Most of the IoT bed models involve data aggregation and energy constrained devices with optimization techniques to enhance utilization. The cluster-based data utilization is proposed with the Q-learning algorithm and it enhances the inter cluster data aggregation. The network lifetime is improved with AI-based modeling with intra-network to enhance green communication. The simulation experiments showcase that the throughput, lifetime and jamming prediction is analyzed and enhances the energy using the MOACO, when compared to the artificial bee colony and genetic algorithm . The jamming activity at low, high moderate stages is analyzed using the AI and MOACO algorithms.},
  archive      = {J_COMCOM},
  author       = {S. Vimal and Manju Khari and Rubén González Crespo and L. Kalaivani and Nilanjan Dey and M. Kaliappan},
  doi          = {10.1016/j.comcom.2020.03.004},
  journal      = {Computer Communications},
  pages        = {481-490},
  shortjournal = {Comput. Commun.},
  title        = {Energy enhancement using multiobjective ant colony optimization with double q learning algorithm for IoT based cognitive radio networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Node layout plans for urban underground logistics systems
based on heuristic bat algorithm. <em>COMCOM</em>, <em>154</em>,
465–480. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper qualitatively classifies the nodes of logistics system as logistics center and distribution center. For planning a logistics center, the requirement of each demand point is considered with a set covering model. Concerning the planning of distribution center, 0–1 mixed integer programming model is constructed to minimize the total logistics costs which include construction, fixed, and distribution costs. This paper introduces the principle and advantages of Bat-inspired Algorithm in a detailed manner. The urban underground logistics system within the central ring road of Shanghai is taken as an example and MATLAB is applied. It is proved that the improved Bat-inspired Algorithm converges faster than the basic Bat-inspired Algorithm and can find the optimal solution more quickly. This paper provides theoretical basis for further study of the urban underground logistics system.},
  archive      = {J_COMCOM},
  author       = {Mengxiao He and Ling Sun and Xufeng Zeng and Wei Liu and Song Tao},
  doi          = {10.1016/j.comcom.2020.02.075},
  journal      = {Computer Communications},
  pages        = {465-480},
  shortjournal = {Comput. Commun.},
  title        = {Node layout plans for urban underground logistics systems based on heuristic bat algorithm},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A lightweight authentication and key agreement scheme for
internet of drones. <em>COMCOM</em>, <em>154</em>, 455–464. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones in Internet of Drones (IoD) can be able to reconnoiter environment, transport the commodity with the help of embedded various sensors. They have been widely used in various fields and brought a great convenience to the production and life. But data collected by sensors embedded in drones are facing new security challenges and privacy issues with the technology update over time. For the sake of ensuring the security of transmitted data, many authentication and key agreement (AKA) schemes have been proposed in the past. Nevertheless, most of schemes are subjected to serious security risks and have high communication and computation cost. To address these issues in IoD, we propose a lightweight AKA scheme in which there are only secure one-way hash function and bitewise XOR operations when drones and users mutually authenticate each other. The proposed scheme can achieve AKA-security under the random oracle model and withstand various known attacks. Meanwhile, the security comparison demonstrates our proposed scheme provides better security. In terms of communication and computation cost, our proposed scheme has better functionality features than the other two schemes.},
  archive      = {J_COMCOM},
  author       = {Yunru Zhang and Debiao He and Li Li and Biwen Chen},
  doi          = {10.1016/j.comcom.2020.02.067},
  journal      = {Computer Communications},
  pages        = {455-464},
  shortjournal = {Comput. Commun.},
  title        = {A lightweight authentication and key agreement scheme for internet of drones},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensing and throughput analysis of a MU-MIMO based cognitive
radio scheme for the internet of things. <em>COMCOM</em>, <em>154</em>,
442–454. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art energy detection (ED) based spectrum sensing requires perfect knowledge of noise power and is vulnerable to noise uncertainty. An eigenvalue-based spectrum sensing approach performs well in such an uncertain environment, but does not mitigate the spectrum scarcity problem, which evolves with the future Internet of Things (IoT) rollout. In this paper, we propose a multi-user multiple-input and multiple-output (MU-MIMO) based cognitive radio scheme for the Internet of Things (CR-IoT) with weighted-eigenvalue detection (WEVD) for the analysis of sensing, system throughput, energy efficiency and expected lifetime. In this scheme, each CR-IoT user is being equipped with MIMO antennas; we calculate the WEVD ratio, which is defined as the ratio between the difference of the maximum eigenvalue and minimum eigenvalue to the sum of the maximum eigenvalue and minimum eigenvalue. This mitigates against the spectrum scarcity problem, enhances system throughput, improves energy efficiency, prolongs expected lifetime and lowers error probability. Simulation results confirm the effectiveness of the proposed scheme; here the WEVD technique demonstrates a better detection gain and enhanced system throughput in comparison to the conventional scheme with eigenvalue based detection (EVD) and ED techniques in a noise uncertainty environment (i.e. SNR &amp;lt; -28). Furthermore, the proposed scheme has a lower energy consumption , prolonged expected lifetime and achieves a low error probability when compared with other schemes like the conventional single-input and single-output (SISO) based CR-IoT scheme with EVD and ED spectrum sensing.},
  archive      = {J_COMCOM},
  author       = {M.S. Miah and M. Schukat and E. Barrett},
  doi          = {10.1016/j.comcom.2020.03.003},
  journal      = {Computer Communications},
  pages        = {442-454},
  shortjournal = {Comput. Commun.},
  title        = {Sensing and throughput analysis of a MU-MIMO based cognitive radio scheme for the internet of things},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decision based unsymmetrical trimmed modified winsorized
variants for the removal of high density salt and pepper noise in images
and videos. <em>COMCOM</em>, <em>154</em>, 433–441. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Decision Based Unsymmetrical trimmed modified Winsorized Variants for the removal of high density salt and pepper noise in images and videos is proposed. The algorithm initially checks for fixed outliers (0 or 255) in the images in a fixed 3x3 neighbourhood. If the processed pixel is an outlier then 4 neighbours are checked for noise. If all 4 neighbours are noisy then mean of 4 neighbours replaces the corrupted pixel. If 4 neighbours are not noisy then number of non noisy pixels is used to replace the corrupted pixel either with unsymmetrical trimmed modified Winsorized median or midpoint. The processed pixel is left unaltered if the pixel does not hold the outliers. The exhaustive experiments on standard database images and videos indicate that the DBUTMWV algorithm has good noise elimination capabilities with excellent information preservation characteristics even at very high noise densities.},
  archive      = {J_COMCOM},
  author       = {Vasanth kishorebabu and R. Varatharajan},
  doi          = {10.1016/j.comcom.2020.02.048},
  journal      = {Computer Communications},
  pages        = {433-441},
  shortjournal = {Comput. Commun.},
  title        = {A decision based unsymmetrical trimmed modified winsorized variants for the removal of high density salt and pepper noise in images and videos},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Opportunistic LoRa-based gateways for delay-tolerant sensor
data collection in urban settings. <em>COMCOM</em>, <em>154</em>,
410–432. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are several ways that sensor nodes in a smart city setting can get data to a base station for processing. Sensor nodes that need not report their data to the base station in real time can opt for a delay-tolerant networking or data muling setup. If the data collector itself would send the data to the internet through its own (mobile) backhaul link, we can consider the data collector to be a mobile gateway . The choice of radio technology for the link between the sensor or end device and the mobile gateway is important: it would affect the number of mobile gateways needed, the required mobility pattern for them to provide a certain level of delay guarantees to the data, and the overall efficiency of the scheme. LoRa, with its long range and relatively low power consumption , can potentially decrease the number of gateways needed in the system, while decreasing delays. This study explores opportunistic, mobile LoRa-based gateways using a pull-based transfer of data to implement a low cost system in terms of communication and the hardware used. We present a MAC layer protocol, for use with the LoRa radio/physical layer, with three gateway operation modes: Independent , Pure Pass Through , and Instruction-based . Comparison with a more traditional baseline system with push-based transfer of data reveals that our pull-based system performs better in terms of percentage of data points that are successfully sent by the end devices to the network server. We also evaluate the performance and scalability of the three modes using a small campus-wide deployment and discrete-event simulations. Experiments reveal that of the three modes, the Instruction-based mode is the most balanced in terms of computation power requirement and communication costs. In this mode, the network server handles the computation load, while the gateway handles the generation of the beacons. This shows a better result compared to the other modes wherein the computation load and beacon generation is condensed in the gateway or the network server. This also follows that the communication cost is high in the latter setup since it is dependent on the connection between the gateway and the network server. Our results also show that while utilizing multiple gateways can result in lower delays, they have to be used carefully, since the existence of multiple gateways in the system can easily result to problems with interference, possibly degrading, instead of improving, the performance of the system.},
  archive      = {J_COMCOM},
  author       = {Nikki John B. Florita and Alyssa Nicole M. Senatin and Angela Margaret A. Zabala and Wilson M. Tan},
  doi          = {10.1016/j.comcom.2020.02.066},
  journal      = {Computer Communications},
  pages        = {410-432},
  shortjournal = {Comput. Commun.},
  title        = {Opportunistic LoRa-based gateways for delay-tolerant sensor data collection in urban settings},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tunable q-factor wavelet transform of acoustic emission
signals and its application on leak location in pipelines.
<em>COMCOM</em>, <em>154</em>, 398–409. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tunable Q-factor wavelet transform (TQWT) is a discrete wavelet transform realized by the iterative two-channel filter group and the discrete Fourier transform (DFT). In this paper, the TQWT is applied to the extraction of leakage signals of the water pipeline network. By using the maximum principle of kurtosis, the Q-factor and the number of decomposition layer were determined to overcome the disadvantages of prefixed Q-factor and number of decomposition layers. The combination of kurtosis and envelope entropy was used to select the subband with abundant information. And then, correlation analysis was conducted further to locate the leakage point. Furthermore, a laboratory water pipe and an outdoor actual water pipe system were built to study the leakage signal. By analyzing the leakage signal from both experimental system, it can be found that the leakage signal characteristics of different leakage points for actual water pipe are all in the first layer, and the positioning error of each leakage point is within 1\%. It indicates that TQWT can effectively extract the leakage components from the leakage signal of low SNR and has a higher location accuracy of the leak point.},
  archive      = {J_COMCOM},
  author       = {Tao Meng and Deguo Wang and Jingpin Jiao and Xiaolong Li},
  doi          = {10.1016/j.comcom.2020.02.047},
  journal      = {Computer Communications},
  pages        = {398-409},
  shortjournal = {Comput. Commun.},
  title        = {Tunable Q-factor wavelet transform of acoustic emission signals and its application on leak location in pipelines},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of attitude tracking algorithm for face
recognition based on OpenCV in the intelligent door lock.
<em>COMCOM</em>, <em>154</em>, 390–397. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of information system authentication is a major problem. Automated embedded systems in today’s world have made a lot of progress. The importance of an automated embedded system has proved highly effective in applications such as surveillance and private security. Modern smart door locks are very susceptible to errors and damage, which will reduce security. Almost every intelligent Door lock has a passcode entry or faces recognition outside the door which makes it vulnerable. The paper is intended to provide the user with open source software OpenCV and proposed an Efficient attitude tracking algorithm (EATA). Furthermore, this article aims to ensure that a key lock system that is retro and modern simultaneously offers a certain safety and reliability. The experimental results show that the proposed system is more efficient, consumes less power, and cost-effective.},
  archive      = {J_COMCOM},
  author       = {Zhiguo Zhu and Yao Cheng},
  doi          = {10.1016/j.comcom.2020.02.003},
  journal      = {Computer Communications},
  pages        = {390-397},
  shortjournal = {Comput. Commun.},
  title        = {Application of attitude tracking algorithm for face recognition based on OpenCV in the intelligent door lock},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Construction of complex network of green infrastructure in
smart city under spatial differentiation of landscape. <em>COMCOM</em>,
<em>154</em>, 380–389. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the rapid urban and economic development, environmental problems have become prominent due to urban expansion and land imbalances. However, good historical and cultural landscapes are distributed in urban centers in large cities, and ecologically-friendly forests, lakes, or farmlands are distributed around these cities. It has the spatial differentiation of landscape resources. Landscape resources are used to build a composite green foundation, and the network of facility can improve urban environmental problems. The methods used in the work included landscape connectivity, minimum cumulative resistance model, Gravity model, Kernel Density Analysis, and Circuit theory. Through these methods, the ecological and cultural landscape networks were constructed, forming a composite network of green infrastructure by organic coupling of node composite, construction of composite landscape corridor, and corridor composite. The results showed that the subjective analysis and landscape connectivity analysis were used to quantitatively evaluate the importance of patches, thus selecting the superior ecological nodes. The minimum cumulative resistance analysis and gravity model were used to extract the GI corridors and their importance, respectively, with ecological landscapes constructed. Kernel density analysis and circuit theory could determine the cultural landscape nodes and extract cultural landscape corridors. Node composite, composite landscape corridor construction, and corridor composite are important methods to couple the composite green infrastructures. Compared to traditional ecological network, it can protect regional culture and ecology.},
  archive      = {J_COMCOM},
  author       = {He Huang and Minghuan Zhang and Kunyong Yu and Yaling Gao and Jian Liu},
  doi          = {10.1016/j.comcom.2020.02.042},
  journal      = {Computer Communications},
  pages        = {380-389},
  shortjournal = {Comput. Commun.},
  title        = {Construction of complex network of green infrastructure in smart city under spatial differentiation of landscape},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud providers ranking and selection using quantitative and
qualitative approach. <em>COMCOM</em>, <em>154</em>, 370–379. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is basically an internet based computing, whereby shared configurable resources are provided to cloud service consumers as services on demand. As an increasing growth of cloud computing, many enterprises provide different cloud services to cloud service consumers . From cloud service consumer’s perspective, it is difficult to choose an appropriate cloud service that satisfies their QoS requirements. As requirements of one cloud service consumer will vary from another, dynamic ranking has to be used to satisfy the requirements of different cloud service consumers. A simple model is needed to address the dynamic ranking of cloud services. The dynamic ranking and selection of cloud services is solved using Linear Programming (LP) model. This project considers quantifiable attributes such as processor speed, cost, etc. and some non-quantifiable attributes like feedback to rank various cloud services according to the requirements of cloud service consumer using Linear Programming (LP) technique.},
  archive      = {J_COMCOM},
  author       = {Devi R. and Shanmugalakshmi R.},
  doi          = {10.1016/j.comcom.2020.02.028},
  journal      = {Computer Communications},
  pages        = {370-379},
  shortjournal = {Comput. Commun.},
  title        = {Cloud providers ranking and selection using quantitative and qualitative approach},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint offloading decision and resource allocation for mobile
edge computing enabled networks. <em>COMCOM</em>, <em>154</em>, 361–369.
(<a href="https://doi.org/10.1016/j.comcom.2020.02.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) based solutions are essential and of great significance for a wide range of promising 5G wireless big data services such as remote healthcare systems and AR/VR games. Present research in this area focuses on the downlink resource allocation scenarios from MEC servers to user equipments (UEs). This paper considers a multi-user MEC-enabled wireless communication system, where UEs suffer limited communication and computation resources. To achieve higher energy efficiency and the better experience for UEs, we aim to maximize the number of offloaded tasks for all UEs in uplink communication while maintaining the computation resources of MEC at an acceptable level. The formulated problem is an NP-hard mixed-integer nonlinear programming problem and it is a challenge to solve it efficiently. As such, an efficient low-complexity heuristic algorithm is proposed, which provides a near-optimal solution with a low time cost. The results show that the proposed scheme achieves the higher number of successful offloaded tasks than the existing centralized resource allocation algorithm (CRAA) and centralized decision and resource allocation algorithm that UEs with the largest saved energy consumption accepted first (CAR-E) under different scenarios. Moreover, the relationship between the optimal transmission power and the computation resource of MEC is investigated. The results obtained in this paper can be extended to design a novel framework of communication, computation and smart coded caching MEC networks.},
  archive      = {J_COMCOM},
  author       = {Yangzhe Liao and Liqing Shou and Quan Yu and Qingsong Ai and Quan Liu},
  doi          = {10.1016/j.comcom.2020.02.071},
  journal      = {Computer Communications},
  pages        = {361-369},
  shortjournal = {Comput. Commun.},
  title        = {Joint offloading decision and resource allocation for mobile edge computing enabled networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive IoT system with intelligence techniques in
sustainable computing environment. <em>COMCOM</em>, <em>154</em>,
347–360. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forest border crossing animals creates major societal related issues, in addition to endangering their own lives. This is the objective focused in this paper targeting the species “The Elephant”, incorporating with technical methodologies namely, multi-sensor data fusion, cognition theories and computational intelligence techniques. Multi-sensor data fusion provides three level detection of target, along with its related outputs, which improves performance metrics. Cognition theory resulted in obtaining other interesting features about the target. Computational intelligence techniques integrate and conclude the presence of the target in the pseudo-boundary. The technical combination enhances the novelty of the research work, resulting in achieving remarkable accuracy and minimized false alert. An IoT kit was designed and deployed in the real time wild environment in Hosur forest region for collecting the data of Elephant. Further, the notification is sent to the registered mobile of the forest authority, as an early warning for chasing the pachyderm back to the forest.},
  archive      = {J_COMCOM},
  author       = {Arun Kumar Sangaiah and Jerline Sheebha Anni Dhanaraj and Prabu Mohandas and Aniello Castiglione},
  doi          = {10.1016/j.comcom.2020.02.049},
  journal      = {Computer Communications},
  pages        = {347-360},
  shortjournal = {Comput. Commun.},
  title        = {Cognitive IoT system with intelligence techniques in sustainable computing environment},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wireless control using reinforcement learning for practical
web QoE. <em>COMCOM</em>, <em>154</em>, 331–346. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless networks show several challenges not found in wired networks, due to the dynamics of data transmission. Besides, home wireless networks are managed by non-technical people, and providers do not implement full management services because of the difficulties of manually managing thousands of devices. Thus, automatic management mechanisms are desirable. However, such control mechanisms are hard to achieve in practice because we do not always have a model of the process to be controlled, or the behavior of the environment is dynamic. Thus, the control must adapt to changing conditions, and it is necessary to identify the quality of the control executed from the perspective of the user of the network service . This article proposes a control loop for transmission power and channel selection, based on Software Defined Networking and Reinforcement Learning (RL), and capable of improving Web Quality of Experience metrics, thus benefiting the user. We evaluate a prototype in which some Access Points are controlled by a single controller or by independent controllers. The control loop uses the predicted Mean Opinion Score (MOS) as a reward, thus the system needs to classify the web traffic. We proposed a semi-supervised learning method to classify the web sites into three classes (light, average and heavy) that groups pages by their complexity, i.e. number and size of page elements. These classes define the MOS predictor used by the control loop. The proposed web site classifier achieves an average score of 87\% ± 1\% 87\%±1\% , classifying 500 unlabeled examples with only fifteen known examples, with a sub-second runtime. Further, the RL control loop achieves higher Mean Opinion Score (up to 167\% in our best result) than the baselines. The page load time of clients browsing heavy web sites is improved by up to 6.6x.},
  archive      = {J_COMCOM},
  author       = {Henrique D. Moura and Daniel F. Macedo and Marcos A.M. Vieira},
  doi          = {10.1016/j.comcom.2020.02.032},
  journal      = {Computer Communications},
  pages        = {331-346},
  shortjournal = {Comput. Commun.},
  title        = {Wireless control using reinforcement learning for practical web QoE},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic signal control for smart cities using reinforcement
learning. <em>COMCOM</em>, <em>154</em>, 324–330. (<a
href="https://doi.org/10.1016/j.comcom.2020.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is increasing globally, and this problem needs to be addressed by the traffic management system . Traffic signal control (TSC) is an effective method among various traffic management systems. In a dynamically changing and interconnected traffic environment, the currently model-based TSCs are not adaptive. In addition, with the rise of smart cities and IoT , there is a need for efficient TSCs that can handle large and complex data. To address this issue, this study proposes a TSC system to maximize the number of vehicles crossing an intersection and balances the signals between roads by using Q-learning (QL). The proposed system has a flexible structure that can be modified to suit the changes in the original structure of the intersection.},
  archive      = {J_COMCOM},
  author       = {Hyunjin Joo and Syed Hassan Ahmed and Yujin Lim},
  doi          = {10.1016/j.comcom.2020.03.005},
  journal      = {Computer Communications},
  pages        = {324-330},
  shortjournal = {Comput. Commun.},
  title        = {Traffic signal control for smart cities using reinforcement learning},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Applications of artificial intelligence and machine learning
in smart cities. <em>COMCOM</em>, <em>154</em>, 313–323. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart cities are aimed to efficiently manage growing urbanization, energy consumption, maintain a green environment, improve the economic and living standards of their citizens, and raise the people’s capabilities to efficiently use and adopt the modern information and communication technology (ICT). In the smart cities concept , ICT is playing a vital role in policy design, decision, implementation, and ultimate productive services. The primary objective of this review is to explore the role of artificial intelligence (AI), machine learning (ML), and deep reinforcement learning (DRL) in the evolution of smart cities. The preceding techniques are efficiently used to design optimal policy regarding various smart city-oriented complex problems. In this survey, we present in-depth details of the applications of the prior techniques in intelligent transportation systems (ITSs), cyber-security, energy-efficient utilization of smart grids (SGs), effective use of unmanned aerial vehicles (UAVs) to assure the best services of 5G and beyond 5G (B5G) communications, and smart health care system in a smart city. Finally, we present various research challenges and future research directions where the aforementioned techniques can play an outstanding role to realize the concept of a smart city.},
  archive      = {J_COMCOM},
  author       = {Zaib Ullah and Fadi Al-Turjman and Leonardo Mostarda and Roberto Gagliardi},
  doi          = {10.1016/j.comcom.2020.02.069},
  journal      = {Computer Communications},
  pages        = {313-323},
  shortjournal = {Comput. Commun.},
  title        = {Applications of artificial intelligence and machine learning in smart cities},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A technological framework for data-driven IoT systems:
Application on landslide monitoring. <em>COMCOM</em>, <em>154</em>,
298–312. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of the paradigm of the Internet of Things has underpinned the development of data-driven cyber–physicalsystems that collect and process data that is dense both in space and time. The application areas of such data-driven IoT systems are numerous and their socio-economic impact of great importance as they enable the monitoring and management of processes in sectors ranging from urban management to management of the natural environment. In this work, we introduce and detail an end-to-end technological framework for data-driven IoT systems for landslide monitoring. The framework is articulated in three tiers — namely data acquisition, data curation and data presentation For each tier we present and detail its design and development aspects; from the IoT hardware design and the wireless communication technologies of choice, to how Big Data infrastructure and Machine Learning components can be combined to support a sophisticated presentation tier that delivers the true added value of a system to its final users. The framework is validated, extended and fine-tuned by means of two pilots at locations experiencing the impact of different landslide types and activity. This work qualitatively improves upon existing methods of landslide monitoring and showcases how data-driven IoT systems can pave new pathways for interdisciplinary research as well as generate positive impact on modern societies.},
  archive      = {J_COMCOM},
  author       = {Sivanarayani M. Karunarathne and Matthew Dray and Lyudmil Popov and Matthew Butler and Catherine Pennington and Constantinos Marios Angelopoulos},
  doi          = {10.1016/j.comcom.2020.02.076},
  journal      = {Computer Communications},
  pages        = {298-312},
  shortjournal = {Comput. Commun.},
  title        = {A technological framework for data-driven IoT systems: Application on landslide monitoring},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Information spreading in a population modeled by continuous
asynchronous probabilistic cellular automata. <em>COMCOM</em>,
<em>154</em>, 288–297. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a model for information propagation in a population based on cellular automata . Different to what is commonly used in the models of the area, instead of a binary level for the information, individuals have a level of knowledge. Moreover, the population can have a marketing campaign to help to spread the information with a certain limit due to the consideration of marketing rejection in the model. Numerical simulations show that these campaigns must be wisely set in order to not saturate the population and decrease the marketing balance due to the rejection. The simulation data is statistically analyzed by using principal component analysis in order to identify the most relevant variables for the model output. The conclusion is that dealing with this rejection is difficult, as well as choosing the percentage of the population which will receive the marketing, and along with the weight for the word-of-mouth were the most important variables of the model according to the simulations and the principal component analysis.},
  archive      = {J_COMCOM},
  author       = {E. Silva and F.H. Pereira and P.H.T. Schimit},
  doi          = {10.1016/j.comcom.2020.02.074},
  journal      = {Computer Communications},
  pages        = {288-297},
  shortjournal = {Comput. Commun.},
  title        = {Information spreading in a population modeled by continuous asynchronous probabilistic cellular automata},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Mining of instant messaging data in the internet of things
based on support vector machine. <em>COMCOM</em>, <em>154</em>, 278–287.
(<a href="https://doi.org/10.1016/j.comcom.2020.02.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development and popularization of mobile communication technology, mobile communication has been applied in more and more industries, and has effectively promoted the progress of the times. How to take effective methods and means to ensure the correct classification and mining of effective instant messaging information has become a top priority for major operators. Based on the analysis of the theory and feature selection technology of support vector machine in machine learning field, this paper studies the main parameters that affect the feature selection of support vector machine , aiming at the dimension disaster caused by large-scale data volume and redundant features of the Internet of things . In this paper, an algorithm is proposed to optimize the feature subsets of samples, and then add the parameters of support vector machine to optimize the classification. The experimental results show that the algorithm has a good effect on the classification of effective instant messaging information of Internet of things big data, and has a good effect and practical application value.},
  archive      = {J_COMCOM},
  author       = {Yang Chen},
  doi          = {10.1016/j.comcom.2020.02.080},
  journal      = {Computer Communications},
  pages        = {278-287},
  shortjournal = {Comput. Commun.},
  title        = {Mining of instant messaging data in the internet of things based on support vector machine},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A wearable device for collecting multi-signal parameters of
newborn. <em>COMCOM</em>, <em>154</em>, 269–277. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, wearable health monitoring equipment has developed rapidly, but most functions are relatively single and can only monitor certain physiological parameters of the human body. This paper designed a wearable multi-physiological parameter monitoring system, which can continuously monitor multiple physiological parameters of newborns for a long time without affecting the normal human activities . The hardware circuit uses MSP430F1611 single-chip microcomputer as the central processing unit . The single-chip computer program completes the calculation of multiple parameters and sends them to the Bluetooth module through the serial port . The Bluetooth module receives the data and transmits it through the module antenna. After testing, each function module works normally. The results of the heart rate measurement experiments show that more than 96\% of the heart rate data is within ± ± 3 BPM (Beat Per Minute). The experimental results of arterial oxygen saturation measurement show that the error of arterial oxygen saturation is within ± ± 2\%. The results of arterial blood pressure measurement experiments show that the error between systolic and diastolic blood pressure meets the standard.},
  archive      = {J_COMCOM},
  author       = {Xiqiu Hu and Jingrong Cao and Hao Wu},
  doi          = {10.1016/j.comcom.2020.02.082},
  journal      = {Computer Communications},
  pages        = {269-277},
  shortjournal = {Comput. Commun.},
  title        = {A wearable device for collecting multi-signal parameters of newborn},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Joint variational bayesian based localization estimation
algorithm on distributed gas source sensor network. <em>COMCOM</em>,
<em>154</em>, 262–268. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the non-linear and unknown diffusion distribution model characteristics of gas leakage diffusion in the real environment, a distributed joint optimal estimation algorithm for gas source localization and parameters estimation was proposed in sensor networks. Firstly, the gas source localization framework was constructed based on the compressed sensing theory, Secondly, the joint sparse estimation method of the state distribution and unknown parameters of gas diffusive source is proposed based on the variational Bayesian inference algorithm. In which, an adaptive grid division strategy is given to improve the accuracy and performance of the joint estimation method and to balance the relationship between energy consumption and network resources. Finally, simulation results show that the proposed algorithm could effectively achieve a joint estimation of the diffusive source state and parameters, which could achieve higher estimation accuracy in a shorter time and meet the real-time requirements in complex environment compared with the traditional CS method.},
  archive      = {J_COMCOM},
  author       = {Yong Zhang and Tong Wang and Yu Shi and Liyi Zhang},
  doi          = {10.1016/j.comcom.2020.02.060},
  journal      = {Computer Communications},
  pages        = {262-268},
  shortjournal = {Comput. Commun.},
  title        = {Joint variational bayesian based localization estimation algorithm on distributed gas source sensor network},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent energy efficient cooperative MIMO-AF
multi-hop and relay based communications for unmanned aerial vehicular
networks. <em>COMCOM</em>, <em>154</em>, 254–261. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs) are recently used for both civilian and military applications in worldwide. Energy Efficiency (EE) is an exceptional design approach for modern communication based systems. New advance technology is needed in order to support UAV applications with reduced energy usage. In this paper, an Energy Efficiency with Hybrid Fuzzy Firefly Algorithm (EE-HFFA) method is introduced for Multiple-Input–Multiple-Output (MIMO) Amplify-And-Forward (AF) systems in which Partial Channel State Information (PCSI) estimation is existing at the relays because of the high speed mobility. A new EE-HFFA algorithm is presented in this research, by means of merging the benefits of the Firefly Algorithm (FA) as well as Differential Evolution (DE). For increasing information sharing both the techniques are implemented in parallel and as a result improve searching efficiency. The outcomes of these two techniques are based upon the fuzzy membership function . For approximation of PCSI for the source node as well as relay nodes , Branch Convolutional Neural Network (B-CNN) classifier is presented to raise the capability of cooperative MIMO-AF systems. EE-optimal source and relay precoding matrices are cooperatively enhanced by means of EE-HFFA. Simulation out comes illustrate that the presented EE-HFFA as well as B-CNN classifier could enhance the EE of MIMO-AF systems with PSCI while matched up with direct/relay link merely precoding optimization.},
  archive      = {J_COMCOM},
  author       = {S. Kanithan and N. Arun Vignesh and E. Karthikeyan and N. Kumareshan},
  doi          = {10.1016/j.comcom.2020.01.029},
  journal      = {Computer Communications},
  pages        = {254-261},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent energy efficient cooperative MIMO-AF multi-hop and relay based communications for unmanned aerial vehicular networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Max–min fairness driven multicast sparse beamforming for
cache-enabled cloud RAN. <em>COMCOM</em>, <em>154</em>, 246–253. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud radio access network (C-RAN) is able to boost network capacity through centralized scheduling of multiple distributed base stations (BSs). Yet it also places serious burdens on backhaul links. Caching and multicast are two enabling candidates to alleviate backhaul cost and achieve efficient content delivery. In this paper, we consider a cache-enabled multicast C-RAN, where multiple BSs cooperatively serve multiple user groups. Each BS is equipped with local storage and is connected to the central processor (CP) via a backhaul link. Then, the beamforming vectors and dynamic BS clustering is carefully designed to maximize fairness among users. To achieve such a goal, a semidefinite relaxation (SDR)-based iterative difference-of-two-convex-function (D.C.) algorithm is proposed by using semidefinite programming (SDP) and smoothed l 0 l0 -norm approximation approaches. After that, to reduce computational complexity , a two-tier convex quadratic-based alternating (TCQA) algorithm is devised by decoupling multi-ratio fractional constraints. In this algorithm, the outer problem is handled in closed-form expressions while the inner one is solved by using D.C. programming. Convergence and complexity of the two proposed algorithms are analyzed. Finally, extensive simulation results demonstrate that our proposed TCQA algorithm significantly outperforms the SDR-based iterative D.C. algorithm.},
  archive      = {J_COMCOM},
  author       = {Jiasi Zhou and Yanjing Sun and Song Li and Bin Wang and Zhijian Tian},
  doi          = {10.1016/j.comcom.2020.02.041},
  journal      = {Computer Communications},
  pages        = {246-253},
  shortjournal = {Comput. Commun.},
  title        = {Max–min fairness driven multicast sparse beamforming for cache-enabled cloud RAN},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Amateur drones detection: A machine learning approach
utilizing the acoustic signals in the presence of strong interference.
<em>COMCOM</em>, <em>154</em>, 236–245. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to small size, sensing capabilities and autonomous nature, the Unmanned Air Vehicles (UAVs) have enormous applications in various areas e.g., remote sensing, navigation, archaeology, journalism, environmental science, and agriculture. However, the un-monitored deployment of UAVs called the amateur drones (AmDr) can lead to serious security threats and risk to human life and infrastructure. Therefore, timely detection of the AmDr is essential for the protection and security of sensitive organizations, human life and other vital infrastructure. AmDrs can be detected using different techniques based on sound, video, thermal, and radio frequencies. However, the performance of these techniques is limited in sever atmospheric conditions. In this paper, we propose an efficient un-supervise machine learning approach of independent component analysis (ICA) to detect various acoustic signals i.e., sounds of bird, airplanes, thunderstorm, rain, wind and the UAVs in practical scenario. After unmixing the signals, the features like Mel Frequency Cepstral Coefficients (MFCC), the power spectral density (PSD) and the Root Mean Square Value (RMS) of the PSD are extracted by using ICA. The PSD and the RMS of PSD signals are extracted by first passing the signals from octave band filter banks. Based on the above features the signals are classified using Support Vector Machines (SVM)and K Nearest Neighbour (KNN)to detect the presence or absence of AmDr. Unique feature of the proposed technique is the detection of a single or multiple AmDrs at a time in the presence of multiple acoustic interfering signals. The proposed technique is verified through extensive simulations and it is observed that the RMS values of PSD with KNN performs better than the MFCC with KNN and SVM.},
  archive      = {J_COMCOM},
  author       = {Zahoor Uddin and Muhammad Altaf and Muhammad Bilal and Lewis Nkenyereye and Ali Kashif Bashir},
  doi          = {10.1016/j.comcom.2020.02.065},
  journal      = {Computer Communications},
  pages        = {236-245},
  shortjournal = {Comput. Commun.},
  title        = {Amateur drones detection: A machine learning approach utilizing the acoustic signals in the presence of strong interference},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain platform for industrial healthcare: Vision and
future opportunities. <em>COMCOM</em>, <em>154</em>, 223–235. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical data has become an essential element for industrial healthcare. The growth in medical data is accompanied by the need to process it in a secure manner. As the infrastructure of this industry consists of connected devices and software applications that communicate with other IT systems, the industrial healthcare market will be greatly impacted by the use of blockchain and the Internet of Things (IoT). These technologies will improve processing efficiency, the creation of business opportunities, requirement regulation, information security, and transparency. While sharing electronic health records can assist in improving diagnosis accuracy, privacy and security preservation are imperative. In the network of IoT devices, that exchange involves sensitive medical data; patient monitoring has to be totally secured against privacy risks and attacks. Delays in treatment progress and emergency treatments could also result in medical data security and confidentiality violations. Applying blockchain technology to the healthcare industry could improve information security management ; healthcare data could be analyzed and communicated while preserving the privacy and security of the data. Here we critically look at how these two key technologies (blockchain and IoT) – especially blockchain – will impact the healthcare industry .},
  archive      = {J_COMCOM},
  author       = {Ahmed Farouk and Amal Alahmadi and Shohini Ghose and Atefeh Mashatan},
  doi          = {10.1016/j.comcom.2020.02.058},
  journal      = {Computer Communications},
  pages        = {223-235},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain platform for industrial healthcare: Vision and future opportunities},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Localization algorithm of wireless sensor network based on
matrix reconstruction. <em>COMCOM</em>, <em>154</em>, 216–222. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In view of the situation that the sensor network is applied to the complex environment, the connectivity is low, the ranging information is limited, and the ranging data has noise, this paper propose the positioning algorithm based on the addition of the generalized Lagrange matrix. Based on the low-rank characteristics of the distance matrix between the nodes of the sensor network, the distance recovery problem under partial sampling information is modeled as the matrix completion problem under Gaussian noise . The unmeasured distance information can be inferred through matrix filling and the noise and anomaly caused by the external environment can be filtered at the same time, which reduces the influence of environmental noise on the positioning and improves the positioning stability and accuracy.},
  archive      = {J_COMCOM},
  author       = {Ping Wang and Gang Tu},
  doi          = {10.1016/j.comcom.2020.01.051},
  journal      = {Computer Communications},
  pages        = {216-222},
  shortjournal = {Comput. Commun.},
  title        = {Localization algorithm of wireless sensor network based on matrix reconstruction},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SEAL: Self-adaptive AUV-based localization for sparsely
deployed underwater sensor networks. <em>COMCOM</em>, <em>154</em>,
204–215. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Se lf-adaptive A UV-based L ocalization (SEAL) scheme, which is specifically designed to provide network-wide localization service to sensor nodes in sparsely deployed Underwater Sensor Networks (UWSN) using a high-speed Autonomous Underwater Vehicle (AUV). Even though the sparse nature of node deployment in UWSN is cost-effective, it creates a new challenge for the existing UWSN localization schemes. Moreover, due to the effect of passive node mobility owing to oceanic waves and currents, the network topology experiences partitioning. In such a sparse deployment scenario , the existing static anchor-based schemes of node localization exhibit low localization coverage, high localization error , and high message overhead. On the contrary, mobile anchor-based schemes are able to maintain low message overhead. However, these schemes achieve low localization coverage only or result in higher average energy consumption. In SEAL, we excogitate a simple and self-adaptive scheme, which empowers the AUV to select deployment-aware transmission range and maintain energy-efficiency. Simulations in NS-3 indicate that SEAL achieves significantly improved localization coverage while maintaining the energy-efficiency of the AUV when compared to the schemes from the existing literature that were considered as benchmarks in this study.},
  archive      = {J_COMCOM},
  author       = {Tamoghna Ojha and Sudip Misra and Mohammad S. Obaidat},
  doi          = {10.1016/j.comcom.2020.02.050},
  journal      = {Computer Communications},
  pages        = {204-215},
  shortjournal = {Comput. Commun.},
  title        = {SEAL: Self-adaptive AUV-based localization for sparsely deployed underwater sensor networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ADMM penalized decoding method based on improved penalty
function for LDPC codes in the IoTs. <em>COMCOM</em>, <em>154</em>,
197–203. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-density parity-check (LDPC) codes is widely used in communication technology which is the key technology of the internet of things (IoTs). By increasing the cost of the pseudocodewords, the alternating direction method of multipliers (ADMM) penalized decoding method improves the decoding performance for LDPC codes at low signal-to-noise ratios. In order to increase the ADMM penalized decoding speed, an improved penalty function, which combines the original l 1 l1 and l 2 l2 penalty functions to form a piecewise function for penalized decoding, is proposed in this letter. The simulation results show that compared with the original ADMM penalized decoding methods for LDPC codes, the improved method obtains better decoding performance and reduces the average decoding time.},
  archive      = {J_COMCOM},
  author       = {Biao Wang and Zhongfei Wang},
  doi          = {10.1016/j.comcom.2020.02.063},
  journal      = {Computer Communications},
  pages        = {197-203},
  shortjournal = {Comput. Commun.},
  title        = {ADMM penalized decoding method based on improved penalty function for LDPC codes in the IoTs},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Big data analytics and IoT in operation safety management in
under water management. <em>COMCOM</em>, <em>154</em>, 188–196. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart city is described as the place where citizens live well-organized urban lives, ensure their sustainability, and cause the least damage to the environment through information and communication technology (ICTs). Big data and the internet of things sensors and applications collect data that allows effective technology solutions. In water management, smart water meters reporting water quality and use, alerting leaks to the water company, or potential contamination. In this paper, the Supervisory controller and data acquirement (SCADA) Approach for sustainable water management in the smart city based on IoT and Big Data Analytics. Big data analysis is a new technical term for the collection from deployed IoT sensors of huge amounts of relevant data to track the physical state, use and quality of the device. The Internet of Things (IoT) software can be extended to the entire water supply system and to device product use to carry out this principle of big data analysis. The experimental results demonstrate that the implementation aims to proactively control the usage of water by both companies and customers and to achieve higher levels of sustainable water supply.},
  archive      = {J_COMCOM},
  author       = {Xiangtian Nie and Tianyu Fan and Bo Wang and Zhiyong Li and Achyut Shankar and Adhiyaman Manickam},
  doi          = {10.1016/j.comcom.2020.02.052},
  journal      = {Computer Communications},
  pages        = {188-196},
  shortjournal = {Comput. Commun.},
  title        = {Big data analytics and IoT in operation safety management in under water management},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Construction of approximate reasoning model for dynamic CPS
network and system parameter identification. <em>COMCOM</em>,
<em>154</em>, 180–187. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CPS (Cyber Physical System) is a large and complex real-time feedback system that integrates computing processes, physical processes, communication networks, sensor networks, and control systems. It has the powerful function of sensing and controlling the physical environment, which is a big wave following the Internet technology. Because the forms of communication, interaction, and collaboration between heterogeneous units within the CPS are intricate and complex, a comprehensive model needs to be established to describe and analyze the CPS. This paper analyzes the CPS architecture and proposes a new and more complete CPS architecture, decomposes according to this architecture, and classifies the physical entities in the CPS. At the same time, event-based modeling thinking is used to define, classify and formalize event messages. Considering the higher real-time requirements of CPS, an event weighting algorithm was designed according to the different priorities of real-time events. In order to reduce the congestion caused by the limited network bandwidth in the CPS system, improve the ability to identify abnormal data with great uncertainty, and fully guarantee the response rate of the CPS system to emergencies, this paper analyzes the complexity of the CPS system from the perspective of information theory . The average dynamic complexity of the CPS system is set as a threshold to determine the level of information entropy of the sensor data in a certain period of time. The CPS system selects high information entropy data to send first. The effectiveness is analyzed through experiments.},
  archive      = {J_COMCOM},
  author       = {Juxia Xiong and Jinzhao Wu},
  doi          = {10.1016/j.comcom.2020.02.073},
  journal      = {Computer Communications},
  pages        = {180-187},
  shortjournal = {Comput. Commun.},
  title        = {Construction of approximate reasoning model for dynamic CPS network and system parameter identification},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection algorithm of regional peak motion based on
acceleration sensor. <em>COMCOM</em>, <em>154</em>, 173–179. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an algorithm of regional peak motion detection based on acceleration sensor is designed. Firstly, the acceleration model is processed by triaxial integration method, and then the signal is filtered by Gaussian filter . Finally, the step result is obtained by combining regional peak detection, threshold limit and other methods. Through the analysis of the data collected by the acceleration sensor, we can extract the parameters representing the motion attitude of the object from the single-chip microcomputer system, and dynamically modify the parameter value set by the system according to the current system motion attitude, and compare the value with the current motion attitude parameter, so as to judge whether the current count is effective. At the same time, this device can be well applied in the industrial system to achieve convenient and effective counting function. The results show that the step counting algorithm in this paper has high accuracy.},
  archive      = {J_COMCOM},
  author       = {Hui Sun and Qiong Wu},
  doi          = {10.1016/j.comcom.2020.02.061},
  journal      = {Computer Communications},
  pages        = {173-179},
  shortjournal = {Comput. Commun.},
  title        = {Detection algorithm of regional peak motion based on acceleration sensor},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the impact of QoS management in an information-centric
internet of things. <em>COMCOM</em>, <em>154</em>, 160–172. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) comprises a relevant class of applications that require Quality of Service (QoS) assurances. Information Centric Networking (ICN) has shown promising characteristics in constrained wireless networks, but differentiated QoS has not yet fully emerged. In this paper, we design and analyze a QoS scheme that manages the NDN resources forwarding and queuing priorities , as well as the utilization of caches and of forwarding state space . In constrained wireless networks, these resources are scarce with a potentially high impact due to lossy radio transmission. We explore the two basic service qualities (i) prompt and (ii) reliable traffic forwarding. We treat QoS resources not only in isolation, but correlate their use on local nodes and between network members. Network-wide coordination is based on simple QoS code points that can be distributed via a routing protocol. Fairness measures that prevent resource starvation are part of this management scheme. Our findings indicate that our coordinated QoS management in ICN does not only effectively prioritize the privileged data chunks, but also improves regular data communication. We can show that appropriate QoS coordination can enhance the overall network performance by more than the sum of its parts and that it exceeds the impact QoS can have in the IP world.},
  archive      = {J_COMCOM},
  author       = {Cenk Gündoğan and Jakob Pfender and Peter Kietzmann and Thomas C. Schmidt and Matthias Wählisch},
  doi          = {10.1016/j.comcom.2020.02.046},
  journal      = {Computer Communications},
  pages        = {160-172},
  shortjournal = {Comput. Commun.},
  title        = {On the impact of QoS management in an information-centric internet of things},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SPARK: Secure pseudorandom key-based encryption for
deduplicated storage. <em>COMCOM</em>, <em>154</em>, 148–159. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deduplication is a widely used technology to reduce the storage and communication cost for cloud storage services . For any cloud infrastructure, data confidentiality is one of the primary concerns. Data confidentiality can be achieved via user-side encryption. However, conventional encryption mechanism is at odds with deduplication. Developing a user-side encryption mechanism with deduplication is a vital research topic. Existing state-of-the-art solutions in security of deduplication are vulnerable to dictionary attacks and tag inconsistency anomaly. In this paper, we present SPARK, a novel approach for secure pseudorandom key-based encryption for deduplicated storage. SPARK achieves semantic security along with deduplication. Security analysis proves that SPARK is secure against dictionary attacks and tag inconsistency anomaly. As a proof of concept , we implement SPARK in realistic environment and demonstrate its efficiency and effectiveness.},
  archive      = {J_COMCOM},
  author       = {Jay Dave and Parvez Faruki and Vijay Laxmi and Akka Zemmari and Manoj Gaur and Mauro Conti},
  doi          = {10.1016/j.comcom.2020.02.037},
  journal      = {Computer Communications},
  pages        = {148-159},
  shortjournal = {Comput. Commun.},
  title        = {SPARK: Secure pseudorandom key-based encryption for deduplicated storage},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Signal extraction and monitoring of motion loads based on
wearable online device. <em>COMCOM</em>, <em>154</em>, 138–147. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring of human exercise load is a hot area of wearable technology . The mainstream human motion calculation method predicts human motion through offline machine learning techniques . Personalized monitoring poses new challenges to the original learning model. Aiming at the detection of R peak value of motion load signal and the location of QRS complex, an improved R-peak detection algorithm based on adaptive threshold is proposed. The feature extraction method of motion load signal is introduced from multiple dimensions. The characteristics of time domain features and frequency domain features are analyzed. The time domain features and the eigenvalues of frequency domain features are defined and extracted. Experiments show that the proposed algorithm has higher detection accuracy. A multi-threshold-peak step algorithm is proposed and a motion state machine model is established. According to the periodic changes of the trunk movement and the arm swing acceleration in motion, the feature values are extracted, the step detection and the gait discrimination are performed, and the influence of external acceleration interference is excluded. The state machine adopts a nested structure, which is divided into two layers, a parent state and a child state, and calibrates the state transition condition. A verification method for the validity of feature parameters is proposed. The selected feature parameters are taken as an example to analyze and simulate the method. Simulation results show that the characteristic parameters in this paper are effective in the monitoring of the reasonableness of exercise load.},
  archive      = {J_COMCOM},
  author       = {Xidan Gong and Huichao He},
  doi          = {10.1016/j.comcom.2020.02.072},
  journal      = {Computer Communications},
  pages        = {138-147},
  shortjournal = {Comput. Commun.},
  title        = {Signal extraction and monitoring of motion loads based on wearable online device},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social media sentiment analysis through parallel dilated
convolutional neural network for smart city applications.
<em>COMCOM</em>, <em>154</em>, 129–137. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning is considered to leverage smart cities through social media sentiment analysis . The digital content in social media can be used for many smart city applications (SCAs) 1 . Classical convolutional neural networks (CNNs) are challenging to parallelize and insufficient to capture long term contextual semantic features for sentiment analysis . In this perspective, this paper initially proposes a domain-specific distributed word representation (DS-DWR) 2 with a considerably small corpus size induced from textual resources in social media. In DS-DWR, different Distributed Word Representations are concatenated to builds rich representations over the input sequence, which is worthwhile for infrequent and unseen terms. Second, a dilated convolutional neural network (D-CNN) 3 , which is composed of three parallel dilated convolutional neural network (PD-CNN) 4 layers and a global average pooling (GAP) 5 layer. Our considered parallel dilated convolution reduces dimension and incorporates an extension in the size of receptive fields without the loss of local information. Further, the long-term contextual semantic information is achieved by the use of different dilation rates. Experiments demonstrate that our architecture accomplishes comparable results with multiple hyperparameters tuning for better parallelism which leads to the minimized computational cost.},
  archive      = {J_COMCOM},
  author       = {Muhammad Alam and Fazeel Abid and Cong Guangpei and L.V. Yunrong},
  doi          = {10.1016/j.comcom.2020.02.044},
  journal      = {Computer Communications},
  pages        = {129-137},
  shortjournal = {Comput. Commun.},
  title        = {Social media sentiment analysis through parallel dilated convolutional neural network for smart city applications},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of secure wireless communications for IoT
networks in the presence of eavesdroppers. <em>COMCOM</em>,
<em>154</em>, 119–128. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem motivates this paper is that securing the critical data of 5G based wireless IoT network is of significant importance. Wireless 5G IoT systems consist of a large number of devices (low-cost legitimate users), which are of low complexity and under strict energy constraints. Physical layer security (PLS) schemes, along with energy harvesting , have emerged as a potential candidate that provides an effective solution to address this issue. During the data collection process of IoT, PHY security techniques can exploit the characteristics of the wireless channel to ensure secure communication. This paper focuses on optimizing the secrecy rate for simultaneous wireless information and power transfer (SWIPT) IoT system, considering that the malicious eavesdroppers can intercept the data. In particular, the main aim is to optimize the secrecy rate of the system under signal to interference noise ratio (SINR), energy harvesting (EH), and total transmits power constraints. We model our design as an optimization problem that advocates the use of additional noise to ensure secure communication and guarantees efficient wireless energy transfer. The primary problem is non-convex due to complex objective functions in terms of transmit beamforming matrix and power splitting ratios . We have considered both the perfect channel state information (CSI) and the imperfect CSI scenarios. To circumvent the non-convexity of the primary problem in perfect CSI case, we proposed a solution based on the concave-convex procedure (CCCP) iterative algorithm , which results in a maximum local solution for the secrecy rate. In the imperfect CSI scenario, we facilitate the use of S-procedure and present a solution based on the iterative successive convex approximation (SCA) approach. Simulation results present the validations of the proposed algorithms. The results provide an insightful view that the proposed iterative method based on the CCCP algorithm achieves higher secrecy rates and lower computational complexity in comparison to the other algorithms.},
  archive      = {J_COMCOM},
  author       = {Sami Ahmed Haider and Muhammad Naeem Adil and MinJian Zhao},
  doi          = {10.1016/j.comcom.2020.02.027},
  journal      = {Computer Communications},
  pages        = {119-128},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of secure wireless communications for IoT networks in the presence of eavesdroppers},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum to “software defined network based
self-diagnosing faulty node detection scheme for surveillance
applications” [comput. Commun. 152 (2020) 333–337]. <em>COMCOM</em>,
<em>154</em>, 118. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {R. Palanikumar and K. Ramasamy},
  doi          = {10.1016/j.comcom.2020.02.056},
  journal      = {Computer Communications},
  pages        = {118},
  shortjournal = {Comput. Commun.},
  title        = {Corrigendum to “Software defined network based self-diagnosing faulty node detection scheme for surveillance applications” [Comput. commun. 152 (2020) 333–337]},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The views, measurements and challenges of elasticity in the
cloud: A review. <em>COMCOM</em>, <em>154</em>, 111–117. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Elasticity is one of the most important characteristics of cloud computing paradigm which enables deployed application to dynamically adapt to a changing demand by acquiring and releasing shared computational resources at runtime. Thus, elasticity is a key enabler for economies of scale in the cloud that enhances utility of cloud services. In practice, elasticity requires an autonomous management to reduce the gaps between the demand and supply of the computing resources at runtime. In this article, we Provide a review of the approaches and techniques from different perspectives. We examine elasticity management aspects from macro and micro economics perspectives to support value-driven elasticity decisions. We analyze the different views for measuring the elasticity of cloud-based systems. Furthermore, we discuss some of the open challenges in this domain.},
  archive      = {J_COMCOM},
  author       = {Ahmed Barnawi and Sherif Sakr and Wenjing Xiao and Abdullah Al-Barakati},
  doi          = {10.1016/j.comcom.2020.02.010},
  journal      = {Computer Communications},
  pages        = {111-117},
  shortjournal = {Comput. Commun.},
  title        = {The views, measurements and challenges of elasticity in the cloud: A review},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous internet of things organization predictive
analysis platform for apple leaf diseases recognition. <em>COMCOM</em>,
<em>154</em>, 99–110. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several abnormal functioning identifiers in the plants and animals to demolish the agricultural production in the field of the agricultural department. Particularly, in the effect of bacteria, fungi, micro-organisms, and viruses are heavily affect the fruits and their leaf. To achieve fantabulous functioning in leaf disease identification is a vital role in the efficient plant’s disease management and its demonstration to the continuous monitoring of bacteria, fungi and micro-organisms viruses persists a vital work that is undertaken or attempted by the agricultural department. To point out the leaf disease in an efficient manner, this article proposed an Advanced Segmented Dimension Extraction (ASDE) with Heterogeneous Internet of things procedural (HIoT) aspects. IoT procedural aspects identified as a repetitive and persistent space in the leaf image. This is also used to find the impact gesture of a leaf image, that insignificant to the identification time to a feasible extent. This paper suggests a Signs based plant disease identification for real-time resembling of leaf diseases namely bacteria, fungi, micro-organisms, and viruses. Diagnosis and Isolation techniques are maintained by Signs based plant disease identification, namely heterogeneous IoT detection. The relying on experiment show that the aimed framework distinguishes a detection of doing plant disease identification successfully accomplishing of 97.35\% with a high-detection quotient. In addition to this proposed paper shows the relevance of algorithms for automatic recognition of fine-tuned disease nodes in the isolated leaf image. On the automatic recognition carried out by parsing , localization , normalization and segmentation procedures.},
  archive      = {J_COMCOM},
  author       = {Sanjeevi Pandiyan and Ashwin M. and Manikandan R. and Karthick Raghunath K.M. and Anantha Raman G.R.},
  doi          = {10.1016/j.comcom.2020.02.054},
  journal      = {Computer Communications},
  pages        = {99-110},
  shortjournal = {Comput. Commun.},
  title        = {Heterogeneous internet of things organization predictive analysis platform for apple leaf diseases recognition},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A remote laser focusing system with spatial light modulator.
<em>COMCOM</em>, <em>154</em>, 92–98. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs a remote laser focusing system (RLFS) based on spatial light modulator (SLM). In this system, the SLM serves as an active optical element that modulates the wavefront of the laser beam, causing variation in beam transmission. Theoretical analysis shows that a reflective SLM can compensate the residual aberrations at different operating distances, enabling the accurate focusing of targets without sacrificing the energy convergence. Based on optical design software , the geometrical parameters were optimized for the presented system through simulation. Finally, experimental demonstration and error analysis were carried out. The results show that the proposed RLFS-SLM is more stable and capable for controlling energy convergence than the traditional mechanical RLFS. Our system provides a desirable tool for high-energy laser applications.},
  archive      = {J_COMCOM},
  author       = {Lin Liu and Lin Li and Zhu Zhao and Yue Wang},
  doi          = {10.1016/j.comcom.2020.01.075},
  journal      = {Computer Communications},
  pages        = {92-98},
  shortjournal = {Comput. Commun.},
  title        = {A remote laser focusing system with spatial light modulator},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Poly-stable matching based scalable controller placement
with balancing constraints in SDN. <em>COMCOM</em>, <em>154</em>, 82–91.
(<a href="https://doi.org/10.1016/j.comcom.2020.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking achieves programmability of the control plane by separating it from the data plane. In this paper, we propose a strategy for controller placement to minimize the maximum load imbalance between controllers while enforcing the placement and balancing constraints. We also propose a scalable algorithm to compute near optimal solutions of the problem on large scale networks. The algorithm uses poly-stable matching to distribute a fraction of switches equally among controllers so as to reduce the load imbalance. The remaining switches are assigned to their nearest controllers while considering latency of switches and load of controllers. Further, the algorithm relocates some of the switches from the controller to which they are currently assigned so as to reduce the latency between switches and controllers. The proposed algorithm is evaluated on widely used Chinanet and Interoute networks extracted from internet topology zoo. The results show that the proposed algorithm outperforms the existing controller placement solutions for software defined wide area networks in terms of load imbalance and inter controller latency without affecting the average and standard deviation in switch to controller latency.},
  archive      = {J_COMCOM},
  author       = {Balaprakasa Rao Killi and Seela Veerabhadreswara Rao},
  doi          = {10.1016/j.comcom.2020.02.053},
  journal      = {Computer Communications},
  pages        = {82-91},
  shortjournal = {Comput. Commun.},
  title        = {Poly-stable matching based scalable controller placement with balancing constraints in SDN},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decreasing security threshold against double spend attack in
networks with slow synchronization. <em>COMCOM</em>, <em>154</em>,
75–81. (<a href="https://doi.org/10.1016/j.comcom.2020.01.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We research the probability change of successful double spend attack on Proof-of-Work consensus protocol depending on network parameters in the model with continuous time. We analyze influence of block generation rate in networks with delayed message delivery on probability of double spend attack success, and provide strict analytical expressions for network security threshold and for the upper bound of block generation rate.},
  archive      = {J_COMCOM},
  author       = {Lyudmila Kovalchuk and Dmytro Kaidalov and Andrii Nastenko and Mariia Rodinko and Oleksiy Shevtsov and Roman Oliynykov},
  doi          = {10.1016/j.comcom.2020.01.079},
  journal      = {Computer Communications},
  pages        = {75-81},
  shortjournal = {Comput. Commun.},
  title        = {Decreasing security threshold against double spend attack in networks with slow synchronization},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart city-based e-commerce security technology with
improvement of SET network protocol. <em>COMCOM</em>, <em>154</em>,
66–74. (<a href="https://doi.org/10.1016/j.comcom.2020.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we proposed an improvement of SET protocol for E-commerce transaction. We study the security technology and protocol flow of set protocol, and point out the shortcomings of SET protocol. Due to the lack of security and low scalability of the current protocol, this paper proposes a server e-wallet strategy, which divides the original client into e-wallet client and e-wallet server, and enhances the convenience and security of the transaction by transferring the client to the issuer or the third-party financial institution, while the scalability is stronger. In order to ensure the atomicity of goods and confirm the atomicity of delivery, this paper proposes a secure e-commerce payment protocol based on the fourth party, which includes master protocol, customer return protocol, customer exchange protocol and customer merchant transaction dispute resolution protocol. According to the efficiency of SET protocol, a security hierarchical control model is proposed, which can select different security levels to operate according to the actual needs of customers, and the principle and implementation of the model are analyzed.},
  archive      = {J_COMCOM},
  author       = {Bing Xu and Darong Huang and Bo Mi},
  doi          = {10.1016/j.comcom.2020.02.024},
  journal      = {Computer Communications},
  pages        = {66-74},
  shortjournal = {Comput. Commun.},
  title        = {Smart city-based e-commerce security technology with improvement of SET network protocol},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotion recognition from spatiotemporal EEG representations
with hybrid convolutional recurrent neural networks via wearable
multi-channel headset. <em>COMCOM</em>, <em>154</em>, 58–65. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition from electroencephalography (EEG) has been an important research direction in affective brain–computer interactions (ABCI). An integration of EEG-based emotion recognition algorithms in ABCI can make the users experience more complete and engaging. In this paper, we propose a new data representation of electroencephalogram (EEG), which transforms 1D chain-like EEG vector sequences into 2D mesh-like matrix sequences. The mesh structure of the matrix at each time point corresponds to the electrodes’ location of EEG headset, which could better represent the spatial correlation of EEG signals among multiple physically adjacent electrodes. Then, the sliding window is used to divide the 2D matrix sequences into segments containing equal time points, and each segment is seen as an EEG sample integrating the temporal and spatial correlation of raw EEG recordings. We also propose both cascaded and parallel hybrid convolution recurrent neural networks to accurately predict the emotional category of each EEG sample. Extensive binary emotion classification experiments in valence and arousal are carried out on a large scale DEAP dataset (32 subjects, 9,830,400 EEG recordings). The experimental results demonstrate that the classification accuracies of both proposed hybrid networks on our spatial–temporal EEG representation achieve over 93\%, which outperform the most recent baseline methods and other deep learning models in within-subject validation scenario. Our proposed methods and hybrid models effectively improve the accuracy and robustness of EEG emotion classification, which can be applied to develop affective BCI applications using consumer multi-electrode EEG headset.},
  archive      = {J_COMCOM},
  author       = {Jingxia Chen and Dongmei Jiang and Yanning Zhang and Pengwei Zhang},
  doi          = {10.1016/j.comcom.2020.02.051},
  journal      = {Computer Communications},
  pages        = {58-65},
  shortjournal = {Comput. Commun.},
  title        = {Emotion recognition from spatiotemporal EEG representations with hybrid convolutional recurrent neural networks via wearable multi-channel headset},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MPDMAC-SIC: Priority-based distributed low delay MAC with
successive interference cancellation for multi-hop industrial wireless
networks. <em>COMCOM</em>, <em>154</em>, 48–57. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communications in industrial applications such as wireless factory automation demand different timing requirements. Providing timely medium access of the critical traffic and its prioritization over regular traffic at the same time is a significant challenge in industrial wireless networks. Successive Interference Cancellation (SIC) technique is an effective way to decrease access delay by allowing multiple packets reception concurrently. A series of novel Medium Access Control (MAC) protocols are proposed to differentiate access delay for various traffic types or exploit SIC for unique traffic type. Our protocol in this paper (MPDMAC-SIC) is the first priority based distributed MAC protocol that employs SIC to provide low access delay and accommodate different types of traffic for multi-hop industrial wireless networks. Two major contributions of our work are: first, we propose a low delay protocol for priority based multi-hop industrial wireless networks by enabling multiple packet reception on power domain with SIC. In MPDMAC-SIC, a power contention procedure other than traditional RTS/CTS contention in CSMA/CA DCF is introduced to allocate proper transmitting power for transmitters. Second, MPDMAC-SIC is modeled by discrete time Markov chain to minimize access delay by optimizing window size in power contention. According to the simulation results, MPDMAC-SIC performs better on access delay and packet arriving rate, compared to the existing good performing priority based CSMA/CA in both single-hop and multi-hop networks.},
  archive      = {J_COMCOM},
  author       = {Yida Xu and Qi Wang and Yongjun Xu and Jianmin Liu and Chentao He},
  doi          = {10.1016/j.comcom.2020.02.036},
  journal      = {Computer Communications},
  pages        = {48-57},
  shortjournal = {Comput. Commun.},
  title        = {MPDMAC-SIC: Priority-based distributed low delay MAC with successive interference cancellation for multi-hop industrial wireless networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Study on real-time wearable sport health device based on
body sensor networks. <em>COMCOM</em>, <em>154</em>, 40–47. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a branch of the wireless sensor network and an important part of the Internet of Things (IoT), Body Sensor Network (BSN) integrates biomedical engineering technology and wireless sensor network . It has high precision, small monitoring range, miniaturization and low power. The congruent feature can monitor the physiological information and motion information of the human body in real time, and provide the tester with many important quantitative information, to realize early monitoring, early prevention and early intervention of some common chronic diseases. This technology can be widely applied in biomedical, sports training, daily activity monitoring and other fields. In addition, the human sensor network is also an implementation of home health care , providing a new way of thinking for telemedicine and home health care . In order to realize the human motion monitoring system based on human body sensor network. This research aims to design a wearable sport health monitoring system with low cost, low power consumption , high modularity, high reliability, and high precision. The human body motion monitoring system of the axis wireless sensor platform enables real-time monitoring of sports health.},
  archive      = {J_COMCOM},
  author       = {Jiayi Zhao and Guangxue Li},
  doi          = {10.1016/j.comcom.2020.02.045},
  journal      = {Computer Communications},
  pages        = {40-47},
  shortjournal = {Comput. Commun.},
  title        = {Study on real-time wearable sport health device based on body sensor networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel three-phase target channel allocation scheme for
multi-user cognitive radio networks. <em>COMCOM</em>, <em>154</em>,
18–39. (<a href="https://doi.org/10.1016/j.comcom.2020.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generation and allocation of Target Channel Sequence (TCS) in relation to spectrum handoff introduces several challenges in a multi-user Cognitive Radio Network . The primary challenge is to ensure fair and unique TCS allocation to multiple Secondary Users (SUs) in order to prevent channel access conflict during concurrent handoff operations. Another challenge is to perform dynamic TCS generation to guard against channel obsolescence effects under time-varying user activities. Inclusion of real-time SUs further mandates the use of time-bound TCS generation in order to prevent call drops due to time-outs during handoff. To address these issues of fairness, uniqueness, dynamic and time-bounded TCS generation, this paper proposes a novel machine-learning enabled three-phase TCS generation and allocation scheme for multiple real-time SUs involved in Voice over IP (VoIP) communication. While proactive and periodic phases compute unique TCS in O (n log n) time, the reactive phase performs on-demand TCS generation. Generation of TCS is formulated as a fractional knapsack problem and greedy technique is applied therein to optimally select channels based on their existing conditions. A novel HMM-BiLSTM (Hidden Markov Model-Bidirectional Long Short Term Memory) framework is further devised to safeguard VoIP interests through periodic channel eligibility prediction. Additionally, an analytical framework is developed which records negligible probability of channel access conflict among multiple SUs. Simulation results confirm fair and dynamic channel allocation with reduced handoff delays and call-drops and intelligent learning based decision-making operations with high accuracy in comparison to existing approaches. Finally, test-bed implementation validates practical applicability of the proposed methodology.},
  archive      = {J_COMCOM},
  author       = {Tamal Chakraborty and Iti Saha Misra},
  doi          = {10.1016/j.comcom.2020.02.026},
  journal      = {Computer Communications},
  pages        = {18-39},
  shortjournal = {Comput. Commun.},
  title        = {A novel three-phase target channel allocation scheme for multi-user cognitive radio networks},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heuristic and random search algorithm in optimization of
route planning for robot’s geomagnetic navigation. <em>COMCOM</em>,
<em>154</em>, 12–17. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the efficiency and accuracy, a new combination algorithm for route planning is proposed, by considering underwater geomagnetic matching navigation area and distribution of environmental constraints. Firstly, with geomagnetic navigation matching regions, Dijkstra algorithm can obtain the primary route points. Secondly, the environmental constraints models are built and normalized, and the route planning environment constrained cost model is established. Thirdly, with the relationships between time, function relation, constraint condition and variable in the environment constrained cost model, the particle swarm optimization algorithm is introduced. With the primary route pints, the route planning is transformed into route optimization . Finally, the primary route points are used as the initial input of the particle swarm optimization algorithm, then the methods of selecting the inertia weight of the particle swarm and the particle coding are improved. The optimal route planning of Dijkstra algorithm and particle swarm optimization is realized. Simulation results demonstrate that the particle size of the search space can get a minimized evaluation, more narrowed search range and higher efficient search. The combination algorithm guarantees the global optimal while ensures the local optimal, then, the non-matching navigation areas can be effectively avoided, and efficient route planning functions can be achieved.},
  archive      = {J_COMCOM},
  author       = {Yan Xu and Guofei Guan and Qingwu Song and Chao Jiang and Lihui Wang},
  doi          = {10.1016/j.comcom.2020.02.043},
  journal      = {Computer Communications},
  pages        = {12-17},
  shortjournal = {Comput. Commun.},
  title        = {Heuristic and random search algorithm in optimization of route planning for robot’s geomagnetic navigation},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IFIP networking 2018 special issue. <em>COMCOM</em>,
<em>154</em>, 11. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Claudio Casetti and Jordi Domingo-Pascual and Fernando Kuipers and James Sterbenz},
  doi          = {10.1016/j.comcom.2020.02.022},
  journal      = {Computer Communications},
  pages        = {11},
  shortjournal = {Comput. Commun.},
  title        = {IFIP networking 2018 special issue},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial bee colony optimization based energy-efficient
wireless network interface selection for industrial mobile devices.
<em>COMCOM</em>, <em>154</em>, 1–10. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Management of energy is a crucial challenge for mobile devices , having the network activity frequently taking up a considerable part of the energy in the overall system. The important goal of this work is to offer energy efficiency for mobile handhelds. The industrial mobile devices in the recent times are fitted with several wireless network interfaces, these devices function with less battery power. In mobile handhelds, each user is able to run multiple applications with the purpose of have particular Quality of Service (QoS) requirements. Hence, it would be beneficial for a multi-interface terminal to simultaneously use two or more interfaces to gain in performance. So satisfying the QoS becomes very difficult task. An energy-effective Adaptive Wireless Network Interface Selection (AWNIS) with Artificial Bee Colony (ABC) is proposed in this paper. AWNIS-ABC algorithm chooses the best of the wireless network interface in regard to the energy consumed by taking the QoS of the link into consideration as well as following a hi-speed network interface-selection interval based on the scenario in the network. Then Hidden Semi Markov Model (HSMM) is introduced for searching the detouring paths if the energy state of a given relay node is very less to utilize the required interface, which ensures timely delivery. Also, it provides the diversification of the route paths in the network with the purpose of extending the lifetime of the network. An alternate path is proposed for reliable data delivery beforehand the route path encounters a breakage owing to energy exhaustion is found. A number of wireless network interfaces in mobile devices are utilized in improving the energy efficiency, satisfaction of QoS occurring during data transfer. The simulation of the network is implemented via the Network Simulator 2(NS2).},
  archive      = {J_COMCOM},
  author       = {S. ArunKumar and B. Vinoth Kumar and M. Pandi},
  doi          = {10.1016/j.comcom.2020.01.067},
  journal      = {Computer Communications},
  pages        = {1-10},
  shortjournal = {Comput. Commun.},
  title        = {Artificial bee colony optimization based energy-efficient wireless network interface selection for industrial mobile devices},
  volume       = {154},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDN-MCHO: Software define network based multi-criterion
hysteresis optimization based for reliable device routing in internet of
things for the smart surveillance application. <em>COMCOM</em>,
<em>153</em>, 632–640. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is a sophisticated communication paradigm that is capable of integrating diverse elements from humans to interactive machines. This kind of integration provides seamless and ubiquitous communication support for mobile users. The infrastructure of IoT environment endorses multiple technologies and networks where, selecting a precise neighbor/ device becomes mandatory for the extreme surveillance application. It determines the reliability is service discovery and resource access. The process of request processing through reliable neighbor discovery is leveraged using multi-criterion hysteresis optimization (MCHO) based on SDN aided routing that is discussed in this article. The introduced routing optimization method is capable of identifying reliable IoT neighbors for request handling and delivery. This routing process depends on the activation function that classifies neighbors on the basis of three metrics namely Received Signal Strength (RSS), Rank, and Expected Transmission Count (ETX)for differentiating the neighbors on the basis of their consistency. Through differentiated hysteresis analysis, the neighbors are segregated and hence optimal devices are integrated to form a request friendly route to the access layer. The introduced routing optimization method is evaluated through appropriate experiments and the results are verified using the metrics: throughput, request delivery ratio, delay, response time, request loss and average ETX.},
  archive      = {J_COMCOM},
  author       = {Tamizhselvan C. and Vijayalakshmi V.},
  doi          = {10.1016/j.comcom.2020.02.029},
  journal      = {Computer Communications},
  pages        = {632-640},
  shortjournal = {Comput. Commun.},
  title        = {SDN-MCHO: Software define network based multi-criterion hysteresis optimization based for reliable device routing in internet of things for the smart surveillance application},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SOS-WS host shield: A sketch-based service oriented shield
against web application business layer IDS attacks. <em>COMCOM</em>,
<em>153</em>, 626–631. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Intrusion Detection Systems (IDS) is becoming important and pretty time/space consuming due to the rising level of explosive data flood. All through the past decades, there have been plenty of studies propose software mechanism to take advantage of the temporal locality in the IDS systems. Yet, it require substantial memory block to accumulate the redundancy table. As a result the performance as well as the memory consumption is still value pursuing. To tackle the above weak point, in this paper, we present SOS (Service Oriented Shield) Host Shield, which explore the guard for business layer against IDS Attack. The SOS Web Shield supports Host based HTTPS protection system. The SOS Host Shield includes 3 stages, one is Generalized Patch-based IDS Verifier, and next one is Service Oriented Hash-based support and finally SOS of IntruXML. The SOS Host Shield create virtualized prevent system for host based IDS. This improves the effectiveness of SOS Host shield by avoid the attack in HTTPs of malicious user at hosts. We developed a prototype of SOS Host shield and watchfully evaluate its efficiency using real attack data collected from a large-scale web cluster.},
  archive      = {J_COMCOM},
  author       = {N. Balasubramanian and A. Askarunisa and A. Ruba},
  doi          = {10.1016/j.comcom.2020.01.065},
  journal      = {Computer Communications},
  pages        = {626-631},
  shortjournal = {Comput. Commun.},
  title        = {SOS-WS host shield: A sketch-based service oriented shield against web application business layer IDS attacks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconstruction of coverage hole model and cooperative repair
optimization algorithm in heterogeneous wireless sensor networks.
<em>COMCOM</em>, <em>153</em>, 614–625. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coverage hole repair not only determines whether the heterogeneous wireless sensor networks (HWSNs) can work normally and effectively, but also determines the network coverage, performance and time to live. The sensor nodes may be covered by random deployment or network failure during the network operation. Therefore, coverage hole repair is a very critical and challenging problem in HWSNs. In this paper, we reconstruct the hole model and proposes a multi-factor collaborative hole repair optimization algorithm (FCH-ROA) between HWSNs nodes. The algorithm considers the distance between the virtual repair node and the mobile node, the energy consumption during the mobile repair process and the confidence of the node to be repaired. A Pearson-like fuzzy matching relationship between the virtual repair node and the mobile node is established to cover the hole repair. Firstly, the hole model is reconstructed, and the Voronoi polygons are randomly divided into the static nodes of the HWSNs in the two-dimensional square monitoring area. Secondly, the key areas of the static nodes are connected in the counterclockwise direction to determine the hole areas. According to the different concave shapes, the convexity is degenerate into a convex hull, and the convex hull center is used as the base point. The Delaunary triangulation is combined with the bulge vertices to calculate the position of the virtual repair node. Finally, based on the relative distance of the nodes, residual energy , and the node of criticality , the multi-factor synergy matching decision table between the virtual repair node and the mobile node, according to the decision table, the mobile node performs the finite distance movement to realize the repair optimization of the coverage hole. Simulation experiments show that compared with the existing coverage hole algorithm, FCH-ROA algorithm improves network coverage and extends network life cycle.},
  archive      = {J_COMCOM},
  author       = {Pingzhang Gou and Gang Mao and Fen Zhang and Xiangdong Jia},
  doi          = {10.1016/j.comcom.2020.01.053},
  journal      = {Computer Communications},
  pages        = {614-625},
  shortjournal = {Comput. Commun.},
  title        = {Reconstruction of coverage hole model and cooperative repair optimization algorithm in heterogeneous wireless sensor networks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Disaster analysis on cultural sites using fuzzy based online
open provision geographic data frameworks. <em>COMCOM</em>,
<em>153</em>, 606–613. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper speaks about the utilization of online open provision geographic data system (OOGIS) for the security of the well known recorded cultural sites and social urban communities in China. As indicated by the qualities of public interest and geographic information system (GIS), Most of the Cultural sites information in china are not accurately traced out by the archaeologist during their research on sculptures in various provinces of China. This paper exhibits a Fuzzy based application structure of OOGIS at various degrees during the time of participating in the assurance of the well known authentic and social urban areas. Further this paper analysis The fuzzy based approach to detect the disaster in cultural cites. This computational technique uses Fuzzy lexical values which uses high security fuzzy membership functions in OOGIS which can furnish archaeologist with more capacities to get all the information about cultural sites, including the publics, specialists and chiefs and so on, Likewise the degree of its application depends on the degree of OOGIS innovation and light of various conditions has been experimentally verified at lab scale using fuzzy based OOGIS software system. Then the introduced system ensures 97.43\% of accuracy compared to existing methods.},
  archive      = {J_COMCOM},
  author       = {Liya Ma and Dongmei Wei and Pei Wang},
  doi          = {10.1016/j.comcom.2019.12.036},
  journal      = {Computer Communications},
  pages        = {606-613},
  shortjournal = {Comput. Commun.},
  title        = {Disaster analysis on cultural sites using fuzzy based online open provision geographic data frameworks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards an SDR implementation of LoRa: Reverse-engineering,
demodulation strategies and assessment over rayleigh channel.
<em>COMCOM</em>, <em>153</em>, 595–605. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LoRa is a popular low-rate, Low-Power Wide Area Network (LPWAN) technology providing long range wireless access over unlicensed sub-GHz frequency bands to the Internet of Things (IoT). It has been used in many applications ranging from smart building to smart agriculture. LoRa is a patented modulation. However preliminary reverse-engineering efforts documented parts of it. In this article, we detail the different stages of LoRa transceivers : channel (de)coding, (de)whitening, (de)interleaving and (de)modulation with reverse-engineering in mind. Closed-form expressions for each of these stages are given, and different demodulation and decoding strategies are presented. This allows for a complete modeling of LoRa, which enables Software Defined Radio (SDR) implementations, as well as performance assessment under various channel conditions. These simulations show that LoRa systems have good properties for time and/or frequency selective channels (especially for the latter), thanks to the robustness of its underlying Chirp-Spread Spectrum (CSS) modulation.},
  archive      = {J_COMCOM},
  author       = {Alexandre Marquet and Nicolas Montavont and Georgios Z. Papadopoulos},
  doi          = {10.1016/j.comcom.2020.02.034},
  journal      = {Computer Communications},
  pages        = {595-605},
  shortjournal = {Comput. Commun.},
  title        = {Towards an SDR implementation of LoRa: Reverse-engineering, demodulation strategies and assessment over rayleigh channel},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Modeling and reasoning of IoT architecture in semantic
ontology dimension. <em>COMCOM</em>, <em>153</em>, 580–594. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The architecture for IoT is the primary foundation for designing and implementing the System of Internet of things. This paper discusses the theory, method, tools and practice of modeling and reasoning the architecture of the Internet of Things system from the dimension of semantic ontology. This paper breaks the way of static ontology modeling, and proposes an implementation framework for real-time and dynamic ontology modeling of the IoT system from the running system. According to the actual needs of the health cabin IoT system and the combination of theory and practice, the system architecture model of the semantic ontology dimension of IoT is built. Then, based on the reasoning rules of the ontology model, the model is reasoned by Pellet reasoning engine which injects the atom of the custom reasoning built-ins into the source code . In this way we have realized the automatic classification and attribute improvement of resources and behaviors of the IoT system, the real-time working state detection and fault diagnosis of the IoT system, and the automatic control of the IoT system and resources.},
  archive      = {J_COMCOM},
  author       = {Guang Chen and Tonghai Jiang and Meng Wang and Xinyu Tang and Wenfei Ji},
  doi          = {10.1016/j.comcom.2020.02.006},
  journal      = {Computer Communications},
  pages        = {580-594},
  shortjournal = {Comput. Commun.},
  title        = {Modeling and reasoning of IoT architecture in semantic ontology dimension},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Construction of U2S communications system based on edge fog
computing. <em>COMCOM</em>, <em>153</em>, 569–579. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer technology and Internet of things technology , the concept of intelligent city is becoming more and more clear, and the construction of information-based city has gradually become the focus of all countries. However, in the concept of smart city, Internet of things technology is one of its key core technologies. At the same time, the construction of information system in intelligent city system is also the key problem to be solved and optimized. In this paper, the core technologies of the Internet of things and the Internet are taken as the basis of the intelligent city information system architecture , and an innovative intelligent city information system platform based on edge fog computing is proposed. On this platform, we will make full use of the lightweight fog computing virtual technology among terminal equipment, cloud server and edge fog computing network layer to provide the whole information system. The functions of storage and calculation can solve the problems of the traditional intelligent city information system, such as the pressure of network bandwidth , time extension and so on. Finally, based on the intelligent city information system proposed in this paper, the intelligent city information system of typical cities is constructed. The experimental results show that the algorithm proposed in this paper has obvious advantages in the running speed and the convergence of the corresponding algorithm.},
  archive      = {J_COMCOM},
  author       = {Yang Li},
  doi          = {10.1016/j.comcom.2020.02.038},
  journal      = {Computer Communications},
  pages        = {569-579},
  shortjournal = {Comput. Commun.},
  title        = {Construction of U2S communications system based on edge fog computing},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Centralized sub-nyquist wideband spectrum sensing for
cognitive radio networks over fading channels. <em>COMCOM</em>,
<em>153</em>, 561–568. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Cognitive Radio (CR) technology is expected to maximize the use of spectrum resources in next generation wireless systems . Hence, Spectrum Sensing (SS) is key to enable CR to gather knowledge from the spectral resources available in the studied bands. However, one of the main setbacks of SS is that it requires a large number of samples to be processed for multi-band signal sampling at rates close to the Nyquist rate. This increases overall detection time and energy consumption while it stimulates the need for high-processing capabilities in Cognitive Radio Devices (CRD). Taking advantage of spatial diversity to enhance the performance of Wide Band Spectrum Sensing (WBSS), this article proposes a new cooperative algorithm based on WBSS for CRD using Sub-Nyquist sampling. Furthermore, a uniform sampling matrix in the disperse domain of the multiband signal is presented. This cooperative wideband scenario leads to closed expressions for probabilities of detection , omitted detection and false alarm. The simulation results reveal that the algorithm enhances the performance of WBSS in terms of the detection probability , improving SNR by 5 dB. The proposed algorithm improves on computational complexity by a factor of at least log n logn in comparison to other WBSS cooperative algorithms based on Sub-Nyquist sampling.},
  archive      = {J_COMCOM},
  author       = {Evelio Astaiza Hoyos and Octavio J. Salcedo Parra and Wilmar Y. Campo Muñoz},
  doi          = {10.1016/j.comcom.2020.02.039},
  journal      = {Computer Communications},
  pages        = {561-568},
  shortjournal = {Comput. Commun.},
  title        = {Centralized sub-nyquist wideband spectrum sensing for cognitive radio networks over fading channels},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling imbalanced data with concept drift by applying
dynamic sampling and ensemble classification model. <em>COMCOM</em>,
<em>153</em>, 553–560. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the availability of a broad range of applications for Big Data streaming, both the class imbalance and concept drift have become crucial learning issues. The concept of drift handling solutions is sensitive to class imbalance. The sampling techniques are widely applied to process the continuously arriving data streams with a sufficient number of instances. The selected instances have to build a statistical inference to support imbalanced class distribution. The stream data classification model without concept drift adaptation is not preferable to the imbalanced class distribution. To solve the issues, this article presents the dynamic sampling and an ensemble classification technique , named as Handling Imbalanced Data with Concept Drift (HIDC). To provide high statistical precision over imbalanced class distribution with concept drift, the HIDC decides an optimal reservoir size using the metrics regarding statistical properties of stream data and control parameter. The former refers to the inequality level in the values of instances arrived from a source, and the latter one controls over the selection of instances from multiple sources. The HIDC estimates the optimal reservoir size using such statistical and control parameters. To select the appropriate instances with an allocated optimal reservoir size, the HIDC applies random sampling over imbalanced classes and chooses a set of instances from multiple sources. The random sampling cannot solve the issues of imbalanced class distribution among the existing classes. To address such problems, the HIDC applies resampling techniques with respect to the imbalance factor. To identify and address the new concepts, the proposed HIDC sampling model trains the candidate classifier and replaces the worst ensemble member with the candidate classifier. Finally, the experimental results show that the HIDC performs better sampling and mining over imbalanced class distribution with concept drifts.},
  archive      = {J_COMCOM},
  author       = {S. Ancy and D. Paulraj},
  doi          = {10.1016/j.comcom.2020.01.061},
  journal      = {Computer Communications},
  pages        = {553-560},
  shortjournal = {Comput. Commun.},
  title        = {Handling imbalanced data with concept drift by applying dynamic sampling and ensemble classification model},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A secure fuzzy extractor based biometric key authentication
scheme for body sensor network in internet of medical things.
<em>COMCOM</em>, <em>153</em>, 545–552. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Body sensor network (BSN) is largely utilized in IoMT to attain easier access of patient’s data remotely without much cost by connecting the various bio-sensors. However, there is a security threat in accessing the BSN because of hacking issues. Hence, In order to secure the most sensitive details of the patient, secured fuzzy extractor combined with fuzzy vault is developed in this approach with an objective of providing more security using bio-metric key authentication scheme. Initially, preprocessing is done to remove the noise in ECG signal using the adaptive filtering . Secured Fuzzy extractor is designed for extracting the features like QRS, PR and QT interval and the private key generation for authentication process is based on these features only. Because of unique features of each ECG, private key cannot be hacked easily. Along with private key values, a set of random chaff points are generated using polynomial construction principle and are stored with a checksum vector in a separate fuzzy vault set. In the authentication phase, the data in the fuzzy set will be checked with checksum values to detect missing data in the communication. The IP address of the device will be used as the public key for estimating the bit rate of sensors at decoding phase. The security of the system depends mainly on the hash function . In our proposed method, the hash variable value is independent of the hash functions to enhance the network security . This variation in hashing does not affect the latency or delay of our proposed technique. The proposed fuzzy extractor based biometric key authentication scheme achieved enhanced results such as 40\% reduced data loss, 20\% reduced energy consumption and reduced delay when compared to previous encoding techniques.},
  archive      = {J_COMCOM},
  author       = {Rakesh Kumar Mahendran ( Research Scholar ) and Parthasarathy Velusamy ( Professor )},
  doi          = {10.1016/j.comcom.2020.01.077},
  journal      = {Computer Communications},
  pages        = {545-552},
  shortjournal = {Comput. Commun.},
  title        = {A secure fuzzy extractor based biometric key authentication scheme for body sensor network in internet of medical things},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on location fusion of spatial geological disaster
based on fuzzy SVM. <em>COMCOM</em>, <em>153</em>, 538–544. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to effectively improve geological disaster response capacity, disaster tolerance capacity, reduce human and financial losses and other aspects of spatial data fusion plays a key role. Whether the location information can be effectively fused is able to monitor the occurrence of geological hazards and effectively identify the existing risks. In machine learning , the similarity and complementarity between support vector machine and fuzzy inference is the basis of their fusion. Support vector machine can achieve knowledge acquisition and learning, while fuzzy inference has the ability to infer knowledge rules. Aiming at the different attributes and dimensions of information spatial location data, a fuzzy fusion method based on support vector machine is proposed to describe Support vector machine related theories and models. Comparing the efficiency of support vector machine-fusion algorithm on GPLUS, OKLAHOMA and UNC with the other three algorithms, there is a great advantage in RMSE and time. The algorithm in this paper also has good performance in the three data sets on F1, which shows that the algorithm has a good effect.},
  archive      = {J_COMCOM},
  author       = {Guobin Chen and Shijin Li},
  doi          = {10.1016/j.comcom.2020.02.033},
  journal      = {Computer Communications},
  pages        = {538-544},
  shortjournal = {Comput. Commun.},
  title        = {Research on location fusion of spatial geological disaster based on fuzzy SVM},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Correcting design flaws: An improved and cloud assisted key
agreement scheme in cyber physical systems. <em>COMCOM</em>,
<em>153</em>, 527–537. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The on demand availability of resources in Cyber physical system (CPS) has emerged as a viable service providing platform to improve the resource usability and reducing the infrastructure costs. Nevertheless, the development recompenses can only be realized after avoiding security and privacy issues. A secure and reliable CPS can offer improved efficiency, usability and reliability along with autonomy. To secure such systems, in 2018 Challa et al. (2018) proposed a security system to extend an authenticated key agreement between a user and a cloud server via trusted authority; as an application, they also customized their system to work with autonomous smart meter and cloud server. Challa et al. then claimed the security of their proposed scheme through formal, informal and automated validations. However, this paper unveils the weaknesses of their scheme and shows that their scheme cannot facilitate in forming a session key between the user/smart meter and the cloud server. Precisely, in the presence of more than one registered users/smart meters, the latter in their scheme may never receive a response message because of a critical design error. Moreover, their scheme lacks the untraceable anonymity and the lack of request verification on cloud server side may also lead to replay and/or denial of services attack . The article then introduces an improved and secure authentication system free of correctness issues, to facilitate a key agreement between user and cloud server via trusted authority. As an application, the proposed system also works for smart meter and cloud server to reach a key agreement. Based on the hardness assumption of Elliptic Curve Decisional Diffi-Hellman Problem (ECDDHP), the formal Random oracle model proves the security of the proposed scheme. Moreover, the robustness of the scheme is explained through informal analysis. The proposed system while providing all known security features has slightly increased the computation and communication costs as compared with the scheme of Challa et al. The proposed scheme completes a cycle of authentication by exchanging 2080 bits in just 13.4066 ms.},
  archive      = {J_COMCOM},
  author       = {Shehzad Ashraf Chaudhry and Taeshik Shon and Fadi Al-Turjman and Mohammed H. Alsharif},
  doi          = {10.1016/j.comcom.2020.02.025},
  journal      = {Computer Communications},
  pages        = {527-537},
  shortjournal = {Comput. Commun.},
  title        = {Correcting design flaws: An improved and cloud assisted key agreement scheme in cyber physical systems},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security and privacy attacks during data communication in
software defined mobile clouds. <em>COMCOM</em>, <em>153</em>, 515–526.
(<a href="https://doi.org/10.1016/j.comcom.2020.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been an enormous growth in networking and data communication between the wireless devices. Cloud computation has taken a giant leap into the mobile domain to cater to the on-going communication demands. The latest programming techniques have also paved the way for incorporating Software Defined Networking techniques in Mobile Cloud environment. The growth of networking infrastructure with many such technological innovations, has led to the parallel increase in security and privacy of data at different levels of communication. The communication links and interfaces have become targeted platform for various security attacks causing denial of services . This survey comprehends an in-depth analysis of the possible data privacy attacks and threats in the proposed Software Defined Mobile Cloud. The possibilities of the attacks which are enlisted focus on various ways of spoofing and flooding of data packets, mis-interpretation and aggregation of the flow rules for communication, packet dropping and traffic flow enrouting at different cross-layered architectural levels built over the heterogeneous networks . An overview of the mechanisms to encounter the various vulnerabilities in the suggested framework is recommended. This article further identifies research directions and challenges to incorporate the possible techniques and preventive solutions, to overcome the malicious attacks in the software defined mobile cloud.},
  archive      = {J_COMCOM},
  author       = {Vaishnavi Moorthy and Revathi Venkataraman and T. Rama Rao},
  doi          = {10.1016/j.comcom.2020.02.030},
  journal      = {Computer Communications},
  pages        = {515-526},
  shortjournal = {Comput. Commun.},
  title        = {Security and privacy attacks during data communication in software defined mobile clouds},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Physical layer impairments aware routing and spectrum
allocation algorithm for transparent flexible-grid optical networks.
<em>COMCOM</em>, <em>153</em>, 507–514. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss physical layer impairments (PLIs) aware routing and spectrum allocation (RSA) algorithm for the transparent flexible-grid optical networks . The flexible-grid optical networks have the capability of delivering data with multi-rate, multi-reach, high spectrum efficiency, high flexibility, and low bit error rates (BER). However, in transparent flexible-grid optical networks, as the transmission distance increases, optical signals are subject to traverse over many bandwidth-variable wavelength cross connects (BV-WXCs) and multiple fiber spans . As a result, the PLIs get accumulated and are added to the optical signal. These accumulated impairments degrade the signal quality to an unacceptable level at the receiver. Hence, the quality of transmission (QoT) falls below the acceptable threshold value and making it hard for the receiver to detect the signal properly. This problem has not received enough attention in the literature yet. Therefore, our objective is to develop an impairments aware RSA algorithm, which establishes the QoT satisfied flexpath based on the available resources and the quality of the signal available at the receiver. We formulate the PLIs-aware RSA problem as an integer linear program (ILP) that provides an optimal solution. We propose a PLIs-aware heuristic algorithm for large-size networks where ILP is not efficient. Using extensive simulation results, we compute the total blocking probability and the spectrum efficiency. The results show that our algorithm outperforms in terms of blocking probability and spectrum utilization.},
  archive      = {J_COMCOM},
  author       = {R. Krishnamurthy and T. Srinivas},
  doi          = {10.1016/j.comcom.2020.02.040},
  journal      = {Computer Communications},
  pages        = {507-514},
  shortjournal = {Comput. Commun.},
  title        = {Physical layer impairments aware routing and spectrum allocation algorithm for transparent flexible-grid optical networks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UAV monitoring and forecasting model in intelligent traffic
oriented applications. <em>COMCOM</em>, <em>153</em>, 499–506. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent transportation system is a traffic management system developed with the progress of society and traffic. Its idea is to integrate the real-time operation of people, vehicles, roads and traffic involved in the traffic. The purpose of this paper is to build a safe, reliable and efficient vehicle monitoring and forecasting model for IOT. Based on the Beidou satellite positioning technology and Lora communication technology, aiming at the problem that the deep learning detection method cannot meet the real-time requirements in processing the monitoring video, this paper proposes a method of using multiple single target trackers instead of some yolov3 detection tasks, and puts forward the design idea and specific implementation scheme of the vehicle monitoring and prediction model. The vehicle monitoring and prediction model is used to detect four kinds of targets, namely, small cars, buses, trucks and pedestrians. The multi-target trajectory tracking is used to carry out the traffic statistics of multi vehicle types, the detection of two kinds of abnormal behaviors of traffic targets is low speed and parking, and the capture of pedestrians. The experimental results show that the vehicle monitoring and prediction model has the highest accuracy of location and type recognition for four types of traffic objects, namely, small cars, trucks, buses and pedestrians, reaching 80\%.},
  archive      = {J_COMCOM},
  author       = {Jingyu Liu and Jing Wu and Mingyu Liu},
  doi          = {10.1016/j.comcom.2020.02.009},
  journal      = {Computer Communications},
  pages        = {499-506},
  shortjournal = {Comput. Commun.},
  title        = {UAV monitoring and forecasting model in intelligent traffic oriented applications},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convolutional neural networks for 5G-enabled intelligent
transportation system: A systematic review. <em>COMCOM</em>,
<em>153</em>, 459–498. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern 5G-enabled Intelligent Transportation System (ITS) provides comfort and safety to the end users by using various models and techniques most of which are based on the machine learning-based techniques. However, a large number of issues such as congestion control , safety and security, traffic management exist in modern ITS for which AI-based techniques can be used. From the existing literature, it has been observed that deep learning based techniques are widely used for object detection, localization , and classification in ITS which in turns provide unforgettable experience to both the users and drivers. Specifically, Convolutional Neural Networks (CNN) and their variants are widely used for object detection, localization , and classification in modern ITS. Motivated from these facts, in this paper, we have reviewed different types of CNN models used in modern ITS for traffic sign recognition, traffic light detection, vehicle classification and pedestrian detection. Various CNN based models and techniques are discussed and compared in comparison to the existing schemes using different performance evaluation metrics . From the in-depth survey provided in this paper, users can identify that which particular model can be used in modern ITS with respect to its merits over the others.},
  archive      = {J_COMCOM},
  author       = {Deepika Sirohi and Neeraj Kumar and Prashant Singh Rana},
  doi          = {10.1016/j.comcom.2020.01.058},
  journal      = {Computer Communications},
  pages        = {459-498},
  shortjournal = {Comput. Commun.},
  title        = {Convolutional neural networks for 5G-enabled intelligent transportation system: A systematic review},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Study on embedded system in monitoring of intelligent city
pipeline network. <em>COMCOM</em>, <em>153</em>, 451–458. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of an intelligent city needs healthy operation in all aspects. The monitoring of the intelligent city’s pipeline network in the paper is studied to ensure its healthy development. The surveillance and management system of urban underground pipeline network can improve the efficiency of network resource management , shorten the maintenance time of pipeline network, reduce the cost of resource consumption, resource management cost, and ensure the healthy operation of society. The pipeline network monitoring system is based on an embedded system , which can realize functions such as viewing, historical data query, trend analysis, alarm record query, data export, report generation, etc. The operation condition monitoring module mainly implements real-time monitoring and alarming functions for the state parameters, for example, temperature drop, pressure drop and flow velocity of each pipe section in the pipeline network, and integrates the temperature, pressure and flow data of the pipeline network and the customer terminal. The safe operation range of state parameters and alarm upper and lower lines are set by intelligent decision analysis system of pipe network and to judge the damage situation and countermeasures . The system integrates operation condition monitoring, corrosion monitoring , water hammer monitoring and other modules. Meanwhile, the monitoring interface integrates intelligent alarm and pipeline network structure information. After preliminary data processing, the system communicates with host computer data. The system also integrates the local alarm function of fault signal and valve control. Through GPRS technology as a data transmission channel and the interaction between the upper computer in the central control room and the embedded unit in the lower computer of scene. The pipeline operation parameters can be transmitted and the intelligent city pipeline network monitoring system can be realized, which plays an important role in the healthy development of the city.},
  archive      = {J_COMCOM},
  author       = {Lunqiang Ye},
  doi          = {10.1016/j.comcom.2020.02.004},
  journal      = {Computer Communications},
  pages        = {451-458},
  shortjournal = {Comput. Commun.},
  title        = {Study on embedded system in monitoring of intelligent city pipeline network},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on intelligent identification technology of
lithology wireless remote transmission based on element measurement.
<em>COMCOM</em>, <em>153</em>, 441–450. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, there are many deficiencies in the process of shale gas drilling traditional drilling. There are mainly backward traditional drilling technology, traditional drilling technology which cannot guarantee efficient and stable drilling of shale gas well and traditional logging method cannot effectively identify the lithology of fine rock cuttings. Furthermore, the relevant drilling model has not formed a mature system, and it is impossible to improve the working condition by rock layer judgement through drilling parameters collection. In view of the above problems, this study proposes to combine the data of element logging with the ground monitoring parameters, and transmit them to the host remotely. At the same time, a large number of historical data are used to analyse the cuttings data with the improved grey weight clustering method and entropy weight method, and an intelligent division model of rock stratum identification is constructed. At the same time Then, the functional relationship between multi parameters and strata is established to judge the possible working conditions during the drilling process. A set of formation interpretation and evaluation methods is formed according to different elements and logging parameters of different lithology. The analysis results are compared with the actual drilling conditions to verify the accuracy of the development trend analysis of the drilling conditions, and the inference engine is modified according to the results to improve the well site conditions. Using data from the deep shale layer of a well drilled in southwest, this paper makes comparison between the analysis results of several methods. The results of comparison verify the accuracy of the new method.},
  archive      = {J_COMCOM},
  author       = {Fujie Yang and Mingyi Deng},
  doi          = {10.1016/j.comcom.2020.02.031},
  journal      = {Computer Communications},
  pages        = {441-450},
  shortjournal = {Comput. Commun.},
  title        = {Research on intelligent identification technology of lithology wireless remote transmission based on element measurement},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning models for secure data analytics: A
taxonomy and threat model. <em>COMCOM</em>, <em>153</em>, 406–440. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, rapid technological advancements in smart devices and their usage in a wide range of applications exponentially increases the data generated from these devices. So, the traditional data analytics techniques may not be able to handle this extreme volume of data known as Big Data (BD) generated by different devices. However, this exponential increase of data opens the doors for the different type of attackers to launch various attacks by exploiting various vulnerabilities (SQL injection, OS fingerprinting, malicious code execution, etc.) during data analytics. Motivated from the aforementioned discussion, in this paper, we explored Machine Learning (ML) and Deep Learning (DL)-based models and techniques which are capable off to identify and mitigate both the known as well as unknown attacks. ML and DL-based techniques have the capabilities to learn from the traffic pattern using training and testing datasets in the extensive network domains to make intelligent decisions concerning attack identification and mitigation. We also proposed a DL and ML-based Secure Data Analytics (SDA) architecture to classify normal or attack input data. A detailed taxonomy of SDA is abstracted into a threat model. This threat model addresses various research challenges in SDA using multiple parameters such as-efficiency, latency, accuracy, reliability, and attacks launched by the attackers. Finally, a comparison of existing SDA proposals with respect to various parameters is presented, which allows the end users to select one of the SDA proposals in comparison to its merits over the others.},
  archive      = {J_COMCOM},
  author       = {Rajesh Gupta and Sudeep Tanwar and Sudhanshu Tyagi and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.02.008},
  journal      = {Computer Communications},
  pages        = {406-440},
  shortjournal = {Comput. Commun.},
  title        = {Machine learning models for secure data analytics: A taxonomy and threat model},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Event alert and detection in smart cities using anomaly
information from remote sensing earthquake data. <em>COMCOM</em>,
<em>153</em>, 397–405. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weak seismic thermal infrared (TIR) anomaly information in offshore earthquake is one of the important contents of earthquake monitoring and event alert and detection of smart cities in coastal areas. To tackle the characteristics of offshore seismic TIR anomaly in the adjacent sea of mainland, this paper proposed a detailed event alert and detection method of offshore earthquake’s weak TIR anomaly information in smart cities from moderate resolution imaging spectroradiometer (MODIS) data. In this method, the monthly and quarterly brightness temperature background field was first established, and then the offshore seismic TIR anomaly were got by wavelet transform and relative power spectrum method from MODIS data. Finally, the current seismic TIR anomaly in the adjacent sea is analyzed and discussed in terms of space–time changes, sequential variation of power spectrum, relationship between anomaly area and earthquake magnitude, sensor performance and the assimilation of brightness temperature background field. Our experiments present that the distribution of weak seismic TIR anomaly information from remote sensing data is good agreement with the seismic activity fault belts. The results reveal that the weak seismic TIR anomaly information can potentially contribute the event alert and detection the offshore earthquake in the adjacent sea and monitoring earthquake.},
  archive      = {J_COMCOM},
  author       = {Lan Liu and Cheng-fan Li and Xian-kun Sun and Jun-juan Zhao},
  doi          = {10.1016/j.comcom.2020.02.023},
  journal      = {Computer Communications},
  pages        = {397-405},
  shortjournal = {Comput. Commun.},
  title        = {Event alert and detection in smart cities using anomaly information from remote sensing earthquake data},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Error detection and control of IIoT network based on CRC
algorithm. <em>COMCOM</em>, <em>153</em>, 390–396. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of computer network communication, there is usually the situation of measuring the instability of data transmission within a specified time, which is the problem of bit error rate (BER). In order to transmit information accurately and reliably, the communication is more secure and the signal is more stable. In general, the corresponding error control measures in the communication network will be taken. Cyclic redundancy check (CRC) algorithm is an effective method to detect network communication errors. In this paper, the application of cyclic redundancy check in computer network communication error detection and control is studied. The proposed CRC algorithm can reduce the error rate of the system by detecting and controlling the errors. In addition, we analyse the principle of CRC algorithm, check rules and the understanding of algorithm programming idea in detail. Finally, the application of CRC algorithm in computer network communication error detection and control is discussed, and the validity of CRC algorithm is verified by experiments.},
  archive      = {J_COMCOM},
  author       = {Zonglin Zhong and Wengui Hu},
  doi          = {10.1016/j.comcom.2020.02.035},
  journal      = {Computer Communications},
  pages        = {390-396},
  shortjournal = {Comput. Commun.},
  title        = {Error detection and control of IIoT network based on CRC algorithm},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Establishment and application of intelligent city building
information model based on BP neural network model. <em>COMCOM</em>,
<em>153</em>, 382–389. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of smart cities in our country has received extensive attention. Under the situation that smart cities are vigorously promoted nowadays, compared with traditional construction and operation and maintenance methods, building information model (BIM) technology is more suitable to serve as an important foundation for intelligent management in the whole process of construction projects. BIM is an abbreviation for building information model. BIM relies on a variety of digital technologies, which can be used to realize information modeling of urban buildings and infrastructure. The efficiency of information exchange in the process of intelligence construction ensures the integrity and accuracy of information data exchange and maintains the consistency of information data exchange. Data and information have objectivity, applicability, transferability, and sharing. Geographic data is a digital representation of various geographical features and phenomena and their relationships. BIM is a digital representation of physical and functional characteristics of a facility. It can It is used as a shared knowledge resource for facility information. It becomes a reliable basis for facility life-cycle decision-making. Input BP neural network , and then learn and train by BP neural network .},
  archive      = {J_COMCOM},
  author       = {Yan-Wen Li and Ke Cao},
  doi          = {10.1016/j.comcom.2020.02.013},
  journal      = {Computer Communications},
  pages        = {382-389},
  shortjournal = {Comput. Commun.},
  title        = {Establishment and application of intelligent city building information model based on BP neural network model},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A performance analysis of software defined network based
prevention on phishing attack in cyberspace using a deep machine
learning with CANTINA approach (DMLCA). <em>COMCOM</em>, <em>153</em>,
375–381. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses a novel frame work approach of Software Defined Network based prevention on phishing attack with the help of the deep machine learning with CANTINA approach (DMLCA) in the cyberspace. Cyber security is a significant concern in the operations of coalition, and is a complex challenge because of some needs in operational effectiveness and also the trust relationship limit which exists over the coalition partners. In networking, new promising paradigms like Software Defined Networks (SDN), offer a method to deal more efficiently with their security constraints. This machine learning approach is to deal with the phishing attack problem based on the SVM (support vector machine) and this machine learning technique with SVM helps to effectively to solve classification problems. The CANTINA approach helps to support the robust hyperlinks with the help of evaluating the term frequency (TF) and inverse document frequency and (IDF). This information retrieval algorithm helps to compare, classify and retrieve various documents. The objective is to improve the detection accuracy with the help of the DMLCA method with the various parameters such as detection accuracy based on the true positive ratio and false positive ratio, precision and recall.},
  archive      = {J_COMCOM},
  author       = {Edwin Raja S. and R. Ravi},
  doi          = {10.1016/j.comcom.2019.11.047},
  journal      = {Computer Communications},
  pages        = {375-381},
  shortjournal = {Comput. Commun.},
  title        = {A performance analysis of software defined network based prevention on phishing attack in cyberspace using a deep machine learning with CANTINA approach (DMLCA)},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social-aware resource allocation for multicast
device-to-device communications underlying UAV-assisted networks.
<em>COMCOM</em>, <em>153</em>, 367–374. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicle (UAV)-assisted base stations (BS) can keep the system performance of the cellular networks with device-to-device (D2D) communications in the scenarios that terrestrial BSs are not available. In this paper, the resource allocation is investigated for D2D communications underlaying UAV-assisted cellular networks , where a UAV-assisted BS serves and coordinates multicast D2D clusters and CUs who share common cellular resources. We propose a novel matching-based social-aware resource allocation algorithm (MSARA) for multicast device-to-device (D2D) communications underlaying a UAV-assisted cellular network. The proposed MSARA allows the joint exploitation of wireless characteristics and social ties between users for optimizing the overall utilities and improving the data offloading in UAV-assisted cellular networks. This resource allocation problem is formulated as a matching game, in which D2D social clusters and resource blocks (RB) rationally and selfishly negotiate with each other on basis of utility functions to obtain optimal matching. The social context influences the formation of D2D clusters and the preferences of players in matching game. To solve the peer effects caused by interacting between the D2D social clusters sharing the same RB, we define swap operations between D2D social clusters to exchange their matched RBs. The proposed algorithm is proved to converge to a two-sided exchange stable matching between D2D social clusters and RBs. Simulation results show that the proposed scheme achieves a good performance gain compared with other schemes in the literature. Moreover, D2D clusters of socially connected users allow a substantially larger data offloading than the social-unaware approach.},
  archive      = {J_COMCOM},
  author       = {Xin Wang and Zhihong Qian and Shuang Zhai and Xue Wang},
  doi          = {10.1016/j.comcom.2020.02.019},
  journal      = {Computer Communications},
  pages        = {367-374},
  shortjournal = {Comput. Commun.},
  title        = {Social-aware resource allocation for multicast device-to-device communications underlying UAV-assisted networks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using data mining techniques for bike sharing demand
prediction in metropolitan city. <em>COMCOM</em>, <em>153</em>, 353–366.
(<a href="https://doi.org/10.1016/j.comcom.2020.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes. A Data mining technique is employed for overcoming the hurdles for the prediction of hourly rental bike demand. This paper discusses the models for hourly rental bike demand prediction. Data used include weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information. The paper also explores an filtering of features approach to eliminate the parameters which are not predictive and ranks the features based on its prediction performance. Five Statistical regression models were trained with their best hyperparameters  using repeated cross-validation and the performance is evaluated using a testing set: (a) Linear Regression (b) Gradient Boosting Machine (c) Support Vector Machine (Radial Basis Function Kernel) (d) Boosted Trees, and (e) Extreme Gradient Boosting Trees. When all the predictors are employed, the best model Gradient Boosting Machine can give the best and highest R 2 value of 0.96 in the training set and 0.92 in the test set. Furthermore, several analyzes are carried out in Gradient Boosting Machine with different combinations of predictors to identify the most significant predictors and the relationships between them.},
  archive      = {J_COMCOM},
  author       = {Sathishkumar V E and Jangwoo Park and Yongyun Cho},
  doi          = {10.1016/j.comcom.2020.02.007},
  journal      = {Computer Communications},
  pages        = {353-366},
  shortjournal = {Comput. Commun.},
  title        = {Using data mining techniques for bike sharing demand prediction in metropolitan city},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compact DGS quad band filter for multi-service wireless
communication systems using stub loaded stepped impedance resonators.
<em>COMCOM</em>, <em>153</em>, 349–352. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a compact dual-mode quad band micro-strip band-pass (BPF) and low pass (LPF) filter by using a stub-loaded stepped-impedance resonator (SIR) and a short-circuited stub-loaded uniform impedance resonator. Also, ring SIR geometry is introduced to miniature the size of this filter while maintaining excellent performance. The use of a stub resonator at the central point of the ring SIR can generate two resonant modes in two pass bands. For demonstration purposes, a quad-band filter for the applications of the WLAN/WiMAX/WLAN/UWB at 1.7/3.8/6.91/10.10, Worldwide Interoperability for Microwave Access at 3.8 GHz and wireless local area networks at 6.91 GHz and 10.10 GHz is designed, and fabricated.},
  archive      = {J_COMCOM},
  author       = {Mariselvam V. and Varatharajan R.},
  doi          = {10.1016/j.comcom.2020.01.078},
  journal      = {Computer Communications},
  pages        = {349-352},
  shortjournal = {Comput. Commun.},
  title        = {Compact DGS quad band filter for multi-service wireless communication systems using stub loaded stepped impedance resonators},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Malware classification algorithm using advanced
word2vec-based bi-LSTM for ground control stations. <em>COMCOM</em>,
<em>153</em>, 342–348. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Internet of Drones (IoD) are issued to utilize the diverse kinds of drones for leisure, education and so on. Researchers study to prevent the situations that drones are disabled by cyber-attackers by embedding malwares into the drones and Ground Control Stations (GCS). Therefore, it is required to protect the malwares considering the diverse kinds of features of the drones and GCSs. Signature-based detection approaches are traditionally utilized. However, given that those approaches only scan files partially, some of malwares are not detected. This paper proposes a novel method for finding the malwares in GCSs that utilizes a fastText model to create lower-dimension vectors than those the vectors by one-hot encoding and a bidirectional LSTM model to analyze the correlation with sequential opcodes. In addition, API function names are utilized to increase the classification accuracy of the sequential opcodes. In the experiments, the Microsoft malware classification challenge dataset was utilized and the malwares in the dataset were classified by family types. The proposed method showed the performance improvement of 1.87\% comparing with the performance by a one-hot encoding-based approach. When the proposed method was compared with a similar decision tree-based malware detection approach, the performance of the proposed method was improved by 0.76\%.},
  archive      = {J_COMCOM},
  author       = {Yunsick Sung and Sejun Jang and Young-Sik Jeong and Jong Hyuk (James J.) Park},
  doi          = {10.1016/j.comcom.2020.02.005},
  journal      = {Computer Communications},
  pages        = {342-348},
  shortjournal = {Comput. Commun.},
  title        = {Malware classification algorithm using advanced word2vec-based bi-LSTM for ground control stations},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security threats and countermeasures in software defined
network using efficient and secure trusted routing mechanism.
<em>COMCOM</em>, <em>153</em>, 336–341. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Recent days, social networks, web applications and mobile platforms make consumers highly vulnerable. A modern approach requires more time to detect the attacks. However, the system has a very restricted knowledge of network malware behavior. It is essential for defenders to know malware behaviors, such as patterns of propagation or membership recruitment, the size of botnets , and distribution of bots, in order to fight against cyber-crime. Where, there is no strong knowledge of the size and allocation of malware in existing systems. To overcome the issues, the proposed method is designed efficient and secure trusted routing mechanism (ESTRM), which promotes a node to choose a different path if the present path often fails to deliver information to the destination. The proposed technique provides privacy from serious assaults for software defined networks by replaying routing data. Based on experiment evaluations, the proposed method improves 5.58 detection accuracy and reduces 0.35 true positive rate (TPR), 0.34 false positive rates (FPR) and 0.19 s execution time (ET) compare than conventional methods.},
  archive      = {J_COMCOM},
  author       = {Abdulrahman Saad Alqahtani},
  doi          = {10.1016/j.comcom.2020.02.020},
  journal      = {Computer Communications},
  pages        = {336-341},
  shortjournal = {Comput. Commun.},
  title        = {Security threats and countermeasures in software defined network using efficient and secure trusted routing mechanism},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exhaustive survey on security and privacy issues in
healthcare 4.0. <em>COMCOM</em>, <em>153</em>, 311–335. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The healthcare industry has revolutionized from 1.0 to 4.0 where Healthcare 1.0 was more doctor centric and Healthcare 2.0 replaced manual records with electronic healthcare records (EHRs). Healthcare 3.0 was patient-centric and Healthcare 4.0 uses cloud computing (CC), fog computing (FC), Internet of things (IoT), and telehealthcare technologies to share data between various stakeholders. However, framing a secure technique for Healthcare 4.0 has always been a challenging task. An in-secure technique for Healthcare 4.0 may lead to the healthcare data breach where hackers can gain full access to patients’ email accounts, messages, and reports. On the contrary, a secured technique for Healthcare 4.0 can provide satisfaction to all stakeholders, including patients and caregivers. Motivated from these facts, this paper presents an extensive literature review and analysis of state-of-the-art proposals to maintain security and privacy in Healthcare 4.0. We also explored the blockchain-based solution to give insights to both researchers and practitioners communities. Different taxonomies used for exploring various security and privacy issues in Healthcare 4.0 are also presented in a structured manner. Then, the advantages and limitations of various security and privacy techniques are explored and discussed in the paper. Finally, existing challenges and future research directions of security and privacy in Healthcare 4.0 are presented.},
  archive      = {J_COMCOM},
  author       = {Jigna J. Hathaliya and Sudeep Tanwar},
  doi          = {10.1016/j.comcom.2020.02.018},
  journal      = {Computer Communications},
  pages        = {311-335},
  shortjournal = {Comput. Commun.},
  title        = {An exhaustive survey on security and privacy issues in healthcare 4.0},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scalable IoT-fog framework for urban sound sensing.
<em>COMCOM</em>, <em>153</em>, 302–310. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is a system of interrelated devices that can be used to allow large-scale collection and analysis of data. However, as it grew, IoT networks were not capable of managing the data from these services. As a result, cloud computing was introduced to address the need for datacentres for IoT networks. As the technology evolved, the demand for a proper means of supporting and managing crowdsensing and real-time data increased, and cloud servers could no longer keep up with the large volumes of incoming data. This demand brought rise to fog computing . It became an extension to the cloud and allowed resources to be allocated around the network effectively. Its integration to IoT reduced the strain towards the cloud servers. However, issues in high power consumption at the end device and data management constraints surfaced. This paper proposes two approaches to alleviate these issues to keep fog computing remain as a reliable option for IoT-related applications. We created an IoT-based sensing framework that used an urban sound classification model . Through active low and high power states and resource reallocation, we created a network configuration . We tested this configuration against IoT frameworks that use the default fog and cloud setups. The results improved the framework’s end device power consumption and server latency. Overall, with the proposed framework, fog computing was proven to be capable of supporting a scalable IoT framework for urban sound sensing.},
  archive      = {J_COMCOM},
  author       = {Marc Jayson Baucas and Petros Spachos},
  doi          = {10.1016/j.comcom.2020.02.012},
  journal      = {Computer Communications},
  pages        = {302-310},
  shortjournal = {Comput. Commun.},
  title        = {A scalable IoT-fog framework for urban sound sensing},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High-order taylor expansion based image space transform
method for real-time augmented reality. <em>COMCOM</em>, <em>153</em>,
294–301. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a real-time augmented reality method based on Taylor expansion formula. This method has the advantage that the pixel relationship in the discrete image space is converted to a continuous high-order Taylor space and maintains pixel invariance. After conversion to Taylor space, the ability to resist dramatic changes in illumination between frames is enhanced and robust to intra-frame local illumination mutations. In the spatial transformation process, differential low-order features are used to represent higher-order features, multiplied by appropriate feature coefficients. These coefficients are first determined theoretically and then experimentally verified, allowing us to obtain high-order feature information and approximate the original pixel values based on the features. We then applied this technique to color-based mean shift tracking problems to achieve promising results.},
  archive      = {J_COMCOM},
  author       = {Feiran Fu and Ming Fang and Huamin Yang and Zhe Li},
  doi          = {10.1016/j.comcom.2020.02.002},
  journal      = {Computer Communications},
  pages        = {294-301},
  shortjournal = {Comput. Commun.},
  title        = {High-order taylor expansion based image space transform method for real-time augmented reality},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent wearable rehabilitation robot control system
based on mobile communication network. <em>COMCOM</em>, <em>153</em>,
286–293. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of disabled people are caused by major diseases and accidents. Because disabled patients cannot exercise freely on their own, in order to prevent muscle atrophy, the most effective treatment is to exercise the patients’ limbs. Therefore, it is necessary to choose a more suitable rehabilitation training method to replace the traditional artificial rehabilitation training method, and the use of intelligent wearable rehabilitation robots to treat hemiplegia patients is particularly important for the rehabilitation treatment of hemiplegia patients. Rehabilitation robots can promote the development of medical technology and medical equipment, and have important practical significance for patients to overcome disease and recover health and build a harmonious family. This paper mainly studies the EMG research of the control system of intelligent wearable rehabilitation robot based on mobile communication network. This paper studies the way of stimulating signals and the processing of signal feedback in the process of electromyographic stimulation of rehabilitation robots to improve the rehabilitation effect of robots after stimulation; explores the problem of using biofeedback and fuzzy control rules to control patients for rehabilitation training, which urges patients actively participate in rehabilitation treatment, effectively guide the recovery of patients’ self-consciousness, and build a variety of training modes for rehabilitation robots to enhance the robot’s ability to adapt to different groups of people. In the experiments of this paper, the time window for data processing is 256ms, and the delay is also 256ms. It can be seen that the original SEMG signal of the control signal has some delay compared with the filtered SEMG signal.},
  archive      = {J_COMCOM},
  author       = {Fengmei Gao and Linhong Wang and Tao Lin},
  doi          = {10.1016/j.comcom.2020.01.054},
  journal      = {Computer Communications},
  pages        = {286-293},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent wearable rehabilitation robot control system based on mobile communication network},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control method of urban intelligent parking guidance system
based on internet of things. <em>COMCOM</em>, <em>153</em>, 279–285. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the economy, people’s living standards continue to improve, which has exacerbated the increase in urban motor vehicles. The increase in the number of cars has facilitated people’s travel and promoted economic growth. However, with the continuous increase in the number of motor vehicles in XX, the problem of difficult parking is becoming more and more dangerous. In order to find a more effective, convenient and accurate parking space prediction effect, this article uses IoT technology to model the roads and main parking lots around XX stations, and uses adaptive genetic algorithms to induce drivers and simulate them. The optimal path and the shortest time for the driver to reach each parking lot from the current location are obtained. In this study, a wavelet neural network model is proposed. The data of the B underground parking lot is used to train and predict the model, and it is found that the prediction accuracy is high. The particle swarm optimization algorithm was used to optimize the wavelet neural network model . As a result, the error between the predicted value and the actual value was further reduced, and the accuracy was further improved. This present work proposes the optimal parking lot selection based on the Logit model. The experimental results show that the parking lot induction method based on the Logit model can realize the selection of the best parking lot. Combined with the optimal path selection, the driver is guided to reach the optimal parking lot on the optimal path.},
  archive      = {J_COMCOM},
  author       = {Jingyu Liu and Jing Wu and Linan Sun},
  doi          = {10.1016/j.comcom.2020.01.063},
  journal      = {Computer Communications},
  pages        = {279-285},
  shortjournal = {Comput. Commun.},
  title        = {Control method of urban intelligent parking guidance system based on internet of things},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multipath congestion control with network assistance.
<em>COMCOM</em>, <em>153</em>, 264–278. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of multiple transport flows over distinct, if possible, paths, is a well-known technique for enhancing the performance and stability of data transfer. Multipath TCP (MPTCP), the most popular multipath transport protocol in-use, allows a single receiver to exploit multiple paths from a single sender. Nevertheless, MPTCP cannot fully exploit the potential gains of multipath connectivity, as it must fairly share resources with regular, single-path TCP, without knowing whether the available paths are distinct or share bottleneck links , due to IP’s design choices. We introduce a hybrid congestion control algorithm for multipath transport that enables higher bandwidth utilization compared to MPTCP, while remaining friendly to TCP-like flows. Our solution employs (i) Normalized Multiflow Congestion Control (NMCC), a novel end-to-end congestion control algorithm and (ii) an in-network module that exposes routing information to the end-users in order to support the greedy friendliness technique. The end-to-end NMCC is architecture-independent and can be seamlessly integrated with MPTCP. The in-network module has been implemented for the PSI Information-Centric Networking architecture, but it can also be integrated with Multi-Protocol Label Switching (MPLS) and Software Defined Networking (SDN). Using an actual protocol implementation deployed on our testbed , as well as on a comprehensive packet-level simulator, we obtain experimental results which demonstrate clear gains for our design in terms of throughput and friendliness to other flows.},
  archive      = {J_COMCOM},
  author       = {Yannis Thomas and George Xylomenos and George C. Polyzos},
  doi          = {10.1016/j.comcom.2020.01.071},
  journal      = {Computer Communications},
  pages        = {264-278},
  shortjournal = {Comput. Commun.},
  title        = {Multipath congestion control with network assistance},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive cache management approach in ICN with pre-filter
queues. <em>COMCOM</em>, <em>153</em>, 250–263. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Information-Centric Networking (ICN), transmission does not depend on the ends of communication, but on the content itself. In-network cache plays an important role in ICN, it empowers nodes in ICN better mobility. It also shortens serving path, lightens load of server, reduces traffic and time delay , its efficiency seriously affects performance of entire network, and thus cache management in ICN draws much attention of researchers recently. Although there are a lot approaches have been proposed, a cache management scheme with better adaptability and less cost remains to be studied. To this end, we propose State-value-and-Cache-rate-Method (SCMethod) to manage cache resources in ICN, which comprises cache deployment policy and cache replacement policy . In cache level, we add pre-filter queues in front of cache queue to filter out popular content to store in cache. In the perspective of node, according to factors that node’s state and relative location on data forwarding path, we define node state and cache rate to select nodes with maximum of state value or minimum cache rate to cache content, and effectively mitigate data redundancy . In order to increase dynamics and adaptive of system for mobility of nodes, we employ cache hit ratio as feedback to dynamically adjust the number of pre-filter queues in every node. With pre-filter queues, we improve Least Recently Used (LRU) cache replacement method. We conduct extensive experiments in simulator Icarus (Saino et al., 2014) with both tree topology and realistic internet topologies , define four metrics to quantitatively evaluate performance of SCMethod and verify its efficacy of reducing latency and load. Simulation results demonstrate that SCMethod we proposed outperform several classic cache schemes of ICN.},
  archive      = {J_COMCOM},
  author       = {Dapeng Man and Qi Lu and Yao Wang and Yang Wu and Xiaojiang Du and Mohsen Guizani},
  doi          = {10.1016/j.comcom.2020.01.062},
  journal      = {Computer Communications},
  pages        = {250-263},
  shortjournal = {Comput. Commun.},
  title        = {An adaptive cache management approach in ICN with pre-filter queues},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing secure blockchain-based access control scheme in
IoT-enabled internet of drones deployment. <em>COMCOM</em>,
<em>153</em>, 229–249. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Internet of Drones (IoD) has emerged as an important research topic in the academy and industry because it has several potential applications ranging from the civilian to military. In IoD environment, several drones, called Unmanned Aerial Vehicles (UAVs), are deployed in different flying zones that communicate each other to exchange crucial information, and then the information are collected by the Ground Station Server ( G S S ) (GSS) . All the drones and the G S S GSS are registered with a central trusted authority, Control Room ( C R ) (CR) prior to their deployment. Since the drones and the G S S GSS communicate over open channel (e.g., wireless medium), there are security and privacy issues in the IoD environment. To handle such issues, in this paper we introduce a blockchain-based access control scheme in the IoD environment that allows secure communication among the drones, and also among the drones and the G S S GSS . Secure data gathered by the G S S GSS form transactions, and those transactions are made into the blocks. The blocks are finally added in the blockchain by the cloud servers connected with the G S S GSS via the Ripple Protocol Consensus Algorithm (RPCA) in a peer-to-peer cloud server network. Once the blocks are added into the blockchain, the transactions containing in the blocks cannot be altered, modified or even removed. We provide all sorts of security analysis including formal security under the random oracle model , informal security and simulation-based formal security verification to assure that the proposed scheme can resist various potential attacks with high probability needed in an IoD environment. In addition, a meticulous comparative analysis among the proposed scheme and other closely related existing schemes shows that our scheme offers more functionality attributes and better security, and also low communication and computation costs as compared to other schemes.},
  archive      = {J_COMCOM},
  author       = {Basudeb Bera and Durbadal Chattaraj and Ashok Kumar Das},
  doi          = {10.1016/j.comcom.2020.02.011},
  journal      = {Computer Communications},
  pages        = {229-249},
  shortjournal = {Comput. Commun.},
  title        = {Designing secure blockchain-based access control scheme in IoT-enabled internet of drones deployment},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient resource management and workload allocation in
fog–cloud computing paradigm in IoT using learning classifier systems.
<em>COMCOM</em>, <em>153</em>, 217–228. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in network-connected computing devices, the Internet of Things (IoT) has progressed in terms of size and speed. Subsequently, the amount of produced data and computation loads has increased dramatically. A solution to handle this huge volume of workloads is cloud computing in which a considerable delay exists in the processing load and this has remained a concern in the field of distributed computing networks. Processing workloads at the edge of the network can reduce the response time while at the same time imposing energy constraints by bringing the task of load processing from data centers , which are supplied by electrical energy sources, to the network edges which are only supported by limited energies of batteries. Therefore, workloads need to be distributed evenly between the clouds and the edges of the network. In this paper, two methods based on XCS learning classifier systems (LCS), namely, XCS and BCM-XCS, are proposed to balance the power consumption at the edge of the network and to reduce delays in the processing of workloads. The results of our experiments are indicative of the superiority of BCM-XCS over the basic XCS-based method. The proposed methods distribute the workloads in a way that the delay in their processing and the communication delay between the cloud and fog nodes are both minimized. In addition to considerable advantages in controlling the fluctuations of the processing delay, the proposed methods can simultaneously reduce the processing delay by 42\% by using a moderate power consumption at the edge of the network. The proposed methods can also recharge the renewable batteries used at the edge of the network about 18 percent more than the best state-of-the-art method.},
  archive      = {J_COMCOM},
  author       = {Mahdi Abbasi and Mina Yaghoobikia and Milad Rafiee and Alireza Jolfaei and Mohammad R. Khosravi},
  doi          = {10.1016/j.comcom.2020.02.017},
  journal      = {Computer Communications},
  pages        = {217-228},
  shortjournal = {Comput. Commun.},
  title        = {Efficient resource management and workload allocation in fog–cloud computing paradigm in IoT using learning classifier systems},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Privacy preserving distributed data mining based on secure
multi-party computation. <em>COMCOM</em>, <em>153</em>, 208–216. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining is an important task to understand the valuable information for making correct decisions. Technologies for mining self-owned data of a party are rather mature. However, how to perform distributed data mining to obtain information from data owned by multiple parties without privacy leakage remains a big challenge. While secure multi-party computation (MPC) may potentially address this challenge, several issues have to be overcome for practical realizations. In this paper, we point out two unsupported tasks of MPC that are common in the real-world. Towards this end, we design algorithms based on optimized matrix computation with one-hot encoding and LU decomposition to support these requirements in the MPC context. In addition, we implement them based on a SPDZ protocol, a computation framework of MPC. The experimental evaluation results show that our design and implementation are feasible and effective for privacy preserving distributed data mining.},
  archive      = {J_COMCOM},
  author       = {Jun Liu and Yuan Tian and Yu Zhou and Yang Xiao and Nirwan Ansari},
  doi          = {10.1016/j.comcom.2020.02.014},
  journal      = {Computer Communications},
  pages        = {208-216},
  shortjournal = {Comput. Commun.},
  title        = {Privacy preserving distributed data mining based on secure multi-party computation},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cascading handcrafted features and convolutional neural
network for IoT-enabled brain tumor segmentation. <em>COMCOM</em>,
<em>153</em>, 196–207. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has revolutionized the medical world by facilitating data acquisition using various IoT devices. These devices generate the data in multiple forms including text, images, and videos. Given this, the extraction of accurate and useful information from the massive serge IoT generated data is a highly challenging task. Recently, the brain tumor segmentation from IoT generated images has emerged as a promising issue that requires sophisticated and efficient techniques. The accurate brain tumor segmentation is challenging due to large variations in tumor appearance. Existing methods either use handcrafted features based techniques or Convolutional Neural Network (CNN). In this paper, a novel cascading approach for fully automatic brain tumor segmentation has been proposed, which intelligently combines handcrafted features and CNN. First, three handcrafted features are computed namely mean intensity, Local Binary Pattern (LBP) and Histogram of Oriented Gradients (HOG) and then Support Vector Machine (SVM) is employed to perform pixel classification that results in Confidence Surface Modality (CSM). This CSM along with the given Magnetic Resonance Imaging (MRI) is fed to a novel three pathways CNN architecture. In the experiments on BRATS 2015 dataset, the proposed method achieves promising results with Dice similarity scores of 0.81, 0.76 and 0.73 on complete, core and enhancing tumor, respectively.},
  archive      = {J_COMCOM},
  author       = {Hikmat Khan and Pir Masoom Shah and Munam Ali Shah and Saif ul Islam and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.comcom.2020.01.013},
  journal      = {Computer Communications},
  pages        = {196-207},
  shortjournal = {Comput. Commun.},
  title        = {Cascading handcrafted features and convolutional neural network for IoT-enabled brain tumor segmentation},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Real-time detection of energy consumption of IoT network
nodes based on artificial intelligence. <em>COMCOM</em>, <em>153</em>,
188–195. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low power loss networks and wireless sensor networks are important components of the Internet of Things . With the development and popularization of artificial intelligence , the network application of wireless sensors is gradually scaled up and industrialized. Aiming at the problems of high energy consumption of the routing strategy, the algorithm protocol is easy to fall into the local optimum and the uneven energy consumption of network nodes. This paper proposes a regional energy balance routing algorithm based on intelligent chaotic ant colony. Based on the intelligent chaotic ant colony algorithm, combined with the remaining energy factors of wireless sensor network nodes, this paper propose a neighbor selection strategy. In order to enhance the ant search ability and speed up the algorithm convergence, an adaptive perturbation strategy and algorithm termination conditions are proposed respectively to find the global optimal solution and avoid falling into the local optimal solution . Simulation results show that the routing planning method in this paper has obvious advantages in terms of network energy consumption and network delay, node equilibrium energy distribution, network life cycle and other performance. Compared with similar algorithms, the average energy consumption has been saved by 7.3\%.},
  archive      = {J_COMCOM},
  author       = {Jianpeng Zhang},
  doi          = {10.1016/j.comcom.2020.02.015},
  journal      = {Computer Communications},
  pages        = {188-195},
  shortjournal = {Comput. Commun.},
  title        = {Real-time detection of energy consumption of IoT network nodes based on artificial intelligence},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). Construction and simulation of performance evaluation index
system of internet of things based on cloud model. <em>COMCOM</em>,
<em>153</em>, 177–187. (<a
href="https://doi.org/10.1016/j.comcom.2020.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the lack of corresponding scientific evaluation standards and effective evaluation methods for the overall performance of the Internet of Things system, the Internet of Things industry and the market are in a chaotic state, and the quality of various products is uneven. It is difficult for users to select a more suitable application system, which seriously restricts the development process of the industrialization of Internet of Things technology. Therefore, it is very necessary for us to conduct research on the performance evaluation methods of IoT systems. In this paper, the performance of IoT system is selected as the performance evaluation index of the system, and the evaluation system is constructed. The performance evaluation method of the Internet of Things system based on the cloud model is proposed. The comprehensive evaluation of the reliability of the IoT system for the cloud model will be based on the AHP. Based on the combination of attribute decision-making methods, a comprehensive evaluation method based on indicators is proposed, and the system’s indicator model is established. The reliability of the Internet of Things system can be comprehensively evaluated by the value of the indicators. Secondly, the probability density function of tracking error is studied, and its optimal probability density distribution is given by optimal control. Based on the optimal probability density distribution, the performance evaluation index of the system is constructed. In order to compare the current probability density function with the reference probability density function, the tracking error function is first vector, then the performance evaluation index is constructed by gray correlation, and the general steps of performance evaluation based on this index are given. Finally, the effectiveness of the proposed system performance evaluation algorithm is verified by simulation comparison. The data processing and experimental simulation are used to achieve the purpose of evaluating the performance of the Internet of Things system.},
  archive      = {J_COMCOM},
  author       = {Yuncheng Wang},
  doi          = {10.1016/j.comcom.2020.02.016},
  journal      = {Computer Communications},
  pages        = {177-187},
  shortjournal = {Comput. Commun.},
  title        = {Construction and simulation of performance evaluation index system of internet of things based on cloud model},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). The method of internet of things access and network
communication based on MQTT. <em>COMCOM</em>, <em>153</em>, 169–176. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of intelligent hardware and the rapid development of the Internet of Things , its security issues are also facing severe challenges. Internet of things devices are often limited devices with limited computing power and limited resource space. Therefore, a lightweight security solution needs to be designed specifically for this purpose. The purpose of this article is to study the method of IoT device access and network communication based on MQTT (Message Queuing Telemetry Transport). Based on the MQTT protocol and the theoretical foundation of Wi-Fi technology, this paper proposes a Wi-Fi distribution network optimization scheme and terminal communication method, and sets up a system test platform. The experiment proves that the communication method of the IoT terminal equipment based on MQTT proposed in this paper can reliably and flexibly implement the communication function of the equipment and meet the communication needs of the IoT system. According to the performance of the Wi-Fi access configuration method, this paper tests the performance of transmitting information with lengths of 10 bytes, 30 bytes, 50 bytes, and 70 bytes, respectively, the average time of the distribution network is 0.6692s, 1.3546s, 2.8600s, 4.7319s, all rates are 100\%. It can be seen that the system has a higher efficiency in network distribution.},
  archive      = {J_COMCOM},
  author       = {Xiangtao Liu and Tianle Zhang and Ning Hu and Peng Zhang and Yu Zhang},
  doi          = {10.1016/j.comcom.2020.01.044},
  journal      = {Computer Communications},
  pages        = {169-176},
  shortjournal = {Comput. Commun.},
  title        = {The method of internet of things access and network communication based on MQTT},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-efficient resource allocation in wireless powered
CCRNs with simultaneous wireless information and power transfer.
<em>COMCOM</em>, <em>153</em>, 159–168. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the optimal energy efficiency resource allocation for simultaneous wireless information and power transfer (SWIPT) in cooperative cognitive radio networks (CCRNs). The optimal design attempts to deploy each secondary receiver (SR) to harvest the energy and to use the signal received from the secondary transmitter (ST) to decode information. For the information transmission, a traditional multiple access scheme , namely, time division multiple access (TDMA) is addressed. For the TDMA-based information transmission, the users are scheduled in non-overlapping time slots to decode information. To tackle the design with the above scenarios, an optimization problem is formulated to maximize the energy efficiency of the secondary system constrained with the uncertainty of channel state information (CSI). To solve this non-convex problem, nonlinear fractional programming is utilized to transform the objective function into a subtractive form. The nonlinear fractional programming is also used to decompose the problem into two convex subproblems , and the probability constraints of signal to interference plus noise ratio (SINR) are converted into the deterministic ones using integral transformation. A joint optimal time and power allocation (JOTPA) iterative algorithm is proposed to determine the optimum of original non-convex problem. Simulation results have verified the effectiveness of the proposed resource allocation algorithm.},
  archive      = {J_COMCOM},
  author       = {Zhixin Liu and Meihua Zhou and Yanyan Shen and Kit Yan Chan and Xinping Guan},
  doi          = {10.1016/j.comcom.2020.01.068},
  journal      = {Computer Communications},
  pages        = {159-168},
  shortjournal = {Comput. Commun.},
  title        = {Energy-efficient resource allocation in wireless powered CCRNs with simultaneous wireless information and power transfer},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effcient video compression and improving quality of video in
communication for computer endcoding applications. <em>COMCOM</em>,
<em>153</em>, 152–158. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, new “digital” area contain in many novel image and video applications and novel technologies in different fields, such as wireless communication , biology, medicine, engineering, and entertainment. The images and videos are compressed, transmitted, captured, and stored in various digital forms, with different types and amounts of impair artifacts at the same time wireless applications, speckle noise and coding artifacts are most common, in the entertainment and engineering applications , the digital coding and transmission artifacts are considered as dominant. This Special Issue is committed to video quality assessment, available bandwidth of the transmission medium and improvement techniques and systems which are aimed for currently challenging applications in which the visual quality is important in computer communication. In this paper, we propose a novel solution to this problem, which we refer to as a Rate Control (RC) scheme in H.264. The Rate Control scheme controls the rate of compression ratio. The level of compression is decided with the help of rate controller scheme. This scheme measures the quality of the transmitted video and available Bandwidth with the proposed technique; we can build a quality multimedia content and transfer over the transmitter. Simulation results show that our protocol achieves efficient video compression in terms of PSNR when compared with other in achieving quality of video in communication while maintaining the quality multimedia content . Video compression is a challenging one for computer communication and other related network communication to improve the Quality of Service in encoder and decoder applications field.},
  archive      = {J_COMCOM},
  author       = {K. Siva Kumar and S. Sasi Kumar and N. Mohan Kumar},
  doi          = {10.1016/j.comcom.2019.11.026},
  journal      = {Computer Communications},
  pages        = {152-158},
  shortjournal = {Comput. Commun.},
  title        = {Effcient video compression and improving quality of video in communication for computer endcoding applications},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent smart city parking facility layout optimization
based on intelligent IoT analysis. <em>COMCOM</em>, <em>153</em>,
145–151. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research based on the utilization of big data has led to new opportunities and developments in contemporary urban planning and smart city construction. This research is based on open big data of networks, such as the website Where to Go and public comments, spatial syntax theory and technical methods using the current layout of urban parking facilities in Shinan District as a case study of the lack of parking facilities and their unreasonable layout. Based on a quantitative analysis of the distribution of the traffic network and parking facilities on the urban scale and the block scale of the Shinan District of Qingdao, we found that the thermal density of Baidu is closely related to the spatial syntactic parameters of the urban area on the large scale and local scale. A field investigation was performed to analyze the traffic network of the Southern District of Qingdao and propose comprehensive optimization strategies to provide technical support for the construction of intelligent shared parking facilities in cities. This study solves a series of problems, such as unreasonable parking facility allocation around scenic spots in tourist cities, and can also be used as a reference for the optimization of parking facility layouts in similar cities.},
  archive      = {J_COMCOM},
  author       = {Xiaowen Ma and Hongyan Xue},
  doi          = {10.1016/j.comcom.2020.01.055},
  journal      = {Computer Communications},
  pages        = {145-151},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent smart city parking facility layout optimization based on intelligent IoT analysis},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design on a wearable armband device for assessing the motion
function of upper limbs. <em>COMCOM</em>, <em>153</em>, 135–144. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of people’s living standards, people’s need for daily health monitoring is increasingly urgent, making human activity assessment based on wearable devices a new research hotspot in the field of pattern recognition and machine learning . In order to meet the needs of the rapid development of mobile medicine, the development of new armband-type wearable upper limb motor function evaluation systems has become increasingly important. This paper designs a human motion signal acquisition system composed of terminal nodes and gateway nodes. The terminal node is worn on the arm part of the human body, collects movement data of the corresponding part, and receives commands from the gateway node wirelessly. Multiple terminal nodes work in an orderly manner under the coordination of the gateway nodes, and the data of each node in the same experiment maintains high synchronization. In addition, the gateway node is connected to the upper computer through the USB interface, and is responsible for the construction of the wireless communication network of the entire system and the forwarding of the commands from the upper computer. In the case of hardware circuit and software design , power consumption and performance tests were performed on the hardware nodes of the evaluation system, and upper limb movement functions were tested. The test results show that the system is safe and reliable.},
  archive      = {J_COMCOM},
  author       = {Xiupeng Gao and Yiwei Yin},
  doi          = {10.1016/j.comcom.2020.01.074},
  journal      = {Computer Communications},
  pages        = {135-144},
  shortjournal = {Comput. Commun.},
  title        = {Design on a wearable armband device for assessing the motion function of upper limbs},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancement of e-commerce security through asymmetric key
algorithm. <em>COMCOM</em>, <em>153</em>, 125–134. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic commerce offers reduced transaction costs and much convenient mode of business to all over global consumers. This paper explains asymmetric methods which uses electronic commerce transactions and other assisted algorithms of cryptography that are important in set up of electronic commerce working. This study explains the essential security problems in electronic commerce. To avoid the issues of security certain secure conditions must be followed which offers sufficient security to transaction data for every entity in transaction of electronic commerce. In this study a multi-layer encryption algorithm namely RSA encryption algorithm and Fernet cipher encryption algorithm is proposed based on security. Multi-layer encryption algorithm is used to construct a sophisticated and complex approach of encryption. This algorithm integrates the strength of several techniques of encryption at the same time. This study reveals how much safe consumer and payment data order will be managed effectively by security-based approaches. Encryption technique discussed in this study is the major technique to make the transaction over internet secure. A better technology of encryption can decrease the fraudlent activities easily and effectively. This study proposes a multi-layer encryption algorithm and implemented it in order to enable delivery of messages through network in a secure way. This study will be helpful to control the decryption and encryption with the use of private and public key of receiver and sender.},
  archive      = {J_COMCOM},
  author       = {Dijesh P. and SuvanamSasidhar Babu and Yellepeddi Vijayalakshmi},
  doi          = {10.1016/j.comcom.2020.01.033},
  journal      = {Computer Communications},
  pages        = {125-134},
  shortjournal = {Comput. Commun.},
  title        = {Enhancement of e-commerce security through asymmetric key algorithm},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance modeling and analysis of a hyperledger-based
system using GSPN. <em>COMCOM</em>, <em>153</em>, 117–124. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a highly scalable permissioned blockchain platform, Hyperledger Fabric supports a wide range of industry use cases ranging from governance to finance. In this paper, we propose a model to analyze the performance of a Hyperledger-based system by using Generalized Stochastic Petri Nets (GSPN). This model decomposes a transaction flow into multiple phases and provides a simulation-based approach to obtain the system latency and throughput with a specific arrival rate. Based on this model, we analyze the impact of different configurations of ordering service on system performance to find out the bottleneck. Moreover, a mathematical configuration selection approach is proposed to determine the best configuration which can maximize the system throughput. Finally, extensive experiments are performed on a real-time system to validate the proposed model and approaches.},
  archive      = {J_COMCOM},
  author       = {Pu Yuan and Kan Zheng and Xiong Xiong and Kuan Zhang and Lei Lei},
  doi          = {10.1016/j.comcom.2020.01.073},
  journal      = {Computer Communications},
  pages        = {117-124},
  shortjournal = {Comput. Commun.},
  title        = {Performance modeling and analysis of a hyperledger-based system using GSPN},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bidirectional congestion control transport protocol for
the internet of drones. <em>COMCOM</em>, <em>153</em>, 102–116. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSNs) are composed of energy constrained devices that autonomously form networks through which sensed information is transported from the region of interest to the central control station (sink), integration with unmanned aerial vehicles (UAVs) leads to enlarged monitoring area and to enhance overall network performance. Due to application specific nature of wireless sensor networks, it is challenging to design a congestion control protocol that is suitable for all types of applications in the Internet of Drones (IoD). Congestion avoidance and control in wireless sensor networks mainly aims at reducing packet drop due to congestion and maintaining fair bandwidth allocation to all network flows. In this research work, we propose a reliable and congestion based protocol, which provides both bidirectional reliability and rate adjustment based congestion control . It uses Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method to select optimal path for data transmission because TOPSIS selects an alternative such that it has shortest distance from the ideal one and greatest distance from negative ideal solution. Congestion is detected by using proportion of average packet service time over average packet inter-arrival time as congestion degree. Then, congestion is notified using implicit notification to save energy and reduce overhead. To mitigate congestion along with maintaining fairness, an equal priority index is assigned to all data sources and when congestion occurs, rate adjustment to optimal value based on priority value is used for congestion control. This approach helps to diminish packet drops, maintain fairness and get better energy efficiency. Finally, we compare the performance of the proposed protocol with that of existing protocols. Our simulation results show reduced average delivery overhead, drop packet ratio, queue length and delay with increased average delivery ratio. Moreover, our protocol provides better energy efficiency and fairness when compared with the existing competing protocols.},
  archive      = {J_COMCOM},
  author       = {Bhisham Sharma and Gautam Srivastava and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.comcom.2020.01.072},
  journal      = {Computer Communications},
  pages        = {102-116},
  shortjournal = {Comput. Commun.},
  title        = {A bidirectional congestion control transport protocol for the internet of drones},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed flocking control strategy for UAV groups.
<em>COMCOM</em>, <em>153</em>, 95–101. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the information security of UAV groups, maximize the detection range of the UAV group and minimize the communication range, this paper improves Olfati–Saber’s flocking algorithm using virtual leader and integrates the multiple UAVs with real environment. The improved swarm control algorithm can help to make all agents accurately track the speed of virtual leaders. Then, we introduce the conception of virtual communication circle to control the communication power of each UAV, and the moving function of the target position is improved to meet the limited conditions of given communication distance, to ensure the non-collision and stable communication of the UAV during the moving process. All UAVs in the group system will keep converging, avoiding collision and the speed is the same as that of the virtual pilot. Therefore, multiple UAVs can track the virtual pilot for cluster flight and a distributed cooperative control strategy can be acquired. The simulation results show that the strategy proposed in this paper makes a better communication performance among UAVs in real time, and the UAV groups achieve the information more timely, which is proved to be an effective way to ensure the security communication among multiple UAVs.},
  archive      = {J_COMCOM},
  author       = {Wei Liu and Zhijun Gao},
  doi          = {10.1016/j.comcom.2020.01.076},
  journal      = {Computer Communications},
  pages        = {95-101},
  shortjournal = {Comput. Commun.},
  title        = {A distributed flocking control strategy for UAV groups},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient routing algorithm in wireless body area
networks for smart wearable patches. <em>COMCOM</em>, <em>153</em>,
85–94. (<a href="https://doi.org/10.1016/j.comcom.2020.01.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently most of the applications in Wireless Body Sensor Network (WBAN) demand effective communication processes, which is used to monitor the data in a remote manner according to the demand and timely manner for wearable systems . The data have been transmitted through the sensor networks among smart wearable devices which help to analyze the various security threats. The data transmission using sensor networks of smart wearable patches may consumes more energy which leads to minimize the entire network lifetime as well as to reduce the data transmission quality. Even though the network transmits the data with effective manner, the data has been aggregated from different sources via common aggregators in the smart wearable patches. At the time of the aggregation process, network lifetime needs to be managed for further data analyzes process. So, in this research the lifetime of the network has been managed by applying the opportunistic energy-efficient routing with load balancing (OE2-LB) algorithm which eliminates the data aggregation delay as well as avoid routing loops with effective manner for the smart wearable patches. Then the efficiency of the system has been validated in terms of network lifetime, delay, error metrics, Energy efficiency and throughput of the network.},
  archive      = {J_COMCOM},
  author       = {A. Sundar Raj and M. Chinnadurai},
  doi          = {10.1016/j.comcom.2020.01.069},
  journal      = {Computer Communications},
  pages        = {85-94},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient routing algorithm in wireless body area networks for smart wearable patches},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Device-to-device content caching techniques in 5G: A
taxonomy, solutions, and challenges. <em>COMCOM</em>, <em>153</em>,
48–84. (<a href="https://doi.org/10.1016/j.comcom.2020.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past many years, content caching is one of the major challenges in the 5G environment. With the advent of the Internet of Things (IoT) and 5G , users want to access various services within a fraction of seconds resulting an extra burden on the underlying network infrastructure to maintain Quality of Service (QoS) and Quality of Experience (QoE) provisions of different applications for the end-users and service providers. However, caching the most popular contents followed by device-to-device (D2D) sharing can resolve the aforementioned problems. But, access delay is still one of the challenges in front of the research community during content caching using D2D communications in a 5G environment. Motivated from these facts, this paper provides an in-depth survey of various D2D based content caching techniques used for popular content sharing among different devices in the 5G environment. A detailed taxonomy is presented to give deep insights to the readers about the findings, constraints, and challenges of various existing proposals. Finally, a relative comparison of the existing D2D content caching proposals is given in the text with respect to various parameters. It gives deep insights to the readers about the applicability of different caching techniques in 5G.},
  archive      = {J_COMCOM},
  author       = {Divya Prerna and Rajkumar Tekchandani and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.01.057},
  journal      = {Computer Communications},
  pages        = {48-84},
  shortjournal = {Comput. Commun.},
  title        = {Device-to-device content caching techniques in 5G: A taxonomy, solutions, and challenges},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software defined solutions for sensors in 6G/IoE.
<em>COMCOM</em>, <em>153</em>, 42–47. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to widely apply 6G/IoE (Internet of Everything) to various scenarios in real life and link the infrastructure closely related to people through the network, this paper analyzes the dual-channel architecture defined by the software of wireless sensor in 6G/IoE and proposes a reasonable solution to reduce the signal interference, so as to better transmit the related signals. Moreover, the node data in the sensor is processed by fog computing and edge computing , and the network communication quality is judged by transmission energy consumption and packet loss rate. On this basis, the delay, channel transmission, and total network throughput are analyzed to find the problem. The results show that the dual-channel architecture of software-defined wireless sensor can transmit control messages and sensor messages of nodes separately, which not only reduces the traffic load of single channel, but also avoids collision between control messages and sensor messages of nodes. It improves the information transmission performance of the network and facilitates the further application of 6G/IoE. Therefore, the analysis of the software definition of sensor and the solution proposed play an important role in the widespread use of 6G/IoE.},
  archive      = {J_COMCOM},
  author       = {Zhihan Lv and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2020.01.060},
  journal      = {Computer Communications},
  pages        = {42-47},
  shortjournal = {Comput. Commun.},
  title        = {Software defined solutions for sensors in 6G/IoE},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Location of three-dimensional movement for a human using a
wearable multi-node instrument implemented by wireless body area
networks. <em>COMCOM</em>, <em>153</em>, 34–41. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wireless human body local area network is a wireless network composed of lightweight, wearable or implantable sensor nodes that sense various physiological parameters of the human body. This paper introduces the key technologies and characteristics of wireless sensor networks and the research status of node localization , analyzes the wireless sensor network localization algorithms and their performance evaluation indicators, and conducts in-depth research on wearable 3D node localization algorithms. The 3D positioning algorithm uses static beacon nodes to achieve the 3D positioning of public nodes. The positioning accuracy and positioning rate depend on the number of beacon nodes, and the number of beacon nodes increases, which increases network costs and energy consumption. Aiming at the spatiotemporal correlation between motion data collected by multiple sensors in a wireless human local area network, an RSSI-based multi-node 3D motion monitoring auxiliary algorithm is used, including the planning of wearable device motion trajectories. Throughout the positioning process, the workflow belongs to the public node and involves the format of the relevant information packet. The 3D wearable multi-node positioning algorithm based on RSSI is a distance-dependent distributed positioning algorithm. The public node uses the RSSI ranging method to obtain the distance during the two-stage positioning process, and then uses the three-dimensional multilateral positioning method to perform its own calculation.},
  archive      = {J_COMCOM},
  author       = {Dong Wang and Qingcheng Huang and Xin Chen and Lijuan Ji},
  doi          = {10.1016/j.comcom.2020.01.070},
  journal      = {Computer Communications},
  pages        = {34-41},
  shortjournal = {Comput. Commun.},
  title        = {Location of three-dimensional movement for a human using a wearable multi-node instrument implemented by wireless body area networks},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent urban planning on smart city blocks based on
bicycle travel data sensing. <em>COMCOM</em>, <em>153</em>, 26–33. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The block is an important spatial unit of urban built-up areas. The investigation of the relationship between bicycle travel mode and land use characteristics at the scale of the block can effectively address the contradiction between the supply and demand for transportation under the background of stock characteristics. Herein, 21 typical blocks in Xi’an are applied as the research object, Mobike bicycle data, mobile phone signaling data and traditional survey data are employed. The correlation analysis and multiple linear regression analysis methods are used to identify the relationship between bicycle travel and land use. As a result, land use characteristics under the influence of bicycle travel are obtained. The results show that the land use indicators significantly related to street bicycle travel are composed of building mixing degree, floor area ratio and riding connectivity. Each index has a positive effect on street bicycle travel. The building mixing degree has the greatest impact on bicycle travel, followed by the floor area ratio and riding connectivity. In different periods, the impact of three indicators on bicycle travel varies. Especially, the impact on weekend bicycle travel is more obvious. This study can provide a reference for the optimization and transformation of land use in blocks under the influence of bicycle travel.},
  archive      = {J_COMCOM},
  author       = {Quanhua Hou and Weijia Li and Xiaoqing Zhang and Yinnan Fang and Yaqiong Duan and Lingda Zhang and Wenqian Liu},
  doi          = {10.1016/j.comcom.2020.01.066},
  journal      = {Computer Communications},
  pages        = {26-33},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent urban planning on smart city blocks based on bicycle travel data sensing},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning paradigms for communication and computing
technologies in IoT systems. <em>COMCOM</em>, <em>153</em>, 11–25. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless communication and computation technologies are becoming increasingly complex and dynamic due to the sophisticated and ubiquitous Internet of things (IoT) applications. Therefore, future wireless networks and computation solutions must be able to handle these challenges and dynamic user requirements for the success of IoT systems. Recently, learning strategies (particularly deep learning and reinforcement learning) are explored immensely to deal with the complexity and dynamic nature of communication and computation technologies for IoT systems, mainly because of their power to predict and efficient data analysis. Learning strategies can significantly enhance the performance of IoT systems at different stages, including at IoT node level, local communication, long-range communication, edge gateway, cloud platform, and corporate data centers . This paper presents a comprehensive overview of learning strategies for IoT systems. We categorize learning paradigms for communication and computing technologies in IoT systems into reinforcement learning , Bayesian algorithms, stochastic learning, and miscellaneous. We then present research in IoT with the integration of learning strategies from the optimization perspective where the optimization objectives are categorized into maximization and minimization along with corresponding applications. Learning strategies are discussed to illustrate how these strategies can enhance the performance of IoT applications. We also identify the key performance indicators (KPIs) used to evaluate the performance of IoT systems and discuss learning algorithms for these KPIs. Lastly, we provide future research directions to further enhance IoT systems using learning strategies},
  archive      = {J_COMCOM},
  author       = {Waleed Ejaz and Mehak Basharat and Salman Saadat and Asad Masood Khattak and Muhammad Naeem and Alagan Anpalagan},
  doi          = {10.1016/j.comcom.2020.01.043},
  journal      = {Computer Communications},
  pages        = {11-25},
  shortjournal = {Comput. Commun.},
  title        = {Learning paradigms for communication and computing technologies in IoT systems},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TS-LoRa: Time-slotted LoRaWAN for the industrial internet of
things. <em>COMCOM</em>, <em>153</em>, 1–10. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automation and data capture in manufacturing, known as Industry 4.0 , requires the deployment of a large number of wireless sensor devices in industrial environments. These devices have to be connected via a reliable, low-latency, low-power and low operating-cost network. Although LoRaWAN provides a low-power and reasonable-cost network technology, its current ALOHA-based MAC protocol limits its scalability and reliability. A common practise in wireless networks is to solve this issue and improve scalability through the use of time-slotted communications. However, any time-slotted approach comes with overheads to compute and disseminate the transmission schedule in addition to ensuring global time synchronisation. Affording these overheads is not straight forward with LoRaWAN restrictions on radio duty-cycle and downlink availability. Therefore, in this work, we propose TS-LoRa, an approach that tackles these overheads by allowing devices to self-organise and determine their slot positions in a frame autonomously. In addition to that, only one dedicated slot in each frame is used to ensure global synchronisation and handle acknowledgements. Our experimental results with 25 nodes show that TS-LoRa can achieve more than 99\% packet delivery ratio even for the most distant nodes. Moreover, our simulations with a higher number of nodes revealed that TS-LoRa exhibits a lower energy consumption than the confirmable version of LoRaWAN while not compromising the packet delivery ratio.},
  archive      = {J_COMCOM},
  author       = {Dimitrios Zorbas and Khaled Abdelfadeel and Panayiotis Kotzanikolaou and Dirk Pesch},
  doi          = {10.1016/j.comcom.2020.01.056},
  journal      = {Computer Communications},
  pages        = {1-10},
  shortjournal = {Comput. Commun.},
  title        = {TS-LoRa: Time-slotted LoRaWAN for the industrial internet of things},
  volume       = {153},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel mission planning method for UAVs’ course of action.
<em>COMCOM</em>, <em>152</em>, 345–356. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Military course of action for unmanned aerial vehicles (UAVs) has the characteristics with antagonism of both sides, uncertainty of execution results, diversity of war ways and urgency of war time. According to this, a novel mission planning method for UAVs’ course of action is proposed in this paper, which is based on a two-segment nested scheme generation strategy. The method is mainly divided into two parts: task decomposition stage and resource scheduling stage. Compared with other methods, this method can generate multiple schemes automatically of the whole operational process, and the generated schemes have great advantages in diversity and task completion time . And the correlation coefficient can be adjusted to realize the tendency of different optimization indexes. The effectiveness of this method is verified by the modelling and simulation of UAV cooperative operation.},
  archive      = {J_COMCOM},
  author       = {Yaoming Zhou and Haoran Zhao and Junfeng Chen and Yuhong Jia},
  doi          = {10.1016/j.comcom.2020.01.006},
  journal      = {Computer Communications},
  pages        = {345-356},
  shortjournal = {Comput. Commun.},
  title        = {A novel mission planning method for UAVs’ course of action},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PMAKE: Privacy-aware multi-factor authenticated key
establishment scheme for advance metering infrastructure in smart grid.
<em>COMCOM</em>, <em>152</em>, 338–344. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced Metering Infrastructure (AMI) ensures bidirectional communication for analysis and improvement of energy usage between service providers and customers. Establishing secure and efficient key exchange has become an important issue for the Internet-based smart grid environment . To ensure a secure, reliable and efficient operation in the smart grid environment , AMI should be protected from security attacks. On the other hand, since smart meters are installed in customer’s homes and businesses without hardware protection mechanisms that could be susceptible to physical attacks, where a dishonest customer may attempt to temper the metering data in order to make differences in billing. In this paper, an efficient privacy-aware multi-factor authenticated key establishment scheme (PMAKE) is proposed. One of the notable properties of the proposed scheme is that it can ensure physical security of the smart meters. From the performance analyses, we can claim that our scheme is secure and suitable for the resource limited smart meters.},
  archive      = {J_COMCOM},
  author       = {Prosanta Gope},
  doi          = {10.1016/j.comcom.2019.12.042},
  journal      = {Computer Communications},
  pages        = {338-344},
  shortjournal = {Comput. Commun.},
  title        = {PMAKE: Privacy-aware multi-factor authenticated key establishment scheme for advance metering infrastructure in smart grid},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Software defined network based self-diagnosing faulty node
detection scheme for surveillance applications. <em>COMCOM</em>,
<em>152</em>, 333–337. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAV) can be used as basic elements of the sensor network or an upgrade of existing network that are built with static wireless sensor nodes . Wireless Networks (WN) are utilized across in surveillance in all domains, like natural disasters, agriculture, water, forest, military, buildings, health monitoring, disaster relief &amp; emergency management, area and industrial surveillance, due to its wider applicability. Though the performance of WN is satisfactory, it still suffers from several challenges such as energy efficiency, reliability and security. This work attempts to render reliability to the wireless network as sensor physical node in network by detecting the faulty sensor nodes . The faulty sensor nodes degrade the performance of the complete sensor network and hence, it is necessary to detect the faulty sensor nodes to attain better Quality of Service (QoS) with software defined in network. The proposed method detects the faulty sensor nodes using software defined network approach by means of Reward-and-Punishment Model (RPM) and the hypothetical analysis of Dempster–Shafer (DS) theory protocol approach. The performance of the proposed approach is observed to be satisfactory in terms of Quality of Service parameters of faulty node detection accuracy, energy consumption and network lifetime.},
  archive      = {J_COMCOM},
  author       = {R. Palanikumar and K. Ramasamy},
  doi          = {10.1016/j.comcom.2019.12.034},
  journal      = {Computer Communications},
  pages        = {333-337},
  shortjournal = {Comput. Commun.},
  title        = {Software defined network based self-diagnosing faulty node detection scheme for surveillance applications},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Smart city as a distributed platform: Toward a system for
citizen-oriented management. <em>COMCOM</em>, <em>152</em>, 323–332. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s society must prioritize the design and development of platforms for Big Data processing . Smart cities generate large volumes of valuable data which the government can use to manage cities more intelligently. Aware of the value of data, many researchers have proposed architectures for optimized data collection and use. This paper proposes a novel approach that enables smart cities to reuse the functionalities of old applications by adapting them to new architectures. To be able to process large amounts of data and solve a variety of problems, smart city platforms need extra computing power. Two case studies have been conducted to verify the performance of the proposed platform. Those case studies have demonstrated that the development process of a smart platform can be simplified by implementing functionalities and components taken from earlier platforms.},
  archive      = {J_COMCOM},
  author       = {Pablo Chamoso and Alfonso González-Briones and Fernando De La Prieta and Ganesh Kumar Venyagamoorthy and Juan M. Corchado},
  doi          = {10.1016/j.comcom.2020.01.059},
  journal      = {Computer Communications},
  pages        = {323-332},
  shortjournal = {Comput. Commun.},
  title        = {Smart city as a distributed platform: Toward a system for citizen-oriented management},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Protection on wireless sensor network from clone attack
using the SDN-enabled hybrid clone node detection mechanisms.
<em>COMCOM</em>, <em>152</em>, 316–322. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WSN is an infrastructure less network that consists of mobile nodes that communicate with each other over wireless links . WSN is vulnerable to the node replication attack (clone attack). Attackers through compromising one sensor node replicate many clones having the same identity (ID) from the compromised node, and place these clones in various places of network. Clones contain all the credentials of legitimate member so appears authentic. This makes the conventional cryptographic tools useless and clone detection difficult. Once the node replication attack has been successful it can help the attacker to exploit almost all of the network operations, like routing, data collection, and key distribution, and also to help launch various other attacks such as black hole, wormhole etc. This proposed work therefore attempts a SDN based mechanism that implements a network level route analysis and time-based analysis methods which involves a low cost timely monitoring of the environment to identify and avoid redundant nodes which may be caused due to cloning attack. Thus, the SDN based cyber security applications are most useful in this situation. The implementation of this SDN based mechanism in WSN helps in maintaining and improving the QoS (Quality of service) constraints. The hybrid clone node detection (HCND) mechanism helps to detect the clone node present in the wireless network. This is to perform efficient clone detection in such a way to eliminate cloning attack in proactive fashion. To detect clones locally as well as across geographical region through cost effective identity verification procedure. This method helps to protect the wireless sensor network from the node identity replicas using the superimposed SDIS junction code. The node identity replicas help to choose the credible path for successful transmissions. The superimposed method is to be used for retrieval of information from node participating on the network. To thwart cluster of attacks hosted from the clones, by removing the hosting clones. The simulation result shows that there is the performance analysis of various parameters such as false positive , false negative ratio analysis, precision analysis, recall analysis and detection analysis.},
  archive      = {J_COMCOM},
  author       = {P.P. Devi and B. Jaison},
  doi          = {10.1016/j.comcom.2020.01.064},
  journal      = {Computer Communications},
  pages        = {316-322},
  shortjournal = {Comput. Commun.},
  title        = {Protection on wireless sensor network from clone attack using the SDN-enabled hybrid clone node detection mechanisms},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive service function chaining mappings in 5G using deep
q-learning. <em>COMCOM</em>, <em>152</em>, 305–315. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With introduction of Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies, mobile network operators are able to provide on-demand Service Function Chaining (SFC) to meet various needs from users. However, it is challenging to map multiple SFCs to substrate networks efficiently, particularly in a number of key scenarios of forthcoming 5G , where user requests have different priorities and various resource demands. To this end, we first formulate the mapping of multiple SFCs with priorities as a multi-step Linear Integer Programming (ILP) problem, of which the mapping strategy (i.e., the objective function) in each step is configurable to improve overall CPU and bandwidth resource utilization rates. Secondly, to solve the strategy selection problem in each step and alleviate the complexity of ILP, we propose an adaptive deep Q-learning based SFC mapping approach (ADAP), where an agent is learned to make decisions from two low-complexity heuristic SFC mapping algorithms . Finally, we conduct extensive simulations using multiple SFC requests with randomly generated CPU and bandwidth demands in a real-world substrate network topology. Related results demonstrate that compared with a single strategy or random selections of strategies under the ILP-based approach or the proposed heuristic algorithms , our ADAP approach can improve whole-system resource efficiency by scheduling this two simply designed heuristic algorithms properly after limited training episodes.},
  archive      = {J_COMCOM},
  author       = {Guanglei Li and Bohao Feng and Huachun Zhou and Yuming Zhang and Keshav Sood and Shui Yu},
  doi          = {10.1016/j.comcom.2020.01.035},
  journal      = {Computer Communications},
  pages        = {305-315},
  shortjournal = {Comput. Commun.},
  title        = {Adaptive service function chaining mappings in 5G using deep Q-learning},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LSTM-based ACB scheme for machine type communications in
LTE-a networks. <em>COMCOM</em>, <em>152</em>, 296–304. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access Class Barring (ACB) scheme has been proposed to control the number of machine-to-machine (M2M) devices accessing Long Term Evolution-Advanced (LTE-A) networks. In the ACB scheme, dynamically adjusting barring factor is crucial for massive M2M communications because inappropriate barring factor may degrade the performance of LTE-A networks. Many studies have proposed to adjust the barring factor dynamically by estimating the number of retransmissions or using reinforcement learning (RL) approach. However, because base stations know nothing about the traffic load in the next period of broadcasting barring factor, the barring factor broadcasted by the base stations may not fit the upcoming traffic load. In this study, we proposed a long short term memory (LSTM)-based ACB scheme to predict the traffic load before adjusting barring factor. A LSTM network continuously detected the traffic conditions, and it predicted the upcoming traffic load to adjust the barring factor. With the proposed scheme, we achieved a high access success rate and did not significantly increase access delay and the number of access attempts. We compared our approach to a dynamic ACB scheme and an RL-based ACB scheme in terms of access success rate, average number of access attempts, and average access delay. The simulation results revealed that the access success rate of the proposed approach was above 99\%. The average number of access attempts decreased by about 6\% as compared to the dynamic ACB scheme, and the average access delay of M2M devices dropped by about 68\% as compared to the RL-based ACB scheme.},
  archive      = {J_COMCOM},
  author       = {Chu-Heng Lee and Shang-Juh Kao and Fu-Min Chang},
  doi          = {10.1016/j.comcom.2020.01.047},
  journal      = {Computer Communications},
  pages        = {296-304},
  shortjournal = {Comput. Commun.},
  title        = {LSTM-based ACB scheme for machine type communications in LTE-A networks},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Multi-node topology location model of smart city based on
internet of things. <em>COMCOM</em>, <em>152</em>, 282–295. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart City is a new model and new form of urban development based on the Internet of Things , the advanced information technology, intelligent technology and multi-network integration. In most cases, wireless sensor networks need to be monitored in complex environments or in areas that humans cannot reach. Most of the nodes will adopt aircraft throwing and other methods, resulting in uncontrollable node positions. Such research cannot be carried out without knowing the specific source of the information. Therefore, the problem of node location in wireless sensor networks has become one of the key issues that must be solved. In this paper, a wireless sensor network topology based on correlation neighbor graph is constructed. The DV-Hop (Distance Vector-Hop) localization algorithm with hop number correction and average hop weighting is proposed. The signal strength value received by the node is converted into the distance between the nodes by the shadowing model; and the ratio of the distance value to the communication radius between the nodes is used to correct the hop value. In order to further improve the positioning performance of the algorithm, the MDV-Hop (Modified Distance Vector-Hop) algorithm is proposed. The MDV-Hop algorithm mainly improves the error caused by the number of hops between anchor nodes , the average hop distance and the network topology in the DV-Hop algorithm. Aiming at the problems of the maximum likelihood coordinate calculation method, the localization problem of nodes is transformed into the minimum problem of solving nonlinear equations , and the improved Bat algorithm is used to replace the maximum likelihood algorithm to obtain the coordinates of unknown nodes. The simulation shows that the unknown node has achieved better positioning results in the IoT positioning model based on wireless sensor network topology and has higher positioning accuracy.},
  archive      = {J_COMCOM},
  author       = {Xianming Huang},
  doi          = {10.1016/j.comcom.2020.01.052},
  journal      = {Computer Communications},
  pages        = {282-295},
  shortjournal = {Comput. Commun.},
  title        = {Multi-node topology location model of smart city based on internet of things},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using cognition to resolve duplicacy issues in socially
connected healthcare for smart cities. <em>COMCOM</em>, <em>152</em>,
272–281. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social web has transformed healthcare communication as patients reach out to seek support and advice by connecting with other patients, caregivers and healthcare professionals. The influx of health-related queries and the volume of answers within the medical forums is a testimony to this adaption. The scalability, natural interaction and dynamism of the continuously collected and connected user-generated social big data can support health assessment, intervention and provisioning to produce the best kind of cognitive smart city. On the flip side the use of social media for healthcare communication suffers from data deluge, lack of reliability and quality, confidentiality and privacy (location/personal) issues. Duplicate questions, that is, queries with similar semantics (meaning) corrupt the filtering mechanism, increase the response time and compromise with the quality of the answer too. This research puts forward solutions to resolve the key challenge of duplicacy within the medical community Question-Answering sites (Medical CQAs). We propose to solve the semantic question matching problem for duplicate question pair detection, using a hybrid deep learning model, which combines a Co-attention based Bi-Directional Long Short-Term Memory (Bi-LSTM) Siamese neural network and a Multi-layer perceptron classifier to output the probability of a similarity match between the two questions. Euclidean distance function is then used to compute the similarity between questions. The proposed model is validated on 100 question pairs which are scrapped from three featured groups, namely, ‘Irritable Bowel Syndrome’, ‘Anxiety Disorder’ and ‘Menopause’ of Patient.info community forum and an accuracy of 86.375\% is observed. The results obtained are comparable to that of the Quora’s state-of-the-art results for duplicate detection .},
  archive      = {J_COMCOM},
  author       = {Akshi Kumar},
  doi          = {10.1016/j.comcom.2020.01.041},
  journal      = {Computer Communications},
  pages        = {272-281},
  shortjournal = {Comput. Commun.},
  title        = {Using cognition to resolve duplicacy issues in socially connected healthcare for smart cities},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved energy efficient design in software defined
wireless electroencephalography sensor networks (WESN) using distributed
architecture to remove artifact. <em>COMCOM</em>, <em>152</em>, 266–271.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networking (SDN) has focused enormous attractiveness in changing conventional network by means of offering flexible and dynamic network management. It has drawn important concentration of the researchers from together academia and industries. Mainly, integrating SDN in Wireless Body Area Network (WBAN) applications specifies capable results in terms of handling with the issues like traffic management, security, energy efficiency etc. Recent improvements in miniaturization and energy efficient physiological sensor designs in SDN based Wireless Body Area Networks (WBANs) paved the way for health monitoring systems for collection and processing the real-time physiological data . The collection of signals from different sensor allows reliable diagnosis in heterogeneous than in homogeneous WBANs. Inspired by the evolutions of heterogeneous WBANs, a study on Wireless Electroencephalography Sensor Networks (WESNs) is carried out under distributed signal processing. The distributed WESNs are designed under two different hierarchy i.e. Hierarchical Fully-Connected Topology (HFCT) and Ad-Hoc Nearest-Neighbor Topology (ANNT) to improve the energy-efficiency using distributed Multi-channel Weighted Weiner Filter design (MW2F). Here, each module transmits linear combination of local channels with other modules. The power efficiency is improved in MW2F signal processing algorithm by avoiding centralization of EEG data. A case study is carried out to test the reduced energy consumption after the removal of eye blink artifacts and it is tested with centralized counterparts. The MW2F is evaluated in both topologies against centralized environments and significant reduction of eye blink artifacts improves the energy efficiency in HFCT than other topologies.},
  archive      = {J_COMCOM},
  author       = {M. Manojprabu and V.R. Sarma Dhulipala},
  doi          = {10.1016/j.comcom.2019.12.056},
  journal      = {Computer Communications},
  pages        = {266-271},
  shortjournal = {Comput. Commun.},
  title        = {Improved energy efficient design in software defined wireless electroencephalography sensor networks (WESN) using distributed architecture to remove artifact},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed robust time-efficient broadcasting algorithms
for multi-channel wireless multi-hop networks with channel disruption.
<em>COMCOM</em>, <em>152</em>, 252–265. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broadcasting is a fundamental problem for wireless multi-hop networks such as wireless ad hoc and sensor networks. In this paper, we study distributed robust time-efficient global broadcasting for SINR-based (i.e., Signal-to-Interference-plus-Noise-Ratio-based) multi-channel wireless multihop networks subject to channel disruption. In this study, we make the following assumptions: i) for successful packet reception , the SINR at receivers must exceed a certain threshold; ii) an adversary exists in the network, which uniformly and randomly chooses t &gt; 0 channels to disrupt from total F F &gt; 1 available channels in every round. To address the broadcasting issue in such networks, we first propose a degree-aware broadcasting algorithm and then propose a degree-independent broadcasting algorithm. The proposed algorithms elaborately integrate distributed channel selection and transmission scheduling at different nodes while considering the following factors: the impact of SINR constraint, availability of channels, sending probability on selected channel, presence of adversary, with and without node degree information. We present the detailed design of the two algorithms. We deduce their worst-case time performance to accomplish the task of global broadcasting with high probability. We further prove that both algorithms can still preserve the same time performance under more powerful oblivious adversary and weakly adaptive adversary. Simulation results show that the proposed algorithms have satisfactory average-case time performance.},
  archive      = {J_COMCOM},
  author       = {Xiang Tian and Baoxian Zhang and Hussein Mouftah},
  doi          = {10.1016/j.comcom.2020.01.048},
  journal      = {Computer Communications},
  pages        = {252-265},
  shortjournal = {Comput. Commun.},
  title        = {Distributed robust time-efficient broadcasting algorithms for multi-channel wireless multi-hop networks with channel disruption},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decentralized authorization in constrained IoT environments
exploiting interledger mechanisms. <em>COMCOM</em>, <em>152</em>,
243–251. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present models that utilize smart contracts and interledger mechanisms to provide decentralized authorization for constrained IoT devices. The models involve different tradeoffs in terms of cost, delay, complexity, and privacy, while exploiting key advantages of smart contracts and multiple blockchains that communicate with interledger mechanisms. These include immutably recording hashes of authorization information and policies in smart contracts, resilience through the execution of smart contract code on all blockchain nodes, and cryptographically linking transactions and IoT events recorded on different blockchains using hash-lock and time-lock mechanisms. In the case of two ledgers, an authorization and a payment ledger, the authorization ledger can be a private Ethereum network or a permissioned ledger such as Hyperledger Fabric. For decentralized authorization where a subset of m-out-of-n authorization servers are required, we present two policies for selecting the m m servers. The first policy can utilize statistics of the authorization servers such as transaction cost and response time. The second policy selects the first m m servers that respond. The proposed models are evaluated on the public Ethereum testnets Rinkeby and Ropsten, and for different implementations on the Hyperledger Fabric permissioned ledger, in terms of execution cost (gas), delay, and reduction of data that needs to be sent to the constrained IoT devices.},
  archive      = {J_COMCOM},
  author       = {Vasilios A. Siris and Dimitrios Dimopoulos and Nikos Fotiou and Spyros Voulgaris and George C. Polyzos},
  doi          = {10.1016/j.comcom.2020.01.030},
  journal      = {Computer Communications},
  pages        = {243-251},
  shortjournal = {Comput. Commun.},
  title        = {Decentralized authorization in constrained IoT environments exploiting interledger mechanisms},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A streaming approach to reveal crowded events from cellular
data. <em>COMCOM</em>, <em>152</em>, 232–242. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection has been a very popular research topics over the last few years and applies to many scenarios from different disciplines. This research focuses on crowded phenomena, and addresses the detection of popular events by looking for “anomalous” patterns in cellular traffic data. In particular, the paper elaborates upon previous proposals and presents two streaming algorithms based on the wavelet decomposition of traffic data. The new algorithms consume traffic samples as soon as they are available, elaborate the data in real time and possibly raise alarms upon threshold crossing. The effectiveness of the approach is assessed by using the public dataset containing the real cellular data acquired over the network of the most popular Italian traffic operator. The experiments prove that the streaming algorithms generally achieve performance comparable to that of their offline counterparts, and that the small degradation that may occasionally be observed is however well counterbalanced by the obvious advantage of detecting anomalies in real-time with no need to wait for the elaboration of overly long traffic timeseries.},
  archive      = {J_COMCOM},
  author       = {Rosario G. Garroppo and Gregorio Procissi},
  doi          = {10.1016/j.comcom.2020.01.036},
  journal      = {Computer Communications},
  pages        = {232-242},
  shortjournal = {Comput. Commun.},
  title        = {A streaming approach to reveal crowded events from cellular data},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy analysis of internet of things data mining algorithm
for smart green communication networks. <em>COMCOM</em>, <em>152</em>,
223–231. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of Internet technology and electronic information technology, big data technology and cloud computing technology also rise and develop, and have a positive impact on people’s lives. Data mining system can deeply mine the value information contained in big data, so as to assist users to solve practical problems and help users to make correct decisions and judgments. This paper presents an energy analysis of data mining algorithm based on cloud platform for Internet of things (IoT). First of all, an improved Apriori algorithm is proposed, which is based on Boolean matrix and sorting index rules. Then Boolean matrix is obtained after scanning the data set and the Boolean matrix is preprocessed to delete the useless transactions and the item set, which are combined with sorting index to produce other item sets, effectively improving the efficiency of frequent item mining, which effectively reduce the memory usage. Secondly, the density-based spatial clustering of applications with noise (DBSCAN) clustering algorithm needs human intervention in the global parameter selection, and the process of regional query is complex and the query is easy to lose objects. An improved parameter adaptive and regional query density clustering algorithm is proposed, which can effectively delete the redundant data in the high-level complex data space on the premise of retaining the internal nonlinear structure of the IoT data. The efficiency of clustering is also improved accordingly Finally, the simulation based on cloud platform verifies the effectiveness and superiority of the algorithm.},
  archive      = {J_COMCOM},
  author       = {Ziping Du},
  doi          = {10.1016/j.comcom.2020.01.046},
  journal      = {Computer Communications},
  pages        = {223-231},
  shortjournal = {Comput. Commun.},
  title        = {Energy analysis of internet of things data mining algorithm for smart green communication networks},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based intelligent face recognition in
IoT-cloud environment. <em>COMCOM</em>, <em>152</em>, 215–222. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Internet-of-Things (IoT) technology is being used in many application areas such as healthcare, video surveillance, transportation etc. The massive adoption and growth of IoT in these areas are generating a massive amount of data. For example, IoT devices such as cameras are generating a huge amount of images when used in hospital surveillance scenarios. Here, face recognition is an important element that can be used for securing hospital facilities, emotion detection and sentiment analysis of patients, detecting patient fraud, and hospital traffic pattern analysis. Automatic and intelligent face recognition systems have high accuracy in a controlled environment; however, they have low accuracy in an uncontrolled environment. Also, the systems need to operate in real-time in many applications such as smart healthcare. This paper suggests a tree-based deep model for automatic face recognition in a cloud environment. The proposed deep model is computationally less expensive without compromising the accuracy. In the model, an input volume is split into several volumes, where a tree is constructed for each volume. A tree is defined by its branching factor and height. Each branch is represented by a residual function, which is constituted by a convolutional layer , a batch normalization , and a non-linear function. The proposed model is evaluated in various publicly available databases. A comparison of performance is also done with state-of-the-art deep models for face recognition. The results of the experiments demonstrate that the proposed model achieved accuracies of 98.65\%, 99.19\%, 95.84\% on FEI, ORL , and LFW databases, respectively.},
  archive      = {J_COMCOM},
  author       = {Mehedi Masud and Ghulam Muhammad and Hesham Alhumyani and Sultan S Alshamrani and Omar Cheikhrouhou and Saleh Ibrahim and M. Shamim Hossain},
  doi          = {10.1016/j.comcom.2020.01.050},
  journal      = {Computer Communications},
  pages        = {215-222},
  shortjournal = {Comput. Commun.},
  title        = {Deep learning-based intelligent face recognition in IoT-cloud environment},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security monitoring of heterogeneous networks for big data
based on distributed association algorithm. <em>COMCOM</em>,
<em>152</em>, 206–214. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous development of heterogeneous networks , the structure and scale of the network are becoming more and more complex, and the difficulty of processing network alarm information is also increasing. Therefore, an efficient and flexible alarm handling scheme will become especially important in the alarm management of heterogeneous networks . In the aspect of alarm analysis of heterogeneous networks, this paper proposes a corresponding distributed alarm analysis model and corresponding distributed association analysis algorithm. Combined with the structural characteristics of heterogeneous networks, the proposed distributed analysis model has many potential advantages. One of them is the significant reduction in the candidate set in the alarm database, which can greatly help us improve the efficiency of alarm correlation analysis in heterogeneous networks, thereby further reducing the time required for our alarm correlation analysis. In many respects, such improvement provides good technical support for the management of alarm information in heterogeneous networks. Finally, the simulation verification of the corresponding algorithm is given. The results show that under different support thresholds, the distributed association analysis algorithm has shorter running time.},
  archive      = {J_COMCOM},
  author       = {Wei Hu and Jing Li and Jie Cheng and Han Guo and Hui Xie},
  doi          = {10.1016/j.comcom.2020.01.045},
  journal      = {Computer Communications},
  pages        = {206-214},
  shortjournal = {Comput. Commun.},
  title        = {Security monitoring of heterogeneous networks for big data based on distributed association algorithm},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The enhancement of catenary image with low visibility based
on multi-feature fusion network in railway industry. <em>COMCOM</em>,
<em>152</em>, 200–205. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Industrial Internet of Things (IIoT), the security and efficiency are indispensable. For the railway industry , the video from inspection vehicle would be influenced by various factors with low visibility and hard for high level vision task, such as the fault diagnosis of catenary system. In this paper, we propose a method based on the multi-feature fusion network to improve the quality and visual effect of the catenary images. The transmission map is learned from the multi-scale and multi-feature fusion network, which would learn coarse and fine details and combine the latent features. In the catenary image, the sky and non-sky regions are segmented through multiple accommodative thresholds to estimate the atmospheric light value. With the refinement of transmission map, the restored catenary image is obtained through the atmospheric scattering model. In the experimental results, it can be seen that the proposed method can improve the clarity of catenary image in haze. The quantitative evaluation shows that it has better visual effect compared with the other traditional methods.},
  archive      = {J_COMCOM},
  author       = {Yuwen Chen and Bin Song and Xiaojiang Du and Nadra Guizani},
  doi          = {10.1016/j.comcom.2020.01.040},
  journal      = {Computer Communications},
  pages        = {200-205},
  shortjournal = {Comput. Commun.},
  title        = {The enhancement of catenary image with low visibility based on multi-feature fusion network in railway industry},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fog assisted task allocation and secure deduplication using
2FBO2 and MoWo in cluster-based industrial IoT (IIoT). <em>COMCOM</em>,
<em>152</em>, 187–199. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog-assisted Internet-of-Things have dynamically received interest in the research community. There are more duplicate data transmitted over the Internet due to the rise in IoT devices. In this paper, task allocation and secure deduplication are implemented over four layers of Fog assisted Cluster-based Industrial IoT. IoT device layer used to sense data and mitigate security threats. Devices presented in this layer are registered to the cloud server using Elliptic Curve Cryptography based Hybrid Multiplier. Multi-Objective based Whale Optimization algorithm is accessible for cluster section. SHA-3 is presented in the fog layer for secure data deduplication . ECC HM private key is used for data encryption before transmitted the data. In cloud, layer indexing is constructed using Merkle Hash Tree . This is endeavored to provide query search results for IoT users at the service layer. The simulation results prove enhancement in average latency , user satisfaction, network lifetime, energy consumption, and security strength.},
  archive      = {J_COMCOM},
  author       = {Shivi Sharma and Hemraj Saini},
  doi          = {10.1016/j.comcom.2020.01.042},
  journal      = {Computer Communications},
  pages        = {187-199},
  shortjournal = {Comput. Commun.},
  title        = {Fog assisted task allocation and secure deduplication using 2FBO2 and MoWo in cluster-based industrial IoT (IIoT)},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient scheduling and resource allocation in 802.11ax
multi-user transmissions. <em>COMCOM</em>, <em>152</em>, 171–186. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {802.11ax introduces OFDMA to WiFi. It thus enables multiplexing users/user groups in the frequency domain. WiFi networks usually operate in a multipath environment which generates a frequency selective channel . Hence, the capacity of a user/user group changes over different subcarriers . A good scheduling and resource allocation scheme can maximize user rates by allocating users and user groups on subcarriers based on their CSI and other system considerations. In this paper, we investigate how to optimally assign users and user groups to subcarriers with the goal of maximizing the throughput in the context of 802.11ax. We introduce a novel divide and conquer based algorithm which we prove to be optimal under the assumption that a user can be assigned to more than one resource unit. We also introduce two practical algorithms, a greedy and a recursive one, which split the bandwidth into resource units and schedule users on them while observing all 802.11ax protocol constraints. Extensive simulations and experiments comparing the performance of the aforementioned algorithms establish that our practical schemes achieve very good performance in all studied scenarios while handling a plethora of real-world constraints.},
  archive      = {J_COMCOM},
  author       = {Kaidong Wang and Konstantinos Psounis},
  doi          = {10.1016/j.comcom.2020.01.010},
  journal      = {Computer Communications},
  pages        = {171-186},
  shortjournal = {Comput. Commun.},
  title        = {Efficient scheduling and resource allocation in 802.11ax multi-user transmissions},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatiotemporal charging scheduling in wireless rechargeable
sensor networks. <em>COMCOM</em>, <em>152</em>, 155–170. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks have a wide range of applications. However, the battery-constrained energy limits the scope of network applications and timeliness. In this paper, we study how to schedule charging and allocate charging time simultaneously for a wireless sensor network for the purpose of prolonging network lifetime and improve charging efficiency. To this end, a mixed integer optimization model for simultaneous charging scheduling and charging time allocation is established through the maximization of the charging efficiency. Then, an offline algorithm is developed to solve the problem. Further, an online charging node insertion algorithm is developed for real-time service. The simulation results show that the proposed algorithm can achieve near 100\% charging success rate under periodic and hybrid services, which is significantly superior to the results obtained by the compared algorithms.},
  archive      = {J_COMCOM},
  author       = {Chuanxin Zhao and Hengjing Zhang and Fulong Chen and Siguang Chen and Changzhi Wu and Taochun Wang},
  doi          = {10.1016/j.comcom.2020.01.037},
  journal      = {Computer Communications},
  pages        = {155-170},
  shortjournal = {Comput. Commun.},
  title        = {Spatiotemporal charging scheduling in wireless rechargeable sensor networks},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Active cross-query learning: A reliable labeling mechanism
via crowdsourcing for smart surveillance. <em>COMCOM</em>, <em>152</em>,
149–154. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is an effective way to collect plenty of labeled data. Rather than just relying on feedback from the crowd, active learning can intentionally request informative instances to be annotated in surveillance applications. Previous work that combines crowdsourcing with active learning focuses on the scenario with the expert being responsible for the most matching task in common communication surveillance. Compared with similar methods, we propose an innovative approach based on the active cross-query learning scheme, allowing each ordinary worker instead of domain experts to label part of the selected query samples, especially in the networks of smart surveillance . By using the balanced incomplete block design (BIBD), each labeling task is repeated several times to complete the cross-query learning. The generated consensus labels are iteratively added to the existing labeled datasets for training the classifier. Experiments conducted on three real-world datasets with our algorithms demonstrate that our method ensures model accuracy and label quality in terms of text classification compared with the several state-of-the art algorithms.},
  archive      = {J_COMCOM},
  author       = {Bohan Li and Anman Zhang and Weitong Chen and Hailian Yin and Ken Cai},
  doi          = {10.1016/j.comcom.2020.01.049},
  journal      = {Computer Communications},
  pages        = {149-154},
  shortjournal = {Comput. Commun.},
  title        = {Active cross-query learning: A reliable labeling mechanism via crowdsourcing for smart surveillance},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An aggregated statistical approach for network flood
detection using gamma-normal mixture modeling. <em>COMCOM</em>,
<em>152</em>, 137–148. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a fast statistical anomaly detector at the aggregated-level for two types of anomalies: floods and flash crowds. The performance of the statistical anomaly detectors is significantly dependent on the accuracy of statistical modeling. Thus, we initially introduce a new efficient statistical model for the network traffic called Gamma Normal mixture (GNM). We study the compatibility of GNM and network traffic using different tests. Consequently, we design a novel anomaly detector based on using the generalized likelihood ratio test (GLRT) and GNM. Moreover, to more accurately determine the position of the anomalies, overlapped sliding windows have been applied in the aggregation step. To evaluate the performance of the proposed anomaly detector, we use receiver operating characteristics (ROC). Experimental results under public network traces, confirm the high efficiency of the proposed method. Also, the comparison of the proposed anomaly detector with its nearest competitor verifies the higher performance and lower computational load in utilizing the new strategy.},
  archive      = {J_COMCOM},
  author       = {Sajjad Hosseinzadeh and Maryam Amirmazlaghani and Mehdi Shajari},
  doi          = {10.1016/j.comcom.2020.01.028},
  journal      = {Computer Communications},
  pages        = {137-148},
  shortjournal = {Comput. Commun.},
  title        = {An aggregated statistical approach for network flood detection using gamma-normal mixture modeling},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain moderated by empty blocks to reduce the energetic
impact of crypto-moneys. <em>COMCOM</em>, <em>152</em>, 126–136. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While cryptocurrencies and blockchain applications continue to gain popularity, their energy cost is evidently becoming unsustainable. In most instances, the main cost comes from the required amount of energy for the Proof-of-Work, and this cost is inherent to the design. In addition, useless costs from discarded work (e.g., the so-called Forks) and lack of scalability (in number of users and in rapid transactions) limit their practical effectiveness. In this paper, we present an innovative scheme which eliminates the nonce and thus the burden of the Proof-of-Work which is the main cause of the energy waste in cryptocurrencies such as Bitcoin . We prove that our scheme guarantees a tunable and bounded average number of simultaneous mining whatever the size of the population in competition, thus by making the use of nonce-based techniques unnecessary, achieves scalability without the cost of consuming a large volume of energy. The technique used in the proof of our scheme is based on the analogy of the analysis of a green leader election. The additional difference with Proof-of-Work schemes (beyond the suppression of the nonce field that is triggering most of the waste), is the introduction of (what we denote as) “empty blocks” which aim are to call regular blocks following a staircase set of values. Our scheme reduces the risk of Forks and provides tunable scalability for the number of users and the speed of block generation. We also prove using game theoretical analysis that our scheme is resilient to unfair competitive investments (e.g., ”51 percent” attack) and block nursing.},
  archive      = {J_COMCOM},
  author       = {Philippe Jacquet and Bernard Mans},
  doi          = {10.1016/j.comcom.2020.01.031},
  journal      = {Computer Communications},
  pages        = {126-136},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain moderated by empty blocks to reduce the energetic impact of crypto-moneys},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic clustering method based on power demand and
information volume for intelligent and green IoT. <em>COMCOM</em>,
<em>152</em>, 119–125. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is an integrated part of the future network which requires comprehensive awareness, reliable delivery and intelligent processing. Therefore, it faces the challenge of energy efficiency during real-time implementations based on respective applications . The work proposes an efficient and green dynamic clustering mechanism based on power demand and information volume. The machine learning approach is based on dynamic cluster formation by avoiding any information loss. Initially, among all the available Poisson distributed nodes, the master node divides them into two temporary clusters based on their power requirements. Then, the power requirements within these two clusters are equalized by a set threshold and based on application requirements, the dynamic clusters are formed by measuring the amount of information in each cluster. The simulation results presents that the proposed method equalizes the power demand of the network and maximizes the information in the cluster, which further improves the energy efficiency of the whole network. The results are also compared with traditional methods to justify the proposed work.},
  archive      = {J_COMCOM},
  author       = {Amrit Mukherjee and Pratik Goswami and Lixia Yang and Ziwei Yan and Mahmoud Daneshmand},
  doi          = {10.1016/j.comcom.2020.01.026},
  journal      = {Computer Communications},
  pages        = {119-125},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic clustering method based on power demand and information volume for intelligent and green IoT},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine learning based code dissemination by selection of
reliability mobile vehicles in 5G networks. <em>COMCOM</em>,
<em>152</em>, 109–118. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the evolving of 5G networks is foreseen as a major driver of future mobile vehicular social networks (VSNs), which can provide a novel method of code disseminations. Based on this concept, vehicles can be used as code disseminators. That is, infrastructures of a smart city can be upgraded by receiving updated program codes that are disseminated by vehicles in the VSNs. Specifically, vehicles in the 5G network are hard to be managed. Under this domain, safety of program codes is a key challenge. Meanwhile, improving coverage of program codes is also challenging. However, arranging plenty of vehicles as code disseminators will incur large costs of the ground control station (GCS). Therefore, by utilizing machine learning methods, this paper proposes a “Machine Learning based Code Dissemination by Selecting Reliability Mobile Vehicles in 5G Networks” (MLCD) scheme to choose vehicles with higher reliable degree and coverage ratio as code disseminators to deliver code with lower costs. Firstly, reliable degrees of vehicles are calculated and selected to improve safety degree of code disseminations. Secondly, vehicles with higher coverage ratio are preferred to promise code coverage. Thirdly, machine learning methods are utilized to select vehicles with both higher coverage ratios and reliable degrees as code disseminators with limited costs. Compared to random-selection and coverage-only scheme respectively, the MLCD scheme can improve safety degree of code dissemination process by 83.6\% and 18.86\% in 5G networks , and can improve coverage ratio of updated information by 23.16\%. Comprehensive performances of the proposed scheme can be improved by 80.56\% and 17.25\% respectively. Future works focus on improving code security in 5G networks by more advanced and suitable machine learning methods.},
  archive      = {J_COMCOM},
  author       = {Ting Li and Ming Zhao and Kelvin Kian Loong Wong},
  doi          = {10.1016/j.comcom.2020.01.034},
  journal      = {Computer Communications},
  pages        = {109-118},
  shortjournal = {Comput. Commun.},
  title        = {Machine learning based code dissemination by selection of reliability mobile vehicles in 5G networks},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EdgeDrone: QoS aware MQTT middleware for mobile edge
computing in opportunistic internet of drone things. <em>COMCOM</em>,
<em>152</em>, 93–108. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things is a crucial research empire in the current era which enables a wide diversity of applications. One of the emerging classes of technology in recent age dominate the universe of IoT is the concept of the Internet of Drones Thing (IoDT). The following work fundamentally emphasizes the key concepts of the Internet of Drones architecture in the context of the Edge computing perspective. A state of the art “EdgeDrone” concept has been engineered where the standard message transfer strategy of IoT and the opportunistic Ad-Hoc network have been amalgamated. Parameters like message transfer latency, overhead ratio, message delivery chances under several QoS values and resource usage, energy performance for the protocol have been analyzed. A hardware testbed has been implemented with the JavaScript platform along with the simulation which has been executed after tuning the performance of the protocols. The result shows 30\% improvement in average packet delivery for enhanced MQTT-SN and about 17\% improvement for enhanced MQTT in comparing to standard strategy. The study also reveals the minimum value of the message delivery latency of 15.5 msec for enhanced MQTT-SN in QoS-1. In memory usage point of view, the result shows that the MQTT broker takes a maximum of 5.6 MB of memory during enhanced MQTT-SN takes to publish–subscribe operation which is significantly less. Another two major parameters which report the maximum message transfer bandwidth of 620 msg/sec for enhanced MQTT-SN at QoS 1 and about 1800 msg/sec for QoS 0 as well as the enhanced MQTT-SN within 802.15.4 interface ensures minimum energy consumption amongst all other strategies},
  archive      = {J_COMCOM},
  author       = {Amartya Mukherjee and Nilanjan Dey and Debashis De},
  doi          = {10.1016/j.comcom.2020.01.039},
  journal      = {Computer Communications},
  pages        = {93-108},
  shortjournal = {Comput. Commun.},
  title        = {EdgeDrone: QoS aware MQTT middleware for mobile edge computing in opportunistic internet of drone things},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance evaluation of hybrid disaster recovery framework
with D2D communications. <em>COMCOM</em>, <em>152</em>, 81–92. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Public Safety Networks (PSNs) provide assistance before- and post-disaster events. With the help of technological advances, PSNs are able to cope with both natural and man-made disasters, protecting people, environment and property. Effective communications, better situational awareness, lower response times and greater emergency efficiency are essential to an effective response to emergencies and disasters. Long Term Evolution (LTE) has been chosen to be the key technology for public safety networks. In this study, a performance model is presented for the PSN frameworks which use cooperative devices with LTE device to device (D2D) communications features. Mobile stations that are out of cellular network coverage range use D2D communications, where mobile stations which are in a healthy area can act as relay nodes to provide information about the location of potential victims to a central system. Since relay nodes have the potential to become bottlenecks for relatively high scale disasters , the interaction between the relay node and the base station is critically considered in this study. The analytical model and solution are suitable for assessing the quality of service for PSNs with similar infrastructures. Results obtained from the analytical model are presented comparatively with those from discrete event simulations for validation. The maximum discrepancy between the results obtained from the analytical model and the simulation results is less than 1.4\%, which is within the confidence interval of the simulation.},
  archive      = {J_COMCOM},
  author       = {Enver Ever and Eser Gemikonakli and Huan X. Nguyen and Fadi Al-Turjman and Adnan Yazici},
  doi          = {10.1016/j.comcom.2020.01.021},
  journal      = {Computer Communications},
  pages        = {81-92},
  shortjournal = {Comput. Commun.},
  title        = {Performance evaluation of hybrid disaster recovery framework with D2D communications},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved DWT-SVD domain watermarking for medical
information security. <em>COMCOM</em>, <em>152</em>, 72–80. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exchange of patient record over network required a technique to guarantee security and privacy for tele-health services. This paper presents an improved watermarking technique capable of providing protection of patient data by embedding multi-watermarks in medical cover image using DWT-SVD domain. Prior to embedding, Hamming code is applied to text watermark in order to reduce channel noise distortion for the sensitive data. After embedding, the watermarked medical image is encrypted then compressed. Out of two encryption method and three compression scheme tested, combination of Chaotic-LZW shows the best performance. However, HyperChaotic-LZW combination is more robust against Gaussian, JPEG compression, speckle noise and histogram equalization attacks. We illustrate the good results in terms of objective and subjective evaluation, and verify its robustness for various attacks while maintaining imperceptibility , security and compression ratio. Experimental results demonstrate that the suggested technique archives high robustness against attacks in comparison to the other scheme for medical images.},
  archive      = {J_COMCOM},
  author       = {Ashima Anand and Amit Kumar Singh},
  doi          = {10.1016/j.comcom.2020.01.038},
  journal      = {Computer Communications},
  pages        = {72-80},
  shortjournal = {Comput. Commun.},
  title        = {An improved DWT-SVD domain watermarking for medical information security},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource allocation and admission control algorithm based on
non-cooperation game in wireless mesh networks. <em>COMCOM</em>,
<em>152</em>, 63–71. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With wireless mesh networks widely deployed in daily life, more and more researchers have begun to put their eyes on the problem of resource allocation and load balancing as well as networking security in wireless mesh networks. The admission control strategy takes great advantages in resource allocation and network load, thus having been widely applied in wireless networking. To maximize the benefits of game participants, it is essential to build an effective admission control model for user admission and resource allocation. Game theory, as an effective analytical modeling tool, is widely used in wireless networking researches. The access points determine whether to allow user’s access according to the admission control mechanism, for which this paper investigates resource allocation in wireless mesh networks. Our main works and contributions are as follows. Firstly, this paper analysis the importance of admission control in wireless mesh network, and addresses the problem of resource allocation and user admission control with game theory on the basis of existing researches. Secondly, this paper depicts the architecture and features of wireless mesh network as well as the functionality of admission control. Then, an admission control algorithm with the non-cooperative game theory for bandwidth and connections allocation in each network area is proposed based on the networking coverage, in which the Nash equilibrium existence is proved. This paper evaluates the proposed algorithm with blocking rate and system efficiency in the networks, which indicates that it is effective and efficient to allocate resource for each area dynamically.},
  archive      = {J_COMCOM},
  author       = {Fengjun Shang and Xinyan Niu and Dexiang He and Hanchao Gong and Xuelan Luo},
  doi          = {10.1016/j.comcom.2020.01.009},
  journal      = {Computer Communications},
  pages        = {63-71},
  shortjournal = {Comput. Commun.},
  title        = {Resource allocation and admission control algorithm based on non-cooperation game in wireless mesh networks},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint-learning segmentation in internet of drones
(IoD)-based monitor systems. <em>COMCOM</em>, <em>152</em>, 54–62. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object segmentation of monitor systems based on the Internet of drones plays an important role in the practical applications of wide-area smart-city intelligent monitoring systems. It is an important step for extracting objects from remote-sensing images, and provides a reliable theoretical basis for key property monitoring, environmental monitoring, disaster monitoring, and agricultural monitoring. To improve the accuracy of object segmentation and to solve the problem of inadequate edge recognition, a joint-learning segmentation scheme was designed that combines the conditional random field (CRF) model with an improved U-net model. It employs the improved U-net model as the front-end model of the joint-learning framework for feature fusion and the CRF model as the back-end of the joint-learning framework for transforming to gradient optimization-based recurrent neural networks . The joint-learning framework enables the front and back parts to interact with each other to obtain the location of the target and its classification information accurately. The joint-learning framework was realized on open datasets and compared with state-of-the-art remote-sensing image segmentation algorithms. The experiment results show that the accuracy of the ground object segmentation improved to 86.1\%, which is an encouraging improvement.},
  archive      = {J_COMCOM},
  author       = {Eric Ke Wang and Chien-Ming Chen and Fan Wang and Muhammad Khurram Khan and Saru Kumari},
  doi          = {10.1016/j.comcom.2020.01.027},
  journal      = {Computer Communications},
  pages        = {54-62},
  shortjournal = {Comput. Commun.},
  title        = {Joint-learning segmentation in internet of drones (IoD)-based monitor systems},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent resource dynamic allocation method for UAV
wireless mobile network which supports QoS. <em>COMCOM</em>,
<em>152</em>, 46–53. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of Unmanned Aerial Vehicle (UAV) business requires that the wireless mobile network can provide the highest possible data rate with limited wireless resources and harsh channel environment, while ensuring the requirements of different quality of service (QoS). The present algorithm only considers one or two spatial sub channels with the maximum eigenvalue, and does not consider how to satisfy multiple requirements with limited resources, nor does it consider the problem of admission control. In order to solve the above problems, this paper proposes an intelligent resource dynamic allocation method based on QoS. In this paper, resources are managed effectively through resource reservation mechanism and selective QoS adjustment mechanism. Then, all non-zero eigenvalue space sub channels are used for data transmission to maximize channel capacity under the condition that the total transmission power is limited and user QoS requirements are met. The simulation results show that the algorithm can effectively improve the throughput of the system by making full use of multi-user diversity on the basis of satisfying the QoS requirements of users.},
  archive      = {J_COMCOM},
  author       = {Chunqiong Wu and Bingwen Yan and Rongrui Yu and Zhangshu Huang and Baoqin Yu and Na Chen},
  doi          = {10.1016/j.comcom.2020.01.032},
  journal      = {Computer Communications},
  pages        = {46-53},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent resource dynamic allocation method for UAV wireless mobile network which supports QoS},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Survivable services oriented protection level-aware virtual
network embedding. <em>COMCOM</em>, <em>152</em>, 34–45. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network virtualization permits the creation of several logical networks (virtual networks) on one shared physical network referred as the substrate network . To protect a network against single substrate link failures, fast local reroute is preferred. With the reservation of backup resources, the flows are switched quickly from primary to backup paths upon substrate link failure to ensure service continuity. Due to the difficulty of primary and backup mappings, most of works in the literature separates the mapping of primary virtual network from the setting of backup paths. Although this approach optimizes primary resources, it can lead to inefficient protection since the existence of backup paths depends on the selected primary paths. In this paper, we propose a framework for protection-level-aware virtual network embedding which minimizes the risks of unrecoverable failures. With our propositions, the primary paths are selected among those which can be fully protected, if there is no such path, then we take the least vulnerable links in order to minimize the failure probability. For primary mapping, we propose a flexible on-line backup verification-based heuristic and a fast backup pre-verification-based heuristic. With the first heuristic, the backup path feasibility is verified on-line for each potential primary link, whereas we pre-compute for each substrate link the optimized set of backup tunnels all the backup paths in advance are deduced with the second heuristic. Simulations show that our propositions significantly reduce the substrate link failure impact on virtual networks, at the price of a slight decrease of the primary acceptance ratio.},
  archive      = {J_COMCOM},
  author       = {Shuopeng Li and Mohand Yazid Saidi and Ken Chen},
  doi          = {10.1016/j.comcom.2020.01.025},
  journal      = {Computer Communications},
  pages        = {34-45},
  shortjournal = {Comput. Commun.},
  title        = {Survivable services oriented protection level-aware virtual network embedding},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of efficient unmanned aerial vehicles to handle
medical emergency data transmission surveillance system by using
wireless body area network. <em>COMCOM</em>, <em>152</em>, 19–33. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Wireless Body Area Network (WBAN) gathers medical data from remote patients using wireless sensor nodes and transmits to the physician or server. The allocation of bandwidth to all network nodes demands the priority for communication because the high priority information presupposes people’s lives. The reduced propagation delay or nearly real-time transmission environment is necessary for top concern or chronic illness systems to transmit data from patients to the care worker comparing healthy patients. In indoor Wireless communication , particularly in hospitals, there is a risk of a significant packet error or failure during transmission. Based on the requirements of the studies, the dynamic cycle-based signal acquisition and bandwidth allocation technique created to reduce the emergency node propagation delay and enhance the signal quality of an emergency node. First, a patient’s priority-based data acquisition and sampling approach completed. Second, the calculation of duty cycle-based bandwidth requirements for non-emergency nodes made. Finally, a dynamic scheduling approach to the allocation of bandwidth using a regression method introduced. In this study, to regulate or handle a significant quantity of wireless node (1000 nodes, the abstract Software Defined Network (SDN) in the WBAN setting used. The controller monitors the network priority based on assigning the bandwidth to the particular nodes using the regression analysis technique.},
  archive      = {J_COMCOM},
  author       = {B. Manickavasagam and B. Amutha},
  doi          = {10.1016/j.comcom.2020.01.022},
  journal      = {Computer Communications},
  pages        = {19-33},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of efficient unmanned aerial vehicles to handle medical emergency data transmission surveillance system by using wireless body area network},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SPARR: Spintronics-based private aggregatable randomized
response for crowdsourced data collection and analysis. <em>COMCOM</em>,
<em>152</em>, 8–18. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of information and communication technologies has revolutionized people’s lives. A large amount of user behavioral data is generated by client software and is valuable for organizations ( e.g. , Apple, Google, and Samsung) to adjust their commercial strategies or to promote the quality of service. However, data collection raises privacy concerns. Either malicious or accidental leaking of sensitive information may cause serious consequences. Randomized response is a candidate solution, and it can provide “plausible deniability” for each individual. The aggregators can only collect sanitized data, but they can still conduct analyses and make predictions. Existing randomized response solutions can either apply pseudo-randomized functions with a predicable period of random numbers or have severely restricted functionality rather than providing practical privacy protection and efficient usability. We propose the spintronics-based private aggregatable randomized response (SPARR) for crowdsourced data collection while satisfying differential privacy . SPARR utilizes a spintronics-based true random number generator and multilayer randomized response to guarantee true data randomness and high data utility. Through multilayer randomized response and the corresponding subtle decoding algorithm, SPARR can obtain exceptionally high accuracy and efficiency in the frequency estimation of client strings even for small collections of applications, compared to state-of-the-art methods.},
  archive      = {J_COMCOM},
  author       = {Yao-Tung Tsou and Hao Zhen and Sy-Yen Kuo and Ching-Ray Chang and Akio Fukushima and Bor-Doou Rong},
  doi          = {10.1016/j.comcom.2020.01.001},
  journal      = {Computer Communications},
  pages        = {8-18},
  shortjournal = {Comput. Commun.},
  title        = {SPARR: Spintronics-based private aggregatable randomized response for crowdsourced data collection and analysis},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spectrum energy detection in cognitive radio networks based
on a novel adaptive threshold energy detection method. <em>COMCOM</em>,
<em>152</em>, 1–7. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive radio (CR) is a smart communication innovation in the development of the network. With advances in remote communications, the issue of bandwidth has proven to be more unique. The innovation of cognitive radio has turned as an approach to take care of this problem by enabling the unlicensed clients to utilize the authorized bands. A constrained available spectrum has been put in the way of impediments by the surpassing interest of remote presentations. To locate the unused spectrum in CR need one of the fundamental technique based on spectrum energy detection. The fundamental prerequisite for enabling CRs has been using the authorized spectrum for the auxiliary premise is not making impedance Primary Users (PU). Spectrum detection allows intelligent users to distinguish between unrecognized parts of the radio spectrum self-determination, and exempt the primary users from interrupting this way. Energy detection based spectrum detecting has been proposed for this work based on the Adaptive Threshold Spectrum Energy Detection (ATSED) strategy. By using ATSED the spectral detection performance can be significantly improved when the noise is uncertain and the primary user can reject the interference level. In this work, a framework model is developed based on spectrum energy detection using Matlab Simulink software. The simulation results demonstrate that the probability of detection is increased fundamentally when Signal to Noise Ratio (SNR) increases. It is likewise watched that the detection of probability decreases when the bandwidth factor increases.},
  archive      = {J_COMCOM},
  author       = {B. Sarala and S. Rukmani Devi and J. Joselin Jeya Sheela},
  doi          = {10.1016/j.comcom.2019.12.058},
  journal      = {Computer Communications},
  pages        = {1-7},
  shortjournal = {Comput. Commun.},
  title        = {Spectrum energy detection in cognitive radio networks based on a novel adaptive threshold energy detection method},
  volume       = {152},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prediction of thermal energy inside smart homes using IoT
and classifier ensemble techniques. <em>COMCOM</em>, <em>151</em>,
581–589. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Development of models based on the Internet of Things (IoT) for household framework leads to the establishment of smart appliances more and more for improving the living style and support of residents. Due to this reason, useful energy becomes an increase in demand for the past few decades that especially usages in smart homes and buildings as people of developing rapidly and enhancing their lifestyle based on modern technology. Various parameters like building characteristics, surrounding weather variables, and energy usage pattern are the reliable sources of buildings energy performance . In this paper, a predictive model is proposed by integrating the mechanisms of IoT and classifier ensemble techniques for forecasting the indoor temperature of the smart building. The online learning-methodology is used for training the predictive model for a successive performance over an unfamiliar dataset. Moreover, the recorded real-sensor data is applied in the experimental process, which is based on the classifier ensemble techniques for validating the model. Furthermore, the building works with an energy-efficient way by using the latest IoT architecture, which is based on Edge Computing . The simulation results compared with other existing approaches and models in which the proposed energy prediction techniques prove to be better.},
  archive      = {J_COMCOM},
  author       = {Hong Xu and Yuan He and Xiang Sun and Jia He and Qiongmei Xu},
  doi          = {10.1016/j.comcom.2019.12.020},
  journal      = {Computer Communications},
  pages        = {581-589},
  shortjournal = {Comput. Commun.},
  title        = {Prediction of thermal energy inside smart homes using IoT and classifier ensemble techniques},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy aware edge computing: A survey. <em>COMCOM</em>,
<em>151</em>, 556–580. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is an emerging paradigm for the increasing computing and networking demands from end devices to smart things. Edge computing allows the computation to be offloaded from the cloud data centers to the network edge and edge nodes for lower latency, security and privacy preservation . Although energy efficiency in cloud data centers has been broadly investigated, energy efficiency in edge computing is largely left uninvestigated due to the complicated interactions between edge devices, edge servers, and cloud data centers. In order to achieve energy efficiency in edge computing, a systematic review on energy efficiency of edge devices, edge servers, and cloud data centers is required. In this paper, we survey the state-of-the-art research work on energy-aware edge computing, and identify related research challenges and directions, including architecture, operating system, middleware, applications services, and computation offloading .},
  archive      = {J_COMCOM},
  author       = {Congfeng Jiang and Tiantian Fan and Honghao Gao and Weisong Shi and Liangkai Liu and Christophe Cérin and Jian Wan},
  doi          = {10.1016/j.comcom.2020.01.004},
  journal      = {Computer Communications},
  pages        = {556-580},
  shortjournal = {Comput. Commun.},
  title        = {Energy aware edge computing: A survey},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cloud assisted big data information retrieval system for
critical data supervision in disaster regions. <em>COMCOM</em>,
<em>151</em>, 548–555. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, the advancement of Cloud Assisted Big Data information retrieval system(CABDIRS) for heterogeneous data management plays a significant role in disaster management framework. In the recent past, facilitating disaster related activities such as Emergency information collection, sharing of exposed insights data about the region, and integration with local groups as well as global scale across various communities’ need assistance for precise and timely information retrieval framework concerning about disaster management. However, the available information retrieval system in the market has limited invariant integration model, whereas it provides improper sharing and collaboration capabilities in dynamic environment about the disaster areas. Hence, this research driving this exploration for powerful use of Cloud assisted big data system which uses Regression based information retrieval measurable computational model (RBIRMM) that offers to foresee the collection, sharing and integration of data in the disaster management regions. This paper features the integration of Cloud assisted IoT(CIoT)and Big data system for information retrieval system which assist the government in taking decisions during disaster conditions in an effective fasten manner. This paper feature the fundamental research that moves through experimental validation which has been conducted and reported with numerical data in a virtual environment. The RBIRMM achieves 98\% of accuracy when compared to other traditional methods.},
  archive      = {J_COMCOM},
  author       = {Chunmei Wang and Fang Qin and Dinesh Jackson Samuel R.},
  doi          = {10.1016/j.comcom.2019.11.028},
  journal      = {Computer Communications},
  pages        = {548-555},
  shortjournal = {Comput. Commun.},
  title        = {Cloud assisted big data information retrieval system for critical data supervision in disaster regions},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards DNA based data security in the cloud computing
environment. <em>COMCOM</em>, <em>151</em>, 539–547. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, data size is increasing day by day from gigabytes to terabytes or even petabytes, mainly because of the evolution of a large amount of real-time data. Most of the big data is transmitted through the internet and they are stored on the cloud computing environment . As cloud computing provides internet-based services, there are many attackers and malicious users. They always try to access user’s confidential big data without having the access right. Sometimes, they replace the original data by any fake data. Therefore, big data security has become a significant concern recently. Deoxyribonucleic Acid (DNA) computing is an advanced emerged field for improving data security, which is based on the biological concept of DNA. A novel DNA based data encryption scheme has been proposed in this paper for the cloud computing environment . Here, a 1024-bit secret key is generated based on DNA computing, user’s attributes and Media Access Control (MAC) address of the user, and decimal encoding rule, American Standard Code for Information Interchange (ASCII) value, DNA bases and complementary rule are used to generate the secret key that enables the system to protect against many security attacks. Experimental results, as well as theoretical analyses, show the efficiency and effectivity of the proposed scheme over some well-known existing schemes.},
  archive      = {J_COMCOM},
  author       = {Suyel Namasudra and Debashree Devi and Seifedine Kadry and Revathi Sundarasekar and A. Shanthini},
  doi          = {10.1016/j.comcom.2019.12.041},
  journal      = {Computer Communications},
  pages        = {539-547},
  shortjournal = {Comput. Commun.},
  title        = {Towards DNA based data security in the cloud computing environment},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain envisioned UAV networks: Challenges, solutions,
and comparisons. <em>COMCOM</em>, <em>151</em>, 518–538. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAV) or drones is a technology with a huge potential for proving different efficient solutions in the smart city. It has been mostly adopted by military, aviation, civil, and commercial sectors for audio and video surveillance. The communication and security challenges of UAV is well mentioned by researchers and organizations (defense) around the world, although many of the challenges remain unresolved (especially for sensitive and consumer-related applications). Moreover, the conventional network systems may not be very efficient in dealing with the dynamic requirements of UAVs. As the UAVs are generally deployed in tough environments and terrains, therefore it is quite essential to provide a strong and secure network. Motivated from these facts, this paper presents an extensive survey on security issues in 5G-enabled UAV networks as per the literature published till the fourth quarter of 2019. It also presents the taxonomy of existing security issues in 5G-enabled UAV networks. Based on the findings from the survey, we present a Blockchain (BC)-based security solution and a summary of research challenges in the integration of BC with 5G-enabled UAV. Then, we present a case study of implementing BC with UAVs to secure industrial applications.},
  archive      = {J_COMCOM},
  author       = {Parimal Mehta and Rajesh Gupta and Sudeep Tanwar},
  doi          = {10.1016/j.comcom.2020.01.023},
  journal      = {Computer Communications},
  pages        = {518-538},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain envisioned UAV networks: Challenges, solutions, and comparisons},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning and big data technologies for IoT security.
<em>COMCOM</em>, <em>151</em>, 495–517. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology has become inevitable in human life, especially the growth of Internet of Things (IoT), which enables communication and interaction with various devices. However, IoT has been proven to be vulnerable to security breaches . Therefore, it is necessary to develop fool proof solutions by creating new technologies or combining existing technologies to address the security issues. Deep learning , a branch of machine learning has shown promising results in previous studies for detection of security breaches . Additionally, IoT devices generate large volumes, variety, and veracity of data. Thus, when big data technologies are incorporated, higher performance and better data handling can be achieved. Hence, we have conducted a comprehensive survey on state-of-the-art deep learning, IoT security, and big data technologies . Further, a comparative analysis and the relationship among deep learning, IoT security, and big data technologies have also been discussed. Further, we have derived a thematic taxonomy from the comparative analysis of technical studies of the three aforementioned domains. Finally, we have identified and discussed the challenges in incorporating deep learning for IoT security using big data technologies and have provided directions to future researchers on the IoT security aspects.},
  archive      = {J_COMCOM},
  author       = {Mohamed Ahzam Amanullah and Riyaz Ahamed Ariyaluran Habeeb and Fariza Hanum Nasaruddin and Abdullah Gani and Ejaz Ahmed and Abdul Salam Mohamed Nainar and Nazihah Md Akim and Muhammad Imran},
  doi          = {10.1016/j.comcom.2020.01.016},
  journal      = {Computer Communications},
  pages        = {495-517},
  shortjournal = {Comput. Commun.},
  title        = {Deep learning and big data technologies for IoT security},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent resource allocation management for vehicles
network: An A3C learning approach. <em>COMCOM</em>, <em>151</em>,
485–494. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand of users for high-speed, low-delay and high-reliability services in connected vehicles network, wireless networks with communication, caching and computing convergence become the trend of network development in the future. To improve the quality of services of vehicles network, we propose a virtualized framework for mobile vehicle services, which using a learning-based resource allocation scheme . The dynamic change processes are modeled as Markov chains without making assumptions about the optimization goal and reducing the complexity of resource allocation computing . A high performance asynchronous advantage actor–critic learning algorithm is proposed to solve the complex dynamic resource allocation problem . Base on software-defined networking and information-centric networking, the method can dynamic orchestration of computing and communication resources to enhance the performance of virtual wireless networks. Simulation results verify that the proposed scheme can converge at a fast speed and improve the network operator’s total rewards.},
  archive      = {J_COMCOM},
  author       = {Miaojiang Chen and Tian Wang and Kaoru Ota and Mianxiong Dong and Ming Zhao and Anfeng Liu},
  doi          = {10.1016/j.comcom.2019.12.054},
  journal      = {Computer Communications},
  pages        = {485-494},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent resource allocation management for vehicles network: An A3C learning approach},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GeoBroker: Leveraging geo-contexts for IoT data
distribution. <em>COMCOM</em>, <em>151</em>, 473–484. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Internet of Things , the relevance of data often depends on the geographic context of data producers and consumers. Today’s data distribution services , however, mostly focus on data content and not on geo-context, which could help to reduce the dissemination of excess data in many IoT scenarios. In this paper, we propose to use the geo-context information associated with devices to control data distribution. We define what geo-context dimensions exist and compare our definition with concepts from related work. Furthermore, we designed GeoBroker, a data distribution service that uses the location of things, as well as geofences for messages and subscriptions, to control data distribution. This way, we enable new IoT application scenarios while also increasing overall system efficiency for scenarios where geo-contexts matter by delivering only relevant messages. We evaluate our approach based on a proof-of-concept prototype and several experiments.},
  archive      = {J_COMCOM},
  author       = {Jonathan Hasenburg and David Bermbach},
  doi          = {10.1016/j.comcom.2020.01.015},
  journal      = {Computer Communications},
  pages        = {473-484},
  shortjournal = {Comput. Commun.},
  title        = {GeoBroker: Leveraging geo-contexts for IoT data distribution},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unmanned aerial vehicle’s runway landing system with
efficient target detection by using morphological fusion for military
surveillance system. <em>COMCOM</em>, <em>151</em>, 463–472. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the surveillance of military system Unmanned Ariel vehicles (UAV’s) offers a remarkable service. Software Defined Network (SDN) is one of approach for UAV for improving target localization with surveillance for many applications . One of the critical issues for an Unmanned Ariel vehicles (UAV’s) landing is the detection of runway in a low visibility conditions with computer vision . Also, the key problem is the accurate and robust detection of runway. A method of runway detection for fixed wing UAVs with a forward-looking camera is uses sensor based communication in network framework between source (UAV’S) and destination (runway sensor). Yet, this depends on the technical experience for landing an UAV’s safely. Nowadays, highly advanced equipments are being developed for improving safety and transportation system to handle the problem of landing under low visibility conditions. However, natural or habitual vision could be reduced during low visibility situations. This may be due to many meteorological factors like haze, darkness, fog etc. From the discussion made in this paper, the authors mainly concentrate on managing an aircraft system under low luminosity condition during the landing. In this research, effective Morphological fusion method is employed for the prediction of virtual runway imagery to avoid accident landing process. For this, fusion of sensor data for DEM (Digital Elevation Map) Data, infrared image (IR) and navigation parameter are used. The performance of this research using Morphological fusion method gives a fused image of the runway prediction for UAV’s under poor visibility condition. After obtaining the fused image, it is involved in ROI (Region of Interest) contour tracing process to get the clear location of landing of an UAV’s without harm. The virtual imaginary model can be produced through contour tracing to predict runway. By this method, a less prediction time or setting time is achieved and maximum accuracy is obtained through simulation using MATLAB tool. Finally, the proposed experimental outcomes are compared with the existing technology. The proposed approach will be use in aircraft sensor based communication between the network (source to destination) to detect the target and to provide a better surveillance for military applications.},
  archive      = {J_COMCOM},
  author       = {N. Nagarani and P. Venkatakrishnan and N. Balaji},
  doi          = {10.1016/j.comcom.2019.12.039},
  journal      = {Computer Communications},
  pages        = {463-472},
  shortjournal = {Comput. Commun.},
  title        = {Unmanned aerial vehicle’s runway landing system with efficient target detection by using morphological fusion for military surveillance system},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient network service deployment across multiple
SDN domains. <em>COMCOM</em>, <em>151</em>, 449–462. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Software Defined Networking (SDN) and Network Function Virtualization (NFV) enables flexible service provisioning and deployment. However, with the continuous expansion of network scale and sharp increasing of end users, how to flexibly provide network services across multiple SDN domains for users is becoming a critical issue. A major challenge in the multi-domain network service provisioning is the network service deployment method taking into account energy efficiency. In this paper, we study the problem of how to optimally deploy network services across multiple SDN domains with the target of saving energy while achieving the load balancing of multi-domain networks. Specifically, firstly, we propose a novel multi-domain network service deployment framework by integrating SDN architecture and NFV technology, which can intelligently deploy virtual network functions (VNFs) into multi-domain networks. Secondly, we formulate this problem as a multi-objective optimization model to achieve the minimization of energy consumption and load balancing of multi-domain networks. Furthermore, we present a heuristic network service deployment algorithm to solve it. Finally, simulation results demonstrate that the proposed heuristic service deployment algorithm is efficient and outperforms comparison algorithms in terms of energy consumption and load balancing degree.},
  archive      = {J_COMCOM},
  author       = {Chuangchuang Zhang and Xingwei Wang and Anwei Dong and Yong Zhao and Qiang He and Min Huang},
  doi          = {10.1016/j.comcom.2020.01.019},
  journal      = {Computer Communications},
  pages        = {449-462},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient network service deployment across multiple SDN domains},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive repair algorithm for TORA routing protocol based on
flood control strategy. <em>COMCOM</em>, <em>151</em>, 437–448. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporally Ordered Routing Algorithms (TORA) is one of the most representative on-demand routing protocols in Mobile Ad Hoc Networks (MANET). This protocol is widely used in high-speed mobile MANET because of its robust topology. In order to improve the shortcomings of TORA in routing maintenance, such as high overhead and delay, and make the routing more suitable for emergency and disaster relief network, an adaptive repair algorithm for TORA routing protocol based on flood control strategy (AR-TORA-FCS) is proposed. Firstly, according to the characteristics of the uniform deployment of the nodes in the network, the self-repair process of the self-repair nodes in the directed acyclic graph (DAG) of TORA is transformed into the optimal search problem for the optimal nodes, and the formula is established. According to Ray-Algorithm to search for the optimal node, it is proved that the search result is the optimal solution of the process of searching for the optimal node. Then, a conditional algorithm to determine the self-repair process is given, and the conditional threshold to initiate the self-repair process is determined. The mapping relationship between the repair process of self-repair nodes and the distance between the nodes is established, and the path repair is carried out before the path fails. In order to reduce control overhead, the definition of optimization region is given, and the algorithm to determine the optimization region is proposed. Simulation results show that the algorithm reduces control overhead, improves the packet delivery rate, and improves average end-to-end delay. The mobile device , which is subject to unified deployment, is used as a network node to test the proposed adaptive repair algorithm in the actual rescue and disaster relief environment. The results show that it is basically consistent with the simulation results, and the overall performance is improved significantly.},
  archive      = {J_COMCOM},
  author       = {Si Liu and Degan Zhang and Xiaohuan Liu and Ting Zhang and Hao Wu},
  doi          = {10.1016/j.comcom.2020.01.024},
  journal      = {Computer Communications},
  pages        = {437-448},
  shortjournal = {Comput. Commun.},
  title        = {Adaptive repair algorithm for TORA routing protocol based on flood control strategy},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybridized interference bounded intuitive splitting for
smart wearable system using cognitive assisted internet of things.
<em>COMCOM</em>, <em>151</em>, 428–436. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the technology of the Internet of Things (IoT) helps to improve the usage of common appliances through the Internet as a medium to enhance our lives. In IoT communication, researchers have brought out security challenges for reliable data transmission of the wearable sensor devices and minimized energy utilization among IoT devices as primary issues need to be addressed. As IoT devices unable to meet the demands of the scarcity of security and more energy utilization during data transmission in a network or among wearable sensors, Cognitive IoT (CIoT) has been introduced to meet and address these demands along with hybridized Interference bounded Intuitive Splitting (HIBJS) algorithm. This intelligent algorithm with optimized policy control strategies splits the time and power to improve the data transmission speed of the wearable sensor devices with more reliability and less energy consumption than the traditional algorithms which are utilized in practice. The experimental and numerical results show that the proposed HIBJS approach has more effective performance in terms of energy consumption, data transmission speed of wearable devices, error rate, accuracy and average signal to noise ratio (SNR) than traditional algorithms. This research focuses to improve the CIoT as a smart information system for users in smart environments using HIBJS.},
  archive      = {J_COMCOM},
  author       = {Torki Altameem and Ayman Altameem},
  doi          = {10.1016/j.comcom.2019.12.047},
  journal      = {Computer Communications},
  pages        = {428-436},
  shortjournal = {Comput. Commun.},
  title        = {Hybridized interference bounded intuitive splitting for smart wearable system using cognitive assisted internet of things},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent software defined network based digital video
stabilization system using frame transparency threshold pattern
stabilization method. <em>COMCOM</em>, <em>151</em>, 419–427. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital Video Stabilization (DVS) allows the acquisition of video sequences without disturbing jerkiness and removing unwanted camera motion. Many researchers attempt to improve the performance of Digital Video Stabilization but all of them not get perfect results. Therefore in this research work we introduce different DVS strategy that proposes to transfer camera veins to a Frame Transparency Threshold Pattern Stabilization (FTTPS) algorithm. The proposed FTTPS algorithm consists of four steps: (i) Frame Representation; (ii) Motion Estimation; (iii) Filtering and (iv) Compensation. The proposed FTTPS method also utilizes an adaptive criterion for filtering and validation of motion vectors moreover to register a Global Motion Vector (GMV) for each frame, the proposed DVS method satisfactorily assesses the think camera motion by moving an unwanted motion of characteristics. The proposed Frame Transparency Threshold Pattern Stabilization method is basically customized in Matlab programming language, the simulation of the proposed system validated through Inter-Frame Transformation Fidelity (ITF) and Peak to Signal Noise Ratio (PSNR) Values and which is more pragmatic and takes less chip asset and general 93.12\% efficiency accomplished utilizing proposed Frame Transparency Threshold Pattern Stabilization system. The suggested digital video stabilization system can be combined with sensible and robot vision, and visual monitoring structures for various low cameras display quality updates.},
  archive      = {J_COMCOM},
  author       = {Kokila S. and Ramesh S.},
  doi          = {10.1016/j.comcom.2019.12.048},
  journal      = {Computer Communications},
  pages        = {419-427},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent software defined network based digital video stabilization system using frame transparency threshold pattern stabilization method},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blockchain for internet of energy management: Review,
solutions, and challenges. <em>COMCOM</em>, <em>151</em>, 395–418. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After smart grid, Internet of Energy (IoE) has emerged as a popular technology in the energy sector by integrating different forms of energy. IoE uses Internet to collect, organize, optimize and manage the networks energy information from different edge devices in order to develop a distributed smart energy infrastructure. Sensors and communication technologies are used to collect data and to predict demand and supply by consumers and suppliers respectively. However, with the development of renewable energy resources , Electric Vehicles (EVs), smart grid and Vehicle-to-grid (V2G) technology, the existing energy sector started shifting towards distributed and decentralized solutions. Moreover, the security and privacy issues because of centralization is another major concern for IoE technology. In this context, Blockchain technology with the features of automation, immutability, public ledger facility, irreversibility , decentralization, consensus and security has been adopted in the literature for solving the prevailing problems of centralized IoE architecture. By leveraging smart contracts , blockchain technology enables automated data exchange, complex energy transactions, demand response management and Peer-to-Peer (P2P) energy trading etc. Blockchain will play vital role in the evolution of the IoE market as distributed renewable resources and smart grid network are being deployed and used. We discuss the potential and applications of blockchain in the IoE field. This article is build on the literature research and it provides insight to the end-user regarding the future IoE scenario in the context of blockchain technology. Lastly this article discusses the different consensus algorithm for IoE technology.},
  archive      = {J_COMCOM},
  author       = {Arzoo Miglani and Neeraj Kumar and Vinay Chamola and Sherali Zeadally},
  doi          = {10.1016/j.comcom.2020.01.014},
  journal      = {Computer Communications},
  pages        = {395-418},
  shortjournal = {Comput. Commun.},
  title        = {Blockchain for internet of energy management: Review, solutions, and challenges},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting drug responsiveness with deep learning from the
effects on gene expression of obsessive–compulsive disorder affected
cases. <em>COMCOM</em>, <em>151</em>, 386–394. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obsessive–Compulsive Disorder (OCD) is a chronic psychiatric condition distinguished by intrusive thoughts followed with the urge to perform repetitive actions. These behaviors are cyclic and uncontrollable for more than a short period. Genetic factors have a strong influence on developing mental illness. Cognitive Behavioral Therapy (CBT) and antidepressants such as Selective Serotonin Reuptake Inhibitors (SSRIs) are the well-known treatment strategies to effectively control the condition. Antipsychotic medication alongside the SSRI procedure exhibits better results on the OCD affected individuals. So, to find more efficacious medications, the responsiveness of certain drugs under the genetic level of the patients should be properly scrutinized. But, analyzing the gene expressions is a computationally-intensive task. The extraction of useful patterns from high dimensional genetic information needs heavily built learning models. In this paper, to discern the drug-responsive coherent genetic markers of OCD, a filter-ensemble fused feature selection model is proposed. Furthermore, to improve the predictability of the learning model, an unsupervised deep learning-based feature extraction method is used. This algorithm captures relevant information as much as possible and finds the logical representation from the input features. The extracted features are trained with supervised machine learning algorithms . The experimental work is carried out in the dataset accessed from Gene Expression Omnibus (GEO) repository and the accession number is GSE76611. The outcome of the experimental work revealed the significant gene markers of OCD with active drug responsiveness. The effectiveness of the treatment becomes phenomenal when the medications are profound following the patient’s condition. The identified genetic markers will be further helpful to transform from the existing schemes towards more personalized treatment.},
  archive      = {J_COMCOM},
  author       = {Karthik Sekaran and Sudha M.},
  doi          = {10.1016/j.comcom.2019.12.049},
  journal      = {Computer Communications},
  pages        = {386-394},
  shortjournal = {Comput. Commun.},
  title        = {Predicting drug responsiveness with deep learning from the effects on gene expression of Obsessive–Compulsive disorder affected cases},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MPLS-based reduction of flow table entries in SDN switches
supporting multipath transmission. <em>COMCOM</em>, <em>151</em>,
365–385. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of resource utilisation improvement in software-defined networking (SDN) is addressed. The need for resource optimisation is understood here be twofold. First, bandwidth in links should be saved when congestion appears. Second, the internal resources represented by table entries of SDN switches should be minimised to ensure fast processing and flexibility. Here, both types of resources are optimised with a new mechanism for flow aggregation. The mechanism is accompanied with a multipath transmission supporting reaction when network conditions change. The proposed mechanism uses classical MPLS labelling, which enables flow aggregation together with multipath transmission; therefore, neither involves any definition of new protocols nor requires the application of legacy signalling protocols. Only simple yet powerful modifications of the existing solutions assured by flexibility of the OpenFlow protocol are necessary. Furthermore, the proposed solution can be incrementally deployed in legacy networks. The aggregation results in a low number of flow entries in core switches in comparison to legacy OpenFlow operation. The simulations show that the number of flow entries in core switches can be reduced by as much as 93\%, while the overall network traffic is increased by around 171\%. This type of scalability improvement of flow processing is obtained as a result of the introduction of a centrally managed MPLS label distribution performed by an SDN controller. Moreover, the proposed method of multipath transmission improves network resource utilisation. Additionally, independently of the traffic pattern, the proposed approach significantly reduces the communication overhead between the controller and the switches.},
  archive      = {J_COMCOM},
  author       = {Zbigniew Duliński and Grzegorz Rzym and Piotr Chołda},
  doi          = {10.1016/j.comcom.2019.12.052},
  journal      = {Computer Communications},
  pages        = {365-385},
  shortjournal = {Comput. Commun.},
  title        = {MPLS-based reduction of flow table entries in SDN switches supporting multipath transmission},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced resource allocation in mobile edge computing using
reinforcement learning based MOACO algorithm for IIOT. <em>COMCOM</em>,
<em>151</em>, 355–364. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Mobile networks deploy and offers a multiaspective approach for various resource allocation paradigms and the service based options in the computing segments with its implication in the Industrial Internet of Things (IIOT) and the virtual reality. The Mobile edge computing (MEC) paradigm runs the virtual source with the edge communication between data terminals and the execution in the core network with a high pressure load. The demand to meet all the customer requirements is a better way for planning the execution with the support of cognitive agent. The user data with its behavioral approach is clubbed together to fulfill the service type for IIOT. The swarm intelligence based and reinforcement learning techniques provide a neural caching for the memory within the task execution, the prediction provides the caching strategy and cache business that delay the execution. The factors affecting this delay are predicted with mobile edge computing resources and to assess the performance in the neighboring user equipment. The effectiveness builds a cognitive agent model to assess the resource allocation and the communication network is established to enhance the quality of service. The Reinforcement Learning techniques Multi Objective Ant Colony Optimization (MOACO) algorithms has been applied to deal with the accurate resource allocation between the end users in the way of creating the cost mapping tables creations and optimal allocation in MEC.},
  archive      = {J_COMCOM},
  author       = {S. Vimal and Manju Khari and Nilanjan Dey and Rubén González Crespo and Y. Harold Robinson},
  doi          = {10.1016/j.comcom.2020.01.018},
  journal      = {Computer Communications},
  pages        = {355-364},
  shortjournal = {Comput. Commun.},
  title        = {Enhanced resource allocation in mobile edge computing using reinforcement learning based MOACO algorithm for IIOT},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decoupling NDN caches via CCndnS: Design, analysis, and
application. <em>COMCOM</em>, <em>151</em>, 338–354. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-network caching is considered to be a vital part of the Internet for future applications (e.g., Internet of Things). One proposal that has attracted interest in recent years, Named Data Networking (NDN), aims to facilitate in-network caching by locating content by name. However, the efficiency of in-network caching has been questioned by experts. Data correlation among caches builds strong dependencies between caches at the edge and in the core. That dependency makes analyzing network performance difficult. This paper proposes CCndnS (Content Caching strategy for NDN with Skip), a caching policy to break the dependencies among caches, thus facilitating the design of an efficient data placement algorithm . Specifically, each cache – regardless of its location in the network – should receive an independent set of requests; otherwise, only misses from downstream caches make their way to the upstream caches, i.e. a filtering effect that induces a correlation among the caches. CCndnS breaks a file into smaller segments and spreads them in the path between requester and publisher in a way that the head of the file (the first segment) should be cached at the edge router close to the requester and the tail far from the requester and towards the content provider. Requests for a segment skip searching caches in its path, to search only the cache with the segment of interest. That reduces the number of futile checks on caches, and thus the delay from memory accesses. This mechanism also decouples the caches, so there is a simple analytical model for cache performance in the network. We illustrate an application of the model to enforce a Service Level Agreement (SLA) between a content provider and the caching system proposed in this paper. The model can be used for cache provisioning for two purposes: (1) To specify the cache size to be reserved for specific contents to reach some desired performance. For instance, if the client of an SLA requires a 50\% cache hit for its content at each router, the model can be used to determine the cache size that needs to be reserved to reach the 50\% hit rate. (2) To calculate the effect of such reservations on other contents that use the routers covered by the SLA. The design, analysis, and application are tested with extensive simulations.},
  archive      = {J_COMCOM},
  author       = {Mostafa Rezazad and Y.C. Tay},
  doi          = {10.1016/j.comcom.2019.12.053},
  journal      = {Computer Communications},
  pages        = {338-354},
  shortjournal = {Comput. Commun.},
  title        = {Decoupling NDN caches via CCndnS: Design, analysis, and application},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anomaly detection in wireless sensor network using machine
learning algorithm. <em>COMCOM</em>, <em>151</em>, 331–337. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security in the Wireless Sensor Network(WSNs) is an essential and a challenging task. Anomaly detection is a key challenge to ensure the security in WSN. WSNs are vulnerable to various threats which may cause the node to get damaged and produce faulty measurements. The detection of such anomalous data is required to reduce false alarms. Machine learning algorithm based detection of anomalous data becomes popular now. Most of the current machine anomaly detection algorithms run in a stationary environment and require the entire training data to be kept in the node. In this paper, we formulate an Online Locally Weighted Projection Regression (OLWPR) for anomaly detection in Wireless Sensor Network . Linear Weighted Projection Regression methods are non parametric and the current predictions are performed by local functions that use only the subset of data. So, the computation complexity is low which is one of the requirements in Wireless Sensor Network . The dimensionality reduction in LWPR is done online by Principal Component Analysis (PCA) to handle the irrelevant and redundant data in the input data. After the prediction process, the dynamic threshold value is determined by a dynamic thresholding method to find the deviations of predicted value from the actual sensed value. OLWPR attains the detection rate of 86 percentage and very low error rate of only 16\%.},
  archive      = {J_COMCOM},
  author       = {I. Gethzi Ahila Poornima ( Research Scholar ) and B. Paramasivan ( Professor )},
  doi          = {10.1016/j.comcom.2020.01.005},
  journal      = {Computer Communications},
  pages        = {331-337},
  shortjournal = {Comput. Commun.},
  title        = {Anomaly detection in wireless sensor network using machine learning algorithm},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization of monitoring network system for eco safety on
internet of things platform and environmental food supply chain.
<em>COMCOM</em>, <em>151</em>, 320–330. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food supply chain and Eco system security in developing nations depend to a limited extent on the practical utilization of common natural resources. Food and Eco system security is generally inspected through three measurement approaches, in particular the accessibility of ecosystem, access to supply chain and use of the food chain. In this research a complex and interlocked network of food supply with various food material and products has been evaluated and it has been monitored for food supply networks to cover food materials and to safeguard the ecosystem. In this paper an advanced intelligent internet of things (IoT) based Optimal Communal Network mathematical modeling system (OCNMM) has been established to displace manual importance and verification in food supply chain system. Moreover, we intend to utilize the smart IoT technology to help the system engineers to discover issues and procedure for the timely solutions. The experimental and numerical analysis shows that OCNMM has prominent outcomes than manual intervention approaches which has been used in practice. The performance factors such as accuracy, precision, recall, F-Score, Stability, Specificity and Sensitivity has been numerically analyzed in this research for validation of the proposed model using NordVal validation.},
  archive      = {J_COMCOM},
  author       = {Wei Xu and Zhipeng Zhang and Hongxun Wang and Yang Yi and Yanpeng Zhang},
  doi          = {10.1016/j.comcom.2019.12.033},
  journal      = {Computer Communications},
  pages        = {320-330},
  shortjournal = {Comput. Commun.},
  title        = {Optimization of monitoring network system for eco safety on internet of things platform and environmental food supply chain},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards a distributed and infrastructure-less vehicular
traffic management system. <em>COMCOM</em>, <em>151</em>, 306–319. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past few years, several systems have been proposed to deal with issues related to the vehicular traffic management. Usually, their solutions include the integration of computational technologies such as vehicular networks , central servers, and roadside units. Most systems use a hybrid approach, which means they still need a central entity (central server or roadside unit) and Internet connection to find out an en-route event as well as alternative routes for vehicles. It is easy to understand the need for a central entity because selecting the most appropriate vehicle to perform aforementioned procedures is a difficult task. This is especially true in a highly dynamic network. In addition to that, as far as we know, there are very few systems that apply the altruistic approach (not selfish behavior) to routing decisions. Because of that, the issue addressed in this work is how to perform the vehicular traffic management, when an en-route event is detected, in a distributed, scalable, and cost-effective fashion. To deal with these issues, we proposed a distributed vehicle traffic management system , named as dEASY ( d istributed v E hicle tr A ffic management SY stem). The dEASY system was designed and implemented on a three-layer architecture, namely environment sensing and vehicle ranking , knowledge generation and distribution , and knowledge consumption . Each layer of the dEASY architecture is responsible for dealing with the main issues that were not addressed in related works or could be improved. The three-layer architecture is arranged as follows: the first layer deals with the task of selecting the most appropriate vehicle to perform data forwarding and/or knowledge generation, the second one addresses the knowledge generation and distribution, and the third layer applies an altruistic approach to choose an alternative route. Simulation results have shown that, compared with other systems from the literature, our proposed system has lower network overhead due to applied vehicle selection and broadcast suppression mechanisms. On average, dEASY also outperformed all other competitors in what regards to the travel time and time lost metrics. Through the analysis of results, it is possible to conclude that our infrastructure-less system is scalable and cost-effective.},
  archive      = {J_COMCOM},
  author       = {Ademar T. Akabane and Roger Immich and Luiz F. Bittencourt and Edmundo R.M. Madeira and Leandro A. Villas},
  doi          = {10.1016/j.comcom.2020.01.002},
  journal      = {Computer Communications},
  pages        = {306-319},
  shortjournal = {Comput. Commun.},
  title        = {Towards a distributed and infrastructure-less vehicular traffic management system},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on intelligent visual image feature region
acquisition algorithm in internet of things framework. <em>COMCOM</em>,
<em>151</em>, 299–305. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to solve the problem that traditional technology is vulnerable to external interference, the visual features are missing, which affects the image feature region acquisition results, and can only be applied to the visual features of color features . This paper proposes an intelligent visual image feature region acquisition algorithm under the Internet of Things framework. This article describes the distribution of vision sensors in the Internet of Things . The IoT vision sensor acquires the experimental image. After the image is smoothed by the neighborhood average method, the inverse process differentiation of the integration is used to sharpen the edge of the image and enhance the sharpness of the image The noise interference of the image is excluded by the adjacent region average method and the differential method. In order to obtain feature region detection results clear and accurate, the agglomerative clustering algorithm sharpens the image, and the image edge list is obtained. Finally, the image stable extreme value area is determined, and the image feature region can be acquired in the stable extreme value area. In the stable extreme region, the SURF algorithm is used to detect the visual characteristic points, and the intelligent visual characteristic regions are collected through the Euler distance. It can be seen from the experiment that the image feature region of the algorithm has high acquisition precision, low mismatch rate, and fast acquisition speed.},
  archive      = {J_COMCOM},
  author       = {Xin Liu},
  doi          = {10.1016/j.comcom.2020.01.008},
  journal      = {Computer Communications},
  pages        = {299-305},
  shortjournal = {Comput. Commun.},
  title        = {Research on intelligent visual image feature region acquisition algorithm in internet of things framework},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the optimization of IIoT data processing
latency. <em>COMCOM</em>, <em>151</em>, 290–298. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As for data processing, data should be sent to cloud, stored and computed. Usually, the amount of data is huge enough for higher latency of processing. In addition, the mobility of cloud service would be much slower. In this paper, an Industrial Internet of Things cloud–fog hybrid network (ITCFN) framework is proposed to solve high latency upon processing industrial data on cloud. In the production equipment area, edge devices such as routers and switches are utilized by framework to construct a fog computing layer between cloud server and production equipment. Since computing power of the edge devices in fog computing is much poor, a distributed computing method for multi-devices is proposed. The aim of minimum task processing delay is achieved by using the constrained particle swarm optimization load balancing algorithm based on simulated annealing method (SAPSO-LB). The experimental results show that the ITCFN based on SAPSO-LB algorithm can effectively reduce the industrial data processing delay. When ten fog computing devices are used and the collected data is between 4GB and 12GB, compared with cloud computing , the latency is improved by 84.1\%-29.9\%.},
  archive      = {J_COMCOM},
  author       = {Weimin Liu and Guan Huang and Aiyun Zheng and Jiaxin Liu},
  doi          = {10.1016/j.comcom.2020.01.007},
  journal      = {Computer Communications},
  pages        = {290-298},
  shortjournal = {Comput. Commun.},
  title        = {Research on the optimization of IIoT data processing latency},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VANETomo: A congestion identification and control scheme in
connected vehicles using network tomography. <em>COMCOM</em>,
<em>151</em>, 275–289. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a vision for an internetwork of intelligent, communicating objects, which is on the cusp of transforming human lives. Smart transportation is one of the critical application domains of IoT and has benefitted from using state-of-the-art technology to combat urban issues such as traffic congestion while promoting communication between the vehicles, increasing driver safety, traffic efficiency and ultimately paving the way for autonomous vehicles. Connected Vehicle (CV) technology, enabled by Dedicated Short Range Communication (DSRC), has attracted significant attention from industry, academia, and government, due to its potential for improving driver comfort and safety. These vehicular communications have stringent transmission requirements. To assure the effectiveness and reliability of DRSC, efficient algorithms are needed to ensure adequate quality of service in the event of network congestion . Previously proposed congestion control methods that require high levels of cooperation among Vehicular Ad-Hoc Network (VANET) nodes. This paper proposes a new approach, VANETomo, which uses statistical Network Tomography (NT) to infer transmission delays on links between vehicles with no cooperation from connected nodes. Our proposed method combines open and closed loops congestion control in a VANET environment. Simulation results show VANETomo outperforming other congestion control strategies.},
  archive      = {J_COMCOM},
  author       = {Anirudh Paranjothi and Mohammad S. Khan and Rizwan Patan and Reza M. Parizi and Mohammed Atiquzzaman},
  doi          = {10.1016/j.comcom.2020.01.017},
  journal      = {Computer Communications},
  pages        = {275-289},
  shortjournal = {Comput. Commun.},
  title        = {VANETomo: A congestion identification and control scheme in connected vehicles using network tomography},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Techniques tanimoto correlated feature selection system and
hybridization of clustering and boosting ensemble classification of
remote sensed big data for weather forecasting. <em>COMCOM</em>,
<em>151</em>, 266–274. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weather forecasting has been done using various techniques but still not efficient for handling the big remote sensed data since the data comprises the more features. Hence the techniques degrade the forecasting accuracy and take more prediction time. To enhance the prediction accuracy (PA) with minimal time, Tanimoto Correlation based Combinatorial MAP Expected Clustering and Linear Program Boosting Classification (TC-CMECLPBC) Technique is proposed. At first, the data and features are gathered from big weather database. After that, relevant features are selected through finding the similarity between the features. Tanimoto Correlation Coefficient is used to find the similarity between the features for selecting the relevant features with higher feature selection accuracy. After selecting the relevant features, MAP expected clustering process is carried out to group the weather data for cluster formation. In this process, a number of cluster and cluster centroids are initialized. In this clustering process , it includes two steps namely expectation (E) and maximization (M) to discover maximum probability for grouping data into the cluster. After that, the clustering result is given to Linear Program boosting classifier to improve the prediction performance. In this classification, the weak classifier results are boosted to create strong classifier. The results evident that the TC-CMECLPBC technique enhance the PA with lesser time and false positive rate (FPR) than the conventional methods.},
  archive      = {J_COMCOM},
  author       = {Pooja S.B. and R.V. Siva Balan and Anisha M. and M.S. Muthukumaran and Jothikumar R.},
  doi          = {10.1016/j.comcom.2019.12.063},
  journal      = {Computer Communications},
  pages        = {266-274},
  shortjournal = {Comput. Commun.},
  title        = {Techniques tanimoto correlated feature selection system and hybridization of clustering and boosting ensemble classification of remote sensed big data for weather forecasting},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed and scalable computing framework for improving
request processing of wearable IoT assisted medical sensors on pervasive
computing system. <em>COMCOM</em>, <em>151</em>, 257–265. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pervasive computing systems (PCS) are distributed heterogeneous network and communication technology integration for satisfying multi-level user requirements Internet of Things (IoT) assisted systems. The openness in communication, the level of management and heterogeneity support for distributed users is still a challenging demand in PCS. This manuscript introduces a novel distributed and scalable computing framework (DSCF) for improving the communication reliability of end-users on wearable IoT assisted medical sensors (WIoT-MSs). This framework uses recurrent learning for analyzing the resource allocation based on demand and sharing features. With the estimated resource requirements, PCS serve end-users with less time delay and improved communication rates of the WIoT-MSs. This framework is designed for end-user mobility management besides resource allocation and sharing on wearable technology medical sensor data transfer. The performance of the proposed framework is estimated through experimental analysis and the consistency of the framework is proved using metrics. These metrics are response time, request failure, requests handled, request backlogs, bandwidth and storage utilization. The proposed DSCF improves requests handled, bandwidth and storage utilization and minimizes request failure and backlogs with less response time.},
  archive      = {J_COMCOM},
  author       = {H. Fouad and Nourelhoda M. Mahmoud and Mohammed Sayed El Issawi and Haytham Al-Feel},
  doi          = {10.1016/j.comcom.2020.01.020},
  journal      = {Computer Communications},
  pages        = {257-265},
  shortjournal = {Comput. Commun.},
  title        = {Distributed and scalable computing framework for improving request processing of wearable IoT assisted medical sensors on pervasive computing system},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network resource planning for evolvability in
software-defined infrastructure. <em>COMCOM</em>, <em>151</em>, 247–256.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software-defined infrastructure (SDI) makes it possible to construct virtual networks with finer time granularity than was possible before, possibly allowing immediate responses to customer requests to increase or decrease resource levels to match demand. Adaptation by virtual network embedding (VNE) control is a promising technique for handling demand fluctuations, and choosing a good physical resource design is important for adaptability of VNE control. Despite its importance, strategies to design a physical network that promotes VNE adaptability have not been previously explored. Here, we propose an SDI resource-design strategy that increases the diversity of VNE solutions by using a control system that varies with demand fluctuation. The proposed strategy imitates biological evolutionary adaptation in order to improve evolvability. We use the proposed strategy to construct a method for reinforcing the computational capacity of physical nodes, and conduct experiments by computer simulation. Our results shows that the probability of convergence with VNE control is improved by using the proposed physical-resource reinforcement, achieving a gain of up to 19\% relative to a basis reinforcement.},
  archive      = {J_COMCOM},
  author       = {Koki Inoue and Shin’ichi Arakawa and Masayuki Murata},
  doi          = {10.1016/j.comcom.2019.12.059},
  journal      = {Computer Communications},
  pages        = {247-256},
  shortjournal = {Comput. Commun.},
  title        = {Network resource planning for evolvability in software-defined infrastructure},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RRAC: Role based reputed access control method for
mitigating malicious impact in intelligent IoT platforms.
<em>COMCOM</em>, <em>151</em>, 238–246. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {IoT Environment is a recent development in communication networks that supports a wide range of individual and cooperative user applications. Due to the openness of the service providing network, communication services are exposed to malicious risks. In this manuscript, a role-based reputed access control (RRAC) method is designed to mitigate malicious attacks in IoT environments. The RRAC operates in two categories: providing an adaptive certificate authentication internally and trusted user communication externally. The internal security method is responsible for authenticating communication between users and resources. The external security feature aids secure service discovery and user selection for discovering services. The integrated security methods mitigate the influence of malicious users and forged resources in the network, improving communication reliability. The access control decides the availability and usability of the devices to participate in service communications either as a neighbor or as a resource. Experimental results show that the proposed RRAC improves the performance of IoT device communication by achieving higher detection and minimizing detection time, service overhead and loss, false positive rate and misdetection .},
  archive      = {J_COMCOM},
  author       = {Mohammed Amoon and Torki Altameem and Ayman Altameem},
  doi          = {10.1016/j.comcom.2020.01.011},
  journal      = {Computer Communications},
  pages        = {238-246},
  shortjournal = {Comput. Commun.},
  title        = {RRAC: Role based reputed access control method for mitigating malicious impact in intelligent IoT platforms},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic routing in wireless networks with privacy
guarantees. <em>COMCOM</em>, <em>151</em>, 228–237. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the source–destination location privacy problem for routing in wireless networks. Previous routing schemes mainly provided privacy protection by minimizing the average detection probability of traffic analysis attempts. However, they do not seek to provide strict privacy guarantees of the vulnerable source–destination pairs, which could still be relatively easy to identify. To address this gap in the literature, we propose the ( k , ϵ ) (k,ϵ) -anonymity property for routing in wireless networks with privacy guarantees. We consider a Bayesian maximum-a-posteriori (MAP) inference-based adversary and design a probabilistic routing scheme that uses a statistical decision-making framework to compute the minimum-cost ( k , ϵ ) (k,ϵ) -anonymous paths. A routing scheme is ( k , ϵ ) (k,ϵ) -anonymous if there are k k or more distinct source–destination pairs within an ϵ ϵ -tolerance of the MAP probability. We compare our approach against a baseline routing scheme that minimizes the average detection probability of the adversary, and our simulation results show that our approach provides significantly better ( k , ϵ ) (k,ϵ) -anonymity privacy guarantees while achieving comparable average adversarial detection probability. We also studied how the adversary’s prior beliefs affect its detection probability and Bayes risk.},
  archive      = {J_COMCOM},
  author       = {Jing Yang Koh and Gareth W. Peters and Ido Nevat and Derek Leong},
  doi          = {10.1016/j.comcom.2019.12.045},
  journal      = {Computer Communications},
  pages        = {228-237},
  shortjournal = {Comput. Commun.},
  title        = {Probabilistic routing in wireless networks with privacy guarantees},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum to “generic cost optimized and secured
sensitive attribute storage model for template based text document on
cloud” [comput. Commun. 150 (2020) 569–580]. <em>COMCOM</em>,
<em>151</em>, 227. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Sumathi M. and Sangeetha S. and Anu Thomas},
  doi          = {10.1016/j.comcom.2019.12.057},
  journal      = {Computer Communications},
  pages        = {227},
  shortjournal = {Comput. Commun.},
  title        = {Corrigendum to “Generic cost optimized and secured sensitive attribute storage model for template based text document on cloud” [Comput. commun. 150 (2020) 569–580]},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Infective flooding in low-duty-cycle networks, properties
and bounds. <em>COMCOM</em>, <em>151</em>, 216–226. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flooding information is an important function in many networking applications. In some networks, as wireless sensor networks or some ad-hoc networks it is so essential as to dominate the performance of the entire system. Exploiting some recent results based on the distributed computation of the eigenvector centrality of nodes in the network graph and classical dynamic diffusion models on graphs, this paper derives a novel theoretical framework for efficient resource allocation to flood information in mesh networks with low duty-cycling without the need to build a distribution tree or any other distribution overlay. Furthermore, the method requires only local computations based on each node neighborhood. The model provides lower and upper stochastic bounds on the flooding delay averages on all possible sources with high probability. We show that the lower bound is very close to the theoretical optimum. A simulation-based implementation allows the study of specific topologies and graph models as well as scheduling heuristics and packet losses . Simulation experiments show that simple protocols based on our resource allocation strategy can easily achieve results that are very close to the theoretical minimum obtained building optimized overlays on the network.},
  archive      = {J_COMCOM},
  author       = {Luca Baldesi and Leonardo Maccari and Renato Lo Cigno},
  doi          = {10.1016/j.comcom.2019.12.044},
  journal      = {Computer Communications},
  pages        = {216-226},
  shortjournal = {Comput. Commun.},
  title        = {Infective flooding in low-duty-cycle networks, properties and bounds},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GrowingNet: An end-to-end growing network for
semi-supervised learning. <em>COMCOM</em>, <em>151</em>, 208–215. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) typically involves a small quantity of labeled data and a large quantity of unlabeled data . As such, the successful application of semi-supervised learning (SSL) depends on distinguishing easy and hard samples which contributes substantial recognition, as well as obtaining a more accurate pseudo target for a hard sample. However, existing SSL network models with deeper layers will suffer from overfitting or optimization difficulties. To address these problems, we propose a growing network (GrowingNet) where the convolution depth of the model can expand and contract. We also propose an incremental learning method by which the amount of pseudo labeled data can be increased uniformly. During training, the goal is to increase the convolutional layers of our model and the number of pseudo labeled data synchronously. We divide training epochs, the convolutional layers of GrowingNet, and pseudo labeled data into u equal parts. During each part of training epochs, we increase one part of convolutional layers, select one division of pseudo labeled data into the training process. The accuracy of the model will improve as training progresses, which distinguishes easy and hard samples and also provides more reliable pseudo labels during subsequent part of training epochs. This provides significant improvements over state-of-the-art networks in most of cases on SSL benchmark tasks (CIFAR-10, CIFAR-100, and SVHN). Specifically, without data augmentation , our model produces error rates of 20.86\%, 18.22\%, and 12.02\% on CIFAR-10 with 1000, 2000, and 4000 labeled data, as well as error rates of 5.03\% and 3.46\% on SVHN with 500 and 1000 labeled data, respectively. With data augmentation , the error rate reaches 12.16\% on CIFAR-10 with 2000 labeled data and 31.06\% on CIFAR-100 with 10,000 labeled data.},
  archive      = {J_COMCOM},
  author       = {Qifei Zhang and Xiaomo Yu},
  doi          = {10.1016/j.comcom.2020.01.003},
  journal      = {Computer Communications},
  pages        = {208-215},
  shortjournal = {Comput. Commun.},
  title        = {GrowingNet: An end-to-end growing network for semi-supervised learning},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real time energy efficient data aggregation and scheduling
scheme for WSN using ATL. <em>COMCOM</em>, <em>151</em>, 202–207. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Network (WSN) has been used for data collection in different situations. Various methods are described earlier for the problem, but they consider only limited parameters in data collection which introduces poor lifetime, throughput and energy holes. To overcome this issue, a real time energy efficient data aggregation approach is presented here. The method schedules the nodes of the network for their working based on the parameters (Availability-Throughput-Lifetime) ATL. Using all these parameters, the method estimates Data Availability Support, Network Throughput Support and Network Lifetime Support measures. Using all these support measures, the method computes the Data Aggregation Support (DAGS) measure. Using the measure estimated, the nodes are scheduled for their working. Similarly, the nodes are selected for data aggregation based on the above support measures estimated. The ATL approach achieves higher data aggregation performance with higher lifetime maximization.},
  archive      = {J_COMCOM},
  author       = {KhadirKumar N. ( Assistant Professor ) and Dr. Bharathi A. ( Professor and Head )},
  doi          = {10.1016/j.comcom.2019.12.027},
  journal      = {Computer Communications},
  pages        = {202-207},
  shortjournal = {Comput. Commun.},
  title        = {Real time energy efficient data aggregation and scheduling scheme for WSN using ATL},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software defined network using enhanced workflow scheduling
in surveillance. <em>COMCOM</em>, <em>151</em>, 196–201. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the rapid development of information transfer technology, the load balancing scheduling of server cluster system must be optimized. In order to optimize the load of server, a load balancing scheduling strategy for server cluster system was proposed in this paper. A new scheduling weighted method was proposed, and the optimization of load allocation was realized. In order to verify the feasibility of the scheduling strategy, the results were tested from several aspects. Through a comprehensive test, the research of load balancing scheduling strategy optimization for server cluster system is feasible, which can further improve the server’s load capacity.},
  archive      = {J_COMCOM},
  author       = {Balaji Vuppala and Swarnalatha P.},
  doi          = {10.1016/j.comcom.2019.12.064},
  journal      = {Computer Communications},
  pages        = {196-201},
  shortjournal = {Comput. Commun.},
  title        = {Software defined network using enhanced workflow scheduling in surveillance},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi objective task scheduling algorithm based on SLA and
processing time suitable for cloud environment. <em>COMCOM</em>,
<em>151</em>, 183–195. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing is a new paradigm which provides subscription-oriented services. Scheduling the tasks in cloud computing environments is a multi-goal optimization problem , which is NP hard. To exaggerate task scheduling performance and reduce the overall Makespan of the task allocation in clouds, this paper proposes two scheduling algorithms named as TBTS (Threshold based Task scheduling algorithm) and SLA-LB (Service level agreement-based Load Balancing) algorithm. TBTS is two-phase scheduling algorithm which schedules the tasks in a batch. It supports task scheduling in virtual machines with distinct configuration. Furthermore, in TBTS algorithm, threshold data generated based on the ETC (Expected Time to Complete) matrix. Virtual machines which execute tasks with the estimated execution time lesser than threshold value are allocated to the particular task. SLA-LB algorithm is a online model which schedules the task dynamically, based on the requirement of clients, like deadline and budget as the two criteria. Prediction based scheduling is implemented in TBTS to increase the system utilization and to improve the load balancing among the machines by allocation of the minimum configuration machine to the task, based on predicted robust threshold value. SLA-LB uses the level of agreement and finds the required system to reduce the Makespan and increase the cloud-utilization. Simulation of proposed algorithms is performed with benchmark datasets (Braun, 2015) and synthetic datasets are generated with random functions. The proposed TBTS and SLA-LB final values of the proposed algorithms are analyzed with assorted scheduling models, namely SLA-MCT, FCFS, EXIST, LBMM, Lbmaxmin, MINMIN and MAXMIN algorithms. Performance metrics such as Makespan, penalty, gain cost and also the VM utilization factor of proposed algorithm compared with existing algorithms. The comparison analysis among various existing algorithms with TBTS and SLA-LB algorithms show that the proposed methods outperform existing algorithms, even in the scalability situation of the dataset and virtual machines.},
  archive      = {J_COMCOM},
  author       = {M. Lavanya and B. Shanthi and S. Saravanan},
  doi          = {10.1016/j.comcom.2019.12.050},
  journal      = {Computer Communications},
  pages        = {183-195},
  shortjournal = {Comput. Commun.},
  title        = {Multi objective task scheduling algorithm based on SLA and processing time suitable for cloud environment},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data consistency matrix based data processing model for
efficient data storage in wireless sensor networks. <em>COMCOM</em>,
<em>151</em>, 172–182. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Data storage Model has been the significant research due to some issues of traffic and attacking systems, and there are numerous methodologies has been communicated about for the effect of data storage and data distributions, but suffer from the exactness and time complicated issues. We propose a novel approach which performs Data Consistency Matrix Based Data Processing Model of routes utilizing with which a correct neighbor node will be chosen. The proposed technique keeps up log about the traffic design at each time window for every data distribution focuses. We assess the attack design at every connection point at each time outline utilizing for which the route matrix factor will be assumed for each route accessible for different goal from a beginning stage. The strategy keeps up various data about the distributed system like the number of connection focuses, then some concerns at every connection point and the separation between the nodes link concentrates, and the amount of nodes goes through the network. Every one of these components is utilized to process the data distribution factor at specific node channel at any period. Given listed data storage factor, we prepare the storage time in every way at various time window to choose the single route to achieve any destination in the network. The proposed approach has created productive outcomes in data storage and data processing model in the system.},
  archive      = {J_COMCOM},
  author       = {Gokulraj J. and Senthilkumar J. and Suresh Y. and Mohanraj V.},
  doi          = {10.1016/j.comcom.2019.12.060},
  journal      = {Computer Communications},
  pages        = {172-182},
  shortjournal = {Comput. Commun.},
  title        = {Data consistency matrix based data processing model for efficient data storage in wireless sensor networks},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved 1D-CNNs for behavior recognition using wearable
sensor network. <em>COMCOM</em>, <em>151</em>, 165–171. (<a
href="https://doi.org/10.1016/j.comcom.2020.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Body Sensor Network (BSNs) are wearable sensors with varying sensing, storage, computation, and transmission capabilities. When data is obtained from multiple devices, multi-sensor fusion is desirable to transform potentially erroneous sensor data into high quality fused data. By analyzing and processing the perceived physical activity data of users, they can be provided with services that may be needed. Wearable sensors transmit human acceleration information to the server through 4G network. In this way, online analysis and recognition of human behavior is realized. In this paper, we study on efficiently real-time behavior recognition algorithm using acceleration sensor. We propose a human behavior recognition method based on improved One-Dimensional Convolutional Neural Networks(1D-CNNs). According to the motion characteristics, the eigenvalues are extract which can distinguish the types of activities. At the same time, we propose a sample autonomous learning method, which aims to find the optimal sample training set and avoid over-fitting problems in traditional CNNs. In the recognition of 11 human activities , our method can reach the average accuracy of 98.7\%. Compared with other behavior recognition methods in the same dataset, better classification is achieved by this method.},
  archive      = {J_COMCOM},
  author       = {Zhiou Xu and Juan Zhao and Yi Yu and Haijun Zeng},
  doi          = {10.1016/j.comcom.2020.01.012},
  journal      = {Computer Communications},
  pages        = {165-171},
  shortjournal = {Comput. Commun.},
  title        = {Improved 1D-CNNs for behavior recognition using wearable sensor network},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fair and efficient resource allocation in IEEE 802.11ah WLAN
with heterogeneous data rates. <em>COMCOM</em>, <em>151</em>, 154–164.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For dense wireless LANs (WLANs), IEEE 802.11ah has specified restricted access window (RAW) as the channel access scheme. Here the competing stations (STAs) are divided into groups and STAs belonging to each group attempt to access the channel during their designated RAW slot by invoking the distributed coordination function (DCF) protocol. This paper describes an analytical model to evaluate the throughput performance of IEEE 802.11ah WLAN, when STAs use distinct data rates and the RAW mechanism is implemented for medium sharing. When STAs are grouped randomly (i.e., without considering their data rates), a group will contain STAs operating at distinct data rates. Since all these STAs simultaneously contend for channel access based on DCF protocol, the throughput of high data rate STAs are down-equalized to that of lower data rate STAs; thus the aggregate network throughput is degraded significantly. To resolve the resulting performance anomaly problem, we consider data rate based grouping where STAs operating at the same data rate are grouped together. We describe an algorithm for implementing data rate based grouping at the access point (AP). Further, we describe an analytical procedure to find the network throughput under data rate based grouping. Through numerical and experimental investigations, we establish that data rate based grouping can significantly improve the aggregate network throughput performance, as compared to the conventional random grouping strategy. Further, we use Jain’s fairness index (JFI) to establish that data rate based grouping can also provide fair resource allocation among the STAs operating at distinct data rates, by ensuring that all the competing STAs in the network achieve throughput proportional to their data rates.},
  archive      = {J_COMCOM},
  author       = {U. Sangeetha and A.V. Babu},
  doi          = {10.1016/j.comcom.2019.12.043},
  journal      = {Computer Communications},
  pages        = {154-164},
  shortjournal = {Comput. Commun.},
  title        = {Fair and efficient resource allocation in IEEE 802.11ah WLAN with heterogeneous data rates},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hazard recognition and reliability analysis of CTCS-3
on-board subsystem. <em>COMCOM</em>, <em>151</em>, 145–153. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an investigation of hazard sources identification and reliability sensitivity analysis of CTCS-3 on-board subsystem. Traditional quantitative and qualitative safety and reliability analysis generally used static analysis methods, such as Fault Tree. When device redundancy, dynamic logic and dynamic mechanism are taken into consideration, dynamic analysis methods are preferred, such as Dynamic Fault Tree (DFT). In this paper, the methods of Hazards and Operability (HAZOP), DFT and Monte Carlo Simulation (MCS) are used for quantitative and qualitative analysis. Firstly, to reflect the structure and functions of on-board subsystem, two models (i.e reference model and function hierarchical model) are built. HAZOP is applied to identify hazard sources of on-board subsystem according to above models. Secondly, DFT is put forward within which the top event is CTCS-3 on-board subsystem failure event and the basic events are from results of HAZOP analysis. Then, both MCS and Maximum Likelihood Estimation (MLE) are adopted to estimate the reliability parameters of the CTCS-3 on-board subsystem and components. Reliability sensitivity analysis is observing the variations in components’ reliability parameter contributing to the changes of Mean Time to Failure (MTTF) of CTCS-3 on-board subsystem. Finally, a failure density curve of CTCS-3 on-board subsystem and a table of MTTF sensitivity parameters are presented. According to the sensitivity table, it is knowledgeable for decision makers to take effective measures to improve the reliability of CTCS-3 on-board subsystem.},
  archive      = {J_COMCOM},
  author       = {Lijuan Shi and Liquan Chen},
  doi          = {10.1016/j.comcom.2019.12.025},
  journal      = {Computer Communications},
  pages        = {145-153},
  shortjournal = {Comput. Commun.},
  title        = {Hazard recognition and reliability analysis of CTCS-3 on-board subsystem},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An intelligent swarm based prediction approach for
predicting cloud computing user resource needs. <em>COMCOM</em>,
<em>151</em>, 133–144. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing aimed at offering elastic resource allocation on demand to cloud consumers. Building a cloud resource demand prediction model is a challenging task because cloud consumer’s demand changes over time. Most of the current works in cloud resource demand prediction study the problem from the cloud provider perspective. In this paper, we study the problem from the cloud consumer perspective with the aim to help the consumers to meet their resource needs, derive estimates for the required IT budget, select the best cloud providers, and get better pricing through the advanced reservation of required cloud resources. We develop a new Swarm Intelligence Based Prediction Approach (SIBPA) to predict with higher accuracy the resource needs of a cloud consumer in terms of CPU, memory, and disk storage utilization. The SIBPA is also able to predict the response time and throughput which in turn enables the cloud consumers to make a better scaling decision. It also takes into account the dynamic behavior of consumer requests in a long term period and the seasonal or/and trend patterns in time series. The SIBPA uses the Particle Swarm Optimization (PSO) approach for selecting the best features from the dataset and for estimating the parameters of the prediction algorithms. The experimental results reveal that the prediction accuracy of the SIBPA outperforms the current prediction models. In terms of CPU utilization prediction, the accuracy of SIBPA outperforms the accuracy of the existing cloud consumer prediction frameworks that use Linear Regression, Neural Network , and Support Vector Machines approaches by 56.95\%, 80.42\%, and 63.86\% respectively according to RMSE , and by 72.66\%, 44.24\%, and 56.78\% according to MAPE. The accuracy of SIBPA also outperforms the accuracy of the existing cloud consumer prediction frameworks in terms of response time, throughput, and memory utilization predictions. The analysis and experiment results of SIBPA are discussed in detail in this paper.},
  archive      = {J_COMCOM},
  author       = {Hisham A. Kholidy},
  doi          = {10.1016/j.comcom.2019.12.028},
  journal      = {Computer Communications},
  pages        = {133-144},
  shortjournal = {Comput. Commun.},
  title        = {An intelligent swarm based prediction approach for predicting cloud computing user resource needs},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating and improving the scalability of RPL security in
the internet of things. <em>COMCOM</em>, <em>151</em>, 119–132. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor and Actuator Networks (WSANs) will represent a key building block for the future Internet of Things , as a cheap and easily-deployable technology to connect smart devices on a large scale. In WSAN the Routing Protocol for Low-Power and Lossy Networks (RPL) has a crucial role as the standard IPv6-based routing protocol. RPL specifications define a basic set of security features, without which it would be open to disruptive routing attacks. However, the impact of these features on the WSAN performance has not been thoroughly investigated yet. The contribution of this paper is two-fold. First, we extensively evaluate the impact of security mechanisms on the scalability of WSANs by means of both simulations and real experiments. We show that the protection against eavesdropping and forgery has a modest impact on the performance, whereas the protection against replay has a more considerable impact, especially on the network formation time which increases noticeably. Despite this, we show that protecting against replay reduces the number of control messages exchanged and improves routes optimality . For these reasons, we recommend to always use the security mechanisms. Finally, we propose a standard-compliant optimization for defending against replay that reduces the impact on the overall performance.},
  archive      = {J_COMCOM},
  author       = {Antonio Arena and Pericle Perazzo and Carlo Vallati and Gianluca Dini and Giuseppe Anastasi},
  doi          = {10.1016/j.comcom.2019.12.062},
  journal      = {Computer Communications},
  pages        = {119-132},
  shortjournal = {Comput. Commun.},
  title        = {Evaluating and improving the scalability of RPL security in the internet of things},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient pattern matching algorithm for security and binary
search tree (BST) based memory system in wireless intrusion detection
system (WIDS). <em>COMCOM</em>, <em>151</em>, 111–118. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Intrusion Detection System (WIDS) has been introduced for providing enhanced security level in WLANs, owing to the numerous and potentially devastating threats against it. WIDS are software- or hardware-based. The hardware-based approaches focus on memory efficiency in pattern matching . This paper proposes a pattern matching algorithm called All-Ready State Traversal pattern matching algorithm. This algorithm constructs the state traversal machine with 1280 bytes size, and enables users to store large sized string patterns in the pattern database. The state traversal machine facilitates the easy retrieval of these patterns through the path vector. Further, the proposed work also follows a number of basic ASCII characters with 128 bytes size; and designs the memory architecture using Binary Search Tree (BST) structure. The hardware generates the addresses of input strings. State traversal machine and bits split algorithms are used to merge together the common addresses of input strings. The merged addresses are encrypted and decrypted by Blowfish algorithm to allow the valid packets and to discard the invalid packets using WIDS. Thus, the proposed algorithm provides a significant reduction in memory usage than that of Aho–Corasick algorithm.},
  archive      = {J_COMCOM},
  author       = {P. Suresh and R. Sukumar and S. Ayyasamy},
  doi          = {10.1016/j.comcom.2019.11.035},
  journal      = {Computer Communications},
  pages        = {111-118},
  shortjournal = {Comput. Commun.},
  title        = {Efficient pattern matching algorithm for security and binary search tree (BST) based memory system in wireless intrusion detection system (WIDS)},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RETRACTED: An assessment of software defined networking
approach in surveillance using sparse optimization algorithm.
<em>COMCOM</em>, <em>151</em>, 98–110. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article has been retracted: please see Elsevier Policy on Article Withdrawal ( https://www.elsevier.com/about/our-business/policies/article-withdrawal ). This article has been retracted at the request of Dr. Rathish Babu, corresponding author of article titled “An assessment of software defined networking approach in surveillance using sparse optimization algorithm” in Computer Communications in Volume 151, 1 February 2020, Pages 98-110. Me, my co-authors along with other friends (Ms.Kalaiyarasi and Dr.Perumal) worked on SAR Images. Without knowledge, we uploaded the article in Computer Communications journal and our friends uploaded in Springer journal (Arabian journal of Geoscience). Unknowingly, both got published at the same time, in this regard we would like to retract our article titled “An assessment of software defined networking approach in surveillance using sparse optimization algorithm” in Computer Communications Volume 151, 1 February 2020, Pages 98-110.The springer paper https://doi.org/10.1007/s12517-019-4900-4 has different title and co-authors but shows\%63 verbatim textual overlap with this article.},
  archive      = {J_COMCOM},
  author       = {T.K.S Rathish Babu and N.M. Balamurugan and S. Suresh and L. Sharmila},
  doi          = {10.1016/j.comcom.2019.12.061},
  journal      = {Computer Communications},
  pages        = {98-110},
  shortjournal = {Comput. Commun.},
  title        = {RETRACTED: An assessment of software defined networking approach in surveillance using sparse optimization algorithm},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wearable exercise electrocardiograph signal quality
assessment based on fuzzy comprehensive evaluation algorithm.
<em>COMCOM</em>, <em>151</em>, 86–97. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable ECG (Electrocardiograph) technology is an effective method for real-time monitoring of human ECG. According to the consistency of the wearable ECG continuous detection in time, the effective filtering estimation method can solve the problem of large motion ECG interference and data loss. In this paper, the detection principle of ECG signals in wearable monitoring and treatment system is analyzed, and the characteristics of ECG waveform and each band are described. The characteristics of the ECG signal and several major noise signals that need to be suppressed are analyzed. Based on the comprehensive analysis of the indicator set of ECG signal quality, a signal quality evaluation model based on fuzzy comprehensive evaluation is proposed. The model can comprehensively evaluate the quality of ECG signals and accurately reflect the signal quality. In addition, a model of exercise heart rate estimation based on signal quality assessment and Kalman filter is presented, and the method of obtaining the best heart rate estimation is analyzed. Through the actual test, the model is proved to have high reliability and effectiveness, and the heart rate estimation can be accurately performed under various motion states.},
  archive      = {J_COMCOM},
  author       = {Jiajie He and Dunbo Liu and Xiaoyang Chen},
  doi          = {10.1016/j.comcom.2019.12.051},
  journal      = {Computer Communications},
  pages        = {86-97},
  shortjournal = {Comput. Commun.},
  title        = {Wearable exercise electrocardiograph signal quality assessment based on fuzzy comprehensive evaluation algorithm},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Experimental research on real-time acquisition and
monitoring of wearable EEG based on TGAM module. <em>COMCOM</em>,
<em>151</em>, 76–85. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-term sleep disorders can reduce the body’s immunity, induce various diseases, and seriously endanger human health Multi-conducting EEG (Electroencephalogram) sleep monitoring is the gold standard for evaluating the quality of sleep all night. However, this method is professional and complicated, and it is difficult to apply to daily sleep monitoring. This paper first designed a wearable EEG acquisition system based on TGAM module. ‘Through the parameter initialization setting of the TGAM module and the Bluetooth module and the analysis of the communication protocol between the modules, the wearable EEG acquisition system was successfully built. Secondly, the extraction of different rhythm waves of EEG signals is realized by several FIR (Finite Impulse Response) bandpass filters . Principal component analysis was used to screen feature quantities. The related experiments were carried out by collecting the EEG signals of several testers through the new sensor TGAM. Finally, event-related potential analysis and event-related simultaneous analysis were used to complete the treatment of EEG segments and normal EEG segments of sleep apnea events, and normalized EEG was identified by normalized standard deviation analysis and triple normalized standard deviation analysis. The results show that the technical requirements of wearable EEG equipment can be met in terms of algorithm calculation and result performance, which can provide theoretical support for sleep monitoring.},
  archive      = {J_COMCOM},
  author       = {Liyong Yin and Chao Zhang and Zhijie Cui},
  doi          = {10.1016/j.comcom.2019.12.055},
  journal      = {Computer Communications},
  pages        = {76-85},
  shortjournal = {Comput. Commun.},
  title        = {Experimental research on real-time acquisition and monitoring of wearable EEG based on TGAM module},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trust management scheme to secure mobile information
centric networks. <em>COMCOM</em>, <em>151</em>, 66–75. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Named Data Networks (NDN) or Information Centric Networks (ICN) are being replaced by point-point procedures in order to ensure a reliable and efficient communication mechanism. The efficient benefits of ICN in terms of improved reliability, efficiency and fast information delivery lifted it as a highly capable interconnected networking form for Internet infrastructure. Smart devices in Mobile Internet of Things (MIoT) and ICN contribute towards exponential growth of technical firms by ensuring reliability, efficiency and availability. Though NDN architectures ensure a secure data communication, however, in order to gain their own benefits, the expert intruders may compromise routers (nodes) and their routing tables. Therefore, in order to ensure a secure communication through MIoT , any modification in stored data of these devices (routers) must be transparently reflected to remaining entities in the network. Recently, trust is proposed as an alternative security measure to secure content delivery within ICN. However, only few of these solutions focused on identifying the legitimacy of the devices. In this paper, we proposed a novel ICN approach to compute the legitimacy of MIoT devices/routers/nodes and routing paths information using trust based on a wide range of real-life parameters including energy consumption while transferring the data from source to destination, message delivery to preceding or succeeding nodes and distance among two devices to identify Denial of Service (DoS), Distributed Denial of Service (DDoS) or Man-in-The-Middle (MiTM) attacks. The proposed solution is evaluated rigorously over various networking parameters such as distance among the devices, energy consumption, information loss while transferring the data and so on. Further, the extensive simulation results of proposed mechanism leads to 94\% efficiency in terms of better response time, lower authentication delays and request ratios from fake nodes.},
  archive      = {J_COMCOM},
  author       = {Geetanjali Rathee and Ashutosh Sharma and Rajiv Kumar and Farhan Ahmad and Razi Iqbal},
  doi          = {10.1016/j.comcom.2019.12.024},
  journal      = {Computer Communications},
  pages        = {66-75},
  shortjournal = {Comput. Commun.},
  title        = {A trust management scheme to secure mobile information centric networks},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of SDN for secure communication in IoT
environment. <em>COMCOM</em>, <em>151</em>, 60–65. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) allows global connectivity to remote smart devices. This technology includes sensing, communication and handling of real-time data received from billions of connected devices with negligible human interference. The constraints related to IoT devices are limited memory, low processing ability and also battery based processes which makes them exposed to different attacks. These attacks are not restricted to Denial of Service (DOS), Man-in-Middle (MIM), Sybil and flooding attacks. Security turns out to be the main criteria to interact with the physical world, particularly in safety-critical applications in the field of health, defence, automobiles etc.  In order to prevent the loss of transmitted packet data, a genuine secure communication process with AESCQTT (Advanced Encryption Standard Constrained Queuing Telemetry Transport Protocol) for IoT devices is established. It provides electronic data protection and used to block Network and Application Level Vulnerabilities. The CoAP functions over TLS with minimal overhead for communications and offer reduced power supplies. If any collision occurs in the message transmission Software-defined networking (SDN) can solve problems like resource availability, virtualization and network security . The entire AESCQTT communication is encrypted using TLS rather than plain TCP which it evades bad attribute and script XSS Command.},
  archive      = {J_COMCOM},
  author       = {Rajeesh Kumar N.V. and Mohan Kumar P.},
  doi          = {10.1016/j.comcom.2019.12.046},
  journal      = {Computer Communications},
  pages        = {60-65},
  shortjournal = {Comput. Commun.},
  title        = {Application of SDN for secure communication in IoT environment},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A detection mechanism on malicious nodes in IoT.
<em>COMCOM</em>, <em>151</em>, 51–59. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing scale of the Internet of Things (IoT) makes systems vulnerable to serious security threats, especially when the attacks of malicious nodes exist in these networks. Different malicious nodes will launch different attacks, but most of them are based on tampering, re-transmission, and discarding methods. For such attacks, an effective method to detect malicious nodes focuses on the received and sent messages of each node. However, gathering messages about each node in the network is time-consuming, as well as collecting all the message in the network would consume the limited resources in the IoT. In this paper, we propose a novel method to detect malicious nodes based on an online learning algorithm . We first calculate the credibility of each path in the network based on the collected packets., then modeled the got path reputation by the online learning algorithm , finally, calculated the trust of each node in the IoT environment and detected the malicious node by a clustering algorithm . To make the model have a good performance when the network scale is small, we perform some processing on the network topology based on the general online learning detection algorithm and get an enhanced online learning detection algorithm . The result of the experiment proves that the methods we proposed can detect malicious nodes with high accuracy and work well with good stability.},
  archive      = {J_COMCOM},
  author       = {Bohan Li and Renjun Ye and Gao Gu and Ruochen Liang and Wei Liu and Ken Cai},
  doi          = {10.1016/j.comcom.2019.12.037},
  journal      = {Computer Communications},
  pages        = {51-59},
  shortjournal = {Comput. Commun.},
  title        = {A detection mechanism on malicious nodes in IoT},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge intelligence based economic dispatch for virtual power
plant in 5G internet of energy. <em>COMCOM</em>, <em>151</em>, 42–50.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, with a large of complicated geography of Distributed Energy Sources (DES), how to integrate distributed renewable energy source and reduce the operational costs by Virtual Power Plant (VPP) becomes a mainstream problem in Internet of energy. The traditional method of energy integration and operational cost optimization utilizes the cloud computing technology to centralized control the computational task, which increases the burden of computing. According with the development of information communication technology, such as Internet of Things and 5G , edge computing technology is an effective way to offload computational task to the edge side of 5G networks. Moreover, with the increase of collected data, it becomes a key point to effectively improve the computing power of edge nodes in edge computing . Currently, machine learning is an effective way to process the big data. Based this situation, it leads the combination of machine learning and edge computing. In this paper, the Edge Intelligence (EI) structure is proposed to solve the Economic Dispatch Problem (EDP) in VPP of Internet of Energy. Compared with the traditional edge computing, the proposed EI structure inherits its original features which reduce the burden of cloud computing , and also the proposed EI structure improves the computational power of edge computing. Through the splitting model and deploying the particle model in the terminal, it is facility to real-time control and take the less costs of VPP. Due to the transmission between the splitting models with counterpart, it transmits the part information and gradient information , which effectively reduces the consumption of communication. The proposed method has verified the effectiveness and feasibility through the numerical experiments of real application data sets.},
  archive      = {J_COMCOM},
  author       = {Dawei Fang and Xin Guan and Lin Lin and Yu Peng and Di Sun and Mohammad Mehedi Hassan},
  doi          = {10.1016/j.comcom.2019.12.021},
  journal      = {Computer Communications},
  pages        = {42-50},
  shortjournal = {Comput. Commun.},
  title        = {Edge intelligence based economic dispatch for virtual power plant in 5G internet of energy},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent manufacturing production line data monitoring
system for industrial internet of things. <em>COMCOM</em>, <em>151</em>,
31–41. (<a href="https://doi.org/10.1016/j.comcom.2019.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying the wireless sensor network of the Industrial Internet of Things and the radio frequency identification technology to the production workshop of the discrete manufacturing industry, the real-time status of the shop floor can be automatically collected, providing a powerful decision-making basis for the upper-level planning management department. This paper proposes a reference architecture and construction path for smart factories by analyzing industrial IoT technology and its application in manufacturing workshops. Combined with the analysis of the status quo and needs of the discrete manufacturing enterprise workshop, this paper designs the overall architecture and theoretical model of the system. In view of the variety of on-site manufacturing data, large amount of data, variable status, heterogeneity, and strong correlation between data, integrated key technologies such as WSN and RFID, the industrial IoTs solution for manufacturing workshops is given. The multi-thread data real-time collection, storage technology and product tracking monitoring of the workshop are studied. Finally, the performance of the system is analyzed from the perspective of real-time and quality. The results show that the system is effective in the monitoring of production line data.},
  archive      = {J_COMCOM},
  author       = {Wei Chen},
  doi          = {10.1016/j.comcom.2019.12.035},
  journal      = {Computer Communications},
  pages        = {31-41},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent manufacturing production line data monitoring system for industrial internet of things},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Task number maximization offloading strategy seamlessly
adapted to UAV scenario. <em>COMCOM</em>, <em>151</em>, 19–30. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) has been proposed in recent years to process resource-intensive and delay-sensitive applications at the edge of mobile networks, which can break the hardware limitations and resource constraints at user equipment (UE). In order to fully use the MEC server resource, how to maximize the number of offloaded tasks is meaningful especially for crowded place or disaster area. In this paper, an optimal partial offloading scheme POSMU (Partial Offloading Strategy Maximizing the User task number) is proposed to obtain the optimal offloading ratio, local computing frequency, transmission power and MEC server computing frequency for each UE. The problem is formulated as a mixed integer nonlinear programming problem (MINLP), which is NP-hard and challenging to solve. As such, we convert the problem into multiple nonlinear programming problems (NLPs) and propose an efficient algorithm to solve them by applying the block coordinate descent (BCD) as well as convex optimization techniques. Besides, we can seamlessly apply POSMU to UAV (Unmanned Aerial Vehicle) enabled MEC system by analyzing the 3D communication model. The optimality of POSMU is illustrated in numerical results, and POSMU can approximately maximize the number of offloaded tasks compared to other schemes.},
  archive      = {J_COMCOM},
  author       = {Qiang Tang and Lu Chang and Kun Yang and Kezhi Wang and Jin Wang and Pradip Kumar Sharma},
  doi          = {10.1016/j.comcom.2019.12.018},
  journal      = {Computer Communications},
  pages        = {19-30},
  shortjournal = {Comput. Commun.},
  title        = {Task number maximization offloading strategy seamlessly adapted to UAV scenario},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Improvement and implementation of wireless network topology
system based on SNMP protocol for router equipment. <em>COMCOM</em>,
<em>151</em>, 10–18. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the continuous expansion of computer network scale and the diversity of network equipment, the traditional single computer network maintenance and management method is no longer applicable. Therefore, in order to achieve efficient and accurate management of computer networks and ensure the stable operation of computer networks in various applications, computer network management software with superior performance and corresponding topology discovery technology become the key. In this paper, SNMP (Simple Network Management Protocol) network topology discovery algorithm is deeply analyzed in the laboratory computer network environment, and its shortcomings are pointed out. In view of the shortcomings of traditional SNMP algorithm, this algorithm is optimized and improved, and helps ICMP (Internet Control Message Protocol) detect the internal subnet, so as to discover the main network topology accurately and efficiently. In order to solve the heterogeneity of information storage modes in MIB (Management Information Base) libraries of different devices in laboratory network environment, this paper innovatively adds an optimized SNMP algorithm aiming at the heterogeneity of network devices, thus realizing the universality of network topology. Finally, the experiments show that the time dissipation of the proposed algorithm is less than 10 data points compared with the traditional algorithm under the same experimental conditions. The laboratory network environment based on the proposed system can achieve a fast and smooth laboratory network, which has obvious advantages compared with the traditional network management system .},
  archive      = {J_COMCOM},
  author       = {Hao Wang},
  doi          = {10.1016/j.comcom.2019.12.038},
  journal      = {Computer Communications},
  pages        = {10-18},
  shortjournal = {Comput. Commun.},
  title        = {Improvement and implementation of wireless network topology system based on SNMP protocol for router equipment},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual-load bloom filter: Application for name lookup.
<em>COMCOM</em>, <em>151</em>, 1–9. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a simple probabilistic data structure , a Bloom filter consumes a small amount of memory in efficiently dealing with a large set of data elements. Bloom filters stored in on-chip memories have been popularly used as pre-filters to minimize unnecessary off-chip memory accesses. This paper proposes an interesting variant of a Bloom filter, the dual-load Bloom filter (DLBF) and shows that the proposed DLBF can be effective for implementing a name lookup algorithm. While Bloom filters usually hold a single type of information, which is either the membership in a given set or the return values of elements, the proposed DLBF holds both the membership and the return values in a single Bloom filter. As one of the trie-based name lookup algorithms developed for named data networking, a path-compressed trie compresses each path in a name prefix trie by removing empty nodes with a single child. This type of trie should be designed to hold skip values to represent the numbers of removed nodes in addition to the name prefixes stored in each node. This paper shows that the proposed DLBF can hold the skip values and the name prefixes to implement a path-compressed trie in an on-chip memory. Simulation results show that the proposed name lookup structure improves search performance by 33\% using a much smaller amount of memory than previous Bloom filter-based structures.},
  archive      = {J_COMCOM},
  author       = {Jungwon Lee and Hayoung Byun and Hyesook Lim},
  doi          = {10.1016/j.comcom.2019.12.029},
  journal      = {Computer Communications},
  pages        = {1-9},
  shortjournal = {Comput. Commun.},
  title        = {Dual-load bloom filter: Application for name lookup},
  volume       = {151},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on wired/wireless internet communications
conference (IFIP WWIC 2017). <em>COMCOM</em>, <em>150</em>, 841–842. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COMCOM},
  author       = {Kaushik Roy Chowdhury ( Guest Editors ) and Marco Di Felice and Ibrahim Matta and Bo Sheng},
  doi          = {10.1016/j.comcom.2019.12.007},
  journal      = {Computer Communications},
  pages        = {841-842},
  shortjournal = {Comput. Commun.},
  title        = {Special issue on Wired/Wireless internet communications conference (IFIP WWIC 2017)},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A non-cooperative rear-end collision avoidance scheme for
non-connected and heterogeneous environment. <em>COMCOM</em>,
<em>150</em>, 828–840. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rear end collisions are deadliest in nature and result in life losses and severe injuries. Many of the proposed rear-end collision avoidance schemes focus only on specific aspects without considering several non-direct factors, such as driver inattention or distraction, tailgating, panic stops, street surface circumstances, driver response time, person on foot stream and vehicle elements. Henceforth presenting greater challenges in proposing a precise numerical model of the vehicle control framework. Moreover, most collision avoidance schemes incorporate fuzzy logic for formulating human inspired collision avoidance controllers. But the problem with a fuzzy based controller is that their efficiency is greatly affected by the number of rules being deployed. Furthermore, no such agent-based modeling has been utilized, which can effectively model the human-inspired behavior. Literature is full of vehicle control frameworks that work in a connected and homogeneous environment, again critics have raised several questions for such frameworks working in a connected environment. This study aims not only to identify these key issues but also propose a human-inspired physics based Spiral Spring based Simple Reflex Agent for rear end collision avoidance. Our scheme will not only work in the non-connected and heterogeneous environment but will also consider the distraction causing road factors and effectively handle them. Extensive experimentations and presentation for the proof of concept have supported our claims and worthiness of proposed agent-based scheme.},
  archive      = {J_COMCOM},
  author       = {Sania Khadim and Faisal Riaz and Sohail Jabbar and Shehzad Khalid and Moayad Aloqaily},
  doi          = {10.1016/j.comcom.2019.11.002},
  journal      = {Computer Communications},
  pages        = {828-840},
  shortjournal = {Comput. Commun.},
  title        = {A non-cooperative rear-end collision avoidance scheme for non-connected and heterogeneous environment},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deployment and integration of smart sensors with IoT devices
detecting fire disasters in huge forest environment. <em>COMCOM</em>,
<em>150</em>, 818–827. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surveillance system applications are drastically growing from small buildings to a wide area of forest monitoring. Forests provide various important things to our daily lives like oxygen, honey. Living things like animals and birds are living in forests. Thus, it is essential to monitor and protect the forests and their assets. To do that, smart sensors have been deployed in the forest to monitor and record the environmental impacts. The abnormal events are identified and detected using the appropriate IoT devices to reduce the risk. Also, to improve the accuracy, the sensed data is analyzed, processed using a software module. Various existing approaches used for learning the data and object detection was good, but slow in the process, which fails in reducing risks. To overcome these issues, this paper utilizes one of the Deep Learning Algorithms such as the Convolution Neural Network (CNN) for Forest Monitoring and identifying the abnormality. The deep CNN has experimented with MATLAB software and the results are verified. The performance of deep CNN is evaluated by comparing the obtained results with the existing approaches and found that deep CNN outperforms the others.},
  archive      = {J_COMCOM},
  author       = {Fengmei Cui},
  doi          = {10.1016/j.comcom.2019.11.051},
  journal      = {Computer Communications},
  pages        = {818-827},
  shortjournal = {Comput. Commun.},
  title        = {Deployment and integration of smart sensors with IoT devices detecting fire disasters in huge forest environment},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint power and time allocation in energy harvesting of UAV
operating system. <em>COMCOM</em>, <em>150</em>, 811–817. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of UAV (Unmanned Aerial Vehicle) technology, the UAVs have been widely used in various fields. However, due to the limited battery capacity and limitation on weight, a short running time of UAVs is still the main factor limiting the UAV wide application. This problem can be overcome by charging UAVs using energy harvesting technology. However, the existing wireless UAV charging does not consider the joint optimization of time and energy consumption. Thus, in this paper, we propose the optimal time and power allocation of the energy harvesting of UAV. The base station is used to power the UAV, and UAV processes user tasks using the acquired wireless energy. Specifically, we define the optimization problem of minimum energy consumption of UAV under wireless charging. In order to solve this problem, we give the optimal time and power allocation of UAV by using the Lagrange multiplier and KKT conditions. The experimental results show that the proposed scheme is superior to the traditional scheme.},
  archive      = {J_COMCOM},
  author       = {Qiang Liu and Miao Li and Jun Yang and Jing Lv and Kai Hwang and M. Shamim Hossain and Ghulam Muhammad},
  doi          = {10.1016/j.comcom.2019.12.009},
  journal      = {Computer Communications},
  pages        = {811-817},
  shortjournal = {Comput. Commun.},
  title        = {Joint power and time allocation in energy harvesting of UAV operating system},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Secure data transmission and detection of anti-forensic
attacks in cloud environment using MECC and DLMNN. <em>COMCOM</em>,
<em>150</em>, 799–810. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anti-forensics is a set of techniques and measures adopted by an attacker aimed at compromising the digital investigation process in a computational environment. Cloud computing , which is an environment providing on demand resources to users, is susceptible to anti-forensic attacks. An anti-forensic attacker in the cloud can influence the cloud forensic process and tamper with evidences, causing damage to the investigation. Though some solutions have been proposed against anti-forensic attacks in cloud, there is a need to secure the evidences while in transit as well as in storage. In this work, we propose efficient algorithms for secure data (evidence) transmission and early detection of Anti-Forensic Attack (AFA). First, the data packets are compressed using a B-tree Huffman Encoding (BHE) algorithm; next, the packet marking technique is implemented to secure the IP address of the sender. For securely sending the data, we propose the Modified Elliptic curve cryptography (MECC) algorithm which encrypts the data packets and transmits it to a receiver. At the receiver side, the training is done using a Deep Learning Modified Neural Network (DLMNN) classifier, which tests the received data packet IP-address. Based on the IP-address of the sender, DLMNN identifies whether the received packet is an packet attacked or a non-attacked one. After the identification of the data packets, the decryption and de-compression of non-attacked data packets are done to obtain the original information. The original evidence information is further analyzed for investigation purposes. Experimental results shown by the proposed method are weighed against the prevailing techniques for performace comparison.},
  archive      = {J_COMCOM},
  author       = {Deevi Radha Rani and G. Geethakumari},
  doi          = {10.1016/j.comcom.2019.11.048},
  journal      = {Computer Communications},
  pages        = {799-810},
  shortjournal = {Comput. Commun.},
  title        = {Secure data transmission and detection of anti-forensic attacks in cloud environment using MECC and DLMNN},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New insights on ground control in intelligent mining with
internet of things. <em>COMCOM</em>, <em>150</em>, 788–798. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conception of Smart city has been gaining momentum in recent years. Coal mines as a part of city should be characterized with smart or intelligent features. Production and safety are two major themes in coal mining . With the development of automation, Internet of Things (IoT), big data, artificial intelligence , and cloud computing in Fourth Industrial Revolution, Intelligence Mining has been put forward by Chinese Academy of Engineering to achieve the goal of unmanned workface production. However, safety is not highlighted in the novel idea. In this paper, ground control in intelligent mining with IoT is studied. An architecture of ground control with IoT is proposed. The previous research on theoretical modeling and on-site monitoring methods are reviewed. Then the IoT based ground control method is proposed. An on-going dynamic platform on ground control are proposed based on our research of nondestructive testing (NDT) on rock bolt anchorage quality assessment. The research progress is introduced with equipment introduction, principles, and an on-site experiment. Future developments on combination of NDT and IoT of ground control is discussed. The ideas, frameworks, and results in this paper can make efforts on safety control and spark new ideas in the much-anticipated Intelligence Mining.},
  archive      = {J_COMCOM},
  author       = {Yang Hao and Yu Wu and Ranjith P.G. and Kai Zhang and Houquan Zhang and Yanlong Chen and Ming Li and Pan Li},
  doi          = {10.1016/j.comcom.2019.12.032},
  journal      = {Computer Communications},
  pages        = {788-798},
  shortjournal = {Comput. Commun.},
  title        = {New insights on ground control in intelligent mining with internet of things},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Safety and security measurement in industrial environment
based on smart IOT technology based augmented data recognizing scheme.
<em>COMCOM</em>, <em>150</em>, 777–787. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safety and Environment assume a massive part of the industry to avoid accidental losses. In this manner, it is essential to screen the industrial condition routinely. The modern networking innovations have enhanced for Human-to-Human associations as opposed to Machine-to-Machine correspondence. Internet of things (IoT) means to extend the Internet to numerous gadgets by describing standard interoperable correspondence traditions. This work proposes a system design using wireless sensor network in augmented data recognizing (ADR) algorithm, in which each hub is containing the computational stage which wires particular mechanical parameters. The consider data has transmitted through WIFI to Central BEAGLEBK controller server which joins the data from various sensor network hubs, standard edge readings and sets the primary cautions if there should arise an occurrence of infringement of safety in masters. WIFI fills in as a spine for correspondence between beagle bone and the sensor hub. This work clears up entire hardware and programming parts of the structure which gives the like watching and announcing of the business safety association system using augmented data recognizing technique.},
  archive      = {J_COMCOM},
  author       = {Rajmohan Palanivelu and Srinivasan P.S.S.},
  doi          = {10.1016/j.comcom.2019.12.013},
  journal      = {Computer Communications},
  pages        = {777-787},
  shortjournal = {Comput. Commun.},
  title        = {Safety and security measurement in industrial environment based on smart IOT technology based augmented data recognizing scheme},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spread spectrum hop count analyzing technique based
code-division multiple access for data frequencies examining in wireless
network. <em>COMCOM</em>, <em>150</em>, 771–776. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code-division multiple access (CDMA) is a bandwidth access technique used by different radio waves and signal advancements. CDMA is a way of providing multiple access, where transmitters can send data at the same time, where a single clock channel can be completed. It enables us to share data frequencies with a few systems (refer to the data transfer and capacity). From the multiple backward spaces allow this CDMA uses a wide range of novelty innovation and exceptional coding scheme (where each transmitter is allocated code). In this work, the different application of the Spread Spectrum Hop Count Analyzing Technique (SSHCA–CDMA) is presented which organizes information testing techniques to create accessible assessment data, with the ultimate goal of providing the most efficient techniques for execution improvement thinking. The underlying area of eligibility testing and the evaluation of metadata inquiry are the expectation space, the data that select the most effective regulatory function. Similarly, in this work, master-based techniques have been demonstrated to validate and analyze SSHCA cells. Long, most recent developments have retained a perspective and the nature of customer correspondence management.},
  archive      = {J_COMCOM},
  author       = {N. Mohan},
  doi          = {10.1016/j.comcom.2019.12.010},
  journal      = {Computer Communications},
  pages        = {771-776},
  shortjournal = {Comput. Commun.},
  title        = {Spread spectrum hop count analyzing technique based code-division multiple access for data frequencies examining in wireless network},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software defined networking approach based efficient routing
in multihop and relay surveillance using lion optimization algorithm.
<em>COMCOM</em>, <em>150</em>, 764–770. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Networks (WN) are widely employed in numerous real time applications in almost all the domains such as healthcare, remote monitoring, object tracking, security and surveillance based applications etc. The inexpensive nature of wireless sensors make it so popular and the major issue being faced by WN is the energy efficiency. The existing literature presents numerous solutions to guarantee energy efficiency, however the optimal energy efficient solutions are still in demand. Software Defined Networking (SDN) provide a hopeful resolution in bendy supervision WSNs by allowing the separation of the control logic from the sensor nodes/actuators. The advantage with this SDN-based supervision in structure of WSNs is that it enables centralized control of the entire WSN making it simpler to deploy network-wide management protocols and applications on demand This paper proposes a hierarchical cluster based routing scheme by employing Lion Optimization (LO) algorithm. The sensor nodes are clustered by means of LO algorithm and routes are established to transmit data. This performance of this work is analysed in terms of packet delivery rate, average latency , energy consumption and network lifetime. The proposed approach proves better results when compared to the existing approaches. Finally Quality of Services (QoS) of network is increased with SDN based routing optimization of proposed approach.},
  archive      = {J_COMCOM},
  author       = {P. Srinivasa Ragavan and K. Ramasamy},
  doi          = {10.1016/j.comcom.2019.11.033},
  journal      = {Computer Communications},
  pages        = {764-770},
  shortjournal = {Comput. Commun.},
  title        = {Software defined networking approach based efficient routing in multihop and relay surveillance using lion optimization algorithm},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of things transmission and network reliability in
complex environment. <em>COMCOM</em>, <em>150</em>, 757–763. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the realization of the Internet of Things from theory to practical application, the work of ensuring high reliability of the system has become the key to system design, and it is also the obstacle to further promotion of the Internet of Things . This paper makes an in-depth study on the Internet of Things transmission and network reliability in complex environments. In this paper, we use the artificial bee colony algorithm to get the shortest path analysis of each cluster head node . The simulation results show that the algorithm proposed in this paper can effectively reduce the amount of data transmitted to sink by the sensor nodes through cluster head node fusion, improve the efficiency of data collection, energy consumption balance and network reliability, and extend the network life cycle. In addition, the index model of Internet of things reliability index system is established, and the comprehensive evaluation method of using the index is explained. The simulation results show that the proposed algorithm reduces the amount of data transmission and network energy consumption, prolongs the network life cycle, improves the efficiency of data fusion and data transmission reliability. Aodv-sms (abc-pso) routing recovery protocol shows that compared with other routing recovery strategies, packet transmission delay time is less, and the gap between them is more and more large; aiming at the end-to-end reliability and the network capacity, the paper focuses on the analysis of the impact of the change of communication link on the network capacity under the mobile node.},
  archive      = {J_COMCOM},
  author       = {Yi Lyu and Peng Yin},
  doi          = {10.1016/j.comcom.2019.11.054},
  journal      = {Computer Communications},
  pages        = {757-763},
  shortjournal = {Comput. Commun.},
  title        = {Internet of things transmission and network reliability in complex environment},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on position correction method for AUV large depth
navigation based on ranging positioning. <em>COMCOM</em>, <em>150</em>,
747–756. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous Underwater Vehicle (AUV) is an important carrier for studying the ocean. AUV’s accurate navigation and positioning capabilities are most important in ocean exploration. Due to the limitation of communication, the limitation of cost, and the limitation of beacon use conditions, the navigation and positioning of AUV still rely on the sensor equipped with its own dead reckoning algorithm. In the deep sea, Extended Kalman Filtering(EKF), Unscented Kalman Filtering(UKF), and Adaptive Kalman Filtering(AKF) all produce error divergence in navigation and positioning. The article adopted the acoustic-based ranging and positioning method to analyze the error under different conditions, accurately compensate the error in the dead reckoning , and finally improve the navigation and positioning accuracy. Considering the controllability and observability of AUV during ranging positioning, the article proved the stability of AUV model. The article also explained the observability and selection of paths in the ranging and positioning methods to ensure the observability of AUV. The simulation results showed that compared with the dead reckoning method using Kalman filter, the method of introducing ranging location is effective and feasible. The article considered the direction and size of the actual current, and verifies the effectiveness of the method under different conditions. The article considered the divergence of the dead reckoning error and explores the optimal path size at different depths to better obtain the actual AUV motion position. The article also discussed the research that can be done in the future. In the practical application of underwater robots , the article proposed a solution to the inaccuracy of navigation and positioning in the case of large diving depth. The results of the article have practical application value.},
  archive      = {J_COMCOM},
  author       = {Lanyong Zhang and Lei Liu and Lei Zhang},
  doi          = {10.1016/j.comcom.2019.11.038},
  journal      = {Computer Communications},
  pages        = {747-756},
  shortjournal = {Comput. Commun.},
  title        = {Research on position correction method for AUV large depth navigation based on ranging positioning},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel high speed low latency column bit compressed MAC
architecture for wireless sensor network applications. <em>COMCOM</em>,
<em>150</em>, 739–746. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Network (WSN) provides significant challenges for application such as distributed control and digital signal processing . Multiply-Accumulate Unit (MAC) plays a significant role in kernel computation which determines the speed and power factor of entire system. Constructing low power and high speed MAC is very critical to utilize VLSI technologies in WSN. This research work concentrates on fast, low power and reduced delay based Low Latency Column Bit Compressed (LLCBC) MAC. This proposed MAC design based on binary stacking counter is designed for optimizing delay, power, area and hardware complexities. Increased operational speed is attained by performing 6:3 and 7:3 binary stacking counters with higher column indeed of conventional full adder. The proposed method is simulated using cadence environment, in which superior outcomes are attained. The parameters such as Area, Cells, leakage power (nW), Dynamic Power (nW), Total Power (nW) and Delay (ps) are evaluated. For instance, in 16 bit, the proposed (LLCBC) MAC consumes 14.4\% Area, 17.5\% Total Power and 46.2\% Delay with respect to maximum value among all MAC units compared. The proposed architecture is simulated, synthesized and place &amp; route is done with 90 nm standard CMOS library using cadence SOC encounter, effectual improvement in terms of Power, Area, and Delay is attained.},
  archive      = {J_COMCOM},
  author       = {Suguna R. and Vimalathithan R.},
  doi          = {10.1016/j.comcom.2019.11.013},
  journal      = {Computer Communications},
  pages        = {739-746},
  shortjournal = {Comput. Commun.},
  title        = {A novel high speed low latency column bit compressed MAC architecture for wireless sensor network applications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Application of image retrieval based on convolutional neural
networks and hu invariant moment algorithm in computer
telecommunications. <em>COMCOM</em>, <em>150</em>, 729–738. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image recognition and retrieval is an important application field of digital image and it has a wide range of application scenarios in the computer telecommunications. Convolutional neural networks (CNN) is a kind of feed-forward neural networks which includes convolution calculation and which has a deep structure and it is one of the typical algorithms of deep learning . In recent years, it has become a highly efficient recognition algorithm which has been widely applied in such fields as pattern recognition and image processing . Its characteristics include few training parameters and strong adaptability. On the other hand, Hu invariant moment algorithm-a conventional algorithm, is also extensively used in various image processing fields due to its simple calculation and high efficiency. This paper analyzes the research background and significance of both CNN and Hu invariant moment algorithm, and introduces their research status. Besides, it also analyzes the results of color-, distance- and weight-based Hu invariant moment algorithm, and compares it with CNN to serve as a theoretical support for better achieving image classification , recognition and retrieval technology.},
  archive      = {J_COMCOM},
  author       = {Zhuang Wu and Shanshan Jiang and Xiaolei Zhou and Yuanyuan Wang and Yuanyuan Zuo and Zhewei Wu and Lei Liang and Qi Liu},
  doi          = {10.1016/j.comcom.2019.11.053},
  journal      = {Computer Communications},
  pages        = {729-738},
  shortjournal = {Comput. Commun.},
  title        = {Application of image retrieval based on convolutional neural networks and hu invariant moment algorithm in computer telecommunications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recursive learning technique for improving information
processing through message classification in IoT–cloud storage.
<em>COMCOM</em>, <em>150</em>, 719–728. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing and accessing distributed information is a prominent requirement for Internet of Things (IoT) in supporting business and consumer applications to improve accessibility. As the volume of information is being stored and processed is hefty, message classification is challenging in a mobile environment. This also results in prolonged processing delays and backlogs. In order to bridge the gap between message classification and request processing, this paper proposes a classification technique that operates on the basis of request-prioritized recursive learning for ease of message identification and service mapping. This learning technique predicts the type of information and its attributes through intensive learning and services them based on priority to minimize retrieval time. The priority of message servicing relies on the error obtained during the learning process. Despite an increasing number of user requests, attributes associated with each are bundled independently to provide an instant response. Prioritization accounts for the minimum number of error states while learning a message with different attributes to curtail prolonged response time. Error in the learning process is evaluated through a numerical analysis for different learning scenarios of the classified messages. The proposed learning-based access and retrieval technique were analyzed using the metrics of request backlogs, response time, caching delay, and the rate of utilization. The results of experiments verified the effectiveness of the proposed technique in terms of minimizing response time, backlogs, and caching delays, and improving utilization.},
  archive      = {J_COMCOM},
  author       = {Amr Tolba and Zafer Al-Makhadmeh},
  doi          = {10.1016/j.comcom.2019.12.001},
  journal      = {Computer Communications},
  pages        = {719-728},
  shortjournal = {Comput. Commun.},
  title        = {A recursive learning technique for improving information processing through message classification in IoT–cloud storage},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A privacy-preserving protocol for efficient nighttime haze
removal using cloud based automatic reference image selection and color
transfer as a service. <em>COMCOM</em>, <em>150</em>, 703–718. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advanced Internet technologies have migrated the people to rejoice a virtual environment known as cloud computing . The user can avail the desired services on a pay-as-you-go model, without worrying about the burden of infrastructure maintenance. However, privacy is one of the major issues in cloud computing. This issue is further widened for highly confidential multimedia data like surveillance images and videos. In the context of cloud based smart multimedia systems , it has been found that due to inconsistent weather conditions, there is a usual requirement of post-processing the captured multimedia for better appearance. However, privacy related concerns are resisting users to move their data to the cloud. One such problem is addressed in this paper, specializing the task of efficient nighttime haze removal using privacy-preserving cloud based automatic reference image selection and color transfer as a service. Different from daytime conditions, nighttime haze image consists of multiple light sources, which makes an ambiguous situation for haze removal. We address this problem by first selecting an appropriate gray image as the reference and then transferring its colors to nighttime haze image. This makes the transformed image a suitable candidate for radiance recovery. The proposed protocol is designed to securely outsource this considerable burden from user end. We accomplish this by first proposing an automatic reference gray image selection method, followed by efficient handling mechanisms for technical challenges arising due to performing color transfer operations securely over cloud. Experimental results and validation demonstrates superiority of the proposed method over state-of-the-art schemes. Security analysis of the proposed protocol is established through a challenge-response game model.},
  archive      = {J_COMCOM},
  author       = {Amitesh Singh Rajput and Balasubramanian Raman},
  doi          = {10.1016/j.comcom.2019.12.022},
  journal      = {Computer Communications},
  pages        = {703-718},
  shortjournal = {Comput. Commun.},
  title        = {A privacy-preserving protocol for efficient nighttime haze removal using cloud based automatic reference image selection and color transfer as a service},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective approach to unmanned aerial vehicle navigation
using visual topological map in outdoor and indoor environments.
<em>COMCOM</em>, <em>150</em>, 696–702. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles are constantly being using in professional activities that require higher precision in navigating and positioning the aircraft during operation. Advanced location technologies such as Global Navigation Satellite System and Real-Time Kinematic are widely used, however, they depend on an area with transmission coverage. In this approach, this article presents a visual navigation methodology based on topological maps. We compared the performance of consolidated classifiers such as Bayesian classifier , k-nearest neighbor, Multilayer Perceptron , Optimal Path Forest and Support Vector Machines (SVM). They are evaluated with attributes returned by last generation resource extractors such as Fourier, Gray Level Co-Occurrence and Local Binary Patterns (LBP). After analyzing the results we found that the combination of LBP and SVM obtained the best values in the evaluation metrics considered, among them, 99.99\% Specificity and 99.98\% Precision in the navigation process. SVM reached 5.49787 s in combination with LBP completes the training in 5.49787 s. Concerning the testing time, SVM achieving 80.91 ms in association with LBP.},
  archive      = {J_COMCOM},
  author       = {Tao Han and Jefferson S. Almeida and Suane Pires P. da Silva and Paulo Honório Filho and Antonio W. de Oliveira Rodrigues and Victor Hugo C. de Albuquerque and Pedro P. Rebouças Filho},
  doi          = {10.1016/j.comcom.2019.12.026},
  journal      = {Computer Communications},
  pages        = {696-702},
  shortjournal = {Comput. Commun.},
  title        = {An effective approach to unmanned aerial vehicle navigation using visual topological map in outdoor and indoor environments},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel motion detecting strategy for rehabilitation in
smart home. <em>COMCOM</em>, <em>150</em>, 687–695. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the flourish in research and development efforts towards clinical rehabilitation systems in smart home applications . One of the most prior is that such systems are needed to provide real-time motion information about patients. In this paper, a motion detecting approach is proposed for efficiently understanding the human movement on the foundation of the Internet of Things (IoT) based architecture. Specifically, the detection algorithm is based on the fuzzy neural network (FNN), which learns to detect the variation among different gait phases. The moving phases as well as the instability of the tester are identified for recognition. On the tasks of identifying the subject motion using wearable sensing devices, this model achieves a significant high accuracy. Experimental results prove that the system is feasible for application designs and could be implemented on technological platforms.},
  archive      = {J_COMCOM},
  author       = {Tongqian Peng},
  doi          = {10.1016/j.comcom.2019.11.043},
  journal      = {Computer Communications},
  pages        = {687-695},
  shortjournal = {Comput. Commun.},
  title        = {A novel motion detecting strategy for rehabilitation in smart home},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Know when to listen: SDN-based protocols for directed IoT
networks. <em>COMCOM</em>, <em>150</em>, 672–686. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-power wireless networks are an integral part of the Internet of Things , composed of resource-constrained devices harvesting ambient information. The appearance of unidirectional links is characteristic of low power wireless networking due to physical effects, device heterogeneity and manufacturing imperfections . Despite the prevalence of unidirectional links, most routing and radio duty cycling protocols designed for these networks do not account for such links. We provide unidirectional-link-capable protocols and study the impact of using such links on network performance indicators, such as the data delivery ratio, delay and energy consumption. Our protocols are flexible and flooding-free, leveraging centralized knowledge provided by the Software-Defined Networking paradigm. Our experiments reveal that, while unidirectional links must be detected, using them for routing enhances network performance only if the unidirectional links are long.},
  archive      = {J_COMCOM},
  author       = {Renan Cerqueira Afonso Alves and Cintia Borges Margi and Fernando A. Kuipers},
  doi          = {10.1016/j.comcom.2019.12.023},
  journal      = {Computer Communications},
  pages        = {672-686},
  shortjournal = {Comput. Commun.},
  title        = {Know when to listen: SDN-based protocols for directed IoT networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DTMM: Evacuation oriented optimized scheduling model for
disaster management. <em>COMCOM</em>, <em>150</em>, 661–671. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over recent years there have been different types of natural hazard and man-made disasters which have been diverse and difficult to manage with heavy casualties. In this research, we are focusing on the rapid and coordinated evacuation of large populations after disasters to effectively reduce damage. An important task and a priority of the research and development is effective evacuation scheduling. We develop the system using it scenario which uses the Dynamic Tracking Mathematical Model (DTMM) for mobile cloud computing platform  developing. DTMM is an Evacuation Oriented Optimized Scheduling Model (EOOSM) for disaster population densities. This includes the mobile (IoT) interface for data collection and the cloud processing and analytics back end system. We develop our solution based in the typical scenario of IoT/Fog disaster management, and we propose an IoT application that uses the Artificial Field Efficiency (AFE), the core DTMM algorithm for evacuation scheduling. AFE is designed as an IoT system, which is suitable for rapid evacuation of large populations and can decide the evacuation path automatically by gradient direction in the potential region. People are usually in distress, which quickly triggers evacuation confusion and leads to a secondary disaster. On the basis of the AFE, the Evacuation Oriented Optimized Scheduling Model (EOOSM) is introduced as the Artificial Field Efficiency with Attraction of the Relationship AFE-AR. AFE-AR directs evacuees in relation to the same shelter, calm evacuees and perform humanitarian evacuation to the extent possible cases.},
  archive      = {J_COMCOM},
  author       = {Bing Bai and Yong Cao and Xiaozheng Li},
  doi          = {10.1016/j.comcom.2019.11.049},
  journal      = {Computer Communications},
  pages        = {661-671},
  shortjournal = {Comput. Commun.},
  title        = {DTMM: Evacuation oriented optimized scheduling model for disaster management},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligence in the internet of medical things era: A
systematic review of current and future trends. <em>COMCOM</em>,
<em>150</em>, 644–660. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Medical Things (IoMT) envisions a network of medical devices and people, which use wireless communication to enable the exchange of healthcare data. Healthcare costs and prices for services have been increasing with the growing population and the use of advanced technology. The combination of IoMT and healthcare can improve the quality of life, provide better care services and can create more cost-effective systems. This paper introduces the status of IoMT for healthcare industry , including research and development plans and applications. The implementation of the IoMT in healthcare has exponentially increased across the world, but still, it has many technical and design challenges. This paper depicts such challenges and shows a generic IoMT framework that consists of three main components, data acquisition, communication gateways, and servers/cloud, to meet the aforementioned challenges. Finally, this paper discusses the opportunities and prospects of IoMT in practice while emphasizing the corresponding open research issues.},
  archive      = {J_COMCOM},
  author       = {Fadi Al-Turjman and Muhammad Hassan Nawaz and Umit Deniz Ulusar},
  doi          = {10.1016/j.comcom.2019.12.030},
  journal      = {Computer Communications},
  pages        = {644-660},
  shortjournal = {Comput. Commun.},
  title        = {Intelligence in the internet of medical things era: A systematic review of current and future trends},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient public key secure scheme for cloud and IoT
security. <em>COMCOM</em>, <em>150</em>, 634–643. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the National Institute of Standard and Technology ( NIST ), the security level of RSA is safe when it is N N -bit modulus ≥ 2048 ≥2048 bits. Because of this, the processing time to generate asymmetric keys also increases. Taking this into account, an efficient and non-shareable Public Key Exponent Secure Scheme ( ENPKESS ) is proposed by using a non-linear Diophantine equation to have high security against side-channel attacks like timing attacks. This scheme has three-stage of encryption and two-stage of decryption, whereas other schemes like ESR and RSA has one level in encryption and decryption. Due to this, extraction of the secret key is extremely hard to determine from our public exponents α , R , N α,R,N . Our methodology is well suited for secure cloud computing environments used in the Internet of Things (IoT). Here we have also applied the Knapsack method to encrypt our ENPKESS keys to enrich high security in cloud systems . We show a strong performance evaluation on standard RSA , Enhanced and Secured RSA Key Generation Scheme ( ESRKGS ), and ENPKESS on its key generation, encryption and decryption by varying the N N -bit moduli size up to 10K bits. From the overall result, ENPKESS consumes 89\% of standard RSA and 27\% of ESRKGS.},
  archive      = {J_COMCOM},
  author       = {Chandrasegar Thirumalai and Senthilkumar Mohan and Gautam Srivastava},
  doi          = {10.1016/j.comcom.2019.12.015},
  journal      = {Computer Communications},
  pages        = {634-643},
  shortjournal = {Comput. Commun.},
  title        = {An efficient public key secure scheme for cloud and IoT security},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy harvesting algorithm considering max flow problem in
wireless sensor networks. <em>COMCOM</em>, <em>150</em>, 626–633. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Wireless Sensor Networks (WSNs), sensor nodes with poor energy always have bad effect on the data rate or max flow. These nodes are called bottleneck nodes . In this paper, in order to increase the max flow, we assume an energy harvesting WSNs environment to investigate the cooperation of multiple Mobile Chargers (MCs). MCs are mobile robots that use wireless charging technology to charge sensor nodes in WSNs. This means that in energy harvesting WSNs environments, sensor nodes can obtain energy replenishment by using MCs or collecting energy from nature by themselves. In our research, we use MCs to improve the energy of the sensor nodes by performing multiple rounds of unified scheduling, and finally achieve the purpose of increasing the max flow at sinks. Firstly, we model this problem as a Linear Programming (LP) to search the max flow in a round of charging scheduling and prove that the problem is NP-hard. In order to solve the problem, we propose a heuristic approach: deploying MCs in units of paths with the lowest energy node priority. To reduce the energy consumption of MCs and increase the charging efficiency, we also take the optimization of MCs’ moving distance into our consideration. Finally, we extend the method to multiple rounds of scheduling called BottleNeck. Simulation results show that Bottleneck performs well at increasing max flow.},
  archive      = {J_COMCOM},
  author       = {Zhenzhen Huang and Qiang Niu and Shuo Xiao and Tianxu Li},
  doi          = {10.1016/j.comcom.2019.12.008},
  journal      = {Computer Communications},
  pages        = {626-633},
  shortjournal = {Comput. Commun.},
  title        = {Energy harvesting algorithm considering max flow problem in wireless sensor networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic pricing techniques for intelligent transportation
system in smart cities: A systematic review. <em>COMCOM</em>,
<em>150</em>, 603–625. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic pricing plays an important role in modern Intelligent Transportation System (ITS) in solving problems such as congestion control , peak load reduction, mobility management of traditional or Electric Vehicles (EVs) in cost-effective manner. It also facilitates the construction of an eco-friendly environment in the society by optimized route planning of vehicles. However, framing dynamic pricing strategies for ITS has always been a challenging task keeping in view of various constraints. An in-efficient dynamic pricing technique may lead to the mismanagement of vehicles, which results an increase in the waiting time of vehicles, an increase in air and noise pollution, wastage of electric and other sources of energies. On the contrary, efficient dynamic pricing strategies can provide satisfaction to all stakeholders, including service providers and service consumers. Motivated from these facts, this paper presents an extensive literature review and analysis of dynamic pricing techniques used in the literature for ITS. The analysis presented in the paper gives new insights to the readers for the applications of one of the techniques in comparison to its merits over the others. Various problems solved by the dynamic pricing techniques, importance of various evaluation parameters, limitations of dynamic pricing techniques and their applications are discussed in-depth in this paper. Different taxonomies used for exploring various issues of dynamic pricing are also presented in a structured manner. Moreover, advantages and limitations of various dynamic pricing techniques are explored and discussed in the paper. Finally, existing challenges and future research directions of dynamic pricing in ITS are presented.},
  archive      = {J_COMCOM},
  author       = {Sandeep Saharan and Seema Bawa and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2019.12.003},
  journal      = {Computer Communications},
  pages        = {603-625},
  shortjournal = {Comput. Commun.},
  title        = {Dynamic pricing techniques for intelligent transportation system in smart cities: A systematic review},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unified call admission control in corporate domains.
<em>COMCOM</em>, <em>150</em>, 589–602. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Call Admission Control is a central mechanism for assurance of quality of service in telephony. While CAC is integrated into Public Switched Telephony Network (PSTN), its application to voice over IP in a corporate environment is challenging not only due to the heterogeneity of technologies, but also because of the difficulty of implementation into commercial VoIP terminals or Access Points. We present a novel framework that unifies call admission control for VoIP telephony corporate users despite their access network (i.e., WiFi or Ethernet) under a single corporate management domain. Our Unified CAC (U-CAC) system can be implemented in a VoIP Gateway/Proxy and uses only standard protocols already present in commercial off-the-shelf devices, avoiding the need to modify the firmware of existing APs or VoIP terminals. We define two variants of the decision algorithm: basic and advanced. In the basic mode of operation, the admission of new calls is based on the availability of spare circuits and the impact of the new call in the speech quality of VoWiFi calls in progress. In the advanced mode of operation, the traffic load in affected APs is proactively reduced by reconfiguring ongoing calls before rejecting the new call. Simulation results show that the number of simultaneous VoWiFi calls under guaranteed quality increases with our unified call admission control scheme. When using the advanced mode of operation, the number of simultaneous calls under guaranteed quality can be doubled when compared to the standard mode of operation.},
  archive      = {J_COMCOM},
  author       = {Vicente Mayor and Rafael Estepa and Antonio Estepa and Germán Madinabeitia},
  doi          = {10.1016/j.comcom.2019.11.041},
  journal      = {Computer Communications},
  pages        = {589-602},
  shortjournal = {Comput. Commun.},
  title        = {Unified call admission control in corporate domains},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Use of wearable devices to study activity of children in
classroom; case study — learning geometry using movement.
<em>COMCOM</em>, <em>150</em>, 581–588. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in wearable devices enable researchers to study various physical and physiological parameters and even behaviour of children in real-life conditions. This paper describes a study of two groups of 7-years old elementary school children, whose physical and psychological activity during teaching of geometry were compared and analysed — the control group was taught in the classical sedentary fashion while the experimental one was learning using movement-based teaching approach. Multiparameter wearable devices were used to measure children’s energy expenditure, intensity of movements, electrodermal activity, body heat flux and skin temperature. Differences in physiology, combined with reported valence of the activity, showed that the level of mental and cognitive engagement in experimental group was higher. The main finding was a significantly higher physical and psychological arousal and a higher knowledge retention in long-term conditions of the experimental group. Wearables were proven to be a useful tool in real-life research settings (i.e. classrooms) facilitating analysis of physiological responses in learning processes that could provide new insights into the effectiveness of different teaching methods.},
  archive      = {J_COMCOM},
  author       = {Vesna Geršak and Helena Smrtnik Vitulić and Simona Prosen and Gregor Starc and Iztok Humar and Gregor Geršak},
  doi          = {10.1016/j.comcom.2019.12.019},
  journal      = {Computer Communications},
  pages        = {581-588},
  shortjournal = {Comput. Commun.},
  title        = {Use of wearable devices to study activity of children in classroom; case study — learning geometry using movement},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Generic cost optimized and secured sensitive attribute
storage model for template based text document on cloud.
<em>COMCOM</em>, <em>150</em>, 569–580. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing stands as the most powerful technology for providing and managing resources as a pay-per-usage system. Nowadays, user documents are stocked in the cloud for easy access, less maintenance cost, and better services, etc. Currently, user data stocked up in the cloud are mostly in the form of template-based unstructured text documents. These documents are stocked up in a group by various organizations. Generally, the template-based text document contains large size common information, common terms, conditions, and sensitive information . For protecting the values in the documents, present methods apply encryption algorithms. But these techniques take high encryption time and required more storage space. Applying encryption algorithms is an extremely time-consuming task since the terms and conditions and instructions are common for all documents, and they do not require any security. But the sensitive information in these documents differs as of one user to another user and as well this sensitive information requires protection. Therefore, there is a requirement for an efficient way of segregating, storing and encrypting sensitive information with minimum storage cost, and computational cost. To tackle these issues, a generic safe data storage model is proposed, which makes use of information extraction techniques of Natural Language Processing for sensitive attribute value identification, and Enhanced ECC for securing sensitive data centered on group key . When weighted against the existing entire document and partition-based encryption technique , the proposed generic secure data storage model for cloud takes lesser encryption time and storage space.},
  archive      = {J_COMCOM},
  author       = {Sumathi M. and Sangeetha S. and Anu Thomas},
  doi          = {10.1016/j.comcom.2019.11.029},
  journal      = {Computer Communications},
  pages        = {569-580},
  shortjournal = {Comput. Commun.},
  title        = {Generic cost optimized and secured sensitive attribute storage model for template based text document on cloud},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mutated k-means algorithm for dynamic clustering to perform
effective and intelligent broadcasting in medical surveillance using
selective reliable broadcast protocol in VANET. <em>COMCOM</em>,
<em>150</em>, 563–568. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular ad-hoc Network (VANET) is an emerging type of Mobile ad-hoc Networks (MANETs) with excellent applications in the intelligent traffic system. Applications in VANETs are life critical since human lives are at stake and therefore, interaction among nodes (vehicles) must be established in the most secure manner. To give effective information transmission between vehicles, Cluster based topology bunches vehicle hubs in geographic region together can be connected to help coordinate correspondence inside and outside group should be possible through group heads . Different variations of K-implies calculation are ordinarily utilized for bunching yet these calculations cannot be specifically connected to VANET due to dynamic evolving topology. In this paper, we propose of dynamic grouping through K-implies which suits well for dynamic topology qualities of VANET. The proposed technique functions admirably with referred to number of bunches ahead of time and also the obscure number of groups. In our approach, the client has the adaptability to settle the quantity of bunches or the base number of groups required. This calculation figures the new bunch focus by expanding the group counter by one in every emphasis until the point that target work is fulfilled. The same can be defined and the ideal group heads and the relationship amongst CMs and CHs can be resolved.},
  archive      = {J_COMCOM},
  author       = {M. Ramalingam and R. Thangarajan},
  doi          = {10.1016/j.comcom.2019.11.023},
  journal      = {Computer Communications},
  pages        = {563-568},
  shortjournal = {Comput. Commun.},
  title        = {Mutated k-means algorithm for dynamic clustering to perform effective and intelligent broadcasting in medical surveillance using selective reliable broadcast protocol in VANET},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient for UAV-enabled mobile edge computing
networks: Intelligent task prediction and offloading. <em>COMCOM</em>,
<em>150</em>, 556–562. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) network provides near-users computing and communication functions and has become a potential 5G evolutionary architecture. In order to overcome the shortcomings of the existing MEC network in fixed base stations and limited computing resources, unmanned arial vehicle (UAV) is introduced as a relay edge computing node and UAV-enabled MEC networks are proposed. However, UAVs have limited energy. Thus, energy consumption would be an optimal target during the information interaction. Therefore, an energy efficiency optimization algorithm based on a three-layer computation offloading strategy is proposed in this paper by combining the UAV position optimization algorithm and the LSTM-based task prediction algorithm. The experiments show that the computation offloading strategy of the UAV-enabled MEC network can be dynamically programmed with the proposed algorithm and architecture, according to the required delay, UAV height, and data size in order to effectively reduce the energy consumption of the UAV.},
  archive      = {J_COMCOM},
  author       = {Gaoxiang Wu and Yiming Miao and Yu Zhang and Ahmed Barnawi},
  doi          = {10.1016/j.comcom.2019.11.037},
  journal      = {Computer Communications},
  pages        = {556-562},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient for UAV-enabled mobile edge computing networks: Intelligent task prediction and offloading},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Advanced wavelet sampling algorithm for IoT based
environmental monitoring and management. <em>COMCOM</em>, <em>150</em>,
547–555. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, various high end systems have been utilized to check the instantaneous change in the climate through deep monitoring methods with advanced mathematical modelling , whereas the major problem in the present research is the data management and precision in detecting various disaster conditions of the smart environment. Though The present instrument for disaster prediction has come up with various satellites and radar, which suffers instrumentation and data management issues that has been resolved in this research. The prominent improvement in the IoT technology shows better fine-grain structure, more flexibility and accuracy. The Proposed technique uses Advanced Adaptive Wavelet Sampling Algorithm (AAWSA)that has been designed and developed in this paper helps to improve the precision range of the instrument during disaster prediction in the urban region. The developed instrument utilizes advanced mathematical modelling with the linear data analytics approach which shows emerging outcomes than the present system which are used in practice.},
  archive      = {J_COMCOM},
  author       = {Zhang Tao},
  doi          = {10.1016/j.comcom.2019.12.006},
  journal      = {Computer Communications},
  pages        = {547-555},
  shortjournal = {Comput. Commun.},
  title        = {Advanced wavelet sampling algorithm for IoT based environmental monitoring and management},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Priority and interference aware multipath routing based
communications for extreme surveillance systems. <em>COMCOM</em>,
<em>150</em>, 537–546. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased natural disaster in various urban and rural areas requires immediate attention to avoid the major causes. In real world, immediate recovery to the disaster areas is ensured by adapting the unmanned aerial vehicles that enable people to reach the disaster areas immediately. Here specific task in the disaster area can be completed efficiently by working with multi Unmanned Aerial Vehicle (UAV) instead of single UAV. Here data communication between the UAV needs to be very reliable to ensure the proper disaster management outcome. It is more complex to provide the required services to the users when there is situation arise to switch between the heterogeneous networks . The QoS-Oriented Distributed routing protocol (QOD) is used in the existing methods to give solution to this problem. The data is transferred between hybrid networks with required QoS. In the existing work, routing is done by considering the QoS consideration thus the efficient and reliable distributed routing is guaranteed. However the existing work lacks from the following issues: It avoids the data transfer through the path in which data transmission is going already to avoid the interference problems which might reduce the throughput rate. Priority of the data transferred from multiple sources are not considered in the previous work and also existing work focused on reducing delay alone as QoS factor. Priority and Interference aware Multipath Routing Protocol (PIMRP) is introduced to rectify this issue in the proposed method. In this method, interference aware and priority routing is ensured by introducing the following research methods. Here, Multipath interference based routing method is used allow transmission of data from multiple path that resides within interference range with guaranteed interference avoidance and increased throughput. Here route path nodes are selected with multiple objectives such as delay, bandwidth, and energy consumption. To provide more preference to the prioritized data transmission nodes with more resource availability is provided to the prioritized data packets which are tiny segmented. The performance of the proposed method is evaluated using NS2 simulation tool. The simulation results confirm the efficiency of the proposed method.},
  archive      = {J_COMCOM},
  author       = {T. Murugeswari and S. Rathi},
  doi          = {10.1016/j.comcom.2019.11.050},
  journal      = {Computer Communications},
  pages        = {537-546},
  shortjournal = {Comput. Commun.},
  title        = {Priority and interference aware multipath routing based communications for extreme surveillance systems},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). UAVs assessment in software-defined IoT networks: An
overview. <em>COMCOM</em>, <em>150</em>, 519–536. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological advancements in the ubiquitous IoT era and the ever-growing desire of communities to enforce smart cities with security and safety of user data as their priority, mini Unmanned Aerial Vehicles (UAVs), or drones, are perceived as a tool for raising living standards by meeting the requirements of societies. Traditionally in UAV communication links, meshed ad hoc networks were among the first options of connectivity. However, the increased demand for deploying multi-UAV networks necessitates the development of a more robust and more secure networking infrastructure. In this regard, Software-Defined Networking (SDN) paradigm has proved to be the better alternative for multi-UAV communication since it can offer flexible services for management and control owing to its unique features such as decoupling control from UAVs and network programmability . Therefore, in this paper, we provide an overview of drone applications in SDN-enabled Drone Base Stations (DBS), surveillance monitoring and emergency networks , and review the performance assessment techniques and the associated cybersecurity aspects in these applications. Moreover, future research directions, after a thorough analysis of the literature, is presented in this paper. Through the development of an innovative and multifaceted drone performance-assessment framework with the primal concerns, that are meeting user-defined requirements and the provision of secure and reliable services, it is, therefore, necessary to advance in IoT-enabled spaces. We believe the present work is a step in the right direction, and it is essential for fastening the movement toward UAV-enabled smart cities.},
  archive      = {J_COMCOM},
  author       = {Fadi Al-Turjman and Mohammad Abujubbeh and Arman Malekloo and Leonardo Mostarda},
  doi          = {10.1016/j.comcom.2019.12.004},
  journal      = {Computer Communications},
  pages        = {519-536},
  shortjournal = {Comput. Commun.},
  title        = {UAVs assessment in software-defined IoT networks: An overview},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective peer-to-peer design for supporting range query in
internet of things applications. <em>COMCOM</em>, <em>150</em>, 506–518.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) refers to the internetworking of diverse devices in an ad-hoc manner to support pervasive applications. IoT devices often generate a wealth of data that ought to be accessible and managed in a distributed manner. Such operational model requires architecture that supports contextual and information centric retrieval of data, and efficient data storage. In this paper, we argue that peer-to-peer (P2P) overlays are well suited for IoT systems. However, existing P2P systems do not efficiently handle queries of data within a range, which is a popular access pattern in IoT applications. Moreover, many of the IoT devices are constrained in their computational resources and consequently the data management model has to cope with such limitation.  Existing P2P solutions do not factor the heterogeneity of the involved nodes and assume abundant storage space. This paper opts to fill the technical gap and proposes an effective P2P solution for efficient handling of range queries in IoT (RQIOT). RQIOT employs a data distribution model based on both consistent and order-preserving hashing and introduces a novel scheme for capacity management of the involved devices. The simulation results have confirmed the effectiveness and scalability of RQIOT, and the superiority of its performance over competing approaches.},
  archive      = {J_COMCOM},
  author       = {Brahim Djellabi and Mohamed Younis and Mourad Amad},
  doi          = {10.1016/j.comcom.2019.12.017},
  journal      = {Computer Communications},
  pages        = {506-518},
  shortjournal = {Comput. Commun.},
  title        = {Effective peer-to-peer design for supporting range query in internet of things applications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). (ReLBT): A reinforcement learning-enabled listen before talk
mechanism for LTE-LAA and wi-fi coexistence in IoT. <em>COMCOM</em>,
<em>150</em>, 498–505. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of Internet of Things (IoT) has increased number of connected devices and consequently transmitted traffic over the Internet. In this regard, Long Term Evolution (LTE) is growing its utilization in unlicensed spectrum as well, and Licensed Assisted Access (LAA) technology is one of the examples. However, unlicensed spectrum is already occupied by other wireless technologies , such as Wi-Fi. The diverse and dissimilar physical layer and medium access control (MAC) layer configurations of LTE-LAA and Wi-Fi lead to coexistence challenges in the network. Currently, LTE-LAA uses a listen-before-talk (LBT) mechanism, and Wi-Fi uses a carrier sense multiple access with collision avoidance (CSMA/CA) as a channel access mechanism. LBT and CSMA/CA are moderately similar channel access mechanisms. However, there is an efficient coexistence issue when these two technologies coexist. Therefore, this paper proposes a Reinforcement Learning-enabled LBT (ReLBT) mechanism for efficient coexistence of LTE-LAA and Wi-Fi scenarios. Specifically, ReLBT utilizes a channel collision probability as a reward function to optimize its channel access parameters. Simulation results show that the proposed ReLBT mechanism efficiently enhances the coexistence of LTE-LAA and Wi-Fi as compared to the LBT, thus improves fairness performance.},
  archive      = {J_COMCOM},
  author       = {R. Ali and B. Kim and S.W. Kim and H.S. Kim and F. Ishmanov},
  doi          = {10.1016/j.comcom.2019.11.055},
  journal      = {Computer Communications},
  pages        = {498-505},
  shortjournal = {Comput. Commun.},
  title        = {(ReLBT): A reinforcement learning-enabled listen before talk mechanism for LTE-LAA and wi-fi coexistence in IoT},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AFA: Adversarial fingerprinting authentication for deep
neural networks. <em>COMCOM</em>, <em>150</em>, 488–497. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the vigorous development of deep learning , sharing trained deep neural network (DNN) models has become a common trend in various fields. An urgent problem is to protect the intellectual property (IP) rights of the model owners and detect IP infringement. DNN watermarking technology, which embeds signature information into the protected model and tries to extract it from the plagiarism model, has been the main approach of IP verification. However, the existing DNN watermarking methods have to be robust to various removal attacks since their watermarks are single in form or limited in quantity. Meanwhile, the process of adding watermarks to the DNN models will affect their original prediction abilities. Moreover, if the model has been distributed before embedding the watermarks, its IP cannot be correctly recognized and protected. To this end, we propose AFA, a new DNN fingerprinting technology aiming at extracting the inherent features of the model itself instead of embedding fixed watermarks. The features we selected as model fingerprints are a set of specially-crafted adversarial examples called Adversarial-Marks, which can transfer much better to the models that are derived from the original model than to other irrelative models. We also design a new IP verification scheme to identify a remote model’s ownership. Experimental results show that our mechanism works well for common image classification models, and it can be easily adapted to other deep neural networks.},
  archive      = {J_COMCOM},
  author       = {Jingjing Zhao and Qingyue Hu and Gaoyang Liu and Xiaoqiang Ma and Fei Chen and Mohammad Mehedi Hassan},
  doi          = {10.1016/j.comcom.2019.12.016},
  journal      = {Computer Communications},
  pages        = {488-497},
  shortjournal = {Comput. Commun.},
  title        = {AFA: Adversarial fingerprinting authentication for deep neural networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LNR-PP: Leaf node count and RSSI based parent prediction
scheme to support QoS in presence of mobility in 6LoWPAN.
<em>COMCOM</em>, <em>150</em>, 472–487. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6LoWPAN network consists of embedded devices and sensors that senses environmental data and passes it to a root called as a 6LBR (6LoWPAN Border Router) which further transfers it to an Internet server for aggregation and processing. Earlier definition of 6LoWPAN consists of devices which are static with constrained resources such as computing power, memory, battery power and communication bandwidth. Recent additions such as mobile devices which are part of the 6LoWPAN network often cause frequent topology changes and disconnections, leading to degraded performance of the network. Handover delay, data loss rate, number of control messages, energy utilization are some of the performance metrics that has been focused and improved by recent works in the literature. But the proposed approaches work well when the number of mobile nodes and mobility rate are moderate. We identify the issues that arise in the 6LoWPAN RPL based network due to higher number of mobile nodes and higher mobility rate which causes problems like delay in data transmission and degraded parent node performance. In this paper we study, analyse and propose modifications in the popular protocols that support mobility in 6LoWPAN such as EC-MRPL. We propose a best-effort scheme called LNR-PP (Leaf node count and RSSI based Parent Prediction) to identify affected Static Nodes (SN) to whom large number of Mobile Nodes (MN) are connected. We call this scheme as a best effort since the parent prediction depends upon the number of neighbours available within the reach of MN in mobility. LNR-PP performs balanced leaf node (Mobile Node) allocation to SN in an effort to minimize the number of RPL control message packets , delay in forwarding data from the MN and power required to transmit control and data packets through SN. This enables the mobile nodes (MN) to communicate with DODAG-ROOT with guaranteed QoS measures under high mobility scenario. We developed a mathematical model to realize the benefits of the proposed scheme which can be incorporated into EC-MRPL and simulated with sample network parameters in MATLAB. The results obtained through simulation shows a significant improvement in term of number of RPL control message packets such as DIS and DIO, power requirement to transfer control and data packets through SN and delay encountered by SN while forwarding large volume of data from MN.},
  archive      = {J_COMCOM},
  author       = {Suganya P. and Pradeep Reddy C.H.},
  doi          = {10.1016/j.comcom.2019.12.012},
  journal      = {Computer Communications},
  pages        = {472-487},
  shortjournal = {Comput. Commun.},
  title        = {LNR-PP: Leaf node count and RSSI based parent prediction scheme to support QoS in presence of mobility in 6LoWPAN},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Analysis and implementation of novel rice golomb coding
algorithm for wireless sensor networks. <em>COMCOM</em>, <em>150</em>,
463–471. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor networks (WSN) comprises of several sensor nodes scattered wirelessly to accomplish a particular task. Each sensor node is empowered by a battery. The various functions of the node namely sensing, computing, storage and transmission/reception of data consumes power from the battery with limited capacity. As these batteries do not last for a long time, an efficient algorithm is required to extend its life time. Data compression algorithm is a unique method adopted to minimize the amount of data being sent or received and thereby reduces the power consumed during communication. This would further increase the lifetime of node and also the network. In this paper a simple lossless compression algorithm is proposed and is also compared with the existing Adaptive Huffman coding algorithm that is been widely used in wireless sensor network applications. The comparative analysis is based on different compression parameters like compression ratio, compression factor, saving percentage , RMSE and encoding &amp; decoding time. The data set for comparison is acquired using a temperature sensor interfaced with NI 3202 programmable sensing node . The comparative analysis is performed and the results are simulated using MATLAB software. The NI WSN nodes are used to execute the algorithm for instantaneous data. The analysis of number of packets transmitted during wireless communication , both before and after compression is performed using Wireshark network analyzer tool. The simulation result shows that the proposed lossless compression algorithm performs better than the existing one. The hardware implementation has proven that the amount of data traffic is reduced after compression which will help in reducing the transmission power and thereby saves the lifetime of the node in a wireless sensor network.},
  archive      = {J_COMCOM},
  author       = {S. Kalaivani and C. Tharini},
  doi          = {10.1016/j.comcom.2019.11.046},
  journal      = {Computer Communications},
  pages        = {463-471},
  shortjournal = {Comput. Commun.},
  title        = {Analysis and implementation of novel rice golomb coding algorithm for wireless sensor networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting the security threats on the spreading of rumor,
false information of facebook content based on the principle of
sociology. <em>COMCOM</em>, <em>150</em>, 455–462. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things (IOT), frequent communication among a huge amount of heterogeneous smart devices over the Online Social Networks(OSN) becomes viable and efficient. Increasing user submissions including online contents, videos and comments are gradually affecting people’s lives, leading to an explosive propagation of information and posing security threats on the spreading of rumor, false information and inappropriate online speech. The goal of popularity prediction of online content is accurate predict the popularity in the future based on the early diffusion status. Existing models for popularity prediction are mostly based on discovering network features or fitting the equation into a varying time function which seldom introduces the principle of sociology. In this paper, we find that there exists a high linear correlation between the proportion of faithful fans in Facebook homepage with frequent shares in the early and the future popularity. The statistical results about Facebook remind us that the principle of mainstream fatigue plays an important role in prediction task. Furthermore, an experimental study clearly illustrates that the effectiveness of the proposed method.},
  archive      = {J_COMCOM},
  author       = {Xiaomeng Wang and Binxing Fang and Hongli Zhang and Xing Wang},
  doi          = {10.1016/j.comcom.2019.11.042},
  journal      = {Computer Communications},
  pages        = {455-462},
  shortjournal = {Comput. Commun.},
  title        = {Predicting the security threats on the spreading of rumor, false information of facebook content based on the principle of sociology},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Net-police: A network patrolling service for effective
mitigation of volumetric DDoS attacks. <em>COMCOM</em>, <em>150</em>,
438–454. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric Distributed Denial of Service (DDoS) attacks are a significant concern for information technology-based organizations. These attacks result in significant revenue losses in terms of wastage of resources and unavailability of services at the victim (e.g., business websites, DNS servers, etc.) as well as the Internet Service Providers (ISPs) along the path of the attack. The state-of-the-art DDoS mitigation mechanisms attempt to alleviate the losses at either the victim or the ISPs, but not both. In this paper, we present Net-Police, which is a traffic patrolling system for DDoS mitigation. Net-Police identifies the sources of attack so that filters can be employed at these sources in order to quickly mitigate the attack. Such a solution effectively prevents the flow of malicious traffic across the ISP networks, thereby benefiting the ISPs also. Net-Police patrols the network by designating a small number of routers as dynamic packet taggers, to prune benign regions in the network, and localize the search to the Autonomous Systems (AS) from which the attack originates. We evaluate the proposed solution on 257 real-world topologies from the Internet Topology Zoo library and the Internet AS level topology. The paper also presents details of our hardware test-bed platform consisting of 30 routers on which network services such as Net-Police can be implemented and studied for on-field feasibility. Our experiments reveal that Net-Police performs better than the state-of-the-art cloud-based and traceback-based solutions in terms of ISP bandwidth savings and availability of the victim to legitimate clients .},
  archive      = {J_COMCOM},
  author       = {Sareena Karapoola and Prasanna Karthik Vairam and Shankar Raman and V. Kamakoti},
  doi          = {10.1016/j.comcom.2019.11.034},
  journal      = {Computer Communications},
  pages        = {438-454},
  shortjournal = {Comput. Commun.},
  title        = {Net-police: A network patrolling service for effective mitigation of volumetric DDoS attacks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous information network-based music recommendation
system in mobile networks. <em>COMCOM</em>, <em>150</em>, 429–437. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of the rapid development of mobile networks, music recommendation systems (MRSs) have experienced considerable success in recent years. Conventional music recommendation systems are, however, in general based on the simple user–track relationships or the content of songs and recommend songs according to intrinsic factors. Furthermore they do not consider the users’ contextual factors towards providing them with a more interpretable, efficient and smart recommendation experience. To address these issues, we propose a novel H eterogeneous I nformation N etwork-based M usic R ecommendation S ystem (HIN-MRS) . By considering the extrinsic factors, such as contextual factors, internal factors, such as the user’s personalized preference, and the heterogeneous relationship between items of song information, this method can perceive the user’s music selection from multiple aspects, automatically maintain the user’s playlist and improve the user’s music experience. First we used the obtained textual data to extract the user’s music preference to provide the topic which is usually related to the contextual factors, by means of which an HIN-MRS can realize the perception of the mobile environment. Second, after determining the topics, we built a small-scale HIN of songs (song HIN) according to topics and used a graph-based algorithm to generate recommendations. The recommendation method based on an HIN renders the recommendation process more efficient and the recommendation results more accurate and increases the users satisfaction. The results of our final experiments also prove the significant advantages of the proposed model over the conventional approaches.},
  archive      = {J_COMCOM},
  author       = {Ranran Wang and Xiao Ma and Chi Jiang and Yi Ye and Yin Zhang},
  doi          = {10.1016/j.comcom.2019.12.002},
  journal      = {Computer Communications},
  pages        = {429-437},
  shortjournal = {Comput. Commun.},
  title        = {Heterogeneous information network-based music recommendation system in mobile networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Intelligent remote monitoring and manufacturing system of
production line based on industrial internet of things. <em>COMCOM</em>,
<em>150</em>, 421–428. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous development of Internet communication technology has given birth to the development of Internet of Things technology and the integration of intelligent manufacturing to accelerate the upgrading of traditional industrial production lines. In view of the slow speed, low fusion accuracy and other problems appeared on the current Internet of Things data fusion method, an Internet of Things heterogeneous data fusion method based on intelligent optimization algorithm is proposed to improve the Internet of Things heterogeneous data fusion effect as the goal. First, multiple nodes are used to collect the monitoring object state data. The data noise collected by each node is filtered. The data scale is initially reduced and the quality of the Heterogeneous data of the Internet of Things is improved. Then, the clustering algorithm is introduced to process the cluster head data, eliminating the redundancy between the data in the cluster. Meanwhile, the redundancy occurs between the data cluster. In the aggregation node , the cluster head data is weighted and integrated by intelligent optimization algorithm . The experiment is compared with other fusion methods under the same environment. Experimental results show that this method can effectively converge the heterogeneous data of the Internet of Things, obtain the results of the higher precision of the heterogeneous data fusion of the Internet of Things, and improve the efficiency of the fusion of Internet of Things data with fewer and faster errors of the Heterogeneous data of the Internet of Things. Finally, MATLAB simulates the proposed network transmission optimization algorithm, and verifies the reliability and stability of wireless network remote monitoring.},
  archive      = {J_COMCOM},
  author       = {Xianming Huang},
  doi          = {10.1016/j.comcom.2019.12.011},
  journal      = {Computer Communications},
  pages        = {421-428},
  shortjournal = {Comput. Commun.},
  title        = {Intelligent remote monitoring and manufacturing system of production line based on industrial internet of things},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Migration strategy of cloud collaborative computing for
delay-sensitive industrial IoT applications in the context of
intelligent manufacturing. <em>COMCOM</em>, <em>150</em>, 413–420. (<a
href="https://doi.org/10.1016/j.comcom.2019.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of intelligent manufacturing, machinery and equipment in the industrial manufacturing process form the “industrial Internet of Things .” In this process of interlocking production, the requirements for sensor data delay typically reach the millisecond level. Once the data is delayed, the equipment will be shut down, which will make the production difficult or dangerous. In the context of intelligent manufacturing, local computers have been unable to complete calculations and decisions quickly and on time for the huge computing demands. Therefore, the cloud computing migration mode needs to be introduced, but cloud computing migration will cause additional delays. Based on the above problems, this paper designs a cloud cooperative migration strategy based on the information exchange structure of the industrial Internet of Things and the delay mechanism caused by the migration. The feasibility of selecting the optimal migration strategy based on task partitioning is verified by simulation.},
  archive      = {J_COMCOM},
  author       = {Ke Wang},
  doi          = {10.1016/j.comcom.2019.12.014},
  journal      = {Computer Communications},
  pages        = {413-420},
  shortjournal = {Comput. Commun.},
  title        = {Migration strategy of cloud collaborative computing for delay-sensitive industrial IoT applications in the context of intelligent manufacturing},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Location assisted delay-less service discovery method for
IoT environments. <em>COMCOM</em>, <em>150</em>, 405–412. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location aided services (LAS) is a significant demand for wireless communication devices for service discovery and resource utilization in internet of things (IoT) environments. IoT devices provide services that are more significant about location and cost efficiency for both privacy and communication. In this paper, a location assisted delay-less service discovery (LDSD) for IoT users is introduced to minimize request–response delays. The proposed service discovery method searches cost effective resource for serving user requests with the knowledge of the resource location. With the knowledge of the location, LDSD classifies the resources based on service request delivery delay and availability for speedy resource mapping and service response. This resource discovery is also facilitated for replicated resource mapping considering service cost and request delivery delay ensuring minimum resource replication The performance of the proposed LDSD is verified through experiments and the benefit of the discovery method is assessed using the metrics: response time, failure rate, resource utilization, request delivery time, resource availability and service latency. Experimental results demonstrate the reliability of the proposed LDSD by minimizing response time, failure rate, request delivery time and service latency and improving resource utilization and availability.},
  archive      = {J_COMCOM},
  author       = {Ahmad AlZubi and Abdulaziz Alarifi and Mohammed Al-Maitah and Omar A. Albasheer},
  doi          = {10.1016/j.comcom.2019.11.045},
  journal      = {Computer Communications},
  pages        = {405-412},
  shortjournal = {Comput. Commun.},
  title        = {Location assisted delay-less service discovery method for IoT environments},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Near real-time estimation of end-to-end performance in
converged fixed-mobile networks. <em>COMCOM</em>, <em>150</em>, 393–404.
(<a href="https://doi.org/10.1016/j.comcom.2019.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The independent operation of mobile and fixed network segments is one of the main barriers that prevents improving network performance while reducing capital expenditures coming from overprovisioning. In particular, a coordinated dynamic network operation of both network segments is essential to guarantee end-to-end Key Performance Indicators (KPI), on which new network services rely on. To achieve such dynamic operation, accurate estimation of end-to-end KPIs is needed to trigger network reconfiguration before performance degrades. In this paper, we present a methodology to achieve an accurate, scalable, and predictive estimation of end-to-end KPIs with sub-second granularity near real-time in converged fixed-mobile networks. Specifically, we extend our CURSA-SQ methodology for mobile network traffic analysis , to enable converged fixed-mobile network operation. CURSA-SQ combines simulation and machine learning fueled with real network monitoring data. Numerical results validate the accuracy, robustness, and usability of the proposed CURSA-SQ methodology for converged fixed-mobile network scenarios.},
  archive      = {J_COMCOM},
  author       = {Alvaro Bernal and Matias Richart and Marc Ruiz and Alberto Castro and Luis Velasco},
  doi          = {10.1016/j.comcom.2019.11.052},
  journal      = {Computer Communications},
  pages        = {393-404},
  shortjournal = {Comput. Commun.},
  title        = {Near real-time estimation of end-to-end performance in converged fixed-mobile networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mathematical modeling and fuzzy approach for disaster
analysis on geo-spatial rock mass in open-pit mining. <em>COMCOM</em>,
<em>150</em>, 384–392. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex nature of open-pit mining rock mass, multiple variables has a significant impact on slope stability, which is difficult to evaluate under disaster conditions. The damaged rock slope stability analysis using fundamental fuzzy model is established using the concept of fuzzy measurements upon the basis of statistical analysis on large amount of measured data in Geo-Spatial study. Because of the marked “fuzziness” of the variables is analyzed in this research, the slope stability issues under disaster conditions has been analyzed using Fuzzy Mathematical Theory (FMT) which examines damaged rock slope deformation failure at the open-pit mining. The fuzzy probability formula for rock mass deformation failure, and a numerical method for calculating the fuzzy probability, is derived by applying the theory of variation probability measurements in open pit mining . Here the damaged rock slope under disaster conditions in open-pit mine area has been analyzed and The fuzzy based disaster data management concept has been proposed for analyzing the disaster in open-pit mine area for the damaged rock due to disasters. Finally, the formulation of the Gauss–Legendre is a three-point technical illustration of damaged rock slope which has been used in the open pit. The practical calculation demonstrates that the technique is used for evaluating the slope stability problems in the metal mine opencast under disaster conditions.},
  archive      = {J_COMCOM},
  author       = {Zhigang Deng and Longjiang Wang and Weijian Liu and Zhenwei Wang and Qiule E.},
  doi          = {10.1016/j.comcom.2019.11.040},
  journal      = {Computer Communications},
  pages        = {384-392},
  shortjournal = {Comput. Commun.},
  title        = {Mathematical modeling and fuzzy approach for disaster analysis on geo-spatial rock mass in open-pit mining},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel mapping technique for ray tracer to system-level
simulation. <em>COMCOM</em>, <em>150</em>, 378–383. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulations have become remarkably useful in evaluating the performance of new techniques and algorithms in communication networks. This is due to its comparative cost, time and complexity advantage over the analytical and field trial approaches. For large-scale networks, system-level simulators (SLS) are used to assess the performance of the systems. The SLS typically employs statistical channel models to characterize the propagation environment . However, the communication channels can be more accurately modeled using the deterministic ray tracing tools, though at the cost of higher complexity. In this work, we present a novel framework for a hybrid system that integrates both the ray tracer and the SLS. In the hybrid system, the channel strength in terms of the signal-to-noise ratio (SNR) is fed from the ray tracer to the SLS which then uses the values for further tasks such as resource allocation and the consequent performance evaluation. Using metrics such as user throughput and spectral efficiency, our results show that the hybrid system predicts the system performance more accurately than the baseline SLS without ray tracing . The hybrid system will thus facilitate the accurate assessment of the performance of next-generation wireless systems .},
  archive      = {J_COMCOM},
  author       = {Muhammad Awais Khan and Sherif Adeshina Busari and Kazi Mohammed Saidul Huq and Shahid Mumtaz and Saba Al-Rubaye and Jonathan Rodriguez and Anwer Al-Dulaimi},
  doi          = {10.1016/j.comcom.2019.11.039},
  journal      = {Computer Communications},
  pages        = {378-383},
  shortjournal = {Comput. Commun.},
  title        = {A novel mapping technique for ray tracer to system-level simulation},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). User mobility and quality-of-experience aware placement of
virtual network functions in 5G. <em>COMCOM</em>, <em>150</em>, 367–377.
(<a href="https://doi.org/10.1016/j.comcom.2019.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual Network Functions (VNFs) in cloud servers of Fifth Generation (5G) network systems are responsible for executing offloaded codes from mobile users. Placement of VNFs in the cloud is very complicated to get on-time execution service due to many reasons including users’ mobility and resource heterogeneity, which often cause VNF relocations from one data center to another. Minimizing service delay (i.e., maximizing user Quality-of-Experience) for the user applications and the number of VNF relocations are the two main design goals of VNF placement problem; however, they do oppose each other. In this paper, we have formulated the above problem as a Multi-objective Integer Linear Programming (MILP), which is proven to be an NP-hard one. The proposed optimization framework trades-off between the number of VNF relocations and user Quality-of-Experience. We then develop an Artificial Intelligence based meta-heuristic Ant Colony Optimization (ACO) algorithm to achieve sub-optimal placement of VNFs within polynomial time . The performance analysis results, carried out in Cloudsim, depict that the proposed system outperforms the state-of-the-art works significantly in terms of user satisfaction and VNF relocation overhead.},
  archive      = {J_COMCOM},
  author       = {Palash Roy and Anika Tahsin and Sujan Sarker and Tamal Adhikary and Md. Abdur Razzaque and Mohammad Mehedi Hassan},
  doi          = {10.1016/j.comcom.2019.12.005},
  journal      = {Computer Communications},
  pages        = {367-377},
  shortjournal = {Comput. Commun.},
  title        = {User mobility and quality-of-experience aware placement of virtual network functions in 5G},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). WiDet: Wi-fi based device-free passive person detection with
deep convolutional neural networks. <em>COMCOM</em>, <em>150</em>,
357–366. (<a
href="https://doi.org/10.1016/j.comcom.2019.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve device-free person detection, various types of signal features, such as moving statistics and wavelet representations , have been extracted from the Wi-Fi Received Signal Strength Index (RSSI), whose value fluctuates when human subjects move near the Wi-Fi transceivers . However, these features do not work effectively under different deployments of Wi-Fi transceivers because each transceiver has a unique RSSI fluctuation pattern that depends on its specific wireless channel and hardware characteristics. To address this problem, we present WiDet, a system that uses a deep Convolutional Neural Network (CNN) approach for person detection. The CNN takes the 2-dimensional wavelet coefficients as input, and extracts effective and robust detection features automatically. With a large number of internal parameters, the CNN can record and recognize the different RSSI fluctuation patterns from different transceivers. We further apply the data augmentation method to improve the algorithm robustness to wireless interferences and pedestrian speed changes. To take advantage of the wide availability of the existing Wi-Fi devices, we design a collaborative sensing technique that can recognize the subject’s moving directions. To validate the proposed design, we implement a prototype system that consists of three Wi-Fi packet transmitters and one receiver on low-cost off-the-shelf embedded development boards. In a multi-day experiment with a total of 163 walking events, WiDet achieves 95.5\% of detection accuracy in detecting pedestrians, which outperforms the moving statistics and the wavelet representation based approaches by 22\% and 8\%, respectively.},
  archive      = {J_COMCOM},
  author       = {Hua Huang and Shan Lin},
  doi          = {10.1016/j.comcom.2019.09.016},
  journal      = {Computer Communications},
  pages        = {357-366},
  shortjournal = {Comput. Commun.},
  title        = {WiDet: Wi-fi based device-free passive person detection with deep convolutional neural networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Analyzing the robotic behavior in a smart city with deep
enforcement and imitation learning using IoRT. <em>COMCOM</em>,
<em>150</em>, 346–356. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart City aims to develop an environment in which different things goes to different people. The smart city provides a core infrastructure by improving the status of the inhabitants by providing a smart environment by applying Smart Solutions. The Internet of Things (IoT) is a revolutionary concept which finds its way in many applications such as business, industry, healthcare, Transportation, modern Information Technology applications and many more. IoT combined with Artificial Intelligence (AI) can be applied to many day to day applications in superior systems like transportation, robotics, industrial, and automation systems applications. This research focuses on developing a robotic behavior control using the Internet of Robotic Things (IoRT) using deep learning for a Smart City. The IoRT is a promising standard that brings together autonomous robotic systems in the midst of the IoT vision of connected sensors and smart objects pervasively embedded in the day to day environments. Robotic behavioral control models the robot with the essential features to react with the immediate environment via sensory-motor links. Robotic behavioral control has a direct interconnection between the sensors and actuators and controls the functions necessary to move around the environment and carry out necessary tasks. This deep learning solution applied to the robotic behavioral control for robotic application uses two main paradigms: Deep Reinforcement Learning (DRL) and Imitation Learning (IL).DRL merges the concept of deep learning architecture using neural networks and Reinforcement learning algorithms to identify the behavior of the robots.IL focus on imitating human learning or expert demonstration for controlling the robot behavior. The behavior of the robot is monitored in a diner and its performance is estimated to be 92\% in realtime},
  archive      = {J_COMCOM},
  author       = {Yan Liu and Wei Zhang and Shuwen Pan and Yanjun Li and Yangting Chen},
  doi          = {10.1016/j.comcom.2019.11.031},
  journal      = {Computer Communications},
  pages        = {346-356},
  shortjournal = {Comput. Commun.},
  title        = {Analyzing the robotic behavior in a smart city with deep enforcement and imitation learning using IoRT},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DC-ECN: A machine-learning based dynamic threshold control
scheme for ECN marking in DCN. <em>COMCOM</em>, <em>150</em>, 334–345.
(<a href="https://doi.org/10.1016/j.comcom.2019.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explicit Congestion Notification (ECN) is a deployment to IP and TCP also playing a crucial role in the congestion control of the Data Center Networks (DCNs). Most DCNs use a single queue scenario in each switch port. However, in the production of DCNs, the industry trend is moving towards one farther queue per port. Therefore, Multi-Service Multi-Queue Data Centers (MQ-ECN) have been proposed to ignite this service; afterward, DemePro improved the MQ-ECN. Yet, the fact that overhead and imprecise measurement are non-negligible for both models should be borne in mind. Also, MQ-ECN works for a round base scheduler while the overflow problem could be contributed by DemePro. Moreover, ECN was designed for single queue scenarios and having MQ-ECN is harmful at least for scheduling of flows. To solve the problem, we could take advantage of the lack of MQ-ECN and propose a machine-learning based dynamic threshold control scheme for ECN marking in DCN, which we named it DC-ECN (Data Center-Explicit Congestion Notification)–a first systematic solution to the problems which have already been mentioned earlier. The main point of DC-ECN is a separation of the mice and elephant flows in dual couple queues using machine learning . Then, to locate them into the requested queue with demand ECN marking threshold independently to achieve low latency and high throughput . Also, by dynamically increase and decrease the ECN marking threshold in elephant buffer, DC-ECN will never mark mice flows and succeed to absorb micro-burst mice traffic to have lowest latency without having sacrifice the throughput. Our mathematical analysis and simulation demonstrate that a steady state behavior of DC-ECN achieves 21.8\% and 16.5\% less flow completion time compared with MQ-ECN and DemoPro, respectively.},
  archive      = {J_COMCOM},
  author       = {Akbar Majidi and Nazila Jahanbakhsh and Xiaofeng Gao and Jiaqi Zheng and Guihai Chen},
  doi          = {10.1016/j.comcom.2019.10.028},
  journal      = {Computer Communications},
  pages        = {334-345},
  shortjournal = {Comput. Commun.},
  title        = {DC-ECN: A machine-learning based dynamic threshold control scheme for ECN marking in DCN},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Internet of things based acquisition system of industrial
intelligent bar code for smart city applications. <em>COMCOM</em>,
<em>150</em>, 325–333. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the acquisition efficiency of bar code acquisition technology and the management efficiency of enterprises in the Internet of things , and bring more benefits to related enterprises, the barcode technology of perception layer in the Internet of things was added into the enterprise resource planning system , thus getting an effective and convenient barcode acquisition system. The research results show that the circuit board of the automatic barcode acquisition system studied here is based on the built-in barcode program and joined the enterprise resource planning system . It realizes the connection and integration of the two, which can not only run independently, but also simultaneously, to a large extent, playing its role. It can be seen that the integration of the barcode technology of the perception layer in Internet of things and the enterprise resource planning system can obtain a new industrial automatic barcode acquisition system. It can not only meet the requirements of barcode acquisition, but also improve the efficiency of barcode acquisition, which can be used for reference for manufacturing enterprises in terms of projects that produce according to the order.},
  archive      = {J_COMCOM},
  author       = {Kun Liu and YunRui Bi and Di Liu},
  doi          = {10.1016/j.comcom.2019.11.044},
  journal      = {Computer Communications},
  pages        = {325-333},
  shortjournal = {Comput. Commun.},
  title        = {Internet of things based acquisition system of industrial intelligent bar code for smart city applications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network condition based multi-level image compression and
transmission in WSN. <em>COMCOM</em>, <em>150</em>, 317–324. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing use of wireless sensor network has great deal with the bandwidth utilization . The most network users access the wireless sensor network for many applications. The image search is the one among them which needs to consider many network parameters. Variety of data compression techniques have been proposed in literature towards the data transmission in WSN. The earlier methods have the deficiency in producing higher image compression and transmission. To overcome the issues, an efficient network condition based approach is presented here. The presence of supportive condition in the network would improve the performance of data transmission. First, the network conditions namely bandwidth available, hop count, energy of sensor and traffic are monitored. Based on the above mentioned parameters of the network, the Data Transmission support (DTS) for each route available has been estimated. With the transmission support measured, a single route is selected and the level of compression is determined. The selected route and compression level is used to perform data transmission. The input image has been compressed into multiple levels by applying wavelet transmission. Compressed image has been transmitted through the route selected. The DTS based approach hikes the quality of service of wireless sensor network and reduces the time complexity as well.},
  archive      = {J_COMCOM},
  author       = {M. Jamuna Rani and C. Vasanthanayaki},
  doi          = {10.1016/j.comcom.2019.11.027},
  journal      = {Computer Communications},
  pages        = {317-324},
  shortjournal = {Comput. Commun.},
  title        = {Network condition based multi-level image compression and transmission in WSN},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). QMR: Q-learning based multi-objective optimization routing
protocol for flying ad hoc networks. <em>COMCOM</em>, <em>150</em>,
304–316. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A network with reliable and rapid communication is critical for Unmanned Aerial Vehicles (UAVs). Flying Ad Hoc Networks (FANETs) consisting of UAVs is a new paradigm of wireless communication . However, the highly dynamic topology of FANETs and limited energy of UAVs have brought great challenges to the routing design of FANETs. It is difficult for existing routing protocols for Mobile Ad Hoc Networks (MANETs) and Vehicular Ad Hoc Networks (VANETs) to adapt the high dynamics of FANETs. Moreover, few of existing routing protocols simultaneously meet the requirement of low delay and low energy consumption of FANETs. This paper proposes a novel Q-learning based Multi-objective optimization Routing protocol for FANETs to provide low-delay and low-energy service guarantees. Most of existing Q-learning based protocols use a fixed value for the Q-learning parameters. In contrast, Q-learning parameters can be adaptively adjusted in the proposed protocol to adapt to the high dynamics of FANETs. In addition, a new exploration and exploitation mechanism is also proposed to explore some undiscovered potential optimal routing path while exploiting the acquired knowledge. Instead of using past neighbor relationships, the proposed method re-estimates neighbor relationships in the routing decision process to select the more reliable next hop. Simulation results show that the proposed method can provide higher packet arrival ratio, lower delay and energy consumption than existing good performing Q-learning based routing method.},
  archive      = {J_COMCOM},
  author       = {Jianmin Liu and Qi Wang and ChenTao He and Katia Jaffrès-Runser and Yida Xu and Zhenyu Li and YongJun Xu},
  doi          = {10.1016/j.comcom.2019.11.011},
  journal      = {Computer Communications},
  pages        = {304-316},
  shortjournal = {Comput. Commun.},
  title        = {QMR: Q-learning based multi-objective optimization routing protocol for flying ad hoc networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Blind packet forwarding in a hierarchical level-based
locator/identifier split. <em>COMCOM</em>, <em>150</em>, 286–303. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Address Confidentiality (NAC) classifies all network nodes as adversaries and limits access to the network packet addresses in cleartext exclusively to the communicating endpoints. In our model, an adversary can control a single network node as well as a part or all of the network nodes on the route of a packet. Moreover, an adversary can observe and exploit network packet addresses. NAC implies certain anonymity properties, namely sender/recipient and relationship unlinkabilities. In contrast to the existing approaches related to NAC and its unlinkability properties with regard to our strong adversary model , Blind Packet Forwarding (BPF) tackles this issue in a clean-slate manner by redesigning the packet forwarding and its associated services to blind ones transferring and processing packet addresses in end-to-end encrypted form. This paper proposes a BPF architecture combining two approaches being based on the Locator/Identifier Split principle for a future network architecture . This BPF design introduces a fine-grained, flexible and dynamic blindness providing multiple NAC and unlinkability levels classified into two blindness taxonomies. In the first taxonomy, the higher the masking rank being applied to an address, the bigger is the radius of network domains within which NAC applies to the address, beginning with the top-level network domain. By applying higher masking ranks in the second blindness taxonomy, an endpoint can mask its address within higher network domains in direction of the top-level network domain. This paper also adapts OpenFlow in order to achieve a BPF implementation which provides high performance and can thus support multiple real-time media communications each with a high sending rate .},
  archive      = {J_COMCOM},
  author       = {Irfan Simsek},
  doi          = {10.1016/j.comcom.2019.11.024},
  journal      = {Computer Communications},
  pages        = {286-303},
  shortjournal = {Comput. Commun.},
  title        = {Blind packet forwarding in a hierarchical level-based Locator/Identifier split},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and development of wireless wearable bio-tooth sensor
for monitoring of tooth fracture and its bio metabolic components.
<em>COMCOM</em>, <em>150</em>, 278–285. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent past bedside monitoring test for oral portion has gained significance in the medical field than routine laboratory diagnosis due to the effectiveness and ease self-monitoring equipment without skilled person. Though various bio-tooth sensors have made their way to market, accurate detection and robustness plays a foremost setback when it comes in usage. In this research an improved wireless wearable Graphite bio-tooth sensor (GBTS) has been designed and developed to diagnose Coughing, drinking, chewing, Fracture, Infection and bio fluid. This sensor has the capability to analyze the object surface with wireless readout for tooth shape reconstruction and it checks the surface reflectance properties as one of the significant factor during tooth analysis. Saliva is generally considered a bio-fluid to be an important medical application for evaluating and monitoring the overall health of a patient using salivary bio-markers integrated into this wearable device . The experimental analysis has been evaluated on lab scale and the results demonstrate promising diagnostic and screening tools to improve the quality of life of patients.},
  archive      = {J_COMCOM},
  author       = {Mohamed Hashem and Abdulaziz A. Al Kheraif and H. Fouad},
  doi          = {10.1016/j.comcom.2019.11.004},
  journal      = {Computer Communications},
  pages        = {278-285},
  shortjournal = {Comput. Commun.},
  title        = {Design and development of wireless wearable bio-tooth sensor for monitoring of tooth fracture and its bio metabolic components},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of coverage algorithm for mobile sensor networks
based on virtual molecular force. <em>COMCOM</em>, <em>150</em>,
269–277. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General virtual force algorithm, when the density of sensor nodes is large in the monitoring area, there are some shortcomings, such as uneven distribution of nodes, more overlap of coverage area and so on. In view of these shortcomings, based on the basic idea of air molecular theory, a virtual molecular force model of mobile sensor networks is established, and the virtual molecular force algorithm for node deployment and mobile coverage of mobile sensor networks is given. The virtual molecular force algorithm assumes that there is interaction between nodes in mobile sensor networks, and the resultant force of these forces constitutes the resultant force network of sensor nodes in the monitoring area, which drives the sensor nodes to move to the corresponding location to repair the monitoring blind area, so as to maximize the coverage of the network. In order to verify the feasibility and effectiveness of the virtual molecular force algorithm, the virtual molecular force algorithm for mobile sensor network node deployment and mobile coverage is simulated and analysed by using MATLAB simulation tool. The simulation results show that the virtual molecular force algorithm can make the sensor nodes repair the monitoring blind area efficiently and quickly, and maximize the monitoring coverage area of the sensor network. In terms of repairing monitoring blind areas and improving network coverage, the virtual molecular force algorithm is superior to other network coverage algorithms such as general virtual force algorithm.},
  archive      = {J_COMCOM},
  author       = {Song Liu and Runlan Zhang and Yongheng Shi},
  doi          = {10.1016/j.comcom.2019.11.001},
  journal      = {Computer Communications},
  pages        = {269-277},
  shortjournal = {Comput. Commun.},
  title        = {Design of coverage algorithm for mobile sensor networks based on virtual molecular force},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Faulty-data detection and data quality measure in
cyber–physical systems through weibull distribution. <em>COMCOM</em>,
<em>150</em>, 262–268. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preeminent challenge when data is compiled from cyber–physical system is the detection and filtering of faulty data. When the storage, processing, and communication of a reasonable amount of data migrate to those mobile and embedded devices, it becomes strenuous to apply conventional powerful algorithms for identifying, eliminating, and tolerating the faulty data because of the resource constraints of these devices. Further, the real-time requirements of CPS applications require CPSs to respond quickly and the aggregation method that is long-established in CPSs makes it challenging to ascertain the value of the original data. Thus, a systematic approach is essential to accomplish the goal of faulty data detection and filtering. In this paper, we present several approaches that we can deploy to detect and filter faulty data efficiently and cost-effectively, to improve the quality of the collected data from a system’s perspective to match the specific requirements of CPSs.},
  archive      = {J_COMCOM},
  author       = {Gifty R. and Bharathi R. and Krishnakumar P.},
  doi          = {10.1016/j.comcom.2019.11.036},
  journal      = {Computer Communications},
  pages        = {262-268},
  shortjournal = {Comput. Commun.},
  title        = {Faulty-data detection and data quality measure in cyber–physical systems through weibull distribution},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An reactive void handling algorithm in sensor networks and
IoT emergency management. <em>COMCOM</em>, <em>150</em>, 254–261. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geographic routing in sensor networks and internet of things (IoT) prevails recent years as the localization technology advancing. The greedy forwarding is one of outstanding geographic routing schemes for its simplicity and efficiency. The greedy forwarding work efficiently in dense network, but may fails to send a packet further towards destination when encountering communication voids. Thus most geographic routing consists of two elements: 1) greedy forwarding scheme is used as long as possible, 2) a backup scheme resumes tasks when greedy forwarding fails due to local minimum. In this paper, we propose a novel void handling approach that detecting the boundary of voids and then a node in convex hull of boundary is selected as relay node . With the knowledge of relay node , the packets from source run around the void to construct path with less hop count. Simulation results indicate that this algorithm outperform classical geographic routing GPSR in several metrics.},
  archive      = {J_COMCOM},
  author       = {Zhao Qian and Fengbin Zhang},
  doi          = {10.1016/j.comcom.2019.11.010},
  journal      = {Computer Communications},
  pages        = {254-261},
  shortjournal = {Comput. Commun.},
  title        = {An reactive void handling algorithm in sensor networks and IoT emergency management},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient task scheduling for servers with dynamic states in
vehicular edge computing. <em>COMCOM</em>, <em>150</em>, 245–253. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicular edge computing has become an appealing paradigm to provide the delay-sensitive and multimedia-rich services by densely deploying the roadside units (RSUs) placed with edge servers. However, due to the geographical difference and energy efficiency, the computation loads of RSUs are serious unbalance, and the state of RSUs may switch to sleep in some cases for saving energy . This paper proposes a novel model of task scheduling where the state of the RSUs may dynamically switch between sleep and work in vehicular edge computing . The task requests of vehicles are modeled as an independent Poisson stream, and each edge server in RSU is modeled as a simple M/M/1 queuing system . The problem of minimizing the total delay of tasks on the proposed model is formulated and the NP-hardness of the problem is proved in this paper. A greedy algorithm is proposed for solving the problem by carefully selecting the RSUs. Meanwhile, a tabu search algorithm is customized to refine the solution generated by the proposed greedy algorithm . Moreover, a deep Q-network based algorithm is proposed utilizing the deep reinforcement learning approach, to learn the optimal scheduling policy without the prior knowledge of dynamic statistics. Simulation results show that, the deep Q-network based algorithm is the best among the proposed algorithms in terms of the total response time of tasks. All the proposed algorithms perform better than the random algorithm also presented in this paper. For example, the total response time of tasks for the deep Q-network based algorithm decreases by 24.13\%, 28.73\% and 35.95\%, compared with the customized tabu search algorithm , the greedy algorithm and the random algorithm, respectively, for the case of that the maximum tolerant response time of each task is 14s.},
  archive      = {J_COMCOM},
  author       = {Yalan Wu and Jigang Wu and Long Chen and Jiaquan Yan and Yuchong Luo},
  doi          = {10.1016/j.comcom.2019.11.019},
  journal      = {Computer Communications},
  pages        = {245-253},
  shortjournal = {Comput. Commun.},
  title        = {Efficient task scheduling for servers with dynamic states in vehicular edge computing},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weibull cumulative distribution based real-time response and
performance capacity modeling of cyber–physical systems through software
defined networking. <em>COMCOM</em>, <em>150</em>, 235–244. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Huge volumes of data are generated at rates faster than the speed of computing resources and executing processors available in market place. This anticipates a draft of information challenges associated with the performance capacity and the ability of big data processing systems to retort in real-time. Moreover, the elapsed time between probabilistic failures drops as the scale of information increases. An error occurred at a specific cluster node of a large Cyber–Physical System influences the overall computation requires to unfold big data transactions. Numerous failure characteristics, statistical response time and lifetime evaluation can be modeled through Weibull Distribution . In this paper, to scrutinize the latency for a data infrastructure, the three-parameter Weibull Cumulative Distribution is used through software defined networking in cyber–physical system. This speculation predicts that the shape of the response time distribution confide in the shape of the learning curve and depicts its parameters to the criterion of the input distribution.},
  archive      = {J_COMCOM},
  author       = {Gifty R. and Bharathi R.},
  doi          = {10.1016/j.comcom.2019.11.018},
  journal      = {Computer Communications},
  pages        = {235-244},
  shortjournal = {Comput. Commun.},
  title        = {Weibull cumulative distribution based real-time response and performance capacity modeling of Cyber–Physical systems through software defined networking},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). IoT assisted hierarchical computation strategic making
(HCSM) and dynamic stochastic optimization technique (DSOT) for energy
optimization in wireless sensor networks for smart city monitoring.
<em>COMCOM</em>, <em>150</em>, 226–234. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, Innovations and applications of the Internet of things (IoT) are empowering smart city activities worldwide. IoT technology is creating smart building frameworks with a heritage structure to enhance sustainability and energy optimization . The primary issue of energy consumption in sensor node depends on the average rate of power consumption of node times in Wireless Sensor Network (WSN) leads to several power optimization issues in the communication network during information sharing and processing. To address the optimization issues this research mainly focused to design and develop a Hybridized IoT assisted Hierarchical Computation Strategic Making (HCSM) Approach and Dynamic Stochastic Optimization Technique (DSOT) to oversee the energy optimization issue in a Wireless Sensor Network for smart city monitoring. Furthermore, the energy-constrained sensor node negotiates numerous activities associated with network and the selection of a sensor cluster node optimizes the energy consumption and sensing accuracy during information processing. The experimental outcomes show that the HCSM &amp; DSOT approaches are found capable of improving the energy efficiency of wireless sensor network and sensor cluster node selection at lab scale experimental validation.},
  archive      = {J_COMCOM},
  author       = {R.P. Meenaakshi Sundhari and K. Jaikumar},
  doi          = {10.1016/j.comcom.2019.11.032},
  journal      = {Computer Communications},
  pages        = {226-234},
  shortjournal = {Comput. Commun.},
  title        = {IoT assisted hierarchical computation strategic making (HCSM) and dynamic stochastic optimization technique (DSOT) for energy optimization in wireless sensor networks for smart city monitoring},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TBM: A trust-based monitoring security scheme to improve the
service authentication in the internet of things communications.
<em>COMCOM</em>, <em>150</em>, 216–225. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Securing communications and information sharing within the Internet of Things (IoT) paradigm is challenging because of the increase in the size and mobility of the user population. Moreover, managing a central security architecture requires adaptability and integration with a cloud network. In this manuscript, a trust-based monitoring (TBM) scheme was designed for improving the security features in cloud-assisted IoT environments. This security scheme employs middleware and intelligent agents for managing user- and communication-level security. TBM operates in three security administering phases namely spoof detection, trust construction, and message authentication . The intelligent agents are responsible for ensuring secure communication by exchanging trust and signal strength observations with the middleware. These agents also assist with monitoring, processing, and task switching to reduce communication costs. TBM was evaluated through extensive simulations. The results demonstrate its consistency in achieving lower response and detection times, misdetection probabilities, and false positive rates. In addition, it was found to improve network lifetime through reduced energy consumption.},
  archive      = {J_COMCOM},
  author       = {Fayez Alqahtani and Zafer Al-Makhadmeh and Amr Tolba and Omar Said},
  doi          = {10.1016/j.comcom.2019.11.030},
  journal      = {Computer Communications},
  pages        = {216-225},
  shortjournal = {Comput. Commun.},
  title        = {TBM: A trust-based monitoring security scheme to improve the service authentication in the internet of things communications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Power efficient memetic optimized and adjacent exponentially
distributed routing in mobile ad hoc networks. <em>COMCOM</em>,
<em>150</em>, 209–215. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile Ad Hoc Networks (MANETs) are self-organizing, infrastructure less, possessing constrained power, linked through wireless links without any centralized controller . Optimal selection of routes with minimum end-to-end delay and maximum packet delivery ratio was ensured using learning-based routing protocol, however power factor was not analyzed and therefore increasing the routing overhead. This paper employs the Adjacent Exponentially Distributed Route Maintenance mechanism to include an energy awareness feature with mean data packet arrival rate and link breakage rate to the identified route discovery mechanism. The proposed technique considers routes distance and power during route selection and includes routes energy consumption in its calculations. Besides, route discovery as an optimization is formulated employing Adjacent Exponential Distribution to choose a route that optimizes weighted function of route distance and energy. The simulation results show that the Memetic Optimized Adjacent Exponentially Distributed Routing (MO-AEDR) improves the packet delivery ratio with minimum end-to-end delay and routing overhead.},
  archive      = {J_COMCOM},
  author       = {P. Thiyagarajan and S. SenthilKumar},
  doi          = {10.1016/j.comcom.2019.11.025},
  journal      = {Computer Communications},
  pages        = {209-215},
  shortjournal = {Comput. Commun.},
  title        = {Power efficient memetic optimized and adjacent exponentially distributed routing in mobile ad hoc networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance improvement in satellite image classification
using adaptive supervised multi-resolution approach. <em>COMCOM</em>,
<em>150</em>, 200–208. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multispectral satellite images have a few straps, which have a lower determination and tight data. The purpose is to increase the external and spectral data of satellite images by utilizing high demand intelligence in a mix of force shadow immersion using Multi-resolution 3D modeling classification approach tracked for this work acceptance. The proposed 3D-based Adaptive Supervised Multi-Resolution (ASMR) method that automatically classifies different regions of space–time detection of remote images. Firstly, a 3D central multispectral and multi-volatile remote sensor is designed to compile data structure . Secondly, 3D multi-resolution framework with the acceptance under purified parameters tracking aims at creating 3D region models and learning spatiotemporal attribute representations. Connected parameters are being monitored to evaluate the performance of a 3D compatible multi-resolution project: Root stands for quadratic error, correlation coefficient, structural similarity index measure, and spectral mean relative error. The generated information uses more arranged knowledge to reduce the number of satellite images used to be used by independent band component evolutionary bias. The performance of the proposed method has been validated by simulation using Matlab software. As compared to the traditional 3D layout of the 3D image classification , the proposed solution achieves 97.72\% accuracy, 98.25\% sensitivity and 94.02\% specificity.},
  archive      = {J_COMCOM},
  author       = {S. Jayanthi and C. Vennila},
  doi          = {10.1016/j.comcom.2019.11.005},
  journal      = {Computer Communications},
  pages        = {200-208},
  shortjournal = {Comput. Commun.},
  title        = {Performance improvement in satellite image classification using adaptive supervised multi-resolution approach},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic classification for connectionless services with
incremental learning. <em>COMCOM</em>, <em>150</em>, 185–199. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technological advancement in VoIP technology and P2P streaming led to the development of novel applications. Most of these applications use UDP traffic. The availability of UDP services for applications such as streaming, trivial file transfer, are denied to legitimate users due to malicious traffic, intentionally created by abnormal requesting behaviour of the botnets . Categorizing the traffic is required to discriminate the malicious traffic that occur due to attacks from normal traffic for better real time resource allocation. For this purpose, this paper proposes a two level hybrid classification model based on incremental learning to detect high and low rate attacks that deny the legitimate access to connectionless services . The simulation results show that the proposed incremental learning strategy improves the classification accuracy of the proposed hybrid classifier compared to existing traditional learning methods.},
  archive      = {J_COMCOM},
  author       = {V. Punitha and C. Mala},
  doi          = {10.1016/j.comcom.2019.11.017},
  journal      = {Computer Communications},
  pages        = {185-199},
  shortjournal = {Comput. Commun.},
  title        = {Traffic classification for connectionless services with incremental learning},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CDAM: Conservative data analytical model for dynamic climate
information evaluation using intelligent IoT environment—an application
perspective. <em>COMCOM</em>, <em>150</em>, 177–184. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of IoT in real-time applications has served the purpose of providing sophisticated services for industrial and residential purposes. Environmental observation and analysis of data have prevailed over multiple real-time applications for improving the efficiency of fore-cast and reporting systems. Analysis of observed data is prominent in determining the efficiency of reporting system despite compensating observation and processing errors. In this article, a conservative data analytical model (CDAM) is presented for real-time data evaluation and remittance. This evaluation model relies on the factors of correlation and conditional similarity verification for remitting reliable information across the reporting system. The correlation analysis model is preceded using fuzzy derivatives for deriving possible solutions. The solutions are obtained for the varying sensor update over uneven time intervals. The proposed CDAM is tested with the available real-time weather information for predicting dynamic climatic changes in a given region. The experimental verification of the proposed CDAM shows that it improves correlation accuracy and data analysis rate by reducing the error rate.},
  archive      = {J_COMCOM},
  author       = {Jun Ma and Hongzhi Yu and Yan Xu and Kaiying Deng},
  doi          = {10.1016/j.comcom.2019.11.014},
  journal      = {Computer Communications},
  pages        = {177-184},
  shortjournal = {Comput. Commun.},
  title        = {CDAM: Conservative data analytical model for dynamic climate information evaluation using intelligent IoT environment—An application perspective},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combination of wearable sensors and internet of things and
its application in sports rehabilitation. <em>COMCOM</em>, <em>150</em>,
167–176. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern neurological rehabilitation medicine and its clinical research results show that through the scientific rehabilitation training, the damaged limb motor function can be restored to some extent. During the entire rehabilitation process, the physician needs to monitor and evaluate the patient’s physical condition and training effect in real time in order to develop or adjust the follow-up rehabilitation training program. Therefore, this paper takes the sports rehabilitation training as the background and based on the Internet of Things technology to develop a sports rehabilitation monitoring system based on wearable sensors and Internet of Things technology . Through the development of the sensory sensor monitoring sensor terminal node , based on the needs of physiological parameter monitoring during the rehabilitation training process, a monitoring system including electrocardiogram (ECG) signals, electromyography (EMG) signals, motion posture, body temperature and other physiological parameters was constructed based on the Internet of Things technology. The experimental results show that the system constructed in this paper can closely monitor the changes of vital signs of target users while providing real-time monitoring, and provide feedback. These physiological data can be analyzed to help doctors formulate effective rehabilitation training programs. Evaluate the recovery of exercise capacity and training participation, so as to achieve the purpose of improving training efficiency and achieving rehabilitation effects},
  archive      = {J_COMCOM},
  author       = {Yanping Jiang},
  doi          = {10.1016/j.comcom.2019.11.021},
  journal      = {Computer Communications},
  pages        = {167-176},
  shortjournal = {Comput. Commun.},
  title        = {Combination of wearable sensors and internet of things and its application in sports rehabilitation},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The construction of smart city information system based on
the internet of things and cloud computing. <em>COMCOM</em>,
<em>150</em>, 158–166. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development and deep application and cooperation of new concepts and technologies brought by the Internet of Things and cloud computing all over the world, all walks of life have gradually moved towards a ”smart” modern society. These technologies have gradually penetrated into the field of smart cities. The traditional urban system, the system that has been handed down since ancient times, has a very inefficient and cumbersome mode of operation, and the information between the systems has not been effectively shared and interconnected. In order to solve this series of problems, this study first studies the development of the Internet of Things , cloud computing-related technologies and smart cities, and then focuses on the key technologies of the Internet of Things and cloud computing in the field of structure and application. Under the support of these two technologies, proposed a smart city system based on Internet and cloud computing. System architecture , application system design, application support platform, various transmission networks and typical sensors are studied in detail and on different levels. In smart city systems based on the Internet of Things, sensor networks are often placed in unreliable communication environments, and this usually causes the transmission of information to fail. Whether the sensor chooses to transmit again after the information transmission fails is an optimized problem. This research study proposes a data aggregation algorithm based on Markov chain to solve the problem of transmitting such data again. The experimental results show that the system can realize information sharing, exchange and fusion between various sensing subsystems, solve the previous information island phenomenon and meet the actual needs of smart cities.},
  archive      = {J_COMCOM},
  author       = {Dingfu Jiang},
  doi          = {10.1016/j.comcom.2019.10.035},
  journal      = {Computer Communications},
  pages        = {158-166},
  shortjournal = {Comput. Commun.},
  title        = {The construction of smart city information system based on the internet of things and cloud computing},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detection of flood disaster system based on IoT, big data
and convolutional deep neural network. <em>COMCOM</em>, <em>150</em>,
150–157. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural disasters could be defined as a blend of natural risks and vulnerabilities. Each year, natural as well as human-instigated disasters, bring about infrastructural damages, distresses, revenue losses, injuries in addition to huge death roll. Researchers around the globe are trying to find a unique solution to gather, store and analyse Big Data (BD) in order to predict results related to flood based prediction system. This paper has proposed the ideas and methods for the detection of flood disaster based on IoT , BD, and convolutional deep neural network (CDNN) to overcome such difficulties. First, the input data is taken from the flood BD. Next, the repeated data are reduced by using HDFS map-reduce (). After removal of repeated data, the data are pre-processed using missing value imputation and normalization function. Then, centred on the pre-processed data, the rule is generated by using a combination of attributes method. At the last stage, the generated rules are provided as the input to the CDNN classifier which classifies them as a) chances for the occurrence of flood and b) no chances for the occurrence of a flood. The outcomes obtained from the proposed CDNN method is compared parameters like Sensitivity, Specificity, Accuracy, Precision, Recall and F-score. Moreover, when the outcomes is compared other existing algorithms like Artificial Neural Network (ANN) &amp; Deep Learning Neural Network (DNN), the proposed system gives is very accurate result than other methods.},
  archive      = {J_COMCOM},
  author       = {M. Anbarasan and BalaAnand Muthu and C.B. Sivaparthipan and Revathi Sundarasekar and Seifedine Kadry and Sujatha Krishnamoorthy and Dinesh Jackson Samuel R. and A. Antony Dasel},
  doi          = {10.1016/j.comcom.2019.11.022},
  journal      = {Computer Communications},
  pages        = {150-157},
  shortjournal = {Comput. Commun.},
  title        = {Detection of flood disaster system based on IoT, big data and convolutional deep neural network},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Software-defined network assisted packet scheduling method
for load balancing in mobile user concentrated cloud. <em>COMCOM</em>,
<em>150</em>, 144–149. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud Network provides a variety of applications and services to meet the requirements of increasing user demands. With its dedicated components, the cloud enables anywhere anytime access of resources to its associated users. A significant factor that holds the performance of the cloud is its congestion, due to unpredictable traffic and asynchronous user demands. Though load balancers serve the purpose of optimizing network traffic, congestion is unavoidable when the level of user demand increases. In this manuscript, a Resource-aware Packet-level Scheduling with Load Balancing (RPS-LB) algorithm is proposed to minimize congestion. In RPS , the incoming network traffic is disseminated through instantaneous neighbors by analyzing their Store and Forward (SF) factor. SF factor is pre-estimated through Estimated Transmission Count (ETX) metric. With this analysis, the reliability of the instantaneous neighbor for handling the current packet-level transmission is verified. This algorithm addresses the issues in user-level and flow-level to mitigate stagnancy and overflow of network traffic. Besides, the proposed load-balancing algorithm is defined as a linear optimization problem within definite constraints to prevent degradation proportional to user density. The performance of the proposed system is assessed by using the performance evaluation parameters such as Queue Utilization, Request Success Rate, Request Failure Rate, Response Time and Link Utilization. The simulation results show that the proposed system performs well than the existing systems.},
  archive      = {J_COMCOM},
  author       = {V. Deeban Chakravarthy and B. Amutha},
  doi          = {10.1016/j.comcom.2019.11.012},
  journal      = {Computer Communications},
  pages        = {144-149},
  shortjournal = {Comput. Commun.},
  title        = {Software-defined network assisted packet scheduling method for load balancing in mobile user concentrated cloud},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bonded channel in cognitive wireless body area network
based on IEEE 802.15.6 and internet of things. <em>COMCOM</em>,
<em>150</em>, 131–143. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the recent developments in communication technologies for wireless body area networks (WBAN), the reliability of packet transmission , especially for emergency and critical data transfer remains a significant challenge. This may be that most of the existing techniques in WBAN use single-channel for data transmission with no intelligence. The cognitive bonded channel which provides high data rate for emergency and the demanding situation. Existing techniques in WBAN rely on the use of the single-channel for data transmission and do not exploit the use of the bonded channel, which can improve the WBAN capacity of off-body communication. In our research, we propose a traffic load aware bonded channel algorithm (TLA-BCA), which exploits channel bonding to improve the performance of off-body communication between the WBAN sink nodes and gateway. Our proposed algorithm, i.e., TLA-BCA utilizes high-quality channels for channel bonding to maximize the capacity of off-body communication in WBANs. TLA-BCA demonstrates significant performance improvement over Traffic Priority Based Channel Assignment Technique (TP-CAT) and Static Channel Assignment (SCA) in terms of average throughput, average end-to-end delay with comparable energy performance.},
  archive      = {J_COMCOM},
  author       = {Fahim Niaz and Muhammad Khalid and Zahid Ullah and Nauman Aslam and Mohsin Raza and M.K. Priyan},
  doi          = {10.1016/j.comcom.2019.11.016},
  journal      = {Computer Communications},
  pages        = {131-143},
  shortjournal = {Comput. Commun.},
  title        = {A bonded channel in cognitive wireless body area network based on IEEE 802.15.6 and internet of things},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ANFIS with natural language processing and gray relational
analysis based cloud computing framework for real time energy efficient
resource allocation. <em>COMCOM</em>, <em>150</em>, 122–130. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the most commonly used types of application, command line applications have aroused extensive attention. Predicting command line application workload and providing reasonable resource scheduling strategy can effectively improve resource utilization and performance of VMs. This paper provided a novel scheme with two-level hybrid adaptive model to predict VMs load based on the strong regularity of command line applications, and elastically configured the CPU and memory resource for VMs. Instead of time series prediction, we extracted and analyzed the feature attributes of command line applications by natural language processing (NLP) technology, and used the gray relational analysis (GRA) to implement attribute reductions . Then a two-level hybrid adaptive model was designed to predict the VM load efficiently and accurately, including CPU and memory load. Bayesian algorithm was used for classification to select the applications that increase the CPU of a VM by more than 5\%, then giving the CPU and memory load prediction of VMs by aANFIS model. Extensive experiments demonstrated that the elastic allocation strategy can improve the VMs performance and resource utilization.},
  archive      = {J_COMCOM},
  author       = {Xiang Wu and Huanhuan Wang and Dashun Wei and Minyu Shi},
  doi          = {10.1016/j.comcom.2019.11.015},
  journal      = {Computer Communications},
  pages        = {122-130},
  shortjournal = {Comput. Commun.},
  title        = {ANFIS with natural language processing and gray relational analysis based cloud computing framework for real time energy efficient resource allocation},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient distributed average consensus in wireless sensor
networks. <em>COMCOM</em>, <em>150</em>, 115–121. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computing the distributed average consensus in Wireless Sensor Networks (WSNs) is investigated in this article. This problem, which is both natural and important, plays a significant role in various application fields such as mobile agents and fleet vehicle coordination, network synchronization , distributed voting and decision, load balancing of divisible loads in distributed computing network systems, and so on. By and large, the average consensus’ objective is to have all nodes in the network converged to the average value of the initial nodes’ measurements based only on local nodes’ information states. In this paper, we introduce a fully distributed algorithm to average the sensed data within the network itself. The network may be large since we never broadcast over all its nodes. Unlike earlier works, when a node detects a load (scalar value) imbalance in its closed neighborhoods during the average process, instead of sending parsimonious amount of load values from highly loaded nodes to less loaded ones, we move a large amount of load values by involving parallel atomic transactions between mutually exclusive pairs of neighbors. This improves the global convergence time speedup with low-cost communication and minimal energy consumption. First, we give the convergence proof of the distributed consensus process, and next we provide some experimental results based on NS3 framework to assess the behavior of the proposed algorithm.},
  archive      = {J_COMCOM},
  author       = {Christophe Guyeux and Mohammed Haddad and Mourad Hakem and Matthieu Lagacherie},
  doi          = {10.1016/j.comcom.2019.11.006},
  journal      = {Computer Communications},
  pages        = {115-121},
  shortjournal = {Comput. Commun.},
  title        = {Efficient distributed average consensus in wireless sensor networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A unified hybrid information-centric naming scheme for IoT
applications. <em>COMCOM</em>, <em>150</em>, 103–114. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is key enabling technology for future Internet, and aims at connecting heterogeneous devices and objects using wireless technologies . This connectivity results in creating a massive number of heterogeneous devices, and a large amount of content, thereby creating new challenges regarding content, service, and device naming. Current Internet applications and use cases are now shifting toward the content-centric paradigm, where the content is the key element in the infrastructure. In this article, we design a hybrid multilayer naming scheme with multi-component hierarchical and attribute-value components for a data-centric Internet of Things . The proposed scheme targets smart IoT applications and provides built-in scalability, efficient routing, and security features. We incorporate a variable-length encoding method, with a prefix-labeling scheme in order to describe hierarchical location names with various embedded semantic functionalities. Moreover, the scheme supports fast local IoT communication using Name-to-Code translation concept, as well as multi-source content retrieval through in-network function. To evaluate the performance and prove the efficiency of the proposed scheme, we carry extensive experiments, using ndnSIM network simulator . The analysis shows that our proposed hybrid naming is inherently better than the existing state-of-the-art solutions, and drastically reduces the memory consumption, lookup time, routing and forwarding overhead, and enhances the overall IoT communication.},
  archive      = {J_COMCOM},
  author       = {Boubakr Nour and Kashif Sharif and Fan Li and Hassine Moungla and Yang Liu},
  doi          = {10.1016/j.comcom.2019.11.020},
  journal      = {Computer Communications},
  pages        = {103-114},
  shortjournal = {Comput. Commun.},
  title        = {A unified hybrid information-centric naming scheme for IoT applications},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FFBKS: Fuzzy fingerprint biometric key based security schema
for wireless sensor networks. <em>COMCOM</em>, <em>150</em>, 94–102. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much advancement in Wireless Sensor Network (WSN) occurred in the recent years forces a higher level of security in data transmission. Cryptographic keys are utilized for confidentiality, authentication , approval, and data integrity. Various research works were carried out to deal with key management issues in WSNs. Currently, a novel Self-managing Volatile Key Scheme (Self-VKS) for WSNs is initiated in which prime numbers are utilized for group key generation. It will accurately examine node security for limited amount of nodes. So, novel methodology is required to model network which can examine node with secure data transmission for more amount of nodes devoid of limitation. In this research paper, Fuzzy Fingerprint Biometric based Key Security (FFBKS) scheme is introduced by utilizing feature extraction. Extracted feature vectors securely produces private key for user. This key is sent to every sensor node , then private key among sensor nodes are produced by pseudo random number and user key. Then, Adaptive Possibilistic C-means Clustering (APCMC) is initiated for nodes grouping based on distance and identifier among nodes. Here group key is produced based on fuzzy membership function from prime numbers and it is utilized for estimation of security. After grouping is formed, data transmission is carried out among group key by fuzzy membership and sensor nodes are carried out by biometric based private key.Cluster group keys are diverse from one cluster to another. At last, recreation is carried out on platform of MATLAB simulator. The experimental results show that the proposed FFBKS scheme achieves better performance compared with the existing system in terms of simulation time, energy consumption, delay and attack detection rate.},
  archive      = {J_COMCOM},
  author       = {B. Nivedetha and Ila. Vennila},
  doi          = {10.1016/j.comcom.2019.11.007},
  journal      = {Computer Communications},
  pages        = {94-102},
  shortjournal = {Comput. Commun.},
  title        = {FFBKS: Fuzzy fingerprint biometric key based security schema for wireless sensor networks},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Car-to-pedestrian communication with MEC-support for
adaptive safety of vulnerable road users. <em>COMCOM</em>, <em>150</em>,
83–93. (<a href="https://doi.org/10.1016/j.comcom.2019.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Car-to-Pedestrian (Car2P) communication has a huge potential for preventing potential accidents between pedestrians and vehicles by exchanging context information. Similar communication principles have been explored for Car-to-Car (C2C) communication since quite a while and are now being deployed as an additional safety mechanism. Unfortunately, Vulnerable Road Users (VRUs) such as pedestrians and bicyclists are not yet covered by these systems. Looking at pedestrians, we explore possibilities for the exchange of relevant safety mechanisms between pedestrians and cars making use of readily available communication capabilities of current LTE networks. Necessary activity and collision detection algorithms have to be run on the users’ smartphones in order to determine the criticality of the situation. In order to improve both the overall system latency and the energy efficiency of the smartphone applications , we suggest the use of Multi-access Edge Computing (MEC). We implemented the system to perform measurements on the smartphone side as well as extensive simulations on the networking side. Our results clearly show the advantages of our concept and the integrated MEC approach.},
  archive      = {J_COMCOM},
  author       = {Quang-Huy Nguyen and Michel Morold and Klaus David and Falko Dressler},
  doi          = {10.1016/j.comcom.2019.10.033},
  journal      = {Computer Communications},
  pages        = {83-93},
  shortjournal = {Comput. Commun.},
  title        = {Car-to-pedestrian communication with MEC-support for adaptive safety of vulnerable road users},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel opportunistic power controlled routing protocol for
internet of underwater things. <em>COMCOM</em>, <em>150</em>, 72–82. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Underwater Things (IoUTs) has been proposed to collect data from aquatic environments, in a large-scale and autonomous manner. These networks currently consider the acoustic channel is as the most viable technology for underwater wireless communication . By using acoustic modems, underwater sensor nodes are capable of collaboratively sense the area of interest and report collected data to a monitoring center through multi-hop underwater wireless communication . However, underwater wireless communication through acoustic channels is daunting due to the limited bandwidth , multipath propagation , shadowing zones, high and variable delay, noisy environment , and high energy cost. These characteristics impair data collection and shorten the IoUT lifetime. In this paper, we propose a novel power control-based opportunistic (PCR) routing protocol for IoUTs. The proposed protocol considers the neighborhood density, link quality, distance, packet advancement, and energy waste to select the suitable transmission power level at each sensor node. Accordingly, each neighboring node eligible to continue forwarding the data packet is considered as a next-hop forwarder node if its inclusion in the next-hop nodes candidate set does not increase the energy waste in the considered hop. Numerical results showed that the proposed protocol improves the data delivery rate while maintaining the energy cost at levels comparable to the related work.},
  archive      = {J_COMCOM},
  author       = {Rodolfo W.L. Coutinho and Azzedine Boukerche and Antonio A.F. Loureiro},
  doi          = {10.1016/j.comcom.2019.10.020},
  journal      = {Computer Communications},
  pages        = {72-82},
  shortjournal = {Comput. Commun.},
  title        = {A novel opportunistic power controlled routing protocol for internet of underwater things},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wearable health monitoring system based on human motion
state recognition. <em>COMCOM</em>, <em>150</em>, 62–71. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wearable health monitoring system is a typical application of wearable computing in the medical field. However, existing research often does not consider the characteristics of human physiological characteristics and exercise state in practical applications, and only judges the health of users from physiological data . The lack of information on the state of motion at that time caused a certain degree of misjudgment. For the coexistence of multiple types of devices and multiple transmission methods, this paper first proposes a wearable health monitoring system architecture based on human motion state recognition. Secondly, according to the characteristics of short-term persistence of daily activities of the human body, its motion state is divided into a steady state and an unstable state. The three-axis acceleration vector value is converted into the acceleration amplitude change amount, which eliminates the wearing correlation of the sensor coordinate system. Finally, we conducted a simulation experiment. The experimental results show that the algorithm achieves high accuracy in state recognition, and the recognition accuracy of running and walking is better than decision tree identification algorithm .},
  archive      = {J_COMCOM},
  author       = {Xiaoxiang Zhou},
  doi          = {10.1016/j.comcom.2019.11.008},
  journal      = {Computer Communications},
  pages        = {62-71},
  shortjournal = {Comput. Commun.},
  title        = {Wearable health monitoring system based on human motion state recognition},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emergent properties, models, and laws of behavioral
similarities within groups of twitter users. <em>COMCOM</em>,
<em>150</em>, 47–61. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA-inspired online behavioral modeling techniques have been proposed and successfully applied to a broad range of tasks. In this paper, we investigate the fundamental laws that drive the occurrence of behavioral similarities among Twitter users, employing a DNA-inspired technique. Our findings are multifold. First, we demonstrate that, despite apparently featuring little to no similarities, the online behaviors of Twitter users are far from being uniformly random. Secondly, we benchmark different behavioral models through a number of simulations. We characterize the main properties of such models and we identify those models that better resemble human behaviors in Twitter. Then, we demonstrate that the number and the extent of behavioral similarities within a group of Twitter users obey a log-normal law, and we leverage this characterization to propose a novel bot detection system. In a nutshell, the results shed light on the fundamental properties that drive the online behaviors of groups of Twitter users, through the lenses of DNA-inspired behavioral modeling techniques. This study is based on a wealth of data gathered over several months that, for the sake of reproducibility, are publicly available for research purposes.},
  archive      = {J_COMCOM},
  author       = {Stefano Cresci and Roberto Di Pietro and Marinella Petrocchi and Angelo Spognardi and Maurizio Tesconi},
  doi          = {10.1016/j.comcom.2019.10.019},
  journal      = {Computer Communications},
  pages        = {47-61},
  shortjournal = {Comput. Commun.},
  title        = {Emergent properties, models, and laws of behavioral similarities within groups of twitter users},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trust management in social internet of things: A taxonomy,
open issues, and challenges. <em>COMCOM</em>, <em>150</em>, 13–46. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is an emerging area in which billions of smart objects are interconnected with each other using Internet for data and resource sharing. These smart objects are generally used to sense various parameters such as temperature, motion of objects, and occupancy from the environment where these are deployed, the values of which are transmitted to the nearest access points to taken intelligent decisions. However, with an increased penetration of smart objects in our daily life, these objects may also participate in social events using machine-to-machine or human-to-machine interactions and are called as Social Objects . This new paradigm of interaction among social objects is referred to as Social IoT (SIoT) . As these objects communicate with each other using an open channel, i.e., Internet, so security and privacy along with integrity of messages always remain a concern. Motivated from the aforementioend issues, in this paper, we provide an elaborated view of trust management among these objects with a focus on SIoT by comparing different existing trust management schemes based on the trust management process, parameters chosen for trust evaluation, characteristics of trust functions and objectives achieved by them. Moreover, we also discuss various challenges such as use of social behavior specific trust evaluation metrics and type of relationships between objects in SIoT with respect to trust management. Thus, the analysis provided in this paper provides insights to the readers for applicability of trust management scheme in SIoT environment keeping in of various challenges and constraints.},
  archive      = {J_COMCOM},
  author       = {Rajanpreet Kaur Chahal and Neeraj Kumar and Shalini Batra},
  doi          = {10.1016/j.comcom.2019.10.034},
  journal      = {Computer Communications},
  pages        = {13-46},
  shortjournal = {Comput. Commun.},
  title        = {Trust management in social internet of things: A taxonomy, open issues, and challenges},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Experimenting with open source tools to deploy a
multi-service and multi-slice mobile network. <em>COMCOM</em>,
<em>150</em>, 1–12. (<a
href="https://doi.org/10.1016/j.comcom.2019.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With network slicing, the infrastructure is divided into separate networks, each one customized to provide a specific service. Network slicing is a key technology to efficiently support services with very diverse requirements, such as the ones that should support 5G networks . While the architectural work for 5G is well advanced, and many theoretical solutions that address diverse aspects such as resource assignment or service composition exist, the experimental work lags behind. In this paper, we aim at filling this gap by describing our implementation experiences when deploying a small-scale multi-service prototype. We consider a video streaming service and an augmented reality service, each one provided over a different network slice, and extend existing open-source software solutions for a better provision of them. Our implementation showcases key features of future 5G networks , such as radio slicing with service differentiation, support for local breakout , or multi-slice orchestration with QoE-triggered optimization. With the core of our implementation being open-source, we believe that our results will prove very useful to researchers and practitioners working on this area of research.},
  archive      = {J_COMCOM},
  author       = {Gines Garcia-Aviles and Marco Gramaglia and Pablo Serrano and Francesco Gringoli and Sergio Fuente-Pascual and Ignacio Labrador Pavon},
  doi          = {10.1016/j.comcom.2019.11.003},
  journal      = {Computer Communications},
  pages        = {1-12},
  shortjournal = {Comput. Commun.},
  title        = {Experimenting with open source tools to deploy a multi-service and multi-slice mobile network},
  volume       = {150},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Link quality and energy utilization based preferable next
hop selection routing for wireless body area networks. <em>COMCOM</em>,
<em>149</em>, 382–392. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising population and cost of medical services triggered the new technologies including Wireless Body Area Networks (WBANs) based on smart and intelligent biosensors nodes for sensing and monitoring the patient vital signs. The biosensor nodes have implanted inside or outside the human body to send the medical information to medical centers. For data dissemination in these services, different types of solutions and model have been designed to address the interference, body movement, disconnection quality of services issues in the network. This paper presents an Energy Aware Routing (EAR) protocol to minimize energy utilization and select preferable next hop by evaluating the link quality of sensor nodes . The proposed protocol evaluates the energy level, link quality, and remaining energy level to balance the load, minimize the energy utilization, and enhance the data transmission. Various simulations have conducted to evaluate the proposed protocols performance in terms of energy consumption, data delivery, delay, and data throughput . Experimental results indicated that the proposed protocol has a better mechanism for date routing and better solution to minimize the energy of sensor nodes in WBANs.},
  archive      = {J_COMCOM},
  author       = {Kashif Naseer Qureshi and Sadia Din and Gwanggil Jeon and Francesco Piccialli},
  doi          = {10.1016/j.comcom.2019.10.030},
  journal      = {Computer Communications},
  pages        = {382-392},
  shortjournal = {Comput. Commun.},
  title        = {Link quality and energy utilization based preferable next hop selection routing for wireless body area networks},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis of dual connectivity in
control/user-plane split heterogeneous networks. <em>COMCOM</em>,
<em>149</em>, 370–381. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure seamless mobility, logical separation between control plane and data plane has been evolved as a promising solution for the forthcoming fifth generation ( 5G ) cellular networks . Here, macro-cells provide control coverage using a low frequency band signal, whereas small-cells provide high data rates to the mobile terminals ( MTs ) over high frequency band signals. While performing frequent handovers over small-cells, throughput perceived by an MT may fall below the requested data rate. To deal with the high data rate demand of the forthcoming 5G networks, recently dual connectivity ( DC ) technology has been proposed for long term evolution ( LTE ) networks in Release 12. However, analyzing the performance of DC in control/user-plane ( C/U ) split LTE heterogeneous networks is quite limited in the preceding literature. In this work, we propose an analytical framework to compare the performances of DC with hard handover in C/U split architecture in terms of system throughput and saturation probability , i.e., the probability that the total demand for resources exceeds the total capacity of the serving cells. Our proposed framework explicitly considers the data rate demands of the MTs , traffic arrival pattern and channel conditions. The analytical results have also been validated against simulation results. Our analyses reveal that the performance gain of DC over traditional hard handover is actually conditional on underlying traffic load density and call arrival rates.},
  archive      = {J_COMCOM},
  author       = {Shankar K. Ghosh and Sasthi C. Ghosh},
  doi          = {10.1016/j.comcom.2019.10.032},
  journal      = {Computer Communications},
  pages        = {370-381},
  shortjournal = {Comput. Commun.},
  title        = {Performance analysis of dual connectivity in control/user-plane split heterogeneous networks},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evaluative review of the VTOL technologies for unmanned
and manned aerial vehicles. <em>COMCOM</em>, <em>149</em>, 356–369. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {VTOL (Vertical Take-Off and Landing) capabilities are desired features of both UAVs (Unmanned Aerial Vehicles) and MAVs (Manned Aerial Vehicles) on condition that a comparable flight performance is achieved. VTOL is not only a very suitable technology for UAVs due to the convenience and concealment mission requirements of UAVs, but also very important for both military and civil MAVs due to the advantages of less or even no dependency on airports/air fields. As such, it is necessary to study and compare the VTOL technology of MAVs and UAVs at the same time. This paper highlights the major VTOL technologies and the representing aircraft configurations. The recent VTOL projects in the US are reviewed and compared to give insight into the technological diversities, application opportunities as well as the future development trend for urban air mobility . Then, an intuitive summary and comparison of famous projects and models has been made. Based on the above research, challenges and constraints of VTOL aircraft are summarized. As a supplement to the review of VTOL technologies, the current research activities on short takeoff and landing technologies via active flow control for large commercial aircraft in Europe is also reviewed. At the end, based on the above analysis, this paper points out the future development direction of VTOL vehicles.},
  archive      = {J_COMCOM},
  author       = {Yaoming Zhou and Haoran Zhao and Yaolong Liu},
  doi          = {10.1016/j.comcom.2019.10.016},
  journal      = {Computer Communications},
  pages        = {356-369},
  shortjournal = {Comput. Commun.},
  title        = {An evaluative review of the VTOL technologies for unmanned and manned aerial vehicles},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A room-level tag trajectory recognition system based on
multi-antenna RFID reader. <em>COMCOM</em>, <em>149</em>, 350–355. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory of objects is a typical data source of indoor location aware applications and smart systems. In some object tracking applications, the continuity of moving trajectories recognition is more important than its positioning accuracy. To solve the problem of signal coverage blind areas and multi-tag identification reliability, this paper proposes a tag trajectory index method that solves the problem of localized tag trajectories between readers, and establishes a tag identification model based on RFID reader with multiple antennas , which is more economic and efficient in deployment. Furthermore, it proposes a multi-antenna optimization control scheme, which automatically adapts to the actual demands to control the number of working antennas, so as to improve the recognition efficiency. A counterpart indoor tag trajectory reasoning data structure OPTR-tree is proposed, which provides an approach for multi-tag track fast recognition in indoor environment at room-level accuracy. Both theoretical analysis and experimental results show that the proposed multi-antenna model can improve the reliability of multiple tags recognition inside buildings Hopefully, the indoor trajectories data can offer a new way for more effective disaster management.},
  archive      = {J_COMCOM},
  author       = {Shuoming Li and Jianbin Lu and Shihong Chen},
  doi          = {10.1016/j.comcom.2019.10.025},
  journal      = {Computer Communications},
  pages        = {350-355},
  shortjournal = {Comput. Commun.},
  title        = {A room-level tag trajectory recognition system based on multi-antenna RFID reader},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliable object recognition system for cloud video data
based on LDP features. <em>COMCOM</em>, <em>149</em>, 343–349. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object recognition is one of the research areas with good scope in most of the applications. However, the object recognition on cloud stored data is very limited and the video based object recognition systems are minimal. Taking this into account, the videos are processed for recognizing the objects of interest by incorporating advanced image processing activities. The video frames are extracted from the videos for recognizing the objects. In order to recognize the objects, the objects have to be detected first. The objects are detected by means of SURF detector and the combination of local and global LDP features is extracted. Finally, the objects present in the videos are matched with the objects of interest. The performance of the proposed object recognition system for cloud video data is tested in three rounds. Initially, the proposed work is tested with different videos and then the proposed work is evaluated by varying the feature extractors such as Local Binary Pattern (LBP), Local LDP, Global LDP. Finally, the video processing time is calculated in terms of both CPU and GPU . All the performance evaluations are carried out in terms of accuracy, sensitivity, specificity and time consumption. The performance of the proposed approach is proven to be satisfactory.},
  archive      = {J_COMCOM},
  author       = {M. Gomathy Nayagam and K. Ramar},
  doi          = {10.1016/j.comcom.2019.10.027},
  journal      = {Computer Communications},
  pages        = {343-349},
  shortjournal = {Comput. Commun.},
  title        = {Reliable object recognition system for cloud video data based on LDP features},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Research on the application of block chain big data platform
in the construction of new smart city for low carbon emission and green
environment. <em>COMCOM</em>, <em>149</em>, 332–342. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharing of government information resources is significant for improving the level of governance and social information. However, due to the existence of cross-domain security and trust islands, government departments are hindering the sharing of government information resources with other organizations and the public. To this end, the blockchain technology is used to construct a decentralized distributed peer-to-peer trust service system, which is integrated with the existing PKI/CA security system to establish a new trust model that supports multi-CA coexistence. Based on this, the structural composition and functional data flow of the blockchain smart city information resource sharing and exchange model designed in this paper. This paper launched a study on the role of the smart big data platform, and selected the development of smart cities in Hefei as an empirical analysis. From the connotation of smart city, block chain and big data technology combined, and the positive effects of relevant information technology summarized on the construction of smart city big data platform. Based on this, the smart city development level evaluation model of TOPSIS method constructed. The evaluation model constructed to make a vertical comparison from 2012 to 2017, the scale of smart cities is growing at an average annual rate of more than 30\%, saving 20\% of urban resource allocation and becoming a new pillar industry. Therefore, Hefei City should further increase environmental supervision and promote the use of low-carbon environmental protection new energy. The improvement of government management level has a positive effect on the construction of smart Hefei.},
  archive      = {J_COMCOM},
  author       = {Minglin Sun and Jian Zhang},
  doi          = {10.1016/j.comcom.2019.10.031},
  journal      = {Computer Communications},
  pages        = {332-342},
  shortjournal = {Comput. Commun.},
  title        = {Research on the application of block chain big data platform in the construction of new smart city for low carbon emission and green environment},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agent-enabled task offloading in UAV-aided mobile edge
computing. <em>COMCOM</em>, <em>149</em>, 324–331. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the appearance of various mobile applications, such as automatic driving and augmented reality , it is difficult for the power and computing ability of mobile terminals to satisfy user demands. Therefore, an increasing number of terminal devices are requesting computing resources on the edge cloud. Because an unmanned aerial vehicle (UAV) is quite flexible and closer to the user side, an UAV can be adopted to assist mobile edge computing (MEC) while executing task offloading , which may reduce the pressure on edge clouds. However, it is unreasonable for users to make blind requests for resources due to the information asymmetry between a user and a service provider, and thus the quality of experience of user may be reduced. In this paper, an agent is introduced into the offloading of computing tasks, and a novel framework of agent-enabled task offloading in UAV-aided MEC(UMEC) is put forth to help the user, UAV, and edge cloud execute the offloading of computing tasks. With the intelligence and perceptibility of an agent, a system model is formulated in this paper to guide the agent in obtaining the optimum computing offloading plan, with minimum task execution delay and energy consumption. Simulation results showed that the introduction of an agent may significantly reduce delay and energy consumption, and the effectiveness of agent has been illustrated.},
  archive      = {J_COMCOM},
  author       = {Rui Wang and Yong Cao and Adeeb Noor and Thamer A Alamoudi and Redhwan Nour},
  doi          = {10.1016/j.comcom.2019.10.021},
  journal      = {Computer Communications},
  pages        = {324-331},
  shortjournal = {Comput. Commun.},
  title        = {Agent-enabled task offloading in UAV-aided mobile edge computing},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic MAC protocol selection in wireless networks based
on reinforcement learning. <em>COMCOM</em>, <em>149</em>, 312–323. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing MAC protocols do not address the dynamism and complexity of the environment and applications of today’s wireless networks. The running applications and the environment change all the time, and as a consequence the requirements of the wireless transmissions change. For example, in one moment a client is transmitting video, requiring high throughput ; next it will control a robotic arm , requiring bounded delays. In this example, a contention-based MAC protocol would cope with flexible traffic demands, however it does not meet the delay constraints. Reservation based protocols, meanwhile, provide performance guarantees, but at a higher overhead. Hence, wireless networks require adaptive techniques that change how the network reacts over time. To that end, we propose SOMAC (Self-Organizing MAC), a system that uses reinforcement learning techniques to switch the MAC protocol in structured wireless networks according to the ongoing network demand. The novelty of SOMAC lies in its use of reinforcement learning , which solves the following shortcomings in the literature: (i) the lack of models that cope with changes in its environment or lack of representative data during training; (ii) the capacity to self-optimize based on a number of metrics. To showcase its genericity, we evaluated the model using two different optimization metrics (throughput and delay) on a testbed . Results indicate that our solution performs similar to an oracle choosing the most suitable MAC protocol from the list of implemented protocols up to 90\% of the time. Further, SOMAC outperforms the state of the art by up to 20\% in terms of protocol selection.},
  archive      = {J_COMCOM},
  author       = {André Gomes and Daniel F. Macedo and Luiz F.M. Vieira},
  doi          = {10.1016/j.comcom.2019.10.023},
  journal      = {Computer Communications},
  pages        = {312-323},
  shortjournal = {Comput. Commun.},
  title        = {Automatic MAC protocol selection in wireless networks based on reinforcement learning},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Testing implementation of FAMTAR: Adaptive multipath
routing. <em>COMCOM</em>, <em>149</em>, 300–311. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow-Aware Multi-Topology Adaptive Routing (FAMTAR) is a new approach to multipath and adaptive routing in IP networks which enables automatic use of alternative paths when the primary one becomes congested. It provides more efficient network resource utilization and higher quality of transmission compared to standard IP routing. However, thus far it has only been evaluated through simulations. In this paper we share our experiences from building a real-time FAMTAR router and present results of its tests in a physical network. The results are in line with those obtained previously through simulations and they open the way to implementation of a production grade FAMTAR router.},
  archive      = {J_COMCOM},
  author       = {Piotr Jurkiewicz and Robert Wójcik and Jerzy Domżał and Andrzej Kamisiński},
  doi          = {10.1016/j.comcom.2019.10.029},
  journal      = {Computer Communications},
  pages        = {300-311},
  shortjournal = {Comput. Commun.},
  title        = {Testing implementation of FAMTAR: Adaptive multipath routing},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Path planning techniques for unmanned aerial vehicles: A
review, solutions, and challenges. <em>COMCOM</em>, <em>149</em>,
270–299. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is one of the most important problems to be explored in unmanned aerial vehicles (UAVs) for finding an optimal path between source and destination. Although, in literature, a lot of research proposals exist on the path planning problems of UAVs but still issues of target location and identification persist keeping in view of the high mobility of UAVs. To solve these issues in UAVs path planning, optimal decisions need to be taken for various mission-critical operations performed by UAVs. These decisions require a map or graph of the mission environment so that UAVs are aware of their locations with respect to the map or graph. Keeping focus on the aforementioned points, this paper analyzes various UAVs path planning techniques used over the past many years. The aim of path planning techniques is not only to find an optimal and shortest path but also to provide the collision-free environment to the UAVs. It is important to have path planning techniques to compute a safe path in the shortest possible time to the final destination. In this paper, various path planning techniques for UAVs are classified into three broad categories, i.e., representative techniques, cooperative techniques, and non-cooperative techniques. With these techniques, coverage and connectivity of the UAVs network communication are discussed and analyzed. Based on each category of UAVs path planning, a critical analysis of the existing proposals has also been done. For better understanding, various comparison tables using parameters such as-path length, optimality , completeness, cost-efficiency, time efficiency, energy-efficiency, robustness and collision avoidance are also included in the text. In addition, a number of open research problems based on UAVs path planning and UAVs network communication are explored to provide deep insights to the readers.},
  archive      = {J_COMCOM},
  author       = {Shubhani Aggarwal and Neeraj Kumar},
  doi          = {10.1016/j.comcom.2019.10.014},
  journal      = {Computer Communications},
  pages        = {270-299},
  shortjournal = {Comput. Commun.},
  title        = {Path planning techniques for unmanned aerial vehicles: A review, solutions, and challenges},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GeoUAVs: A new geocast routing protocol for fleet of UAVs.
<em>COMCOM</em>, <em>149</em>, 259–269. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routing in cooperative UAVs networks is a challenging task due to mobility of nodes, dynamically changing topology and three-dimensional (3D) movement. In this work, we study the fleet routing problem in FANET, which aims at delivering data to a specific group of mobile drones identified by their geographical location. Although many fleet routing protocols have been proposed, only partial inherent constraints of FANET (such as mobility, 3D movement and reliability) are taken into account. Therefore, we propose a new geocast routing protocol namely Geocast routing protocol for fleet of UAVs (GeoUAVs). This protocol aims at delivering information to a specific group of mobile UAVs identified by their geographical location. It takes into account the mobility of nodes, dynamic changing topology with 3D movement, and reliability. Simulations conducted in NS-3 simulator demonstrate that our proposal GeoUAVs outperforms AntHocNet and BeeAdHoc protocols by reducing the average delay by more than to 61\% and increasing both the packet delivery ratio and throughput.},
  archive      = {J_COMCOM},
  author       = {Fatima Zohra Bousbaa and Chaker Abdelaziz Kerrache and Zohra Mahi and Abdou El Karim Tahari and Nasreddine Lagraa and Mohamed Bachir Yagoubi},
  doi          = {10.1016/j.comcom.2019.10.026},
  journal      = {Computer Communications},
  pages        = {259-269},
  shortjournal = {Comput. Commun.},
  title        = {GeoUAVs: A new geocast routing protocol for fleet of UAVs},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards 5G network slicing for vehicular ad-hoc networks: An
end-to-end approach. <em>COMCOM</em>, <em>149</em>, 252–258. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The upcoming 5G networks not only have to support increasing data rates but also must provide a common infrastructure on which new services with vastly different network QoS requirements with lower delay are delivered. More precisely, applications for VANETs, that are mainly oriented to safety issues and entertainment (e.g. video streaming and video-on-demand, web browsing) are increasing. Most of these applications have strict latency constraints of the order of few milliseconds, and very high reliability requirements. To address such needs, a 5G platform needs the ability to dynamically create programmable virtual networks and differentiated traffic treatment utilizing solutions such as network slicing. To this end, in this paper, we propose a programmable and dynamic end-to-end slicing mechanism in an M-CORD based LTE network. One of the key features of M-CORD that the proposed network slicing mechanism utilizes is the virtualized EPC that enables customization and modification. M-CORD provides necessary functionality to program slice definitions, where the proposed mechanism fully follows its software-defined approach. Furthermore, we demonstrate how end devices placed in different slices can be allocated with different QoS treatments from the network operator based on end-user type. The results show that the proposed network slicing mechanism selects appropriate slices and allocates resources to users specific to their needs and service type.},
  archive      = {J_COMCOM},
  author       = {Muhammad Afaq and Javed Iqbal and Talha Ahmed and Ihtesham Ul Islam and Murad Khan and Muhammad Sohail Khan},
  doi          = {10.1016/j.comcom.2019.10.018},
  journal      = {Computer Communications},
  pages        = {252-258},
  shortjournal = {Comput. Commun.},
  title        = {Towards 5G network slicing for vehicular ad-hoc networks: An end-to-end approach},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benchmarking big data systems: A survey. <em>COMCOM</em>,
<em>149</em>, 241–251. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the enormous growth on the availability and usage of Big Data storage and processing systems, it has become essential to assess the various performance aspects of these systems so that we can carefully understand their strong and weak aspects. In practice, currently, when an individual/enterprise aims to develop a Big Data storage and processing solution for harnessing the knowledge inside their data, they will get challenged by the availability of several frameworks from which they need to select. This is a challenging task which needs to directed by with good knowledge about various perspectives of such systems. Additionally, the choice normally vary from one scenario to another according to the essential needs of the application. In practice, there is no single benchmark study which can cover the different types of big data processing requirements, systems, application scenarios and metrics. Several benchmarks and benchmarking studies have been developed where each study focuses on some representative type of frameworks and only consider some aspects to cover. In this article, we provide a comprehensive survey and analysis of the state-of-the-art of benchmarking the different types of big data systems (e.g., NoSQL databases, Big SQL engines, Big Streaming engines, Big Graph Processing engines, Big Machine/Deep Learning engines). Additionally, we highlight some of the significant open challenges and missing requirements of current benchmarks of big data systems with suggestions of directions for future extensions and improvements.},
  archive      = {J_COMCOM},
  author       = {Fuad Bajaber and Sherif Sakr and Omar Batarfi and Abdulrahman Altalhi and Ahmed Barnawi},
  doi          = {10.1016/j.comcom.2019.10.002},
  journal      = {Computer Communications},
  pages        = {241-251},
  shortjournal = {Comput. Commun.},
  title        = {Benchmarking big data systems: A survey},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On 5G network slice modelling: Service-, resource-, or
deployment-driven? <em>COMCOM</em>, <em>149</em>, 232–240. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network slicing has been one of the hottest topics in standardization recently, as telecom operators are intensively investigating its usage for operating isolated and independently configurable logical networks, in order to ease and promote the network sharing and neutral hosting business. However, extensive deployments of slice management solutions are often impeded by incompatibilities of the used slice data models, which stem from different definitions and modelling approaches for the slicing concept, e.g., some driven by 3GPP standards, others by other standards or proprietary solutions , and so on. Although various studies on slicing have been performed, none of them has focused on slice data modelling across research and standards. Incompatible slice models do not only limit interoperability but they also reduce the efficiency of network slicing systems. This paper lays a foundation towards more efficient and interoperable network slice modelling by methodically investigating, categorizing, and formally describing core slice modelling approaches, including new modelling suggestions. Subsequently, we analyse their advantages and disadvantages and we propose slice model quality metrics, which we use for performing a case study on our testbed .},
  archive      = {J_COMCOM},
  author       = {Apostolos Papageorgiou and Adriana Fernández-Fernández and Shuaib Siddiqui and Gino Carrozzo},
  doi          = {10.1016/j.comcom.2019.10.024},
  journal      = {Computer Communications},
  pages        = {232-240},
  shortjournal = {Comput. Commun.},
  title        = {On 5G network slice modelling: Service-, resource-, or deployment-driven?},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive QR-based energy efficient signal detection
scheme in MIMO-OFDM systems. <em>COMCOM</em>, <em>149</em>, 225–231. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive QR-based energy efficient low complexity signal detection scheme in multiple input multiple output-orthogonal frequency division multiplexing (MIMO-OFDM) systems with nearly optimal error performance is proposed for solving the disadvantage of path elimination QR decomposition-M algorithm (PEQRD- M M ). For minimizing the loss of error performance, the proposed scheme uses suboptimal PEQRD- M M , and hybrid PEQRD- M M and lattice reduction-aided decision feedback equalizer (LR-aided DFE) adaptively by using channel state. The proposed scheme selects the signal detection scheme adaptively by calculating the condition number of wireless channel. The proposed scheme uses PEQRD- M M when the channel state is poor where its condition number is high, and reversely uses the hybrid PEQRD- M M and LR-aided DFE when the channel state is favorable where its condition number is low. The simulation results show that the proposed scheme has nearly the same error performance as PEQRD- M M and low complexity at low signal to noise ratio (SNR).},
  archive      = {J_COMCOM},
  author       = {Jae-Hyun Ro and Seung-Jun Yu and Young-Hwan You and Sung Kyung Hong and Hyoung-Kyu Song},
  doi          = {10.1016/j.comcom.2019.10.017},
  journal      = {Computer Communications},
  pages        = {225-231},
  shortjournal = {Comput. Commun.},
  title        = {An adaptive QR-based energy efficient signal detection scheme in MIMO-OFDM systems},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On improved DFT-based low-complexity channel estimation
algorithms for LTE-based uplink NB-IoT systems. <em>COMCOM</em>,
<em>149</em>, 214–224. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel estimation is crucial to achieving wide-area coverage for ultra-low-cost and low-power narrowband Internet of Things (NB-IoT) devices that are in coverage extremities. Radio coverage can be extended by repeatedly transmitting the same signal over a protracted period. In repetition dominated NB-IoT systems, existing channel estimators extensively used in the orthogonal frequency-division multiplexing (OFDM) system may be no longer applicable due to their considerable computational complexity and power consumption . In this paper, we propose narrowband demodulation reference signal (NDMRS)-assisted transform-domain low-complexity channel estimation algorithms named random sorting least squares (RS-LS), and de-noising LS (D-LS). Another sub-optimal estimator, stemming from the filtered channel estimates called linear minimum mean square error-approximation (LMMSE-A) is also studied. We first estimate initial channel response at pilot frequencies using the conventional LS method; and then, apply several additional operations in time-domain to suppress LS estimation error without exploiting extra frequency-band resources, and increasing significant computational complexity . Finally, channel estimates for the remaining OFDM symbols within an NB-IoT subframe are obtained by employing the time dimensional linear interpolation . Through several simulation examples, the viability of the proposed estimators is verified in comparison with the conventional LS, denoise, and optimal LMMSE estimators in terms of channel mean square error (MSE), block error rate (BLER), and throughput against signal-to-noise ratio (SNR) for Long Term Evolution (LTE)-based uplink NB-IoT systems.},
  archive      = {J_COMCOM},
  author       = {Md Sadek Ali and Yu Li and Shuo Chen and Fujiang Lin},
  doi          = {10.1016/j.comcom.2019.10.022},
  journal      = {Computer Communications},
  pages        = {214-224},
  shortjournal = {Comput. Commun.},
  title        = {On improved DFT-based low-complexity channel estimation algorithms for LTE-based uplink NB-IoT systems},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-level data aggregation for WMSNs employing a novel VBEAO
and HOSVD. <em>COMCOM</em>, <em>149</em>, 194–213. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent growth in camera/video technology, alongside the development of visual data aggregation and transmission algorithms, has facilitated a new kind of WSN called the Wireless Multimedia Sensor Network (WMSN). In traditional WSNs, environmental parameters such as temperature, humidity and pressure are analyzed with scalar sensor nodes , which compress redundant data using simple data aggregation functions to reduce transmission energy before sending the data to the receiver. However, this mechanism may not be suitable for image processing and image transmission in WMSNs. This is because camera sensor nodes handle vast quanta of redundant data, particularly if the Field of View (FoV) of camera sensor nodes overlaps with each other to increase monitoring accuracy. In a traditional WSN cluster-based protocol, much of the process relies on a cluster head (CH), which may run out of energy to become a dead node, eventually leading to network failure. To handle this scenario, a Distributed Two-Layer Cluster (DTLC) framework is proposed to minimize the energy consumption of individual nodes in WMSN by sharing the processes performed by a CH. This framework also extends the overall network lifetime by distributing the computational load among camera sensor nodes. A Two-Level Image Aggregation (TLIA) algorithm is proposed to remove the inter-view correlation in the DTLC-based node deployment. The local cluster head (LCH) performs first-level image aggregation (FLIA), which eliminates the correlated information of multi-view images from local cluster members (LCM) by combining multi-view images together, using a novel Varying Bit Encoding based on Arithmetic Operations (VBEAO) with bit reduction. The FLIA results in a compression ratio of 2.4. The master cluster head (MCH) performs second-level image aggregation (SLIA) to further eliminate redundant data from LCHs using a Higher-Order SVD (HOSVD), followed by logarithmic quantization on both the decomposed tensor core and factor matrices . SLIA results in the next level of compression, with a ratio of about 8.9. A comparison of the performance with existing approaches demonstrates the superiority of WMSNs, with improvements in terms of network lifetime and energy consumption.},
  archive      = {J_COMCOM},
  author       = {M. Nava Barathy and Dejey},
  doi          = {10.1016/j.comcom.2019.10.013},
  journal      = {Computer Communications},
  pages        = {194-213},
  shortjournal = {Comput. Commun.},
  title        = {Two-level data aggregation for WMSNs employing a novel VBEAO and HOSVD},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of space time block codes and cosets for 5G and its
applications. <em>COMCOM</em>, <em>149</em>, 189–193. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key parameters of 5G communication technology includes high data rate and latency to support Internet of Things (IoTs) in future. There are many ways to boost up system capacity of 5G systems. In this work, design of an efficient space time block code (STBC) is presented based on maximum rank distance (MRD) codes that give enhanced system capacity in terms of diversity gain. The work also includes a comparative study of orthogonal STBC and all of its equivalent group codes including MRD for 2 transmit antennas and 1 receive antenna (2 × 1) STBCs. It is shown through simulation that MRD code and all other related coset codes can achieve full diversity gain for 2 × 1 scenario similar to what orthogonal codes can do. In addition, it is shown that orthogonal code generally outperforms all equivalent codes. A unique case is also discussed in which MRD code outperforms orthogonal STBC . Due to full diversity gain, these codes find their direct applications in 5G, Unmanned Aerial Vehicles (UAVs) used in sensor networks.},
  archive      = {J_COMCOM},
  author       = {Hafiz M. Asif},
  doi          = {10.1016/j.comcom.2019.10.015},
  journal      = {Computer Communications},
  pages        = {189-193},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of space time block codes and cosets for 5G and its applications},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ethanol: A software-defined wireless networking architecture
for IEEE 802.11 networks. <em>COMCOM</em>, <em>149</em>, 176–188. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Networks have become ubiquitous to support the growing demand from mobile users, and other devices, like in the Internet of Things (IoT). This article proposes a Software-Defined Wireless Networking architecture specialized in 802.11 Wireless LANs, called Ethanol , which provides a more fine-grained control. Ethanol is the first wireless SDN architecture that extends the control to the user devices. Further, Ethanol allows intelligent white-box control with finer grain than the state of the art, since it is optimized for WiFi. The proposed architecture is evaluated on a prototype over three use cases. Ethanol can be deployed in any Access Point (AP) running embedded Linux , since it has a negligible overhead — up to 1\% in memory and 0.1\% in CPU usage. Our results show that Ethanol dynamically alter the throughput of an application up to 3x during a prioritization period, returning bandwidth to other applications outside this period. Only by controlling the best time to perform the handover , our results show about 45\% improvement over the traditional signal-based handover process .},
  archive      = {J_COMCOM},
  author       = {Henrique Moura and Alisson R. Alves and Jonas R.A. Borges and Daniel F. Macedo and Marcos A.M. Vieira},
  doi          = {10.1016/j.comcom.2019.10.010},
  journal      = {Computer Communications},
  pages        = {176-188},
  shortjournal = {Comput. Commun.},
  title        = {Ethanol: A software-defined wireless networking architecture for IEEE 802.11 networks},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SDN-based real-time urban traffic analysis in VANET
environment. <em>COMCOM</em>, <em>149</em>, 162–175. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and real-time traffic flow prediction plays a central role for efficient traffic management. Software Defined Networking (SDN) is one of the key concerns in networking that has caught much attention in recent years. Extensive advancement in software-based configurable equipment has made ready for a new networking paradigm called software-defined vehicular networks (SDVNs). In this paper, we propose a data-driven approach for implementing an artificially intelligent model for vehicular traffic behavior prediction. We combine the flexibility, scalability, and adaptability leveraged by the SDVN architecture along with the machine learning algorithms to model the traffic flow efficiently. First, we introduce an ingenious approach to find congestion sensitive spots in the VANET by means of clustering algorithm and then predicting the future traffic densities for each spot by recurrent neural networks (RNNs). Neural networks (NNs) have been extensively used to model short-term traffic prediction in the past years. We construct a long short-term memory neural network (LSTM-NN) architecture which overcomes the issue of back-propagated error decay through memory blocks for spatiotemporal traffic prediction with high temporal dependency. Due to such learning ability, LSTM can capture the stochastic characteristics and non-linear nature of the traffic flow. The performance evaluation of the proposed approach shows that it has the potential to predict real-time traffic trends accurately with Mean Squared Error (MSE) of 3 . 0 e − 3 3.0e−3 in the scaled metrics, which is equivalent to 97\% accuracy in traffic density prediction.},
  archive      = {J_COMCOM},
  author       = {Jitendra Bhatia and Ridham Dave and Heta Bhayani and Sudeep Tanwar and Anand Nayyar},
  doi          = {10.1016/j.comcom.2019.10.011},
  journal      = {Computer Communications},
  pages        = {162-175},
  shortjournal = {Comput. Commun.},
  title        = {SDN-based real-time urban traffic analysis in VANET environment},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient dynamic relay probing and concurrent backhaul link
scheduling for mmWave cellular networks. <em>COMCOM</em>, <em>149</em>,
146–161. (<a
href="https://doi.org/10.1016/j.comcom.2019.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting the enormous chunks of mmWave spectrum between 30 GHz and 300 GHz have the potential to facilitate gigabit rate services to the future 5G cellular networks , and help in alleviating the current spectrum crisis. Conventional backhaul links such as Digital Subscriber Line (DSL) and Asymmetric Digital Subscriber Line (ADSL) have been proved to be a major bottleneck in satisfying these high data rate demands of indoor user equipments associated with traditional Femto Base Stations (FBS). One possible solution is to deploy higher capacity optical fiber cable to satisfy such demands. However, it is a costly and non-flexible solution. Thus, mmWave wireless backhaul links can be utilized at the FBSs. But due to their high-frequency, mmWave carrier signals are highly susceptible to obstacles and thus suffer a high attenuation in signal strength when passed through the obstacles. In order to alleviate the losses incurred due to blockages and to improve the signal reachability , in this paper, we propose an efficient distributed mode selection and dynamic relay probing scheme. We also propose an efficient scheduling scheme, for scheduling wireless backhaul links, which works jointly with the proposed mode selection and relay probing scheme to further improve the system throughput. Our proposed scheduling scheme permits non-interfering links to schedule and transmit concurrently. An expression for calculating the expected number of concurrent transmissions for our proposed scheduling scheme is derived and validated. Through extensive simulations under various system parameters, we have demonstrated the superiority of our proposed mode selection and relay probing scheme over the fixed relay probing scheme.},
  archive      = {J_COMCOM},
  author       = {Anup Chaudhari and C. Siva Ram Murthy},
  doi          = {10.1016/j.comcom.2019.09.019},
  journal      = {Computer Communications},
  pages        = {146-161},
  shortjournal = {Comput. Commun.},
  title        = {Efficient dynamic relay probing and concurrent backhaul link scheduling for mmWave cellular networks},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Implementation of fruit fly optimization algorithm (FFOA) to
escalate the attacking efficiency of node capture attack in wireless
sensor networks (WSN). <em>COMCOM</em>, <em>149</em>, 134–145. (<a
href="https://doi.org/10.1016/j.comcom.2019.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSN) is a group of a huge number of low price, low control, and self-organizing specialized sensor nodes . WSN is very much vulnerable to different types of physical attacks due to limited resource capacity and screened to external atmosphere for circulating data. The node capture attack is one of the major attacks in WSN in which the intruder physically captures the node and remove the secret information from the node’s memory. We propose a Fruit Fly Optimization Algorithm (FFOA) that is based on multiple objectives node capture attack algorithm which consists of several objectives: maximum node contribution, maximum key contribution, and least resource expenses to discover optimal nodes. It will influence an inclusive tool to demolish maximum part of the network along with effective cost and maximum attacking efficiency. The simulation result illustrates that FFOA obtains a maximum fraction of compromised traffic, lower attacking rounds, and lower energy cost as compared with Genetic Algorithm (GA) and other node capture attack algorithms. Therefore, FFOA gives maximum attacking efficiency than GA and other algorithms by capturing minimum nodes that compromise the whole network.},
  archive      = {J_COMCOM},
  author       = {Ruby Bhatt and Priti Maheshwary and Piyush Shukla and Prashant Shukla and Manish Shrivastava and Soni Changlani},
  doi          = {10.1016/j.comcom.2019.09.007},
  journal      = {Computer Communications},
  pages        = {134-145},
  shortjournal = {Comput. Commun.},
  title        = {Implementation of fruit fly optimization algorithm (FFOA) to escalate the attacking efficiency of node capture attack in wireless sensor networks (WSN)},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resource configuration for minimizing source energy
consumption in multi-carrier networks with energy harvesting relay and
data-rate guarantee. <em>COMCOM</em>, <em>149</em>, 121–133. (<a
href="https://doi.org/10.1016/j.comcom.2019.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous wireless information and power transfer (SWIPT) is a promising technique for wireless energy harvesting , which enables a relay node to overcome its unwillingness due to the energy awareness, with essentially protecting it from excessively depleting energy reserves. To further improve the energy efficiency, the energy consumption minimization problem aims at minimizing the energy consumption of an active source node, which drives the passive relay node with energy harvesting capability to forward data to the destination. This is studied by jointly considering transmission power limits, time switching factors, and data-rate demand, etc., in a decode-and-forward relay network with SWIPT. The energy consumption minimization problem is formulated as a non-convex optimization problem . The facilitation of the derivation of the optimal solution is through transforming it into an equivalent convex optimization problem by variable substitution. Since the problem is not always feasible, a feasibility assessment problem is then developed by introducing an assessing factor. Simultaneously solving the above inter-related problems, i.e., energy consumption minimization and feasibility assessment, they are unified in a convex-optimization framework, in which both the result about the feasibility assessment and the optimal solution (if it exists) can be obtained. Even if the problem is not feasible, the achievable maximum data rate that network resources can support can be obtained as well. Simulation results further validate that energy consumption minimization-feasibility assessment algorithm is effective in minimizing source energy consumption and in realizing optimal resource configuration .},
  archive      = {J_COMCOM},
  author       = {Liang Xue and Ying Liu and Yanyan Shen and Xiaoxia Huang and Kyung Sup Kwak},
  doi          = {10.1016/j.comcom.2019.09.022},
  journal      = {Computer Communications},
  pages        = {121-133},
  shortjournal = {Comput. Commun.},
  title        = {Resource configuration for minimizing source energy consumption in multi-carrier networks with energy harvesting relay and data-rate guarantee},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An accurate and complete performance modeling of the IEEE
802.11p MAC sublayer for VANET. <em>COMCOM</em>, <em>149</em>, 107–120.
(<a href="https://doi.org/10.1016/j.comcom.2019.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an analytical model for the throughput, channel access delay, and queueing delay of the IEEE 802.11p enhanced distributed channel access (EDCA) mechanism in the medium-access control (MAC) sublayer . In order to make the proposed analytical model explicitly solvable and to avoid computation complexity caused by most of existing 3-D or 4-D Markov-chain-based analytical models, a combination of 2-D and 1-D Markov chain model is used. The 2-D Markov chain is established to model the backoff procedure of each access category (AC) queue, deriving a relationship between the transmission probability and collision probability for each AC queue. Afterwards, a 1-D discrete-time Markov chain is established to model the contention period caused by the distinction of four different arbitration inter-frame space (AIFS) and contention window (CW) values, deriving another relationship between the transmission probability and collision probability of each AC queue. In order to consider both saturated and non-saturated cases, an infinite-long 1-D Markov chain model is used. In the proposed analytical model, all the features in the EDCA such as different CW and AIFS for each AC, various saturation status, internal collision, backoff counter freezing, up-to-date standard parameters, and initial-carrier-sensing procedure are taken into consideration. Based on the two Markov models, we further derive performance models which describe the relationships between the network parameters and channel access performance metrics in terms of normalized throughput , channel access delay, and queueing delay , respectively. The proposed analytical model applies to both basic access mode and request-to-send/clear-to-send (RTS/CTS) access mode, and is suitable for four access categories of traffic in the IEEE 802.11p. The proposed model can be employed to analyze the performance of real-world vehicular network . Simulation results are shown to verify the accuracy and effectiveness of the proposed analytical model.},
  archive      = {J_COMCOM},
  author       = {Shengbin Cao and Victor C.S. Lee},
  doi          = {10.1016/j.comcom.2019.08.026},
  journal      = {Computer Communications},
  pages        = {107-120},
  shortjournal = {Comput. Commun.},
  title        = {An accurate and complete performance modeling of the IEEE 802.11p MAC sublayer for VANET},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cognitive computing and wireless communications on the edge
for healthcare service robots. <em>COMCOM</em>, <em>149</em>, 99–106.
(<a href="https://doi.org/10.1016/j.comcom.2019.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we have witnessed dramatic developments of mobile healthcare robots, which enjoy many advantages over their human counterparts. Previous communication networks for healthcare robots always suffer from high response latency and/or time-consuming computing demands. Robust and high-speed communications and swift processing are critical, sometimes vital in particular in the case of healthcare robots, to the healthcare receivers. As a promising solution, offloading delay-sensitive and communicating-intensive tasks to the robot is expected to improve the services and benefit users. In this paper, we review several state-of-the-art technologies, such as the human–robot interface, environment and user status perceiving, navigation, robust communication and artificial intelligence , of a mobile healthcare robot and discuss in details the customized demands over offloading the computation and communication tasks. According to the intrinsic demands of tasks over the network usage, we categorize abilities of a typical healthcare robot into alternative classes: the edge functionalities and the core functionalities . Many latency-sensitive tasks, such as user interaction, or time-consuming tasks including health receiver status recognition and autonomous moving, can be processed by the robot without frequent communications with data centers . On the other hand, several fundamental abilities, such as radio resource management , mobility management, service provisioning management, need to update the main body with the cutting-edge artificial intelligence . Robustness and safety, in this case, are the primary goals in wireless communications that AI may provide ground-breaking solutions. Based on this partition, this article refers to several state-of-the-art technologies of a mobile healthcare robot and reviews some challenges to be met for its wireless communications .},
  archive      = {J_COMCOM},
  author       = {Shaohua Wan and Zonghua Gu and Qiang Ni},
  doi          = {10.1016/j.comcom.2019.10.012},
  journal      = {Computer Communications},
  pages        = {99-106},
  shortjournal = {Comput. Commun.},
  title        = {Cognitive computing and wireless communications on the edge for healthcare service robots},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy consumption and network connectivity based on
novel-LEACH-POS protocol networks. <em>COMCOM</em>, <em>149</em>, 90–98.
(<a href="https://doi.org/10.1016/j.comcom.2019.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSN) is used for a large number of sensor nodes and energy efficiency is important to constrained resources in wireless sensor networks. Wireless sensors networks use multiple approaches such as data cycling, energy optimal scheduling and energy aware routing to reduce energy consumption throughout the network. Energy awareness is an essential design for WSNs hence, data broadcasting protocols, routing and power management are specially designed to meet their requirements. The past decade was mitigating the issues of energy dissipation to ensure energy efficient routing and clustering. To address these issues, a novel idea is presented where the energy efficiency will incorporate the selection mechanism of nodes. In Wireless Sensor Networks, path routing for nodes is a difficult and tricky task. It is a crucial role to increase the stability and network lifetime. The LEACH Protocol is a measured level of the sensor networks lifetime by pairing the node energy consumption. Simulation results show that protocol outperform its routing protocols Low Energy Adaptive Clustering Hierarchy (LEACH) and Novel-LEACH in terms of network connectivity and power consumption . Also, a new energy efficient clustering scheme for WSNs with the use of Particle Swarm Optimization (PSO) is proposed. The clustering algorithm is implemented with the goal of concurrently minimizing the intra-cluster distance along with optimizing the usage of network energy.},
  archive      = {J_COMCOM},
  author       = {Moorthi and R. Thiagarajan},
  doi          = {10.1016/j.comcom.2019.10.006},
  journal      = {Computer Communications},
  pages        = {90-98},
  shortjournal = {Comput. Commun.},
  title        = {Energy consumption and network connectivity based on novel-LEACH-POS protocol networks},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A lightweight and scalable attribute-based encryption system
for smart cities. <em>COMCOM</em>, <em>149</em>, 78–89. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the near future, a technological revolution will involve our cities, where a variety of smart services based on the Internet of Things will be developed to facilitate the needs of the citizens. Sensing devices are already being deployed in urban environments, and they will generate huge amounts of data. Such data is typically outsourced to some cloud service in order to lower capital and operating expenses and guarantee high availability. However, cloud services may suffer from data breaches due to software and hardware vulnerabilities, or they may have incentives to release stored data to unauthorized entities. In this work we present ABE-Cities, an encryption system for urban sensing which solves the above problems while ensuring fine-grained access control on data by means of Attribute-Based Encryption (ABE). ABE-Cities senses data from the city and stores it on the cloud in an encrypted form. Then, it provides users with keys able to decrypt only data sensed from authorized paths or zones of the city. In ABE-Cities, sensors perform only lightweight symmetric-key encryption, thus we can employ constrained sensor devices such as battery powered motes. ABE-Cities allows us to plan an expiration date for each key, as well as to revoke a given key in an unplanned fashion. We prove that ABE-Cities scales well with the number of users and the number of streets by simulating it with 30 000 users on the Beijing street network, which consists of more than 30 000 streets. In addition to the “vanilla” ABE-Cities scheme, we propose an “advanced” one that leverages the presence of IoT gateways to reduce the computational load otherwise weighing on a single Trusted Third Party. We validate this by testing the advanced scheme on the simulated Houston and Beijing street networks.},
  archive      = {J_COMCOM},
  author       = {Marco Rasori and Pericle Perazzo and Gianluca Dini},
  doi          = {10.1016/j.comcom.2019.10.005},
  journal      = {Computer Communications},
  pages        = {78-89},
  shortjournal = {Comput. Commun.},
  title        = {A lightweight and scalable attribute-based encryption system for smart cities},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Orchestration of heterogeneous wireless networks: State of
the art and remaining challenges. <em>COMCOM</em>, <em>149</em>, 62–77.
(<a href="https://doi.org/10.1016/j.comcom.2019.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless devices have a plethora of technologies at their disposal to connect to the Internet and other services. Management and control of each technology are traditionally isolated, and coordination between technologies is nearly non-existent. This isolation leads to poor resource usage, which in turn reduces performance and service guarantees. To satisfy growing user demands, we need to leverage the different service guarantees offered by each technology. Additionally, we need to improve orchestration between technologies to increase performance and flexibility while offering a more extensive range of service guarantees and maximizing resource utilization across networks and users. In this work, we present the general challenges one encounters when managing heterogeneous wireless networks. We argue that the primary challenge is the heterogeneity itself, the number of different devices and technologies, the different service requirements, and the increasing complexity as a consequence. However, technology abstraction can overcome these challenges. We provide an overview of state of the art commercial and scientific solutions and show their strengths and weaknesses. Based on this, we discuss the current status and what future challenges still await to provide full seamless heterogeneous wireless network management.},
  archive      = {J_COMCOM},
  author       = {Patrick Bosch and Tom De Schepper and Ensar Zeljković and Jeroen Famaey and Steven Latré},
  doi          = {10.1016/j.comcom.2019.10.008},
  journal      = {Computer Communications},
  pages        = {62-77},
  shortjournal = {Comput. Commun.},
  title        = {Orchestration of heterogeneous wireless networks: State of the art and remaining challenges},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling drone charging for multi-drone network based on
consensus time-stamp and game theory. <em>COMCOM</em>, <em>149</em>,
51–61. (<a href="https://doi.org/10.1016/j.comcom.2019.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drones or Unmanned Aerial Vehicles (UAVs) can be highly efficient in various applications like hidden area exploration, delivery, or surveillance and can enhance the quality of experience (QoE) for end-users. However, the number of drone-based applications are not very high due to the constrained flight time. The weights of the drones need to be kept less, and intuitively they cannot be loaded with big batteries. Frequent recharging and battery replacement processes limit the appropriate use of drones in most applications. A peer-to-peer distributed network of drones and charging stations is a highly promising solution to empower drones to be used in multiple applications by increasing their flight time. The charging stations are limited, and therefore, an adequate, fair, and cost-optimal scheduling algorithm is required to serve the most needed drone first. The proposed model allows the drones to enter into the network and request for a charging time slot from the station. The stations are also the part of the same network, this work proposes a scheduling algorithm for drones who compete for charging slots with constraints of optimizing criticality and task deadline. A game-theoretic approach is used to model the energy trading between the drones and charging station in a cost-optimal manner. Numerical results based on simulations show that the proposed model provides a better price for the drones to get charged and better revenue for the charging stations simultaneously.},
  archive      = {J_COMCOM},
  author       = {Vikas Hassija and Vikas Saxena and Vinay Chamola},
  doi          = {10.1016/j.comcom.2019.09.021},
  journal      = {Computer Communications},
  pages        = {51-61},
  shortjournal = {Comput. Commun.},
  title        = {Scheduling drone charging for multi-drone network based on consensus time-stamp and game theory},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-level cluster-based satellite-terrestrial integrated
communication in internet of vehicles. <em>COMCOM</em>, <em>149</em>,
44–50. (<a href="https://doi.org/10.1016/j.comcom.2019.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth of vehicles and mobile services has brought new challenges to Internet of vehicles (IoV). In order to accurately locate vehicles and quickly process data for alleviating the pressure of communication, clustering method based on data analysis are studied in this paper for vehicles in the Internet of vehicles, so as to make sure that mobile stations and terminals on the road are able to access maximum transmission opportunity and suffer minimal communication interference from adjacent vehicles . A satellite-terrestrial integrated communication framework for the IoV is designed to support analysis of data from vehicles, mobile tracking of vehicles, and unsupervised adaptive communication scheduling; then, a multi-level cluster-based satellite-terrestrial integrated communication model (MCSIC) is designed to realize the effective real-time data communication based on data analysis. Finally, the performance of MCSIC is analyzed through several simulations.},
  archive      = {J_COMCOM},
  author       = {Kai Lin and Chensi Li and Pasquale Pace and Giancarlo Fortino},
  doi          = {10.1016/j.comcom.2019.10.009},
  journal      = {Computer Communications},
  pages        = {44-50},
  shortjournal = {Comput. Commun.},
  title        = {Multi-level cluster-based satellite-terrestrial integrated communication in internet of vehicles},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cluster based data aggregation scheme for latency and packet
loss reduction in WSN. <em>COMCOM</em>, <em>149</em>, 36–43. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Wireless Sensor Networks (WSN), the main issues of cluster based data aggregation algorithms are energy balancing, packet loss and latency reduction . In existing scheduling algorithms for data aggregation, time slots are mostly assigned based on the data sensing period and data transmission rate , ignoring packet loss and latency. In this paper, Cluster based Data Aggregation Scheme for Latency and Packet Loss Reduction in WSN is proposed. The proposed scheme consists of two phases: Aggregation Tree Construction and Slot scheduling algorithm. In phase-1, each cluster head applies compressive aggregation for the data received from its members. Then the aggregation tree is constructed by the sink using Minimum Spanning Tree (MST). In phase-2, the packet loss rate and latency are taken into consideration while prioritizing and assigning timeslots to the nodes with aggregated data. This scheme avoids using unnecessary retransmissions and waiting, which results to be beneficial in enhancing the network performance in WSN. Simulation results show that the proposed scheme reduces the latency and overhead and increases the packet delivery ratio and residual energy .},
  archive      = {J_COMCOM},
  author       = {V. Seedha Devi and T. Ravi and S. Baghavathi Priya},
  doi          = {10.1016/j.comcom.2019.10.003},
  journal      = {Computer Communications},
  pages        = {36-43},
  shortjournal = {Comput. Commun.},
  title        = {Cluster based data aggregation scheme for latency and packet loss reduction in WSN},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized unmanned aerial vehicles deployment for static and
mobile targets’ monitoring. <em>COMCOM</em>, <em>149</em>, 27–35. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the recent decade, drones or Unmanned Aerial Vehicles (UAVs) are getting increasing attention by both industry and academia. Due to the support of advanced technologies, they might be soon an integral part of any smart-cities related project. In this paper, we propose a cost-effective framework related to the optimal placement of drones in order to monitor a set of static and/or dynamic targets in the IoT era. The main objective of this study is to minimize the total number of drones required to monitor an environment while providing the maximum coverage, which in turn leads to significant reduction in cost. Our simulation results show that by increasing the battery capacity of the drones, the drones’ visibility range would also increase and thus, the number of drones would be reduced. Moreover, when the targets are sparsely distributed across a large number of different regions, a further increase to the targets does not require an increase in the number of drones needed to monitor them.},
  archive      = {J_COMCOM},
  author       = {Fadi Al-Turjman and Hadi Zahmatkesh and Ibrhaim Al-Oqily and Reda Daboul},
  doi          = {10.1016/j.comcom.2019.10.001},
  journal      = {Computer Communications},
  pages        = {27-35},
  shortjournal = {Comput. Commun.},
  title        = {Optimized unmanned aerial vehicles deployment for static and mobile targets’ monitoring},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic and interoperable communication framework for
controlling the operations of wearable sensors in smart healthcare
applications. <em>COMCOM</em>, <em>149</em>, 17–26. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this manuscript, a dynamic and interoperable communication framework (DICF) for regulating the operations of wearable healthcare devices is introduced. The framework is responsible for monitoring, decision making and controlling the functionalities and operating time of the wearable sensors (WS) as a part of smart health care tracking applications. In this framework, the nature of the wireless sensing device and its intrinsic features are accounted to design a fully operative and automated seamless working of the sensing devices. The sensing devices operate in both autonomous and interconnected manner depending upon the sensed information and the observed body conditions of the patient. The frequency of operation and the time interval varies with the scheduled and random recommendations of the communication framework of the interconnected devices. The framework is designed to improve the interoperability of the devices acclimatized to adapt dynamic nature of different tracking healthcare applications to leverage its performance.},
  archive      = {J_COMCOM},
  author       = {S. Baskar and P. Mohamed Shakeel and R. Kumar and M.A. Burhanuddin and R. Sampath},
  doi          = {10.1016/j.comcom.2019.10.004},
  journal      = {Computer Communications},
  pages        = {17-26},
  shortjournal = {Comput. Commun.},
  title        = {A dynamic and interoperable communication framework for controlling the operations of wearable sensors in smart healthcare applications},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unmanned aerial vehicle (UAV) based forest fire detection
and monitoring for reducing false alarms in forest-fires.
<em>COMCOM</em>, <em>149</em>, 1–16. (<a
href="https://doi.org/10.1016/j.comcom.2019.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary sources for ecological degradation currently are the Forest Fires (FF). The present observation frameworks for FF absence need supporting in constant checking of each purpose of the location at all time and prime location of the fire dangers. This approach gives works on preparing UAV (Unmanned Aerial Vehicle) aeronautical picture information as indicated by the prerequisites of ranger service territory application on a UAV stage. It provides a continuous and remote watch on a flame in forests and mountains, all the while the UAV is flying and getting the elevated information, helping clients maintain the number and area of flame focuses. Observing programming spreads capacities, including Fire: source identification, area, choice estimation, and LCD module. This paper proposed includes (1) Color Code Identification, (2) Smoke Motion Recognition, and (3) Fire Classification algorithms . Strikingly, the use of a helicopter with visual cameras portrayed. The paper introduces the strategies utilized for flame division invisible cameras, and the systems to meld the information acquired the following: Correctly, the current FF location stays testing, given profoundly convoluted and non-organized conditions of the forest, smoke hindering the flame, the movement of cameras mounted on UAVs, and analogs of fire attributes. These unfavorable impacts can truly purpose either false alert. This work focuses on the improvement of trustworthy and exact FF recognition algorithms which apply to UAVs. To effectively execute missions and meet their relating execution criteria examinations on the best way to diminish false caution rates, increment the possibility of profitable recognition, and upgrade versatile abilities to different conditions are firmly requested to improve the unwavering quality and precision of FF location framework.},
  archive      = {J_COMCOM},
  author       = {S. Sudhakar and V. Vijayakumar and C. Sathiya Kumar and V. Priya and Logesh Ravi and V. Subramaniyaswamy},
  doi          = {10.1016/j.comcom.2019.10.007},
  journal      = {Computer Communications},
  pages        = {1-16},
  shortjournal = {Comput. Commun.},
  title        = {Unmanned aerial vehicle (UAV) based forest fire detection and monitoring for reducing false alarms in forest-fires},
  volume       = {149},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
