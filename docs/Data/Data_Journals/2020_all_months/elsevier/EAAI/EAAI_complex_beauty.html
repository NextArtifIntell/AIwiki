<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---359">EAAI - 359</h2>
<ul>
<li><details>
<summary>
(2020). Learning adversarial attack policies through multi-objective
reinforcement learning. <em>EAAI</em>, <em>96</em>, 104021. (<a
href="https://doi.org/10.1016/j.engappai.2020.104021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Reinforcement Learning has shown promising results in learning policies for complex sequential decision-making tasks. However, different adversarial attack strategies have revealed the weakness of these policies to perturbations to their observations. Most of these attacks have been built on existing adversarial example crafting techniques used to fool classifiers, where an adversarial attack is considered a success if it makes the classifier outputs any wrong class. The major drawback of these approaches when applied to decision-making tasks is that they are blind for long-term goals. In contrast, this paper suggests that it is more appropriate to view the attack process as a sequential optimization problem, with the aim of learning a sequence of attacks, where the attacker must consider the long-term effects of each attack. In this paper, we propose that such an attack policy must be learned with two objectives in view. On the one hand, the attack must pursue the maximum performance loss of the attacked policy. On the other hand, it also should minimize the cost of the attacks. Therefore, in this paper we propose a novel modelization of the process of learning an attack policy as a Multi-objective Markov Decision Process with two objectives: maximizing the performance loss of the attacked policy and minimizing the cost of the attacks. We also reveal the conflicting nature of these two objectives and use a Multi-objective Reinforcement Learning algorithm to draw the Pareto fronts for four well-known tasks: the GridWorld, the Cartpole, the Mountain car and the Breakout.},
  archive      = {J_EAAI},
  author       = {Javier García and Rubén Majadas and Fernando Fernández},
  doi          = {10.1016/j.engappai.2020.104021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104021},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning adversarial attack policies through multi-objective reinforcement learning},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary optimized artificial intelligence model for
modeling scouring depth of submerged weir. <em>EAAI</em>, <em>96</em>,
104012. (<a
href="https://doi.org/10.1016/j.engappai.2020.104012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement in computer aid and artificial intelligence (AI) models have received a noticeable progression in several engineering applications. In this research, an investigation for the capacity of a hybrid artificial intelligence model for predicting depth scouring of submerged weir. Scouring phenomena is one of the most complex problems in the field of the river and hydraulic engineering. Accurate and precise prediction for the depth scouring ( d s ) is one of the essential processes for maintaining a sustainable hydraulic structure. This article introduces a new predictive model called tBPSO-SVR, which is a hybridization of an enhanced binary particle swarm optimization (PSO) algorithm with support vector regression (SVR) model as an efficient predictive model. The roles of the PSO algorithm are tuning the internal hyperparameters of the SVR model in addition to the optimization of the predictors selection “feature selection” for the d s modeling. The prediction matrix is constructed based on several related geometric dimensions, flow information and sediment properties. The proposed model is validated against several well-established machine learning models introduced over the literature. The prediction potential of the proposed tBPSO-SVR model exhibited a superior capability. In quantitative terms, tBPSO-SVR attained minimum mean absolute error (MAE = 0.012 m) and maximum coefficient of determination ( R 2 = 0.956). Remarkably, the proposed hybrid artificial intelligence demonstrated an efficient prediction model for depth scouring prediction with reducing the input parameters.},
  archive      = {J_EAAI},
  author       = {Sinan Q. Salih and Maria Habib and Ibrahim Aljarah and Hossam Faris and Zaher Mundher Yaseen},
  doi          = {10.1016/j.engappai.2020.104012},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104012},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An evolutionary optimized artificial intelligence model for modeling scouring depth of submerged weir},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two novel models and a parthenogenetic algorithm for
detecting common driver pathways from pan-cancer data. <em>EAAI</em>,
<em>96</em>, 104010. (<a
href="https://doi.org/10.1016/j.engappai.2020.104010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of high-throughput sequencing technologies, huge volumes of generated cancer genomics data make it into reality to understand the carcinogenic pathogenesis from the molecular level. It is believed that the study of commonalities among different cancers is one of the significant problems for understanding cancers, and will be beneficial for personalized therapy and precision medicine in cancer treatment. The ComMDP method is a useful one for solving this problem. However, when there is a substantially difference among the number of samples, the method of accumulating the absolute weight value of every cancer, employed by the ComMDP method, may give rise to missing some driver pathways. In this paper, two mathematical models CDP-V and CDP-H, replacing the absolute weight values with relative ones, are presented by using variance and harmonic mean , respectively. By devising a sort of short chromosome code and a greedy based recombination operator, a parthenogenetic algorithm is proposed for solving these two models. Extensive experiments were performed on both simulated and real cancer data. The experimental results show that given several types of cancer, the gene sets identified based on the presented models and algorithm not only mutate in a large proportion of samples of these cancers, but have close proportion of mutated samples in each cancer. In addition, some biologically meaningful gene sets, which are missed by the ComMDP one, are indeed detected. Hence the identified methods based on the presented models and algorithm may become useful complementary tools for identifying cancer pathways.},
  archive      = {J_EAAI},
  author       = {Jingli Wu and Ke Pan and Gaoshi Li and Kai Zhu and Qirong Cai},
  doi          = {10.1016/j.engappai.2020.104010},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104010},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two novel models and a parthenogenetic algorithm for detecting common driver pathways from pan-cancer data},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MOEPO: A novel multi-objective emperor penguin optimizer for
global optimization: Special application in ranking of cloud service
providers. <em>EAAI</em>, <em>96</em>, 104008. (<a
href="https://doi.org/10.1016/j.engappai.2020.104008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the extension of currently developed Emperor Penguin Optimizer (EPO) in terms of multi-objective problems solving capability, which is entitled as Multi-objective Emperor Penguin Optimizer (MOEPO) In this algorithm, a concept of dynamic archive is introduced, which has the feature to cache the non-dominated Pareto optimal solutions. Here, the roulette-wheel approach is utilized to choose the effective archived solutions by simulating the huddling behaviors of emperor penguins. The proposed algorithm is approved by testing it with twenty-four well-known benchmark test functions, and its performance is compared with existing metaheuristic algorithms. The developed algorithm is analyzed on seven constrained problems of engineering to assess its appropriateness for finding solutions of real world problems. After, that it is validated on cloud computing application and compared between competitor approaches. By using the proposed algorithm, improvements in tackling the resource scheduling issue in cloud computing have been established. The outcomes from the empirical analyzes depict that the proposed algorithm is better than other existing algorithms.},
  archive      = {J_EAAI},
  author       = {Harsimran Kaur and Anurag Rai and Sarvjit Singh Bhatia and Gaurav Dhiman},
  doi          = {10.1016/j.engappai.2020.104008},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104008},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MOEPO: a novel multi-objective emperor penguin optimizer for global optimization: special application in ranking of cloud service providers},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Metaheuristics for the multi-task simultaneous supervision
dual resource-constrained scheduling problem. <em>EAAI</em>,
<em>96</em>, 104004. (<a
href="https://doi.org/10.1016/j.engappai.2020.104004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This comprehensive study develops advantageous optimization methods to solve a nascent problem, namely multi-task simultaneous supervision dual resource-constrained (MTSSDRC) scheduling. MTSSDRC is a complex problem that deals with machine assignment, job sequencing, operator allocation, and task sequencing. Setup and unloading must be scheduled to operators, and they are allowed to leave machines while processing jobs. Earlier research on MTSSDRC developed a permutation-based genetic algorithm (PGA) with a specific decoding scheme, namely DSE, to solve the problem. Many previous studies succeed in solving scheduling problems by modifying well-known metaheuristic techniques. Therefore, we are inspired by this to explore further modifications to particular metaheuristics. The first contribution of the present study lies in the development of new decoding schemes that can perform better than the existing option. Five new decoding schemes are considered. Two of those schemes, namely DS2 and DS4, perform significantly better than DSE, reaching 6% relative deviation. DS4 is superior in terms of solution quality, but DS2 can run eight times faster. Another contribution is the development of six modified metaheuristics that are implemented for the MTSSDRC problem: tabu search, simulated annealing, particle swarm optimization, bees algorithm (BA), artificial bee colony, and grey wolf optimization. The performance of these metaheuristics is compared with that of the PGA. The results show that the PGA and BA are consistently superior for medium- and large-sized problems. The BA is more promising in terms of solution quality, but the PGA is faster.},
  archive      = {J_EAAI},
  author       = {Muhammad Akbar and Takashi Irohara},
  doi          = {10.1016/j.engappai.2020.104004},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104004},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metaheuristics for the multi-task simultaneous supervision dual resource-constrained scheduling problem},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning in electrical utility industry: A
comprehensive review of a decade of research. <em>EAAI</em>,
<em>96</em>, 104000. (<a
href="https://doi.org/10.1016/j.engappai.2020.104000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart-grid (SG) is a new revolution in the electrical utility industry (EUI) over the past decade. With each moving day, some new advanced technologies are coming into the picture which forces the utility engineers to think about its application to make the electrical grid become smarter. Artificial intelligence (AI) techniques such as machine learning (ML), artificial neural network (ANN), deep learning (DL), reinforcement learning (RL), and deep-reinforcement learning (DRL) are the few examples of above-mentioned advanced technologies by which large volume of collected information being processed, and deliver the solution to the complex problems associated with EUI. In recent times, DL for artificial intelligence applications has gained huge attention in the diverse research area. The traditional ML techniques have several constrained for processing the data in raw form. However, the DL provides the options to process the raw data without extracting and selecting the feature vector. The DL techniques belong to a new era of AI development. This article presents the taxonomy of DL algorithms available in the literature applied to different problems in EUI. The main objective of this survey is to provide a comprehensive idea to the researcher/utility engineer about the applications and future research scope of DL methods for power systems studies.},
  archive      = {J_EAAI},
  author       = {Manohar Mishra and Janmenjoy Nayak and Bighnaraj Naik and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.104000},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104000},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning in electrical utility industry: A comprehensive review of a decade of research},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A reaction–diffusion based level set method for image
segmentation in three dimensions. <em>EAAI</em>, <em>96</em>, 103998.
(<a href="https://doi.org/10.1016/j.engappai.2020.103998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image segmentation of computed tomography data for three-dimensional biological structures remains challenging because of the limitations of existing numerical techniques and computer resources. The work represents the structures as the zero-level contour of a level set function whose value is constrained to a narrow band ranging. A cost functional composed of fitting energy for extracting the local intensity and diffusion energy for regularization is minimized within a framework of optimization. To avoid the re-initialization procedure and accelerate the convergence when updating the level set function, a reaction–diffusion technique is developed to replace the upwind algorithm by finite element analysis. Numerical examples demonstrate elegant biological structures with clear and smooth interfaces can be generated within a few iteration steps because the time step 100-fold larger than the allowable value of Courant–Friedrichs–Lewy stability condition can be applied in the proposed method.},
  archive      = {J_EAAI},
  author       = {Zhe Zhang and Yi Min Xie and Qing Li and Shiwei Zhou},
  doi          = {10.1016/j.engappai.2020.103998},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103998},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reaction–diffusion based level set method for image segmentation in three dimensions},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tutorial on solving ordinary differential equations using
python and hybrid physics-informed neural network. <em>EAAI</em>,
<em>96</em>, 103996. (<a
href="https://doi.org/10.1016/j.engappai.2020.103996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a tutorial on how to directly implement integration of ordinary differential equations through recurrent neural networks using Python. In order to simplify the implementation, we leveraged modern machine learning frameworks such as TensorFlow and Keras. Besides, offering implementation of basic models (such as multilayer perceptrons and recurrent neural networks) and optimization methods, these frameworks offer powerful automatic differentiation. With all that, the main advantage of our approach is that one can implement hybrid models combining physics-informed and data-driven kernels, where data-driven kernels are used to reduce the gap between predictions and observations. Alternatively, we can also perform model parameter identification. In order to illustrate our approach, we used two case studies. The first one consisted of performing fatigue crack growth integration through Euler’s forward method using a hybrid model combining a data-driven stress intensity range model with a physics-based crack length increment model. The second case study consisted of performing model parameter identification of a dynamic two-degree-of-freedom system through Runge–Kutta integration. The examples presented here as well as source codes are all open-source under the GitHub repository https://github.com/PML-UCF/pinn_code_tutorial .},
  archive      = {J_EAAI},
  author       = {Renato G. Nascimento and Kajetan Fricke and Felipe A.C. Viana},
  doi          = {10.1016/j.engappai.2020.103996},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103996},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A tutorial on solving ordinary differential equations using python and hybrid physics-informed neural network},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel discrete evidence fusion approach by considering the
consistency of belief structures. <em>EAAI</em>, <em>96</em>, 103994.
(<a href="https://doi.org/10.1016/j.engappai.2020.103994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion of discrete belief structures gets much attention owing to the widespread existence of discrete information in decision analysis, expert system and other fields. Recently, one method that combines discrete evidence was proposed by establishing an optimization model. However, the existing optimization model of discrete belief structure has a problem of high computational complexity since it needs to calculate all the cases of deterministic evidence combination to obtain maximum and minimum values of each focal element in combination result. In this paper, a novel method of discrete evidence fusion is proposed to reduce the computational complexity by considering the consistency of belief structures of evidence groups and finding the most consistent and most inconsistent cases. Example and application are given to illustrate the effectiveness and rationality of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xinyang Deng and Yang Yang and Jihao Yang},
  doi          = {10.1016/j.engappai.2020.103994},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103994},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel discrete evidence fusion approach by considering the consistency of belief structures},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommender systems for sensor-based ambient control in
academic facilities. <em>EAAI</em>, <em>96</em>, 103993. (<a
href="https://doi.org/10.1016/j.engappai.2020.103993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic spaces are an environment that promotes student performance not only because of the quality of its equipment, but also because of its ambient comfort conditions, which can be controlled by means of actuators that receive data from sensors. Something similar can be said about other environments, such as home, business, or industry environment. However, sensor devices can cause faults or inaccurate readings in a timely manner, affecting control mechanisms. The mutual relationship between ambient variables can be a source of knowledge to predict a variable in case a sensor fails. Moreover, the relationship between these variables and the occupation of spaces by students over time also contains an adequate knowledge of the context for prediction. In this article we propose to predict ambient variables by means of recommendation systems based on collaborative filtering, which are fed with data from sensors over time in different academic rooms. For this purpose, we applied two different algorithms: Probabilistic Matrix Factorization and Bayesian Non-negative Matrix Factorization. The accuracy of the algorithms when comparing actual and predicted values and the performance comparison between the two collaborative filtering implementations lead us to propose Probabilistic Matrix Factorization as a good approach for supporting ambient control systems.},
  archive      = {J_EAAI},
  author       = {Francisco Pajuelo-Holguera and Juan A. Gómez-Pulido and Fernando Ortega},
  doi          = {10.1016/j.engappai.2020.103993},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103993},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recommender systems for sensor-based ambient control in academic facilities},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Switching TS fuzzy model-based dynamic sliding mode observer
design for non-differentiable nonlinear systems. <em>EAAI</em>,
<em>96</em>, 103990. (<a
href="https://doi.org/10.1016/j.engappai.2020.103990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents four sliding mode observers (SMOs) based on a novel approach in Takagi–Sugeno (TS) fuzzy modeling of multi-input multi-output (MIMO) non-linear systems that have non-differentiable operating points. A comprehensive approach is proposed to using the TS fuzzy model (TSFM) in the field of non-differentiable nonlinear systems, where the TSFM is an approximation with high accuracy and a negligible error (2 ε ) of the nonlinear model. Furthermore, the considered system can be with measurable or unmeasurable premise variables. The observers are synthesized for the above two cases and dynamic observers for state estimations of MIMO non-linear Lipschitz systems. The dynamic gain of the observer is established from inspiring state-space representation of an LTI system with error as input, internal states, and the gain of the observer as output. The dynamics used in the gain of the observer will increase the degrees of freedom in the design procedure and a generalization to the one used in previous works. The proposed method is applicable for continuous-time, but not necessarily differentiable, nonlinear systems. Considering the inherent strongly nonlinear and coupling performance of the plant, the switching method driven by states is presented. This paper presents a comparison of four SMOs and multiple-model adaptive estimation (MMAE) for benchmark hydraulic wind power transfer (HWPT). Simulation results demonstrate improvement in the state observation convergence rate and simplicity and universality of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Kazem Zare and Mokhtar Shasadeghi and Afshin Izadian and Taher Niknam and Mohammad Hassan Asemani},
  doi          = {10.1016/j.engappai.2020.103990},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103990},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Switching TS fuzzy model-based dynamic sliding mode observer design for non-differentiable nonlinear systems},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach integrating AHP and TOPSIS under spherical
fuzzy sets for advanced manufacturing system selection. <em>EAAI</em>,
<em>96</em>, 103988. (<a
href="https://doi.org/10.1016/j.engappai.2020.103988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid of AHP and TOPSIS has led researchers to integrate the combination with different extensions of fuzzy sets. The recently developed three-dimensional spherical fuzzy set is an extension of the fuzzy set, which is effective in handling uncertainty and quantifying expert judgements. In this paper, a novel framework is elaborated which combines AHP and TOPSIS with a spherical fuzzy set. Spherical fuzzy AHP is used to calculate the spherical fuzzy weights of the criteria, while spherical fuzzy TOPSIS is used to find the final rank of the alternatives. A new spherical fuzzy geometric mean formula is proposed for calculating the spherical fuzzy criteria weights. A new eleven-point spherical fuzzy linguistic term scale is presented, which can be used by the experts to quantify the preference. The proposed framework is applied to an advanced manufacturing system selection problem with six evaluation criteria and four alternatives. It is found that spherical fuzzy AHP-TOPSIS is effective in handling uncertainty in decision making and leads to robust and competitive results compared with state-of-the-art multi-criteria decision-making (MCDM) approaches.},
  archive      = {J_EAAI},
  author       = {Manoj Mathew and Ripon K. Chakrabortty and Michael J. Ryan},
  doi          = {10.1016/j.engappai.2020.103988},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103988},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach integrating AHP and TOPSIS under spherical fuzzy sets for advanced manufacturing system selection},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy adaptive automatic train operation control with
protection constraints: A residual nonlinearity approximation-based
approach. <em>EAAI</em>, <em>96</em>, 103986. (<a
href="https://doi.org/10.1016/j.engappai.2020.103986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present fuzzy adaptive control based on residual nonlinearity approximation in the presence of protection constraints for the target trajectory tracking problem observed in automatic train operation. Herein, protection constraints refer to a condition wherein the speed and position of a controlled train are not allowed to surpass the boundaries imposed by automatic train protection and moving authority. By defining proper coordinate transformation, the protection constraints are converted to an error-prescribed performance control problem that facilitates operational efficiency by reducing the margin with respect to target trajectories. Based on the prescribed performance control methodology, we present an improved scheme using fuzzy residual nonlinearity approximation and establish the uniformly ultimately boundedness (UUB) property. A novel feature therein is that the ultimate boundary of the proposed scheme is simultaneously characterized by the prescribed performance functions and control parameters, with rigorous and analytically mathematical expressions; while pioneering the prescribed performance control methodology, the ultimate boundary is characterized solely by the prescribed performance functions. To verify the effectiveness and advantages of the proposed scheme, the controllers are applied to the automatic train operation on the Beijing Yizhuang line, which contains 13 operational intervals. Finally, comparative and simulation results are presented to validate the proposed method.},
  archive      = {J_EAAI},
  author       = {Shigen Gao and Jin Wei and Haifeng Song and Zixuan Zhang and Hairong Dong and Xiaoming Hu},
  doi          = {10.1016/j.engappai.2020.103986},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103986},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy adaptive automatic train operation control with protection constraints: A residual nonlinearity approximation-based approach},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new classification method based on the negation of a basic
probability assignment in the evidence theory. <em>EAAI</em>,
<em>96</em>, 103985. (<a
href="https://doi.org/10.1016/j.engappai.2020.103985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the practical application of classification, how to handle uncertain information for efficient classification is a hot topic. In this paper, in the frame of Dempster–Shafer evidence theory, a new classification method based on the negation of basic probability assignment (BPA) is proposed to implement an effective classification. The proposed method addresses the issue that the values of samples’ attributes cannot clearly point out a certain class in classification problems. For uncertain information modeling, the negation of BPA is adopted to obtain more valuable information in the body of evidence. To measure the uncertain information represented by the negation of BPA, the belief entropy is used for calculating the uncertain degree of each body of evidence. Finally, Dempster’s combination rule is used for data fusion to identify and recognize the unknown class. The effectiveness and efficiency of the new classification method are validated according to experiments on several UCI data sets. In addition, the classification experiment on the data sets with the changing proportion of the training set verifies that the method is robust and feasible.},
  archive      = {J_EAAI},
  author       = {Dongdong Wu and Zijing Liu and Yongchuan Tang},
  doi          = {10.1016/j.engappai.2020.103985},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103985},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new classification method based on the negation of a basic probability assignment in the evidence theory},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep neural annealing model for the semantic representation
of documents. <em>EAAI</em>, <em>96</em>, 103982. (<a
href="https://doi.org/10.1016/j.engappai.2020.103982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a result of the growing production of unstructured textual data, techniques for representing words and documents in the vector space have emerged recently. The Brazilian Public Ministry has received several textual requests that are send by citizens with different needs, such as those involved in cases of domestic violence against women, others requesting intensive care unit admissions, and more. The time spent in classifying, detecting similar requests and distributing them is essential to optimize and save public resources. Therefore, we adopted the neural model with the Simulated Annealing (SA), a classic global optimization algorithm with low computational complexity, because of the need to reduce the daily training time, providing a more friendly graphic visualization of documents in high dimensions, supporting the judicial decision process. The physical analogy of the SA meta-heuristic associated with the continuous representation of documents in the vector space contribute greatly to the friendly visualization of a high-dimensional dataset, maintaining a comparable score with other deep models and optimization algorithms, such as Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and Bayesian Optimization (BO).},
  archive      = {J_EAAI},
  author       = {Leandro R.C. de Mendonça and Gelson da Cruz Júnior},
  doi          = {10.1016/j.engappai.2020.103982},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103982},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep neural annealing model for the semantic representation of documents},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary extreme learning machine with novel activation
function for credit scoring. <em>EAAI</em>, <em>96</em>, 103980. (<a
href="https://doi.org/10.1016/j.engappai.2020.103980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The term credit scoring is extensively used in credit industries for decision making and measuring the risk associated with an applicant. It uses applicants’ historical data for credit risk evaluation by applying machine learning or statistical techniques. Credit risk evaluation has become progressively important field in financial risk management for credit industries. In this study, Extreme Learning Machine (ELM) is utilized as a classification tool for credit risk evaluation model. ELM requires more number of hidden neurons and random determination of the input weights and hidden biases. Moreover, ELM performance depends on activation function, weights and biases assigned to hidden neurons. An appropriate approach for selection of activation function, weights and biases may improve the performance of ELM. Hence, we have proposed a novel activation function and an evolutionary approach to get optimized weights and biases by utilizing Bat optimization algorithm. Further, the simulations are performed on four bench-marked credit scoring datasets with various activation functions. Simulation results demonstrate that proposed Evolutionary ELM (EELM) is more suitable for credit risk evaluation.},
  archive      = {J_EAAI},
  author       = {Diwakar Tripathi and Damodar Reddy Edla and Venkatanareshbabu Kuppili and Annushree Bablani},
  doi          = {10.1016/j.engappai.2020.103980},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103980},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evolutionary extreme learning machine with novel activation function for credit scoring},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust empirical wavelet fuzzy cognitive map for time series
forecasting. <em>EAAI</em>, <em>96</em>, 103978. (<a
href="https://doi.org/10.1016/j.engappai.2020.103978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive maps have achieved significant success in time series modeling and forecasting. However, fuzzy cognitive maps still contain weakness to handle the nonstationarity and outliers. We propose a novel time series forecasting model based on fuzzy cognitive maps and empirical wavelet transformation in this paper. The empirical wavelet transformation is applied to decompose the original time series into different levels which capture information of different frequencies. Then, the high-order fuzzy cognitive map is trained to model the relationships among all the sub-series generated and original time series. To enhance the robustness of high-order fuzzy cognitive maps against outliers, a novel learning method based on support vector regression is designed. Finally, we divide the summation of each concept value of the high-order fuzzy cognitive map by two to obtain the numerical predictions. A comprehensive empirical study on eight public time series validates the superiority of proposed model compared with the popular baseline models from the literature.},
  archive      = {J_EAAI},
  author       = {Ruobin Gao and Liang Du and Kum Fai Yuen},
  doi          = {10.1016/j.engappai.2020.103978},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103978},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust empirical wavelet fuzzy cognitive map for time series forecasting},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An attention long short-term memory based system for
automatic classification of speech intelligibility. <em>EAAI</em>,
<em>96</em>, 103976. (<a
href="https://doi.org/10.1016/j.engappai.2020.103976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech intelligibility can be degraded due to multiple factors, such as noisy environments, technical difficulties or biological conditions. This work is focused on the development of an automatic non-intrusive system for predicting the speech intelligibility level in this latter case. The main contribution of our research on this topic is the use of Long Short-Term Memory (LSTM) networks with log-mel spectrograms as input features for this purpose. In addition, this LSTM-based system is further enhanced by the incorporation of a simple attention mechanism that is able to determine the more relevant frames to this task. The proposed models are evaluated with the UA-Speech database that contains dysarthric speech with different degrees of severity. Results show that the attention LSTM architecture outperforms both, a reference Support Vector Machine (SVM)-based system with hand-crafted features and a LSTM-based system with Mean-Pooling.},
  archive      = {J_EAAI},
  author       = {Miguel Fernández-Díaz and Ascensión Gallardo-Antolín},
  doi          = {10.1016/j.engappai.2020.103976},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103976},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An attention long short-term memory based system for automatic classification of speech intelligibility},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic epileptic EEG classification based on differential
entropy and attention model. <em>EAAI</em>, <em>96</em>, 103975. (<a
href="https://doi.org/10.1016/j.engappai.2020.103975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In epilepsy electroencephalogram (EEG) analysis, clinicians usually interpret EEG page by page, which is time-consuming and brings heavy workload. This paper proposes a novel automatic epileptic EEG classification approach based on differential entropy and attention mechanism, aiming at designing a short-term epileptic EEG classification model with high accuracy and good generalization performance. Firstly, the original EEG recordings are decomposed into five sub-frequency bands which approximately obey the Gaussian distribution. Afterward, a improved attention model framework considering both row and column attention with a shallower VGGNet (AttVGGNet-RC) is put forward as the classifier. Finally, non-patient specific method is employed to evaluate the performance with pre-tuned hypermeters. With 8-fold data, the proposed model yielded 77.33 ± 2.91% sensitivity, 86.67 ± 3.70% specificity and 82.00 ± 1.43% accuracy, and accuracy was increased by 5.34%, 8.99%, 26.24% and 4.47% respectively compared with multi-layer perceptron (MLP), extreme learning machine (ELM), support vector machine (SVM) and Long Short-Term Memory (LSTM). With 10-fold shuffled data, the improved attention model yielded 93.84 ± 0.63% sensitivity, 95.84 ± 0.74% specificity and 95.12 ± 0.20% accuracy, and the accuracy was 1.34%, 16.29%, 27.12% and 8.24% higher than MLP, ELM, SVM and LSTM respectively. The experimental result showed that the attention model achieved high classification accuracy with low standard deviation as well as good generalization performance. Furthermore, compared with state-of-art epilepsy analysis system, the proposed approach also show better performance. Therefore, this study has significant clinical application value in epilepsy analysis.},
  archive      = {J_EAAI},
  author       = {Jian Zhang and Zuochen Wei and Junzhong Zou and Hao Fu},
  doi          = {10.1016/j.engappai.2020.103975},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103975},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic epileptic EEG classification based on differential entropy and attention model},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust RGB-d tracking via compact CNN features.
<em>EAAI</em>, <em>96</em>, 103974. (<a
href="https://doi.org/10.1016/j.engappai.2020.103974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature representation is at the core of visual tracking. This paper presents a robust tracking method in RGB-D videos. Firstly, the RGB and depth images are separately encoded using a hierarchical convolutional neural network (CNN) features. Secondly, in order to reduce computation cost, we exploit random projection to compress the CNN features. The high dimensional CNN features are randomly projected into a low dimensional feature space. The correlation filter tracking framework is then independently carried out in RGB and depth images. And backward tracking scheme is adopted to evaluate the tracking results in these two images. The final position is determined according to the tracked location in the two image channels. In addition, model updating is implemented adaptively. Our tracker is evaluated on two RGB-D benchmark datasets and achieves comparable results to the other state-of-the-art RGB-D tracking methods.},
  archive      = {J_EAAI},
  author       = {Yong Wang and Xian Wei and Lingkun Luo and Wen Wen and Yang Wang},
  doi          = {10.1016/j.engappai.2020.103974},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103974},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust RGB-D tracking via compact CNN features},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel ensemble learning based on bayesian belief network
coupled with an extreme learning machine for flash flood susceptibility
mapping. <em>EAAI</em>, <em>96</em>, 103971. (<a
href="https://doi.org/10.1016/j.engappai.2020.103971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable flash flood susceptibility maps are a vital tool for land planners and emergency management officials for early flood warning and mitigation. We have developed a new ensemble learning model that predicts flash flood susceptibility at Haraz, Iran. The new model couples a Bayesian Belief Network (BBN) model with an extreme learning machine (ELM) and backpropagation (BP) structure optimized by a genetic algorithm (GA) named GA-BN-NN model. We applied the support vector machine (SVM) technique to a database of 194 flood locations with ten conditioning factors. An artificial neural network (ANN) algorithm with a multi-layer perceptron function, MLP-BP, optimized by a genetic algorithm, GA-MLP, and a shuffled frog-leaping algorithm, SFLA-MLP, were used as benchmark models for assessing the power prediction of the proposed model. Statistical measures, including sensitivity, specificity, accuracy, F1-measure and Jaccard coefficient, and root mean square error, were used to evaluate the goodness-of-fit and prediction accuracy, respectively, of the training and testing datasets. We found that all ten factors are positively correlated with flood occurrence, but slope angle has the highest average merit (AM = 9.7) and thus contributes most to the occurrence of flooding. Results indicate that the GA-BN-NN model has the highest goodness-of-fit and prediction accuracy (AUC = 0.966) and hence outperforms other ensemble learning models that we tested — the SFLA-MLP, MLP-BP, and GA-MLP models. We thus conclude that the proposed model is a promising technique for managing risk in flood-prone areas around the world.},
  archive      = {J_EAAI},
  author       = {Ataollah Shirzadi and Shahrokh Asadi and Himan Shahabi and Somayeh Ronoud and John J. Clague and Khabat Khosravi and Binh Thai Pham and Baharin Bin Ahmad and Dieu Tien Bui},
  doi          = {10.1016/j.engappai.2020.103971},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103971},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel ensemble learning based on bayesian belief network coupled with an extreme learning machine for flash flood susceptibility mapping},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group reduced kernel extreme learning machine for fault
diagnosis of aircraft engine. <em>EAAI</em>, <em>96</em>, 103968. (<a
href="https://doi.org/10.1016/j.engappai.2020.103968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original kernel extreme learning machine (KELM) employs all training samples to construct hidden layer, thus avoiding the performance fluctuations caused by the ELM randomly assigning weights. However, excessive nodes will inevitably lead to structural redundancy, which hinders its application in systems with high real-time performance requirements but limited onboard storage and computing capacity. Considering the well interpretability of sparse learning, this study introduces the group sparse structure for KELM to resolve its limitation of structural redundancy. Specifically, the proposed novel method introduces a special norm to reformulate the dual optimization problem of KELM to realize group sparse structure in output weights. As a result, nodes with large weights can be selected as the significant nodes, while nodes with small weights will be regarded as the redundant nodes and neglected directly. In addition, we have also devised an alternating iterative optimization algorithm and deduced the complete proof of convergence to solve the non-smoothness optimization problem in proposed method. Then, the validity and feasibility of the proposed method are verified by extensive experiments on benchmark datasets. More importantly, tests of fault diagnosis for an aircraft engine show that the proposed approach can maintain the competitive recognition performance with much faster testing speed.},
  archive      = {J_EAAI},
  author       = {Bing Li and Yong-Ping Zhao},
  doi          = {10.1016/j.engappai.2020.103968},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103968},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Group reduced kernel extreme learning machine for fault diagnosis of aircraft engine},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New imbalanced fault diagnosis framework based on
cluster-MWMOTE and MFO-optimized LS-SVM using limited and complex
bearing data. <em>EAAI</em>, <em>96</em>, 103966. (<a
href="https://doi.org/10.1016/j.engappai.2020.103966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity of their working conditions, historical rolling bearing datasets are mostly limited and imbalanced. The fault data may be composed of multiple subclusters; that is, the historical rolling bearing data have both between-class and within-class imbalances. While support vector machines (e.g., least squares support vector machines (LS-SVMs)) offer advantages when dealing with limited data, traditional fault diagnosis using an LS-SVM has the disadvantages of easy failure of complex imbalanced data and large dependence on the classifier hyperparameters. Therefore, this paper presents a new imbalanced fault diagnosis framework based on a cluster-majority weighted minority oversampling technique (Cluster-MWMOTE) and a moth-flame optimization (MFO)-based LS-SVM classifier. As an extension of MWMOTE, our proposed Cluster-MWMOTE combines the clustering algorithm represented by agglomerative hierarchical clustering (AHC) with MWMOTE. Unlike MWMOTE, Cluster-MWMOTE can avoid the ignoring of small subclusters of faulty (minority) instances far from normal (majority) instances. That is, Cluster-MWMOTE further improves the adaptation to within-class imbalances. As a novel heuristic intelligent algorithm, MFO exhibits faster convergence and higher precision than the traditional optimization algorithms (e.g., particle swarm optimization (PSO) and genetic algorithm (GA)). Therefore, we utilize MFO to optimize the hyperparameters (Sigma &amp; γ ) of the LS-SVM classifier for the first time. The fault diagnosis results represented by CWRU and IMS bearing data suggest that the proposed framework provides higher fault diagnosis recognition rates and algorithm robustness than 16 existing algorithms.},
  archive      = {J_EAAI},
  author       = {Jianan Wei and Haisong Huang and Liguo Yao and Yao Hu and Qingsong Fan and Dong Huang},
  doi          = {10.1016/j.engappai.2020.103966},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103966},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New imbalanced fault diagnosis framework based on cluster-MWMOTE and MFO-optimized LS-SVM using limited and complex bearing data},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adapted multi-objective genetic algorithm for solving the
cash in transit vehicle routing problem with vulnerability estimation
for risk quantification. <em>EAAI</em>, <em>96</em>, 103964. (<a
href="https://doi.org/10.1016/j.engappai.2020.103964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aimed to develop a model for vehicle routing problem with two objective functions of risk and distance minimization to optimize safety of cash/valuable commodities transportation. It is necessary to properly anticipate and prevent the occurrence of robbery to reduce the vulnerability to robbery attempts. The proposed approach for the vulnerability estimation of an armed robbery has been based on game theory and multi-criteria decision making (MCDM), which can accurately measure the amount of risk. A new multi-objective intelligent genetic algorithm (MOIGA) comprised of various heuristics is also designed to identify and intelligently select the most efficacious heuristic. The following experiments are used to test the proposed MOIGA: (1) Examining the influence of each proposed operator on the performance of the algorithm; (2) Evaluating the quality and diversity of MOIGA solutions compared to other popular algorithms. The obtained results demonstrate the effectiveness and efficiency of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Seyed Farid Ghannadpour and Fatemeh Zandiyeh},
  doi          = {10.1016/j.engappai.2020.103964},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103964},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adapted multi-objective genetic algorithm for solving the cash in transit vehicle routing problem with vulnerability estimation for risk quantification},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid optimization approach for reactive power
dispatch problem considering voltage stability index. <em>EAAI</em>,
<em>96</em>, 103963. (<a
href="https://doi.org/10.1016/j.engappai.2020.103963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel, reliable, and effective hybrid approach based on the integration of the firefly algorithm (FA) and the adaptive particularly tunable fuzzy particle swarm optimization (APT-FPSO) method to address reactive power dispatch (RPD) problem, a crucial optimization problem in the operation of power systems. Similar to many other original meta-heuristic optimization techniques, the standard FA suffers from some severe drawbacks, most importantly being easily trapped into a locally optimal solution. In order to tackle these difficulties, in the current study, an improved version of fuzzy-based particle swarm optimization is utilized in the internal structure of the original FA. The developed hybrid approach, which is capable of avoiding premature convergence of the original FA by enhancing exploration and exploitation procedures, is employed to determine the optimum control variables (i.e., the voltage of generation buses, tap positions of tap-changer transformers, and reactive power output of shunt compensators) through optimizing three distinct objective functions consisting of total transmission real power loss, the voltage magnitude deviations as well as voltage stability index. To validate the accuracy and competency of the proposed hybrid approach, it is firstly used for solving several benchmark optimization functions and then applied to three test systems at different scales, consisting of IEEE 30-bus, IEEE 57-bus, and IEEE 118-bus power systems, for solving the RPD problem. Eventually, the results of the presented hybrid method will be compared to those obtained by other implemented swarm intelligence-based approaches. The statistical analysis of this research substantiates the robustness and effectiveness of the developed algorithm to handle sophisticated optimization problems, particularly the RPD problem.},
  archive      = {J_EAAI},
  author       = {Mostafa Nasouri Gilvaei and Hossein Jafari and Mojtaba Jabbari Ghadi and Li Li},
  doi          = {10.1016/j.engappai.2020.103963},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103963},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel hybrid optimization approach for reactive power dispatch problem considering voltage stability index},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-evolutionary sibling models to forecast railway
arrivals using reservation data. <em>EAAI</em>, <em>96</em>, 103960. (<a
href="https://doi.org/10.1016/j.engappai.2020.103960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasts of daily arrivals are of essential to allocate seat resources for transportation companies. Most studies addressed the issue from conventional time series aspects to retrieve historical arrival patterns and project future numbers. This study aims to utilize railway reservation records instead of arrival data to construct self-evolutionary advanced booking models and compare with three benchmarks. In addition, the proposed model involved the spirit of one prototype with multiple versions to pursue accuracy improvement. A family of eight sibling versions based on the curve similarity model, differentiating from the evaluation of similarities among booking curves, was established. The results showed that the constructed sibling versions perform differently with respect to individual data series. In other words, the way of similarity evaluation did affect the predictive performance. Although there was no single version outperforming the others, the selection based on the lowest validation errors was verified to be a good strategy to attain promising out-of-sample performance. Overall speaking, maintaining the family of sibling models for booking data with distinctive characteristics can achieve at least 4.5% and at most 23% improvement of accuracy if comparing with one specific version to all data series. In addition, the proposed sibling models can also outperform popular advanced booking benchmarks such as pick up, regression, and conventional curve similarity approach up to 36%, 32%, and 35%, respectively.},
  archive      = {J_EAAI},
  author       = {Tsung-Hsien Tsai},
  doi          = {10.1016/j.engappai.2020.103960},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103960},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-evolutionary sibling models to forecast railway arrivals using reservation data},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A user-knowledge crowdsourcing task assignment model and
heuristic algorithm for expert knowledge recommendation systems.
<em>EAAI</em>, <em>96</em>, 103959. (<a
href="https://doi.org/10.1016/j.engappai.2020.103959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expert Knowledge Recommendation System (EKRS) is a scientific research assistant system that actively provides experts with the latest domain knowledge according to their professional knowledge background. This paper applies the crowdsourcing task assignment method, taking experts as users and recommending corresponding professional knowledge as tasks. To solve the problems of inaccurate user-knowledge matching and low assignments in EKRS, a user-knowledge task assignment model is established. To maximize the number of global task assignments, the model first applies an improved greedy assignment algorithm to convert the user-knowledge task maximum assignment problem into the maximum weight problem in bipartite graphs. Based on the matching value between a task and a user, a task is assigned to the user with a high matching value. Then, the assigned tasks are sorted with the tree decomposition technique to obtain the optimal task scheduling scheme. The heuristic depth-first search algorithm (DFS+HA) is used to update the boundaries of the heuristic function quickly, and the assignment scheme of the optimal solution can be obtained efficiently through the upper and lower bounds of the search process. Finally, the algorithm was experimentally verified with artificial data sets and the real data extracted from EKRS. The experimental results indicated that the algorithm proposed in this paper can improve the amount of user-knowledge task assignment in EKRS, find the optimal assignment scheme to maximize the number of global task assignments, and improve the search efficiency.},
  archive      = {J_EAAI},
  author       = {Li Gao and Yi Gan and Binghai Zhou and Mengyu Dong},
  doi          = {10.1016/j.engappai.2020.103959},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103959},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A user-knowledge crowdsourcing task assignment model and heuristic algorithm for expert knowledge recommendation systems},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new similarity measure between picture fuzzy sets and its
application. <em>EAAI</em>, <em>96</em>, 103956. (<a
href="https://doi.org/10.1016/j.engappai.2020.103956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy set is a generalization of intuitionistic fuzzy set, which can describe fuzzy, uncertain, incomplete and inconsistent information. Similarity measure is a technique used to evaluate the degree of similarity between picture fuzzy sets. Although there are some similarity measures between picture fuzzy sets, some of them cannot meet the axiomatic definition of similarity measure, or there are some unreasonable situations when distinguishing different picture fuzzy information. In order to overcome these defects, a new similarity measure based on the three constituent functions of picture fuzzy sets is proposed in this paper. Through a numerical example and some pattern recognition experiments, the effectiveness and superiority of the proposed similarity measure are verified.},
  archive      = {J_EAAI},
  author       = {Minxia Luo and Yue Zhang},
  doi          = {10.1016/j.engappai.2020.103956},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103956},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new similarity measure between picture fuzzy sets and its application},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification, prediction, and monitoring of parkinson’s
disease using computer assisted technologies: A comparative analysis.
<em>EAAI</em>, <em>96</em>, 103955. (<a
href="https://doi.org/10.1016/j.engappai.2020.103955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease is a neurogenerative disorder that occurs due to the loss of dopamine-producing cells. Till now, there is no cure for this disease but correct medications can slow down the progression. Therefore, early diagnosis of this disease is very important to improve the quality of life of Parkinson patients. This paper provides a comparative analysis of computer-assisted technologies for classification, prediction, and monitoring of Parkinson patients. The articles are selected based on the type, source of data, and symptoms to diagnose Parkinson’s disease. Our contribution in this paper includes the study of recent articles from the year 2017, 2018, and 2019 and some other articles to consolidate some of the previous work as well. Research articles are chosen based on symptoms, type, and source of data to cover each aspect of Parkinson’s disease. There is a great potential for early diagnosis as well as improving the quality of life with the help of computer-assisted rehabilitation techniques. We have divided our analysis into six sub-categories. A detailed analysis has been done on each sub-category. Information about some tools, software, and libraries are provided for the use of researchers. A comparison has also been done on different feature extraction and classification techniques so that researchers can further explore these techniques. Research gaps and future directions are also discussed along with challenges related to each gap for researchers to work on.},
  archive      = {J_EAAI},
  author       = {Jinee Goyal and Padmavati Khandnor and Trilok Chand Aseri},
  doi          = {10.1016/j.engappai.2020.103955},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103955},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification, prediction, and monitoring of parkinson’s disease using computer assisted technologies: A comparative analysis},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). CubeSatNet: Ultralight convolutional neural network designed
for on-orbit binary image classification on a 1U CubeSat. <em>EAAI</em>,
<em>96</em>, 103952. (<a
href="https://doi.org/10.1016/j.engappai.2020.103952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A 1U CubeSat has severe limitations on size, power and downlink capabilities. Transferring images taken by imaging payload from orbit can be a challenging. To save time and effort in downlinking and post-processing, a mechanism must be in place to sort quality data before transmitting it to the ground station. This paper presents an innovative approach combining a novel CubeSat image dataset and a lightweight Convolutional Neural Network architecture for automatically selecting images for downlink on a 1U CubeSat. Coined as CubeSatNet, the neural network is trained on 60,000 augmented images, is tiny enough to run on an ARM Cortex MCU and is tested on on-orbit data from Kyushu Institute of Technology’s BIRDS-3 CubeSats with an accuracy of 90% and F1 score of 0.92. CubeSatNet outperformed SVM, DBN and AE trained to classify CubeSat images. If implemented, the CNN could cut down operation time by about 2/3 while significantly improving the quality of received data.},
  archive      = {J_EAAI},
  author       = {Abhas Maskey and Mengu Cho},
  doi          = {10.1016/j.engappai.2020.103952},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103952},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CubeSatNet: Ultralight convolutional neural network designed for on-orbit binary image classification on a 1U CubeSat},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Forecast-informed power load profiling: A novel approach.
<em>EAAI</em>, <em>96</em>, 103948. (<a
href="https://doi.org/10.1016/j.engappai.2020.103948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Power load forecasting plays a critical role in the context of electric supply optimization. The concept of load characterization and profiling has been used in the past as a valuable approach to improve forecasting performance as well as problem interpretability. This paper proposes a novel, fully fledged theoretical framework for a joint probabilistic clustering and regression model, which is different from existing models that treat both processes independently. The clustering process is enhanced by simultaneously using the input data and the prediction targets during training. The model is thus capable of obtaining better clusters than other methods, leading to more informative data profiles, while maintaining or improving predictive performance. Experiments have been conducted using aggregated load data from two U.S.A. regional transmission organizations, collected over 8 years. These experiments confirm that the proposed model achieves the goals set for interpretability and forecasting performance.},
  archive      = {J_EAAI},
  author       = {Óscar García Hinde and Vanessa Gómez Verdejo and Manel Martínez-Ramón},
  doi          = {10.1016/j.engappai.2020.103948},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103948},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecast-informed power load profiling: A novel approach},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural dynamics simulation using a novel physics-guided
machine learning method. <em>EAAI</em>, <em>96</em>, 103947. (<a
href="https://doi.org/10.1016/j.engappai.2020.103947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-guided machine learning (ML) is an emerging paradigm that combines both data-driven ML models and physics-based models together to fully take advantage of the data discovery ability of ML without losing the valuable physics/domain knowledge. This paper proposes a novel physics-guided ML method based on recurrent neural network (RNN) and multilayer perceptron (MLP) for structural dynamics simulation. The key idea is to integrate the underlying physics of structural dynamics into data-enabled ML models to ‘guide’ the training and prediction of ML models. First, structural dynamics formulation and the use of data-driven RNN and MLP for modeling dynamical systems are briefly reviewed, which leads to the development of the proposed physics-guided ML model. Physics-guided ML model contains physics-based layers to encode the known physics and data-driven layers to approximate the unknown relationships. Thus, the data-driven RNN and MLP are augmented with existing physics knowledge for better performance in simulations. Following this, several numerical case studies for structural dynamics are presented to demonstrate the proposed methodology. It is observed that: (1) compared with purely data-driven ML method, the proposed physics-guided ML method has better generalization ability and reduced training costs; (2) compared with physics-based modeling, the proposed method has improved computational efficiency and can handle partially unknown physics. Finally, conclusions and future works are presented based on the proposed study.},
  archive      = {J_EAAI},
  author       = {Yang Yu and Houpu Yao and Yongming Liu},
  doi          = {10.1016/j.engappai.2020.103947},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103947},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural dynamics simulation using a novel physics-guided machine learning method},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random error sampling-based recurrent neural network
architecture optimization. <em>EAAI</em>, <em>96</em>, 103946. (<a
href="https://doi.org/10.1016/j.engappai.2020.103946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks are good at solving prediction problems. However, finding a network that suits a problem is quite hard because their performance is strongly affected by their architecture configuration. Automatic architecture optimization methods help to find the most suitable design, but they are not extensively adopted because of their high computational cost. In this work, we introduce the Random Error Sampling-based Neuroevolution (RESN), an evolutionary algorithm that uses the mean absolute error random sampling, a training-free approach to predict the expected performance of an artificial neural network, to optimize the architecture of a network. We empirically validate our proposal on four prediction problems, and compare our technique to training-based architecture optimization techniques, neuroevolutionary approaches, and expert designed solutions. Our findings show that we can achieve state-of-the-art error performance and that we reduce by half the time needed to perform the optimization.},
  archive      = {J_EAAI},
  author       = {Andrés Camero and Jamal Toutouh and Enrique Alba},
  doi          = {10.1016/j.engappai.2020.103946},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103946},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Random error sampling-based recurrent neural network architecture optimization},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aircraft engines remaining useful life prediction with an
adaptive denoising online sequential extreme learning machine.
<em>EAAI</em>, <em>96</em>, 103936. (<a
href="https://doi.org/10.1016/j.engappai.2020.103936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining Useful Life (RUL) prediction for aircraft engines based on the available run-to-failure measurements of similar systems becomes more prevalent in Prognostic Health Management (PHM) thanks to the new advanced methods of estimation. However, feature extraction and RUL prediction are challenging tasks, especially for data-driven prognostics. The key issue is how to design a suitable feature extractor that is able to give a raw of time-varying sensors measurements more meaningful representation to enhance prediction accuracy with low computational costs. In this paper, a new Denoising Online Sequential Extreme Learning Machine (DOS-ELM) with double dynamic forgetting factors (DDFF) and Updated Selection Strategy (USS) is proposed. First, depending on the characteristics of the training data that comes from aircraft sensors, robust feature extraction using a modified Denoising Autoencoder (DAE) is introduced to learn important patterns from data. Then, USS is integrated to ensure that only the useful data sequences pass through the training process. Finally, OS-ELM is used to fit the non-accumulative linear degradation function of the engine and to address dynamic programming by trucking the new coming data and forgetting gradually the old ones based on the proposed DDFF. The proposed DOS-ELM is tested on the public dataset of commercial modular aeropropulsion system simulation (C-MAPSS) of a turbofan engine and compared with OS-ELM trained with ordinary Autoencoder (AE), basic OS-ELM and previous works from the literature. Comparison results prove the effectiveness of the new integrated robust feature extraction scheme by showing more stability of the network responses even under random solutions.},
  archive      = {J_EAAI},
  author       = {Tarek Berghout and Leïla-Hayet Mouss and Ouahab Kadri and Lotfi Saïdi and Mohamed Benbouzid},
  doi          = {10.1016/j.engappai.2020.103936},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103936},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aircraft engines remaining useful life prediction with an adaptive denoising online sequential extreme learning machine},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mining top high utility association rules using binary
differential evolution. <em>EAAI</em>, <em>96</em>, 103935. (<a
href="https://doi.org/10.1016/j.engappai.2020.103935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, in a first-of-its-kind-study a Binary Differential Evolution (BDE) and an Adaptive Binary Differential Evolution (ABDE)-based top non-redundant high utility association rule mining (TNR-HUARM) algorithms are proposed. A real-life OnlineRetail dataset is analyzed as an application of TNR-HUARM for customer segmentation based on value, i.e. utility. Apart from this dataset, also tested the effectiveness of our proposed models on six high utility benchmark datasets. The results show that BDE based TNR-HUARM numerically outperformed ABDE based TNR-HUARM on all seven datasets. But, when a t-test is performed, it turned out that the null hypothesis is not rejected. Therefore, Differential Evolution and Adaptive Differential Evolution based rule miners are found to be statistically equal in six out of seven datasets. The proposed algorithms were compared against two state-of-the-art algorithms and mixed results were obtained.},
  archive      = {J_EAAI},
  author       = {Gutha Jaya Krishna and Vadlamani Ravi},
  doi          = {10.1016/j.engappai.2020.103935},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103935},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mining top high utility association rules using binary differential evolution},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High average-utility itemset mining with multiple minimum
utility threshold: A generalized approach. <em>EAAI</em>, <em>96</em>,
103933. (<a
href="https://doi.org/10.1016/j.engappai.2020.103933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High Average-Utility Itemset (HAUI) mining is an emerging pattern mining technique to extract meaningful patterns from a transaction dataset. In the past, several HAUI mining algorithms have been developed with efficient upper-bounds and pruning strategies. However, all these algorithms use a single value of the minimum average-utility threshold for all the itemsets, which limits their applicability to real-life datasets. In order to address this issue, several HAUI mining algorithms with multiple average-utility thresholds have been developed that process the items in ascending order of their minimum average-utility threshold. However, it makes them inapplicable on traditional HAUI mining algorithms. Moreover, the perturbation in preference of items may reduce the performance of the algorithms. This paper presents an HAUI mining algorithm named Generalized High Average-utility Itemset Miner (GHAIM) that processes the items in ascending order of their Average Utility Upper-Bound (AUUB) like the traditional HAUI mining algorithms. A new approach named suffix minimum average-utility is proposed to retain the downward closure property of AUUB and several pruning methods. Besides, a compact list structure is also proposed to mine the HAUIs in one phase. Several pruning methods have been introduced for reducing search space and improving efficiency. Extensive experiments were performed with different sparse and dense types of datasets to determine GHAIM efficiency compared to two existing algorithms. It was observed from the results that GHAIM outperforms both the current algorithms in run time, memory consumption, number of candidate itemsets, and scalability.},
  archive      = {J_EAAI},
  author       = {Krishan Kumar Sethi and Dharavath Ramesh},
  doi          = {10.1016/j.engappai.2020.103933},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103933},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {High average-utility itemset mining with multiple minimum utility threshold: A generalized approach},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On a clustering-based mining approach for spatially and
temporally integrated traffic sub-area division. <em>EAAI</em>,
<em>96</em>, 103932. (<a
href="https://doi.org/10.1016/j.engappai.2020.103932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sub-area division plays an important role in traffic control and is a critical task for traffic system management and traffic network analysis. Most existing algorithms for traffic sub-area division are based on traffic road networks and face a significant challenge in dealing with complex and time-varying traffic network conditions. This paper proposes a clustering-based method for Spatially and Temporally integrated Traffic Sub-area Division, referred to as ST-TSD, which takes into account a complete spectrum of spatiotemporal trajectory information. ST-TSD determines not only a set of traffic sub-areas but also a time interval when these sub-areas are formed without user intervention. In this method, we first establish a discrete linear representation of trajectory points to generate a series of trajectory segments and transform them into multidimensional data points in Euclidean space. We then design an algorithm to extract potential intensive time intervals based on multidimensional data points and improve an existing density clustering algorithm to divide the whole traffic network at each corresponding intensive time interval into a set of sub-areas. Finally, we employ the Convey Hull algorithm to identify the boundaries of filtered sub-areas. For performance evaluation, we design a traffic sub-area division indicator, referred to as T S D I , as a performance metric by combining the W C S S indicator and the classical Davies–Bouldin index. Experimental results on real-life trajectory datasets illustrate that the proposed ST-TSD method significantly improves the quality of traffic sub-area division over existing methods.},
  archive      = {J_EAAI},
  author       = {Xinzheng Niu and Jiahui Zhu and Chase Q. Wu and Shimin Wang},
  doi          = {10.1016/j.engappai.2020.103932},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103932},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {On a clustering-based mining approach for spatially and temporally integrated traffic sub-area division},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering analysis using an adaptive fused distance.
<em>EAAI</em>, <em>96</em>, 103928. (<a
href="https://doi.org/10.1016/j.engappai.2020.103928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of a proper distance function is crucial for analyzing the data efficiently. To find an appropriate distance for clustering algorithm is an unsolved problem as of now. The purpose of this study is to introduce an adaptive fused distance. The S-distance is integrated with the Euclidean distance with the help of a statistical coefficient that depends on density variance of a dataset. We afterward propose a modified k -means clustering algorithm using the novel distance in order to achieve improvement in clustering by finding out the natural and obscure patterns in the data. Some useful properties of the novel distance metrics are elaborated. Theoretical convergence analysis of the proposed clustering is addressed. All the experiments are performed on fourteen datasets. Empirical results using five clustering evaluation metrics on fourteen datasets illustrate that the proposed clustering algorithm defeats seven state-of-the-art clustering methods before and after adding noisy features. It is also proved that the proposed clustering algorithm is statistically significant.},
  archive      = {J_EAAI},
  author       = {Krishna Kumar Sharma and Ayan Seal},
  doi          = {10.1016/j.engappai.2020.103928},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103928},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Clustering analysis using an adaptive fused distance},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NORMO: A new method for estimating the number of components
in CP tensor decomposition. <em>EAAI</em>, <em>96</em>, 103926. (<a
href="https://doi.org/10.1016/j.engappai.2020.103926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decompositions are multi-way analysis tools which have been successfully applied in a wide range of different fields. However, there are still challenges that remain few explored, namely the following: when applying tensor decomposition techniques, what should we expect from the result? How can we evaluate its quality? It is expected that, when the number of components is suitable, then few redundancy is observed in the decomposition result. Based on this assumption, we propose a new method, NORMO, which aims at estimating the number of components in CANDECOMP/PARAFAC (CP) decomposition so that no redundancy is observed in the result. To the best of our knowledge, this work encompasses the first attempt to tackle such problem. According to our experiments, the number of non-redundant components estimated by NORMO is among the most accurate estimates of the true CP number of components in both synthetic and real-world tensor datasets (thus validating the rationale guiding our method). Moreover, NORMO is more efficient than most of its competitors. Additionally, our method can be used to discover multi-levels of granularity in the patterns discovered.},
  archive      = {J_EAAI},
  author       = {Sofia Fernandes and Hadi Fanaee-T and João Gama},
  doi          = {10.1016/j.engappai.2020.103926},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103926},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NORMO: A new method for estimating the number of components in CP tensor decomposition},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rough computing — a review of abstraction, hybridization and
extent of applications. <em>EAAI</em>, <em>96</em>, 103924. (<a
href="https://doi.org/10.1016/j.engappai.2020.103924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of information and communication technology captured common man and various organizations and influenced each individual’s life, work, and study. It leads to a data explosion. It has no utility without any analysis and leads to many analytical techniques. The prime objective of these techniques is to derive some useful knowledge. However, the transformation of data into knowledge is not easy because of many reasons, such as disorganized, incomplete, uncertainties, etc. Furthermore, analyzing uncertainties present in data is not a straight forward task. Many different models, like fuzzy sets, rough sets, soft sets, neural networks, generalizations, and hybrid models obtained by combining two or more of these models, have been fruitful in representing knowledge. To this end, this paper identifies the conventionally used rough computing techniques and discusses their concepts, developments, abstraction, hybridization, and scope of applications.},
  archive      = {J_EAAI},
  author       = {D.P. Acharjya and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103924},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103924},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rough computing — a review of abstraction, hybridization and extent of applications},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A probability-based core dandelion guided dandelion
algorithm and application to traffic flow prediction. <em>EAAI</em>,
<em>96</em>, 103922. (<a
href="https://doi.org/10.1016/j.engappai.2020.103922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dandelion Algorithm (DA) is a recently proposed intelligent optimization algorithm inspired by dandelion sowing. For enhancing its exploitation ability and speeding up its convergence, this work proposes a probability-based core dandelion guided dandelion algorithm (GDA). Specifically, the probability of dandelions being selected is calculated firstly. Then the dandelions need to learn from the core dandelion based on previously calculated probability in the process of sowing. Meanwhile, a greedy selection strategy is applied to GDA. Experimental results show that the proposed algorithm not only outperforms DA and its variants, but also outperforms eight state-of-the-art intelligent optimization algorithms on most functions and three real world problems. In addition, the proposed algorithm is applied to optimize kernel extreme learning machine (KELM) for traffic flow prediction, and the results show that the proposed model has a smaller prediction error than its peers.},
  archive      = {J_EAAI},
  author       = {Xiaojing Liu and Xiaolin Qin},
  doi          = {10.1016/j.engappai.2020.103922},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103922},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A probability-based core dandelion guided dandelion algorithm and application to traffic flow prediction},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-objective deep reinforcement learning framework.
<em>EAAI</em>, <em>96</em>, 103915. (<a
href="https://doi.org/10.1016/j.engappai.2020.103915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new scalable multi-objective deep reinforcement learning (MODRL) framework based on deep Q-networks. We develop a high-performance MODRL framework that supports both single-policy and multi-policy strategies, as well as both linear and non-linear approaches to action selection. The experimental results on two benchmark problems (two-objective deep sea treasure environment and three-objective Mountain Car problem) indicate that the proposed framework is able to find the Pareto-optimal solutions effectively. The proposed framework is generic and highly modularized, which allows the integration of different deep reinforcement learning algorithms in different complex problem domains. This therefore overcomes many disadvantages involved with standard multi-objective reinforcement learning methods in the current literature. The proposed framework acts as a testbed platform that accelerates the development of MODRL for solving increasingly complicated multi-objective problems.},
  archive      = {J_EAAI},
  author       = {Thanh Thi Nguyen and Ngoc Duy Nguyen and Peter Vamplew and Saeid Nahavandi and Richard Dazeley and Chee Peng Lim},
  doi          = {10.1016/j.engappai.2020.103915},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103915},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective deep reinforcement learning framework},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Architectural planning with shape grammars and reinforcement
learning: Habitability and energy efficiency. <em>EAAI</em>,
<em>96</em>, 103909. (<a
href="https://doi.org/10.1016/j.engappai.2020.103909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes the generation of sketches of small single-family dwellings that satisfy habitability requirements and are energy efficient. The proposed approach considers three stages in the generation process, and each one is based on a combination of shape grammars and reinforcement learning. First a set of very simple shape grammar rules is defined that are capable of generating a great variety of sketches. In order to guarantee the generation of sketches that are both suitable for habitation and energy efficient, a reinforcement learning process is applied on this set. Then the grammar so trained is used to generate only “good” sketches. More precisely, the learning process applies positive rewards to sketches that satisfy desired habitability and energy efficiency guidelines. As a result, sequences of grammar rules that lead to good sketches are identified. In this paper we present the general approach followed to develop the system and describe in detail the procedure applied in the reinforcement learning process. Experimental results are also presented, to show convergence of the learning process, and to compare the obtained results with those of real designs. A standard energy simulation program is used to validate the approach.},
  archive      = {J_EAAI},
  author       = {Lawrence Mandow and José-Luis Pérez-de-la-Cruz and Ana Belén Rodríguez-Gavilán and Manuela Ruiz-Montiel},
  doi          = {10.1016/j.engappai.2020.103909},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {103909},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Architectural planning with shape grammars and reinforcement learning: Habitability and energy efficiency},
  volume       = {96},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved population-based incremental learning of bayesian
networks with partly known structure and parallel computing.
<em>EAAI</em>, <em>95</em>, 103920. (<a
href="https://doi.org/10.1016/j.engappai.2020.103920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Network is a frequently-used model for fault detection and diagnosis in industrial processes. In this article, some modifications are made to Population-Based Incremental Learning and the improved algorithm is applied to structure learning of Bayesian networks. A pre-training step with K2 algorithm is added to the Population-Based Incremental Learning process to obtain an initial probability vector. Then, an elitist strategy is introduced into this method, providing a better way to update the probability vector. Individuals generated in every iteration, and elites in history are utilized to update the vector. The nature of this method makes it possible to learn the bayesian network whose structure is partly known, for sometimes we can specify some parts of the structure with prior process knowledge. A benchmark network Alarm and an industrial process are provided for performance evaluation and comparisons. Furthermore, we parallelize the algorithm to make it more efficient to learn Bayesian Networks. The speed of Improved Population-Based Incremental Learning has been improved significantly after parallelization.},
  archive      = {J_EAAI},
  author       = {Lingquan Zeng and Zhiqiang Ge},
  doi          = {10.1016/j.engappai.2020.103920},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103920},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved population-based incremental learning of bayesian networks with partly known structure and parallel computing},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Policy-based reinforcement learning for time series anomaly
detection. <em>EAAI</em>, <em>95</em>, 103919. (<a
href="https://doi.org/10.1016/j.engappai.2020.103919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection has become a crucial and challenging task driven by the rapid increase of streaming data with the arrival of the Internet of Things. Existing methods are either domain-specific or require strong assumptions that cannot be met in realistic datasets. Reinforcement learning (RL), as an incremental self-learning approach, could avoid the two issues well. However, the current investigation is far from comprehensive. In this paper, we propose a generic policy-based RL framework to address the time series anomaly detection problem. The policy-based time series anomaly detector (PTAD) is progressively learned from the interactions with time-series data in the absence of constraints. Experimental results show that it outperforms the value-based temporal anomaly detector and other state-of-the-art detection methods whether training and test datasets come from the same source or not. Furthermore, the tradeoff between precision and recall is well respected by the PTAD, which is beneficial to fulfill various industrial requirements.},
  archive      = {J_EAAI},
  author       = {Mengran Yu and Shiliang Sun},
  doi          = {10.1016/j.engappai.2020.103919},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103919},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Policy-based reinforcement learning for time series anomaly detection},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive review on type 2 fuzzy logic applications:
Past, present and future. <em>EAAI</em>, <em>95</em>, 103916. (<a
href="https://doi.org/10.1016/j.engappai.2020.103916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a concise overview of the work that has been done by various researchers in the area of type-2 fuzzy logic is analyzed and discussed. Type-2 fuzzy systems have been widely applied in the fields of intelligent control, pattern recognition and classification, among others. The overview mainly focuses on past, present and future trends of type-2 fuzzy logic applications. Of utmost importance is the last part, outlining possible areas of applied research in type-2 FL in the future. The major contribution of the paper is briefing of the most relevant work in the area of type-2 fuzzy logic, including its theoretical and practical implications. As well as envisioning possible future works and trends in this area of research. We believe that this paper will provide a good platform for people interested in this area for their future research work.},
  archive      = {J_EAAI},
  author       = {Kanika Mittal and Amita Jain and Kunwar Singh Vaisla and Oscar Castillo and Janusz Kacprzyk},
  doi          = {10.1016/j.engappai.2020.103916},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103916},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive review on type 2 fuzzy logic applications: Past, present and future},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep learning framework for text-independent writer
identification. <em>EAAI</em>, <em>95</em>, 103912. (<a
href="https://doi.org/10.1016/j.engappai.2020.103912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwriting Writer Identification (HWI) refers to the process of handwriting text image analysis to identify the authorship of the documents. It has yielded promising results in various applications, including digital forensics, criminal purposes, exploring the writer of historical documents, etc. The complexity of the text image, especially in images with various handwriting makes the writer identification difficult. In this work, we propose an end-to-end system that relies on a straightforward yet well-designed deep network and very efficient feature extraction, emphasizing feature engineering. Our system is an extended version of ResNet by conjugating deep residual networks and a new traditional yet high-quality handwriting descriptor towards handwriting analysis. Our descriptor analyzes the handwriting thickness as a preliminary and essential feature for human handwriting characteristics. Our approach can also provide text-independent writer identification that we do not need to have the same handwriting content for learning our model. The proposed approach is evaluated and achieved consistent results on four public and well-known datasets of IAM, Firemaker, CVL, and CERUG-EN. We empirically demonstrate that our conjugated network outperforms the original ResNet, and it can work well for real-world applications in which patches with few letters exist.},
  archive      = {J_EAAI},
  author       = {Malihe Javidi and Mahdi Jampour},
  doi          = {10.1016/j.engappai.2020.103912},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103912},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning framework for text-independent writer identification},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective ensembles of echo state networks and extreme
learning machines for streamflow series forecasting. <em>EAAI</em>,
<em>95</em>, 103910. (<a
href="https://doi.org/10.1016/j.engappai.2020.103910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Streamflow series forecasting composes a fundamental step in planning electric energy production for hydroelectric plants. In Brazil, such plants produce almost 70% of the total energy. Therefore, it is of great importance to improve the quality of streamflow series forecasting by investigating state-of-the-art time series forecasting algorithms. To this end, this work proposes the development of ensembles of unorganized machines, namely Extreme Learning Machines (ELMs) and Echo State Networks (ESNs). Two primary contributions are proposed: (1) a new training logic for ESNs that enables the application of bootstrap aggregation (bagging); and (2) the employment of multi-objective optimization to select and adjust the weights of the ensemble’s base models, taking into account the trade-off between bias and variance. Experiments are conducted on streamflow series data from five real-world Brazilian hydroelectric plants, namely those in Sobradinho , Serra da Mesa , Jiraú , Furnas and Água Vermelha . The statistical results for four different prediction horizons (1, 3, 6, and 12 months ahead) indicate that the ensembles of unorganized machines achieve better results than autoregressive (AR) models in terms of the Nash–Sutcliffe model efficiency coefficient (NSE), root mean squared error (RMSE), coefficient of determination (R 2 ), and RMSE-observations standard deviation ratio (RSR). In such results, the ensembles with ESNs and the multi-objective optimization design procedure achieve the best scores.},
  archive      = {J_EAAI},
  author       = {Victor Henrique Alves Ribeiro and Gilberto Reynoso-Meza and Hugo Valadares Siqueira},
  doi          = {10.1016/j.engappai.2020.103910},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103910},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective ensembles of echo state networks and extreme learning machines for streamflow series forecasting},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Background image-assisted divide-and-conquer reconstruction
method for ECT. <em>EAAI</em>, <em>95</em>, 103906. (<a
href="https://doi.org/10.1016/j.engappai.2020.103906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrical capacitance tomography (ECT) is a potential image-based measurement technology for monitoring time-varying industrial processes, but its applicability is challenged by low-quality images. To address this conundrum, a two-stage reconstruction (TSR) method with more effective priors and optimizer is presented in this work. In the first stage, the random vector functional link network (RVFLN) is developed to calculate a data-dependent background image, and a new distributed computing method is developed to achieve efficient training. To decrease the expensive computation load in the RVFLN training, the regularized projective nonnegative matrix factorization (RPNMF) method is developed to diminish the size of the sample data. A new optimization problem (OP) is proposed to model the RPNMF problem, which is solved by a new optimizer efficiently. In the second stage, a new OP that achieves the confluence of the domain knowledge-based prior related to imaging objects and the measurement physics is built, and a new divide-and-conquer optimizer is devised to solve the OP. To reduce the difficulty of parameter adjustment, the background image is used to initialize the proposed computing algorithm, and such treatment not only achieves the simultaneous fusion of the domain knowledge-based prior and the data-dependent prior but also decreases the computational difficulty. Numerical results show that the TSR algorithm is not only robust but also can achieve high precision reconstruction in comparison with popular imaging techniques.},
  archive      = {J_EAAI},
  author       = {J. Lei and Q.B. Liu},
  doi          = {10.1016/j.engappai.2020.103906},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103906},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Background image-assisted divide-and-conquer reconstruction method for ECT},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modified particle swarm optimization for multimodal
multi-objective optimization. <em>EAAI</em>, <em>95</em>, 103905. (<a
href="https://doi.org/10.1016/j.engappai.2020.103905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective evolutionary algorithm, particle swarm optimization (PSO) has been widely used to solve single or multi-objective optimization problems. However, the performance of PSO in solving multi-objective problems is unsatisfactory, so a variety of PSO has been proposed to enhance the performance of PSO on multi-objective optimization problems. In this paper, a modified particle swarm optimization (AMPSO) is proposed to solve the multimodal multi-objective problems. Firstly, a dynamic neighborhood-based learning strategy is introduced to replace the global learning strategy, which enhances the diversity of the population. Meanwhile, to enhance the performance of PSO, the offering competition mechanism is utilized. 11 multimodal multi-objective optimization functions are utilized to verify the feasibility and effectiveness of the proposed AMPSO. Experimental results and statistical analysis indicate that AMPSO has competitive performance compared with 5 state-of-the-art multimodal multi-objective algorithms.},
  archive      = {J_EAAI},
  author       = {XuWei Zhang and Hao Liu and LiangPing Tu},
  doi          = {10.1016/j.engappai.2020.103905},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103905},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modified particle swarm optimization for multimodal multi-objective optimization},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensor defense in-software (SDI): Practical software based
detection of spoofing attacks on position sensors. <em>EAAI</em>,
<em>95</em>, 103904. (<a
href="https://doi.org/10.1016/j.engappai.2020.103904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Position sensors, such as the gyroscope, the magnetometer and the accelerometer, are found in a staggering variety of devices, from smartphones and UAVs to autonomous robots. Several works have shown how adversaries can mount spoofing attacks to remotely corrupt or even completely control the outputs of these sensors. With more and more critical applications relying on sensor readings to make important decisions, defending sensors from these attacks is of prime importance. In this work we present practical software based defenses against attacks on two common types of position sensors, specifically the gyroscope and the magnetometer. We first characterize the sensitivity of these sensors to acoustic and magnetic adversaries. Next, we present two software-only defenses: a machine learning-based single sensor defense, and a sensor fusion defense which makes use of the mathematical relationship between the two sensors. We performed a detailed theoretical analysis of our defenses, and implemented them on a variety of smartphones, as well as on a resource-constrained IoT sensor node. Our defenses do not require any hardware or OS-level modifications, making it possible to use them with existing hardware. Moreover, they provide a high detection accuracy, a short detection time and a reasonable power consumption.},
  archive      = {J_EAAI},
  author       = {Kevin Sam Tharayil and Benyamin Farshteindiker and Shaked Eyal and Nir Hasidim and Roy Hershkovitz and Shani Houri and Ilia Yoffe Iofedov and Michal Oren and Yossi Oren},
  doi          = {10.1016/j.engappai.2020.103904},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103904},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sensor defense in-software (SDI): Practical software based detection of spoofing attacks on position sensors},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performing predefined tasks using the human–robot
interaction on speech recognition for an industrial robot.
<em>EAAI</em>, <em>95</em>, 103903. (<a
href="https://doi.org/10.1016/j.engappai.2020.103903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People who are not experts in robotics can easily implement complex robotic applications by using human–robot interaction (HRI). HRI systems require many complex operations such as robot control, image processing, natural speech recognition, and decision making. In this study, interactive control with an industrial robot was performed by using speech recognition software in the Turkish language. The collected voice data were converted to text data by using automatic speech recognition module based on deep neural networks (DNN). The proposed DNN (p-DNN) was compared to classic classification algorithms. Converted text data was improved in another module to select the process to be applied. According to selected process, position data were defined using image processing. The determined position information was sent to the robot using a fuzzy controller. The developed HRI system was implemented on a KUKA KR Agilus KR6 R900 sixx robot manipulator. The word accuracy rate of the p-DNN model was measured as 90.37%. The developed image processing module and fuzzy controller worked with minimal errors. The contribution of this study is that an industrial robot is easily programming using this software by people who are not experts in robotics and know Turkish.},
  archive      = {J_EAAI},
  author       = {Mustafa Can Bingol and Omur Aydogmus},
  doi          = {10.1016/j.engappai.2020.103903},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103903},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performing predefined tasks using the human–robot interaction on speech recognition for an industrial robot},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting customer satisfaction based on online reviews and
hybrid ensemble genetic programming algorithms. <em>EAAI</em>,
<em>95</em>, 103902. (<a
href="https://doi.org/10.1016/j.engappai.2020.103902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determination of the design attribute settings of a new product is essential for maximizing customer satisfaction. A model is necessary to illustrate the relation between the design attributes and dimensions of customer satisfaction such as product performance, affection and quality. The model is commonly developed based on customer survey data collected from questionnaires or interviews which require a long deployment time; hence the developed model cannot completely reflect the current marketplace. In this paper, a framework is proposed based on online reviews in which past and current customer opinions are included to develop the model. The proposed framework overcomes the limitation of the aforementioned approaches in which the developed models are not up-to-date. Indeed, the proposed framework develops models based on machine learning technologies, namely genetic programming, which has better generalization capabilities than classical approaches, and has higher transparency capabilities than implicit modelling approaches. To further enhance the prediction capability, committee member selection is proposed. The proposed selection method improves the currently used selection method which trains several models and only selects the best one. The proposed selection method generates a hybrid model which integrates the predictions of the generated models. Each prediction is weighted by how likely the prediction is agreed by others. The proposed framework is implemented on electric hair dryer design of which online reviews in amazon.com are used. Experimental results show that models with more accurate prediction capabilities can be generated by the proposed framework.},
  archive      = {J_EAAI},
  author       = {Kit Yan Chan and C.K. Kwong and Gül E. Kremer},
  doi          = {10.1016/j.engappai.2020.103902},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103902},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting customer satisfaction based on online reviews and hybrid ensemble genetic programming algorithms},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A lexicographic-based two-stage algorithm for vehicle
routing problem with simultaneous pickup–delivery and time window.
<em>EAAI</em>, <em>95</em>, 103901. (<a
href="https://doi.org/10.1016/j.engappai.2020.103901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing problem with simultaneous pickup–delivery and time window (VRPSPDTW) is computationally challenging as it generalizes the classical and NP-hard vehicle routing problem. According to the state-of-the-art, VRPSPDTW usually has two hierarchical optimization objectives: a primary objective of minimizing the number of vehicles (NV) and a secondary objective of reducing the transportation distance (TD). Given the existing research and our trial results, we find that the optimization of TD is not necessarily a promotion for reducing NV. In this paper, an effective learning-based two-stage algorithm, which has never been studied before, is proposed to solve the VRPSPDTW. In the first stage, a modified variable neighborhood search with a learning-based objective function is proposed to minimize the primary objective with retaining the potential structures. In the second stage, a bi-structure based tabu search (BSTS) is designed to optimize the primary and secondary objectives further. The experimental results on 93 benchmark instances demonstrate that the proposed algorithm performs remarkably well both in terms of computational efficiency and solution quality. In particular, the proposed two-stage algorithm improve several best known solutions (either a better NV or a better TD when NV are the same) from the state-of-the-art. To our knowledge, this is the first learning-based two-stage algorithm for solving VRPSPDTW reaching such a performance. Finally, we empirically analyze several critical components of the algorithm to highlight their impacts on the performance of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Yong Shi and Yanjie Zhou and Toufik Boudouh and Olivier Grunder},
  doi          = {10.1016/j.engappai.2020.103901},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103901},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lexicographic-based two-stage algorithm for vehicle routing problem with simultaneous pickup–delivery and time window},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial neural networks in microgrids: A review.
<em>EAAI</em>, <em>95</em>, 103894. (<a
href="https://doi.org/10.1016/j.engappai.2020.103894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work it is shown that artificial neural networks have certain characteristics that make them advantageous in the development of controllers in the different levels of control that microgrids must include to be economic, efficient and able to satisfy the energy power quality and quantity requirements. An objective of this paper is to bring attention to the promising applicability of artificial neural networks applied to the control of microgrid distributed generation sources, as well as in scheduling, power sharing, supervisory control and optimization.},
  archive      = {J_EAAI},
  author       = {Tania B. Lopez-Garcia and Alberto Coronado-Mendoza and José A. Domínguez-Navarro},
  doi          = {10.1016/j.engappai.2020.103894},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103894},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks in microgrids: A review},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective memetic algorithm for the generalized
bike-sharing rebalancing problem. <em>EAAI</em>, <em>95</em>, 103890.
(<a href="https://doi.org/10.1016/j.engappai.2020.103890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized bike-sharing rebalancing problem (BRP) entails driving a fleet of capacitated vehicles to rebalance bicycles among bike-sharing system stations at a minimum cost. To solve this NP-hard problem, we present a highly effective memetic algorithm that combines (i) a randomized greedy construction method for initial solution generation, (ii) a route-copy-based crossover operator for solution recombination, and (iii) an effective evolutionary local search for solution improvement integrating an adaptive randomized mutation procedure. Computational experiments on real-world benchmark instances indicate a remarkable performance of the proposed approach with an improvement in the best-known results (new upper bounds) in more than 46% of the cases. In terms of the computational efficiency, the proposed algorithm shows to be nearly two to six times faster when compared to the existing state-of-the-art heuristics. In addition to the generalized BRP, the algorithm can be easily adapted to solve the one-commodity pickup-and-delivery vehicle routing problem with distance constraints, as well as the multi-commodity many-to-many vehicle routing problem with simultaneous pickup and delivery.},
  archive      = {J_EAAI},
  author       = {Yongliang Lu and Una Benlic and Qinghua Wu},
  doi          = {10.1016/j.engappai.2020.103890},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103890},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective memetic algorithm for the generalized bike-sharing rebalancing problem},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TDIFS: Two dimensional intuitionistic fuzzy sets.
<em>EAAI</em>, <em>95</em>, 103882. (<a
href="https://doi.org/10.1016/j.engappai.2020.103882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy sets (IFS) are widely used in multi-attribute decision-making (MADM) because of its strong ability to express uncertainty in terms of membership degree, non-membership degree and hesitancy degree. Additionally, Z -number is a novel two-dimension framework to handle uncertainty problems by introducing the reliability of expert evaluation. However, a simple index in the framework of Z -number is not enough to express the evaluation of experts. In order to integrate the uncertainty and reliability expressions of IFS, inspired by Z -number, we propose a two-dimensional intuitionistic fuzzy set (TDIFS) model in this paper. In TDIFS model, the first dimensionality is the evaluation data from experts with regard to attributes, and the second dimensionality represents the reliability of expert in terms of the first component of TDIFS. Moreover, for each dimensionality, it is expressed as an ordered pair of intuitionistic fuzzy set, which can carry more information than a simple index. Furthermore, a novel combination rule is proposed for fusing TDIFSs. The TDIFS combination rule fully integrates expert evaluation and expert reliability, where it can reduce the uncertainty during combination process, so that more convincing results can be obtained. In addition, a new MADM method is proposed based on TDIFS model and TDIFS combination rule. Through comparing with the existing methods in an application of pattern recognition, it is demonstrated that the proposed MADM method is more effective, which can achieve higher robustness and better recognition results.},
  archive      = {J_EAAI},
  author       = {Yi Fan and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2020.103882},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103882},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TDIFS: Two dimensional intuitionistic fuzzy sets},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A highly robust automatic 3D reconstruction system based on
integrated optimization by point line features. <em>EAAI</em>,
<em>95</em>, 103879. (<a
href="https://doi.org/10.1016/j.engappai.2020.103879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current reconstruction systems often face the challenge of drifting when reconstructing complex scenes. Recent 3D(three-dimensional) reconstruction systems have shown convincing results, but still suffer from the following problems: (1) When the current vision-based 3D reconstruction system uses a single camera , the small angle of view of the camera is likely to cause the reconstructed 3D model to be incomplete. (2) Some image frames have fewer image feature points and image blurring, which leads to a larger deviation of the estimated camera pose value. (3) The current mainstream line feature 3D reconstruction system causes linearization and limits the update efficiency due to the adoption of the filter frame. In order to solve the above problems, this paper proposes a highly robust automatic 3D reconstruction system based on integrated optimization by point line features. Firstly, a multi-depth camera collaborative scanning method is developed to obtain a relatively complete 3D model. Secondly, a more accurate camera pose initial value can be obtained in advance without the position estimation. Thirdly, a comprehensive optimization method based on point line feature is used, which can improve the accuracy of camera pose and the consistency and accuracy of map construction. Many experiments show that the system can solve the problems of small viewing angle, blurred image and low modeling efficiency. The proposed system can be applied to 3D reconstruction of various complex large scenes. The obtained high-precision 3D model can be widely applied in the fields of human–computer interaction, virtual reality, etc.},
  archive      = {J_EAAI},
  author       = {Junyi Hou and Lei Yu and Shumin Fei},
  doi          = {10.1016/j.engappai.2020.103879},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103879},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A highly robust automatic 3D reconstruction system based on integrated optimization by point line features},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel methodology to classify test cases using natural
language processing and imbalanced learning. <em>EAAI</em>, <em>95</em>,
103878. (<a
href="https://doi.org/10.1016/j.engappai.2020.103878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting the dependency between integration test cases plays a vital role in the area of software test optimization. Classifying test cases into two main classes – dependent and independent – can be employed for several test optimization purposes such as parallel test execution, test automation, test case selection and prioritization, and test suite reduction. This task can be seen as an imbalanced classification problem due to the test cases’ distribution. Often the number of dependent and independent test cases is uneven, which is related to the testing level, testing environment and complexity of the system under test. In this study, we propose a novel methodology that consists of two main steps. Firstly, by using natural language processing we analyze the test cases’ specifications and turn them into a numeric vector. Secondly, by using the obtained data vectors, we classify each test case into a dependent or an independent class. We carry out a supervised learning approach using different methods for handling imbalanced datasets. The feasibility and possible generalization of the proposed methodology is evaluated in two industrial projects at Bombardier Transportation, Sweden, which indicates promising results.},
  archive      = {J_EAAI},
  author       = {Sahar Tahvili and Leo Hatvani and Enislay Ramentol and Rita Pimentel and Wasif Afzal and Francisco Herrera},
  doi          = {10.1016/j.engappai.2020.103878},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103878},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel methodology to classify test cases using natural language processing and imbalanced learning},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nucleus for bayesian partially observable markov games:
Joint observer and mechanism design. <em>EAAI</em>, <em>95</em>, 103876.
(<a href="https://doi.org/10.1016/j.engappai.2020.103876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An intelligent agent suggests an autonomous entity, which manages and learns actions to be taken towards achieving goals. The problem, reported as common knowledge in the literature in Artificial Intelligence (AI), is that it is a challenge to develop an approach able to compute efficient decisions that maximize the total reward of interacting agents upon an environment with unknown, incomplete, and uncertain information. To address these shortcomings, this paper provides a step forward: a nucleus for Bayesian Partially Observable Markov Games (BPOMGs) supported by an AI approach. Three fundamental topics conform the structure of the nucleus: game theory, learning and inference. First, we present a novel general Bayesian approach which is conceptualized for games that considered both, the incomplete information of the Bayesian model and the incomplete information over the states of the Markov system. In this new model, execution uncertainty is handled by using a Partially Observable Markov Game (POMG). Second, we extend the design theory, which now involves the mechanism design and the joint observer design (both unknown). The mechanism design results from the fact that agents act in their own individuals’ self-interest, and to induce agents to not reveal their private information and create a particular outcome. The joint observer design goal is related to represent the fact that agents may not be interested to provide accurate information of their states. In addition, agents follow a model that employs a Reinforcement Learning (RL) approach for estimating the transition matrices (also unknown) at each time step. Hence, as our final contribution, is an extended model of POMGs by introducing a new variable and proposing an analytical solution to compute both the observer design and the mechanism design (the two unknown). The proposed extension makes the game theory problem computationally tractable. We derive relations to recover analytically the variables of interest for each agent, i.e. observation kernels, joint observers, mechanism, strategies, and distribution vectors. The usefulness and effectiveness of the proposed nucleus is validated in simulation on a game-theoretic analysis of the patrolling problem designing the mechanism, computing the observers, and employing an RL approach.},
  archive      = {J_EAAI},
  author       = {Julio B. Clempner and Alexander S. Poznyak},
  doi          = {10.1016/j.engappai.2020.103876},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103876},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A nucleus for bayesian partially observable markov games: Joint observer and mechanism design},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new hybrid financial time series prediction model.
<em>EAAI</em>, <em>95</em>, 103873. (<a
href="https://doi.org/10.1016/j.engappai.2020.103873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the characteristics of financial time series, such as being non-linear, non-stationary and noisy, with uncertain and hidden relationships, it is difficult to capture its non-stationary state and to accurately describe its moving tendency. This is also a consequence of using a single approach to artificial intelligence, and other techniques that have been conventionally used. Therefore, those participating in financial markets, along with researchers, have paid a great deal of attention to tackling this problem. Hence, several approaches have been developed to alleviate the influence of inherent characteristics. However, the noise characteristic can refer to the unavailability of information, which affects how financial markets behave, as well as captured prices in both the past and the future. Therefore, the prediction of stock prices and detecting their noise is considered a very challenging financial topic. This paper adopts a novel three-step hybrid intelligent prediction model that combines a collection of intelligent modelling techniques and a feature extraction algorithm. At first, ensemble empirical mode decomposition is applied to the original data, as to facilitate model fitting to them. Then neural network and support vector regression is proposed individually for modelling the extracted features. Finally, a weighted ensemble average using a genetic algorithm to optimise and determine the weight is proposed for establishing a unified prediction. Experimental results are presented which illustrate the excellent performance of the proposed approach, and that is significantly outperforming the existing models, in terms of error criteria such as MSE, RMSE and MAE.},
  archive      = {J_EAAI},
  author       = {Bashar Alhnaity and Maysam Abbod},
  doi          = {10.1016/j.engappai.2020.103873},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103873},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new hybrid financial time series prediction model},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Basic uncertain information soft set and its application to
multi-criteria group decision making. <em>EAAI</em>, <em>95</em>,
103871. (<a
href="https://doi.org/10.1016/j.engappai.2020.103871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to develop a novel type of soft set called basic uncertain information soft set (BUISS), which combines the notion of basic uncertain information and soft set theory. Since basic uncertain information can measure the quality of datum by using the degree of certainty, the developed BUISS provides a novel extension of soft set. In this paper, set operations and comparison law of basic uncertain information are also developed. Then, operations on BUISSs include set operations, ’AND’ operation and ’OR’ operation are defined. Besides, the Jaccard similarity between two BUISSs is introduced. The properties of the operations and similarity measure are studied. Theoretically, a multi-criteria group decision making (MAGDM) problem under basic uncertain information environment is analysed by using BUISSs. Two decision algorithms based on level BUISS and the aggregation of ϵ -approximate elements are proposed. Finally, an assessment of natural gas security in China is investigated to illustrate the feasibility and validity of the developed decision approaches.},
  archive      = {J_EAAI},
  author       = {Zhifu Tao and Ziyue Shao and Jinpei Liu and Ligang Zhou and Huayou Chen},
  doi          = {10.1016/j.engappai.2020.103871},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103871},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Basic uncertain information soft set and its application to multi-criteria group decision making},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reinforcement learning for quadrupedal locomotion with
design of continual–hierarchical curriculum. <em>EAAI</em>, <em>95</em>,
103869. (<a
href="https://doi.org/10.1016/j.engappai.2020.103869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end reinforcement learning is a promising approach to enable robots to acquire complicated skills. However, this requires numerous samples to be implemented successfully. The issue is that it is often difficult to collect the sufficient number of samples. To accelerate learning in the field of robotics, knowledge gathered from robotics engineering and previously learned tasks must be fully exploited. Specifically, we propose using a sample-efficient curriculum to establish quadrupedal robot control in which the walking and turning tasks are divided into two hierarchical layers, and a robot learns them incrementally from lower to upper layers. To develop such a curriculum, two core components are designed. First the fractal design of neural networks in reservoir computing is aimed at allocating the tasks to be learned to respective modules in fractal networks. This allows mitigating the problem of catastrophic forgetting in neural networks and achieves the capability of continuous learning. The second task includes hierarchical task decomposition according to robotics knowledge for controlling legged robots. Owing to the combination of these two components, the proposed curriculum enables a robot to tune the lower layer even when the upper layer is optimized. As a result of implementing the proposed design, we confirm that a quadrupedal robot in a dynamical simulator succeeds in learning skills hierarchically according to the given curriculum, starting from moving legs and finally, walking/turning, unlike the considered conventional curriculums that are unable to achieve such results.},
  archive      = {J_EAAI},
  author       = {Taisuke Kobayashi and Toshiki Sugino},
  doi          = {10.1016/j.engappai.2020.103869},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103869},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning for quadrupedal locomotion with design of continual–hierarchical curriculum},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-modal recognition of worker activity for
human-centered intelligent manufacturing. <em>EAAI</em>, <em>95</em>,
103868. (<a
href="https://doi.org/10.1016/j.engappai.2020.103868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims at sensing and understanding the worker’s activity in a human-centered intelligent manufacturing system. We propose a novel multi-modal approach for worker activity recognition by leveraging information from different sensors and in different modalities. Specifically, a smart armband and a visual camera are applied to capture Inertial Measurement Unit (IMU) signals and videos, respectively. For the IMU signals, we design two novel feature transform mechanisms, in both frequency and spatial domains, to assemble the captured IMU signals as images, which allow using convolutional neural networks to learn the most discriminative features. Along with the above two modalities, we propose two other modalities for the video data, i.e., at the video frame and video clip levels. Each of the four modalities returns a probability distribution on activity prediction. Then, these probability distributions are fused to output the worker activity classification result. A worker activity dataset is established, which at present contains 6 common activities in assembly tasks, i.e., grab a tool/part, hammer a nail, use a power-screwdriver, rest arms, turn a screwdriver, and use a wrench. The developed multi-modal approach is evaluated on this dataset and achieves recognition accuracies as high as 97% and 100% in the leave-one-out and half-half experiments, respectively.},
  archive      = {J_EAAI},
  author       = {Wenjin Tao and Ming C. Leu and Zhaozheng Yin},
  doi          = {10.1016/j.engappai.2020.103868},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103868},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-modal recognition of worker activity for human-centered intelligent manufacturing},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regulated kalman filter based training of an interval type-2
fuzzy system and its evaluation. <em>EAAI</em>, <em>95</em>, 103867. (<a
href="https://doi.org/10.1016/j.engappai.2020.103867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most industrial systems are non-linear and prone to different sources of uncertainties. Accordingly, data generated by these systems for their model development can contain noise and outliers, which consecutively affect the approximation accuracy of their models. Hence, there is a need to use robust approaches, such as fuzzy systems. The type-2 fuzzy system is characterized by a foot print of uncertainty (FOU), which enables it to handle the impreciseness in non-linear systems. In this paper, a strategy for optimizing the membership function (MF) parameters of an interval type-2 fuzzy system using the Kalman gain and error covariance of its constant consequent parameter is presented. In the proposed strategy, the MF parameters are not a part of the input to the extended Kalman filter (EKF) algorithm, which reduces the computational cost of optimization. The proposed strategy was used to identify a robot hand path, Mackey–Glass Chaotic Series, dynamic system, and the inverse kinematics of a 6-PSS parallel robot. The proposed strategy was compared with an interval type-2 fuzzy system having only the consequent parameters being optimized by the extended Kalman filter (KFT2FS). The performance characteristic considered was the root mean square error between the desired output and the model output. The comparison results showed that the proposed model outperformed the KFT2FS, with an improved performance of 85%, 15.7%, 11.25%, and 3.6% for the robot hand path, Mackey–Glass Chaotic Series, dynamic system, and 6-PSS parallel robot respectively and also 7.3%, 17.5%, and 37.1% for 20 dB, 15 dB, and 10 dB corrupted 6-PSS parallel robot data respectively.},
  archive      = {J_EAAI},
  author       = {Ahmed Abdul Ibrahim and Hai-bo Zhou and Shuai-xia Tan and Chao-long Zhang and Ji-an Duan},
  doi          = {10.1016/j.engappai.2020.103867},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103867},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Regulated kalman filter based training of an interval type-2 fuzzy system and its evaluation},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel grey riccati–bernoulli model and its application for
the clean energy consumption prediction. <em>EAAI</em>, <em>95</em>,
103863. (<a
href="https://doi.org/10.1016/j.engappai.2020.103863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting energy demand can better predict future changes in energy demand. This study is aimed to develop more accurate clean energy prediction model from two perspectives of the modeling mechanisms and improvements on the model structure. For this purpose, a novel Riccati–Bernoulli differential equation is established through social practice theory, supply–demand relationship, and the preference of consumption in the energy economy. Considering the limited information in observation data, this differential equation is then transformed into a grey Riccati–Bernoulli model (GRBM(1,1)) according to the differential information principle. With the response function solved on the basis of polynomial equation theory and the power exponent optimized combining the modified flower pollination algorithm, the main process of GRBM(1,1) can be summarized. The four validation examples are provided for confirming the effectiveness and reliability of the new model by comparing with other existing models. Finally, the proposed model is employed to estimate and forecast the clean energy consumption in China and India. The results show that the proposed model demonstrates better estimation in all cases and efficiency in short-term clean energy consumption forecasting. Therefore, by using this optimum model, China’s preference coefficient in total energy consumption is 0.7103, lower than that of India (0.8799), and China’s preference coefficient in clean energy consumption is 0.9665, higher than that of Indian (0.7155), which means China has less interest to increase total energy consumption but more interest in popularizing the clean energy.},
  archive      = {J_EAAI},
  author       = {Qinzi Xiao and Mingyun Gao and Xinping Xiao and Mark Goh},
  doi          = {10.1016/j.engappai.2020.103863},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103863},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel grey Riccati–Bernoulli model and its application for the clean energy consumption prediction},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Declarative and mathematical programming approaches to
decision support systems for food recycling. <em>EAAI</em>, <em>95</em>,
103861. (<a
href="https://doi.org/10.1016/j.engappai.2020.103861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every year about one third of the food production intended for humans gets lost or wasted. This wastefulness of resources leads to the emission of unnecessary greenhouse gas, contributing to global warming and climate change. The solution proposed by the SORT project is to “recycle” the surplus of food by reconditioning it into animal feed or fuel for biogas/biomass power plants. In order to maximize the earnings and minimize the costs, several choices must be made during the reconditioning process. Given the extremely complex nature of the process, Decision Support Systems (DSSs) could be helpful to reduce the human effort in decision making. In this paper, we present a DSS for food recycling developed using two approaches for finding the optimal solution: one based on Binary Linear Programming (BLP) and the other based on Answer Set Programming (ASP), which outperform our previous approach based on Constraint Logic Programming (CLP) on Finite Domains (CLP(FD)). In particular, the BLP and the CLP(FD) approaches are developed in ECL i PS e , a Prolog system that interfaces with various state-of-the-art Mathematical and Constraint Programming solvers. The ASP approach, instead, is developed in clingo . The three approaches are compared on several synthetic datasets that simulate the operative conditions of the DSS.},
  archive      = {J_EAAI},
  author       = {Federico Chesani and Giuseppe Cota and Marco Gavanelli and Evelina Lamma and Paola Mello and Fabrizio Riguzzi},
  doi          = {10.1016/j.engappai.2020.103861},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103861},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Declarative and mathematical programming approaches to decision support systems for food recycling},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensor-based activity recognition of solitary elderly via
stigmergy and two-layer framework. <em>EAAI</em>, <em>95</em>, 103859.
(<a href="https://doi.org/10.1016/j.engappai.2020.103859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the acceleration of aging process of population structure, the single resident lifestyle is increasing on account of the high cost of care services and the privacy invasion concern. It is essential to monitor the activities of solitary elderly to find the emergency and lifestyle deviation, as independent life cannot be maintained due to physical or mental problems. The unobtrusive systems are the most preferred choice for the real-life long-term monitoring, while the camera and wearable devices based systems are not suitable due to the privacy and uncomfortableness, respectively. We propose a novel sensor-based activity recognition model based on the two-layer multi-granularity framework and the emergent paradigm with marker-based stigmergy. The stigmergy based marking subsystem builds features by aggregating the context-aware information and generating the two-dimensional activity pheromone trail. The two-layer framework consists of coarse-grained and fine-grained classification subsystems. The coarse-grained subsystem identifies whether the input completed activity segmented by the traditional method is easily-confused, and utilizes our generalized segmentation method to increase the inter-cluster distance. The fine-grained subsystem employs machine learning or deep learning classifiers to realize the activity recognition task. The proposed model is a data-driven model based on the information self-organization. It does not need sophisticated domain knowledge, and can fully mine the hidden feature structure containing semantically related information and spatio-temporal characteristics. The experimental results demonstrate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Zimin Xu and Guoli Wang and Xuemei Guo},
  doi          = {10.1016/j.engappai.2020.103859},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103859},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Sensor-based activity recognition of solitary elderly via stigmergy and two-layer framework},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Space–time series clustering: Algorithms, taxonomy, and case
study on urban smart cities. <em>EAAI</em>, <em>95</em>, 103857. (<a
href="https://doi.org/10.1016/j.engappai.2020.103857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a short overview of space–time series clustering, which can be generally grouped into three main categories such as: hierarchical, partitioning-based, and overlapping clustering. The first hierarchical category is to identify hierarchies in space–time series data. The second partitioning-based category focuses on determining disjoint partitions among the space–time series data, whereas the third overlapping category explores fuzzy logic to determine the different correlations between the space–time series clusters. We also further describe solutions for each category in this paper. Furthermore, we show the applications of these solutions in an urban traffic data captured on two urban smart cities (e.g., Odense in Denmark and Beijing in China). The perspectives on open questions and research challenges are also mentioned and discussed that allow to obtain a better understanding of the intuition, limitations, and benefits for the various space–time series clustering methods. This work can thus provide the guidances to practitioners for selecting the most suitable methods for their used cases, domains, and applications.},
  archive      = {J_EAAI},
  author       = {Asma Belhadi and Youcef Djenouri and Kjetil Nørvåg and Heri Ramampiaro and Florent Masseglia and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.engappai.2020.103857},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103857},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Space–time series clustering: Algorithms, taxonomy, and case study on urban smart cities},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved failure mode and effect analysis with
interval-valued intuitionistic fuzzy rough number theory. <em>EAAI</em>,
<em>95</em>, 103856. (<a
href="https://doi.org/10.1016/j.engappai.2020.103856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA) is a prospective risk analysis instrument applied in various fields for eliminating known or potential failures in products. However, conventional FMEA has suffered from plenty of criticisms that limit its effectiveness. Due to fuzzy and imprecise information often exist in risk assessments, numerous modified FMEA methods based on fuzzy theory are employed to improve the classical FMEA. However, the previous fuzzy-based FMEA approaches still have some drawbacks, e.g., requisition of extra information, no ability in handling hesitation of individual and subjectivity of group simultaneously, consideration of only three risk elements, and deeming the experts’ judgments are rational among most of them. Hence, this paper develops a novel concept of interval-valued intuitionistic fuzzy rough number (IVIFRN) by utilizing the merit of interval-valued intuitionistic fuzzy set in handling fuzziness and hesitation of individuals’ judgments and the benefit of rough number in manipulating imprecision and subjectivity of group’s assessments and presents a new FMEA model based on IVIFRN. Then, maintenance is regarded as a new risk aspect and to further establish a risk evaluation structure containing eight risk elements. Moreover, the experts’ bounded rationality and risk elements’ importance are determined by two synthetic weighting methods considering both subjective and objective information. Finally, a real case is performed to illustrate the effectiveness of the developed model.},
  archive      = {J_EAAI},
  author       = {Guangquan Huang and Liming Xiao and Genbao Zhang},
  doi          = {10.1016/j.engappai.2020.103856},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103856},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved failure mode and effect analysis with interval-valued intuitionistic fuzzy rough number theory},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised feature selection based on adaptive similarity
learning and subspace clustering. <em>EAAI</em>, <em>95</em>, 103855.
(<a href="https://doi.org/10.1016/j.engappai.2020.103855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection methods have an important role on the readability of data and the reduction of complexity of learning algorithms. In recent years, a variety of efforts are investigated on feature selection problems based on unsupervised viewpoint due to the laborious labeling task on large datasets. In this paper, we propose a novel approach on unsupervised feature selection initiated from the subspace clustering to preserve the similarities by representation learning of low dimensional subspaces among the samples. A self-expressive model is employed to implicitly learn the cluster similarities in an adaptive manner. The proposed method not only maintains the sample similarities through subspace clustering, but it also considers the underlying structure of data based on a regularized regression model. In line with the convergence analysis of the proposed method, the experimental results on benchmark datasets demonstrate the effectiveness of our approach as compared with the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Mohsen Ghassemi Parsa and Hadi Zare and Mehdi Ghatee},
  doi          = {10.1016/j.engappai.2020.103855},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103855},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised feature selection based on adaptive similarity learning and subspace clustering},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel integrated price and load forecasting method in
smart grid environment based on multi-level structure. <em>EAAI</em>,
<em>95</em>, 103852. (<a
href="https://doi.org/10.1016/j.engappai.2020.103852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of load and price are two critical key in power system planning and operation. Most of the recent works in this area forecast the load and price signals separately but, a dynamic model in smart grid is evaluated while, the customers may have opportunity to react the proposed prices changing through shifting the electricity usages from expensive to cheaper hours. So, the load and price signals are coupled strongly which made the previous prediction models ineffective. In this research, a synthetic prediction approach has been proposed by considering the load and price signals, simultaneously. This method works as multi-input multi-output (MIMO) model based on least square support vector machine (LSSVM) forecast engine. Furthermore, a dyadic wavelet transform (DWT) is suggested in this approach to decompose the original signal into different small sub-signals. Beside of that, the modified mutual information (MMI) filter has been used to choose the best candidate input of forecast engine. The learning section is also coupled with novel modified optimization algorithm based on gravitational search algorithm (GSA) which called as modified GSA (MGSA). Finally, various forecasting errors have been considered as average mean absolute percentage error and error variance to get the comparison outcomes and performance of forecasting approaches. For this purpose, different markets have been considered as test case to show the efficiency of suggested approach.},
  archive      = {J_EAAI},
  author       = {Yang Zhang and Caibo Deng and Ran Zhao and Sebastian leto},
  doi          = {10.1016/j.engappai.2020.103852},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103852},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel integrated price and load forecasting method in smart grid environment based on multi-level structure},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Remaining useful life estimation with multiple local
similarities. <em>EAAI</em>, <em>95</em>, 103849. (<a
href="https://doi.org/10.1016/j.engappai.2020.103849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In prognostics and health management (PHM), remaining useful life (RUL) estimation has become a major focus for guaranteeing the safety and reliability of systems. Similarity-based RUL estimation methods, which predict a system’s RUL based on the RULs of other systems with similar degradation behaviors, have been proven effective when no or limited mechanism knowledge is available. Global similarity-based approaches apply the whole-life history to find similar degradation patterns and may lead to few or even no candidates. In contrast, local similarity-based methods only utilize the data close to the prediction time, and then, false positives are inevitable. A given system may have experienced several events before being tested for RUL, and each event may impact its RUL. Systems that have undergone similar events will probably degrade similarly in the future. Hence, the past events must be effectively identified and fully utilized. This paper proposes estimating a system’s RUL by using multiple impacts from its past. The system’s history is transformed into a set of local segments by which the degradation events are represented. Then, a coarse-to-fine strategy is introduced to efficiently locate the events similar to the test. The most similar segments are regarded as references, and their corresponding RULs are a natural data basis for RUL estimation. Since segments may correspond to different features, we adopt two adjustment strategies to make reference RULs more applicable. A self-adaptive weight allocation method is also proposed to further improve the prediction performance. The experimental results show the effectiveness and advantages of our proposed method.},
  archive      = {J_EAAI},
  author       = {Jianhua Lyu and Rongrong Ying and Ningyun Lu and Baili Zhang},
  doi          = {10.1016/j.engappai.2020.103849},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103849},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Remaining useful life estimation with multiple local similarities},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy mutation embedded hybrids of gravitational search and
particle swarm optimization methods for engineering design problems.
<em>EAAI</em>, <em>95</em>, 103847. (<a
href="https://doi.org/10.1016/j.engappai.2020.103847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gravitational Search Algorithm (GSA) and Particle Swarm Optimization (PSO) are nature-inspired, swarm-based optimization algorithms respectively. Though they have been widely used for single-objective optimization since their inception, they suffer from premature convergence. Even though the hybrids of GSA and PSO perform much better, the problem remains. Hence, to solve this issue, we have proposed a fuzzy mutation model for two hybrid versions of PSO and GSA — Gravitational Particle Swarm (GPS) and PSOGSA. The developed algorithms are called Mutation based GPS (MGPS) and Mutation based PSOGSA (MPSOGSA). The mutation operator is based on a fuzzy model where the probability of mutation has been calculated based on the closeness of particle to population centroid and improvement in the particle value. We have evaluated these two new algorithms on 23 benchmark functions of three categories (unimodal, multimodal and multimodal with fixed dimension). The experimental outcome shows that our proposed model outperforms their corresponding ancestors, MGPS outperforms GPS 13 out of 23 times (56.52%) and MPSOGSA outperforms PSOGSA 17 times out of 23 (73.91%). We have also compared our results against those of some recently proposed optimization algorithms such as Sine Cosine Algorithm (SCA), Opposition-Based SCA, and Volleyball Premier League Algorithm (VPL). In addition, we have applied our proposed algorithms on some classic engineering design problems and the outcomes are satisfactory. The related codes of the proposed algorithms can be found in this link: Fuzzy-Mutation-Embedded-Hybrids-of-GSA-and-PSO .},
  archive      = {J_EAAI},
  author       = {Devroop Kar and Manosij Ghosh and Ritam Guha and Ram Sarkar and Laura Garcia-Hernandez and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103847},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103847},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy mutation embedded hybrids of gravitational search and particle swarm optimization methods for engineering design problems},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modified incremental gravitational search algorithm for
short-term hydrothermal scheduling with variable head. <em>EAAI</em>,
<em>95</em>, 103845. (<a
href="https://doi.org/10.1016/j.engappai.2020.103845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the solution of short-term hydrothermal coordination problem (STHCP) with variable head was performed. In the manuscript, incremental gravitational search algorithm (IGSA) which was developed as a new method has been applied to two different power problems. One of the systems used as an example is a variable head STHCP which has previously been solved in the literature by neglecting transmission line losses. The second is a lossy system designed as a variable head STHCP, with the purpose of contributing to the literature. In the lossy system, Newton–Raphson AC power flow method was used to calculate transmission line losses. Possible electrical and hydraulic constraints in the solution of the problem were satisfied using the penalty function method. The results obtained from the solutions of the sample systems were compared and discussed.},
  archive      = {J_EAAI},
  author       = {Celal Yaşar and Serdar Özyön},
  doi          = {10.1016/j.engappai.2020.103845},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103845},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A modified incremental gravitational search algorithm for short-term hydrothermal scheduling with variable head},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Metaheuristic algorithms with solution encoding mixing for
effective optimization of SDM optical networks. <em>EAAI</em>,
<em>95</em>, 103843. (<a
href="https://doi.org/10.1016/j.engappai.2020.103843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the continuous growth of Internet traffic, new technologies are proposed to overcome the capacity crunch problem. One of the most promising solutions for optical backbone networks is space division multiplexing (SDM), which allows parallel transmissions in properly designed optical fibers. In SDM, the problem of routing, space, and spectrum allocation (RSSA) emerges. RSSA is more challenging than corresponding optimization problems in optical networks without spatial multiplexing since the additional spatial dimension significantly increases the number of encodable solutions. The exact optimization methods can be used only for small and unrealistic problem instances. Therefore, effective metaheuristics are needed to solve RSSA for larger and practice-based problem instances. In this paper, we propose a new technique of solution encoding in metaheuristic algorithms. The key novelty and contribution is to mix two different solution encoding types to utilize their advantages and improve the overall method performance. The results of experiments conducted on reference optical network topologies using two representative optimization methods (dedicated evolutionary algorithm and tabu search) show that the proposed approach significantly improves the quality of the results for both method types. The proposed encoding technique is generic and applicable to many different metaheuristics employed in solving various optimization problems.},
  archive      = {J_EAAI},
  author       = {Michal Witold Przewozniczek and Róża Goścień and Piotr Lechowicz and Krzysztof Walkowiak},
  doi          = {10.1016/j.engappai.2020.103843},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103843},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Metaheuristic algorithms with solution encoding mixing for effective optimization of SDM optical networks},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization framework and clustering-based algorithm for
energy-aware adaptive sensing. <em>EAAI</em>, <em>95</em>, 103841. (<a
href="https://doi.org/10.1016/j.engappai.2020.103841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of controlling the operation of the multiple sensors in a monitoring network is one of jointly optimizing for both information requirements and energy constraints. These goals conflict with each other — increasing the sampling rate collects more data but this consumes energy and hence reduces system lifetime. On the other hand, sampling at a higher rate when the environment is not changing does not generate more useful information. This work presents a general data-centric framework for adaptive sensing that brings together both information requirements and energy constraints in an optimization problem for generating sensor control actions. Clustering of correlated sensors is proposed as a solution for this framework where the collected data is periodically used to learn the relationship between sensors and energy parameters. Control is divided into periods of full sensing and periods of approximation. During periods of full sensing, measurements collected from all sensors are used to compute pair-wise correlations which are then used as the distance metric for clustering. A regression function is learned to approximate the measurement of a sensor given its past sensor measurements and the measurements of another sensor in the cluster. The control framework is evaluated using a publicly-available dataset of approximately 2.4 million sensor readings collected from 54 sensors over a period of approximately 35 days. The parameter space of the clustering-based adaptive sensing policy is systematically explored using this dataset. The framework enables a point on the energy-information trade-off curve to be quantified for different choices of policy parameters.},
  archive      = {J_EAAI},
  author       = {Mohammadreza Hajy Heydary and Anand Panangadan},
  doi          = {10.1016/j.engappai.2020.103841},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103841},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization framework and clustering-based algorithm for energy-aware adaptive sensing},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computation offloading in edge computing environments using
artificial intelligence techniques. <em>EAAI</em>, <em>95</em>, 103840.
(<a href="https://doi.org/10.1016/j.engappai.2020.103840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge Computing (EC) is a recent architectural paradigm that brings computation close to end-users with the aim of reducing latency and bandwidth bottlenecks, which 5G technologies are committed to further reduce, while also achieving higher reliability. EC enables computation offloading from end devices to edge nodes. Deciding whether a task should be offloaded, or not, is not trivial. Moreover, deciding when and where to offload a task makes things even harder and making inadequate or off-time decisions can undermine the EC approach. Recently, Artificial Intelligence (AI) techniques, such as Machine Learning (ML), have been used to help EC systems cope with this problem. AI promises accurate decisions, higher adaptability and portability, thus diminishing the cost of decision-making and the probability of error. In this work, we perform a literature review on computation offloading in EC systems with and without AI techniques. We analyze several AI techniques, especially ML-based, that display promising results, overcoming the shortcomings of current approaches for computing offloading coordination We sorted the ML algorithms into classes for better analysis and provide an in-depth analysis on the use of AI for offloading, in particular, in the use case of offloading in Vehicular Edge Computing Networks, actually one technology that gained more relevance in the last years, enabling a vast amount of solutions for computation and data offloading. We also discuss the main advantages and limitations of offloading, with and without the use of AI techniques.},
  archive      = {J_EAAI},
  author       = {Gonçalo Carvalho and Bruno Cabral and Vasco Pereira and Jorge Bernardino},
  doi          = {10.1016/j.engappai.2020.103840},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103840},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computation offloading in edge computing environments using artificial intelligence techniques},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient deep discriminant embedding: Application to face
beauty prediction and classification. <em>EAAI</em>, <em>95</em>,
103831. (<a
href="https://doi.org/10.1016/j.engappai.2020.103831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by deep learning architectures, we introduce a multi-layer local discriminant embedding algorithm that integrates feature selection as a main step to capture the most relevant and discriminant features of an input face image or face descriptor. The proposed framework allows to transform any linear method to a deep variant via a cascaded feature extraction and selection architecture able to convert weak and noisy descriptors to strong ones. As a case study, the local discriminant embedding (LDE) projection is adopted as a linear feature extraction method. The resulting framework can be considered as an efficient deep discriminant embedding technique. To validate this framework, we have considered two different computer vision problems: face beauty prediction which involves both classification and regression tasks, and face recognition which is a classical classification problem. Experiments conducted on different public benchmark databases show that this approach enhances the performance of the LDE algorithm and provides a discriminating strategy to solve the dimensionality reduction problem. For face beauty regression, our proposed framework achieved on average an improvement of about 5% and 7% with respect to two other configurations where only VGG-face and VGG-face followed by LDE have been considered. For face beauty classification, the proposed algorithm outperformed many classical manifold learning techniques reaching in some databases improvements of about 10%.},
  archive      = {J_EAAI},
  author       = {F. Dornaika and A. Moujahid and K. Wang and X. Feng},
  doi          = {10.1016/j.engappai.2020.103831},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103831},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient deep discriminant embedding: Application to face beauty prediction and classification},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust modelling of binary decisions in laplacian
eigenmaps-based echo state networks. <em>EAAI</em>, <em>95</em>, 103828.
(<a href="https://doi.org/10.1016/j.engappai.2020.103828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to present a framework for supervised binary classification of n -Boolean functions through Echo State Networks endowed with Laplacian Eigenmaps for dimensionality reduction. The proposed method is applied both to improve the classification performance when the learnt weights are quantised in view of a digital implementation and as a computational demonstration of the neural reuse theory when parallel outputs are allowed. Our analysis focuses on the effect of various forms of noise (i.e., normal noise, uniform noise and quantisation noise) when all the possible Boolean functions of n input bits are learnt. External disturbances are applied both over the learnt weights and the input features so that we can analyse how resilient the whole architecture is when various forms of parametric noise is injected into the system. Results presented here show that dimensionality reduction allowed by the Laplacian Eigenmaps-based approach improves robustness to these different sources of noise, leading to reduced memory storage requirements while maintaining high classification performance. Our results are compared to those derived from other more common classification techniques in terms of learning performance and computational complexity, also considering a realistic dataset describing a decision making task in a wall-following navigation session with mobile robots.},
  archive      = {J_EAAI},
  author       = {Paolo Arena and Luca Patanè and Angelo Giuseppe Spinosa},
  doi          = {10.1016/j.engappai.2020.103828},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103828},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust modelling of binary decisions in laplacian eigenmaps-based echo state networks},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discretization of hybrid CPPS data into timed automaton
using restricted boltzmann machines. <em>EAAI</em>, <em>95</em>, 103826.
(<a href="https://doi.org/10.1016/j.engappai.2020.103826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber–Physical Production Systems (CPPSs) are hybrid systems composed of a discrete and continuous part. However, most of the applied machine learning algorithms handle the dynamics of the two parts separately and in different fashions: for the discrete part, the notion of discrete events (and their timings) is essential (e.g. when learning automata or rules), while the dynamics of the continuous part is often defined by differential equations or time-series models. Reconciling the different nature of the two is a major challenge for machine learning. One solution is to express continuous behavior in discrete terms, i.e. the explicit events are extracted. Then, at the cost of information loss caused by discretization, the overall behavior can be jointly analyzed. This paper proposes a novel machine learning discretization approach called DENTA ( Deep Network Timed Automaton ) which solves the aforementioned challenges through the construction of an (overall) deterministic timed automaton from the original hybrid data. First, it hierarchically extracts new features from the continuous data using a deep network of stacked restricted Boltzmann machines (RBMs). We show that high-level RBM abstractions can further be used to automatically detect meaningful discrete events in continuous system behavior. Finally, a discrete representation of overall system behavior in the form of a timed automaton is created, which allows a joint timing analysis of the whole system. The model is verified by the anomaly detection on a synthetic and a real-world dataset and the results show clear advantages of the approach for a specific class of systems.},
  archive      = {J_EAAI},
  author       = {Nemanja Hranisavljevic and Alexander Maier and Oliver Niggemann},
  doi          = {10.1016/j.engappai.2020.103826},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103826},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discretization of hybrid CPPS data into timed automaton using restricted boltzmann machines},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data-driven method for detecting and diagnosing causes of
water quality contamination in a dataset with a high rate of missing
values. <em>EAAI</em>, <em>95</em>, 103822. (<a
href="https://doi.org/10.1016/j.engappai.2020.103822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Democratization of sensing devices in industrial systems has made it possible to collect a large amount of data of different types, which has led to the necessity of handling complex analyses for knowledge extraction. The field of water resources is of those areas which has drawn the attention of decision-makers seeking to preserve human health and safety. Recent advances in Artificial Intelligence, particularly in the domain of Machine Learning, have opened the potential to leverage massive data to better address the issue related to the relationship between water quality and human activities. However, high rate of missing data and heterogeneity of the measurements are scientific issues that cannot be solved by standard methods, especially when no prior knowledge on the label of each observation is provided. In this article, Prognostics and Health Management was implemented to detect and diagnose anomalies in water quality datasets, taking into account the uncertainties induced by the above-mentioned issues. Fuzzy c-means was used to identify the different water quality classes, while Random Forest was applied to determine the most influencing parameters, with respect to potential contamination of water resources in the southwest of France. The results suggest that multiple imputation methods can handle the missingness issue, while the use of decision rules based on well-known water quality standards can solve the problem regarding the lack of labelled observations. In addition, two potential sources of contamination (atrazine and nitrate) were identified and then validated by hydrogeology experts, prior to further online deployment of the proposed model.},
  archive      = {J_EAAI},
  author       = {Raymond Houé Ngouna and Romy Ratolojanahary and Kamal Medjaher and Fabien Dauriac and Mathieu Sebilo and Jean Junca-Bourié},
  doi          = {10.1016/j.engappai.2020.103822},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103822},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-driven method for detecting and diagnosing causes of water quality contamination in a dataset with a high rate of missing values},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new interval type-2 fuzzy approach for multi-scenario
project cash flow assessment based on alternative queuing method and
dependency structure matrix with a case study. <em>EAAI</em>,
<em>95</em>, 103815. (<a
href="https://doi.org/10.1016/j.engappai.2020.103815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing project costs effectively, which comprises numerous aspects, is a highly complicated process for project managers that needs dependable cash knowledge in the entire life cycle of the project. Project managers’ proficiency and anticipating dependable cash flows lead to substantial improvements in project costs management. Moreover, healthy cash flow prognostication for the whole construction project gives project managers a real insight into the identification of problems, and its deficiency results in the failure of firms even with big profits to maintain themselves as well. Therefore, predicting reliable cash flow and monitoring the progress of projects in terms of cash are essential to be considered. Furthermore, due to the existence of uncertainties in projects, it is necessary to find it as a significant part of different approaches. Building upon these, an innovative approach is presented in this paper to prognosticate project cash flow based on both type-2 fuzzy extension of dependency structure matrix for project scheduling with overlapping activities and extended alternative queuing method under type-2 fuzzy environment to adopt the best scenario. Moreover, type-2 fuzzy numbers are applied to address the uncertainty of activities. Subsequently, a real case study of a gas field development project is employed to represent the efficiency of proposed approach. Ultimately, a comparative study is conducted to validate the results, and superiorities of the proposed approach are addressed from different aspects. The results illustrate that the presented approach is capable of handling real project problems and providing project managers with a suitable tool to comprehend the cash conditions of the projects.},
  archive      = {J_EAAI},
  author       = {Seyed Ali Mirnezami and Seyed Meysam Mousavi and Vahid Mohagheghi},
  doi          = {10.1016/j.engappai.2020.103815},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103815},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new interval type-2 fuzzy approach for multi-scenario project cash flow assessment based on alternative queuing method and dependency structure matrix with a case study},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantized generalized maximum correntropy criterion based
kernel recursive least squares for online time series prediction.
<em>EAAI</em>, <em>95</em>, 103797. (<a
href="https://doi.org/10.1016/j.engappai.2020.103797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information theoretic learning, the maximum correntropy criterion (MCC) has been widely used in time series prediction area. Especially, the kernel recursive least squares (KRLS) based on MCC is studied recently due to its online recursive form and the ability to resist noise and be robust in non-Gaussian environments. However, it is not always an optimal choice that using the correntropy, which is calculated by default Gaussian kernel function, to describe the local similarity between variables. Besides, the computational burden of MCC based KRLS will raise as data size increases, thus causing difficulties in accommodating time-varying environments. Therefore, this paper proposes a quantized generalized MCC (QGMCC) to solve the above problem. Specifically, a generalized MCC (GMCC) is utilized to enhance the accuracy and flexibility in calculating the correntropy. In order to solve the problem of computational complexity, QGMCC quantizes the input space and upper bounds the network size by vector quantization (VQ) method. Furthermore, QGMCC is applied to KRLS and forming a computationally efficient and precisely predictive algorithm. After that, the improved algorithm named quantized kernel recursive generalized maximum correntropy (QKRGMC) is set up and the derivation process is also given. Experimental results of one benchmark dataset and two real-world datasets are present to verify the effectiveness of the online prediction algorithm.},
  archive      = {J_EAAI},
  author       = {Tianyu Shen and Weijie Ren and Min Han},
  doi          = {10.1016/j.engappai.2020.103797},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103797},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantized generalized maximum correntropy criterion based kernel recursive least squares for online time series prediction},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive switchover hybrid particle swarm optimization
algorithm with local search strategy for constrained optimization
problems. <em>EAAI</em>, <em>95</em>, 103771. (<a
href="https://doi.org/10.1016/j.engappai.2020.103771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical engineering optimization problems are almost constrained optimization problems and difficult to be solved effectively, therefore, how to handle these problems has attracted more and more attention. Particle swarm optimization (PSO) is one of the most popular algorithms in solving the complicated optimization problems due to its relatively strong global optimization capability and low requirement for computing resources. However, PSO is easy to converge prematurely like other swarm intelligence algorithms due to the loss of diversity among particles. This article proposes an adaptive switchover hybrid PSO framework with local search process (ASHPSO), which adaptively switches the optimization searching process between the standard PSO and the differential evolution (DE) modified by a full dimension crossover strategy to avoid the premature convergence problem. Moreover, a local search strategy is employed to improve the boundary search capability of PSO in consideration of the engineering problems characteristics. Experiments on 28 well-known benchmark functions, 5 engineering problems and a full vehicle multi-disciplinary optimization problem demonstrate the effectiveness of the proposed algorithm compared with other hybrid variants.},
  archive      = {J_EAAI},
  author       = {Zhao Liu and Zhiwei Qin and Ping Zhu and Han Li},
  doi          = {10.1016/j.engappai.2020.103771},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {103771},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An adaptive switchover hybrid particle swarm optimization algorithm with local search strategy for constrained optimization problems},
  volume       = {95},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel similarity measures in spherical fuzzy environment and
their applications. <em>EAAI</em>, <em>94</em>, 103837. (<a
href="https://doi.org/10.1016/j.engappai.2020.103837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spherical fuzzy sets (SFSs) have gained great attention from researchers in various fields. The spherical fuzzy set is characterized by three membership functions expressing the degrees of membership, non-membership and the indeterminacy to provide a larger preference domain. It was proposed as a generalization of picture fuzzy sets and Pythagorean fuzzy sets in order to deal with uncertainty and vagueness information. The similarity measure is one of the essential and advantageous tools to determine the degree of similarity between items. Several studies on similarity measures have been developed due to the importance of similarity measure and application in decision making, data mining, medical diagnosis, and pattern recognition in the literature. The contribution of this study is to present some novel spherical fuzzy similarity measures. We develop the Jaccard, exponential, and square root cosine similarity measures under spherical fuzzy environment. Each of these similarity measures is analyzed with respect to decision-makers’ optimistic or pessimistic point of views. Then, we apply these similarity measures to medical diagnose and green supplier selection problems. These similarity measures can be computed easily and they can express the dependability similarity relation apparently.},
  archive      = {J_EAAI},
  author       = {Seyed Amin Seyfi Shishavan and Fatma Kutlu Gündoğdu and Elmira Farrokhizadeh and Yaser Donyatalab and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2020.103837},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103837},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel similarity measures in spherical fuzzy environment and their applications},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel interdependence based multilevel thresholding
technique using adaptive equilibrium optimizer. <em>EAAI</em>,
<em>94</em>, 103836. (<a
href="https://doi.org/10.1016/j.engappai.2020.103836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multilevel thresholding is one important operation in computer vision, which is a subfield of artificial intelligence (AI), used to understand and interpret the data in the real world. The existing entropic methods, based on the histogram of an image for the multilevel thresholding mostly deal with the maximization of the entropic information excluding the shred boundary, which reduces the accuracy. These problems lead to the poor thresholding accuracy and a lower speed. To address the problem, we propose a novel interdependence based technique that uses the shred boundary, which is a minimization problem. A firsthand objective function is investigated, which takes care of the shred boundary. The traditional multilevel thresholding techniques are computationally expensive due to the exhaustive search process, an alternate method is to use the evolutionary computation based on a nature-inspired algorithm. In this paper, a new optimizer called adaptive equilibrium optimizer (AEO) is also proposed for multilevel thresholding, an improvement over the basic equilibrium optimizer (EO) by implementing an adaptive decision making of dispersal for nonperformer search agents. The AEO performance is compared with state-of-the-art algorithms — equilibrium optimizer (EO), gray wolf optimizer (GWO), whale optimization algorithm (WOA), squirrel search algorithm (SSA) and the wind driven optimization (WDO) algorithm, using standard benchmark functions. Based on the qualitative and quantitative analysis, the AEO outperformed EO, GWO, WOA, SSA, and WDO. The optimal thresholds are obtained by minimizing the objective function using the AEO. For the experiment, 500 images of the BSDS 500 dataset are considered. Popular metrics such as the peak signal to noise ratio (PSNR), structural similarity index (SSIM), and the feature similarity index (FSIM) are considered for a quantitative analysis. Remarkable differences in the thresholding accuracy are observed with a simultaneously decreasing computational complexity. The merits of the paper are highlighted to ensure its future use in the world of engineering applications using soft computing, a subfield of the AI.},
  archive      = {J_EAAI},
  author       = {Aneesh Wunnava and Manoj Kumar Naik and Rutuparna Panda and Bibekananda Jena and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103836},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103836},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bid evaluation in civil construction under uncertainty: A
two-stage LSP-ELECTRE III-based approach. <em>EAAI</em>, <em>94</em>,
103835. (<a
href="https://doi.org/10.1016/j.engappai.2020.103835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing growth and development of building industry and civil engineering motivates enterprises to advance bid evaluation process in an effort to ameliorate building quality and diminish construction cost. The selection of qualified construction contractor has been generally formulated and addressed as a multi-attribute group decision-making problem. However, few existing studies have taken the reasoning logic pattern in human cognition process and the compensatory among attributes into account. Therefore, a two-stage logic scoring of preference-ELECTRE III-based approach is established for the management and manipulation of bidder selection. In a bid to facilitate expert evaluation articulation, alternative-attribute assessments in this approach take the form of generalized comparative linguistic expressions, which are subsequently converted into possibility-distribution-based hesitant fuzzy linguistic term set via the similarity measure-based generation approach to enhance information quality and reliability. Then, nonlinear optimization-based direction rules are introduced to advance the automatic minimum-distance-based consensus reaching model and based on which, the individual semantic-embedded assessments are algorithmically adjusted to reach acceptable consensus. Furthermore, the expert and attribute importance degrees are extracted from both semantic and formal logic aspects, and the modified individual assessments are gathered by integrating the two-stage logic scoring of preference aggregation structure and the ELECTRE III method. The present approach provides a solution to bid evaluation problems considering the reasoning logic pattern in human cognition process and the compensatory among attributes. A practical case study and a comparative analysis are performed to demonstrate the feasibility and effectiveness of the established multi-attribute group decision-making approach.},
  archive      = {J_EAAI},
  author       = {Zhen-Song Chen and Xuan Zhang and Witold Pedrycz and Xian-Jia Wang and Miroslaw J. Skibniewski},
  doi          = {10.1016/j.engappai.2020.103835},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103835},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bid evaluation in civil construction under uncertainty: A two-stage LSP-ELECTRE III-based approach},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Condensed representations of changes in dynamic graphs
through emerging subgraph mining. <em>EAAI</em>, <em>94</em>, 103830.
(<a href="https://doi.org/10.1016/j.engappai.2020.103830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change mining is one of the main subjects of analysis on time-evolving data. Regardless of the distribution of the changes over the data, often the algorithms return very large sets of results. In fact, one class of algorithms designed for change mining is based on pattern mining, which notoriously suffers from the problem of a huge number of returned patterns. Moreover, the complexity of some types of data, like dynamic graphs, could make the size of the final changes even larger, which makes interpretation difficult or even impossible. This paper represents the first attempt, to our knowledge, to build condensed representations of changes from dynamic graphs. We study changes captured with the pattern (subgraph) mining framework and focus on the discovery of subgraphs able to (i) represent evident changes and (ii) convey graph-based information that is not already expressed by other subgraphs. To do this, we revise an existing approach by introducing the notion of emerging subgraphs, used to remove uninteresting changes and the notions of closed and maximal subgraphs, used to remove redundant changes. Experiments performed on real-world dynamic graphs show that the condensed representations maintain the accuracy levels of the original approach and often offer a loss-less representation of the detected changes.},
  archive      = {J_EAAI},
  author       = {Angelo Impedovo and Corrado Loglisci and Michelangelo Ceci and Donato Malerba},
  doi          = {10.1016/j.engappai.2020.103830},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103830},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Condensed representations of changes in dynamic graphs through emerging subgraph mining},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning semantic information from internet domain names
using word embeddings. <em>EAAI</em>, <em>94</em>, 103823. (<a
href="https://doi.org/10.1016/j.engappai.2020.103823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word embeddings is a well-known set of techniques widely used in Natural Language Processing (NLP). These techniques are able to learn words’ semantic based on the distributional hypothesis which states that words that are used and occur in the same contexts tend to purport similar meanings. This paper explores the usage of word embeddings in a new scenario to create a Vector Space Model (VSM) for Internet Domain Names (DNS). Our goal is to find semantically similar domains only using information of DNS queries without any knowledge about the content of those domains. The results presented here have practical applications in many engineering activities including websites recommendations, identification of fraudulent or risky sites, parental-control systems and anomaly detection in network traffic analysis (among others). We use the distributional hypothesis to learn the semantic of domain names from users’ web navigation patterns, validating empirically that domain names that occur in the same web sessions tend to have similar semantic. We also test different word embeddings techniques: word2vec , app2vec (considering time intervals between DNS queries), and fastText (which includes sub-word information). Due to the characteristics of domain names, we found fastText as the best option for building a VSM for DNS, being 10.5% superior than word2vec with Skip-Gram which was the next best technique considering the Mean Average Precision at k (MAP@k) metric, which compares the most similar domains in our VSM with the most similar domains provided by a third party source, namely, similar sites service offered by Alexa Internet, Inc.},
  archive      = {J_EAAI},
  author       = {Waldemar López and Jorge Merlino and Pablo Rodríguez-Bocca},
  doi          = {10.1016/j.engappai.2020.103823},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103823},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning semantic information from internet domain names using word embeddings},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Change detection in images using shape-aware siamese
convolutional network. <em>EAAI</em>, <em>94</em>, 103819. (<a
href="https://doi.org/10.1016/j.engappai.2020.103819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection gradually becomes a core technique due to its wide applications of image or video analysis like land cover analysis and real-time monitoring system. Recently, siamese convolutional networks have been adopted for change detection which demonstrate the state-of-the-art performance. Although most of the previous works have better location accuracy, these methods cannot avoid side effects such as coarse boundaries and empty holes. In this paper, we propose a shape-aware siamese convolutional network (SASCNet) to simultaneously integrate different information for change detection with three steps in an unified network. In the first step, we extract multi-dimension features from paired images and select multi-level change maps generated by a novel siamese encoder–decoder network with multi-scale supervisions. In the second step, we integrate these change maps to obtain complementary information in detail. Finally, we use a residual fine-tune module to refine the predicted change maps and enhance the performance. Because of rich information in different levels and multi-scale supervisions, the predicted change maps could provide precise positioning as well as high-quality shapes. Experimental results on “CDnet 2014 dataset” and “AICD-2012 dataset” show that our method outperforms the state-of-the-art methods in most challenging conditions.},
  archive      = {J_EAAI},
  author       = {Suicheng Li and Pengcheng Han and Shuhui Bu and Pinmo Tong and Qing Li and Ke Li and Gang Wan},
  doi          = {10.1016/j.engappai.2020.103819},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103819},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Change detection in images using shape-aware siamese convolutional network},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost function based on the self-organizing map for parameter
estimation of chaotic discrete-time systems. <em>EAAI</em>, <em>94</em>,
103817. (<a
href="https://doi.org/10.1016/j.engappai.2020.103817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameter estimation problem of dynamical systems is an important task in controller design and system identification. In this paper, a novel approach is proposed towards parameter estimation of discrete dynamical systems with chaotic behaviors. Here, we utilize models of attractors to find unknown parameters of a real systems. This method relies on introducing a new cost function based on self-organizing maps (SOM) of measured data obtained from the system. In addition, theoretical justifications and computational complexity analyses are presented regarding the efficiency of SOM-based cost function. Experimental results on several benchmarks showed suitable performances of the proposed cost function compared to previously published cost functions such as Mean-Squared Error (MSE), Return Map Fingerprint (RMF), and Gaussian Mixture Model (GMM).},
  archive      = {J_EAAI},
  author       = {Ali Mousazadeh and Yasser Shekofteh},
  doi          = {10.1016/j.engappai.2020.103817},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103817},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cost function based on the self-organizing map for parameter estimation of chaotic discrete-time systems},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differentially private 1R classification algorithm using
artificial bee colony and differential evolution. <em>EAAI</em>,
<em>94</em>, 103813. (<a
href="https://doi.org/10.1016/j.engappai.2020.103813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is an important topic in data mining field. Privacy preserving classification is a substantial subtopic that aims to perform classification of private data with satisfactory accuracy, while allowing sensitive information leakage at minimal level. Differential privacy is a strong privacy guarantee that determines privacy leakage ratio by using ϵ parameter; and enables privacy of individuals whose sensitive data are stored in a database. There exist some differentially private implementations of well-known classification algorithms such as ID3, random tree, random forests, Naïve Bayes, SVM, logistic regression, k-NN etc. Although One Rule (1R) is a simple but powerful classification algorithm, any implementation of differentially private 1R classification algorithm has not been proposed in the literature to our best knowledge. Motivated by this gap, first we propose a differentially private 1R classification algorithm (DP1R), then improve its performance by using metaheuristics that are differential evolution (DE) and artificial bee colony (ABC) in this study. Additionally, we also apply DE and ABC to improve performance of differentially private Naïve Bayes classifier and compare with DP1R. Moreover, DP1R is compared with the state-of-the-art differentially private algorithms such as differentially private SVM, differentially private logistic regression, differentially private ID3, and differentially private random tree on nine publicly available UCI datasets. The experimental results demonstrate that DP1R is an efficient classifier that has very similar accuracy to differentially private SVM which has the best accuracy results, however with respect to running time comparison of the methods, DP1R has the best performance among the all methods.},
  archive      = {J_EAAI},
  author       = {Ezgi Zorarpacı and Selma Ayşe Özel},
  doi          = {10.1016/j.engappai.2020.103813},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103813},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differentially private 1R classification algorithm using artificial bee colony and differential evolution},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluation of human standing balance using wearable inertial
sensors: A machine learning approach. <em>EAAI</em>, <em>94</em>,
103812. (<a
href="https://doi.org/10.1016/j.engappai.2020.103812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to recent studies, mobility and balance problems represent a risk factor for elderly people, resulting into augmented fall probabilities with negative impact on medical, social and economical aspects. Posturographic analysis plays a major role in clinical applications, enabling the evaluation of standing balance and the quantification of specific risks. Wearable devices represent a viable option to support diagnostic practice, but several issues need to be addressed to design systems with the required reliability. In this work, we propose a solution that hinges upon signals that could be gathered in principle from sensors on board of wearable devices. In particular, we propose to extract meaningful features from the accelerometer and gyroscope data streams that could be processed and exploited to feed machine learning algorithms (namely Support Vector Machines) and recognize determined standing balance tasks. Specifically, we put forward to exploit time-domain, frequency-domain and structural features that are usually used for processing signals from plate force devices and we augment them with those obtained from the gyroscope. Experimental results underline the effectiveness of the proposed method, which could effectively classify subjects involved in standing balance exercises and also discriminate between specific tasks reaching average performance levels of 87% in terms of precision, 86% in terms of recall, 87% in terms of F1 score, and 92% for what regards accuracy. The proposed study confirms the possibility of developing hardware–software systems that could represent affordable, flexible, yet meaningful solutions to assist, therefore, monitoring activities at fine grain resolution.},
  archive      = {J_EAAI},
  author       = {Emanuele Lattanzi and Valerio Freschi},
  doi          = {10.1016/j.engappai.2020.103812},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103812},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluation of human standing balance using wearable inertial sensors: A machine learning approach},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A semi-explicit short text retrieval method combining
wikipedia features. <em>EAAI</em>, <em>94</em>, 103809. (<a
href="https://doi.org/10.1016/j.engappai.2020.103809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advantages such as openness, interactivity, immediacy, and simplicity, the large number of short text data appear in the Web information space. Considering the short length, little information, sparse features and irregular grammar, the traditional information analyzing and retrieval technologies cannot deal with short text effectively. In view of the above problems, in this paper a new short text retrieval method based on the current mainstream semantic knowledge source, Wikipedia, is proposed. To be specific, a semantic feature selection algorithm is proposed to return the top k most relevant Wikipedia concepts as the whole vector space for a given short text. Thus, by analyzing the topic information of the semantic features contained in Wikipedia concepts, we propose some formulas to determine the association coefficient list between different components of the corresponding positions in two different feature vectors. On this basis, a new semantic relatedness assessment method under this lower dimensional semantic space is designed. According to computing and sorting the semantic relatedness between user queries and the target short text, a novel semi-explicit short text retrieval method combining Wikipedia concept feature and the corresponding topic information is proposed. Lastly, based on the experimental results on twitter subsets, we verify that our proposal has advantages over other some current retrieval methods on MAP , P@k and R-Prec , and can return more valid results.},
  archive      = {J_EAAI},
  author       = {Pu Li and Tianci Li and Suzhi Zhang and Yuhua Li and Yong Tang and Yuncheng Jiang},
  doi          = {10.1016/j.engappai.2020.103809},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103809},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A semi-explicit short text retrieval method combining wikipedia features},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Path planning of multiple UAVs with online changing tasks by
an ORPFOA algorithm. <em>EAAI</em>, <em>94</em>, 103807. (<a
href="https://doi.org/10.1016/j.engappai.2020.103807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unmanned aerial vehicle (UAV) is a new type oilfield inspection tool which is characterized by high flexibility, low cost and high efficiency. In the UAV based oilfield inspection technology, the path planning is an indispensable element which finds an optimal flight path for UAV to finish the inspection jobs successfully. In comparison with the other researches, our study focuses on two challenging issues: path planning of multiple UAVs by traversing a certain amount of task points in the three-dimensional environment within the required completion time, and optimizing solving for the best flight path with online changing tasks. In the research, a novel task assignment method including the initial task assignment and the task assignment with changing tasks is proposed to determine the initial task sequences of each UAV and rapidly replan task sequences after tasks change. An improved fruit fly optimization algorithm (named ORPFOA) is proposed to solve the path planning problem in both initial task sequences and new task sequences after tasks change, in which the optimal reference point and a distance cost matrix are used to reach both faster solving and higher optimizing precision for the optimal flight path. In ORPFOA, two cost functions are defined to evaluate the optimizing results in the initial phase and the new phase after task changes, respectively. A simulation model of the three-dimensional oilfield environment is established to verify the effectiveness of the proposed method in comparison with other six algorithms.},
  archive      = {J_EAAI},
  author       = {Kun Li and Fawei Ge and Ying Han and Yi’an Wang and Wensu Xu},
  doi          = {10.1016/j.engappai.2020.103807},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103807},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Path planning of multiple UAVs with online changing tasks by an ORPFOA algorithm},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A scale-adaptive positive selection algorithm based on
b-cell immune mechanisms for anomaly detection. <em>EAAI</em>,
<em>94</em>, 103805. (<a
href="https://doi.org/10.1016/j.engappai.2020.103805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current anomaly detection immune algorithms, the methods for setting the detection radius of detectors fail to take into account the concentration characteristic of self samples, which weaken their application effect. In response to this deficiency, we proposed a new type of detector named the scale-adaptive B-cells (SAB-cells) detector, and a novel algorithm named scale-adaptive positive selection algorithm (SA-PSA). This algorithm is mainly based on the B-cell immune mechanisms of clonal variation and network suppression. In SA-PSA, the detection radius of SAB-cells can be adaptively adjusted by clonal variation, and the number of redundant SAB-cells can be effectively compressed by fusion variation, so as to eventually obtain efficient detectors. Based on the Iris data set, firstly, we analyzed the effects of three main control parameters on SA-PSA; secondly, we compared SA-PSA with other mainstream anomaly detection immune algorithms by three performance indicators; thirdly, we performed the analysis of receiver operating characteristic (ROC) curve and verified the effectiveness of SA-PSA. At last, we also applied SA-PSA to bearing anomaly detection and further verified its effectiveness in more complicated engineering applications.},
  archive      = {J_EAAI},
  author       = {Hongli Zhang and Zhongyuan Ren and Shaojie Xin and Shulin Liu and Chao Lan and Xin Sun},
  doi          = {10.1016/j.engappai.2020.103805},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103805},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A scale-adaptive positive selection algorithm based on B-cell immune mechanisms for anomaly detection},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mechanism analysis of non-inertial particle swarm
optimization for internet of things in edge computing. <em>EAAI</em>,
<em>94</em>, 103803. (<a
href="https://doi.org/10.1016/j.engappai.2020.103803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper carries out the mechanism analysis of non-inertial particle swarm optimization. It is a modified algorithm based on a new kinetic equation which is applied to the prediction of non-stationary time series for the internet of things in the edge computing. In order to avoid premature convergence and accelerate convergence rate, different from standard particle swarm optimization, the modified algorithm uses a new kinetic equation to lead particles motion direction, besides generalized opposition-based learning (GOBL) and adaptive elite mutation (AEM) strategies. The work presents the second order standardized recurrence equation for the new kinetic equation whose corresponding characteristic equations can be analyzed via the difference functions to obtain the boundaries of coefficients and its convergence region. Besides, GOBL and AEM strategies are also analyzed to boost global and local convergence of the algorithm as an interpretation. It is illustrated that performance analysis of the algorithm with two well-known test functions. The good performance is further validated from application in edge computing.},
  archive      = {J_EAAI},
  author       = {Lanlan Kang and Ruey-Shun Chen and Wenliang Cao and Yeh-Cheng Chen and Yu-Xi Hu},
  doi          = {10.1016/j.engappai.2020.103803},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103803},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Mechanism analysis of non-inertial particle swarm optimization for internet of things in edge computing},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Backtracking search optimization algorithm-based least
square support vector machine and its applications. <em>EAAI</em>,
<em>94</em>, 103801. (<a
href="https://doi.org/10.1016/j.engappai.2020.103801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on statistical learning theory, least square support vector machine can effectively solve the learning problem of small samples. However, the parameters of the least square support vector machine model have a great influence on its performance. At the same time, there is no clear theoretical basis for how to choose these parameters. In order to cope with the parameters optimization of the least square support vector machine, a backtracking search optimization algorithm-based least square support vector machine model is proposed. In this model, backtracking search optimization algorithm is introduced to optimize the parameters of the least square support vector machine. Meanwhile, the least square support vector machine model is updated by the prediction error combined with the sliding window strategy to solve the problem of mis-match between the prediction model and the actual sample data in the time-varying system. The performance of the proposed model is verified by classification and regression problems. The classification performance of the model is verified by five Benchmark datasets, and the regression prediction performance is verified by the dynamic liquid level of the oil production process. Compared with genetic algorithm, particle swarm optimization algorithm, and improved free search algorithm optimized least square support vector machine, the simulation results show that the proposed model has higher classification accuracy with less computation time, and higher prediction accuracy and reliability for the dynamic liquid level. The proposed model is effective.},
  archive      = {J_EAAI},
  author       = {Zhongda Tian},
  doi          = {10.1016/j.engappai.2020.103801},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103801},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Backtracking search optimization algorithm-based least square support vector machine and its applications},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trajectory based lateral control: A reinforcement learning
case study. <em>EAAI</em>, <em>94</em>, 103799. (<a
href="https://doi.org/10.1016/j.engappai.2020.103799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) has been employed in many applications of robotics and has steadily been gaining traction in the field of Autonomous Driving (AD). This paper proposes a Deep Reinforcement Learning based approach for lateral Vehicle Motion Control (VMC), and explores the generalization capabilities of the approach. The proposed methodology uses a sequence of waypoints generated from a planning module of an AD stack as the input. The network has been trained to predict accurate steering commands to follow the given trajectory. In this paper we detail our implementation and share our learning experience on real-vehicle deployment of the RL based controller. Our experiments yield promising results with an agent trained on less than 4 h of simulated driving experience without any real-world data. The trained agent is able to successfully complete unseen and more complex tracks using different unseen vehicle models. The agent safely reached up to 150 km/h in simulation and up to 60 km/h in a real-life Sport Utility Vehicle (SUV) weighing more than 2000 kg.},
  archive      = {J_EAAI},
  author       = {Asanka Wasala and Donal Byrne and Philip Miesbauer and Joseph O’Hanlon and Paul Heraty and Peter Barry},
  doi          = {10.1016/j.engappai.2020.103799},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103799},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trajectory based lateral control: A reinforcement learning case study},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved weighted one class support vector machine for
turboshaft engine fault detection. <em>EAAI</em>, <em>94</em>, 103796.
(<a href="https://doi.org/10.1016/j.engappai.2020.103796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class support vector machine (OC-SVM) is a common algorithm to solve one-class classification (OCC) problem. Weighted OC-SVM (WOC-SVM) is an improved algorithm based on OC-SVM, which assigns a weight to each sample through a specific weight calculation method so as to improve the robustness of the algorithm. The recently proposed WOC-SVM algorithm based on neighbors’ distribution named as WOC-SVM(ND) is an easily understandable and effective algorithm. The weighting strategy of WOC-SVM(ND) is only related to the distribution of instance’s k -nearest neighbors. In other words, the farther the distance between the instance and the boundary of the data distribution is, the more even the distribution of k -nearest neighbors is and the bigger the corresponding weight of the instance is. However, this weight calculation method is unreasonable to some extent. That is to say, it only considers the distribution angle of k -nearest neighbors, but does not consider the influence of the distance between k -nearest neighbors and the instance on the weight. Besides, WOC-SVM(ND) cannot effectively solve the problem which has complex dataset consisting of multiple clusters. The algorithm proposed in this paper can solve these two problems simultaneously, which is composed of two parts. One is an improved version on the basis of WOC-SVM(ND), and the other takes into account the distribution density of samples’ k -nearest neighbors. Their linear combination makes the weighting strategy more reasonable. Experimental results on eight benchmark datasets show that the proposed algorithm is feasible and effective. Moreover, when the proposed algorithm is applied to the fault detection of turboshaft engine, an impressive effectiveness is obtained.},
  archive      = {J_EAAI},
  author       = {Yong-Ping Zhao and Gong Huang and Qian-Kun Hu and Bing Li},
  doi          = {10.1016/j.engappai.2020.103796},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103796},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved weighted one class support vector machine for turboshaft engine fault detection},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving maritime traffic emission estimations on missing
data with CRBMs. <em>EAAI</em>, <em>94</em>, 103793. (<a
href="https://doi.org/10.1016/j.engappai.2020.103793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime traffic emissions are a major concern to governments as they heavily impact the Air Quality in coastal cities. Ships use the Automatic Identification System (AIS) to continuously report position and speed among other features, and therefore this data is suitable to be used to estimate emissions, if it is combined with engine data. However, important ship features are often inaccurate or missing. State-of-the-art complex systems, like CALIOPE at the Barcelona Supercomputing Center, are used to model Air Quality. These systems can benefit from AIS based emission models as they are very precise in positioning the pollution. Unfortunately, these models are sensitive to missing or corrupted data, and therefore they need data curation techniques to significantly improve the estimation accuracy. In this work, we propose a methodology for treating ship data using Conditional Restricted Boltzmann Machines (CRBMs) plus machine learning methods to improve the quality of data passed to emission models that can also be applied to other GPS and time-series problems. Results show that we can improve the default methods proposed to cover missing data. In our results, we observed that using our method the models boosted their accuracy to detect otherwise undetectable emissions. In particular, we used a real data-set of AIS data, provided by the Spanish Port Authority, to estimate that thanks to our method, the model was able to detect 45 % of additional emissions, representing 152 tonnes of pollutants per week in Barcelona and propose new features that may enhance emission modeling.},
  archive      = {J_EAAI},
  author       = {Alberto Gutierrez-Torre and Josep Ll. Berral and David Buchaca and Marc Guevara and Albert Soret and David Carrera},
  doi          = {10.1016/j.engappai.2020.103793},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103793},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving maritime traffic emission estimations on missing data with CRBMs},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel retrieval strategy for case-based reasoning based on
attitudinal choquet integral. <em>EAAI</em>, <em>94</em>, 103791. (<a
href="https://doi.org/10.1016/j.engappai.2020.103791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval is a very important stage in the case-based reasoning (CBR) process because it is the critical foundation for the success of the CBR system. Its goal is to retrieve valuable cases that can be employed as references to solve the target problem. The most commonly employed methods in the retrieval process today is similarity-based weighted average operators, which have been criticized for not considering the interactions among features. In this paper, we develop a novel retrieval strategy for CBR based on the attitudinal Choquet integral ( ACI ), which can capture (a) the features interaction, (b) relative features importance, and (c) the attitudinal character of decision maker. The core of the retrieval strategy is to define a global similarity which aggregates local similarity and feature similarity through ACI . In addition, to ensure the availability of data in the case base, we present a method of filling in missing data. The novel retrieval strategy and filling method are validated through two simulation experiments on several real data sets. The superiority of the developed approaches in terms of retrieval capability and filling efficiency can be demonstrated by approaching an average recognition rate of 82% and a filling accuracy of over 90%.},
  archive      = {J_EAAI},
  author       = {Liguo Fei and Yuqiang Feng},
  doi          = {10.1016/j.engappai.2020.103791},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103791},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel retrieval strategy for case-based reasoning based on attitudinal choquet integral},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simheuristic-based decision support system for efficiency
improvement of an iron ore crusher circuit. <em>EAAI</em>, <em>94</em>,
103789. (<a
href="https://doi.org/10.1016/j.engappai.2020.103789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production rate of an ore crushing circuit depends on the amount of equipment in operation. If the amount of active equipment is less than the optimum level, the reduced ore flow paths restrict the production rate. However, if the amount of active equipment is greater than the optimum level, the excess circulating load ore and extra energy consumption reduce the circuit efficiency. In addition, the optimum amount of active equipment can change over time due to changes in the ore characteristics, such as hardness and particle size. In this paper, a decision support system is proposed for optimizing the amount of active equipment for maximum crushing production considering changes in the circuit feed rate. The proposed solution is based on a simheuristic approach in which a simulated plant model is used to evaluate the production rate. Real production scenarios at a Brazilian mining plant are used in computational experiments. The results show that the simheuristic solutions generate a higher production rate and result in less energy consumption. Production is increased by up to 9%, and energy consumption is reduced by up to 59%, demonstrating the efficacy of the proposal.},
  archive      = {J_EAAI},
  author       = {Mário S. Santos and Thomás V.B. Pinto and Ênio Lopes Júnior and Luciano P. Cota and Marcone J.F. Souza and Thiago A.M. Euzébio},
  doi          = {10.1016/j.engappai.2020.103789},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103789},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simheuristic-based decision support system for efficiency improvement of an iron ore crusher circuit},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preserving empirical data utility in k-anonymous
microaggregation via linear discriminant analysis. <em>EAAI</em>,
<em>94</em>, 103787. (<a
href="https://doi.org/10.1016/j.engappai.2020.103787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s countless benefits of exploiting data come with a hefty price in terms of privacy. k -Anonymous microaggregation is a powerful technique devoted to revealing useful demographic information of microgroups of people, whilst protecting the privacy of individuals therein. Evidently, the inherent distortion of data results in the degradation of its utility. This work proposes and analyzes an anonymization method that draws upon the technique of linear discriminant analysis (LDA), with the aim of preserving the empirical utility of data. Further, this utility is measured as the accuracy of a machine learning model trained on the microaggregated data. By transforming the original data records to a different data space, LDA enables k -anonymous microaggregation to build microcells more tailored to an intrinsic classification threshold. To do this, first, data is rotated (projected) towards the direction of maximum discrimination and, second, scaled in this direction by a factor α that penalizes distortion across the classification threshold. The upshot is that thinner cells are built along the threshold, which ends up preserving data utility in terms of the accuracy of machine learned models for a number of standardized data sets.},
  archive      = {J_EAAI},
  author       = {Ana Rodríguez-Hoyos and David Rebollo-Monedero and José Estrada-Jiménez and Jordi Forné and Luis Urquiza-Aguiar},
  doi          = {10.1016/j.engappai.2020.103787},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103787},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Preserving empirical data utility in k-anonymous microaggregation via linear discriminant analysis},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data flow and distributed deep neural network based low
latency IoT-edge computation model for big data environment.
<em>EAAI</em>, <em>94</em>, 103785. (<a
href="https://doi.org/10.1016/j.engappai.2020.103785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trillion-fold increase in computing power brings the accessibility of deep learning to everyone. Deep learning offers precise information almost all the time when compared to other learning algorithms. On the other hand, the popularity of Internet of Things (IoT) has increased in various areas such as Smart City, Oil Mining, and Transportation. Edge/Fog computing environment helps to handle significant challenges faced by the IoT, viz. latency, bandwidth consumption, and everlasting network connectivity. For analytics in Edge computing, which is distributed in nature, the trend is more towards distributed machine learning. This research work is focused on the integration of data flow and distributed deep learning in the IoT-Edge environment to bring down the latency and increase accuracy starting from the data generation phase. To this end, a novel Data Flow and Distributed Deep Neural Network (DF-DDNN) based IoT-Edge model for big data environment has been proposed. Our proposed method has resulted in latency reduction of up to 33% when compared to the existing traditional IoT-Cloud model.},
  archive      = {J_EAAI},
  author       = {Veeramanikandan and Suresh Sankaranarayanan and Joel J.P.C. Rodrigues and Vijayan Sugumaran and Sergei Kozlov},
  doi          = {10.1016/j.engappai.2020.103785},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103785},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data flow and distributed deep neural network based low latency IoT-edge computation model for big data environment},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the influence of international benchmark oil
price on china’s real exchange rate forecasting. <em>EAAI</em>,
<em>94</em>, 103783. (<a
href="https://doi.org/10.1016/j.engappai.2020.103783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exchange rate forecasting plays an important role in the economic and financial fields. Oil price fluctuations have a great impact on the country’s economic activity. Based on the theory of exchange rate determination, this paper combines quantitative and qualitative research methods to study the impact of three major international benchmark crude oil price changes on the real effective exchange rate forecast of the RMB. In this paper, the correlation between the three international benchmark oil prices and the real exchange rate is discussed through the hybrid Copula function, and then the bivariate neural network model is constructed. Brent crude oil price having the greatest degree of correlation with China’s real exchange rate, the Kendall correlation coefficient and the Spearman correlation coefficient are 0.4327 and 0.5792. MAPE values of the three Brent variable models in the one-step prediction reached 0.54%, 0.51%, and 0.54%. The results of the experiments and discussions shows that the bivariate model has excellent forecasting performance, and indicates that the continuous fluctuations in oil prices have a great impact on the exchange rate, and that oil price information has provided effective help for China’s real exchange rate forecasting.},
  archive      = {J_EAAI},
  author       = {Jianzhou Wang and Xinsong Niu and Zhenkun Liu and Lifang Zhang},
  doi          = {10.1016/j.engappai.2020.103783},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103783},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysis of the influence of international benchmark oil price on china’s real exchange rate forecasting},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spherical data clustering and feature selection through
nonparametric bayesian mixture models with von mises distributions.
<em>EAAI</em>, <em>94</em>, 103781. (<a
href="https://doi.org/10.1016/j.engappai.2020.103781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we tackle the problem of clustering spherical (i.e. L 2 normalized) data vectors using nonparametric Bayesian mixture models with von Mises distributions. Our model is formulated by employing a nonparametric Bayesian framework known as the Pitman–Yor process mixture model. Different from finite mixture models in which the determination of the number of clusters is a crucial problem and often requires extra effort (e.g. by inspecting information criteria), the proposed model is nonparametric such that the number of clusters in the model is assumed to be infinite at the initial stage and will be inferred automatically based on the data. Moreover, an unsupervised feature selection scheme is incorporated into the proposed model to remove features that do not contribute significantly to the clustering process. We develop a stochastic variational inference algorithm to estimate model parameters, model complexity and feature saliencies simultaneously and effectively through the method of stochastic gradient ascent. We demonstrate the merits of the proposed nonparametric Bayesian mixture model on clustering spherical data vectors by conducting experiments on both synthetic datasets and two real-world applications namely topic novelty detection and flower images categorization.},
  archive      = {J_EAAI},
  author       = {Wentao Fan and Nizar Bouguila},
  doi          = {10.1016/j.engappai.2020.103781},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103781},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spherical data clustering and feature selection through nonparametric bayesian mixture models with von mises distributions},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved sine cosine algorithm combined with optimal
neighborhood and quadratic interpolation strategy. <em>EAAI</em>,
<em>94</em>, 103779. (<a
href="https://doi.org/10.1016/j.engappai.2020.103779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sine cosine algorithm (SCA) is a new population-based stochastic optimization algorithm, utilizing the oscillating property of the sine cosine function to balance the exploration and exploitation performance of SCA. A hybrid sine cosine algorithm based on the optimal neighborhood and quadratic interpolation strategy (QISCA) was proposed to overcome the shortcoming of updating the population guided by the global optimal individual in the sine cosine algorithm. The new algorithm uses a Stochastic Optimal Neighborhood for neighborhood updates, and it adopts a Quadratic Interpolation curve for individual updates. In addition, QISCA incorporates Quasi-Opposition Learning strategies to enhance the population’s global exploration capabilities, and improves the convergence speed and accuracy. The two simulation experiments of 23 benchmark functions and 30 latest CEC2017 test functions show that the new algorithm can better coordinate the exploration and exploitation capabilities and improve the global optimization ability, compared with the other improved sine cosine algorithm and the representative stochastic optimization algorithm. The three representative engineering problems validate the effectiveness of the new algorithm to solve practical problems.},
  archive      = {J_EAAI},
  author       = {Wen-yan Guo and Yuan Wang and Fang Dai and Peng Xu},
  doi          = {10.1016/j.engappai.2020.103779},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103779},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved sine cosine algorithm combined with optimal neighborhood and quadratic interpolation strategy},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross-scale generative adversarial network for crowd density
estimation from images. <em>EAAI</em>, <em>94</em>, 103777. (<a
href="https://doi.org/10.1016/j.engappai.2020.103777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research develops a cross-scale convolutional spatial generative adversarial network (CSGAN), in order to estimate the crowd density from images accurately. It consists of two similar generators, one for the whole feature extraction, and the other for patch scale feature extraction. An encoder–decoder structure is employed to generate density maps from input images or patches. Additionally, a new objective function for crowd counting called cross-scale consistency pursuit containing an adversarial loss, L2 loss, perceptual loss, and consistency loss, is developed to make the generated density maps more realistic and closer to the ground truth. The effectiveness of the proposed CSGAN is verified in two public datasets. Results indicate that the new objective function is able to reach the most satisfying value of evaluation metrics in both the low-density and high-density crowd scenes when it is compared with other state-of-the-art methods on the test datasets. Moreover, the proposed CSGAN is more practical and flexible due to the smaller computational complexity. Its estimation capability will be significantly improved even in a small size of training data. Overall, this research contributes to the development of a novel computer vision approach together with a new objective function to generate density maps from cross-scale crowd images, enabling the counting process more accurately and efficiently.},
  archive      = {J_EAAI},
  author       = {Gaowei Zhang and Yue Pan and Limao Zhang and Robert Lee Kong Tiong},
  doi          = {10.1016/j.engappai.2020.103777},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103777},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross-scale generative adversarial network for crowd density estimation from images},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotion recognition using speech and neural structured
learning to facilitate edge intelligence. <em>EAAI</em>, <em>94</em>,
103775. (<a
href="https://doi.org/10.1016/j.engappai.2020.103775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotions are quite important in our daily communications and recent years have witnessed a lot of research works to develop reliable emotion recognition systems based on various types data sources such as audio and video. Since there is no apparently visual information of human faces, emotion analysis based on only audio data is a very challenging task. In this work, a novel emotion recognition is proposed based on robust features and machine learning from audio speech. For a person independent emotion recognition system, audio data is used as input to the system from which, Mel Frequency Cepstrum Coefficients (MFCC) are calculated as features. The MFCC features are then followed by discriminant analysis to minimize the inner-class scatterings while maximizing the inter-class scatterings. The robust discriminant features are then applied with an efficient and fast deep learning approach Neural Structured Learning (NSL) for emotion training and recognition. The proposed approach of combining MFCC, discriminant analysis and NSL generated superior recognition rates compared to other traditional approaches such as MFCC-DBN, MFCC-CNN, and MFCC-RNN during the experiments on an emotion dataset of audio speeches. The system can be adopted in smart environments such as homes or clinics to provide affective healthcare. Since NSL is fast and easy to implement, it can be tried on edge devices with limited datasets collected from edge sensors. Hence, we can push the decision-making step towards where data resides rather than conventionally processing of data and making decisions from far away of the data sources. The proposed approach can be applied in different practical applications such as understanding peoples’ emotions in their daily life and stress from the voice of the pilots or air traffic controllers in air traffic management systems.},
  archive      = {J_EAAI},
  author       = {Md. Zia Uddin and Erik G. Nilsson},
  doi          = {10.1016/j.engappai.2020.103775},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103775},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emotion recognition using speech and neural structured learning to facilitate edge intelligence},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimized task distribution based on task requirements and
time delay in edge computing environments. <em>EAAI</em>, <em>94</em>,
103774. (<a
href="https://doi.org/10.1016/j.engappai.2020.103774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing is a new technology for completing real-time and complex tasks with low latency. However, due to limited storage, computing and communication capabilities of edge nodes, it is often necessary for multiple edge nodes to share a task’s related work load to decrease its overall execution time. To solve the problem, this paper proposes a task distribution method based on the analysis of task requirements and time delay in an edge computing environment. First, the related data is received by a proxy server to obtain the running states of edge nodes. Then, a task-based edge node selection algorithm is designed to select appropriate target edge nodes. It can meet task requirements by using a Bloom filter to filter malicious nodes. Finally, based on the above selected nodes, optimized target edge nodes are selected to achieve the minimum time delay. Based on the selected optimized target edge nodes, this paper proposes an algorithm to optimize task distribution for meeting task requirements and achieve the minimum delay in an edge computing environment. Because the method considers both task requirements and time delay, it can distribute tasks to target nodes at low cost. The experimental results show that the method is feasible and effective and outperforms two commonly-used methods},
  archive      = {J_EAAI},
  author       = {PeiYun Zhang and AiQing Zhang and Ge Xu},
  doi          = {10.1016/j.engappai.2020.103774},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103774},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimized task distribution based on task requirements and time delay in edge computing environments},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting algorithms for network intrusion detection: A
comparative evaluation of real AdaBoost, gentle AdaBoost and modest
AdaBoost. <em>EAAI</em>, <em>94</em>, 103770. (<a
href="https://doi.org/10.1016/j.engappai.2020.103770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer networks have been experienced ever-increasing growth since they play a critical role in different aspects of human life. Regarding the vulnerabilities of computer networks, they should be monitored regularly to detect intrusions and attacks by using high-performance Intrusion Detection Systems (IDSs). IDSs try to differentiate between normal and abnormal behaviors to recognize intrusions. Due to the complex behavior of malicious entities, it is crucially important to adopt machine learning methods for intrusion detection with a fine performance and low time complexity. Boosting approach is considered as a way to deal with this challenge. In this paper, we prepare a clear summary of the latest progress in the context of intrusion detection methods, present a technical background on boosting, and demonstrate the ability of the three well-known boosting algorithms (Real Adaboost, Gentle Adaboost, and Modest Adaboost) as IDSs by using five IDS public benchmark datasets. The results show that the Modest AdaBoost has a higher error rate compared to Gentle and Real AdaBoost in IDSs. Besides, in the case of IDSs, Gentle and Real AdaBoost show the same performance as they have about 70% lower error rates compared to Modest Adaboost, however, Modest AdaBoost is about 7% faster than them. In addition, as IDSs need to retrain the model frequently, the results show that Modest AdaBoost has a much lower performance than Gentle and Real AdaBoost in case of error rate stability.},
  archive      = {J_EAAI},
  author       = {Amin Shahraki and Mahmoud Abbasi and Øystein Haugen},
  doi          = {10.1016/j.engappai.2020.103770},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103770},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Boosting algorithms for network intrusion detection: A comparative evaluation of real AdaBoost, gentle AdaBoost and modest AdaBoost},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic learning-from-data approach to the
history-matching problem. <em>EAAI</em>, <em>94</em>, 103767. (<a
href="https://doi.org/10.1016/j.engappai.2020.103767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {History matching is the process whereby the values of uncertain attributes of a reservoir model are changed with the purpose of finding models that match existing reservoir production data. As an inverse and ill-posed problem in engineering, it admits multiple solutions and plays a key role in reservoir management tasks: reservoir models support important and strategic field development decisions and, the more calibrated the models, the higher the confidence on their forecast for the actual reservoir’s performance. In this work, we introduce a stochastic learning-from-data approach to the history-matching problem. With a data-driven nature, the proposed algorithm has dedicated components to handle petrophysical and global uncertain attributes, and generates new solutions using the patterns of attributes present in solutions that are judiciously selected among a set of solutions for each well and variable involved in the history-matching process. We apply our approach to the UNISIM-I-H benchmark, a challenging synthetic case based on the Namorado Field, Campos Basin, Brazil. The results indicate the potential of our learning proposal towards generating multiple solutions that not only match the history data but, most importantly, offer acceptable performance while forecasting field production. Compared with history-matching methodologies previously applied to the same benchmark, our approach produces competitive results in terms of matching quality and forecast capacity, using substantially fewer simulations.},
  archive      = {J_EAAI},
  author       = {Cristina C.B. Cavalcante and Célio Maschio and Denis Schiozer and Anderson Rocha},
  doi          = {10.1016/j.engappai.2020.103767},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103767},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A stochastic learning-from-data approach to the history-matching problem},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An engine-fault-diagnosis system based on sound intensity
analysis and wavelet packet pre-processing neural network.
<em>EAAI</em>, <em>94</em>, 103765. (<a
href="https://doi.org/10.1016/j.engappai.2020.103765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the techniques of sound intensity analysis, incomplete wavelet packet analysis (WPA) and artificial neural network (ANN), a WPA pre-processing method for noise-based engine fault diagnosis (EFD), so-called WPA–ANN model, is presented in this paper. The noises of an EFI gasoline engine under normal and fault states are measured and their contours of sound intensity level (SIL) are calculated by interpolation approach to initially investigate the possibility of a SIL-based EFD. Furthermore, an incomplete WPA model, which consists of a five-level discrete wavelet transform (DWT) and a four-level WPA, is developed and applied to the measured noise signals for extracting fault features of the engine, as is a multi-layered ANN model for engine failure classification by using the extracted features of the noises. To verify the proposed approach, the WPA–ANN model is extended to recognize other noise-related faults of the engine. The results suggest that the noise-based WPA–ANN models are effective for engine fault diagnosis. Due to its time–frequency characteristics and pattern recognition capacity, the WPA–ANN can be used to process both the stationary and nonstationary signals. In view of the applications, the proposed WPA–ANN model can be directly used in vehicle EFDs, and may be extended to other sound-related fields for failure diagnosis in engineering.},
  archive      = {J_EAAI},
  author       = {Y.S. Wang and N.N. Liu and H. Guo and X.L. Wang},
  doi          = {10.1016/j.engappai.2020.103765},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103765},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An engine-fault-diagnosis system based on sound intensity analysis and wavelet packet pre-processing neural network},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new kho-kho optimization algorithm: An application to
solve combined emission economic dispatch and combined heat and power
economic dispatch problem. <em>EAAI</em>, <em>94</em>, 103763. (<a
href="https://doi.org/10.1016/j.engappai.2020.103763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a new optimization technique known as Kho-Kho optimization (KKO) algorithm is presented. This proposed technique is a population based meta-heuristic method which is inspired from the strategies used by players in a well known tag-team game played in India, i.e. Kho-Kho. The performance and superiority of the proposed method with respect to other existing methods is evaluated using twenty nine benchmark functions and real-time optimization problems related to power system i.e. combined emission economic dispatch and combined heat and power economic dispatch problem.},
  archive      = {J_EAAI},
  author       = {Abhishek Srivastava and Dushmanta Kumar Das},
  doi          = {10.1016/j.engappai.2020.103763},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103763},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new kho-kho optimization algorithm: An application to solve combined emission economic dispatch and combined heat and power economic dispatch problem},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep neural network model with bayesian hyperparameter
optimization for prediction of NOx at transient conditions in a diesel
engine. <em>EAAI</em>, <em>94</em>, 103761. (<a
href="https://doi.org/10.1016/j.engappai.2020.103761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to increasing interest in the environment, particularly on air quality, regulations in the automobile industry have become stricter. Test cycles have been substituted to simulate real driving conditions, and they offer opportunities for researchers to satisfy regulations and predict emissions using models. The objective of this study is to develop a deep neural network (DNN) model, optimize its hyperparameters using the Bayesian optimization method, and use hidden-node determination logic to predict engine-out NO x emissions by using the worldwide harmonized light vehicles test procedure (WLTP) of diesel engines. A DNN network learns the internal relationships between inputs and target outputs even though they are complicated. However, the hyperparameters of DNNs are typically determined by researchers before training, and they affected the accuracy of the model. In this study, the hyperparameters of the DNN model such as the number of hidden layers, number of nodes in each hidden layer, learning rate, learning rate decay, and batch size are automatically optimized using the Bayesian optimization method. Some logical equations are combined with the number of nodes in the first hidden layer and the number of hidden layers to realize the model’s structure instead of using the number of hidden nodes in each hidden layer. Compared with grid search and random sampling, the Bayesian optimization method is a promising solution to optimize hyperparameters. In addition, a hidden-node determination logic further improved the accuracy of the model. The accuracy of the optimized model is indicated by an R 2 value of 0.9675 with 14 input features. The result of cycle prediction shows that the mean absolute errors are approximately 16–17 ppm for four WLTP cycles, which are 1.6% of the maximum NO x value. These results indicate that the accuracy of the model is comparable to that of a physical NO x measurement device whose linearity is 1% of the full scale (5,000 ppm).},
  archive      = {J_EAAI},
  author       = {Seunghyup Shin and Youngbok Lee and Minjae Kim and Jihwan Park and Sangyul Lee and Kyoungdoug Min},
  doi          = {10.1016/j.engappai.2020.103761},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103761},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep neural network model with bayesian hyperparameter optimization for prediction of NOx at transient conditions in a diesel engine},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scoring and assessment in medical VR training simulators
with dynamic time series classification. <em>EAAI</em>, <em>94</em>,
103760. (<a
href="https://doi.org/10.1016/j.engappai.2020.103760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes and evaluates scoring and assessment methods for Virtual Reality (VR) training simulators. VR simulators capture detailed n-dimensional human motion data which is useful for performance analysis. Custom made medical haptic VR training simulators were developed and used to record data from 271 trainees of multiple clinical experience levels. DTW Multivariate Prototyping (DTW-MP) is proposed. VR data was classified as Novice, Intermediate or Expert. Accuracy of algorithms applied for time-series classification were: dynamic time warping 1-nearest neighbor (DTW-1NN) 60%, nearest centroid SoftDTW classification 77.5%, Deep Learning: ResNet 85%, FCN 75%, CNN 72.5% and MCDCNN 28.5%. Expert VR data recordings can be used for guidance of novices. Assessment feedback can help trainees to improve skills and consistency. Motion analysis can identify different techniques used by individuals. Mistakes can be detected dynamically in real-time, raising alarms to prevent injuries.},
  archive      = {J_EAAI},
  author       = {Neil Vaughan and Bogdan Gabrys},
  doi          = {10.1016/j.engappai.2020.103760},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103760},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scoring and assessment in medical VR training simulators with dynamic time series classification},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discriminative sparse embedding based on adaptive graph for
dimension reduction. <em>EAAI</em>, <em>94</em>, 103758. (<a
href="https://doi.org/10.1016/j.engappai.2020.103758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional manifold learning methods usually utilize the original observed data to directly define the intrinsic structure among data. Because the original samples often contain a deal of redundant information or it is corrupted by noises, it leads to the unreliability of the obtained intrinsic structure. In addition, the intrinsic structure learning and subspace learning are completely separated. For solving above problems, this paper presents a novel dimension reduction method termed discriminative sparse embedding (DSE) based on adaptive graph. By projecting the original samples into a low-dimensional subspace, DSE learns a sparse weight matrix, which can reduce the effects of redundant information and noises of the original data, and uncover essential structural relationship among the data. In DSE, the robust subspace is learned from the original data. Meanwhile, the intrinsic local structure and the optimal subspace can be simultaneously learned, in which they are mutually improved, and the accurate structure can be captured, and the optimal subspace can be obtained. We propose an alternative and iterative method to solve the DSE model. In order to evaluate the performance of DSE, it is compared with some state-of-the-art feature extraction algorithms. Various experiments show that our DSE is effective and feasible.},
  archive      = {J_EAAI},
  author       = {Zhonghua Liu and Kaiming Shi and Kaibing Zhang and Weihua Ou and Lin Wang},
  doi          = {10.1016/j.engappai.2020.103758},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103758},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discriminative sparse embedding based on adaptive graph for dimension reduction},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trust management and evaluation for edge intelligence in the
internet of things. <em>EAAI</em>, <em>94</em>, 103756. (<a
href="https://doi.org/10.1016/j.engappai.2020.103756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information and Communication Technologies (ICTs) have revolutionised the traditional communication processes, converting the cities into Smart Cities. Internet of Things (IoT) is one of the leading frameworks in Smart Cities realm; it is based on heterogeneous infrastructure, digital systems, smart technologies, and intelligent services. Due to the complex networks supporting the IoT world, smart devices and services are quickly degrading due to various factors. Security is one of the considered factors, and it also represents a difficult challenge. Malicious nodes disrupt the data traffic and integrity of IoT-based networks. This paper presents a novel Cumulative Trust Evaluation based Efficient Technique (CTBET) by singling out numerous viewpoints on governing and implementing the security in edge-based IoT networks. The proposed CTBET is based on the cumulative trust concept, which calculates the direct and indirect trust among nodes considering the packet drop rate and the packet data rate among different transmission nodes. Furthermore, it enforces suitable approaches to implement the trust mechanism based technique to enhance security and privacy. The proposed scheme handles the On-Off, Denial of Service (DoS) and Bad-Mouth attacks and is also able to isolate the malicious nodes in edge-based IoT networks. The provided simulation results show encouraging performance in terms of network life span, level of trustworthiness of nodes, lesser end-to-end delay and high data delivery ratio, during data transmission in the presence of the malicious and selfish nodes in the network.},
  archive      = {J_EAAI},
  author       = {Kashif Naseer Qureshi and Abeer Iftikhar and Shahid Nazeer Bhatti and Francesco Piccialli and Fabio Giampaolo and Gwanggil Jeon},
  doi          = {10.1016/j.engappai.2020.103756},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103756},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Trust management and evaluation for edge intelligence in the internet of things},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time prediction of process forces in milling operations
using synchronized data fusion of simulation and sensor data.
<em>EAAI</em>, <em>94</em>, 103753. (<a
href="https://doi.org/10.1016/j.engappai.2020.103753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To prevent undesirable effects during milling processes, online predictions of upcoming events can be used. Process simulations enable the capability to retrieve additional knowledge about the process, since their application allows the generation of data about characteristics, which cannot be measured during the process and can be incorporated as pre-calculated features into the analysis. Furthermore, sensor technologies were used as reasonable data sources for analyzing different monitoring scopes of milling processes. Machine learning-based models utilize data, acquired by various available data sources, to generate predictions of upcoming events in real-time. In this paper, we propose a novel approach for combining simulation data with sensor data to generate online predictions of process forces, which are influenced by tool wear, using an ensemble-based machine learning method. In addition, a methodology was developed in order to synchronize pre-calculated simulation data and streaming sensor measurements in real time. Milling experiments using ball-end milling tools with varying cutting speeds and tooth feeds showed the robustness of the approach in enhancing the prediction accuracy compared to only using one of each data source.},
  archive      = {J_EAAI},
  author       = {Felix Finkeldey and Amal Saadallah and Petra Wiederkehr and Katharina Morik},
  doi          = {10.1016/j.engappai.2020.103753},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103753},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of process forces in milling operations using synchronized data fusion of simulation and sensor data},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The heterogeneous vehicle routing problem with time windows
and a limited number of resources. <em>EAAI</em>, <em>94</em>, 103745.
(<a href="https://doi.org/10.1016/j.engappai.2020.103745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the heterogeneous vehicle routing problem with time windows and a limited number of resources (HVRPTW-LR), a practical extension of the classical vehicle routing problem in which routes to be designed share common scarce resources. The HVRPTW-LR arises when a limited number of resources, such as vehicles, drivers, instruments, and so on, are available but are insufficient to serve all customers in a route planning. Therefore, the route design involves the selection of customers to be visited at each route and resources to be used. Applications to this problem are found in real services companies with high seasonal demand which attend to different types of works and have to decide on how to effectively manage their resources. For designing optimal routes, a hierarchical objective function is considered, maximizing the total number of served customers as the primary objective, and minimizing the travel costs as secondary. A mathematical model of linear programming is introduced to describe and understand all constraints clearly. The problem is first heuristically solved by a semi-parallel insertion heuristic. Then, solutions are improved by a hybrid variable neighborhood descent metaheuristic based on a Tabu Search algorithm for the exploration of the neighborhood and a holding list. Experiments are conducted on numerous sets of benchmark instances from the literature to evaluate the performance of the proposed algorithm. Results show that the algorithm proposed in this paper has a good performance and can be easily applied for solving numerous vehicle routing problem variants from the literature. A new set of benchmark cases for the HVRPTW-LR are also presented and solved.},
  archive      = {J_EAAI},
  author       = {Jose C. Molina and Jose L. Salmeron and Ignacio Eguia and Jesus Racero},
  doi          = {10.1016/j.engappai.2020.103745},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103745},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The heterogeneous vehicle routing problem with time windows and a limited number of resources},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi level directional cross binary patterns: New
handcrafted descriptor for SVM-based texture classification.
<em>EAAI</em>, <em>94</em>, 103743. (<a
href="https://doi.org/10.1016/j.engappai.2020.103743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pattern recognition and computer vision have experienced a prominent progress in feature extraction techniques, judged by the extensive proposed methods in the literature. A big part of these works was devoted to enhance the texture classification performance, regarding the important role of textural analysis in various real-world and challenging applications. Developing discriminant feature extractors requires solid knowledge in machine learning and applied mathematics. However, Local Binary Patterns (LBP) offered much more space to develop enhanced handcrafted descriptors thanks to its simplicity and flexibility. In this paper we introduce a brand new LBP variant referred to as Multi Level Directional Cross Binary Patterns (MLD-CBP). The proposed representation is training-free, low-dimensional, yet discriminative and robust handcrafted operator for texture description. The concept of the proposed MLD-CBP descriptor is based on encoding the most informative directions contained within multi radiuses, which helps in detecting the gray level variations that may occur in different directions. Moreover, the proposed MLD-CBP handcrafted is combined with an automated SVM classifier based on the RBF Kernel, where the γ parameter is calculated automatically according to the training images. Conducted experiments on 15 well known and challenging databases of the literature, demonstrate prominent performance and stability compared to the results achieved by 30 recent and most powerful descriptors of the state-of-the-art. This paper provides also a comparative study on the effect of γ parameter to show the benefits of automatically tuning this parameter value considering the nature of the database and its size.},
  archive      = {J_EAAI},
  author       = {M. Kas and I. El khadiri and Y. El merabet and Y. Ruichek and R. Messoussi},
  doi          = {10.1016/j.engappai.2020.103743},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103743},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi level directional cross binary patterns: New handcrafted descriptor for SVM-based texture classification},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extra-adaptive robust online subspace tracker for anomaly
detection from streaming networks. <em>EAAI</em>, <em>94</em>, 103741.
(<a href="https://doi.org/10.1016/j.engappai.2020.103741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in time-evolving networks has many applications, for instance, traffic analysis in transportation networks and intrusion detection in computer networks. One group of popular methods for anomaly detection from evolving networks are robust online subspace trackers. However, these methods suffer from problem of insensitivity to drastic changes in the evolving subspace. In order to solve this problem, we propose a new robust online subspace and anomaly tracker, which is more adaptive and robust against sudden drastic changes in the subspace. More accurate estimation of low rank and sparse components by this tracker leads to more accurate anomaly detection. We evaluate the accuracy of our method with real-world dynamic network data sets with varying sparsity levels. The result is promising and our method outperforms the state-of-the-art.},
  archive      = {J_EAAI},
  author       = {Maryam Amoozegar and Behrouz Minaei-Bidgoli and Mansoor Rezghi and Hadi Fanaee-T},
  doi          = {10.1016/j.engappai.2020.103741},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103741},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extra-adaptive robust online subspace tracker for anomaly detection from streaming networks},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-agent system for guiding users in on-line social
environments. <em>EAAI</em>, <em>94</em>, 103740. (<a
href="https://doi.org/10.1016/j.engappai.2020.103740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work is a study of the detection of negative affective or emotional states, the high-stress levels that people have using social network sites (SNSs), and the effect that this negative state or stress level has on the repercussions of posted messages. We aim to discover to what extent a user that has a state detected as negative by an analyzer (Sentiment analyzer and Stress analyzer) can affect other users and generate negative repercussions, and also determine whether it is more suitable to predict a future negative situation using different analyzers. We propose two different methods for creating a combined model of sentiment and stress, and we use them in our experimentation to discern which one is more suitable for predicting future negative situations that could arise from the interaction between users, and in what context. Additionally, we designed a Multi-Agent System (MAS) that integrates the analyzers to protect or advise users on a SNS. We have conducted this study to help build future systems that prevent negative situations where a user that has a negative state creates a repercussion in the SNS. This can help users avoid getting into a bad mood or help avoid privacy issues (e.g. a user that has a negative state posting information that the user does not really want to post).},
  archive      = {J_EAAI},
  author       = {G. Aguado and V. Julian and A. Garcia-Fornes and A. Espinosa},
  doi          = {10.1016/j.engappai.2020.103740},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103740},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-agent system for guiding users in on-line social environments},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards privacy preserving AI based composition framework in
edge networks using fully homomorphic encryption. <em>EAAI</em>,
<em>94</em>, 103737. (<a
href="https://doi.org/10.1016/j.engappai.2020.103737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a privacy-preserving framework for Artificial Intelligence (AI) enabled composition for the edge networks. Edge computing is a very promising technology for provisioning realtime AI services due to low response time and network bandwidth requirements. Due to the lack of computational capabilities, an edge device alone cannot provide the complex AI services. Complex AI tasks should be divided into multiple sub-tasks and distributed among multiple edge devices for efficient service provisioning in the edge network. AI-enabled or automatic service composition is one of the essential AI tasks in the service provisioning. In edge computing-based service provisioning, service composition related tasks need to be offloaded to several edge nodes for efficient service. Edge nodes can be used for monitoring services, storing Quality-of-Service (QoS) data, and composing services to find the best composite service. Existing service composition methods use plaintext QoS data. Hence, attackers may compromise edge devices to reveal QoS data of services and modify them for giving an advantage to particular edge service providers, and the AI-based service composition becomes biased. From that point of view, a privacy-preserving framework for AI-based service composition is required for the edge networks. In our proposed framework, we introduce an AI-based composition model for edge services in the edge networks. Additionally, we present a privacy-preserving AI service composition framework to perform composition on encrypted QoS data using fully homomorphic encryption (FHE) algorithm. We conduct several experiments to evaluate the performance of our proposed privacy-preserving service composition framework using a synthetic QoS dataset.},
  archive      = {J_EAAI},
  author       = {Mohammad Saidur Rahman and Ibrahim Khalil and Mohammed Atiquzzaman and Xun Yi},
  doi          = {10.1016/j.engappai.2020.103737},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103737},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards privacy preserving AI based composition framework in edge networks using fully homomorphic encryption},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Erasable pattern mining based on tree structures with damped
window over data streams. <em>EAAI</em>, <em>94</em>, 103735. (<a
href="https://doi.org/10.1016/j.engappai.2020.103735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several pattern mining methods have been proposed to process dynamic data streams because the data generated in industrial fields is continually accumulated. Erasable pattern mining techniques for processing dynamic data streams are needed to discover erasable patterns from dynamic data streams. In previous erasable pattern mining approaches suggested for dynamic data streams, all data are considered to have the same importance regardless of its timestamp. However, dynamic data streams have the characteristic that the new data is relatively more significant than the old data. In erasable pattern mining, one of the desired techniques is an approach in consideration of such characteristic of data streams. For this reason, we propose an erasable pattern mining algorithm over dynamic data streams based on the damped window model. Since the suggested technique considers the new data more important than the previous data, it can find more useful erasable patterns. In addition, erasable pattern mining based on the damped window model is conducted efficiently by employing the tree and table structures. In performance test, we present that our pruning techniques remove unnecessary operations related to invalid erasable patterns efficiently from damped-window-based data streams. Performance evaluation results using real datasets and synthetic datasets show that the proposed approach has good performance with regard to as execution time, pattern generation, and scalability by comparing between the suggested technique and the state of the art algorithms.},
  archive      = {J_EAAI},
  author       = {Yoonji Baek and Unil Yun and Heonho Kim and Hyoju Nam and Gangin Lee and Eunchul Yoon and Bay Vo and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.engappai.2020.103735},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103735},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Erasable pattern mining based on tree structures with damped window over data streams},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel method for locating the critical slip surface of a
soil slope. <em>EAAI</em>, <em>94</em>, 103733. (<a
href="https://doi.org/10.1016/j.engappai.2020.103733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calculating the minimum slope safety factor or locating the critical slip surface of a soil slope is a complex optimization problem. This paper describes an improved whale optimization algorithm (IWOA) for locating the critical slip surface of a soil slope. Locating a critical slip surface is transformed into a three-dimensional problem from a high-dimensional optimization. Combined with the Morgenstern–Price method, IWOA is compared against other optimization techniques in an experimental study. Test results using 13 benchmark functions show that IWOA significantly outperforms the conventional whale optimization algorithm (WOA) and particle swarm optimization (PSO). The IWOA method is then used to search for the critical slip surfaces of four slopes. The results show that IWOA again performs better than WOA and PSO in locating the critical slip surface.},
  archive      = {J_EAAI},
  author       = {S.H. Li and L.Z. Wu and X.H. Luo},
  doi          = {10.1016/j.engappai.2020.103733},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103733},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel method for locating the critical slip surface of a soil slope},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lévy flight distribution: A new metaheuristic algorithm for
solving engineering optimization problems. <em>EAAI</em>, <em>94</em>,
103731. (<a
href="https://doi.org/10.1016/j.engappai.2020.103731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new metaheuristic algorithm based on Lévy flight called Lévy flight distribution (LFD) for solving real optimization problems. The LFD algorithm is inspired from the Lévy flight random walk for exploring unknown large search spaces (e.g., wireless sensor networks (WSNs). To assess the performance of the LFD algorithm, various optimization test bed problems are considered, namely the congress on evolutionary computation (CEC) 2017 suite and three engineering optimization problems: tension/compression spring, the welded beam, and pressure vessel. The statistical simulation results revealed that the LFD algorithm provides better results with superior performance in most tests compared to several well-known metaheuristic algorithms such as simulated annealing (SA), differential evolution (DE), particle swarm optimization (PSO), elephant herding optimization (EHO), the genetic algorithm (GA), moth-flame optimization algorithm (MFO), whale optimization algorithm (WOA), grasshopper optimization algorithm (GOA), and Harris Hawks Optimization (HHO) algorithm. Furthermore, the performance of the LFD algorithm is tested on other different optimization problems of unknown large search spaces such as the area coverage problem in WSNs. The LFD algorithm shows high performance in providing a good deployment schema than energy-efficient connected dominating set (EECDS), A3, and CDS-Rule K topology construction algorithms for solving the area coverage problem in WSNs. Eventually, the LFD algorithm performs successfully achieving a high coverage rate up to 43.16 %, while the A3, EECDS, and CDS-Rule K algorithms achieve low coverage rates up to 40 % based on network sizes used in the simulation experiments. Also, the LFD algorithm succeeded in providing a better deployment schema than A3, EECDS, and CDS-Rule K algorithms and enhancing the detection capability of WSNs by minimizing the overlap between sensor nodes and maximizing the coverage rate. The source code is currently available for public from: https://www.mathworks.com/matlabcentral/fileexchange/76103-lfd .},
  archive      = {J_EAAI},
  author       = {Essam H. Houssein and Mohammed R. Saad and Fatma A. Hashim and Hassan Shaban and M. Hassaballah},
  doi          = {10.1016/j.engappai.2020.103731},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103731},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lévy flight distribution: A new metaheuristic algorithm for solving engineering optimization problems},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust master planning of a socially responsible supply
chain under fuzzy-stochastic uncertainty (a case study of clothing
industry). <em>EAAI</em>, <em>94</em>, 103715. (<a
href="https://doi.org/10.1016/j.engappai.2020.103715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an integrated physical supply channel, aggregate production, and transportation planning problem through the lens of social sustainability under uncertainty. The three-echelon supply chain network includes multiple suppliers, a manufacturer and multiple distribution centres. Social-related criteria such as workers’ job-security and health (i.e. working conditions) and social investment are contemplated in the supply chain under consideration. In doing so, a chance constraint mixed integer non-linear programming model is built to determine the centralized planning of procurement-production-transportation under fuzzy-stochastic uncertainty over the tactical planning horizon. Moreover, an efficient hybrid solution procedure is developed utilizing convexification and defuzzification strategies. Finally, a real-case study in clothing industry is presented to show the model applicability and the solution procedure efficiency.},
  archive      = {J_EAAI},
  author       = {R. Ghasemy Yaghin and P. Sarlak and A.A. Ghareaghaji},
  doi          = {10.1016/j.engappai.2020.103715},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103715},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust master planning of a socially responsible supply chain under fuzzy-stochastic uncertainty (A case study of clothing industry)},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Precise object detection using adversarially augmented
local/global feature fusion. <em>EAAI</em>, <em>94</em>, 103710. (<a
href="https://doi.org/10.1016/j.engappai.2020.103710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection, which aims at recognizing or locating the objects of interest in remote sensing imagery with high spatial resolutions (HSR), plays a significant role in many real-world scenarios, e.g., environment monitoring, urban planning, civil infrastructure construction, disaster rescuing, and geographic image retrieval. As a long-lasting challenging problem in both machine learning and geoinformatics communities, many approaches have been proposed to tackle it. However, previous methods always overlook the abundant information embedded in the HSR remote sensing images. The effectiveness of these methods, e.g., accuracy of detection, is therefore limited to some extent. To overcome the mentioned challenge, in this paper, we propose a novel two-phase deep framework, dubbed GLGOD-Net, to effectively detect meaningful objects in HSR images. GLGOD-Net firstly attempts to learn the enhanced deep representations from super-resolution image data. Fully utilizing the augmented image representations, GLGOD-Net then learns the fused representations into which both local and global latent features are implanted. Such fused representations learned by GLGOD-Net can be used to precisely detect different objects in remote sensing images. The proposed framework has been extensively tested on a real-world HSR image dataset for object detection and has been compared with several strong baselines. The remarkable experimental results validate the effectiveness of GLGOD-Net. The success of GLGOD-Net not only advances the cutting-edge of image data analytics, but also promotes the corresponding applicability of deep learning in remote sensing imagery.},
  archive      = {J_EAAI},
  author       = {Xiaobing Han and Tiantian He and Yew-Soon Ong and Yanfei Zhong},
  doi          = {10.1016/j.engappai.2020.103710},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103710},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Precise object detection using adversarially augmented local/global feature fusion},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Surrogate-assisted parallel tempering for bayesian neural
learning. <em>EAAI</em>, <em>94</em>, 103700. (<a
href="https://doi.org/10.1016/j.engappai.2020.103700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the need for robust uncertainty quantification, Bayesian neural learning has gained attention in the era of deep learning and big data. Markov Chain Monte-Carlo (MCMC) methods typically implement Bayesian inference which faces several challenges given a large number of parameters, complex and multimodal posterior distributions, and computational complexity of large neural network models. Parallel tempering MCMC addresses some of these limitations given that they can sample multimodal posterior distributions and utilize high-performance computing. However, certain challenges remain given large neural network models and big data. Surrogate-assisted optimization features the estimation of an objective function for models which are computationally expensive. In this paper, we address the inefficiency of parallel tempering MCMC for large-scale problems by combining parallel computing features with surrogate assisted likelihood estimation that describes the plausibility of a model parameter value, given specific observed data. Hence, we present surrogate-assisted parallel tempering for Bayesian neural learning for simple to computationally expensive models. Our results demonstrate that the methodology significantly lowers the computational cost while maintaining quality in decision making with Bayesian neural networks. The method has applications for a Bayesian inversion and uncertainty quantification for a broad range of numerical models.},
  archive      = {J_EAAI},
  author       = {Rohitash Chandra and Konark Jain and Arpit Kapoor and Ashray Aman},
  doi          = {10.1016/j.engappai.2020.103700},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103700},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surrogate-assisted parallel tempering for bayesian neural learning},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault diagnosis model based on granular computing and echo
state network. <em>EAAI</em>, <em>94</em>, 103694. (<a
href="https://doi.org/10.1016/j.engappai.2020.103694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to improve the efficiency and accuracy of electronic equipment fault diagnosis, a fault diagnosis model based on Granular Computing and Echo State Network (ESN) is proposed. Firstly, the attribute reduction of test index is carried out based on granular computing model. An attribute distinguishing ability index is defined based on attribute value influence degree. As the basis of similarity measure, a number of attribute granules of similar distinguish are obtained through affinity propagation clustering algorithm, then fault attribute reduction was completed by selecting clustering center attributes. In the stage of fault identification by ESN, in order to improve the dynamic adaptability of ESN reservoir to samples, Bienenstock–Cooper–Munro(BCM) rule is introduced into the reservoir construction to train the connection weight matrix. Meanwhile, the L 1 ∕ 2 -norm penalty term is added to the objective function in order to improve the sparsification efficiency, and a smoothing L 1 ∕ 2 -norm regularization term is used to overcome the iterative numerical oscillation problem, the model is solved by using the half threshold iteration method at last. The effectiveness and superiority of the proposed method are verified by a fault diagnosis example of terminal guidance radar signal processing module.},
  archive      = {J_EAAI},
  author       = {Cheng Lu and Peng Xu and Lin-hu Cong},
  doi          = {10.1016/j.engappai.2020.103694},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {103694},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis model based on granular computing and echo state network},
  volume       = {94},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Affinity matrix with large eigenvalue gap for graph-based
subspace clustering and semi-supervised classification. <em>EAAI</em>,
<em>93</em>, 103722. (<a
href="https://doi.org/10.1016/j.engappai.2020.103722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the graph-based learning method, the data graph or similarity matrix reveals the relationship between data, and reflects similar attributes within a class and differences between classes. Inspired by Davis–Kahan Theorem that the stability of matrix eigenvector space depends on its spectral distance (i.e. its eigenvalue gap), in this paper, we propose a global local affinity matrix model with low rank subspace sparse representation (GLAM-LRSR) based on global information of eigenvalue gap and local distance between samples. This method approximate the similarity matrix with ideally diagonal block structure from the perspective of maximizing the eigenvalue gap, and the local distance between data is utilized as a regular term to prevent the eigenvalue gap from being too large to ensure the efficacy of similarity matrix. We have shown that the combination of subspace (LRSR) partitioning method such as Sparse Subspace Clustering(SSC) and the similarity matrix constructed by GLAM can improve the accuracy of subspace clustering, and that the similarity matrix constructed by GLAM-LRSR can be successfully applied to graph-based semi-supervised classification task. Our experiments on synthetic data as well as the real-world datasets for face clustering, face recovery and motion segmentation have clearly demonstrate the significant advantages of GLAM-LRSR and its effectiveness.},
  archive      = {J_EAAI},
  author       = {Xiaofang Liu and Jun Wang and Dansong Cheng and Feng Tian and Yongqiang Zhang},
  doi          = {10.1016/j.engappai.2020.103722},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103722},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Affinity matrix with large eigenvalue gap for graph-based subspace clustering and semi-supervised classification},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A state of the art review on condition assessment models
developed for sewer pipelines. <em>EAAI</em>, <em>93</em>, 103721. (<a
href="https://doi.org/10.1016/j.engappai.2020.103721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to achieve an efficient and a successful operation and maintenance plan for assets, management personnel should have detailed information on the condition of the assets to make informed strategic decisions and properly plan expenditure of capital investments. Condition assessment models for sewage pipelines can be considered as a helpful tool to achieve such objective and from which a decision regarding the required and appropriate intervention can be made. This paper presents a review for the different physical, Artificial Intelligence and statistical models that have been developed to assess the condition of sewage pipelines over a period from 1998 through 2019. The description of different techniques used in building the condition assessment models, and the data required to construct these models are presented. In addition, the major disadvantages and limitations of using these techniques in developing the models have also been discussed. The conducted literature review indicates that various condition assessment models were capable of precisely forecasting the future condition of sewer pipelines. Most of the developed assessment models have been validated with various identified techniques to ensure the adequacy of the predictions. The main problem in model development arises from data availability and liability as several factors were identified by researchers to impact the deterioration of sewer pipelines. In order to overcome this problem, municipalities must utilize the new emerging technologies to facilitate gathering the required dataset in a complete and precise manner. Also, certain techniques such as evidential reasoning or Bayesian Belief Network can be used due to their capabilities in dealing with missing data. Furthermore, the influence of the factors on the pipe condition were identified by some researchers. Although there were discrepancies in the findings, but the majority concluded that both age and material factors have high influence and pipe slope has low influence.},
  archive      = {J_EAAI},
  author       = {Alaa Hawari and Firas Alkadour and Mohamed Elmasry and Tarek Zayed},
  doi          = {10.1016/j.engappai.2020.103721},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103721},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A state of the art review on condition assessment models developed for sewer pipelines},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A memory guided sine cosine algorithm for global
optimization. <em>EAAI</em>, <em>93</em>, 103718. (<a
href="https://doi.org/10.1016/j.engappai.2020.103718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world optimization problems demand an algorithm which properly explores the search space to find a good solution to the problem. The sine cosine algorithm (SCA) is a recently developed and efficient optimization algorithm, which performs searches using the trigonometric functions sine and cosine. These trigonometric functions help in exploring the search space to find an optimum. However, in some cases, SCA becomes trapped in a sub-optimal solution due to an inefficient balance between exploration and exploitation. Therefore, in the present work, a balanced and explorative search guidance is introduced in SCA for candidate solutions by proposing a novel algorithm called the memory guided sine cosine algorithm (MG-SCA). In MG-SCA, the number of guides is decreased with increase in the number of iterations to provide a sufficient balance between exploration and exploitation. The performance of the proposed MG-SCA is analysed on benchmark sets of classical test problems, IEEE CEC 2014 problems, and four well known engineering benchmark problems. The results on these applications demonstrate the competitive ability of the proposed algorithm as compared to other algorithms.},
  archive      = {J_EAAI},
  author       = {Shubham Gupta and Kusum Deep and Andries P. Engelbrecht},
  doi          = {10.1016/j.engappai.2020.103718},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103718},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A memory guided sine cosine algorithm for global optimization},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-stationary gaussian process regression applied in
validation of vehicle dynamics models. <em>EAAI</em>, <em>93</em>,
103716. (<a
href="https://doi.org/10.1016/j.engappai.2020.103716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work compares methods to compute confidence bands in a validation task of a vehicle single-track model. The confidence bands are computed from time series by naïve method, Gaussian process regression and heteroscedastic and non-stationary Gaussian process regression. The simulation model considers the epistemic uncertainty of the vehicle mass parameter by Latin hypercube sampling. The validation procedure compares all stochastically simulated time series of the vehicle yaw rate with the confidence band of the reference data. The model is marked as valid if the yaw rate for each time step is within the confidence band of the reference data. The data was challenging due to noise and time-varying variance and smoothness. Due to required data pre-processing and the high sensitivity to noise in the reference data, the naïve method has generated unusable confidence bands and cannot be recommended for similar validation tasks. Gaussian process regression solved the problem of noise sensitivity, but was not able to model the time-varying length scale of the reference data. Therefore, heteroscedastic and non-stationary Gaussian process regression is proposed to calculate accurate confidence bands of time-varying and noisy reference data for the validation of dynamic models by a confidence band approach.},
  archive      = {J_EAAI},
  author       = {Stephan Rhode},
  doi          = {10.1016/j.engappai.2020.103716},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103716},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-stationary gaussian process regression applied in validation of vehicle dynamics models},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Regenerative braking system modeling by fuzzy q-learning.
<em>EAAI</em>, <em>93</em>, 103712. (<a
href="https://doi.org/10.1016/j.engappai.2020.103712">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regeneration factor, that expresses the ratio between the energy recovered to the battery during braking and the total braking energy, is difficult to be measured from independent instruments. In this paper, a reinforcement learning (RL) method is used to adjust and improve a fuzzy logic model for regenerative braking (FLmRB) for modeling Electric Vehicles’ (EV) regenerative braking systems (RBSs). With the proposed approach, a specialist can infer the regeneration factor, by tuning the model for a specific EV using real data gathered from field tests, using as inputs, only variables measured from independent instruments, namely EV acceleration and jerk, and road inclination. The proposed approach was tested with real data sets of the Nissan Leaf EV. Twelve short-distance data sets in urban areas were collected to learn the regeneration factor, and two long-distance data sets in urban and sub-urban areas were used to validate the learned models. The results show that the learning method can successfully learn the regenerative braking factor improving the previously proposed FLmRB model approach which is based on manual design of the model.},
  archive      = {J_EAAI},
  author       = {Ricardo Maia and Jérôme Mendes and Rui Araújo and Marco Silva and Urbano Nunes},
  doi          = {10.1016/j.engappai.2020.103712},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103712},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Regenerative braking system modeling by fuzzy Q-learning},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Survival analysis of failures based on hawkes process with
weibull base intensity. <em>EAAI</em>, <em>93</em>, 103709. (<a
href="https://doi.org/10.1016/j.engappai.2020.103709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we construct a Hawkes process with time-varying base intensity to model the sequence of failure, i.e., failure events of the compressor station, and we combine survival analysis and point process model on various failure events of the compressor station based on Hawkes process. To our best knowledge, until now, nearly all relevant literature of the Hawkes point processes assumes that the base intensity of the conditional intensity function is time-invariant. This assumption is apparently too harsh to be verified. For example, in the practical application, including financial analysis, reliability analysis, survival analysis and social network analysis, the truth variation of the base intensity of the failure occurrence over time is not constant. The constant base intensity will not reflect the base intensity trend of the failure occurring over time. Thus, in order to solve this problem, in this paper, we propose a new time-varying base intensity, e.g. which is treated as obeying Weibull distribution. First, we introduce the base intensity into a Hawkes process that obeys the Weibull distribution, and then we propose an effective learning algorithm based on the maximum likelihood estimator. Experiments on the constant base intensity synthetic data, time-varying base intensity synthetic data, and real-world data show that our method can learn the triggering patterns of the Hawkes processes and the time-varying base intensity simultaneously and robustly. Experiments on real-world data also reveal the Granger causality of different types of failures and the base probability of failure varying over time. We put forward some suggestions for practical production based on the experimental results.},
  archive      = {J_EAAI},
  author       = {Lu-ning Zhang and Jian-wei Liu and Xin Zuo},
  doi          = {10.1016/j.engappai.2020.103709},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103709},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Survival analysis of failures based on hawkes process with weibull base intensity},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-parametric spatially constrained local prior for scene
parsing on real-world data. <em>EAAI</em>, <em>93</em>, 103708. (<a
href="https://doi.org/10.1016/j.engappai.2020.103708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene parsing aims to recognize the object category of every pixel in scene images, and it plays a central role in image content understanding and computer vision applications. However, accurate scene parsing from unconstrained real-world data is still a challenging task. In this paper, we present the non-parametric Spatially Constrained Local Prior (SCLP) for scene parsing on realistic data. For a given query image, the non-parametric SCLP is learnt by first retrieving a subset of most similar training images to the query image and then collecting prior information about object co-occurrence statistics between spatial image blocks and between adjacent superpixels from the retrieved subset. The SCLP is powerful in capturing both long- and short-range context about inter-object correlations in the query image and can be effectively integrated with traditional visual features to refine the classification results. Our experiments on the SIFT Flow and PASCAL-Context benchmark datasets show that the non-parametric SCLP used in conjunction with superpixel-level visual features achieves one of the top performance compared with state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Ligang Zhang},
  doi          = {10.1016/j.engappai.2020.103708},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103708},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-parametric spatially constrained local prior for scene parsing on real-world data},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhanced fault diagnosis method using conditional gaussian
network for dynamic processes. <em>EAAI</em>, <em>93</em>, 103704. (<a
href="https://doi.org/10.1016/j.engappai.2020.103704">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying fault detection and diagnosis (FDD) technology to the process industry can help to detect faults in time and minimize their impact. The purpose of this study is to propose an enhanced fault diagnosis method under a Conditional Gaussian Network(CGN) efficient and suitable for dynamic processes fault monitoring. The key paths are as follows: first, a time series model is established for the process data and decomposed into time-dependent components and time-independent components; second, time-dependent components are discarded and time-independent components void of auto-correlation are considered instead of the original data to learn the CGN model. A numerical simulation case is used to illustrate the interest of our proposal. The effectiveness of the proposed method is further verified and compared on the Tennessee Eastman Process (TEP). The obtained results show that our method has high and better accuracies regarding the diagnosis of known and unknown faults in dynamic processes.},
  archive      = {J_EAAI},
  author       = {Chuyue Lou and Xiangshun Li and M. Amine Atoui and Jin Jiang},
  doi          = {10.1016/j.engappai.2020.103704},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103704},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhanced fault diagnosis method using conditional gaussian network for dynamic processes},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting an airport ground access mode using novel fuzzy
LBWA-WASPAS-h decision making model. <em>EAAI</em>, <em>93</em>, 103703.
(<a href="https://doi.org/10.1016/j.engappai.2020.103703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Airports are critical in ensuring a fast way of transporting people and goods. Choosing a reliable, fast and comfortable access mode to the airport is vital to ensure a seamless aviation system. The aim of this study is to select the best transport mode for Istanbul’s newly constructed Istanbul Airport. One of the largest airports in the world with 150,000 passenger capacity per year, Istanbul Airport is located in the northern part of Istanbul, outside the city. However, the access to the new airport resulted in many controversies about the selection of the best mode. Underground metro, bus rapid transit (BRT), light rail transit (LRT) and premium bus services are put forward as alternative ground access modes. These alternatives are evaluated based on 4 main decision criteria including financial aspects, operating features, project characteristics and environmental sustainability, which are broken down into 14 sub-criteria. In this paper, the importance weights of the criteria are determined by novel fuzzy Level Based Weight Assessment (LBWA) which is capable of modelling human thinking. Afterwards, the traditional Weighted Aggregated Sum Product Assessment (WASPAS) method is enhanced by the integration of the fuzzy Weighted Heronian Mean (WHM) and fuzzy Weighted Geometric Heronian Mean (WGHM) functions. A hybrid fuzzy multi-criteria decision making method based on LBWA-WASPAS-H model is used to solve this ground access mode selection problem. The results show that an underground metro is the most optimal mode, followed by LRT, BRT, and premium bus services.},
  archive      = {J_EAAI},
  author       = {Dragan Pamucar and Muhammet Deveci and Fatih Canıtez and Vesko Lukovac},
  doi          = {10.1016/j.engappai.2020.103703},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103703},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Selecting an airport ground access mode using novel fuzzy LBWA-WASPAS-H decision making model},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The PRISMA hand i: A novel underactuated design and
EMG/voice-based multimodal control. <em>EAAI</em>, <em>93</em>, 103698.
(<a href="https://doi.org/10.1016/j.engappai.2020.103698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novel underactuated design of the PRISMA HAND I and its multimodal control based on integrated electromyographic signals and voice commands is presented. Due to limitations of EMG sensors and residual physiological signals of amputees, a smart solution utilizing a voice recognition module has been integrated into the EMG control to realize advanced intuitive commands and easy connection with the arm. Inspired by neuroscience studies on the human hand, two motor synergies have been implemented. The thumb adduction/abduction independent motion allows in-hand manipulation. The transmission system is based on whiffletree and pulleys for motion differentiation and on antagonistic elastic tendons. Using EMG and voice commands, the motors are moved together in a certain number of combination suitably and easily programmed using Arduino electronic prototyping. The use of a current sensor allows controlling the strength of the grasp to handle also fragile objects. The contributions of this work are: the bio-inspired design of kinematics and motion couplings by means of two motor synergies, the simple and efficient control interface allowing easy connection to the arm and intuitive use, finally, the cost reduction using economic hardware and mechanical components while preserving performance.},
  archive      = {J_EAAI},
  author       = {Fanny Ficuciello and Giulio Pisani and Salvatore Marcellini and Bruno Siciliano},
  doi          = {10.1016/j.engappai.2020.103698},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103698},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The PRISMA hand i: A novel underactuated design and EMG/voice-based multimodal control},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Addressing unequal area facility layout problems with the
coral reef optimization algorithm with substrate layers. <em>EAAI</em>,
<em>93</em>, 103697. (<a
href="https://doi.org/10.1016/j.engappai.2020.103697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Unequal Area Facility Layout Problem (UA-FLP) is a relevant task in industrial manufacturing, in which the disposition of a number of facilities (or departments ) in a manufacturing system must be obtained, under several optimization criteria and different constraints. The UA-FLP is a hard optimization problem, in which traditional optimization techniques do not obtain good results. Thus, it has been successfully tackled with different heuristics and meta-heuristics in the last years. In this work we address the UA-FLP with a multi-method ensemble approach, the Coral Reefs Optimization algorithm with Substrate Layers (CRO-SL). It is a novel multi-method evolutionary algorithm that encourages the evolution of several searching procedures at the same time over a single population. The CRO-SL has been previously applied to very difficult optimization problems, obtaining excellent performance. In this case, we adapt the CRO-SL to the UA-FLP, by means of increasing the diversity generation within the algorithm, which is helpful to improve the exploration of the searching space, avoiding to fall into local minima. Specifically, we propose to include several reproduction mechanisms (adapted to the UA-FLP) within each substrate of the algorithm, which will highly increase the diversity generation in the CRO-SL. An exhaustive experimental study of the CRO-SL performance in a large number of UA-FLP instances is carried out, including a comparison with the state-of-the-art algorithms for this problem. We will show the ability of the CRO-SL to reach or surpass the best-known solutions in most of the tested UA-FLP cases.},
  archive      = {J_EAAI},
  author       = {L. Garcia-Hernandez and J.A. Garcia-Hernandez and L. Salas-Morera and C. Carmona-Muñoz and N.S. Alghamdi and J. Valente de Oliveira and S. Salcedo-Sanz},
  doi          = {10.1016/j.engappai.2020.103697},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103697},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Addressing unequal area facility layout problems with the coral reef optimization algorithm with substrate layers},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural hole-based approach to control public opinion in
a social network. <em>EAAI</em>, <em>93</em>, 103690. (<a
href="https://doi.org/10.1016/j.engappai.2020.103690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural hole spanners play an important role in information diffusion. Compared with opinion leaders, structural hole spanners have better locations in social networks to expand the scope of information diffusion. In the past, researchers focused on evolution rules and opinion dynamics environments to monitor and even manage public opinion. In this study, we propose a novel structural-hole-based approach to control public opinion in social networks, hereinafter referred to as the SHCPO approach. We discuss the influence of both ordinary agents and structural hole spanners on opinion evolution using our improved Friedkin–Johnsen (FJ) model. Further, we analyze the evolution tendency of public opinion, which leads to the final consensus of public opinion, via the FJ model with ordinary agents in a community and structural hole spanners in joint communities. We reveal three kinds of connections between structural hole spanners and ordinary agents in joint communities. These comprise structural hole spanners connecting (1) two opinion leaders; (2) two ordinary agents; (3) one opinion leader and one ordinary agent. The three connections will lead to different opinion evolution conditions. According to the structural balance theory, we reconstruct the social network by changing the connections between structural hole spanners and agents in different communities. This guides the public opinion tendencies of joint communities towards the positive. Experimental results demonstrate beneficial effects of the SHCPO approach. We use three evaluation indicators to compare the SHCPO approach to five alternative methods. The percentage of positive opinions is used as an evaluation indicator. The SHCPO approach, compared with adding informed agents, add edges, the method from WWW and varying susceptibility to persuasion method, which guide the agent with a negative opinion towards positive opinion, has improved about 17%, 10%, 9%, 1%, respectively.},
  archive      = {J_EAAI},
  author       = {Cheng Gong and Yajun Du and Xianyong Li and Xiaoliang Chen and Xiaoying Li and Yakun Wang and Qiaoyu Zhou},
  doi          = {10.1016/j.engappai.2020.103690},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103690},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structural hole-based approach to control public opinion in a social network},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A deep fusion model based on restricted boltzmann machines
for traffic accident duration prediction. <em>EAAI</em>, <em>93</em>,
103686. (<a
href="https://doi.org/10.1016/j.engappai.2020.103686">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents causing nonrecurrent congestion can decrease the capacity of highways and increase car emissions. Some models in previous studies have been built based on artificial intelligence or statistical theory because estimating the duration of an accident can aid traffic operation and management. However, only characteristics of traffic accidents were considered in most models; the spatial–temporal correlations of traffic flow were always ignored. In this study, a deep fusion model, which can simultaneously handle categorical and continuous variables, is proposed. The model considers not only the characteristics of traffic accidents but also the spatial–temporal correlations in traffic flow. In this model, a stacked restricted Boltzmann machine (RBM) is used to handle the categorical variables, a stacked Gaussian-Bernoulli RBM is used to handle the continuous variables, and a joint layer is used to fuse the extracted features. With extracted I-80 data, the performance of the proposed model was evaluated and compared to some benchmark models. Furthermore, the target variable (duration) was divided into ten groups, and then the evaluation criteria of the models of each group were calculated. The results show that the novel model outperforms some previous models and that the fusion of different types of variables can improve prediction accuracy. In conclusion, the proposed model can fully mine nonlinear and complex patterns in traffic accident data and traffic flow data. The fusion of features is important to predict traffic accident durations.},
  archive      = {J_EAAI},
  author       = {Linchao Li and Xi Sheng and Bowen Du and Yonggang Wang and Bin Ran},
  doi          = {10.1016/j.engappai.2020.103686},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103686},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep fusion model based on restricted boltzmann machines for traffic accident duration prediction},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Auto-adaptive multi-scale laplacian pyramids for modeling
non-uniform data. <em>EAAI</em>, <em>93</em>, 103682. (<a
href="https://doi.org/10.1016/j.engappai.2020.103682">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel-based techniques have become a common way for describing the local and global relationships of data samples that are generated in real-world processes. In this research, we focus on a multi-scale kernel based technique named Auto-adaptive Laplacian Pyramids (ALP). This method can be useful for function approximation and interpolation. ALP is an extension of the standard Laplacian Pyramids model that incorporates a modified Leave-One-Out Cross Validation procedure, which makes the method stable and automatic in terms of parameters selection without extra cost. This paper introduces a new algorithm that extends ALP to fit datasets that are non-uniformly distributed. In particular, the optimal stopping criterion will be point-dependent with respect to the local noise level and the sample rate. Experimental results over real datasets highlight the advantages of the proposed multi-scale technique for modeling and learning complex, high dimensional data.},
  archive      = {J_EAAI},
  author       = {Ángela Fernández and Neta Rabin and Dalia Fishelov and José R. Dorronsoro},
  doi          = {10.1016/j.engappai.2020.103682},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {103682},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Auto-adaptive multi-scale laplacian pyramids for modeling non-uniform data},
  volume       = {93},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel strategy for classifying perceived video quality
using electroencephalography signals. <em>EAAI</em>, <em>92</em>,
103692. (<a
href="https://doi.org/10.1016/j.engappai.2020.103692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video streaming through the Internet is abundant nowadays. While video quality is continuously demanded, monitoring users’ quality of experience (QoE) is essential when watching video contents. QoE can be evaluated directly through subjective assessment which is the human ground truths; however, such assessment is generally expensive and time consuming, and cannot be implemented in real time. QoE can also be evaluated by video quality models; however, the evaluation is fully based on video contents but human physical states cannot be taken into account. To tackle the limitations, detection of a prominent electroencephalography (EEG) signal feature namely P300 correlated to QoE can be used, when users are viewing videos. P300 is a positive deflection pulse that appears around 300 ms after a significant video distortion appears. QoE can be indicated by P300 pulses. However, the captured EEG signal is generally contaminated with noise. Strong noise generates P300 although video carries no distortion. Hence, detections of P300 patterns are not accurate. In this paper, a double classifier consisting of a first and second classifier is proposed. The first classifier attempts to determine whether the captured EEG feature is abnormal or not, where the abnormal caption behaves opposite to the normal P300 characteristic when showing the distorted video. The second classifier is developed to perform classifications for either normal or abnormal features. We evaluate the performance of the proposed double classifier based on the EEG samples, which are captured when showing video stimuli to participants. The proposed classifier is implemented by the support vector machine and logistic regression, which are commonly used for detection of EEG patterns and are computationally much simpler than deep learning. The performance of the proposed classifier is compared to those of the single classifiers, which determine the QoE directly when the EEG signal is given. Cross-validations showed that generally more than 5% improvement can be achieved by the proposed double classifier. Statistical tests indicate that the proposed double classifier can generally obtain better classification rates than solely using the single classifier at a 97.5% confidence level.},
  archive      = {J_EAAI},
  author       = {Kit Yan Chan and Sebastian Arndt and Ulrich Engelke},
  doi          = {10.1016/j.engappai.2020.103692},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103692},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel strategy for classifying perceived video quality using electroencephalography signals},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A particle swarm optimisation-trained feedforward neural
network for predicting the maximum power point of a photovoltaic array.
<em>EAAI</em>, <em>92</em>, 103688. (<a
href="https://doi.org/10.1016/j.engappai.2020.103688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a feedforward Artificial Neural Network (ANN) technique using experimental data is designed for predicting the maximum power point of a photovoltaic array. An ANN model training strategy is challenging due to the variations in the training and the operation conditions of a photovoltaic system. In order to improve ANN model accuracy, the Particle Swarm Optimisation (PSO) algorithm is utilised to find the best topology and to calculate the optimum initial weights of the ANN model. Hence, the dilemma between computational time and the best-fitting regression of the ANN model is addressed, as well as the mean squared error being minimised. To evaluate the proposed method, a MATLAB/Simulink model for an installed photovoltaic system is developed. Experimental data of a sunny and cloudy day are utilised to determine the average efficiency of this proposed method under varying atmospheric conditions. The results show that the optimised feedforward ANN technique based on the PSO algorithm using real data predicts the maximum power point accurately, achieving hourly average efficiencies of more than 99.67% and 99.30% on the sunny and cloudy day, respectively.},
  archive      = {J_EAAI},
  author       = {Sadeq D. Al-Majidi and Maysam F. Abbod and Hamed S. Al-Raweshidy},
  doi          = {10.1016/j.engappai.2020.103688},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103688},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A particle swarm optimisation-trained feedforward neural network for predicting the maximum power point of a photovoltaic array},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach to solve AI planning problems in graph
transformations. <em>EAAI</em>, <em>92</em>, 103684. (<a
href="https://doi.org/10.1016/j.engappai.2020.103684">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of AI planning is to solve the problems with no exact solution available. These problems usually have a big search space, and planning may not find plans with the least actions and in the shortest time. Recent researches show that using suitable heuristics can help to find desired plans. In planning problems specified formally through graph transformation system (GTS), there are dependencies between applied rules (actions) in the search space. This fact motivates us to solve the planning problem for a small goal (instead of the main goal), extract dependencies from the searched space, and use these dependencies to solve the planning problem for the main goal. In GTS based systems, the nodes of a state (really is a graph) can be grouped due to their type. To create a small (refined) goal, we use a refinement technique to remove the predefined percent of nodes from each group of the main goal. Bayesian Optimization Algorithm (BOA) is then used to solve the planning problem for the refined goal. BOA is an Estimation of Distribution Algorithm (EDA) in which Bayesian networks are used to evolve the solution populations. Actually, a Bayesian network is learned from the current population, and then this network is employed to generate the next population. Since the last Bayesian network learned in BOA has the knowledge about dependencies between applied rules, this network can be used to solve the planning problem for the main goal. Experimental results on four well-known planning domains confirm that the proposed approach finds plans with the least actions and in the lower time compared with the state-of-the-art approaches.},
  archive      = {J_EAAI},
  author       = {Einollah Pira},
  doi          = {10.1016/j.engappai.2020.103684},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103684},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel approach to solve AI planning problems in graph transformations},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A weighted corrective fuzzy reasoning spiking neural p
system for fault diagnosis in power systems with variable topologies.
<em>EAAI</em>, <em>92</em>, 103680. (<a
href="https://doi.org/10.1016/j.engappai.2020.103680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on power system fault diagnosis based on Weighted Corrective Fuzzy Reasoning Spiking Neural P Systems with real numbers (rWCFRSNPSs) to propose a graphic fault diagnosis method, called FD-WCFRSNPS. In the FD-WCFRSNPS, an rWCFRSNPS is proposed to model the logical relationships between faults and potential warning messages triggered by the corresponding protective devices. In addition, a matrix-based reasoning algorithm for the rWCFRSNPS is devised to reason about the fault alarm messages using parallel representations. Besides, a layered modeling method based on rWCFRSNPSs is developed to adapt to topological changes in power systems and a Temporal Order Information Processing Method based on Cause–Effect Networks is designed to correct fault alarm messages before the fault reasoning. Finally, in a case study considering a local subsystem of a 220kV power system, the diagnosis results of five test cases prove that the proposed FD-WCFRSNPS is viable and effective.},
  archive      = {J_EAAI},
  author       = {Tao Wang and Xiaoguang Wei and Jun Wang and Tao Huang and Hong Peng and Xiaoxiao Song and Luis Valencia Cabrera and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.engappai.2020.103680},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103680},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A weighted corrective fuzzy reasoning spiking neural p system for fault diagnosis in power systems with variable topologies},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving physical activity recognition using a new deep
learning architecture and post-processing techniques. <em>EAAI</em>,
<em>92</em>, 103679. (<a
href="https://doi.org/10.1016/j.engappai.2020.103679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Human Activity Recognition system composed of three modules. The first one segments the acceleration signals into overlapped windows and extracts information from each window in the frequency domain. The second module detects the performed activity at each window using a deep learning structure based on Convolutional Neural Networks (CNNs). The first part of this structure has several layers associated to each sensor independently and the second part combines the outputs from all sensors in order to classify the physical activity. The third module integrates the window-level decision in longer periods of time, obtaining a significant performance improvement (from 89.83% to 96.62%). These are the best classification results on the PAMAP2 dataset with a Leave-One-Subject-Out (LOSO) evaluation.},
  archive      = {J_EAAI},
  author       = {Manuel Gil-Martín and Rubén San-Segundo and Fernando Fernández-Martínez and Javier Ferreiros-López},
  doi          = {10.1016/j.engappai.2020.103679},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103679},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving physical activity recognition using a new deep learning architecture and post-processing techniques},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Potential, challenges and future directions for deep
learning in prognostics and health management applications.
<em>EAAI</em>, <em>92</em>, 103678. (<a
href="https://doi.org/10.1016/j.engappai.2020.103678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning applications have been thriving over the last decade in many different domains, including computer vision and natural language understanding. The drivers for the vibrant development of deep learning have been the availability of abundant data, breakthroughs of algorithms and the advancements in hardware. Despite the fact that complex industrial assets have been extensively monitored and large amounts of condition monitoring signals have been collected, the application of deep learning approaches for detecting, diagnosing and predicting faults of complex industrial assets has been limited. The current paper provides a thorough evaluation of the current developments, drivers, challenges, potential solutions and future research needs in the field of deep learning applied to Prognostics and Health Management (PHM) applications.},
  archive      = {J_EAAI},
  author       = {Olga Fink and Qin Wang and Markus Svensén and Pierre Dersin and Wan-Jui Lee and Melanie Ducoffe},
  doi          = {10.1016/j.engappai.2020.103678},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103678},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Potential, challenges and future directions for deep learning in prognostics and health management applications},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An iterated greedy algorithm for the obnoxious p-median
problem. <em>EAAI</em>, <em>92</em>, 103674. (<a
href="https://doi.org/10.1016/j.engappai.2020.103674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The obnoxious p-median problem (OpM) is one of the NP-hard combinatorial optimization problems, in which the goal is to find optimal places to facilities that are undesirable ( e.g. noisy, dangerous, or pollutant) such that the sum of the minimum distances between each non-facility location and its nearest facility is maximized. In this paper, for the first time in the literature, Iterated Greedy (IG) metaheuristic has been applied at a higher level to solve this problem. A powerful composite local search method has also been developed by combining two fast and effective local search algorithms, namely RLS1 and RLS2, which were previously used to solve the OpM. Comprehensive experiments have been conducted to test the performance of the proposed algorithm using a common benchmark for the problem. The computational results show the effectiveness of the IG algorithm that it can find high-quality solutions in a short time. Based on the set of selected instances, the results also reveal that the developed IG algorithm outperforms most of the state-of-the-art algorithms and contributes to the literature with 5 new best-known solutions.},
  archive      = {J_EAAI},
  author       = {Osman Gokalp},
  doi          = {10.1016/j.engappai.2020.103674},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103674},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An iterated greedy algorithm for the obnoxious p-median problem},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modified sauvola binarization for degraded document images.
<em>EAAI</em>, <em>92</em>, 103672. (<a
href="https://doi.org/10.1016/j.engappai.2020.103672">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The binarization of historical documents is a difficult job due to the presence of many degradations. Many existing local binarization techniques use certain manually adjusted parameters. The output of these techniques is much dependent on the value of these parameters. One of such parameters is window size which is kept fixed for the whole text image. The fixed window size will not be able to perform well for images having variable stroke widths and text sizes. The proposed binarization technique (Modified Sauvola) is the modification of state of art Sauvola’s binarization technique. It automatically computes window size dynamically across the image pixel to pixel using the stroke width transform (SWT). This led to reduction in number of manually adjusted parameters. The results are compared with the nine existing techniques using the quantitative measures: FM, PSNR, NRM, MPM, and DRD. The results show that the proposed method outperforms existing methods for images having variable stroke widths and text sizes.},
  archive      = {J_EAAI},
  author       = {Amandeep Kaur and Usha Rani and Gurpreet Singh Josan},
  doi          = {10.1016/j.engappai.2020.103672},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103672},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modified sauvola binarization for degraded document images},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting, locating and recognising human touches in social
robots with contact microphones. <em>EAAI</em>, <em>92</em>, 103670. (<a
href="https://doi.org/10.1016/j.engappai.2020.103670">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many situations in our daily life where touch gestures during natural human–human interaction take place: meeting people (shaking hands), personal relationships (caresses), moments of celebration or sadness (hugs), etc. Considering that robots are expected to form part of our daily life in the future, they should be endowed with the capacity of recognising these touch gestures and the part of its body that has been touched since the gesture’s meaning may differ. Therefore, this work presents a learning system for both purposes: detect and recognise the type of touch gesture (stroke, tickle, tap and slap) and its localisation. The interpretation of the meaning of the gesture is out of the scope of this paper. Different technologies have been applied to perceive touch by a social robot, commonly using a large number of sensors. Instead, our approach uses 3 contact microphones installed inside some parts of the robot. The audio signals generated when the user touches the robot are sensed by the contact microphones and processed using Machine Learning techniques. We acquired information from sensors installed in two social robots, Maggie and Mini (both developed by the RoboticsLab at the Carlos III University of Madrid), and a real-time version of the whole system has been deployed in the robot Mini. The system allows the robot to sense if it has been touched or not, to recognise the kind of touch gesture, and its approximate location. The main advantage of using contact microphones as touch sensors is that by using just one, it is possible to “cover” a whole solid part of the robot. Besides, the sensors are unaffected by ambient noises, such as human voice, TV, music etc. Nevertheless, the fact of using several contact microphones makes possible that a touch gesture is detected by all of them, and each may recognise a different gesture at the same time. The results show that this system is robust against this phenomenon. Moreover, the accuracy obtained for both robots is about 86%.},
  archive      = {J_EAAI},
  author       = {Juan José Gamboa-Montero and Fernando Alonso-Martín and José Carlos Castillo and María Malfaz and Miguel A. Salichs},
  doi          = {10.1016/j.engappai.2020.103670},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103670},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting, locating and recognising human touches in social robots with contact microphones},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel and effective optimization algorithm for global
optimization and its engineering applications: Turbulent flow of
water-based optimization (TFWO). <em>EAAI</em>, <em>92</em>, 103666. (<a
href="https://doi.org/10.1016/j.engappai.2020.103666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study we present a new and effective grouping optimization algorithm (namely, the Turbulent Flow of Water-based Optimization (TFWO)), inspired from a nature search phenomenon, i.e. whirlpools created in turbulent flow of water, for global real-world optimization problems. In the proposed algorithm, the problem of selecting control parameters is eliminated, the convergence power is increased and the algorithm have a fixed structure. The proposed algorithm is used to find the global solutions of real-parameter benchmark functions with different dimensions. Besides, in order to further investigate the effectiveness of TFWO, it was used to solve various types of nonlinear Economic Load Dispatch (ELD) optimization problems in power systems and Reliability–RedundancyAllocation Optimization (RRAO) for the overspeed protection system of a gas turbine, as two real-world engineering optimization problems. The results of TFWO are compared with other algorithms, which provide evidence for efficient performance with superior solution quality of the proposed TFWO algorithm in solving a great range of real-parameter benchmark and real-world engineering problems. Also, the results prove the competitive performance and robustness of TFWO algorithm compared to other state-of-the-art optimization algorithms in this study. The source codes of the TFWO algorithm are publicly available at https://github.com/ebrahimakbary/TFWO .},
  archive      = {J_EAAI},
  author       = {Mojtaba Ghasemi and Iraj Faraji Davoudkhani and Ebrahim Akbari and Abolfazl Rahimnejad and Sahand Ghavidel and Li Li},
  doi          = {10.1016/j.engappai.2020.103666},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103666},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel and effective optimization algorithm for global optimization and its engineering applications: Turbulent flow of water-based optimization (TFWO)},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DLCSS: A new similarity measure for time series data mining.
<em>EAAI</em>, <em>92</em>, 103664. (<a
href="https://doi.org/10.1016/j.engappai.2020.103664">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Longest Common Subsequence (LCSS) is considered as a classic problem in computer science. In most studies related to time series data mining, LCSS had been mentioned as the best and the most usable similarity measurement method. The results of time series data mining under LCSS strongly depend on the similarity threshold, because the similarity measurement approach in LCSS is a zero–one approach. Since there is no knowledge about the data, and it is very difficult to determine the right amount of similarity threshold, using LCSS can actually lead to poor results. In this research, a new similarity measurement method named Developed Longest Common Subsequence (DLCSS) has been suggested for time series data mining based on LCSS. In DLCSS, by defining two similarity thresholds and determining their values, LCSS’ shortcoming was eliminated. The performance of DLCSS was compared with performance of LCSS and Dynamic Time Warping (DTW) using 1-Nearest neighbor and k-medoids clustering techniques. This evaluation was carried out on 63 time series datasets of UCR collection. Using these results, it could be claimed that the 1-NN accuracy and clustering accuracy under DLCSS is better than that of under LCSS and DTW with at least 99.5% and 99% confidence, respectively. Also, DLCSS has better effect in correctly predicting the number of clusters compared to LCSS and DTW. In addition, the effect of DLCSS in determining the better cluster representatives is greater than that of under LCSS and DTW with at least 99.95% confidence.},
  archive      = {J_EAAI},
  author       = {Gholamreza Soleimani and Masoud Abessi},
  doi          = {10.1016/j.engappai.2020.103664},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103664},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DLCSS: A new similarity measure for time series data mining},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fractional-order cuckoo search algorithm for parameter
identification of the fractional-order chaotic, chaotic with noise and
hyper-chaotic financial systems. <em>EAAI</em>, <em>92</em>, 103662. (<a
href="https://doi.org/10.1016/j.engappai.2020.103662">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the parameters of the chaos phenomena in the economic-financial systems is a critical issue to control and avoid the financial crises and bogging the market down. Therefore, in this paper, an efficient and reliable optimization algorithm is developed to identify the corresponding parameters of that chaotic dynamical behavior in the fractional-order chaotic, chaotic with noise, and hyper-chaotic financial systems. The introduced algorithm is a cooperation among the fractional calculus (FC) perspective and the basic cuckoo search algorithm to enhance the stochastic cuckoo’s walk via considering the cuckoo’s earlier behaviors from memory. The developed fractional-order cuckoo search (FO-CS) is validated with twenty-eight functions of CEC2017 with different dimensions. Several measures and non-parametric statistical tests are presented to demonstrate the superiority of the introduced algorithm while compared with the CS and the state-of-the-art techniques. The results show that merging of FC properties magnifies CS’s efficiency, convergence speed, and robustness against the complexity of the considered CEC benchmarks suite and the non-linearity of the fractional-order chaotic, chaotic with noise, and hyper-chaotic financial systems.},
  archive      = {J_EAAI},
  author       = {Dalia Yousri and Seyedali Mirjalili},
  doi          = {10.1016/j.engappai.2020.103662},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103662},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fractional-order cuckoo search algorithm for parameter identification of the fractional-order chaotic, chaotic with noise and hyper-chaotic financial systems},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A t–s fuzzy model identification approach based on evolving
MIT2-FCRM and WOS-ELM algorithm. <em>EAAI</em>, <em>92</em>, 103653. (<a
href="https://doi.org/10.1016/j.engappai.2020.103653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inter type-2 fuzzy model has been confirmed to be more effective in Takagi–Sugeno (T–S) fuzzy model identification compared to type-1 fuzzy model. It is indisputable that some algorithms based on inter type-2 fuzzy model have already been developed and shown remarkable modeling performance. To further improve the modeling accuracy, the optimization methods and the neural network are taken into consideration. In this paper, an evolving modified inter type-2 fuzzy c-regression model (MIT2-FCRM) algorithm based on gravitational search algorithm (GSA) and a consequent parameter identification method based on extreme learning machine algorithm with forgetting factor for processing online sequences (namely WOS-ELM) were proposed. Then a novel approach for T–S fuzzy modeling was presented, in which, the coefficients of the upper and lower hyperplanes were obtained by evolving MIT2-FCRM algorithm based on GSA, a hyper-plane-shaped membership function (MF) was utilized to identify the antecedent parameters of the T–S fuzzy model, and WOS-ELM was employed to identify the consequent parameters. The modeling results of six examples indicate that the proposed approach is superior to other studies in terms of identification accuracy, compact fuzzy rules and noise resistance ability.},
  archive      = {J_EAAI},
  author       = {Chunyang Wei and Chaoshun Li and Chen Feng and Jianzhong Zhou and Yongchuan Zhang},
  doi          = {10.1016/j.engappai.2020.103653},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103653},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A T–S fuzzy model identification approach based on evolving MIT2-FCRM and WOS-ELM algorithm},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel three-way decision method in a hybrid information
system with images and its application in medical diagnosis.
<em>EAAI</em>, <em>92</em>, 103651. (<a
href="https://doi.org/10.1016/j.engappai.2020.103651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decisions are effective and heuristic methods in information processing, moreover, it provides a trisecting-and-acting framework for complex problem solving. In this paper, combining with the practical application scenario, we propose a novel three-way decisions approach and apply it to medical diagnosis. First, we build an information system which is called a hybrid information system with images by considering the characteristics of the examination items of nephritis, including urinary color, urinary tuberculosis, pH, red blood cell count, urinary irritation, computed tomography, white blood cell count and so on. Second, to describe two objects of the conditional attribute set in a hybrid information system with images, we propose the hybrid distance based on Euclidean distance. Then, the tolerance relation induced by this system is constructed. In addition, considering that missing values exist in a hybrid information system with images, interval-valued numbers are used to obtain the loss function. Given different types of parameters can respond the level of the tolerance relation and the risk preference of decision makers, and the decision rules are shown in tabular forms. Finally, an illustration is showed to verify the feasibility and reasonability of the proposed method.},
  archive      = {J_EAAI},
  author       = {Zhaowen Li and Pengfei Zhang and Ningxin Xie and Gangqiang Zhang and Ching-Feng Wen},
  doi          = {10.1016/j.engappai.2020.103651},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103651},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel three-way decision method in a hybrid information system with images and its application in medical diagnosis},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new w-SVM kernel combining PSO-neural network transformed
vector and bayesian optimized SVM in GDP forecasting. <em>EAAI</em>,
<em>92</em>, 103650. (<a
href="https://doi.org/10.1016/j.engappai.2020.103650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering that in the literature there is a very limited number of studies proposing new SVM kernels especially in regression problems, the scope of this research is to investigate the development of a novel Support Vector Machine Kernel. The proposed new W-SVM (Weighted-SVM) kernel was developed by applying a suitably transformed weight vector derived from particle swarm optimized neural networks in order to satisfy the kernel conditions of Mercer’s theorem and then incorporated to a Bayesian Optimized (BO) kernel for building the new proposed W-SVM kernel. The proposed SVM kernel was applied in Gross Domestic Product growth forecasting. The new kernel has led to significantly improved forecasting results compared to all the other conventional ANN, SVM, and optimized BO-SVM, PSO-ANN machine learning models.},
  archive      = {J_EAAI},
  author       = {Georgios N. Kouziokas},
  doi          = {10.1016/j.engappai.2020.103650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new W-SVM kernel combining PSO-neural network transformed vector and bayesian optimized SVM in GDP forecasting},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DEACO: Adopting dynamic evaporation strategy to enhance ACO
algorithm for the traveling salesman problem. <em>EAAI</em>,
<em>92</em>, 103649. (<a
href="https://doi.org/10.1016/j.engappai.2020.103649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant Colony Optimization (ACO) algorithm is one of the effective solutions to solve the problem of combination optimization like traveling salesman problem (TSP) which belongs to NP-hard problem. However, this algorithm is robust and has a strong ability for solution discovery, but the convergence speed of that is low and stuck into local optimum. Therefore, for overcoming the drawbacks of ACO, we proposed a self-adaptive ACO with unique strategies to improve uncertain convergence time and random decisions of this algorithm. The proposed technique (DEACO) adjusting the ACO parameters dynamically. In this mechanism, main idea is how to select the first city (start point) to achieve the shortest path based on clustering. In this approach, DEACO finds the minimum cost/shortest path for each cluster. The data that used for this experiment is from TSPLIB library under MATLAB simulation with 10 TSP instances. The experiment outcome illustrates better performance of the proposed method than the conventional ACO in term of faster convergence speed and higher search accuracy.},
  archive      = {J_EAAI},
  author       = {Sahar Ebadinezhad},
  doi          = {10.1016/j.engappai.2020.103649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DEACO: Adopting dynamic evaporation strategy to enhance ACO algorithm for the traveling salesman problem},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Granular space, knowledge-encoded deep learning architecture
and remote sensing image classification. <em>EAAI</em>, <em>92</em>,
103647. (<a
href="https://doi.org/10.1016/j.engappai.2020.103647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand-crafted features of remotely sensed (RS) image require the involvement of expensive human experts for classification. This factor motivates for designing the classification model with representative feature learning-based deep architecture to automate the feature extraction process and improve the generalization capability of the model. With this reasoning, we propose a deep auto-encoder neural network (NN) architecture with knowledge-encoded granular space for the classification of RS images. The network works with wavelet-rough granulated spaces and its architecture is designed with the encoded domain knowledge that strategically initializes the network parameters. Mostly, the learning time and performance of deep auto-encoders are persuaded by randomly selected weights and thus, we aim here to minimize these efforts with the domain knowledge. Neighborhood rough sets (NRS) are used to encode the domain knowledge and explore the contextual information for improved decision. We perform the knowledge-encoding operation for all stages of the auto-encoder. The proposed model thus exploits the mutual merits of deep network, wavelet-rough granular space and knowledge-encoding method. Comparative experimental results with multispectral and hyperspectral RS images demonstrate the superiority of our model to the related advanced methods.},
  archive      = {J_EAAI},
  author       = {Saroj K. Meher},
  doi          = {10.1016/j.engappai.2020.103647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Granular space, knowledge-encoded deep learning architecture and remote sensing image classification},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed gas concentration prediction with intelligent
edge devices in coal mine. <em>EAAI</em>, <em>92</em>, 103643. (<a
href="https://doi.org/10.1016/j.engappai.2020.103643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas disaster can be triggered by gas concentrations exceeding standard levels, and gas concentration prediction system can reduce the occurrence of gas disaster by predicting the trend of gas concentration and alerting engineers to take necessary measures whenever needed. With the increasing use of intelligent edge devices in coal mines and the limitations of some existing systems, developing a new gas concentration prediction system for large-scale intelligent edge devices has become an important issue. This work proposes to address the issue through a novel method for predicting gas concentrations by taking full advantage of multidimensional data in an intelligent edge system. Specifically, 1) it proposed a S ingle hidden layer R andom W eights N eural N etwork (SRWNN) as the prediction model, which is based on interval prediction rather than point prediction; 2) It employs a Non-dominated Sorting Genetic Algorithm II (NSGA-II) to train SRWNN; 3) To significantly reduce the time consumed during model training and facilitate real-time predictions, it proposes a distributed gas concentration prediction scheme based on an intelligent edge system; and 4) it conducts extensive experiments by using actual industrial data collected from a company to demonstrate the superior performance of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yiwen Zhang and Haishuai Guo and Zhihui Lu and Lu Zhan and Patrick C.K. Hung},
  doi          = {10.1016/j.engappai.2020.103643},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103643},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed gas concentration prediction with intelligent edge devices in coal mine},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). TextTricker: Loss-based and gradient-based adversarial
attacks on text classification models. <em>EAAI</em>, <em>92</em>,
103641. (<a
href="https://doi.org/10.1016/j.engappai.2020.103641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples are generated by adding infinitesimal perturbations to legitimate inputs so that incorrect predictions can be induced into deep learning models. They have received increasing attention recently due to their significant values in evaluating and improving the robustness of neural networks. While adversarial attack algorithms have achieved notable advancements in the continuous data of images, they cannot be directly applied for discrete symbols such as text, where all the semantic and syntactic constraints in languages are expected to be satisfied. In this paper, we propose a white-box adversarial attack algorithm, TextTricker , which supports both targeted and non-targeted attacks on text classification models. Our algorithm can be implemented in either a loss-based way, where word perturbations are performed according to the change in loss, or a gradient-based way, where the expected gradients are computed in the continuous embedding space to restrict the perturbations towards a certain direction. We perform extensive experiments on two publicly available datasets and three state-of-the-art text classification models to evaluate our algorithm. The empirical results demonstrate that TextTricker performs notably better than baselines in attack success rate. Moreover, we discuss various aspects of TextTricker in details to provide a deep investigation and offer suggestions for its practical use.},
  archive      = {J_EAAI},
  author       = {Jincheng Xu and Qingfeng Du},
  doi          = {10.1016/j.engappai.2020.103641},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103641},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TextTricker: Loss-based and gradient-based adversarial attacks on text classification models},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision making for energy investments by using neutrosophic
present worth analysis with interval-valued parameters. <em>EAAI</em>,
<em>92</em>, 103639. (<a
href="https://doi.org/10.1016/j.engappai.2020.103639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing energy consumption of the world, new alternative energy sources are needed. The alternative energy resources can be classified into three categories such as fossil fuels energy resources, renewable energy resources, and nuclear energy resources. Solar energy is a very commonly used renewable energy resource for generating electricity and heating water. In this paper, establishing a solar energy system is handled as an investment analysis problem whose parameters are defined under uncertainty. Therefore, neutrosophic sets as a mean of dealing with uncertainty have been preferred to capture this vagueness and impreciseness. Neutrosophic sets are one of the extensions of intuitionistic fuzzy sets, which use an indeterminacy function unlike the other extensions of fuzzy sets. This paper proposes a new neutrosophic investment analysis method by using interval-valued parameters to evaluate solar energy systems. In the application section, three different types of solar energy systems are evaluated by the proposed method. It is observed that the proposed method presents big flexibility to experts and it gives effective and efficient results.},
  archive      = {J_EAAI},
  author       = {Serhat Aydın and Cengiz Kahraman and Mehmet Kabak},
  doi          = {10.1016/j.engappai.2020.103639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decision making for energy investments by using neutrosophic present worth analysis with interval-valued parameters},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An accelerator for online SVM based on the fixed-size KKT
window. <em>EAAI</em>, <em>92</em>, 103637. (<a
href="https://doi.org/10.1016/j.engappai.2020.103637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machine (SVM), as a general and useful supervised learning tool, is facing with some challenges such as low learning efficiency, poor generalization performance, noise sensitivity, etc. when it is applied to online learning tasks. To overcome these limitations, an accelerator model based on window technology and the KKT conditions for online SVM learning is proposed in this paper. The proposed model is not an independent online algorithm but may be regarded as an accelerator for other online SVM learning algorithms, and it constructs working set of SVM by a fixed-size window with the samples which violate the KKT conditions. The relationship between Lagrangain multipliers in dual problem of SVM and KKT conditions are analyzed in the case of online learning. On this basis, a fixed-size KKT window can be constructed according to whether the samples violate KKT conditions or not. Then, it takes the samples that violate the KKT conditions as the training window, which not only makes the training samples with the same size each time, but also ensures that all samples are useful for the hyperplane updating (it means that the classifier can be updated more smoothly). Two typical and specific online SVM algorithms are used as baseline, and the corresponding speeding online SVM learning algorithms with ”X+accelerator” models are proposed to testing the performance of the proposed accelerator. Comprehensive experiments clearly show that the proposed model can accelerate the online learning process effectively and has good robustness and generalization performance.},
  archive      = {J_EAAI},
  author       = {Husheng Guo and Aijuan Zhang and Wenjian Wang},
  doi          = {10.1016/j.engappai.2020.103637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An accelerator for online SVM based on the fixed-size KKT window},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple model extended continuous ant colony filter applied
to real-time wind estimation in a fixed-wing UAV. <em>EAAI</em>,
<em>92</em>, 103629. (<a
href="https://doi.org/10.1016/j.engappai.2020.103629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new heuristic multiple model filter, called Multiple Model Extended Continuous Ant Colony Filter , is proposed to solve a nonlinear multiple model state estimation problem. In this filter, a bank of extended continuous ant colony filters are run in parallel to solve the multiple model estimation problem. The probability of each model is continually updated and consequently both the true model and the states of the nonlinear system are updated based on the weighted sum of the filters. The new multiple model filter is tested on an engineering problem. The problem is to estimate simultaneously the states of a fixed-wing unmanned aerial vehicle as well as the wind model, applied to the system. Four different wind models are considered and the proposed filter is unaware of the wind type. Then, observability of the states and the wind components are analyzed. Four new propositions are introduced and proved for unknown input observability , state and unknown input observability , the effect of time-varying unknown input matrix on the unknown input observability , and the effect of linearization errors on the state observability . Moreover, observability of the wind parameters is analyzed based on the nonlinear systems observability theory. Performance of the proposed filter is also evaluated in maneuvering flight and compared to a single extended continuous ant colony filter and a multiple model extended Kalman filter. A hardware-in-the-loop experiment is also performed to verify the real-time implementation capability of the suggested architecture.},
  archive      = {J_EAAI},
  author       = {Hadi Nobahari and Alireza Sharifi},
  doi          = {10.1016/j.engappai.2020.103629},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103629},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple model extended continuous ant colony filter applied to real-time wind estimation in a fixed-wing UAV},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel machine learning technique for computer-aided
diagnosis. <em>EAAI</em>, <em>92</em>, 103627. (<a
href="https://doi.org/10.1016/j.engappai.2020.103627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary motivation of this paper is twofold: first, to employ a heuristic optimization algorithm to optimize the dendritic neuron model (DNM) and second, to design a tidy visual classifier for computer-aided diagnosis that can be easily implemented on a hardware system. Considering that the backpropagation (BP) algorithm is sensitive to the initial conditions and can easily fall into local minima, we propose an evolutionary dendritic neuron model (EDNM), which is optimized by the gbest-guided artificial bee colony (GABC) algorithm. The experiments are performed on the Liver Disorders Data Set, the Wisconsin Breast Cancer Data Set, the Haberman’s Survival Data Set, the Diabetic Retinopathy Debrecen Data Set and Hepatitis Data Set, and the effectiveness of our model was rigorously validated in terms of the classification accuracy, the sensitivity, the specificity, the F_measure, Cohen’s Kappa, the area under the receiver operating characteristic curve (AUC), convergence speed and the statistical analysis of the Wilcoxon signed-rank test. Moreover, after training, the EDNM can simplify its neural structure by removing redundant synapses and superfluous dendrites by the neuronal pruning mechanism. Finally, the simplified structural morphology of the EDNM can be replaced by a logic circuit (LC) without sacrificing accuracy. It is worth emphasizing that once implemented by an LC, the model has a significant advantage over other classifiers in terms of speed when handling big data. Consequently, our proposed model can serve as an efficient medical classifier with excellent performance.},
  archive      = {J_EAAI},
  author       = {Cheng Tang and Junkai Ji and Yajiao Tang and Shangce Gao and Zheng Tang and Yuki Todo},
  doi          = {10.1016/j.engappai.2020.103627},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103627},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel machine learning technique for computer-aided diagnosis},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bibliometric analysis and cutting-edge overview on fuzzy
techniques in big data. <em>EAAI</em>, <em>92</em>, 103625. (<a
href="https://doi.org/10.1016/j.engappai.2020.103625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few years, Big Data has gained a tremendous attention from the research community. The data being generated in huge quantity from almost every field is unstructured and unprocessed. Extracting knowledge base and useful information from the big raw data is one of the major challenges, present today. Various computational intelligence and soft computing techniques have been proposed for efficient big data analytics. Fuzzy techniques are one of the soft computing approaches which can play a very crucial role in current big data challenges by pre-processing and reconstructing data. There is a wide spread application domains where traditional fuzzy sets (type-1 fuzzy sets) and higher order fuzzy sets (type-2 fuzzy sets) have shown remarkable outcomes. Although, this research domain of “fuzzy techniques in Big Data” is gaining some attention, there is a strong need for a motivation to encourage researchers to explore more in this area. In this paper, we have conducted bibliometric study on recent development in the field of “fuzzy techniques in big data”. In bibliometric study, various performance metrics including total papers, total citations, and citation per paper are calculated. Further, top 10 of most productive and highly cited authors, discipline, source journals, countries, institutions, and highly influential papers are also evaluated. Later, a comparative analysis is performed on the fuzzy techniques in big data after analysing the most influential works in this field.},
  archive      = {J_EAAI},
  author       = {Amit K. Shukla and Pranab K. Muhuri and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103625},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {103625},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bibliometric analysis and cutting-edge overview on fuzzy techniques in big data},
  volume       = {92},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Support vector machine classifier with huberized pinball
loss. <em>EAAI</em>, <em>91</em>, 103635. (<a
href="https://doi.org/10.1016/j.engappai.2020.103635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The original support vector machine (SVM) uses the hinge loss function, which is non-differentiable and makes the problem difficult to solve in particular for regularized SVM, such as with ℓ 1 -regularized. On the other hand, the hinge loss is sensitive to noise. To circumvent these drawbacks, a huberized pinball loss function is proposed. It is less sensitive to noise, similar to the pinball loss which is related to the quantile distance. The proposed loss function is differentiable everywhere and this differentiability can significantly reduce the computational cost for the SVM algorithm. The elastic net penalty is applied to the SVM and the support vector machine classifier with huberized pinball loss (HPSVM) is proposed. Due to the continuous differentiability of the huberized pinball loss function, the Proximal Gradient method is used to solve the proposed model. The numerical experiments on synthetic data, real world datasets confirm the robustness and effectiveness of the proposed method. Statistical comparison is performed to show the significant difference between the proposed method and other compered ones.},
  archive      = {J_EAAI},
  author       = {Wenxin Zhu and Yunyan Song and Yingyuan Xiao},
  doi          = {10.1016/j.engappai.2020.103635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Support vector machine classifier with huberized pinball loss},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new exponentially expanded robust random vector functional
link network based MPPT model for local energy management of PV-battery
energy storage integrated microgrid. <em>EAAI</em>, <em>91</em>, 103633.
(<a href="https://doi.org/10.1016/j.engappai.2020.103633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a new Maximum Power Point Tracking (MPPT) model is presented for Local Energy Management (LEM) of a multiple Photovoltaic (PV) based microgrid. To detect accurate MPP references under local uncertainties, a non-iterative Linear Recurrence Relationship (LRR) based PV model is incorporated with PV penetration index. A robust, accurate and fast Exponentially Expanded Robust Random Vector Functional Link network (EE-RRVFLN) based MPPT algorithm is constructed with an exponentially expansion unit to address positive dynamic volatility and a direct link relationship to address null vs. positive volatility in PV data. The robustness is further incorporated by a maximum likelihood estimator using Huber’s cost function, where both input and output weights are optimally estimated by targeting reduction in MPP tracking error. An Assessment Index (i.e. MPPT error related) based Distributed Adaptive Droop (DAD) mechanism is suggested as Primary Controller (PC) for effective power sharing among multiple PVs. A detailed case study is presented to evaluate the accuracy of the proposed model in MATLAB simulation, as well as in dSPACE 1104 based Hardware-in-Loop (HIL) platform. Historical data for different intervals/ seasons, partial shading, improved LEM validations (simulation and HIL) are considered as different cases to establish the excellence of the proposed approach, as compared with conventional Functional Link Neural Network (FLNN) and Random Vector Functional Link Neural Network (RVFLNN).},
  archive      = {J_EAAI},
  author       = {Lipsa Priyadarshini and P.K. Dash and Snehamoy Dhar},
  doi          = {10.1016/j.engappai.2020.103633},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103633},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new exponentially expanded robust random vector functional link network based MPPT model for local energy management of PV-battery energy storage integrated microgrid},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault diagnosis using novel AdaBoost based discriminant
locality preserving projection with resamples. <em>EAAI</em>,
<em>91</em>, 103631. (<a
href="https://doi.org/10.1016/j.engappai.2020.103631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis plays a pivotal role in ensuring the safety of process industries. However, due to the diversity of process faults and the high coupling of fault data, it becomes very difficult to achieve high accuracy in the fault diagnosis of complex industrial processes. To address this concern, in this article, a novel AdaBoost-based discriminant locality preserving projection (DLPP) with resamples (A-DLPPR) model is proposed. The proposed A-DLPPR model has two features: to address the problem of matrix decomposition in DLPP, the bootstrap method is utilized to generate groups of resample data, and to obtain high classification accuracy, the AdaBoost-based classification technique is adopted. Finally, an effective fault diagnosis model using the proposed A-DLPPR model can be established. To validate the effectiveness of the proposed A-DLPPR model, the Tennessee Eastman process (TEP) is selected, and case studies using different kinds of TEP faults are conducted. The simulation results indicate that the proposed A-DLPPR model can achieve higher fault diagnosis accuracy than some other models, which verifies that in the field of complex industrial processes, the proposed A-DLPPR method can be used as an effective model for fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Yan-Lin He and Yang Zhao and Xiao Hu and Xiao-Na Yan and Qun-Xiong Zhu and Yuan Xu},
  doi          = {10.1016/j.engappai.2020.103631},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103631},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault diagnosis using novel AdaBoost based discriminant locality preserving projection with resamples},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-label log-loss function using l-BFGS for document
categorization. <em>EAAI</em>, <em>91</em>, 103623. (<a
href="https://doi.org/10.1016/j.engappai.2020.103623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text mining, which fundamentally involves quantitative tactics to analyze textual data, can be used for discovering knowledge and to achieve scholarly research goals. For large-scale data such as corpus text, intelligent learning methods have been effectively approached. In this paper, an artificial neural network with a quasi-Newton updating procedure is presented for multi-label multi-class text classification. This numerical unconstrained training technique, the Multi-Label extension of Log-Loss function using in Limited-memory Broyden–Fletcher–Goldfarb–Shanno algorithm (ML4BFGS), provides a noteworthy opportunity for text mining and leads to a significant improvement in text classification performances. The ML4BFGS training approach is applied to allocate some (one or multi) of the classes to each corresponding sentence from different available labels. We evaluate this method on English translations of the Holy Quran. These religious texts have been chosen for experiments of this manuscript because each verse (sentence) usually has multiple labels (topics) and different translations of each verse should have the same labels. Experimental results show that ML4BFGS is talented for multi-label multi-class classification in the Quranic corpus. Evaluation criteria of some advanced updating methods such as ITCG, BFGS, L-BFGS-B, L3BFGS as well as some other multi-label approaches such as ML-k-NN, and well-known SVM are compared with the proposed ML4BFGS and the outcomes are fully-described in this study. The performance measures including the Hamming loss, recall, precision, and F1 score show that the ML4BFGS achieves the best results in extracting related classes for each verse, while the proposed network takes the least epochs compared to the other training approach for completing learning or training phase. Simultaneously, the elapsed time for ML4BFGS is just 78% (in seconds) of the best experience of this term. Compared with the applicability of some state-of-the-art algorithms, ML4BFGS has a less computational cost, faster convergence rate, and much accuracy in corpus analysis.},
  archive      = {J_EAAI},
  author       = {Mostafa Borhani},
  doi          = {10.1016/j.engappai.2020.103623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-label log-loss function using L-BFGS for document categorization},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotional, affective and biometrical states analytics of a
built environment. <em>EAAI</em>, <em>91</em>, 103621. (<a
href="https://doi.org/10.1016/j.engappai.2020.103621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personal interests constitute the emphasis of client-centered, personalized marketing, which leads to personalized client fulfillment. Current shoppers are interested in more than simply buying products and services; shoppers are also interested in the surroundings of the shopping site. Everywhere in the world, an analysis of marketing value, with rare exceptions, does not integrate criteria relevant to the emotional, affective and biometrical states, valence and arousal of potential buyers. Such parameters require assessment for implementing an accurate and more effective, client-centered marketing process. This research, which required developing the Emotional, Affective and Biometrical States Analytics of the Built Environment (VINERS) Method, provides a “big picture” of built environment neuromarketing. A multiple-criteria analysis integrated the emotional, affective and biometrical states of potential buyers and the surrounding environment (its physical, economic, social and environmental criteria). Neuro-decision and neuro-correlation matrices analysis constituted its basis. This research involved the accumulation and analysis of over 350 million remote data points, which aimed to ascertain the development of the biometrical, affective and emotional maps and sought to determine over 35,000 of average and strong correlations. The obtained dependencies constituted the basis for calculating and graphically submitting the VINERS circumplex model of affect, which the authors of this article had developed. This model is similar to Russell’s circumplex model of affect. However, now, the VINERS Method has provided supplements offering new opportunities. Determination of an integrated emotional market rental (IEMR) value, provision of digital tips and optimization of the IEMR value are made possible by the VINERS Method.},
  archive      = {J_EAAI},
  author       = {Arturas Kaklauskas and Ajith Abraham and Gintautas Dzemyda and Saulius Raslanas and Mark Seniut and Ieva Ubarte and Olga Kurasova and Arune Binkyte-Veliene and Justas Cerkauskas},
  doi          = {10.1016/j.engappai.2020.103621},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103621},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emotional, affective and biometrical states analytics of a built environment},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning on robot skills: Motion adjustment and smooth
concatenation of motion blocks. <em>EAAI</em>, <em>91</em>, 103619. (<a
href="https://doi.org/10.1016/j.engappai.2020.103619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies involving robot skill learning have focused on learning to encode and regenerate a simple motion trajectory. Few studies have been conducted on robot skill learning of complex tasks. In this study, kinesthetic teaching was adopted to train basic robot motion blocks, which were adjusted according to the environmental situation and concatenated to accomplish a specified complex task. The difficulties were adjusting and concatenating motion blocks to render the robot motion smooth and natural. Regarding motion adjustment, the Cartesian trajectories of motion blocks were translated, rotated, and scaled to a target position and their joint trajectories were optimized to be similar to those in a human demonstration. Regarding smooth motion concatenation, a weighting function was proposed to smoothly connect two successive adjusted motion blocks. A humanoid robot arm was used to validate the proposed skill learning method. The experiment results indicated that the robot was able to generate smooth Cartesian and joint trajectories to reach to a cup, grasp it, and pour water.},
  archive      = {J_EAAI},
  author       = {Hsien-I Lin},
  doi          = {10.1016/j.engappai.2020.103619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning on robot skills: Motion adjustment and smooth concatenation of motion blocks},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved k2 algorithm for bayesian network structure
learning. <em>EAAI</em>, <em>91</em>, 103617. (<a
href="https://doi.org/10.1016/j.engappai.2020.103617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of learning the structure of Bayesian networks from data, which takes a dataset and outputs a directed acyclic graph. This problem is known to be NP-hard. Almost most of the existing algorithms for structure learning can be classified into three categories: constraint-based, score-based, and hybrid methods. The K2 algorithm, as a score-based algorithm, takes a random order of variables as input and its efficiency is strongly dependent on this ordering. Incorrect order of variables can lead to learning an incorrect structure. Therefore, the main challenge of this algorithm is strongly dependency of output quality on the initial order of variables. The main contribution of this paper is to derive a significant order of variables from the given dataset. Also, one of the significant challenges of structure learning is to find a practical structure learning approach to learn an optimal structure from complex and high-dimensional datasets in a reasonable time. We propose a new fast and straightforward algorithm for addressing this problem in a reasonable time. The proposed algorithm is based on an ordering by extracting strongly connected components of the graph built from data. We reduce the super-exponential search space of structures to the smaller space of nodes ordering. We evaluated the proposed algorithm using some standard benchmark datasets and compare the results with the results obtained from some state of the art algorithms. Finally, we show that the proposed algorithm is competitive with some algorithms for structure learning.},
  archive      = {J_EAAI},
  author       = {Shahab Behjati and Hamid Beigy},
  doi          = {10.1016/j.engappai.2020.103617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved k2 algorithm for bayesian network structure learning},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). STDnet: Exploiting high resolution feature maps for small
object detection. <em>EAAI</em>, <em>91</em>, 103615. (<a
href="https://doi.org/10.1016/j.engappai.2020.103615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of small object detection with convolutional neural networks (ConvNets) lags behind that of larger objects. This can be observed in popular contests like MS COCO. This is in part caused by the lack of specific architectures and datasets with a sufficiently large number of small objects. Our work aims at these two issues. First, this paper introduces STDnet, a convolutional neural network focused on the detection of small objects that we defined as those under 16 × 16 pixels. The high performance of STDnet is built on a novel early visual attention mechanism, called Region Context Network (RCN), to choose the most promising regions, while discarding the rest of the input image. Processing only specific areas allows STDnet to keep high resolution feature maps in deeper layers providing low memory overhead and higher frame rates. High resolution feature maps were proved to be key to increasing localization accuracy in such small objects. Second, we also present USC-GRAD-STDdb, a video dataset with more than 56,000 annotated small objects in challenging scenarios. Experimental results over USC-GRAD-STDdb show that STDnet improves the AP @ . 5 of the best state-of-the-art object detectors for small target detection from 50.8% to 57.4%. Performance has also been tested in MS COCO for objects under 16 × 16 pixels. In addition, a spatio-temporal baseline network, STDnet-bST, has been proposed to make use of the information of successive frames, increasing the AP @ . 5 of STDnet in 2.3%. Finally, optimizations have been carried out to be fit on embedded devices such as Jetson TX2.},
  archive      = {J_EAAI},
  author       = {Brais Bosquet and Manuel Mucientes and Víctor M. Brea},
  doi          = {10.1016/j.engappai.2020.103615},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103615},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STDnet: Exploiting high resolution feature maps for small object detection},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hydrophobicity classification of composite insulators based
on convolutional neural networks. <em>EAAI</em>, <em>91</em>, 103613.
(<a href="https://doi.org/10.1016/j.engappai.2020.103613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the classification of composite insulators in hydrophobicity classes, according to the spray method of IEC Standard 62073, using convolutional neural networks. By applying the spray method, about 4500 photos were collected and are available online, from all hydrophobicity classes using distilled water–ethyl alcohol as spraying solution. Convolutional neural networks were trained, validated and tested, in order to determine the hydrophobicity class of composite insulators and to eliminate the operator’s subjectivity, which is the main problem in this measurement. Various configuration setups of convolutional neural networks are applied and compared for their appropriateness in accurately classifying the composite insulators. The proposed methodology is a useful tool for the classification of composite insulators in hydrophobicity classes restricting the subjectivity of human judgment. The experiments showed this method gives almost 98% accuracy in this classification task. Therefore, the proposed methodology is helpful in maintaining of composite insulators.},
  archive      = {J_EAAI},
  author       = {Christos-Christodoulos A. Kokalis and Thanos Tasakos and Vassiliki T. Kontargyri and Giorgos Siolas and Ioannis F. Gonos},
  doi          = {10.1016/j.engappai.2020.103613},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103613},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hydrophobicity classification of composite insulators based on convolutional neural networks},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incorporating domain knowledge into reinforcement learning
to expedite welding sequence optimization. <em>EAAI</em>, <em>91</em>,
103612. (<a
href="https://doi.org/10.1016/j.engappai.2020.103612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Welding Sequence Optimization (WSO) is very effective to minimize the structural deformation, however selecting proper welding sequence leads to a combinatorial optimization problem. State-of-the-art algorithms could take more than one week to compute the best sequence for an assembly of eight weld beads which is unrealistic for the early stages of Product Delivery Process (PDP). In this article, we develop and implement a novel Reinforcement Q-learning algorithm for WSO where structural deformation is used to compute reward function. We utilize a thermo-mechanical Finite Element Analysis (FEA) to predict deformation. The exploration–exploitation dilemma has been tackled by domain knowledge driven ε -greedy algorithm into Q-RL which helps to expedite the WSO and we call this novel algorithm as DKQRL. We run welding simulation experiment using well-known Simufact® software on a typical widely used mounting bracket which contains eight welding beads. DKQRL allows the reduction of structural deformation up to ∼ 71% and it substantially speeds up the computational time over Modified Lowest Cost Search (MLCS), Genetic Algorithm (GA), exhaustive search, and standard RL algorithm. Results of welding simulation demonstrate a reasonable agreement with real experiment in terms of structural deformation.},
  archive      = {J_EAAI},
  author       = {Jesus Romero-Hdz and Baidya Nath Saha and Seiichiro Tstutsumi and Riccardo Fincato},
  doi          = {10.1016/j.engappai.2020.103612},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103612},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Incorporating domain knowledge into reinforcement learning to expedite welding sequence optimization},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Purifying real images with an attention-guided style
transfer network for gaze estimation. <em>EAAI</em>, <em>91</em>,
103609. (<a
href="https://doi.org/10.1016/j.engappai.2020.103609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the progress of learning-by-synthesis has proposed a training model for synthetic images, which can effectively reduce the cost of human and material resources. Image synthesis has been widely accepted as a cost effective way to learn models because it provides training sets that are large, diverse and accurately labeled. However, the realism of the synthetic image is not enough, this affects generalization on naturalistic test image. In an attempt to address this issue, previous methods learn a model to improve the realism of synthetic image. Different from previous methods, we take the first step towards purifying the real image to weaken the influence of light and convert the distribution of an outdoor naturalistic image through a real-time style transfer task to that of indoor synthetic image. In this paper, we first introduce the segmentation masks to construct Red, Green, and Blue-mask (RGB-mask) pairs as inputs, then we design an attention-guided style transfer network to learn style features separately from the attention and background regions, learn content features from full and attention regions. Moreover, we propose a novel region-level task-guided loss to restrain the features learnt from style and content. Experiments were performed using a mixed research (qualitative and quantitative) method to demonstrate the possibility of purifying real images in complex directions. We evaluate the proposed method on three public datasets, including Labeled pupils in the wild (LPW), Common Objects in COntext (COCO) and MPIIGaze. Extensive experimental results show that the proposed method is effective and achieves the state-of-the-art results.},
  archive      = {J_EAAI},
  author       = {Xianping Fu and Yuxiao Yan and Yang Yan and Jinjia Peng and Huibing Wang},
  doi          = {10.1016/j.engappai.2020.103609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Purifying real images with an attention-guided style transfer network for gaze estimation},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extended MULTIMOORA method based on OWGA operator and
choquet integral for risk prioritization identification of failure
modes. <em>EAAI</em>, <em>91</em>, 103605. (<a
href="https://doi.org/10.1016/j.engappai.2020.103605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effects analysis (FMEA) is one of the important methods for risk analysis, and has been used in various fields to improve the reliability of systems. However, in the fuzzy environment, the aggregation, weight calculation, risk evaluation and prioritization of evaluation information limit its wide application. Therefore, this paper proposes an extended multi-objective optimization by ratio analysis plus full multiplicative form (MULTIMOORA) method based on the ordered weighted geometric averaging (OWGA) operator and Choquet integral for FMEA. Firstly, trapezoidal fuzzy numbers (TrFNs) are used for describing the fuzzy ratings of failure modes. Secondly, considering the uncertainty preferences of decision-makers, the OWGA operator is adopted for aggregating the evaluation information given by multiple decision-makers. Thirdly, the TrFNs ranking method based on the relative preference relation is combined with Choquet integral to model the interactions among risk factors, thus capturing their importance weights. On this basis, an extended MULTIMOORA method is proposed to determine the risk priority of failure modes. Finally, two case studies are provided to illustrate the effectiveness and practicability of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yifan Chen and Yan Ran and Zhichao Wang and Xinlong Li and Xin Yang and Genbao Zhang},
  doi          = {10.1016/j.engappai.2020.103605},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103605},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An extended MULTIMOORA method based on OWGA operator and choquet integral for risk prioritization identification of failure modes},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A CLSTM-TMN for marketing intention detection.
<em>EAAI</em>, <em>91</em>, 103595. (<a
href="https://doi.org/10.1016/j.engappai.2020.103595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, neural network-based models such as machine learning and deep learning have achieved excellent results in text classification. On the research of marketing intention detection, classification measures are adopted to identify news with marketing intent. However, most of current news appears in the form of dialogs. There are some challenges to find potential relevance between news sentences to determine the latent semantics. In order to address this issue, this paper has proposed a CLSTM-based topic memory network (called CLSTM-TMN for short) for marketing intention detection. A ReLU-Neuro Topic Model (RNTM) is proposed. A hidden layer is constructed to efficiently capture the subject document representation, Potential variables are applied to enhance the granularity of subject model learning. We have changed the structure of current Neural Topic Model (NTM) to add CLSTM classifier. This method is a new combination ensemble both long and short term memory (LSTM) and convolution neural network (CNN). The CLSTM structure has the ability to find relationships from a sequence of text input, and the ability to extract local and dense features through convolution operations. The effectiveness of the method for marketing intention detection is illustrated in the experiments. Our detection model has a more significant improvement in F1 (7%) than other compared models.},
  archive      = {J_EAAI},
  author       = {Yufeng Wang and Kun Ma and Laura Garcia-Hernandez and Jing Chen and Zhihao Hou and Ke Ji and Zhenxiang Chen and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103595},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103595},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A CLSTM-TMN for marketing intention detection},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development and implementation of induction motor drive
using sliding-mode based simplified neuro-fuzzy control. <em>EAAI</em>,
<em>91</em>, 103593. (<a
href="https://doi.org/10.1016/j.engappai.2020.103593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a sliding-mode based simplified structure of neuro-fuzzy speed and torque compensator incorporated with an induction motor (IM) drive deploying feedback linearization (FBL). The intuitive linearization technique with the proposed simplified structure neuro-fuzzy sliding-mode control (NFSMC) considerably improves the torque and speed responses under system uncertainty and outer load disturbance, giving optimal system performance. This proposed technique also has high computational efficiency due to single error input over conventional one and thus can easily be applied for industrial uses. The parameter tuning of the simplified neuro-fuzzy control (NFC) is done by sliding-mode control (SMC) based adaptive mechanism. The proposed simplified method based linearized drive is simulated as well as experimentally investigated using low-cost DSP2812. The responses prove that the drive system performance characteristics using proposed simplified NFSMC is well-preserved compared to that of conventional one. Additionally, it provides optimal dynamic performance and is robust in terms of parameter variations and peripheral load disturbance.},
  archive      = {J_EAAI},
  author       = {Rabi Narayan Mishra and Kanungo Barada Mohanty},
  doi          = {10.1016/j.engappai.2020.103593},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103593},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Development and implementation of induction motor drive using sliding-mode based simplified neuro-fuzzy control},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble-based active learning using fuzzy-rough approach
for cancer sample classification. <em>EAAI</em>, <em>91</em>, 103591.
(<a href="https://doi.org/10.1016/j.engappai.2020.103591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objective: Classification of cancer from gene expression data is one of the major research areas in the field of machine learning and medical science. Generally, conventional supervised methods are not able to produce desired classification accuracy due to inadequate training samples present in gene expression data to train the system. Ensemble-based active learning technique in this situation can be effective as it determines few informative samples by all the base classifiers and ensemble the decisions of all the base classifiers to get the most informative samples. Most informative samples are labeled by the subject experts and those are added to the training set, which can improve the classification accuracy. Method: We propose a novel ensemble-based active learning using fuzzy-rough approach for cancer sample classification from microarray gene expression data. The proposed method is able to deal with the uncertainty, overlap and indiscernibility usually present in the subtype classes of the gene expression data and can improve the accuracy of the individual base classifier in presence of limited training samples. Results: The proposed method is validated using eight microarray gene expression datasets. The performance of the proposed method in terms of classification accuracy, precision, recall, F 1 -measures and kappa is compared with six other methods. The improvements in accuracy achieved by the proposed method compared to its nearest competitive methods are 2.96%, 9.34%, 0.93%, 3.69%, 7.2% and 4.53% respectively for Colon cancer, Prostate cancer, SRBCT, Ovarian cancer, DLBCL and Central nervous system datasets. Results of the paired t -test justify the statistical relevance of the results in favor of the proposed method for most of the datasets. Conclusion: The proposed method is an effective general purpose ensemble-based active learning adopting the fuzzy-rough concept and therefore can be applied for other classification problem in future.},
  archive      = {J_EAAI},
  author       = {Ansuman Kumar and Anindya Halder},
  doi          = {10.1016/j.engappai.2020.103591},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103591},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble-based active learning using fuzzy-rough approach for cancer sample classification},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep reinforcement one-shot learning for artificially
intelligent classification in expert aided systems. <em>EAAI</em>,
<em>91</em>, 103589. (<a
href="https://doi.org/10.1016/j.engappai.2020.103589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years there has been a sharp rise in applications, in which significant events need to be classified but only a few training instances are available. These are known as cases of one-shot learning. To handle this challenging task, organizations often use human analysts to classify events under high uncertainty. Existing algorithms use a threshold-based mechanism to decide whether to classify an object automatically or send it to an analyst for deeper inspection. However, this approach leads to a significant waste of resources since it does not take the practical temporal constraints of system resources into account. By contrast, the focus in this paper is on rigorously optimizing the resource consumption in the system which applies to broad application domains, and is of a significant interest for academic research, industrial developments, as well as society and citizens benefit. The contribution of this paper is threefold. First, a novel Deep Reinforcement One-shot Learning (DeROL) framework is developed to address this challenge. The basic idea of the DeROL algorithm is to train a deep-Q network to obtain a policy which is oblivious to the unseen classes in the testing data. Then, in real-time, DeROL maps the current state of the one-shot learning process to operational actions based on the trained deep-Q network, to maximize the objective function. Second, the first open-source software for practical artificially intelligent one-shot classification systems with limited resources is developed for the benefit of researchers and developers in related fields. Third, an extensive experimental study is presented using the OMNIGLOT dataset for computer vision tasks, the UNSW-NB15 dataset for intrusion detection tasks, and the Cleveland Heart Disease Dataset for medical monitoring tasks that demonstrates the versatility and efficiency of the DeROL framework.},
  archive      = {J_EAAI},
  author       = {Anton Puzanov and Senyang Zhang and Kobi Cohen},
  doi          = {10.1016/j.engappai.2020.103589},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103589},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement one-shot learning for artificially intelligent classification in expert aided systems},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Long short-term memory neural network with weight
amplification and its application into gear remaining useful life
prediction. <em>EAAI</em>, <em>91</em>, 103587. (<a
href="https://doi.org/10.1016/j.engappai.2020.103587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important component of industrial equipment, once gears have failures, they may cause serious catastrophes. Thus, the prediction of gear remaining life is of great significance. The health indicator of gears is first generated by fusing time-domain and frequency-domain features of gears vibration signals via the isometric mapping algorithm. Then a new type of long-short-term memory neural network with weight amplification (LSTMP-A) is proposed for accurately predicting gear remaining life. Compared with traditional LSTMs, LSTMP-A amplifies the input weights and the recurrent weights of the hidden layer to different degrees by the attention mechanism according to the contribution degree of the corresponding data, and a projection layer is added into the network. With LSTMP-A, we can predict the health characteristics of gears based on historical fusion features. With the monitoring data of a gear life cycle test, the comparative experiments show that the proposed gear remaining life prediction method has higher prediction accuracy than the conventional prediction methods.},
  archive      = {J_EAAI},
  author       = {Sheng Xiang and Yi Qin and Caichao Zhu and Yangyang Wang and Haizhou Chen},
  doi          = {10.1016/j.engappai.2020.103587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long short-term memory neural network with weight amplification and its application into gear remaining useful life prediction},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Artificial intelligence techniques empowered edge-cloud
architecture for brain CT image analysis. <em>EAAI</em>, <em>91</em>,
103585. (<a
href="https://doi.org/10.1016/j.engappai.2020.103585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strokes are one of the leading causes of death in the world. Despite the high mortality rate, chances of recovery are high when an accurate diagnosis is made quickly, and appropriate treatment is provided. Several types of neuroimaging techniques are used to detect strokes, and computed tomography (CT) and magnetic resonance imaging are the main ones. Although magnetic resonance imaging shows clearer results, CT is, in most cases, the most viable alternative, due to the reduced examination time and low cost. Several computer-aided diagnostic systems have been developed in recent years with a focus on the Internet of Things (IoT). These systems, which establish rapid communication between the IoT devices, provide greater integration between specialists and patients, and consequently, a better medical follow up. However, stroke detection and classification techniques in IoT devices require that these methods developed methods have low computational and low storage costs. Thus, Edge computing devices have been attracting attention for their excellent processing capabilities, providing a layer between the IoT device and the cloud. This work proposes a new feature extractor for brain CT images based on an Adaptive Analysis of Brain Tissue Densities. The proposed method presented promising results of accuracy and F1-score, reaching 98.13% and 97.83%, respectively, surpassing several state-of-the-art methods. Furthermore, the proposed method presents low computational cost, with an average extraction time of 0.087s per image, and is, thus, a viable option for integration in IoT and Edge Computing devices, by providing rapid detection and classification of strokes.},
  archive      = {J_EAAI},
  author       = {Francisco F.X. Vasconcelos and Róger M. Sarmento and Pedro P. Rebouças Filho and Victor Hugo C. de Albuquerque},
  doi          = {10.1016/j.engappai.2020.103585},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103585},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial intelligence techniques empowered edge-cloud architecture for brain CT image analysis},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-level principal–agent model for schedule risk control of
IT outsourcing project based on genetic algorithm. <em>EAAI</em>,
<em>91</em>, 103584. (<a
href="https://doi.org/10.1016/j.engappai.2020.103584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing developments in the Information Technology (IT) outsourcing industry, many enterprises outsource IT services to reduce costs. However, the schedule risk of IT outsourcing (ITO) projects may result in enormous economic losses for an enterprise. In this paper, the principal–agent theory is used to control the schedule risk of ITO projects. A two-level mathematical model is built to describe the decision process of the client and vendors. With an increase to the number of subprojects and activities, the scale of the problem will become very large. The resulting optimization is an NP hard problem with continuous domain. Therefore, a genetic algorithm (GA) is designed to solve the proposed model. Experiments are performed to test the ability of the proposed algorithm. Some insights from simulation analysis – the principal–agent theory and two-level mathematical model – are suitable for describing the cooperative relationship between principle and agent. By comparing with ant colony optimization and simulated annealing, the proposed GA shows strong optimization abilities for convergence, reliability, and efficiency, which is a good tool for this kind of optimization problem. The near-optimal plan reduced the schedule risk of the project remarkably, which is the scientific quantitative proposal for the decision maker. This study provides practitioners insights on relationships of schedule risk and ITO projects, and the design model and algorithms of this paper provides practitioners effective potential method to reduce the schedule risk of ITO projects in their operations. However, the uncertain characteristics of key and multiple factors should be considered in future work. Stochastic Programming and the Monte Carlo Simulation Method are two potential tools for dealing with uncertain factors. Additionally, the proposed GA could potentially be improved in terms of convergence. The advantages of other intelligent algorithms could be applied to the GA in order to improve its searching ability, such as the Taboo mechanism.},
  archive      = {J_EAAI},
  author       = {Hualing Bi and Fuqiang Lu and Shupeng Duan and Min Huang and Jinwen Zhu and Mengying Liu},
  doi          = {10.1016/j.engappai.2020.103584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-level principal–agent model for schedule risk control of IT outsourcing project based on genetic algorithm},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient truthfulness privacy-preserving tendering
framework for vehicular fog computing. <em>EAAI</em>, <em>91</em>,
103583. (<a
href="https://doi.org/10.1016/j.engappai.2020.103583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a proposal for a tendering-based incentive framework in order to encourage vehicle owners to join in announced tasks in the vehicular fog computing. The truthfulness of users is ensured by using the incentive mechanism that also assists a fog node server to choose suitable resources for the task. An illustrative language, which is a novel approach to guaranteeing fairness amongst vehicles, is designed based on heterogeneous vehicular resource types. The signcryption technique and a homomorphic concept are integrated in the proposed framework in order to preserve vehicles privacy. Moreover, a detailed performance analysis demonstrates that the communication and computational overheads of this privacy-preserving scheme are significantly more efficient than the available alternatives.},
  archive      = {J_EAAI},
  author       = {Abdulrahman Alamer and Sultan Basudan},
  doi          = {10.1016/j.engappai.2020.103583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient truthfulness privacy-preserving tendering framework for vehicular fog computing},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Demand coverage diversity based ant colony optimization for
dynamic vehicle routing problems. <em>EAAI</em>, <em>91</em>, 103582.
(<a href="https://doi.org/10.1016/j.engappai.2020.103582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic vehicle routing problem (DVRP) has attracted increasing attention due to its wide applications in logistics. Compared with the static vehicle routing problem, DVRP is characterized by the prior unknown customer requests dynamically appearing in route execution. Nevertheless, the newly appeared customers pose a great challenge to route optimizer, since the optimized route may be contrarily of bad quality when including the new customers that are far from planned routes in route planning. To address this issue, in this paper we propose a demand coverage diversity based metaheuristic, termed ACO-CD, in the framework of ant colony algorithm. In ACO-CD, a demand coverage diversity adaptation method is suggested to maintain the diversity of covered customers in routes so that the optimizer can effectively response to the newly appeared customer requests. Experimental results on 27 DVRP test instances demonstrate the effectiveness of the proposed demand coverage diversity adaptation method and the superiority of the proposed ACO-CD over four state-of-the-art DVRP algorithms in terms of solution quality.},
  archive      = {J_EAAI},
  author       = {Xiaoshu Xiang and Jianfeng Qiu and Jianhua Xiao and Xingyi Zhang},
  doi          = {10.1016/j.engappai.2020.103582},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103582},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Demand coverage diversity based ant colony optimization for dynamic vehicle routing problems},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coalition formation with dynamically changing externalities.
<em>EAAI</em>, <em>91</em>, 103577. (<a
href="https://doi.org/10.1016/j.engappai.2020.103577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider multiple self-interested bounded-rational agents each of which has a goal it needs to achieve. Goals are achievable by executing a set of interdependent tasks. Some tasks exhibit time dependencies and may require sequential execution. For each agent, there may be several alternative sets of tasks that can achieve the goal. Execution of alternatives, may be more beneficial when done by a group of agents and not by a single agent. To jointly achieve goals, agents may form interdependent coalitions. Such coalition formation is computationally intractable. We nevertheless seek a practical solution that is not necessarily optimal yet acceptable by the agents. A solution where agents examine only coalitions in which they are members is inapplicable, as externalities are a major factor given task interdependencies. In this paper we study this coalition formation problem. We describe the problem and introduce a novel Multi-lateral Negotiation Protocol ( MNP ) that solves it by forming interdependent coalitions. We allow agents to heuristically make gradual concessions, revise their proposals and converge on specific alternatives, and nevertheless increase their expected gains.},
  archive      = {J_EAAI},
  author       = {Youcef Sklab and Samir Aknine and Onn Shehory and Abdelkamel Tari},
  doi          = {10.1016/j.engappai.2020.103577},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103577},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coalition formation with dynamically changing externalities},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stabilization of stochastic time-varying coupled systems
with delays and lévy noise on networks based on aperiodically
intermittent control. <em>EAAI</em>, <em>91</em>, 103576. (<a
href="https://doi.org/10.1016/j.engappai.2020.103576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to research the stabilization of stochastic time-varying coupled systems with delays and Lévy noise on networks (STSDLN) via aperiodically intermittent control. It is worth pointing out that the time-varying coupling is considered into Lévy noise systems in the first time. Then, by means of a graph-theoretic approach, Lyapunov method and some techniques of inequalities, some stabilization criteria are obtained to guarantee exponentially stability in mean square for STSDLN. Therein, we weaken the sufficient condition for dealing with the time-varying coupling compared to the existing literature, which can reduce the conservation of the conclusions. Additionally, the intensity of control is closely related to the perturbed intensity of noise and the time-varying coupling strength. In particular, as a practical application of our theoretical results, the stabilization of stochastic time-varying coupled oscillators with delays and Lévy noise on networks is studied. Finally, a numerical example is provided to illustrate the validity of the results obtained.},
  archive      = {J_EAAI},
  author       = {Hui Zhou and Jin Song and Wenxue Li},
  doi          = {10.1016/j.engappai.2020.103576},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103576},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stabilization of stochastic time-varying coupled systems with delays and lévy noise on networks based on aperiodically intermittent control},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Short-term wind speed prediction based on LMD and improved
FA optimized combined kernel function LSSVM. <em>EAAI</em>, <em>91</em>,
103573. (<a
href="https://doi.org/10.1016/j.engappai.2020.103573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of wind speed is of great significance to the operation and maintenance of wind farms, the optimal scheduling of turbines, and the safe and stable operation of power grids. A new prediction method for short-term wind speed based on local mean decomposition (LMD) and combined kernel function least squares support vector machine (LSSVM) is proposed. The short-term wind speed time series is decomposed into some components by the LMD algorithm. Based on LSSVM, radial basis function and the Polynomial function are used to generate the combined kernel function. The combined kernel function LSSVM combines the advantages of the radial basis function and the Polynomial function, which can achieve better prediction accuracy. The decomposed wind speed time series are predicted separately by the combined kernel function LSSVM model. At the same time, an improved firefly algorithm is proposed to optimize the parameters of the combined kernel function LSSVM. The final predictive value can be obtained by superimposing the predicted value of each combined kernel function LSSVM prediction model. The actual collected short-term wind speed data is chosen as the research object, the simulation experiments with four prediction horizons have been implemented. Compared with state-of-the-art prediction methods, through the comparison result curve between the prediction and actual wind speed, the box-plot results of predictive error distribution, the comparison results of the relative prediction error, the performance indicators, the Pearson’s test, the DM test and the Taylor diagram results show that the proposed prediction method has higher prediction accuracy and is able to reflect the laws of wind speed correctly. Furthermore, the simulation results of four new datasets and adding noise to the input data of training set show that the proposed prediction method has strong robustness.},
  archive      = {J_EAAI},
  author       = {Zhongda Tian},
  doi          = {10.1016/j.engappai.2020.103573},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103573},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term wind speed prediction based on LMD and improved FA optimized combined kernel function LSSVM},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint DBN and fuzzy c-means unsupervised deep clustering for
lung cancer patient stratification. <em>EAAI</em>, <em>91</em>, 103571.
(<a href="https://doi.org/10.1016/j.engappai.2020.103571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patient stratification has made a great contribution to efficient and personalized medicine. An important task in patient stratification is to discover quite distinct disease subtypes for effective treatment. In this paper, we propose a new deep learning and clustering model which combines Deep Belief Network (DBN) and Fuzzy C-Means(FCM), called Unsupervised Deep Fuzzy C-Means clustering Network(UDFCMN), to cluster lung cancer patients from lung CT images. In our deep clustering network, images after preprocessing are first encoded into multiple layers of hidden variables to extract hierarchical features and feature distribution and form the high-level representations. Here, to solve the problem of feature homogenization in DBN, we introduce the Winner-Take-All (WTA) idea to meliorate the traditional DBN structure, called WTADBN. Then FCM is used to produce the initial cluster labels with the new representations learnt by stacked WTARBM. Therefore, the FCM-generated cluster labels are used for the fine-tuning of the DBN as ground-truth labels. And an unsupervised image clustering and patient stratification process is completed by cross iteration. We tested our deep FCM clustering algorithm to do experiment on both public dataset from the internet and private dataset from cooperate hospital. For the latter one, the clinical and biological verification was also performed. Experimental results reveal outperformance of UDFCMN as compared to the state-of-the-art unsupervised classification methods. These results also indicate that our approach may have practical applications in lung cancer pathogenesis studies and provide useful guidelines for personalized cancer therapy.},
  archive      = {J_EAAI},
  author       = {Zijuan Zhao and Juanjuan Zhao and Kai Song and Akbar Hussain and Qianqian Du and Yunyun Dong and Jihua Liu and Xiaotang Yang},
  doi          = {10.1016/j.engappai.2020.103571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint DBN and fuzzy C-means unsupervised deep clustering for lung cancer patient stratification},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An encoder–decoder approach to mine conditions for
engineering textual data. <em>EAAI</em>, <em>91</em>, 103568. (<a
href="https://doi.org/10.1016/j.engappai.2020.103568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data engineering seeks to support artificial intelligence processes that extract knowledge from raw data. Many such data are rendered in natural language from which entity-relation extractors extract facts and opinion miners extract opinions; the goal of condition mining is to mine the conditions that have an influence on them. In this article, a new condition mining method is proposed. It relies on a deep neural network and attempts to overcome the limitations of existing methods for condition mining that we reviewed. The materials used include readily-available software components for natural language processing and a large multi-lingual, multi-topic dataset. The common information retrieval performance measures were used to assess the results, namely: precision, which is the fraction of correct conditions to the mined ones, recall, which is the fraction of correct conditions that have been mined to the total number of correct conditions, and the F 1 score, which is the harmonic mean of precision and recall. The results of the experimental analysis prove that the new proposal can attain an F 1 score that is significantly greater than with existing methods. Furthermore, a comprehensive analysis of the dataset was performed, which revealed two key findings: the connectives follows a long-tail distribution and the conditions are quite dissimilar from a semantic point of view.},
  archive      = {J_EAAI},
  author       = {Fernando O. Gallego and Rafael Corchuelo},
  doi          = {10.1016/j.engappai.2020.103568},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103568},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An encoder–decoder approach to mine conditions for engineering textual data},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel gait-appearance-based multi-scale video covariance
approach for pedestrian (re)-identification. <em>EAAI</em>, <em>91</em>,
103566. (<a
href="https://doi.org/10.1016/j.engappai.2020.103566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to handle the complex databases of acquired images in the security area, a robust and adaptive framework for Video Surveillance Data Mining as well as for multi-shot pedestrian (re)-identification is required. The pedestrian’s signature must be invariant and robust against the noise and uncontrolled variation. In this paper a new fast Gait-Appearance-based Multi-Scale Video Covariance (GAMS-ViCov) unsupervised approach was proposed to efficiently describe any image-sequence, on streaming or stored in the database, of a pedestrian into a compact and fixed size signature while exploiting the whole relevant spatiotemporal information. The proposed model is based on multi-scale features extracted from a novel data structure called ‘Two-Half-Video-Tree’ (THVT) which represents the pedestrians and allows discarding the uncontrolled variations. THVT can efficiently model the gait and appearance of the upper and lower parts of the person’s silhouette into trees of multi-scale features. THVT can thus model the video data to new structured forms through a fast algorithm. Furthermore, GAMS-ViCov approach can also be competitive as a technique of dynamic video summarization using k-means clustering to model the signatures extracted from the image-sequences of each person into a cluster center. For each person’s cluster, the image-sequence that its signature is nearest to the centroid is selected and stored as the key image-sequence of this person. The proposed approach was evaluated for the person (re)-identification with i-LIDS and PRID databases. The experimental results show that GAMS-ViCov outperforms the most of unsupervised approaches.},
  archive      = {J_EAAI},
  author       = {Bassem Hadjkacem and Walid Ayedi and Mossaad Ben Ayed and Shaya A. Alshaya and Mohamed Abid},
  doi          = {10.1016/j.engappai.2020.103566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel gait-appearance-based multi-scale video covariance approach for pedestrian (re)-identification},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing the maximum receiver interference in wireless
sensor networks using probabilistic interference model. <em>EAAI</em>,
<em>91</em>, 103563. (<a
href="https://doi.org/10.1016/j.engappai.2020.103563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Now in the era of the Internet of Energy (IoE), researchers are more focused on optimal energy utilization. In the wireless sensor network, maximization of battery lifetime or network lifetime is one of the primary research objectives. There are many techniques available to enhance the network lifetime, and interference minimization is one of them. Interference minimization leads to less transmission power consumption in wireless sensor networks and thus enhances the network lifetime. The interference minimization is proven to be NP-Hard problem. In this paper, we have proposed a method to minimize receiver interference using different encoding schemes and genetic algorithm. We have used more realistic probabilistic interference model to calculate receiver interference instead of the graph-based model used in most of the literature. The Genetic Algorithm used to minimize receiver interference uses three different chromosome representation schemes, namely Prüfer code, Edge-set, and Edge-window-decoder. We have used benchmark data sets and special cases like exponential node chain, two exponential node chain, spiral model, one cluster, and two-cluster for experimental simulations. Our proposed algorithm outperforms other algorithms available in the literature like MI-S (Minimizing Interference in Sensor networks), MinMax-RIP (Minimizing Maximum Receiver Interference Problem), and MST (Minimum Spanning Tree: Prim’s algorithm) in terms of minimizing maximum receiver interference in the network.},
  archive      = {J_EAAI},
  author       = {Susil Kumar Mohanty and Siba K. Udgata},
  doi          = {10.1016/j.engappai.2020.103563},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103563},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Minimizing the maximum receiver interference in wireless sensor networks using probabilistic interference model},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpretation and modeling of emotions in the management of
autonomous robots using a control paradigm based on a scheduling
variable. <em>EAAI</em>, <em>91</em>, 103562. (<a
href="https://doi.org/10.1016/j.engappai.2020.103562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a technical introduction to psychological theories of emotions. It highlights a usable idea implemented in a number of recently developed computational systems of emotions, and the hypothesis that emotion can play the role of a scheduling variable in controlling autonomous robots. In the main part of this study, we outline our own computational system of emotion – xEmotion – designed as a key structural element in the developed target device, being an Intelligent System of Decision-making (ISD) for autonomous and robotic units. The ISD system has a cognitive architecture based on the principles of human psychology. The main purpose of building such a system is to prepare a framework for autonomous units used in system engineering (Kowalczuk and Czubenko, 2011; Czubenko et al., 2015). In particular, ISD is based on the concepts of cognitive psychology (in information processing) and motivation theory , which includes the system of needs (for decision-making). The xEmotion subsystem, however, focuses on modeling an alternative approach based on emotion. The xEmotion implementation covers aspects of somatic, appraisal and evolutionary theories of emotions using fuzzy sets. In this article, we also illustrate the core emotional behavior of the ISD system using simulation. The first application is a user interface for identifying emotions and predicting human behavior. The second is an eSailor simulation, which illustrates the possible behavior of the xEmotion subsystem. The last is an xDriver simulation experiment, which is to prove the validity of the concept of using emotion-based systems, according to the SVC principle. In summary, we also discuss other possible applications of the xEmotion system.},
  archive      = {J_EAAI},
  author       = {Zdzisław Kowalczuk and Michał Czubenko and Tomasz Merta},
  doi          = {10.1016/j.engappai.2020.103562},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103562},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretation and modeling of emotions in the management of autonomous robots using a control paradigm based on a scheduling variable},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interpretable policies for reinforcement learning by
empirical fuzzy sets. <em>EAAI</em>, <em>91</em>, 103559. (<a
href="https://doi.org/10.1016/j.engappai.2020.103559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a method and an algorithm to implement interpretable fuzzy reinforcement learning (IFRL). It provides alternative solutions to common problems in RL, like function approximation and continuous action space. The learning process resembles that of human beings by clustering the encountered states, developing experiences for each of the typical cases, and making decisions fuzzily. The learned policy can be expressed as human-intelligible IF-THEN rules, which facilitates further investigation and improvement. It adopts the actor–critic architecture whereas being different from mainstream policy gradient methods. The value function is approximated through the fuzzy system AnYa. The state–action space is discretized into a static grid with nodes. Each node is treated as one prototype and corresponds to one fuzzy rule, with the value of the node being the consequent. Values of consequents are updated using the Sarsa( λ ) algorithm. Probability distribution of optimal actions regarding different states is estimated through Empirical Data Analytics (EDA), Autonomous Learning Multi-Model Systems (ALMMo), and Empirical Fuzzy Sets ( ε FS). The fuzzy kernel of IFRL avoids the lack of interpretability in other methods based on neural networks. Simulation results with four problems, namely Mountain Car, Continuous Gridworld, Pendulum Position, and Tank Level Control, are presented as a proof of the proposed concept.},
  archive      = {J_EAAI},
  author       = {Jianfeng Huang and Plamen P. Angelov and Chengliang Yin},
  doi          = {10.1016/j.engappai.2020.103559},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103559},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable policies for reinforcement learning by empirical fuzzy sets},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Alternatives selection for produced water management: A
network-based methodology. <em>EAAI</em>, <em>91</em>, 103556. (<a
href="https://doi.org/10.1016/j.engappai.2020.103556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Products and process strategies selection has attracted much attention, especially for produced water management. In order to select best alternatives, it is necessary to develop a comprehensive decision-making methodology applicable to complex and uncertain systems. In this paper, we propose a new network-based methodology of decision-making. Firstly, the discrete quantitative and qualitative input data are mapped into networks based on ordered visibility graph. Then we take advantages of network topologies, which are node degree and node distance, to establish the relationships among the input data. Finally, the data are aggregated into a single value to make a decision. The case study indicates that our method is advantageous to make decisions objectively while inheriting the characteristics of network structures.},
  archive      = {J_EAAI},
  author       = {Shengzhong Mao and Yong Deng and Danilo Pelusi},
  doi          = {10.1016/j.engappai.2020.103556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Alternatives selection for produced water management: A network-based methodology},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust support vector data description for novelty detection
with contaminated data. <em>EAAI</em>, <em>91</em>, 103554. (<a
href="https://doi.org/10.1016/j.engappai.2020.103554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector data description (SVDD) is a widely used novelty detection algorithm. It provides excellent predictions even in the absence of negative samples and retains the mathematical elegance of Support Vector Machines. The decision boundary can be very flexible due to the incorporation of kernel functions. However, SVDD can suffer a lot from contaminated data containing, for example, outliers or mislabeled observations. Although several weighting schemes have been proposed to find a more reliable description of the target data, the calculation of the weight are themselves affected by the outliers and does not provide much insight in the data. The masked outliers fail to receive lower weight values. The Stahel–Donoho (SD) outlyingness from multivariate statistics is a very robust measure to expose the outliers. To avoid the masking effect, we propose to assign weight to each observation based on the SD outlyingness in an arbitrary kernel space. A robust SVDD is defined down-weighting the samples with large outlyingness. The experimental results demonstrate superiority of the proposed method in terms of AUC for contaminated data.},
  archive      = {J_EAAI},
  author       = {Kunzhe Wang and Haibin Lan},
  doi          = {10.1016/j.engappai.2020.103554},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103554},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust support vector data description for novelty detection with contaminated data},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Directional adversarial training for cost sensitive deep
learning classification applications. <em>EAAI</em>, <em>91</em>,
103550. (<a
href="https://doi.org/10.1016/j.engappai.2020.103550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications of Machine Learning it is of paramount importance not only to provide accurate predictions, but also to ensure certain levels of robustness. Adversarial Training is a training procedure aiming at providing models that are robust to worst-case perturbations around predefined points. Unfortunately, one of the main issues in adversarial training is that robustness w.r.t. gradient-based attackers is always achieved at the cost of prediction accuracy. In this paper, a new algorithm, called Wasserstein Projected Gradient Descent (WPGD), for adversarial training is proposed. WPGD provides a simple way to obtain cost-sensitive robustness, resulting in a finer control of the robustness-accuracy trade-off. Moreover, WPGD solves an optimal transport problem on the output space of the network and it can efficiently discover directions where robustness is required, allowing to control the directional trade-off between accuracy and robustness. The proposed WPGD is validated in this work on image recognition tasks with different benchmark datasets and architectures. Moreover, real world-like datasets are often imbalanced: this paper shows that when dealing with such type of datasets, the performance of adversarial training are mainly affected in term of standard accuracy.},
  archive      = {J_EAAI},
  author       = {Matteo Terzi and Gian Antonio Susto and Pratik Chaudhari},
  doi          = {10.1016/j.engappai.2020.103550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Directional adversarial training for cost sensitive deep learning classification applications},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online prediction of noisy time series: Dynamic adaptive
sparse kernel recursive least squares from sparse and adaptive tracking
perspective. <em>EAAI</em>, <em>91</em>, 103547. (<a
href="https://doi.org/10.1016/j.engappai.2020.103547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the deepening of the research on kernel recursive least squares (KRLS), significant researches have been applied to time series online prediction. However, it usually ignores the extraneous and redundant factors in the raw data, which can cause bias in the prediction. In addition, it usually contains both noise and non-stationary characteristics, resulting in deteriorated prediction accuracy and reduced model efficiency. To ease the above two drawbacks of conventional KRLS, this brief presents a dynamic adaptive sparse kernel recursive least squares (DASKRLS) filtering algorithm. It first uses the online vector projection standard and the approximate linear dependence criterion to effectively constrain kernel matrix dimension, and reduce the computational complexity of the model. After that, the regularized maximum correlation entropy criterion to significant process noise-containing data from the perspective of improving generalization ability. Moreover, the adaptive update mechanism can dynamically track the real-time weight of non-stationary signals. The dynamic sparse process is essentially equivalent to a feature selection process that maintains low-dimensional manifold information. Lorenz benchmarking experiments and real data experiments show that DASKRLS achieves better prediction performance in complex systems with noise and nonstationary.},
  archive      = {J_EAAI},
  author       = {Kai Zhong and Junzhu Ma and Min Han},
  doi          = {10.1016/j.engappai.2020.103547},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103547},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online prediction of noisy time series: Dynamic adaptive sparse kernel recursive least squares from sparse and adaptive tracking perspective},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid DEMATEL-FRACTAL method of handling dependent
evidences. <em>EAAI</em>, <em>91</em>, 103543. (<a
href="https://doi.org/10.1016/j.engappai.2020.103543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster combination rule in evidence theory is widely used in data fusion system. One assumption of Dempster combination rule is the independence among different evidences. However, it is difficult to satisfy this requirement due to many influencing factors. The main contribution of this paper is to propose a systematic model to deal with dependence evidences in evidence theory. The core of the model can be divided into two parts: handling inner dependence and handling outer dependence. For the inner dependence, we use DEMATEL model to establish the relationships between different components in the system and get their relative weights considering their influences. For the outer dependence, we use BPAs inherent fractals features to deal with the uncertainty in the outer environment as well as the dependence among each collected evidence. After that we combine these two aspects of dependence and make decisions. By discounting evidences we avoid redundant calculation thus obtain useful information as much as possible. A case study of transportation project selection problem is used to illustrate our proposed method.},
  archive      = {J_EAAI},
  author       = {Shengzhong Mao and Yuzhen Han and Yong Deng and Danilo Pelusi},
  doi          = {10.1016/j.engappai.2020.103543},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {103543},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid DEMATEL-FRACTAL method of handling dependent evidences},
  volume       = {91},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emerging issues and applications of type-2 fuzzy sets and
systems. <em>EAAI</em>, <em>90</em>, 103596. (<a
href="https://doi.org/10.1016/j.engappai.2020.103596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Oscar Castillo ( Special Issue Editors ) and Pranab K. Muhuri and Patricia Melin and Pietari Pulkkinen},
  doi          = {10.1016/j.engappai.2020.103596},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103596},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emerging issues and applications of type-2 fuzzy sets and systems},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding of wheelchair ramp scenes for disabled people
with visual impairments. <em>EAAI</em>, <em>90</em>, 103569. (<a
href="https://doi.org/10.1016/j.engappai.2020.103569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Helping disabled people with visual impairments understand wheelchair ramp scenes has considerable value in computer vision. However, due to the diversity of wheelchair ramp scenes, understanding them remains a big challenge. Wheelchair ramp planes can be considered as a composition of rectangles that do not satisfy manhattan assumption. These non-manhattan rectangles are projected into two dimensional projections, shaping into special geometric configurations, which may enable us to estimate their original orientation and position in 3D scenes. In this paper, we presented a method for disabled people with visual impairments to understand wheelchair ramp scenes from a single image without any prior training. Firstly angle projections can be assigned to different clusters. Secondly ramp vanishing points (RVPs) can be estimated. Then it is possible to determine ramp planes consisting of angle projections that belong to the estimated RVPs. Finally, the algorithm can understand wheelchair ramp scenes including not only manhattan structures but also ramp planes belonging to non-manhattan structures. The proposed approach requires no prior training or any knowledge of the camera’s internal parameters. Besides, it is robust to the errors in calibration and image noise. We compared the estimated wheelchair ramp scene layout against the ground truth, measuring the percentage of pixels that were incorrectly classified. The experimental results showed that the method can understand wheelchair ramp scenes including not only manhattan structures but also non-manhattan structures of ramp planes, making it practical and efficient for disabled people with visual impairments.},
  archive      = {J_EAAI},
  author       = {Luping Wang and Hui Wei},
  doi          = {10.1016/j.engappai.2020.103569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Understanding of wheelchair ramp scenes for disabled people with visual impairments},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic review on content-based video retrieval.
<em>EAAI</em>, <em>90</em>, 103557. (<a
href="https://doi.org/10.1016/j.engappai.2020.103557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-based video retrieval and indexing have been associated with intelligent methods in many applications such as education, medicine and agriculture. However, an extensive and replicable review of the recent literature is missing. Moreover, relevant topics that can support video retrieval, such as dimensionality reduction, have not been surveyed. This work designs and conducts a systematic review to find papers able to answer the following research question: “what segmentation, feature extraction, dimensionality reduction and machine learning approaches have been applied for content-based video indexing and retrieval?”. By applying a research protocol proposed by us, 153 papers published from 2011 to 2018 were selected. As a result, it was found that strategies for cut-based segmentation, color-based indexing, k-means based dimensionality reduction and data clustering have been the most frequent choices in recent papers. All the information extracted from these papers can be found in a publicly available spreadsheet. This work also indicates additional findings and future research directions.},
  archive      = {J_EAAI},
  author       = {Newton Spolaôr and Huei Diana Lee and Weber Shoity Resende Takaki and Leandro Augusto Ensina and Claudio Saddy Rodrigues Coy and Feng Chung Wu},
  doi          = {10.1016/j.engappai.2020.103557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review on content-based video retrieval},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Holistic design for deep learning-based discovery of tabular
structures in datasheet images. <em>EAAI</em>, <em>90</em>, 103551. (<a
href="https://doi.org/10.1016/j.engappai.2020.103551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting data from tabular structures contained within product datasheets is crucial in many contexts, particularly in the management and optimization of supply chains that serve various industries. In order to minimize human intervention, table detection and table structure detection form the essential functionality. However, a self-contained holistic solution to extract the tables as well as their columns and rows in not readily available. To address this challenge, This study presents a new formal procedure that consists of the following sequence: table detection, structure segmentation and holistic tabular structure detection on documents. The proposed table detection model outperforms the state-of-the-art solutions by achieving a recall value of 1.0 and a precision of more than 0.99 on public competition datasets. Furthermore, this work introduces a judging mechanism and an agreement-based post-processing procedure to incorporate hand-crafted rules into the deep learning models. Though the individual components achieve a new state-of-the-art F1-Score, when integrated the best achieved F-measure for the holistic system is 0.89.},
  archive      = {J_EAAI},
  author       = {Ertugrul Kara and Mark Traquair and Murat Simsek and Burak Kantarci and Shahzad Khan},
  doi          = {10.1016/j.engappai.2020.103551},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103551},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Holistic design for deep learning-based discovery of tabular structures in datasheet images},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Toward optimum fuzzy support vector machines using error
distribution. <em>EAAI</em>, <em>90</em>, 103545. (<a
href="https://doi.org/10.1016/j.engappai.2020.103545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVM) is one of the prevalent techniques in the machine learning which is applicable in many of the real world classification problems. However, these problems are sensitive to noise and the presence of the outliers in training data. For this reason, other methods like fuzzy SVM (FSVM) were introduced to solve this challenge. Similar to SVM, these methods look for finding an optimal hyperplane that separates classes with the maximum possible margin. The main difference is the allocation of fuzzy membership degree to each training sample based on its significance so that leads to the resistance of the method. In this paper to overcome this problem, we proposed a robust FSVM based on prior knowledge related to error distribution (PKED-FSVM) to classify synthetic and real data. The optimal coefficient in our proposed PKED-FSVM method is introduced from the viewpoint of minimum Bayesian risk. Our proposed method is compared with SVM and other FSVM methods and results are obtained on several types of synthetic data from UCI. Finally, we collected the social media images from 500px based on user-tagged and created two data sets; Coastal-Non-Coastal, and the Rural–urban, and used the proposed method to classify these two data sets and separating coastal areas from non-coastal areas, and urban areas from rural areas, respectively. The results show that our proposed method has acceptable performance and works better than other competing methods.},
  archive      = {J_EAAI},
  author       = {Tahereh Bahraini and Saeedeh Ghazi and Hadi Sadoghi Yazdi},
  doi          = {10.1016/j.engappai.2020.103545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Toward optimum fuzzy support vector machines using error distribution},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tunicate swarm algorithm: A new bio-inspired based
metaheuristic paradigm for global optimization. <em>EAAI</em>,
<em>90</em>, 103541. (<a
href="https://doi.org/10.1016/j.engappai.2020.103541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a bio-inspired metaheuristic optimization algorithm named Tunicate Swarm Algorithm (TSA). The proposed algorithm imitates jet propulsion and swarm behaviors of tunicates during the navigation and foraging process. The performance of TSA is evaluated on seventy-four benchmark test problems employing sensitivity, convergence and scalability analysis along with ANOVA test. The efficacy of this algorithm is further compared with several well-regarded metaheuristic approaches based on the generated optimal solutions. In addition, we also executed the proposed algorithm on six constrained and one unconstrained engineering design problems to further verify its robustness. The simulation results demonstrate that TSA generates better optimal solutions in comparison to other competitive algorithms and is capable of solving real case studies having unknown search spaces. Note that the source codes of the proposed TSA algorithm are available at},
  archive      = {J_EAAI},
  author       = {Satnam Kaur and Lalit K. Awasthi and A.L. Sangal and Gaurav Dhiman},
  doi          = {10.1016/j.engappai.2020.103541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tunicate swarm algorithm: A new bio-inspired based metaheuristic paradigm for global optimization},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic shuffled frog-leaping algorithm for distributed
hybrid flow shop scheduling with multiprocessor tasks. <em>EAAI</em>,
<em>90</em>, 103540. (<a
href="https://doi.org/10.1016/j.engappai.2020.103540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed scheduling problems have attracted much attention in recent years; however, distributed hybrid flow shop scheduling problem (DHFSP) is seldom investigated. In this paper, DHFSP with multiprocessor tasks is studied and a dynamic shuffled frog-leaping algorithm (DSFLA) is proposed to minimize makespan. Dynamic search process is executed in each memeplex with at least two improved solutions. Global search and dynamic multiple neighborhood search are applied, in which neighborhood structure is chosen based on its optimization effect. A new destruction-construction process is hybridized with DSFLA and population shuffling is done when shuffling condition is met. Lower bound is obtained and proved. A number of experiments are conducted on a set of instances. The computational results validate the effectiveness of the new strategies of DSFLA and the competitive performances on solving the considered DHFSP.},
  archive      = {J_EAAI},
  author       = {Jingcao Cai and Rui Zhou and Deming Lei},
  doi          = {10.1016/j.engappai.2020.103540},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103540},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic shuffled frog-leaping algorithm for distributed hybrid flow shop scheduling with multiprocessor tasks},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast and scalable algorithms for mining subgraphs in a
single large graph. <em>EAAI</em>, <em>90</em>, 103539. (<a
href="https://doi.org/10.1016/j.engappai.2020.103539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining frequent subgraphs is an important issue in graph mining. It is defined as finding all subgraphs whose occurrences in the dataset are greater than or equal to a given frequency threshold. In recent applications, such as social networks, the underlying graphs are very large. Algorithms for mining frequent subgraphs from a single large graph have been developing rapidly lately. Among all such algorithms, GraMi is considered the state-of-the-art. However, GraMi still consumes a lot of time and memory in the mining of a large graph. In this paper, we propose two effective strategies to optimize the GraMi algorithm, which help to increase performance as well as reduce memory consumption during execution. Firstly, GraMi only lists all frequent subgraphs, without computing the support of each mined subgraph. This is disadvantageous in decision support systems, which require information about the support of all subgraphs. Therefore, we optimize GraMi to compute the support values during the mining process. Secondly, we apply the strategy of sorting all edges in graphs by their frequencies, which means that edges with low frequencies will be mined first, and vice versa . This sorting strategy can reduce the number of possibly infrequent subgraph candidates, especially on large subgraphs that are usually derived from those edges with high frequency. Thirdly, we apply a parallel processing technique, in which each frequent edge is executed simultaneously in a separate thread, and improve our parallel strategy by combination with the sorting strategy. Our experiments were performed on three real datasets and the results showed that the performance, as well as memory requirements, are better than those of the original GraMi algorithm},
  archive      = {J_EAAI},
  author       = {Lam B.Q. Nguyen and Bay Vo and Ngoc-Thao Le and Vaclav Snasel and Ivan Zelinka},
  doi          = {10.1016/j.engappai.2020.103539},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103539},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast and scalable algorithms for mining subgraphs in a single large graph},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple random empirical kernel learning with margin
reinforcement for imbalance problems. <em>EAAI</em>, <em>90</em>,
103535. (<a
href="https://doi.org/10.1016/j.engappai.2020.103535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalance problems arise in real-world applications when the number of negative samples far exceeds the number of positive samples, such as medical data. When solving the classification of imbalance problems, the samples located near the decision hyperplane contribute more to the decision hyperplane, and the samples far from the decision hyperplane contribute less to the decision hyperplane. So we can consider giving higher weights to the samples near the decision hyperplane, but they are sensitive to noise, and too much emphasis on them may lead to unstable performance. This paper proposes a Margin Reinforcement (MR) method to overcome the above dilemma. Because the imbalance problem is a cost-sensitive problem, MR gives positive samples a uniform high weight to improve the misclassification cost of the positive sample. For negative samples, according to their entropy, samples away from the decision surface and noise samples mixed in the positive samples are given a smaller weight, in order to improve the efficiency and robustness of the algorithm. Therefore, MR can emphasize the importance of samples located in overlapping regions of positive and negative classes and ignore the effects of noise samples to produce superior performance. Multiple Random Empirical Kernel Learning (MREKL) has proven to be effective and efficient in dealing with balance problems. In order to improve the performance of MREKL on imbalanced datasets, MR is introduced into MREKL to propose a novel Multiple Random Empirical Kernel Learning with Margin Reinforcement (MREKL-MR). MREKL-MR efficiently map the samples into low-dimensional feature spaces, then utilizes the MR approach to reenforce the importance of margin samples and decrease the effects of noise samples. Experimental results on 28 imbalanced datasets indicate that MREKL-MR is superior to comparison algorithms. Finally, the effectiveness of MREKL-MR in dealing with imbalance problems is verified on the Heart Failure dataset.},
  archive      = {J_EAAI},
  author       = {Zhe Wang and Lilong Chen and Qi Fan and DongDong Li and Daqi Gao},
  doi          = {10.1016/j.engappai.2020.103535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple random empirical kernel learning with margin reinforcement for imbalance problems},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of multi-view graph embedding using multiple kernel
learning. <em>EAAI</em>, <em>90</em>, 103534. (<a
href="https://doi.org/10.1016/j.engappai.2020.103534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph embedding is the process of representing the graph in a vector space using properties of the graphs and this technique has now being widely used for analyzing the graph data using machine learning algorithms. The existing graph embeddings rely mostly on a single property of graphs for data representation which is found to be inappropriate to capture all the characteristics of the data. Hence we designed graph embedding using multi-view approach, where each view is an embedding of the graph using a graph property. The input space of multi-view learning is then taken as the direct sum of the subspaces in which the graph embedding lie. We did analysis on real world data by incorporating the proposed model on support vector machines (SVM). The reproducing kernel used in SVM is represented as the linear combination of the kernels defined on the individual embeddings. The optimization technique used in simple multiple kernel learning (simpleMKL) is used to find the parameters of the optimal kernel. To analyze the individual representation capability of the embeddings, an R-convolution graph kernel is designed over each of the views. In our experimental analysis, the multi-view graph embedding showed a superior performance in comparison with that of the state-of-the-art graph embeddings as well as graph kernels.},
  archive      = {J_EAAI},
  author       = {Asif Salim and S.S. Shiju and S. Sumitra},
  doi          = {10.1016/j.engappai.2020.103534},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103534},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Design of multi-view graph embedding using multiple kernel learning},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The fast maximum distance to average vector (f-MDAV): An
algorithm for k-anonymous microaggregation in big data. <em>EAAI</em>,
<em>90</em>, 103531. (<a
href="https://doi.org/10.1016/j.engappai.2020.103531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive exploitation of tons of data is currently guiding critical decisions in domains such as economics or health. But serious privacy risks arise since personal data is commonly involved. k -Anonymous microaggregation is a well-known method that guarantees individuals’ privacy while preserving much of data utility. Unfortunately, methods like this are computationally expensive in big data settings, whereas the application domain of data might require an immediate response to make “life or death” decisions. Accordingly, this paper proposes five strategies to simplify the internal operations (such as distance calculations and element sorting) of the maximum distance to average vector algorithm, the de facto microaggregation standard. For the sake of its usability in large-scale databases, they, e.g., reduce the number of operations necessary to compute distances from 3 m to 2 m , where m is the number of attributes of the data set. Also, the complexity of sorting operations gets reduced from O ( n log n ) to O ( n ) where n is the number of records. Through extensive experimentation over multiple data sets, we show that the new algorithm gets significantly faster. Interestingly, the speedup factor by each technique is not greater than 2, but the multiplicative effect of combining them all turns the algorithm four times faster than the original microaggregation mechanism. This remarkable speedup factor is achieved, literally, with no additional cost in terms of data utility, i.e., it does not incur greater information loss.},
  archive      = {J_EAAI},
  author       = {Ana Rodríguez-Hoyos and José Estrada-Jiménez and David Rebollo-Monedero and Ahmad Mohamad Mezher and Javier Parra-Arnau and Jordi Forné},
  doi          = {10.1016/j.engappai.2020.103531},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103531},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The fast maximum distance to average vector (F-MDAV): An algorithm for k-anonymous microaggregation in big data},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comprehensive overview of smart wearables: The state of
the art literature, recent advances, and future challenges.
<em>EAAI</em>, <em>90</em>, 103529. (<a
href="https://doi.org/10.1016/j.engappai.2020.103529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart wearables have gained considerable attention from Information Systems (IS) academics, business managers, and health practitioners. In spite of the availability of authentic research studies of smart wearables, there is still a lack of systematic review on the different aspects of smart wearables concept to find the current state of research, particularly from the perspective of IS field. Therefore, the predominant aim of this research is to review smart wearables literature, recent advances, and future challenges. Accordingly, a systematic literature review was conducted to explore smart wearables by reviewing previous studies from 2010 to 2019. For covering all related papers during these years, an integrated review protocol consisting of automatic and manual stages was pursued. 244 papers were identified to address smart wearables issues and challenges. According to the findings, it is observed that smart wearable studies have increased dramatically during the last years. Moreover, the results show that current studies covered different research themes which are related to smart wearables area, particularly user behavior, technology-focused, security and privacy, design, and social acceptability. Furthermore, based on the results of the weight analysis technique, perceived usefulness, attitude toward technology, social influence, and privacy concerns are identified as the best predictors of smart wearables adoption. Additionally, the results show that the Technology Acceptance Model (TAM) is the most commonly adopted theory in the smart wearable studies. The findings of this review would assist academics to realize the existing limitations and gaps as well as the future works for smart wearables research studies.},
  archive      = {J_EAAI},
  author       = {Naghmeh Niknejad and Waidah Binti Ismail and Abbas Mardani and Huchang Liao and Imran Ghani},
  doi          = {10.1016/j.engappai.2020.103529},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103529},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive overview of smart wearables: The state of the art literature, recent advances, and future challenges},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaborative weighted multi-view feature extraction.
<em>EAAI</em>, <em>90</em>, 103527. (<a
href="https://doi.org/10.1016/j.engappai.2020.103527">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current multi-view feature extraction methods mainly consider the consistency and complementary information between multi-view samples, therefore have some drawbacks. They ignore the manifold structure of the single-view itself, and also ignore the differences among the similarities between any two views when the number of views is greater than two, because of assigning the same weight to them. In this paper, we propose a novel multi-view feature extraction method termed as collaborative weighted multi-view feature extraction or CWMvFE. Here the local collaborative representative (LCR) method is utilized to preserve the local correlation in between-view and within-view respectively. Furthermore, it realizes that less similar view pairs should share more consistency and complementary information, where Jensen Shannon divergence is used to reflect the similarity between different view pairs. Therefore, the proposed CWMvFE not only preserves the local correlation in multi-view, including local correlation in both between-view and within-view, but also explores the differences in similarities between different view pairs. Experiments on four image datasets demonstrate that CWMvFE has better performance than other related methods.},
  archive      = {J_EAAI},
  author       = {Jinxin Zhang and Peng Zhang and Liming Liu and Naiyang Deng and Ling Jing},
  doi          = {10.1016/j.engappai.2020.103527},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103527},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collaborative weighted multi-view feature extraction},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel policy gradient algorithm with PSO-based parameter
exploration for continuous control. <em>EAAI</em>, <em>90</em>, 103525.
(<a href="https://doi.org/10.1016/j.engappai.2020.103525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous control has attracted enormous attention due to its essential role in real-world applications. However, it is considerably difficult to be addressed through explicitly modeling in practice. As promising approaches, model-free policy gradient (PG) based methods in reinforcement learning (RL), however, suffer from slow convergence and complex computation owing to the high variance of gradient estimating and sophisticated backpropagation. Therefore, in this paper, a gradient-free policy gradient algorithm with PSO-based parameter exploration (PG-PSOPE) is proposed for continuous control tasks. To reduce variance and improve convergence rate, the PSO is combined with PG to provide a novel way for training policy network in RL. Experimental results of simulated physical control tasks verify the effectiveness of the proposed algorithm. Besides, the PG-PSOPE is superior in both convergence speed and final performance to the typical on-policy PG and the off-policy deep RL method. Furthermore, the PG-PSOPE exhibits the simplicity and high effectiveness by comparison of training time under different tasks, and its running time is reduced by 58 times compared with other gradient-based methods for the best case.},
  archive      = {J_EAAI},
  author       = {Tundong Liu and Liduan Li and Guifang Shao and Xiaomin Wu and Meng Huang},
  doi          = {10.1016/j.engappai.2020.103525},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103525},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel policy gradient algorithm with PSO-based parameter exploration for continuous control},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A machine learning approach to modelling escalator demand
response. <em>EAAI</em>, <em>90</em>, 103521. (<a
href="https://doi.org/10.1016/j.engappai.2020.103521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article relates to the topic of the escalator demand response potential. Previous studies mapped escalators as an unrealized potential for additional demand response. The decrease of the nominal speed is the proposed method of reducing the power consumption of an escalator that comes at the cost of passenger travel time and queuing. This work proposes a solution to a problem of selecting appropriate escalators from a large pool to accommodate the target of power curtailment at a minimum cost and highlights the escalator features that constitute the best demand response candidates. The paper compares four methods which differ in calculation speed and accuracy. The primal solution is the earlier developed and enhanced simulation-based model. The random forest and the neural network models provide a solution trained on the output of the simulation-based model aiming to enhance the calculation speed. Finally, all of the developed solutions are compared to the random selection of escalators. The comparison of the proposed statistical approaches shows that the random forest outperforms the neural networks with a maximum error in the prediction of the overall costs in the range of 10.5% of the simulation-based model solution, while the neural network solution lies within 10%–58%, depending on the targeted value of the power reduction. Statistical approaches enable performing predictions for different times of the day and for new escalator populations without the need for time-demanding simulations. Comparison to the random selection of escalators demonstrates that the proposed models generally outperform the random selection at least seven-fold.},
  archive      = {J_EAAI},
  author       = {Semen Uimonen and Toni Tukia and Jussi Ekström and Marja-Liisa Siikonen and Matti Lehtonen},
  doi          = {10.1016/j.engappai.2020.103521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A machine learning approach to modelling escalator demand response},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semisupervised classification of remote sensing images using
efficient neighborhood learning method. <em>EAAI</em>, <em>90</em>,
103520. (<a
href="https://doi.org/10.1016/j.engappai.2020.103520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency of a classification model can be enhanced with more number of accurately labeled samples, which are difficult to obtain in remote sensing imagery. To mitigate this issue, semisupervised learning methodologies can be suitably used that exploit both unlabeled and labeled samples in the learning process and lead to the performance improvement of a classification model. With this reasoning, the present article proposes a self-learning semisupervised classification model using a neural network (NN) as the base classifier. The model uses an efficient neighborhood information learning method for the NN to overcome the demerits of existing conventional approaches. It is very crucial and challenging to find the true and the most relevant neighborhood information of unlabeled samples. Using two different approaches, we propose the generation of similarity matrixes for extracting neighborhood information that eventually improve the learning process of NN. The first method considers mutual neighborhood information and the second method uses the class-map of unlabeled samples. Class labels of the unlabeled samples are predicted by a classifier, i.e., trained with the available labeled samples. Finally, the collaborative neighborhood information is derived from these two matrixes and used for the development of the proposed semisupervised classification model. Experimental demonstration on three multispectral and one hyperspectral remote sensing images justified the superiority of the proposed model compared to the existing state-of-the-art methods. For comparative analysis, various performance measures, such as overall accuracy, kappa coefficient, precision, recall, dispersion score, β , and Davies–Bouldin (DB) scores are used.},
  archive      = {J_EAAI},
  author       = {Neeta S. Kothari and Saroj K. Meher},
  doi          = {10.1016/j.engappai.2020.103520},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103520},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semisupervised classification of remote sensing images using efficient neighborhood learning method},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ensemble framework by using nature inspired algorithms for
the early-stage forest fire rescue — a case study of dynamic
optimization problems. <em>EAAI</em>, <em>90</em>, 103517. (<a
href="https://doi.org/10.1016/j.engappai.2020.103517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose rescue ensemble to simulate the dynamic rescue process between forest fire spread and forest fire rescue, while simultaneously formulating this process as a dynamic optimization problem. However, there is still little research about simulating this kind of the dynamic rescue process, even when many new unmanned monitoring systems and large-scale firefighting aircraft emerge in the forest-fire-rescue field. Our rescue ensemble that consists of rescue simulator and rescue algorithm is characterized by supporting the offline simulation of the dynamic rescue process between forest fire spread (like offensive forces) and forest fire rescue (like defensive forces). Based on modifying the cellular automaton model of forest fire spread, rescue simulator is able to simulate forest fire spread and aircraft firefighting, simultaneously. Besides, the main goal of rescue algorithm is to realize the aircraft task allocation. Firefighting particle swarm optimization is proposed by us as our rescue algorithm, which is characterized by considering fire edge suppression, the burning-cell continuity, and wind direction. We construct our test problems based on real forest maps and aircraft firefighting capability. Comparing with four compared rescue algorithms, we test the different capabilities of firefighting particle swarm optimization, such as searching dynamic optimal solution, shortening the rescue time, controlling the spread speed of fire edge, and minimizing the burned cost. Experimental results demonstrate that the framework of rescue ensemble is feasible. Meanwhile, the results of firefighting particle swarm optimization are satisfactory in most cases.},
  archive      = {J_EAAI},
  author       = {HongGuang Zhang and ZiHan Liang and HuaJian Liu and Rui Wang and YuanAn Liu},
  doi          = {10.1016/j.engappai.2020.103517},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103517},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble framework by using nature inspired algorithms for the early-stage forest fire rescue — a case study of dynamic optimization problems},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Advising reinforcement learning toward scaling agents in
continuous control environments with sparse rewards. <em>EAAI</em>,
<em>90</em>, 103515. (<a
href="https://doi.org/10.1016/j.engappai.2020.103515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper adapts the success of the teacher–student framework for reinforcement learning to a continuous control environment with sparse rewards. Furthermore, the proposed advising framework is designed for the scaling agents problem, wherein the student policy is trained to control multiple agents while the teacher policy is well trained for a single agent. Existing research on teacher–student frameworks have been focused on discrete control domain. Moreover, they rely on similar target and source environments and as such they do not allow for scaling the agents. On the other hand, in this work the agents face a scaling agents problem where the value functions of the source and target task converge at different rates. Existing concepts from the teacher–student framework are adapted to meet new challenges including early advising, importance of advising, and mistake correction, but a modified heuristic was used to decide on when to teach. The performance of the proposed algorithm was evaluated using the case study of pushing, and picking and placing objects with a dual arm manipulation system. The teacher policy was trained using a simulated scenario consisting of a single arm. The student policy was trained to handle the dual arm manipulation system in simulation under the advice of the teacher agent. The trained student policy was then validated using two Quanser Mico arms for experimental demonstration. The effects of varying parameters on the student performance in the advising framework was also analyzed and discussed. The results showed that the proposed advising framework expedited the training process and achieved the desired scaling within a limited advising budget.},
  archive      = {J_EAAI},
  author       = {Hailin Ren and Pinhas Ben-Tzvi},
  doi          = {10.1016/j.engappai.2020.103515},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103515},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advising reinforcement learning toward scaling agents in continuous control environments with sparse rewards},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A rational and consensual method for group decision making
with interval-valued intuitionistic multiplicative preference relations.
<em>EAAI</em>, <em>90</em>, 103514. (<a
href="https://doi.org/10.1016/j.engappai.2020.103514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued intuitionistic multiplicative variables (IVIMVs) can conveniently and effectively represent the uncertain multiplicative preferred and non-preferred judgements of decision makers, this paper studies group decision making (GDM) with interval-valued intuitionistic multiplicative preference relations (IVIMPRs). To calculate the interval-valued intuitionistic multiplicative priority weight vector reasonably, a new consistency concept is introduced that satisfies robustness and upper triangular property. Following this concept, models to judge the consistency and obtain consistent IVIMPRs from inconsistent ones are constructed, respectively. To address the problem of incomplete preferences, consistency-based model to determine missing values is built. Furthermore, we study the consensus for GDM with IVIMPRs and provide a new consensus approach. When an acceptable consensus level is not achieved, an interactive and automatic adjustment method is applied to reach a better consensus level. Following discussion about consistency and consensus, an algorithm for GDM is offered that can address inconsistent and incomplete IVIMPRs. Finally, a practical problem about selecting the steel supplier is selected to show the application of the new method.},
  archive      = {J_EAAI},
  author       = {Fanyong Meng and Jie Tang and Francisco Javier Cabrerizo and Enrique Herrera-Viedma},
  doi          = {10.1016/j.engappai.2020.103514},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103514},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A rational and consensual method for group decision making with interval-valued intuitionistic multiplicative preference relations},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel bat algorithm with double mutation operators and its
application to low-velocity impact localization problem. <em>EAAI</em>,
<em>90</em>, 103505. (<a
href="https://doi.org/10.1016/j.engappai.2020.103505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-velocity impact localization in the plate structure of the ship is a critical problem which can be considered as a nonlinear optimization problem. The bat algorithm (BA) has been widely used to solve nonlinear optimization problems. However, the standard BA exhibits poor performance on complex problems because of its premature convergence. In this study, a novel bat algorithm with double mutation operators (TMBA), in which a modified time factor and two mutation operators are integrated, is proposed to enhance BA’s performance on nonlinear optimization problems. Classical benchmark functions are employed to analyze the contributions of the three modifications and demonstrate the significant improvement of TMBA. For the low-velocity impact localization problem, the low-velocity impact localization system based on fiber Bragg grating (FBG) sensors is utilized to receive the impact signals. The wavelet threshold de-noising method and the generalized cross-correlation method are both applied to the extraction of time differences between the impact signals. Then, the proposed algorithm and several well-known optimization algorithms are adopted to solve the minimization fitness function which is established using the triangulation method. The statistical results indicate that TMBA is more feasible and effective for solving the low-velocity impact localization problem.},
  archive      = {J_EAAI},
  author       = {Qi Liu and Jindong Li and Lei Wu and Fengde Wang and Wensheng Xiao},
  doi          = {10.1016/j.engappai.2020.103505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel bat algorithm with double mutation operators and its application to low-velocity impact localization problem},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A critical review of the use of holonic paradigm in traffic
and transportation systems. <em>EAAI</em>, <em>90</em>, 103503. (<a
href="https://doi.org/10.1016/j.engappai.2020.103503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents a critical review of the use of holonic paradigm in order to model and simulate traffic and transportation systems. After an introduction presenting the principles of this paradigm as well as its frameworks and concepts, the paper surveys existing works using the holonic paradigm for traffic and transportation applications. This is followed by a detailed analysis of the results of the survey. In particular, the relevance, the design approaches and the holonification orientation methodologies are investigated. Finally, based on this extensive review, open issues of holonic paradigm in modeling and simulation of traffic and transportation models are highlighted.},
  archive      = {J_EAAI},
  author       = {Igor H. Tchappi and Stéphane Galland and Vivient Corneille Kamla and Jean Claude Kamgang and Yazan Mualla and Amro Najjar and Vincent Hilaire},
  doi          = {10.1016/j.engappai.2020.103503},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103503},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A critical review of the use of holonic paradigm in traffic and transportation systems},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid meta-heuristic algorithm for scientific workflow
scheduling in heterogeneous distributed computing systems.
<em>EAAI</em>, <em>90</em>, 103501. (<a
href="https://doi.org/10.1016/j.engappai.2020.103501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has attracted great attentions in research community because of its ubiquitous, unlimited computing resources, low cost, and flexibility owing to virtualization technology. This paper presents a hybrid meta-heuristic algorithm to solve parallelizable scientific workflows on elastic cloud platforms since applying a single approach cannot yield optimal solution in such complicated problems. Scientific workflows are modeled in the form of directed acyclic graph (DAG) in which there exists data dependency between sub-tasks. In the cloud marketplace, each provider delivers variable virtual machine (VM) configurations which lead different performance. Generally, parallelizable task scheduling on parallel computing machines to obtain minimum total execution time, makespan , belongs to NP-Hard problem. To deal with the combinatorial problem, the hybrid discrete particle swarm optimization (HDPSO) algorithm is presented that has three main phases. At the first phase a random algorithm following by novel theorems is applied to produce swarm members; it is as input of presented new discrete particle swarm optimization (DPSO) algorithm in the second phase. To avoid getting stuck in sub-optimal trap and to balance between exploration and exploitation, local search improvement is randomly combined in DPSO by calling Hill Climbing technique at the third phase to enhance overall performance. Second and third phases are iterated till the termination criteria is met. The average results reported from different executions of intensive settings on 12 scientific datasets proved our hybrid meta-heuristic has the amount of 10.67, 14.48, and 3 percentage dominance in terms of SLR , SpeedUp , and efficiency respectively against other existing meta-heuristics.},
  archive      = {J_EAAI},
  author       = {Mirsaeid Hosseini Shirvani},
  doi          = {10.1016/j.engappai.2020.103501},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103501},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid meta-heuristic algorithm for scientific workflow scheduling in heterogeneous distributed computing systems},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combined weighted multi-objective optimizer for instance
reduction in two-class imbalanced data problem. <em>EAAI</em>,
<em>90</em>, 103500. (<a
href="https://doi.org/10.1016/j.engappai.2020.103500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance reduction from class-balanced data has been investigated in much research. However, there is a lack of studies on class-imbalanced data. Learning from imbalanced data lately has attracted a lot of attention due to the practical applications. In the case of two-class imbalanced data, the instances from one class, majority class, are more numerous than the instances from the other class, which is a minority class. The present paper aims to introduce a new instance reduction method that preserves between-class distributions in the balanced data and handles minority class instance reduction in two-class imbalanced data, efficiently. The proposed method solves the instance reduction issue from an unconstrained multi-objective optimization problem aspect. Accordingly, a new combined weighted optimizer is designed. By employing the chaotic krill herd evolutionary algorithm, both the minority and majority class spaces with the accelerated convergence are explored. Through this method, the original data set is purged of those instances that decrease accuracy, and Gmean. The performance has been evaluated on both imbalanced and balanced data sets collected from the UCI repository by the 10-fold cross-validation method. Evaluations show that the proposed method outperforms state-of-the-art methods in terms of classification accuracy, Gmean, reduction rates, and computational time.},
  archive      = {J_EAAI},
  author       = {Javad Hamidzadeh and Niloufar Kashefi and Mona Moradi},
  doi          = {10.1016/j.engappai.2020.103500},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103500},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combined weighted multi-objective optimizer for instance reduction in two-class imbalanced data problem},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time series segmentation for state-model generation of
autonomous aquatic drones: A systematic framework. <em>EAAI</em>,
<em>90</em>, 103499. (<a
href="https://doi.org/10.1016/j.engappai.2020.103499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous surface vessels are becoming increasingly important for water monitoring. Their aim is to navigate rivers and lakes with limited intervention of human operators, to collect real-time data about water parameters. To reach this goal, these intelligent systems must interact with the environment and act according to the situations they face. In this work we propose a framework based on the integration of recent time-series clustering/segmentation methods and cluster validity indices, for detecting, modeling and evaluating aquatic drone states. The approach is completely data-driven and unsupervised. It takes unlabeled multivariate time series of sensor traces and returns both a set of statistically significant state-models (generated by different mathematical approaches) and a related segmentation of the dataset. We test the approach on a real dataset containing data of six campaigns, two in rivers and four in lakes, in different countries for about 5.6 h of navigation. Results show that the methodology is able to recognize known states and to discover unknown states, enabling novelty detection. The approach is therefore an easy-to-use tool for discovering and interpreting significant states in sensor data, that enables improved data analysis and drone autonomy.},
  archive      = {J_EAAI},
  author       = {Alberto Castellini and Manuele Bicego and Francesco Masillo and Maddalena Zuccotto and Alessandro Farinelli},
  doi          = {10.1016/j.engappai.2020.103499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Time series segmentation for state-model generation of autonomous aquatic drones: A systematic framework},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A competency question-oriented approach for the
transformation of semi-structured bioinformatics data into linked open
data. <em>EAAI</em>, <em>90</em>, 103495. (<a
href="https://doi.org/10.1016/j.engappai.2020.103495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bioinformatics data obtained using different molecular biology techniques must be processed through different analysis tools to discover new biological knowledge. Since plain processed data have no explicit semantic value, the extraction of additional knowledge through data exploration would benefit from the transformation of bioinformatics data into Linked Open Data (LOD). Different approaches have been proposed to support the transformation of different types of biomedical data into LOD. However, these approaches are not flexible enough so they can be easily adapted for the transformation of semi-structured bioinformatics data into LOD. Thus, this paper proposes a novel approach to support such transformation. According to this approach, a set of competency questions drive not only the definition of transformation rules, but also the data transformation and exploration afterwards. The paper also presents a support toolset and describes the successful application of the proposed approach in the functional genomics domain.},
  archive      = {J_EAAI},
  author       = {Gabriel C.S.G. de Paula and Cléver R.G. de Farias},
  doi          = {10.1016/j.engappai.2020.103495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A competency question-oriented approach for the transformation of semi-structured bioinformatics data into linked open data},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliable blood supply chain network design with facility
disruption: A real-world application. <em>EAAI</em>, <em>90</em>,
103493. (<a
href="https://doi.org/10.1016/j.engappai.2020.103493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blood supply of hospitals in disasters is a crucial issue in supply chain management. In this paper, a dynamic robust location–allocation model is presented for designing a blood supply chain network under facility disruption risks and uncertainty in a disaster situation. A scenario-based robust approach is adapted to the model to tackle the inherent uncertainty of the problem, such as a great deal of a periodic variation in demands and facilities disruptions. It is considered that the effect of disruption in facilities depends on the initial investment level for opening them, which are affected by the allocated budget. The usage of the model is implemented by a real-world case example that addresses the demand and disruption probability as uncertain parameters. For large-scale problems, two meta-heuristic algorithms, namely the self-adaptive imperialist competitive algorithm and invasive weed optimization, are presented to solve the model. Furthermore, several numerical examples of managerial insights are evaluated.},
  archive      = {J_EAAI},
  author       = {Nazanin Haghjoo and Reza Tavakkoli-Moghaddam and Hani Shahmoradi-Moghadam and Yaser Rahimi},
  doi          = {10.1016/j.engappai.2020.103493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reliable blood supply chain network design with facility disruption: A real-world application},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Large-scale monitoring of operationally diverse district
heating substations: A reference-group based approach. <em>EAAI</em>,
<em>90</em>, 103492. (<a
href="https://doi.org/10.1016/j.engappai.2020.103492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical district heating (DH) network consists of hundreds, sometimes thousands, of substations. In the absence of a well-understood prior model or data labels about each substation, the overall monitoring of such large number of substations can be challenging. To overcome the challenge, an approach based on the collective operational monitoring of each substation by a local group (i.e., the reference-group) of other similar substations in the network was formulated. Herein, if a substation of interest (i.e., the target) starts to behave differently in comparison to those in its reference-group, then it was designated as an outlier. The approach was demonstrated on the monitoring of the return temperature variable for atypical 1 and faulty operational behavior in 778 substations associated with multi-dwelling buildings. The choice of an appropriate similarity measure along with its size k were the two important factors that enables a reference-group to effectively detect an outlier target. Thus, different similarity measures and size k for the construction of the reference-groups were investigated, which led to the selection of the Euclidean distance with k = 80 . This setup resulted in the detection of 77 target substations that were outliers, i.e., the behavior of their return temperature changed in comparison to the majority of those in their respective reference-groups. Of these, 44 were detected due to the local construction of the reference-groups. In addition, six frequent patterns of deviating behavior in the return temperature of the substations were identified using the reference-group based approach, which were then further corroborated by the feedback from a DH domain expert.},
  archive      = {J_EAAI},
  author       = {Shiraz Farouq and Stefan Byttner and Mohamed-Rafik Bouguelia and Natasa Nord and Henrik Gadd},
  doi          = {10.1016/j.engappai.2020.103492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Large-scale monitoring of operationally diverse district heating substations: A reference-group based approach},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Teaching machines to write like humans using l-attributed
grammar. <em>EAAI</em>, <em>90</em>, 103489. (<a
href="https://doi.org/10.1016/j.engappai.2020.103489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reading and writing are easy for humans. The automatic reading of handwritten characters has been studied for several decades. Machine learning algorithms for reading tasks often require a huge amount of data to perform with similar accuracy to humans, yet it is also difficult to gain sufficient meaningful data. Automatic writing tasks have not been studied as extensively. In this paper, we teach machines to write like teaching a child by telling the machine the method for writing each character using L-attributed grammar. With the aid of the proposed TMTW (Teaching Machines To Write) interacting system, a human as a teacher only needs to provide the writing sequence of parts and control lines. The proposed system automatically perceives the relationships between control lines and parts, and constructs the grammars. Top-down derivation and the stroke generation method are applied to generate varying characters based on the learned grammars. For as long as a machine can write, it can be applied in robot control or training sample generation for automatic reading tasks. The MNIST and CASIA datasets are used to demonstrate the effectiveness of the proposed system on different languages. The machine written samples are used to train a network, which is evaluated on the MNIST test set. A test error rate of 1.23% is achieved using only approximately 20 grammars on average for each digit. Using the generated and handwritten samples together as a training set can reduce the test error rate to 0.61%. Similar experiments are conducted using the CASIA data set, and the results demonstrated that the proposed method is effective in generating characters with a complex structure. The source codes and grammars used in this paper have been made publicly available in https://github.com/step123456789/TMTW .},
  archive      = {J_EAAI},
  author       = {Yunxue Shao and Cheng-Lin Liu},
  doi          = {10.1016/j.engappai.2020.103489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Teaching machines to write like humans using L-attributed grammar},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generalized matrix profile framework with support for
contextual series analysis. <em>EAAI</em>, <em>90</em>, 103487. (<a
href="https://doi.org/10.1016/j.engappai.2020.103487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Matrix Profile is a state-of-the-art time series analysis technique that can be used for motif discovery, anomaly detection, segmentation and others, in various domains such as healthcare, robotics, and audio. Where recent techniques use the Matrix Profile as a preprocessing or modeling step, we believe there is unexplored potential in generalizing the approach. We derived a framework that focuses on the implicit distance matrix calculation. We present this framework as the Series Distance Matrix (SDM). In this framework, distance measures (SDM-generators) and distance processors (SDM-consumers) can be freely combined, allowing for more flexibility and easier experimentation. In SDM, the Matrix Profile is but one specific configuration. We also introduce the Contextual Matrix Profile (CMP) as a new SDM-consumer capable of discovering repeating patterns. The CMP provides intuitive visualizations for data analysis and can find anomalies that are not discords. We demonstrate this using two real world cases. The CMP is the first of a wide variety of new techniques for series analysis that fits within SDM and can complement the Matrix Profile.},
  archive      = {J_EAAI},
  author       = {Dieter De Paepe and Sander Vanden Hautte and Bram Steenwinckel and Filip De Turck and Femke Ongenae and Olivier Janssens and Sofie Van Hoecke},
  doi          = {10.1016/j.engappai.2020.103487},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103487},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A generalized matrix profile framework with support for contextual series analysis},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new insight into implementing mamdani fuzzy inference
system for dynamic process modeling: Application on flash separator
fuzzy dynamic modeling. <em>EAAI</em>, <em>90</em>, 103485. (<a
href="https://doi.org/10.1016/j.engappai.2020.103485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a novel approach to model the dynamic behavior of the flash separation process (as a main building block of non-reacting stage-wise operations) based on Mamdani Fuzzy Inference Systems is proposed. This model surmounts the need to solve various types of mathematical equations governing the system and does not require thermodynamic properties which are either not available or computationally demanding. Hence it can be easily used in dynamic simulation of multi-phase flow in distributed systems. In the proposed approach the overall model is broken into several simple sub-models based on intuitive analysis of an expert. Moreover, a new fuzzy concept, named “Linguistic Composition Variable” is introduced to represent components mole fractions of each phase as a fuzzy variable. Accordingly, large number of rules which is the main shortcoming of the Mamdani Fuzzy system is significantly reduced. The performance of the proposed dynamic model is evaluated through comparing its results against their corresponding counterparts for a flash separator of crude oil. Overall MAPE (Mean Absolute Percentage Error) values of 7.17% for the gas molar fractions, 3.06% for liquid molar fractions, 10.16% for the temperature, 0.63% for the pressure and 16.44% for the liquid level of the separator have been achieved showing that the proposed fuzzy model can effectively capture the general trends of process data of the dynamic process.},
  archive      = {J_EAAI},
  author       = {Mohammad Hosein Eghbal Ahmadi and Sayed Javid Royaee and Shokoufe Tayyebi and Ramin Bozorgmehry Boozarjomehry},
  doi          = {10.1016/j.engappai.2020.103485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new insight into implementing mamdani fuzzy inference system for dynamic process modeling: Application on flash separator fuzzy dynamic modeling},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel fractional-order type-2 fuzzy control method for
online frequency regulation in ac microgrid. <em>EAAI</em>, <em>90</em>,
103483. (<a
href="https://doi.org/10.1016/j.engappai.2020.103483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel adaptive fractional-order fuzzy control method is developed for frequency control in an ac microgrid (MG). A sequential general type-2 fuzzy system based on the radial basis neural network is presented for online modeling of the frequency response of the MG. Then, the parameters of the type-2 fuzzy controller based on the online estimated model are online tuned, such that the frequency deviation is minimized. The consequent parameters, i.e., centers of membership functions (MFs), the values of α -cuts, and the type-reduction parameters are optimized based on the proposed algorithm, which is inspired from the particle swarm optimization and artificial bee colony algorithm (PSO-ABC). The simulation results and comparison with other methods show that the proposed control scheme is effective, and results in a good and robust performance in the presence of variation of solar radiation, wind speed, load disturbance, and time-varying dynamics of the other units of MG. Moreover, the effectiveness of the proposed fuzzy system and the learning algorithm are examined by using white noise as the control input, and it is shown that the proposed identification scheme results in good performance even in the noisy environment.},
  archive      = {J_EAAI},
  author       = {Ardashir Mohammadzadeh and Erkan Kayacan},
  doi          = {10.1016/j.engappai.2020.103483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel fractional-order type-2 fuzzy control method for online frequency regulation in ac microgrid},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Safe energy savings through context-aware hot water demand
prediction. <em>EAAI</em>, <em>90</em>, 103481. (<a
href="https://doi.org/10.1016/j.engappai.2020.103481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tank-style water heaters provide a critical utility but often waste energy, as low temperatures encourage the formation of harmful bacteria. We develop low-cost hardware to capture training data from a single home’s hot water consumption and present a system capable of proactively anticipating demand while remaining sensitive to health concerns by combining a flow-predictive autoregressive convolutional neural network with a Cognitive Supervisor for minimizing Legionella formation. The predictive performance is evaluated for different receptive fields, and the best-performing model successfully tracks water demand one week into the future, providing robust input for the Supervisor to reform Legionella growth with minimal energy expenditure. First-order estimates find U.S. homeowner savings of $ 10 B in heating costs and 80MMT of C O 2 without increased health risks. This system uniquely combines predictive and protective elements to augment new and incumbent water heater installations including those used in low to middle-high income countries, enhancing global impact.},
  archive      = {J_EAAI},
  author       = {Joshua E. Siegel and Aniruddha Das and Yongbin Sun and Shane R. Pratt},
  doi          = {10.1016/j.engappai.2020.103481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Safe energy savings through context-aware hot water demand prediction},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Differential evolution: A review of more than two decades of
research. <em>EAAI</em>, <em>90</em>, 103479. (<a
href="https://doi.org/10.1016/j.engappai.2020.103479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since its inception in 1995, Differential Evolution (DE) has emerged as one of the most frequently used algorithms for solving complex optimization problems. Its flexibility and versatility have prompted several customized variants of DE for solving a variety of real life and test problems. The present study, surveys the near 25 years of existence of DE. In this extensive survey, 283 research articles have been covered and the journey of DE is shown through its basic aspects like population generation, mutation schemes, crossover schemes, variation in parameters and hybridized variants along with various successful applications of DE. This study also provides some key bibliometric indicators like highly cited papers having citations more than 500, publication trend since 1996, journal citations etc. The main aim of the present document is to serve as an extended summary of 25 years of existence of DE, intended for dissemination to interested parties. It is expected that the present survey would generate interest among the new users towards the philosophy of DE and would also guide the experience researchers.},
  archive      = {J_EAAI},
  author       = {Bilal and Millie Pant and Hira Zaheer and Laura Garcia-Hernandez and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.103479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differential evolution: A review of more than two decades of research},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning the representation of raw acoustic emission signals
by direct generative modelling and its use in chronology-based clusters
identification. <em>EAAI</em>, <em>90</em>, 103478. (<a
href="https://doi.org/10.1016/j.engappai.2020.103478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic emission (AE) is a passive monitoring technique used for learning about the behaviour of an engineered system. The streaming obtained by continuously recording AE transient signals is treated by a four steps procedure: 1) The detection of salient AE signals by distinguishing noise against non-noise signals using wavelet denoising, 2) the statistical representation of randomly selected AE signals using Autoregressive Weakly Hidden Markov Models, 3) an inference phase by applying those models to unknown AE signals and generating a set of novelty scores reflecting differences between signals, 4) the clustering of novelty scores using constraint-based consensus clustering. Compared to the standard way relying on the transformation of all AE signals by manual feature engineering (MFE) before clustering, the main breaktrough proposed in this paper holds in the use of the raw AE signals, with different lengths and various scales, to build high level information and organise the low level streaming data. Validated first on simulated data, we show the potential of this methodology for interpreting acoustic emission streaming originating from composite materials.},
  archive      = {J_EAAI},
  author       = {Emmanuel Ramasso and Pauline Butaud and Thomas Jeannin and Fabrizio Sarasini and Vincent Placet and Nathalie Godin and Jacopo Tirillò and Xavier Gabrion},
  doi          = {10.1016/j.engappai.2020.103478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning the representation of raw acoustic emission signals by direct generative modelling and its use in chronology-based clusters identification},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enhancing semantic segmentation with detection priors and
iterated graph cuts for robotics. <em>EAAI</em>, <em>90</em>, 103467.
(<a href="https://doi.org/10.1016/j.engappai.2019.103467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To foster human–robot interaction, autonomous robots need to understand the environment in which they operate. In this context, one of the main challenges is semantic segmentation, together with the recognition of important objects, which can aid robots during exploration, as well as when planning new actions and interacting with the environment. In this study, we extend a multi-view semantic segmentation system based on 3D Entangled Forests (3DEF) by integrating and refining two object detectors, Mask R-CNN and You Only Look Once (YOLO), with Bayesian fusion and iterated graph cuts. The new system takes the best of its components, successfully exploiting both 2D and 3D data. Our experiments show that our approach is competitive with the state-of-the-art and leads to accurate semantic segmentations.},
  archive      = {J_EAAI},
  author       = {Morris Antonello and Sabrina Chiesurin and Stefano Ghidoni},
  doi          = {10.1016/j.engappai.2019.103467},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103467},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing semantic segmentation with detection priors and iterated graph cuts for robotics},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Altered mineral segmentation in thin sections using an
incremental-dynamic clustering algorithm. <em>EAAI</em>, <em>90</em>,
103466. (<a
href="https://doi.org/10.1016/j.engappai.2019.103466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent mineral segmentation in thin section images of rocks still remains a challenging task in modern computational mineralogy. The objective of the paper is segmenting minerals in geological thin section’s images with special attention on altered mineral segmentation. In this paper, an efficient incremental-dynamic clustering algorithm is developed for segmentation of minerals in thin sections containing altered and non-altered minerals. In the clustering algorithm, there is no need for determining the number of clusters (minerals) existed in thin section images, and also it is able to deal with color changing and non-evident boundaries in altered minerals. We have solved two main existing limitations: segmentation of mineral pixels that are frequently labeled as background pixels, and segmentation of thin sections containing altered minerals. Moreover, we created an open database (Alborz Mineralogical Database), as a benchmark database in computational geosciences regarding image studies of mineral. The proposed method is validated based on the results provided by the segmentation maps, and experimental results indicate that the proposed method is very efficient and outperforms previous segmentation methods for altered minerals in thin section images. The proposed method can be applied in mining engineering, rock mechanics engineering, geotechnique engineering, mineralogy, petrography, and applications such as NASA’s Mars Rover Explorations (MRE).},
  archive      = {J_EAAI},
  author       = {Hossein Izadi and Javad Sadri and Fateme Hormozzade and Vahidoddin Fattahpour},
  doi          = {10.1016/j.engappai.2019.103466},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103466},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Altered mineral segmentation in thin sections using an incremental-dynamic clustering algorithm},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ontological approach for pathology assessment and
diagnosis of tunnels. <em>EAAI</em>, <em>90</em>, 103450. (<a
href="https://doi.org/10.1016/j.engappai.2019.103450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tunnel maintenance requires complex decision making, which involves pathology diagnosis and risk assessment, to ensure full safety while optimising maintenance and repair costs. A Decision Support System (DSS) can play a key role in this process by supporting the decision makers in identifying pathologies based on disorders present in various tunnel portions and contextual factors affecting a tunnel. Another key aspect is to identify which spatial stretches within a tunnel contain pathologies of similar kinds within neighbouring tunnel segments. This paper presents PADTUN, a novel intelligent decision support system that assists with pathology diagnosis and assessment of tunnels with respect to their disorders and diagnosis influencing factors. It utilises semantic web technologies for knowledge capture, representation, and reasoning. The core of PADTUN is a family of ontologies which represent the main concepts and relations associated with pathology assessment, and capture the decision process concerning tunnel maintenance. Tunnel inspection data is linked to these ontologies to take advantage of inference capabilities offered by semantic technologies. In addition, an intelligent mechanism is presented which exploits abstraction and inference capabilities. Thus PADTUN provides the world’s first semantically based intelligent DSS for tunnel maintenance. PADTUN was developed by an interdisciplinary team of tunnel experts and knowledge engineers in real-world settings offered by the NeTTUN EU Project. An evaluation of the PADTUN system is performed using real-world tunnel data and diagnosis tasks. We show how the use of semantic technologies allows addressing the complex issues of tunnel pathology inferencing, aiding in, and matching transportation experts’ expectations of decision support. The methodology is applicable to any linear transport structures, offering intelligent ways to aid with complex decision processes related to diagnosis and maintenance.},
  archive      = {J_EAAI},
  author       = {Vania Dimitrova and Muhammad Owais Mehmood and Dhavalkumar Thakker and Bastien Sage-Vallier and Joaquin Valdes and Anthony G. Cohn},
  doi          = {10.1016/j.engappai.2019.103450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An ontological approach for pathology assessment and diagnosis of tunnels},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A type-2 fuzzy community detection model in large-scale
social networks considering two-layer graphs. <em>EAAI</em>,
<em>90</em>, 103206. (<a
href="https://doi.org/10.1016/j.engappai.2019.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly aims to identify communities with different interactions between nodes in complex networks. Community detection algorithms partition vertices into densely-connected components in a complex network. In recent researches, a node is related to multiple aspects of relationships resulting in new challenges in social networks. The two aspects of relationships could be shown as a two-layer graph which comprises two graphs dependent on each other; and each graph shows a specific aspect of the interaction. In this research, a new community detection model is proposed based on the possibilistic c-means clustering model considering two-layer graphs (PCMTL) in order to detect overlapping communities based on the two-layer graphs using both structural and attribute similarities in large-scale social networks. The nodes are assigned to communities by upper and lower membership values that are indicative of the degree of belonging to the communities through type-2 fuzzy membership values, and the suggested values of interval type-2 fuzzy membership determine how a node belongs to a community with regard to two different aspects of interactions in a two-layer graph. Moreover, according to the proposed model, a validity index is introduced to assess the suggested model in comparison to the approach existing in the literature. Ultimately, two artificial and two real large-scale social networks are used to validate the performance of the suggested model.},
  archive      = {J_EAAI},
  author       = {Mansoureh Naderipour and Mohammad Hossein Fazel Zarandi and Susan Bastani},
  doi          = {10.1016/j.engappai.2019.07.021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {103206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A type-2 fuzzy community detection model in large-scale social networks considering two-layer graphs},
  volume       = {90},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic bayesian network for robust latent variable modeling
and fault classification. <em>EAAI</em>, <em>89</em>, 103475. (<a
href="https://doi.org/10.1016/j.engappai.2020.103475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with robust dynamic probabilistic modeling and fault classification for process data. In dynamic processes, observed variables can be numerous in amount and correlated with each other in both variable-wise and time-wise. While multivariate statistical analysis methods such as principle component analysis (PCA) are widely used to handle variable-wise correlations and also for dimension reduction purpose, the time-wise correlation among process data is typically addressed by constructing dynamical models, e.g. time-series data model, state space model, etc. In this paper, the robust probabilistic principle component analysis (RPPCA) model is introduced for feature extraction from contaminated process data, suffered from outliers, disturbances, heave noises, etc. A dynamic Bayesian network (DBN) is then constructed, with incorporation of a mixture of Gaussian components for approximation of the non-Gaussian characteristics of latent variables. Based on the developed robust dynamic Bayesian network model, a fault classification scheme is proposed. To validate the effectiveness and feasibility of the new method, two well-known benchmark case studies are carried out. Simulation results show that robust dynamic method performs better in outlier contaminated situations, where the performance has been improved by 10%–20% in most cases.},
  archive      = {J_EAAI},
  author       = {Junhua Zheng and Jinlin Zhu and Guangjie Chen and Zhihuan Song and Zhiqiang Ge},
  doi          = {10.1016/j.engappai.2020.103475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic bayesian network for robust latent variable modeling and fault classification},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved magnetic charged system search optimization
algorithm with application to satellite formation flying. <em>EAAI</em>,
<em>89</em>, 103473. (<a
href="https://doi.org/10.1016/j.engappai.2020.103473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the implementation and application of an improved version of the metaheuristic algorithm called magnetic charged system search. Some modifications and novelties are introduced and tested. Firstly, the authors’ attempt is to develop a self-adaptive and user-friendly algorithm which can automatically set all the preliminary parameters (such as the numbers of particles, the maximum iterations number) and the internal coefficients. Indeed, some mathematical laws are proposed to set the parameters and many coefficients can dynamically change during the optimization process based on the verification of internal conditions. Secondly, some strategies are suggested to enhance the performances of the proposed algorithm. A chaotic local search is introduced to improve the global best particle of each iteration by exploiting the features of ergodicity and randomness. Moreover, a novel technique is proposed to handle bad-defined boundaries; in fact, the possibility to self-enlarge the boundaries of the optimization variables is considered, allowing to achieve the global optimum even if it is located on the boundaries or outside. The algorithm is tested through some benchmark functions and engineering design problems, showing good results, followed by an application regarding the problem of time-suboptimal manoeuvres for satellite formation flying, where the inverse dynamics technique, together with the B-splines, is employed. This analysis proves the ability of the proposed algorithm to optimize control problems related to space engineering, obtaining better results with respect to more common and used algorithms in literature.},
  archive      = {J_EAAI},
  author       = {Andrea D’Ambrosio and Dario Spiller and Fabio Curti},
  doi          = {10.1016/j.engappai.2020.103473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved magnetic charged system search optimization algorithm with application to satellite formation flying},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven oriented optimization of resource allocation in
the forging process using bi-objective evolutionary algorithm.
<em>EAAI</em>, <em>89</em>, 103469. (<a
href="https://doi.org/10.1016/j.engappai.2019.103469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource allocation in the forging process of the steel production industry is an important element of the material supply in upstream processes, and the subsequent processing of semi-finished products downstream. However, the existing literature rarely discusses issues related to this problem. In this study, the information flow is built by referring to specifications and process logic, which is a kind of pre-processing in data analysis flow in order to break the initial barrier of resource allocation in forging. In addition, Bi-objective Evolutionary Algorithm (BOEA) is proposed to optimize the resource allocation in the forging process. Using the built information flow, the available multiple forging process resources can be effectively connected, and information of available resource combinations can be established for orders. Since real users have preferences for different objectives in practice, experiment results show that the proposed BOEA can deal with these preferences by effectively optimizing both the remnants (the remaining materials) and the execution cost, and the profit contribution is also proved by effective cost savings.},
  archive      = {J_EAAI},
  author       = {Tsung-Jung Hsieh},
  doi          = {10.1016/j.engappai.2019.103469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven oriented optimization of resource allocation in the forging process using bi-objective evolutionary algorithm},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel incremental kernel nonparametric SVM model (iKN-SVM)
for data classification: An application to face detection.
<em>EAAI</em>, <em>89</em>, 103468. (<a
href="https://doi.org/10.1016/j.engappai.2019.103468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel incremental classifier to overcome problems associated with batch techniques, along with issues related to data spread that Kernel Support Vector Machines (KSVM) may encounter. Basically, we present a Kernel SVM-based model that learns incrementally, as new data is available over time, in order to handle dynamic and large data effectively and reduce the computational time. The proposed model deals with the data spread issues by introducing near-global variations, from the scatter matrices of the Kernel Nonparametric Discriminant Analysis (KNDA), into the optimization problem of incremental KSVM, while considering local characteristics of the data provided by KSVM. Besides, our model has a quadratic convex optimization problem with one global solution. Furthermore, an extensive comparison of the model with other state-of-the-art incremental and batch algorithms on various datasets, has been carried out, in order to show its advantages and effectiveness for classification tasks. Moreover, an evaluation of the proposed method on face detection is provided.},
  archive      = {J_EAAI},
  author       = {Arbia Soula and Khaoula Tbarki and Riadh Ksantini and Salma Ben Said and Zied Lachiri},
  doi          = {10.1016/j.engappai.2019.103468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel incremental kernel nonparametric SVM model (iKN-SVM) for data classification: An application to face detection},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple universum empirical kernel learning. <em>EAAI</em>,
<em>89</em>, 103461. (<a
href="https://doi.org/10.1016/j.engappai.2019.103461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel framework called Multiple Universum Empirical Kernel Learning (MUEKL) that combines the Universum learning with Multiple Empirical Kernel Learning (MEKL) for the first time to inherit the advantages of both techniques. The proposed MUEKL not only obtained supplementary information of multiple feature spaces through MEKL, but also obtained priori information of samples by Universum learning. MUEKL incorporates a novel method, Imbalanced Modified Universum (IMU), to generate more efficient Universum samples by introducing the imbalanced ratio of data. MUEKL develops the basic multiple kernel learning framework by introducing a regularization of Universum data. The function of the introduced regularization is to adjust the classifier boundary closer to the Universum data to alleviate the influence of the imbalanced data. Moreover, MUEKL performs excellent generalization for both the imbalanced and balanced problems. Extensive experiments verify the effectiveness of the MUEKL and IMU.},
  archive      = {J_EAAI},
  author       = {Zhe Wang and Sisi Hong and Lijuan Yao and Dongdong Li and Wenli Du and Jing Zhang},
  doi          = {10.1016/j.engappai.2019.103461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple universum empirical kernel learning},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cross multi-scale locally encoded gradient patterns for
off-line text-independent writer identification. <em>EAAI</em>,
<em>89</em>, 103459. (<a
href="https://doi.org/10.1016/j.engappai.2019.103459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Writer identification is experiencing a revival of activity in recent years and continues to attract great deal of attention as a challenging and important area of research in the field of forensic and authentication. In this work, we introduce a reliable off-line system for text-independent writer identification of handwritten documents. Feature engineering is an essential component of a pattern recognition system, which can enhance or decrease the classification performance. A well-designed and defined feature extraction method improves the classification task. This paper proposes, for feature extraction, an effective, yet high-quality and conceptually simple feature image descriptor referred to as Cross multi-scale Locally encoded Gradient Patterns (CLGP). The proposed CLGP feature extraction method, which is expected to better represent salient local writing structure, operates at small observation regions (i.e., connected component sub-images) of the writing sample. CLGP histogram feature vectors computed from all these observation regions in all writing samples are considered as classification inputs to identify query writers using the Nearest Neighbor Classifier (1-NN). Our system is evaluated on six standard databases (IFN/ENIT, AHTID/MW, CVL, IAM, Firemaker, and ICDAR2011) including handwritten samples in Arabic, English, French, Greek, German, and Dutch languages. Comparing the identification performance with old and recent state-of-the-art methods, the proposed system achieves the highest performance on IFN/ENIT, AHTID/MW, and ICDAR2011 databases, and demonstrates competitive performance on IAM, CVL, and Firemaker databases.},
  archive      = {J_EAAI},
  author       = {Abderrazak Chahi and Youssef El merabet and Yassine Ruichek and Raja Touahni},
  doi          = {10.1016/j.engappai.2019.103459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cross multi-scale locally encoded gradient patterns for off-line text-independent writer identification},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Refraction-learning-based whale optimization algorithm for
high-dimensional problems and parameter estimation of PV model.
<em>EAAI</em>, <em>89</em>, 103457. (<a
href="https://doi.org/10.1016/j.engappai.2019.103457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Whale optimization algorithm (WOA) is a relatively new meta-heuristic optimization algorithm which mimics the hunting behavior of humpback whales. This paper presents a modified version of WOA, called RLWOA, for solving high-dimensional optimization problems. The proposed RLWOA adopts a modified conversion parameter update rule that relies on Logistic model to balance between diversity and convergence during the search process, and a new refraction-learning strategy based on the principle of refraction of light is proposed to help the population jump out of a local optimum. The experiments on a set of benchmark test functions with various features, i.e., 12 widely used benchmark functions with 100, 1000, and 10000 dimensions, two practical engineering design problems, and parameter estimation problem of photovoltaic model. The comparisons demonstrate that the proposed RLWOA shows better or at least competitive performance against the standard WOA, WOA variants and other state-of-the-art meta-heuristic algorithms for solving high-dimensional numerical optimization, practical engineering design optimization, and photovoltaic model parameter estimation problems.},
  archive      = {J_EAAI},
  author       = {Wen Long and Tiebin Wu and Jianjun Jiao and Mingzhu Tang and Ming Xu},
  doi          = {10.1016/j.engappai.2019.103457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Refraction-learning-based whale optimization algorithm for high-dimensional problems and parameter estimation of PV model},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time EEG classification via coresets for BCI
applications. <em>EAAI</em>, <em>89</em>, 103455. (<a
href="https://doi.org/10.1016/j.engappai.2019.103455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) based on the motor imagery (MI) paradigm translates a subject’s motor intention into a control signal by classifying the electroencephalogram (EEG) signals of different tasks. However, most existing systems use either (i) a high-quality algorithm to train the data off-line and run only the classification in real-time since the off-line algorithm is too slow, or (ii) low-quality heuristics that are sufficiently fast for real-time training but introduce relatively large classification error. In this work, we propose a novel processing pipeline that allows real-time and parallel learning of EEG signals using high-quality but potentially inefficient algorithms. This is done by forging a link between BCI and coresets, a technique that originated in computational geometry for handling streaming data via data summarization. We suggest an algorithm that maintains the representation of such coresets tailored to handle the EEG signal which enables (i) real-time and continuous computation of the common spatial pattern (CSP) feature extraction method on a coreset representation of the signal (instead of the signal itself) , (ii) improvement of CSP algorithm efficiency with provable guarantees by applying the CSP algorithm on the coreset, and (iii) real-time addition of the data trials (EEG data windows) to the coreset. For simplicity, we focus on the CSP algorithm, which is a classic algorithm. Nevertheless, we expect that our coreset will be extended to other algorithms in future papers. In the experimental results, we show that our system can indeed learn EEG signals in real-time in, for example, a 64-channel setup with hundreds of time samples per second.},
  archive      = {J_EAAI},
  author       = {Eitan Netzer and Alex Frid and Dan Feldman},
  doi          = {10.1016/j.engappai.2019.103455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time EEG classification via coresets for BCI applications},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A heuristic algorithm combining pareto optimization and
niche technology for multi-objective unequal area facility layout
problem. <em>EAAI</em>, <em>89</em>, 103453. (<a
href="https://doi.org/10.1016/j.engappai.2019.103453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unequal area facility layout problem (UA-FLP) is the problem of placing departments with different areas in a facility so that departments satisfy some given objectives and constraints. In this paper, two objectives including the material handling cost and the closeness rating are optimized. Based on the quasi-physical strategy, we introduce an extrusive elastic potential energy based on the overlapping distance between departments into the layout system. After a novel handling approach of the non-overlapping constraint formed by executing the gradient method with an adaptive step length and subsequent department deformation strategy is developed to deal with the interference among departments and between any department and the facility, the problem is first converted into an optimization problem without the non-overlapping constraint. Then, we use a new heuristic algorithm that combines the local search based on the Pareto optimization and the global optimum search based on the niche technology to obtain Pareto-optimal solutions of the problem. In the proposed heuristic algorithm, in order to overcome the shortcomings of low efficient search toward the diversity of solutions in classical Pareto optimization method, we propose a heuristic layout updating strategy and a niche technology. To improve the convergence of the algorithm to the Pareto front, a mechanism of evolution of population named a feasible layout bank in the algorithm based on the local search and global optimum search is proposed. Two sets of representative instances from the literature with the size of the problem up to 62 departments are tested. The experimental results show that the proposed heuristic algorithm is an effective method for solving the multi-objective UA-FLP.},
  archive      = {J_EAAI},
  author       = {Jingfa Liu and Jun Liu and Xueming Yan and Bitao Peng},
  doi          = {10.1016/j.engappai.2019.103453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A heuristic algorithm combining pareto optimization and niche technology for multi-objective unequal area facility layout problem},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adaption neighborhood density clustering method for
mixed data stream with concept drift. <em>EAAI</em>, <em>89</em>,
103451. (<a
href="https://doi.org/10.1016/j.engappai.2019.103451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering analysis is an important data mining method for data stream. In this paper, a self-adaption neighborhood density clustering method for mixed data stream is proposed. The method uses a significant metric criteria to make categorical attribute values become numeric and then the dimension of data is reduced by a nonlinear dimensionality reduction method. In the clustering method, each point is evaluated by neighborhood density. The k points are selected from the data set with maximum mutual distance after k is determined according to rough set. In addition, a new similarity measure based on neighborhood entropy is presented. The data points can be partitioned into the nearest cluster and the algorithm adaptively adjusts the clustering center points by clustering error. The experimental results show that the proposed method can obtain better clustering results than the comparison algorithms on the most data sets and the experimental results prove that the proposed algorithm is effective for data stream clustering.},
  archive      = {J_EAAI},
  author       = {Shuliang Xu and Lin Feng and Shenglan Liu and Hong Qiao},
  doi          = {10.1016/j.engappai.2019.103451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaption neighborhood density clustering method for mixed data stream with concept drift},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emotional neural networks with universal approximation
property for stable direct adaptive nonlinear control systems.
<em>EAAI</em>, <em>89</em>, 103447. (<a
href="https://doi.org/10.1016/j.engappai.2019.103447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Universal approximation, continuity, and differentiability are desirable properties of any computational framework, including those that rise from human cognition and/or are inspired by nature. Emotional machines constitute one such framework, but few studies have addressed their mathematical properties. Here, we propose a Continuous Radial Basis Emotional Neural Network (CRBENN) that benefits from the universal approximation property, continuous output, and simple structure of RBF; while keeping the fast response properties of emotion-based approaches. As such, CRBENN is amenable to a wide array of challenging problems in systems engineering and artificial intelligence. Here, we propose a CRBENN-based direct adaptive robust emotional neuro-control approach (DARENC) for a class of uncertain nonlinear systems. Stability is theoretically established using Lyapunov analysis of the closed-loop system. DARENC is then applied to control two nonlinear systems, and the performance of the controller is numerically compared with several competing fuzzy, neural, and emotional controllers. The simulation results indicate improved tracking performance, better disturbance rejection, and less control effort. Finally, DARENC is implemented on a real-world 3-PSP (spherical–prismatic–spherical) parallel robot in our laboratory. The experimental results show the satisfactory performance of the robot in tracking the desired trajectory with low control effort.},
  archive      = {J_EAAI},
  author       = {F. Baghbani and M.-R. Akbarzadeh-T and M.-B. Naghibi-Sistani and Alireza Akbarzadeh},
  doi          = {10.1016/j.engappai.2019.103447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emotional neural networks with universal approximation property for stable direct adaptive nonlinear control systems},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel island model based on coral reefs optimization
algorithm for solving the unequal area facility layout problem.
<em>EAAI</em>, <em>89</em>, 103445. (<a
href="https://doi.org/10.1016/j.engappai.2019.103445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel approach to address the Unequal Area Facility Layout Problem (UA-FLP), based on the combination of both an Island Model and a Coral Reefs Optimization (CRO) algorithm. Two different versions of this Island Model based on Coral Reefs Optimization Algorithm (IMCRO) are proposed and applied to the UA-FLP. The structure of flexible bays has been selected as effective encoding to represent the facility layouts within the algorithm. The two versions of the proposed approach have been tested in 22 UA-FLP cases, considering small, medium and large size categories. The empirical results obtained are compared with previous state of the art algorithms, in order to show the performance of the IMCRO. From this comparison, it can be extracted that both versions of the proposed IMCRO algorithm show an excellent performance, accurately solving the UA-FLP instances in all the size categories.},
  archive      = {J_EAAI},
  author       = {L. Garcia-Hernandez and L. Salas-Morera and C. Carmona-Muñoz and J.A. Garcia-Hernandez and S. Salcedo-Sanz},
  doi          = {10.1016/j.engappai.2019.103445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel island model based on coral reefs optimization algorithm for solving the unequal area facility layout problem},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating overlapping community discovery and role
analysis: Bayesian probabilistic generative modeling and mean-field
variational inference. <em>EAAI</em>, <em>89</em>, 103437. (<a
href="https://doi.org/10.1016/j.engappai.2019.103437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint modeling of community discovery and role analysis was shown useful to explain, predict and reason on network topology. Nonetheless, earlier research on the integration of both tasks suffers from major limitations. Foremost, a key aspect of role analysis, i.e., the strength of role-to-role interactions, is ignored. Moreover, two fundamental properties of networks are disregarded, i.e., heterogeneity in the connectivity structure of communities and the growing link probability with node involvement in common communities. Additionally, scalability with network size is limited. In this manuscript, we incrementally develop two new machine learning approaches to deal with the foresaid issues. The proposed approaches consist in performing inference under as many Bayesian generative models of networks with overlapping communities and roles. Under both models, nodes are associated with communities and roles through suitable affiliations, that are dichotomized for link directionality. The strength of such affiliations is captured through nonnegative latent random variables, drawn from Gamma priors. Besides, link establishment is explained by both models through Poisson distributions. In particular, under the second model, the parameterizing rate of the Poisson distribution also accommodates the strength of role-to-role interactions, as captured via latent mixed-membership stochastic blockmodeling. On sparse networks, the adoption of the Poisson distribution expedites model inference. On this point, mean-field variational inference is derived and implemented as a coordinate-ascent algorithm, for the exploratory and unsupervised analysis of node affiliations. Comparative experiments on several real-world networks demonstrate the superiority of the proposed approaches in community discovery, link prediction as well as scalability.},
  archive      = {J_EAAI},
  author       = {Gianni Costa and Riccardo Ortale},
  doi          = {10.1016/j.engappai.2019.103437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating overlapping community discovery and role analysis: Bayesian probabilistic generative modeling and mean-field variational inference},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary neuro-fuzzy c-means clustering technique.
<em>EAAI</em>, <em>89</em>, 103435. (<a
href="https://doi.org/10.1016/j.engappai.2019.103435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the standard approaches for data analysis in unsupervised machine learning techniques is cluster analysis or clustering, where the data possessing similar features are grouped into a certain number of clusters. Among several significant ways of performing clustering, Fuzzy C-means (FCM) is a methodology, where every data point is hypothesized to be associated with all the clusters through a fuzzy membership function value. FCM is performed by minimizing an objective functional by optimally estimating the decision variables namely, the membership function values and cluster representatives, under a constrained environment. With this approach, a marginal increase in the number of data points leads to an enormous increase in the size of decision variables. This explosion, in turn, prevents the application of evolutionary optimization solvers in FCM, which thereby leads to inefficient data clustering. In this paper, a Neuro-Fuzzy C-Means Clustering algorithm (NFCM) is presented to resolve the issues mentioned above by adopting a novel Artificial Neural Network (ANN) based clustering approach. In NFCM, a functional map is constructed between the data points and membership function values, which enables a significant reduction in the number of decision variables. Additionally, NFCM implements an intelligent framework to optimally design the ANN structure, as a result of which, the optimal number of clusters is identified. Results of 9 different data sets with dimensions ranging from 2 to 30 are presented along with a comprehensive comparison with the current state-of-the-art clustering methods to demonstrate the efficacy of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Priyanka D. Pantula and Srinivas S. Miriyala and Kishalay Mitra},
  doi          = {10.1016/j.engappai.2019.103435},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103435},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An evolutionary neuro-fuzzy C-means clustering technique},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine-tool condition monitoring with gaussian mixture
models-based dynamic probabilistic clustering. <em>EAAI</em>,
<em>89</em>, 103434. (<a
href="https://doi.org/10.1016/j.engappai.2019.103434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combination of artificial intelligence with data, computing power, and new algorithms can provide important tools for solving engineering problems, such as machine-tool condition monitoring. However, many of these problems require algorithms that can perform in highly dynamic scenarios where the data streams have extremely high sampling rates from different types of variables. The unsupervised learning algorithm based on Gaussian mixture models called Gaussian-based dynamic probabilistic clustering (GDPC) is one of these tools. However, this algorithm may have major limitations if a large amount of concept drifts associated with transients occurs within the data stream. GDPC becomes unstable under these conditions, so we propose a new algorithm called GDPC+ to increase its robustness. GDPC+ represents an important improvement because we introduce: (a) automatic selection of the number of mixture components based on the Bayesian information criterion (BIC), and (b) concept drift transition stabilization based on Cauchy–Schwarz divergence integrated with the Dickey–Fuller test. Thus, GDPC+ can perform better in highly dynamic scenarios than GDPC in terms of the number of false positives. The behavior of GDPC+ was investigated using random synthetic data streams and in a real data stream-based condition monitoring obtained from a machine-tool that produces engine crankshafts at high speed. We found that the initial temporal window size can be used to adapt the algorithm to different analytical requirements. The clustering results were also investigated by induction of the rules generated by the repeated incremental pruning to produce error reduction (RIPPER) algorithm in order to provide insights from the underlying monitored process and its associated concept drifts.},
  archive      = {J_EAAI},
  author       = {Javier Diaz-Rozo and Concha Bielza and Pedro Larrañaga},
  doi          = {10.1016/j.engappai.2019.103434},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103434},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine-tool condition monitoring with gaussian mixture models-based dynamic probabilistic clustering},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A soft set based VIKOR approach for some decision-making
problems under complex neutrosophic environment. <em>EAAI</em>,
<em>89</em>, 103432. (<a
href="https://doi.org/10.1016/j.engappai.2019.103432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications in various fields of neutrosophic soft set theory enhance its appreciation to the researchers. Although, this uncertain solving tool can accomplish several types of real-life problems, but not able to deal with the decision-making problems in which considering an additional information of a corresponding parameter is needed to get a proper decision from a problem. But, complex neutrosophic soft sets can handle such type of decision-making problems. Consequently, in this study, we have given concentration on solving soft set based decision-making problems in the field of complex neutrosophic environment. Firstly, we have introduced some basic set-theoretic operations of complex neutrosophic sets including different types of unions, intersections and aggregations. Then, a new definition of score function of a complex neutrosophic number has been proposed. Additionally, the above-defined unions and intersections of complex neutrosophic sets have been stated for complex neutrosophic soft sets. Finally, by utilizing these proposed notions, we have offered a complex neutrosophic soft VIKOR approach to get a compromise optimal solution for single as well as multiple decision-maker based problems. Our proposed approach has been clarified by several real life-related problems including medical diagnosis problem, sustainable manufacturing material selection problem, company’s manager selection problem, etc. The feasibility and effectiveness of our proposed approach have also been included in the article.},
  archive      = {J_EAAI},
  author       = {Soumi Manna and Tanushree Mitra Basu and Shyamal Kumar Mondal},
  doi          = {10.1016/j.engappai.2019.103432},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103432},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A soft set based VIKOR approach for some decision-making problems under complex neutrosophic environment},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost of selfishness in the allocation of cities in the
multiple travelling salesmen problem. <em>EAAI</em>, <em>89</em>,
103429. (<a
href="https://doi.org/10.1016/j.engappai.2019.103429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision to centralise or decentralise human organisations needs to be based on quantified evidence, yet little is available in the literature. We provide such data in a variant of the Multiple Travelling Salesmen Problem (MTSP) in which we study how the allocation sub-problem may be decentralised among selfish salesmen. Our contributions are: (i) this modification of the MTSP to include selfishness; (ii) the proposition of organisations to solve this modified MTSP; and (iii) the comparison of these organisations. Our 5 organisations may be summarised as follows: (i) OptDecentr is a pure Centralised Organisation (CO) in which a Central Authority (CA) finds the best solution that could be found by a Decentralised Organisation (DO); (ii) Cluster and (iii) Auction are CO/DO hybrids; and (iv) P2P and (v) CNP are pure DO. The sixth and seventh organisations are used as benchmarks: (vi) NoRealloc is a pure DO which ignores the allocation problem; and (vii) FullCentr is a pure CO which solves a different problem, v i z . , the traditional MTSP. Comparing the efficiency of pairs of these mechanisms quantifies the price of decentralising an organisation. In particular, our model of selfishness in OptDecentr , with 5 (respectively, 9) salesmen, makes the total route length 30% (respectively, 60%) longer than the traditional MTSP in FullCentr when the computation time is limited to 30 min. With this time limit, our results also seem to indicate that the level of coercion of the CA impacts the total route length more than the level of centralisation.},
  archive      = {J_EAAI},
  author       = {Thierry Moyaux and Eric Marcon},
  doi          = {10.1016/j.engappai.2019.103429},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103429},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cost of selfishness in the allocation of cities in the multiple travelling salesmen problem},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic parallel extreme artificial hydrocarbon networks:
An implementation for fast and robust supervised machine learning in
high-dimensional data. <em>EAAI</em>, <em>89</em>, 103427. (<a
href="https://doi.org/10.1016/j.engappai.2019.103427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 10 , 000 x times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.},
  archive      = {J_EAAI},
  author       = {Hiram Ponce and Paulo V. de Campos Souza and Augusto Junio Guimarães and Guillermo González-Mora},
  doi          = {10.1016/j.engappai.2019.103427},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103427},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incremental model-based global dual heuristic programming
with explicit analytical calculations applied to flight control.
<em>EAAI</em>, <em>89</em>, 103425. (<a
href="https://doi.org/10.1016/j.engappai.2019.103425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel adaptive dynamic programming method, called incremental model-based global dual heuristic programming, is proposed to generate a self-learning adaptive flight controller, in the absence of sufficient prior knowledge of system dynamics. An incremental technique is employed for online local dynamics identification, instead of the artificial neural networks commonly used in global dual heuristic programming, to enable a fast and precise learning. On the basis of the identified model, two neural networks are adopted to facilitate the implementation of the self-learning controller, by approximating the cost-to-go and the control policy, respectively. The required derivatives of cost-to-go are computed by explicit analytical calculations based on differential operations. Both methods are applied to an online attitude tracking control problem of a nonlinear aerospace system and the results show that the proposed method outperforms conventional global dual heuristic programming in tracking precision, online learning speed, robustness to different initial states and adaptability for fault-tolerant control problems.},
  archive      = {J_EAAI},
  author       = {Bo Sun and Erik-Jan van Kampen},
  doi          = {10.1016/j.engappai.2019.103425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Incremental model-based global dual heuristic programming with explicit analytical calculations applied to flight control},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combinatorial search for selecting the structure of models
of dynamical systems with equation discovery. <em>EAAI</em>,
<em>89</em>, 103423. (<a
href="https://doi.org/10.1016/j.engappai.2019.103423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated modeling aims at the induction of mathematical models, both their structure and parameter values, from time-series measurements of observed system variables. In this paper, we address the task of model structure selection, i.e., selecting an optimal structure from a user-specified finite set of alternative model structures, using various approaches to combinatorial search. We propose a mapping of the set of candidate model structures to a fixed-length, vector representation allowing the use of an arbitrary search algorithm as a solver of the structure selection task. We perform a comparative analysis of the performance of thirteen variants of several search algorithms, ranging from ones with high intensification, i.e., focus on neighborhood of the best candidate solutions, to ones with high diversification, i.e., focus on covering the entire search space. The empirical analysis involves eight tasks of reconstructing known models of dynamical systems from synthetic and measured data. The results of the analysis show that search algorithms involving moderate diversification methods have superior performance on the structure selection task. The empirical analysis also reveals that this finding is related to specific properties of the search space of candidate model structures.},
  archive      = {J_EAAI},
  author       = {Jovan Tanevski and Ljupčo Todorovski and Sašo Džeroski},
  doi          = {10.1016/j.engappai.2019.103423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combinatorial search for selecting the structure of models of dynamical systems with equation discovery},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fitting model based intuitionistic fuzzy rough feature
selection. <em>EAAI</em>, <em>89</em>, 103421. (<a
href="https://doi.org/10.1016/j.engappai.2019.103421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature subset selection is an essential machine learning approach aimed at the process of dimensionality reduction of the input space. By removing irrelevant and/or redundant variables, not only it enhances model performance, but also facilitates its improved interpretability. The fuzzy set and the rough set are two different but complementary theories that apply the fuzzy rough dependency as a criterion for performing feature subset selection. However, this concept can only maintain a maximal dependency function. It cannot preferably illustrate the differences in object classification and does not fit a particular dataset well. This problem was handled by using a fitting model for feature selection with fuzzy rough sets. However, intuitionistic fuzzy set theory can deal with uncertainty in a much better way when compared to fuzzy set theory as it considers positive, negative and hesitancy degree of an object simultaneously to belong to a particular set. Therefore, in the current study, a novel intuitionistic fuzzy rough set model is proposed for handling above mentioned problems. This model fits the data well and prevents misclassification. Firstly, intuitionistic fuzzy decision of a sample is introduced using neighborhood concept. Then, intuitionistic fuzzy lower and upper approximations are constructed using intuitionistic fuzzy decision and parameterized intuitionistic fuzzy granule. Furthermore, a new dependency function is established. Moreover, a greedy forward algorithm is given using the proposed concept to calculate reduct set. Finally, this algorithm is applied to the benchmark datasets and a comparative study with the existing algorithm is presented. From the experimental results, it can be observed that the proposed model provides more accurate reduct set than existing model.},
  archive      = {J_EAAI},
  author       = {Pankhuri Jain MCA and Anoop Kumar Tiwari PhD and Tanmoy Som PhD},
  doi          = {10.1016/j.engappai.2019.103421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fitting model based intuitionistic fuzzy rough feature selection},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DFNet: Discriminative feature extraction and integration
network for salient object detection. <em>EAAI</em>, <em>89</em>,
103419. (<a
href="https://doi.org/10.1016/j.engappai.2019.103419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the powerful feature extraction capability of Convolutional Neural Networks, there are still some challenges in saliency detection. In this paper, we focus on two aspects of challenges: i) Since salient objects appear in various sizes, using single-scale convolution would not capture the right size. Moreover, using multi-scale convolutions without considering their importance may confuse the model. ii) Employing multi-level features helps the model use both local and global context. However, treating all features equally results in information redundancy. Therefore, there needs to be a mechanism to intelligently select which features in different levels are useful. To address the first challenge, we propose a Multi-scale Attention Guided Module. This module not only extracts multi-scale features effectively but also gives more attention to more discriminative feature maps corresponding to the scale of the salient object. To address the second challenge, we propose an Attention-based Multi-level Integrator Module to give the model the ability to assign different weights to multi-level feature maps. Furthermore, our Sharpening Loss function guides our network to output saliency maps with higher certainty and less blurry salient objects, and it has far better performance than the Cross-entropy loss. For the first time, we adopt four different backbones to show the generalization of our method. Experiments on five challenging datasets prove that our method achieves the state-of-the-art performance. Our approach is fast as well and can run at a real-time speed.},
  archive      = {J_EAAI},
  author       = {Mehrdad Noori and Sina Mohammadi and Sina Ghofrani Majelan and Ali Bahri and Mohammad Havaei},
  doi          = {10.1016/j.engappai.2019.103419},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103419},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DFNet: Discriminative feature extraction and integration network for salient object detection},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New mixed-coding PSO algorithm for a self-adaptive and
automatic learning of mamdani fuzzy rules. <em>EAAI</em>, <em>89</em>,
103417. (<a
href="https://doi.org/10.1016/j.engappai.2019.103417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to its algorithmic performances, PSO algorithm becomes a popular tune tool for fuzzy systems in literature. However, it still encounters many complications, especially when dealing with Mamdani fuzzy system type because of its nature. The Mamdani fuzzy system is known as a linguistic model where the semantic meaning of the fuzzy rules is an intrinsic characteristic that must be retained during the learning process, while seeking for high accuracy. Therefore, to tune the Mamdani fuzzy system, it is very crucial to well represent each rule in a way that preserves this characteristic firstly, and to look for a search mechanism to optimize them throughout this topic secondly. In this paper, we introduce a new and promising approach to optimize the Mamdani fuzzy systems without a need of any prior knowledge. To the best of our knowledge, this approach is the first to optimize simultaneously the membership functions, the scaling factor parameters and the fuzzy rule conclusions with a mixed-coding PSO algorithm by combining a special monitoring function and a self-adaptive threshold. The proposed approach is validated by a comparative study with other design strategies taken from Box–Jenkinsgas furnace system literature and two theoretical examples in addition to a real-time control of the inverted pendulum Feedback 33-200 . The obtained results proved the potential and the effectiveness of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Mohand Akli Kacimi and Ouahib Guenounou and Lamine Brikh and Fateh Yahiaoui and Nouh Hadid},
  doi          = {10.1016/j.engappai.2019.103417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New mixed-coding PSO algorithm for a self-adaptive and automatic learning of mamdani fuzzy rules},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Traffic-signal control reinforcement learning approach for
continuous-time markov games. <em>EAAI</em>, <em>89</em>, 103415. (<a
href="https://doi.org/10.1016/j.engappai.2019.103415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic-Signal Control (TSC) models have been transformed from simple pre-timed isolated indications to a more complex form of actuated and coordinated TSC models for highways, railroads, etc. However, existing TSC models cannot always manage inconveniences like: over-saturation, delays by incidents, congestion by weather conditions, among others, which is why this is still an open area of research. An important challenge is to propose a TSC solution model for multiple intersections, which adapts traffic signal timing according to real-time traffic. This paper introduces a novel Reinforcement Learning (RL) approach for solving the Traffic-Signal Control problem for multiple intersections using Continuous-Time Markov Games (CTMG). The RL model is based on a temporal difference method. For estimating the transition rates of the Markov model, we use non-degenerate randomized Markov laws are being used, such that the connected chain is shown to be ergodic, and to visit all states infinitely often, using all the controls in every state. Our reinforcement learning model supposes to have complete information. The estimation of the transition rates is obtained by the number of transitions on an interval of time divided by the total value of the holding time. The estimation of the rewards is defined as the arithmetic mean of the observed rewards. We consider a non-cooperative game model for solving the multiple intersections problem. For computing the Nash equilibrium, we employ an iterative proximal gradient method. As our final contribution, we present a numerical example for validating our model and concretely measure the benefits of the TSC model.},
  archive      = {J_EAAI},
  author       = {Román Aragon-Gómez and Julio B. Clempner},
  doi          = {10.1016/j.engappai.2019.103415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Traffic-signal control reinforcement learning approach for continuous-time markov games},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing makespan in a flow shop sequence dependent group
scheduling problem with blocking constraint. <em>EAAI</em>, <em>89</em>,
103413. (<a
href="https://doi.org/10.1016/j.engappai.2019.103413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flow Shop Sequence Dependent Group Scheduling (FSDGS) problems gathered much attention from the body of literature in recent years. Nevertheless, the combination of blocking constraint and Group Technology (GT) principles has not been faced by academics so far. The aim of the present paper is to propose an original meta-heuristic approach for minimizing makespan in a FSDGS problem with blocking constraint. To this end, a novel Parallel Self-Adaptive Genetic Algorithm (PSAGA) which adaptively varies the genetic parameters along the evolutionary mechanism was devised. Validation of the proposed metaheuristics was performed by means of the global optima generated by a proper mixed integer linear programming model. An extended experimental campaign, also supported by a specific statistical analysis, demonstrates the effectiveness of the proposed approach compared to other meta-heuristics arising from the relevant literature.},
  archive      = {J_EAAI},
  author       = {A. Costa and F.V. Cappadonna and S. Fichera},
  doi          = {10.1016/j.engappai.2019.103413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Minimizing makespan in a flow shop sequence dependent group scheduling problem with blocking constraint},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective clustering method based on data indeterminacy
in neutrosophic set domain. <em>EAAI</em>, <em>89</em>, 103411. (<a
href="https://doi.org/10.1016/j.engappai.2019.103411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a new clustering algorithm is proposed based on neutrosophic set (NS) theory. The main contribution is to use NS to handle boundary and outlier points as challenging points of clustering methods. In the first step, a new definition of data indeterminacy (indeterminacy set) is proposed in NS domain based on density properties of data. Lower indeterminacy is assigned to data points in dense regions and vice versa. In the second step, indeterminacy set is presented for a proposed cost function in NS domain by considering a set of main clusters and a noisy cluster. In the proposed cost function, two conditions based on distance from cluster centers and value of indeterminacy, are considered for each data point. In the third step, the proposed cost function is minimized by gradient descend methods. Data points are clustered based on their membership degrees. Outlier points are assigned to noise cluster; and boundary points are assigned to main clusters with almost same membership degrees. To show the effectiveness of the proposed method, three types of datasets including diamond, UCI and image datasets are used. Results demonstrate that the proposed cost function handles boundary and outlier points with more accurate membership degrees and outperforms existing state of the art clustering methods in all datasets.},
  archive      = {J_EAAI},
  author       = {Elyas Rashno and Behrouz Minaei-Bidgoli and Yanhui Guo},
  doi          = {10.1016/j.engappai.2019.103411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective clustering method based on data indeterminacy in neutrosophic set domain},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Photo-voltaic power daily predictions using expanding PDE
sum models of polynomial networks based on operational calculus.
<em>EAAI</em>, <em>89</em>, 103409. (<a
href="https://doi.org/10.1016/j.engappai.2019.103409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photo-Voltaic (PV) power production is subject to the current local weather situation which result in the amount of solar radiation components possible to convert by PV modules. Numerical Weather Prediction (NWP) systems are usually run every 6 h to provide course local 24–48-hour forecasts. Statistical models, developed with spatial historical data, can convert or post-process these NWP data to predict PV power for a plant specific situation. Statistical predictions are more precise if rely on the latest weather observations and power measurements as the accuracy of NWP cloudiness is mostly inadequate for PV plant operation and the forecast errors are only magnified. Differential Polynomial Neural Network (D-PNN) is a novel neuro-computing technique based on analogies with brain pulse signal processing. It can model complex patterns without reducing significantly the data dimensionality as regression and soft-computing methods do. D-PNN decomposes the general Partial Differential Equation (PDE), being able to describe the local atmospheric dynamics, into node specific 2nd order sub-PDEs. These are converted using adapted procedures of Operational Calculus to obtain the Laplace images of unknown node functions, which are inverse transformed to obtain the originals. D-PNN can select from dozens of input variables to produce applicable sum PDE components which can extend, step by step, its composite models towards the optima. The PDE models are developed with historical spatial data from the estimated optimal lengths of daily training periods to process the last day input data and predict Clear Sky Index 24-hours ahead. They obtain a better prediction accuracy than simplified statistical solutions which allow to predict in horizon of a few hours only.},
  archive      = {J_EAAI},
  author       = {Ladislav Zjavka},
  doi          = {10.1016/j.engappai.2019.103409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Photo-voltaic power daily predictions using expanding PDE sum models of polynomial networks based on operational calculus},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting customer absence for automobile 4S shops: A
lifecycle perspective. <em>EAAI</em>, <em>89</em>, 103405. (<a
href="https://doi.org/10.1016/j.engappai.2019.103405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Repair and maintenance services are among the most lucrative aspects of the entire automobile business chain. However, in the context of fierce competition, customer churns have led to the bankruptcy of several 4S (sales, spare parts, services, and surveys) shops. In this regard, a six-year dataset is utilized to study customer behaviors to aid managers identify and retain valuable but potential customer churn through a customized retention solution. First, we define the absence and presence behaviors of customers and thereafter generate absence data according to customer habits; this makes it possible to treat the customer absence prediction problem as a classification problem. Second, the repeated absence and presence behaviors of customers are considered as a whole from a lifecycle perspective. A modified recurrent neural network (RNN-2L) is proposed; it is more efficient and reasonable in structure compared with traditional RNN. The time-invariant customer features and the sequential lifecycle features are handled separately; this provides a more sensible specification of the RNN structure from a behavioral interpretation perspective. Third, a customized retention solution is proposed. By comparing the proposed model with those that are conventional, it is found that the former outperforms the latter in terms of area under the curve (AUC), confusion matrix, and amount of time consumed. The proposed customized retention solution can achieve significant profit increase. This paper not only elucidates the customer relationship management in the automobile aftermarket (where the absence and presence behaviors are infrequently considered), but also presents an efficient solution to increase the predictive power of conventional machine learning models. The latter is achieved by considering behavioral and business perspectives.},
  archive      = {J_EAAI},
  author       = {Jiawen Wang and Xinjun Lai and Sheng Zhang and W.M. Wang and Jianghang Chen},
  doi          = {10.1016/j.engappai.2019.103405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting customer absence for automobile 4S shops: A lifecycle perspective},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-phase trajectory optimization for an aerial-aquatic
vehicle considering the influence of navigation error. <em>EAAI</em>,
<em>89</em>, 103404. (<a
href="https://doi.org/10.1016/j.engappai.2019.103404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environment-induced multi-phase trajectory optimization problem is studied in this paper, and the underwater target tracking task is focused on. The task is finished by an aerial-aquatic coaxial eight-rotor vehicle and is divided into two phases, i.e., the diving phase and the underwater navigation phase. The dynamic model and constraints on angular velocity of rotor in each phase are established to understand the motion characteristic. Then the model of navigation information and terrain matching are contained in the trajectory optimization model to reflect the influence of underwater navigation error on the quality of trajectory. Correspondingly, the forms of collision detection and cost function are changed to adapt to the inaccurate navigation information. To obtain the trajectory with the minimum terminal position error, an improved teach &amp; learn-based optimization (ITLBO) algorithm is developed to strengthen the influence of individual historical optimal solution. Besides, Chebyshev collocation points are applied to determine the locations of control variables. Simulation results demonstrate that the established navigation error-based trajectory optimization model can reflect the real situation of multi-phase task. Especially, it is able to calculate the collision probability between the vehicle and the obstacle when GPS is unavailable underwater, thus ensuring the safety of underwater navigation. Compare to other common effective algorithms, the proposed ITLBO algorithm is in general more suitable for solving this problem because it is swarm-based and can obtain good solution without worrying about the inappropriate values of user-defined parameters.},
  archive      = {J_EAAI},
  author       = {Yu Wu and LeiLei Li and Xichao Su and Jiapeng Cui},
  doi          = {10.1016/j.engappai.2019.103404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-phase trajectory optimization for an aerial-aquatic vehicle considering the influence of navigation error},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting indicators of cognitive impairment via graph
convolutional networks. <em>EAAI</em>, <em>89</em>, 103401. (<a
href="https://doi.org/10.1016/j.engappai.2019.103401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the life expectancy is on the rise all over the world, more people face health related problems such as cognitive decline. Dementia is a name used to describe progressive brain syndromes affecting memory, thinking, behaviour and emotion. People suffering from dementia may lose their abilities to perform daily life activities and they become on their caregivers. Hence, detecting the indicators of cognitive decline and warning the caregivers and medical doctors for further diagnosis would be helpful. In this study, we tackle the problem of activity recognition and abnormal behaviour detection in the context of dementia by observing daily life patterns of elderly people. Since there is no real-world data available, firstly a method is presented to simulate abnormal behaviour that can be observed in daily activity patterns of dementia sufferers. Secondly, Graph Convolutional Networks (GCNs) are exploited to recognise activities based on their granular-level sensor activations. Thirdly, abnormal behaviour related to dementia is detected using activity recognition confidence probabilities. Lastly, GCNs are compared against the state-of-the-art methods. The results obtained indicate that GCNs are able to recognise activities and flag abnormal behaviour related to dementia.},
  archive      = {J_EAAI},
  author       = {Damla Arifoglu and Hammadi Nait Charif and Abdelhamed Bouchachia},
  doi          = {10.1016/j.engappai.2019.103401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Detecting indicators of cognitive impairment via graph convolutional networks},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Three-dimensional pavement crack detection based on primary
surface profile innovation optimized dual-phase computing.
<em>EAAI</em>, <em>89</em>, 103376. (<a
href="https://doi.org/10.1016/j.engappai.2019.103376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate pavement crack detection has long been a challenging task, causing significant difficulties to the pavement management sectors in the managerial decision making. The high complexity of the crack’s characteristics and the less effective of the crack analytical tools are the two crucial aspects to be accounted for. Recently, three-dimensional (3D) technology based high precision crack detection methodologies has undergone extensive developments. Nevertheless, none of those methods has taken into the errors caused by the data collection systems into consideration, resulting in a less satisfying performance. Hence, the primary objective of this research is to outline the Primary Surface Profile (PSP) optimized dual-phase computing 3D crack detection methodology. Two years ago, variations caused by the automatic 3D data collection systems were observed, so researchers proposed PSP based data filtering algorithm. Therefore, this research is the upgrade solution of the previous innovation regarding the unbiased 3D pavement crack detection. Firstly, the dual-phase computing approach is proposed in dealing with the non-variance 3D data. Then, the self-adaptive 3D PSP generation method is introduced. Finally, PSP is embedded in the dual-phase computing method for performance optimization. For performance assessment, both precisions and recalls of the proposed approach are compared with conventional method for transverse, longitudinal, and map crack detections. Even crack detection precisions are found for both methods, which are all higher than 0.9. However, the recalls of the proposed method (transverse cracks:0.973, longitudinal cracks:0.981, map cracks:0.940) are significantly outperforming non-optimized dual-phase computing method (transverse cracks: 0.682, longitudinal cracks: 0.789, map cracks:0.811).},
  archive      = {J_EAAI},
  author       = {Ju Huyan and Wei Li and Susan Tighe and Liyang Xiao and Zhaoyun Sun and Nana Shao},
  doi          = {10.1016/j.engappai.2019.103376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Three-dimensional pavement crack detection based on primary surface profile innovation optimized dual-phase computing},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Genetic programming based feature construction methods for
foreground object segmentation. <em>EAAI</em>, <em>89</em>, 103334. (<a
href="https://doi.org/10.1016/j.engappai.2019.103334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foreground object segmentation is a crucial preprocessing step for many high-level computer vision tasks, e.g. object recognition. It is still challenging to achieve accurate segmentation, especially for complex images (e.g. with high variations). Feature construction can help to improve the segmentation performance by extracting more distinctive features for foreground/background regions from the original features. However, commonly-used feature construction methods (e.g. principle component analysis) often involve certain assumptions/constraints, and the constructed features cannot be interpreted. To address these problems, genetic programming (GP) is employed in this paper, which is a well-suited feature construction technique. The aim of this work is to design new feature construction methods using GP, and analyse/compare popular GP-based feature construction methods for foreground object segmentation, especially on complex image datasets with high variations. Specifically, one new feature construction method that incorporates the subtree technique in GP is designed, which can construct multiple features simultaneously (called SubtMFC, Subtree Multiple Feature Construction). Moreover, a parsimony pressure technique is introduced to improve SubtMFC for bloat control (a common issue for GP-based methods), which forms the method, PSubtMFC (Parsimony SubtMFC). In addition, comparison of popular GP-based feature construction methods for foreground object segmentation is conducted for the first time. Results show that SubtMFC achieves better or similar performance compared with three reference methods. In addition, compared with SubtMFC that does not control bloat, PSubtMFC can significantly reduce the solution size while maintain similar performance in the segmentation accuracy. The GP-based feature construction framework is further extended for feature representation based knowledge transfer, which can handle the problem of the scare labelled training data. Moreover, after GP is thoroughly investigated on benchmark datasets with one type of foreground objects (i.e. the Weizmann horse dataset and Pascal aeroplane dataset), it is considered whether the GP methods can perform well on datasets containing multiple types of foreground objects. Compared with three other well-performing GP-based feature construction methods, the proposed method achieves better or comparable results for the given segmentation tasks. In addition, this paper thoroughly compares/analyses popular GP-based feature construction methods for complex figure-ground segmentation for the first time. Moreover, further analyses on the input features frequently used by the GP-evolved feature construction functions reflect the effectiveness of the extracted high-level features.},
  archive      = {J_EAAI},
  author       = {Jiayu Liang and Yu Xue and Jianming Wang},
  doi          = {10.1016/j.engappai.2019.103334},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103334},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Genetic programming based feature construction methods for foreground object segmentation},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Audio content analysis for unobtrusive event detection in
smart homes. <em>EAAI</em>, <em>89</em>, 103226. (<a
href="https://doi.org/10.1016/j.engappai.2019.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental sound signals are multi-source, heterogeneous, and varying in time. Many systems have been proposed to process such signals for event detection in ambient assisted living applications. Typically, these systems use feature extraction, selection, and classification. However, despite major advances, several important questions remain unanswered, especially in real-world settings. This paper contributes to the body of knowledge in the field by addressing the following problems for ambient sounds recorded in various real-world kitchen environments: (1) which features and which classifiers are most suitable in the presence of background noise? (2) what is the effect of signal duration on recognition accuracy? (3) how do the signal-to-noise-ratio and the distance between the microphone and the audio source affect the recognition accuracy in an environment in which the system was not trained? We show that for systems that use traditional classifiers, it is beneficial to combine gammatone frequency cepstral coefficients and discrete wavelet transform coefficients and to use a gradient boosting classifier. For systems based on deep learning, we consider 1D and 2D Convolutional Neural Networks (CNN) using mel-spectrogram energies and mel-spectrograms images as inputs, respectively, and show that the 2D CNN outperforms the 1D CNN. We obtained competitive classification results for two such systems. The first one, which uses a gradient boosting classifier, achieved an F1-Score of 90.2% and a recognition accuracy of 91.7%. The second one, which uses a 2D CNN with mel-spectrogram images, achieved an F1-Score of 92.7% and a recognition accuracy of 96%.},
  archive      = {J_EAAI},
  author       = {Anastasios Vafeiadis and Konstantinos Votis and Dimitrios Giakoumis and Dimitrios Tzovaras and Liming Chen and Raouf Hamzaoui},
  doi          = {10.1016/j.engappai.2019.08.020},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {103226},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Audio content analysis for unobtrusive event detection in smart homes},
  volume       = {89},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Improved stochastic fractal search algorithm and modified
cost function for automatic generation control of interconnected
electric power systems. <em>EAAI</em>, <em>88</em>, 103407. (<a
href="https://doi.org/10.1016/j.engappai.2019.103407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An improved stochastic fractal search algorithm (ISFS) and a modified cost function are proposed in this paper to skillfully handle the issue of automatic generation control (AGC) of power systems. Most employed power system models namely two-area non-reheat thermal power system with and without governor dead band nonlinearity, and three-area hydro-thermal power plant with generation rate constraints are considered to be controlled by a PID controller. Then the gains of this controller are optimized with SFS and ISFS individually by minimizing the value of cost function proposed. This function consists in minimizing the integral time absolute error (ITAE) and also the time rates of frequency and tie-line power deviations. After recognizing the supremacy of SFS tuned PID controller over some existing methods in improving settling time and oscillations of frequency and tie-line power deviations, ISFS tuned PID controller is shown to promote the system performance further to compete with some other control schemes of higher degree and complexity available in the literature. This outcome has unveiled the superior tuning ability of ISFS over the original version of SFS. Also, convergence curves of the algorithms are analyzed from which it is observed that the speed of convergence for ISFS is remarkable.},
  archive      = {J_EAAI},
  author       = {Emre Çelik},
  doi          = {10.1016/j.engappai.2019.103407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved stochastic fractal search algorithm and modified cost function for automatic generation control of interconnected electric power systems},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A segmentation-based approach for polyp counting in the
wild. <em>EAAI</em>, <em>88</em>, 103399. (<a
href="https://doi.org/10.1016/j.engappai.2019.103399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of jellyfish polyp counting in underwater images. Modern methods utilize convolutional neural networks for feature extraction and work in two stages. First, hypothetical regions are proposed at potential locations, the features of the regions are extracted and classified according to the contained object. Such methods typically require a dense grid for region proposals, explicitly test various scales and are prone to failure in densely populated regions. We propose a segmentation-based polyp counter — SegCo. A convolutional neural network is trained to produce locally-circular segmentation masks on the polyps, which are then detected by localizing circularly symmetric areas in the segmented image. Detection stage is efficient and avoids a greedy search over position and scales. SegCo outperforms the current state-of-the-art object detector RetinaNet (Lin et al., 2017) and the recent specialized polyp detection method PoCo (Vodopivec et al., 2018) by 2% and 24% in F-score, respectively, and sets a new state-of-the-art in polyp detection.},
  archive      = {J_EAAI},
  author       = {Vitjan Zavrtanik and Martin Vodopivec and Matej Kristan},
  doi          = {10.1016/j.engappai.2019.103399},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103399},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A segmentation-based approach for polyp counting in the wild},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized elastic net lp-norm nonparallel support vector
machine. <em>EAAI</em>, <em>88</em>, 103397. (<a
href="https://doi.org/10.1016/j.engappai.2019.103397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized eigenvalue proximal support vector machine (GEPSVM) is the first nonparallel support vector machine. Compared to standard support vector machine (SVM), GEPSVM coped with the “Xor” problem well. In this paper, by defining a generalized elastic net regularization which is the combination of the L2-norm and Lq-norm, we propose a generalized elastic net Lp-norm nonparallel proximal support vector machine (GLpNPSVM), where p , q &gt; 0 . GLpNPSVM measures the distance of a sample to each hyperplane by the Lp-norm, and hence can achieve desired performance by choosing appropriate p . In addition, the generalized elastic net regularization makes GLpNPSVM own good generalization ability. GLpNPSVM is a generalized formulation, and GEPSVM and some of its improvements are special cases of GLpNPSVM. A simple but effective iterative technique is introduced to solve GLpNPSVM, and we prove its convergence for certain p , q &gt; 0 . Experimental results on different types of contaminated data sets show the effectiveness of GLpNPSVM.},
  archive      = {J_EAAI},
  author       = {Chun-Na Li and Pei-Wei Ren and Yuan-Hai Shao and Ya-Fen Ye and Yan-Ru Guo},
  doi          = {10.1016/j.engappai.2019.103397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generalized elastic net lp-norm nonparallel support vector machine},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy functional dependencies and linguistic interpretations
employed in knowledge discovery tasks from relational databases.
<em>EAAI</em>, <em>88</em>, 103395. (<a
href="https://doi.org/10.1016/j.engappai.2019.103395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge discovery from databases copes with several problems including the heterogeneity of data and interpreting the solution in an understandable and convenient form for domain experts. Fuzzy logic approaches based on the computing with words paradigm are very appealing since they offer the possibility to express useful knowledge from a large volume of data by linguistic terms, which are easily understandable for diverse users. In this paper, the novel descriptive data mining algorithm based on fuzzy functional dependencies has been proposed. In the first step, data are fuzzified, which ensures the same manipulation of crisp and fuzzy data. The data mining step is based on revealing fuzzy functional dependencies among considered attributes. In the final step, the mined knowledge is interpreted linguistically by the fuzzy modifiers and quantifiers. The proposed algorithm has been explained on illustrative data and tested on real-world dataset. Finally, its benefits, weak points and possible future research topics are discussed.},
  archive      = {J_EAAI},
  author       = {Miljan Vučetić and Miroslav Hudec and Boško Božilović},
  doi          = {10.1016/j.engappai.2019.103395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzy functional dependencies and linguistic interpretations employed in knowledge discovery tasks from relational databases},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A feature extraction based trajectory segmentation approach
based on multiple movement parameters. <em>EAAI</em>, <em>88</em>,
103394. (<a
href="https://doi.org/10.1016/j.engappai.2019.103394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the trajectories of movements among moving objects is of interest in many fields to understand the dynamics and behavior of those objects. In this paper, a cluster-centric trajectory segmentation approach is proposed to reveal and visualize segments of trajectories among moving objects. Characteristics such as position, direction, and speed of moving objects (called movement parameters) are considered for this purpose. First, profiles generated for different movement parameters are divided into several portions using sliding windows of different length. Next, changes with respect to each particular movement parameter profile in the sliding windows are extracted as features. Finally, by clustering the extracted features, subsequences of trajectories with similar movement characteristics are detected. Some cluster-validity indices were used to find the (near) optimal number of clusters. The performance of the proposed segmentation technique is evaluated through a trajectory clustering as well as a movement pattern detection case study over some real-word datasets.},
  archive      = {J_EAAI},
  author       = {Zahedeh Izakian and M. Saadi Mesgari and Robert Weibel},
  doi          = {10.1016/j.engappai.2019.103394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A feature extraction based trajectory segmentation approach based on multiple movement parameters},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertainties in conditional probability tables of discrete
bayesian belief networks: A comprehensive review. <em>EAAI</em>,
<em>88</em>, 103384. (<a
href="https://doi.org/10.1016/j.engappai.2019.103384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete Bayesian Belief Network (BBN) has become a popular method for the analysis of complex systems in various domains of application. One of its pillar is the specification of the parameters of the probabilistic dependence model (i.e. the cause–effect relation) represented via a Conditional Probability Table (CPT). Depending on the available data (observations, prior knowledge, expert-based information, etc.), CPTs can be populated in different manners, i.e. different assumptions can be made and different methods are available, which might lead to uncertain BBN-based results. Through an extensive review study of the past ten years, we aim at addressing three questions related to the CPT uncertainties. First, we show how to constrain these uncertainties either using elicitation of expert inputs, or using a combination of scarce data and expert-derived information. Second, we show how to integrate these uncertainties in the BBN-based analysis through propagation procedures either using probabilities or imprecise probabilities within the setting of credal or evidential networks. Finally, we show how to test the robustness of the BBN-based results to these uncertainties via sensitivity analysis specifically dedicated to BBNs. A special care was paid to describe the best practices for the implementation of the reviewed methods and the remaining gaps.},
  archive      = {J_EAAI},
  author       = {Jeremy Rohmer},
  doi          = {10.1016/j.engappai.2019.103384},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103384},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Uncertainties in conditional probability tables of discrete bayesian belief networks: A comprehensive review},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust neural network approximation-based prescribed
performance output-feedback controller for autonomous underwater
vehicles with actuators saturation. <em>EAAI</em>, <em>88</em>, 103382.
(<a href="https://doi.org/10.1016/j.engappai.2019.103382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A robust neural network approximation-based output-feedback tracking controller is proposed for autonomous underwater vehicles (AUVs) in six degrees-of-freedom in this paper. The prescribed performance technique is employed to obtain some pre-defined maximum overshoot/undershoot, convergence speed and ultimate tracking accuracy for the tracking errors. A high-gain observer is used to approximate unavailable velocity vector which is crucial to design the output-feedback controller. A robust multi-layer neural network and adaptive robust techniques are combined to simultaneously compensate for the unmodeled dynamics, system nonlinearities, exogenous kinematic and dynamic disturbances, and reduce the risk of the actuator saturation. Then, the uniform ultimate boundedness stability of the closed-loop control system is proved via a Lyapunov-based stability synthesis. It is demonstrated that the posture tracking errors converge to a vicinity of the origin with a guaranteed prescribed performance during the tracking mission without velocity measurements. Finally, simulation results with a comparative study verify the theoretical findings.},
  archive      = {J_EAAI},
  author       = {Omid Elhaki and Khoshnam Shojaei},
  doi          = {10.1016/j.engappai.2019.103382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust neural network approximation-based prescribed performance output-feedback controller for autonomous underwater vehicles with actuators saturation},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lazy reinforcement learning for real-time generation control
of parallel cyber–physical–social energy systems. <em>EAAI</em>,
<em>88</em>, 103380. (<a
href="https://doi.org/10.1016/j.engappai.2019.103380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To learn human intelligence, the social system/human system is added to a cyber–physical energy system in this paper. To accelerate the configuration process of the parameters of the cyber–physical energy system, parallel systems based on artificial societies-computational experiments-parallel execution are added to the cyber–physical energy system, i.e., a parallel cyber–physical–social energy system is proposed in this paper. This paper proposes a real-time generation control framework to replace the conventional generation control framework with multiple time scales, which consist of long-term time scale, short-term time scale, and real-time scale. Since a lazy operator employed into reinforcement learning, a lazy reinforcement learning is proposed for the real-time generation control framework. To reduce the real simulation time, multiple virtual parallel cyber–physical–social energy systems and a real parallel cyber–physical–social energy system are built for the real-time generation control of large-scale multi-area interconnected power systems. Compared with a total of 146016 conventional generation control algorithms and a relaxed artificial neural network in the simulation of IEEE 10-generator 39-bus New-England power system, the proposed lazy reinforcement learning based real-time generation control controller can obtain the highest control performance. The active power between two areas and the systemic frequency deviation can be reduced by the lazy reinforcement learning, and the simulation results verify the effectiveness and feasibility of the proposed lazy reinforcement learning based real-time generation control controller for the parallel cyber–physical–social energy systems.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Shengyuan Li and Hui Liu},
  doi          = {10.1016/j.engappai.2019.103380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lazy reinforcement learning for real-time generation control of parallel cyber–physical–social energy systems},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating cement compressive strength using
three-dimensional microstructure images and deep belief network.
<em>EAAI</em>, <em>88</em>, 103378. (<a
href="https://doi.org/10.1016/j.engappai.2019.103378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of cement compressive strength is of great significance in the quality inspections, technological designs, and engineering applications for cement. Compared to destructive methods, the nondestructive estimation approaches save the cost in the manpower and material. However, the existing nondestructive methods have the large error because the used influence factors are difficult to control and the used two-dimensional microstructure images can not reflect the specific spatial structure of the entire cement. In this paper, a novel model is proposed to estimate the cement compressive strength using three-dimensional microstructure images and deep belief network. To reduce the computation consumption induced by three-dimensional images with abundant information, this method extracts image features that reflect the cement hydration state to estimate cement compressive strength. Deep belief network is applied to build the estimation model. Its unique training pattern and flexibility of parameters improve the ability to learn nonlinear relationships between microstructure images and cement compressive strength. Furthermore, the training processes are accelerated on the graphics processing units. The experimental results prove that the proposed method estimates cement compressive strength nondestructively and improves the efficiency.},
  archive      = {J_EAAI},
  author       = {Jifeng Guo and Meihui Li and Lin Wang and Bo Yang and Liangliang Zhang and Zhenxiang Chen and Shiyuan Han and Laura Garcia-Hernandez and Ajith Abraham},
  doi          = {10.1016/j.engappai.2019.103378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimating cement compressive strength using three-dimensional microstructure images and deep belief network},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A point-of-interest suggestion algorithm in multi-source
geo-social networks. <em>EAAI</em>, <em>88</em>, 103374. (<a
href="https://doi.org/10.1016/j.engappai.2019.103374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newly emerging location-based social network (LBSN) services provide us with new platforms to share interests and individual experience based on their activity history. The problems of data sparsity and user distrust in LBSNs create a severe challenge for traditional recommender systems. Moreover, users’ behaviors in LBSNs show an obvious spatio-temporal pattern. Valuable extra information from microblog-based social networks (MBSNs) can be utilized to improve the effectiveness of POI suggestion. In this study, we propose a latent probabilistic generative model called MTAS, which can accurately capture the underlying information in users’ words extracted from both LBSNs and MBSNs by taking into consideration the decision probability, a latent variable indicating a user’s tendency to publish a review in LBSNs or MBSNs. Then, the parameters of the MTAS model can be inferred by the Gibbs sampling method in an effective manner. Based on MTAS, we design an effective framework to fulfill the top- k suggestion. Extensive experiments on two real geo-social networks show that MTAS achieves better performance than existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Xi Xiong and Shaojie Qiao and Yuanyuan Li and Nan Han and Guan Yuan and Yongqing Zhang},
  doi          = {10.1016/j.engappai.2019.103374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A point-of-interest suggestion algorithm in multi-source geo-social networks},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of machine learning for new generation smart
dispatch in power systems. <em>EAAI</em>, <em>88</em>, 103372. (<a
href="https://doi.org/10.1016/j.engappai.2019.103372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the characteristics and challenges of the new generation smart dispatch systems, and proposes the framework of smart dispatch. Secondly, the development of the new generation artificial intelligence technology is represented, especially the development of machine learning algorithms. Thirdly, the applications of machine learning in power systems, e.g. smart generation control, optimal power flow, security assessment, smart dispatch, are listed. Finally, the framework of dispatching robot technology based on parallel learning is present.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Qi Gao and Lulin Zhao and Bin Zhang and Tao Wang and Shengyuan Li and Hui Liu},
  doi          = {10.1016/j.engappai.2019.103372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A review of machine learning for new generation smart dispatch in power systems},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Performance analysis of chaotic multi-verse harris hawks
optimization: A case study on solving engineering problems.
<em>EAAI</em>, <em>88</em>, 103370. (<a
href="https://doi.org/10.1016/j.engappai.2019.103370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several optimization algorithms are proposed, one of them is Multi-Verse Optimizer (MVO). In this paper, a modified version of MVO is proposed, called CMVHHO, which uses the chaos theory and the Harris Hawks Optimization (HHO). The main aim of using the chaotic maps in the proposed method is to determine the optimal value for the parameters of the basic MVO. Besides, the HHO is used as a local search to improve the ability of the MVO to exploit the search space. The performance of the CMVHHO is conducted using a set of chaotic maps to determine the most suitable map, as well as, the different experiments are performed to determine which parameter has the largest effect on the effectiveness of the MVO. Moreover, the performance of the CMVHHO is compared with a set of state-of-the-art algorithms to find the best solution for global optimization problems. Furthermore, the proposed CMVHHO with the best map is applied to solve four well-known engineering problems. The experimental results illustrate that the chaotic Circle map is the best map among all maps because it improved the performance of the CMVHHO, as well as the HHO, affected positively in the behavior of the proposed algorithm. The CMVHHO showed the best results than other algorithms in terms of the performance measures as well as in engineering problems and it outperformed the state-of-the-art algorithms in all problems.},
  archive      = {J_EAAI},
  author       = {Ahmed A. Ewees and Mohamed Abd Elaziz},
  doi          = {10.1016/j.engappai.2019.103370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Performance analysis of chaotic multi-verse harris hawks optimization: A case study on solving engineering problems},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A population-based iterated greedy algorithm for no-wait job
shop scheduling with total flow time criterion. <em>EAAI</em>,
<em>88</em>, 103369. (<a
href="https://doi.org/10.1016/j.engappai.2019.103369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The no-wait job shop where no waiting time is allowed between two successive operations of a job has a strong industrial background, especially in steel-making industry and concrete manufacturing. This study formulates the no-wait job shop problem with a total flow time criterion based on time difference and decomposes the problem into timetabling and sequencing subproblems. Several timetabling methods are designed for the total flow time criterion to generate a sequence timetable. By adopting favourable features of the iterated greedy algorithm, the population-based iterated greedy (PBIG) algorithm for the sequencing subproblem is proposed. The individuals in the population evolve by means of a destruction and construction perturbator and an insertion-based local search. In each iteration, a tournament selection is designed to replace a relatively worse solution. In order to generate starting solutions with a certain quality and diversity, the Nawaz–Enscore–Ham-based heuristics for flow shop scheduling are extended in no-wait job shops. In computational experiments based on well-known benchmark instances, timetabling methods are investigated, and it is shown that the left timetabling is superior to other timetabling methods for the total flow time minimisation. Computational results also show that the proposed algorithm significantly outperforms several state-of-the-art metaheuristics, and it could be applicable to practical production environment.},
  archive      = {J_EAAI},
  author       = {Guanlong Deng and Qingtang Su and Zhiwang Zhang and Huixia Liu and Shuning Zhang and Tianhua Jiang},
  doi          = {10.1016/j.engappai.2019.103369},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103369},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A population-based iterated greedy algorithm for no-wait job shop scheduling with total flow time criterion},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Picture fuzzy time series: Defining, modeling and creating a
new forecasting method. <em>EAAI</em>, <em>88</em>, 103367. (<a
href="https://doi.org/10.1016/j.engappai.2019.103367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extant literature has shown that fuzzy sets can be applied to solve forecasting problems. A fuzzy time series is a kind of time series whose observations are fuzzy sets or fuzzy numbers. A picture fuzzy set is a generalized form of fuzzy and intuitionistic fuzzy sets that is also referred to as a standard neutrosophic set. In this study, a picture fuzzy time series and a single variable high order picture fuzzy time series forecasting model are defined based on picture fuzzy sets. We also propose a new picture fuzzy time series forecasting method. The proposed method solves the issues inherent in the high order single variable picture fuzzy time series forecasting model. The proposed method has three basic steps: (1) picture fuzzification, (2) model construction, and (3) forecasting. In the proposed method, picture fuzzification is accomplished via picture fuzzy clustering, and positive, neutral and negative membership values are obtained. The model construction step consists of estimating a function. This study employed a pi-sigma artificial neural network for this estimation. The proposed method is applied to a meteorological data set with an expanding window approach. The proposed method outperforms recent fuzzy time series and classical methods found in the extant literature.},
  archive      = {J_EAAI},
  author       = {Erol Egrioglu and Eren Bas and Ufuk Yolcu and Mu Yen Chen},
  doi          = {10.1016/j.engappai.2019.103367},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103367},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Picture fuzzy time series: Defining, modeling and creating a new forecasting method},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic topic models for large scale and nonstationary
data. <em>EAAI</em>, <em>88</em>, 103364. (<a
href="https://doi.org/10.1016/j.engappai.2019.103364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many traditional database’s processing schemes are batch-based with their abilities to utilize the entire information available at a time. Though, their limitations include storage (memory issues) and computational speed (often slow) for large scale applications. Another major disadvantage of the batch processing is that any small change or update in the database often requires a reevaluation using all the data at a time. This is not efficient as it is time consuming and exhausting. So, the approach seems to be a little obsolete in this new generation of fast computation. Furthermore and recently, the decrease in the cost of performing computations online promoted the increase in streaming and online-based models. In other words, new systems are taking advantage of the online setting to build models that are able to perform in real time and handle fast computations with real time updates. Traditional models could no longer scale to very large applications. So, much support has been given to online framework as these massive and nonstationary data could not keep up with the available storage. In the case of generative models, usually, the lack of flexible priors and sometimes the high complexities in the methods often hindered their performances. In addition and most importantly, many online-based models still use traditional inference approaches such as variational Bayes (VB) and Markov chain Monte Carlo (MCMC) which individually are not flexible enough as they suffer from either accuracy or efficiency. As a result, we propose in this paper, a new model that operates in online fashion with BL (Beta-Liouville) prior due to its flexibilities in topic correlation analysis. Carrying only very few parameters (compared to the generalized Dirichlet distribution, for instance), the BL is now coupled with a robust and stochastic generative process within a new hybrid inference that combines only the advantages of the VB and Gibbs sampling in the collapsed space. This insures an efficient, fast, and accurate processing. Experimental results with nonstationary datasets for face detection, image classification, and text documents processing show the merits of the new stochastic approach.},
  archive      = {J_EAAI},
  author       = {Koffi Eddy Ihou and Nizar Bouguila},
  doi          = {10.1016/j.engappai.2019.103364},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103364},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Stochastic topic models for large scale and nonstationary data},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal capacity allocation under random passenger demands
in the high-speed rail network. <em>EAAI</em>, <em>88</em>, 103363. (<a
href="https://doi.org/10.1016/j.engappai.2019.103363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity allocation is a practically significant factor to influence the quality of the train timetables in the rail operations, especially under the fluctuation of passenger demands. This paper aims to investigate a detailed description for the structure and characteristics of the capacity allocation problem under random demand in the high-speed rail network. A two-stage stochastic integer programming model is provided to get the capacity allocation solutions to meet random fluctuations of passenger demands in the daily operations, which incorporates demand uncertainty and makes no assumptions for the rail network structure and distribution of passenger demands. Given the inherent complexity for solving this problem, we provide a solution framework including a heuristic algorithm based on tabu search in order to obtain a near-optimal solution and strategies to obtain an efficient timetable and train formation adjustment. Finally, two sets of examples, in which a sample rail network with 5 stations and the Beijing-Shanghai high-speed rail network data are adopted as the experimental environments to illustrate the performance and effectiveness of the proposed methods.},
  archive      = {J_EAAI},
  author       = {Chengxuan Cao and Ziyan Feng},
  doi          = {10.1016/j.engappai.2019.103363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal capacity allocation under random passenger demands in the high-speed rail network},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Teaching a humanoid robot to walk faster through safe
reinforcement learning. <em>EAAI</em>, <em>88</em>, 103360. (<a
href="https://doi.org/10.1016/j.engappai.2019.103360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching a humanoid robot to walk is an open and challenging problem. Classical walking behaviors usually require the tuning of many control parameters (e.g., step size, speed). To find an initial or basic configuration of such parameters could not be so hard, but optimizing them for some goal (for instance, to walk faster) is not easy because, when defined incorrectly, may produce the fall of the humanoid, and the consequent damages. In this paper we propose the use of Safe Reinforcement Learning for improving the walking behavior of a humanoid that permits the robot to walk faster than with a pre-defined configuration. Safe Reinforcement Learning assumes the existence of a safe baseline policy that permits the humanoid to walk, and probabilistically reuse such a policy to learn a better one, which is represented following a case based approach. The proposed algorithm has been evaluated in a real humanoid robot proving that it drastically increases the learning speed while reduces the number of falls during learning when compared with state-of-the-art algorithms.},
  archive      = {J_EAAI},
  author       = {Javier García and Diogo Shafie},
  doi          = {10.1016/j.engappai.2019.103360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Teaching a humanoid robot to walk faster through safe reinforcement learning},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online prediction of time series with assumed behavior.
<em>EAAI</em>, <em>88</em>, 103358. (<a
href="https://doi.org/10.1016/j.engappai.2019.103358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of future time series values is essential for many fields and applications. In some settings, the time series behavior is expected to follow distinct patterns which in turn may change over time due to a change in the user’s preferences/behavior or a change in the environment itself. In this article, we propose to leverage the assumed time series behavior by developing specialized novel online machine learning algorithms. To demonstrate the potential benefits of our approach compared to existing practices we focus on two commonly assumed time series behaviors: exponential decay and sigmoidal. We present two innovative online learning algorithms, Exponentron for the prediction of exponential decay time series and Sigmoidtron for the prediction of sigmoidal time series. We provide an extensive evaluation of both algorithms both theoretically and empirically using synthetic and real-world data. Our results show that the proposed algorithms compare favorably with the classic time series prediction methods commonly deployed today by providing a substantial improvement in prediction accuracy. Furthermore, we demonstrate the potential applicative benefit of our approach for the design of a novel automated agent for the improvement of the communication process between a driver and its automotive climate control system. Through an extensive human study with 24 drivers we show that our agent improves the communication process and increases drivers’ satisfaction.},
  archive      = {J_EAAI},
  author       = {Ariel Rosenfeld and Moshe Cohen and Sarit Kraus and Joseph Keshet},
  doi          = {10.1016/j.engappai.2019.103358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online prediction of time series with assumed behavior},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tour-guide robot: Moving towards interaction with humans.
<em>EAAI</em>, <em>88</em>, 103356. (<a
href="https://doi.org/10.1016/j.engappai.2019.103356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this research project is to develop a smart social robot showing sufficient intelligence to work as a tour-guide in different environments. In doing so, both a software and a hardware architecture are proposed, the different modules of which, such as a laser, cameras, platform, face, and voice, among others, control the different components of the robot. Those components are in turn used by other modules designed for navigation and interaction. A sensor fusion for the purposes of localization is implemented by means of an Extended Kalman Filter, which is one of the navigation module components, together with the proposed fuzzy controllers needed for path following. A fuzzy emotion system that controls the face and the voice modules also forms part of this architecture for assisting interaction. Finally, all the modules are controlled with a customized programming language that is a mixture of C, Pascal, and JavaScript. The modules are optimized for immediate execution to achieve realistic human–machine interaction.},
  archive      = {J_EAAI},
  author       = {Biel Piero E. Alvarado Vásquez and Fernando Matía},
  doi          = {10.1016/j.engappai.2019.103356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A tour-guide robot: Moving towards interaction with humans},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust nonnegative matrix factorization with local
coordinate constraint for image clustering. <em>EAAI</em>, <em>88</em>,
103354. (<a
href="https://doi.org/10.1016/j.engappai.2019.103354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) has attracted increasing attention in data mining and machine learning. However, existing NMF methods have some limitations. For example, some NMF methods seriously suffer from noisy data contaminated by outliers, or fail to preserve the geometric information of the data and guarantee the sparse parts-based representation. To overcome these issues, in this paper, a robust and sparse NMF method, called correntropy based dual graph regularized nonnegative matrix factorization with local coordinate constraint (LCDNMF) is proposed. Specifically, LCDNMF incorporates the geometrical information of both the data manifold and the feature manifold, and the local coordinate constraint into the correntropy based objective function. The half-quadratic optimization technique is utilized to solve the nonconvex optimization problem of LCDNMF, and the multiplicative update rules are obtained. Furthermore, some properties of LCDNMF including the convergence, relation with gradient descent method, robustness, and computational complexity are analyzed. Experiments of clustering demonstrate the effectiveness and robustness of the proposed LCDNMF method in comparison to several state-of-the-art methods on six real world image datasets.},
  archive      = {J_EAAI},
  author       = {Siyuan Peng and Wee Ser and Badong Chen and Lei Sun and Zhiping Lin},
  doi          = {10.1016/j.engappai.2019.103354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust nonnegative matrix factorization with local coordinate constraint for image clustering},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new grey model for traffic flow mechanics. <em>EAAI</em>,
<em>88</em>, 103350. (<a
href="https://doi.org/10.1016/j.engappai.2019.103350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and real-time short-term traffic flow prediction is the core technology of an intelligent transportation system. In this paper, the vehicle conservation principle of traffic flow mechanics is applied to study the differential equation of traffic flow is established by analysing traffic flow parameters. Using the principle of grey difference information, and a grey model of traffic flow in a road section is proposed. This model obtains traffic flow information about traffic flow inflow and congestion via matrix least squares technology and obtains the time response function and modelling steps of the model using a mathematical analysis method, which is applied to short-term traffic flow prediction. The results of three short-term traffic flow cases show that the simulation and prediction results of the new model are better than those of other grey models and two machine learning methods. Relevant information about the traffic flow parameters obtained by the new model is consistent with an actual situation of traffic flow.},
  archive      = {J_EAAI},
  author       = {Xinping Xiao and Huiming Duan},
  doi          = {10.1016/j.engappai.2019.103350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new grey model for traffic flow mechanics},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Network-based direction of movement prediction in financial
markets. <em>EAAI</em>, <em>88</em>, 103340. (<a
href="https://doi.org/10.1016/j.engappai.2019.103340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Market prediction has been an important research problem for decades. Having better predictive models that are both more accurate and faster has been attractive for both researchers and traders. Among many approaches, semi-supervised graph-based prediction has been used as a solution in recent researches. Based on this approach, we present two prediction models. In the first model, a new network structure is introduced that can capture more information about markets’ direction of movements compared to the previous state of the art methods. Based on this novel network, a new algorithm for semi-supervised label propagation is designed that is able to prediction the direction of movement faster and more accurately. The second model is a mixture of experts system that decides between supervised or semi-supervised approaches. Besides this, the model gives us the ability to identify the markets that their data are helpful in constructing the network. Our models are shown to be both faster regarding computational complexity and running time and more accurate in prediction comparing to best rival models in literature of graph-based semi-supervised prediction. The results are also tested to be statistically significant.},
  archive      = {J_EAAI},
  author       = {Arash Negahdari Kia and Saman Haratizadeh and Saeed Bagheri Shouraki},
  doi          = {10.1016/j.engappai.2019.103340},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103340},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Network-based direction of movement prediction in financial markets},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault location estimation for series-compensated
double-circuit transmission line using EWT and weighted RVFLN.
<em>EAAI</em>, <em>88</em>, 103336. (<a
href="https://doi.org/10.1016/j.engappai.2019.103336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, empirical Wavelet transform (EWT), Hilbert transform (HT) and weighted random vector functional link network (WRVFLN) are integrated for fault detection, classification, and location estimation in a series capacitor compensated double circuit transmission line (SCCDCTL). The full cycle current signals from the point of fault inception are decomposed using EWT to extract three band-limited modes (BLMs). The four efficacious instantaneous features namely energy, Shannon entropy, the standard deviation of the magnitude, and crest factor are computed from the Hilbert transformed array of the BLMs to construct the feature vector. A diagonal matrix W is computed from the zero sequence current of original six current signals as a weighting factor to categorize the ground fault accurately. Numerous faults are generated with a wide variation of the system conditions such as fault resistance, fault inception angle, fault distance, percentage compensation level, source impedance, line parameters, load angle, and inter-circuit fault in MATLAB/Simulink environments. An efficient WRVFLN computational intelligence technique is proposed to recognize and estimate the location of the faults by taking the extracted suitable feature vector with weight factor as an input. The performances of WRVFLN are compared with the recently developed advanced classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM) in the MATLAB interface. The lesser computational complexity, faster learning speed, superior classification accuracy, accurate fault location estimation, and short event detection time prove that the proposed EWTHT–WRVFLN method can be implemented in the real power system for online fault diagnosis. Finally, the developed system architecture is implemented on the reconfigurable digital field programmable gate array (FPGA) in ISE design suite 14.5 environments to verify the cogency of the proposed method in real-time. The feasibility of the proposed method is tested and validated by using the fast FPGA digital circuitry in a loop.},
  archive      = {J_EAAI},
  author       = {Mrutyunjaya Sahani and P.K. Dash},
  doi          = {10.1016/j.engappai.2019.103336},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103336},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault location estimation for series-compensated double-circuit transmission line using EWT and weighted RVFLN},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Meta-cognitive recurrent kernel online sequential extreme
learning machine with kernel adaptive filter for concept drift handling.
<em>EAAI</em>, <em>88</em>, 103327. (<a
href="https://doi.org/10.1016/j.engappai.2019.103327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a multi-step prediction model for time series prediction, i.e. Meta-cognitive Recurrent Kernel Online Sequential Extreme Learning Machine with Drift Detector Mechanism (Meta-RKOS-ELM ALD ). Recurrent multi-step algorithm is applied to release the limitation in the number of prediction steps, and Drift Detector Mechanism (DDM) is used to overcome the problem of concept drift in the prediction model. The new meta-cognitive strategy decides the way of the incoming data during training, which decreases the training computation of prediction model and solves the parameter dependency. In our evaluation, we use a total of six artificial data sets and three real-world data sets (Standard &amp; Poor’s 500 Index, Shanghai Stock Exchange Composite Index, and Ozone Concentration in Toronto) to prove the ability of kernel filters, the detecting ability of concept drift detector, and situation of applying meta-cognitive strategy in our proposed model. Experiments results indicate that the Meta-KOS-ELM ALD with DDM has better forecasting ability in various predicting periods with the shortest learning time, as compared with other algorithms.},
  archive      = {J_EAAI},
  author       = {Zongying Liu and Chu Kiong Loo and Kitsuchart Pasupa and Manjeevan Seera},
  doi          = {10.1016/j.engappai.2019.103327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Meta-cognitive recurrent kernel online sequential extreme learning machine with kernel adaptive filter for concept drift handling},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Veracity handling and instance reduction in big data using
interval type-2 fuzzy sets. <em>EAAI</em>, <em>88</em>, 103315. (<a
href="https://doi.org/10.1016/j.engappai.2019.103315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the aspect of big data, veracity refers to the existing uncertainty in the dataset. The continuous flow of unstructured data with unwanted noise may bring abnormality in the dataset making them unusable. In this paper, we propose a novel method to handle the veracity characteristic of the big data using the concept of footprint of uncertainty (FOU) in interval type-2 fuzzy sets (IT2 FSs). The proposed method helps in handling the veracity issue in big data and reduces the instances to a manageable extent. We have compared the results with the existing clustering based methods and examined the relationship between the clusters and the FOUs by comparing their centroids and defuzzified values. To scrutinize the validity of our results, we have also performed a number of additional experiments by appending extra instances to the datasets. To check its consistency and efficacy, the proposed methodology is assessed from three different aspects. Experimental result validates that the proposed method can suitably handle the veracity issue in big datasets and is efficient in reducing the instances.},
  archive      = {J_EAAI},
  author       = {Amit K. Shukla and Megha Yadav and Sandeep Kumar and Pranab K. Muhuri},
  doi          = {10.1016/j.engappai.2019.103315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {103315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Veracity handling and instance reduction in big data using interval type-2 fuzzy sets},
  volume       = {88},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finite-interval-valued type-2 gaussian fuzzy numbers applied
to fuzzy TODIM in a healthcare problem. <em>EAAI</em>, <em>87</em>,
103352. (<a
href="https://doi.org/10.1016/j.engappai.2019.103352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria decision making (MCDM), especially fuzzy MCDM process, is the most suitable approach for evaluating strategic decisions. However, in most cases, the Type-1 fuzzy form is insufficient for addressing uncertainty. The Type-2 fuzzy set is a more powerful tool for characterizing uncertainty in complex problems for several domains. The symmetric shape of Gaussian functions better fits most real cases. In many areas, this Gaussian feature serves to describe complex situations in terms of knowledge representation and to resolve critical decision problems. Therefore, a wide usage of Gaussian Type-2 fuzzy sets is expected; however, because of their complexity, very few studies can be found in the literature. The details of Type-2 Gaussian fuzzy sets have not been thoroughly studied. The foundation of interval-valued Type-2 (IT2) Gaussian fuzzy sets with finite ranges, which are called Finite Interval Type-2 (FIT2) Gaussian fuzzy numbers, is proposed in this study. Then, arithmetic operations on FIT2 Gaussian fuzzy numbers and a ranking procedure are derived and adapted to the strategic selection process. The extended TODIM method with FIT2 Gaussian fuzzy numbers is integrated into a real economic evaluation of a medical device selection problem. This problem is detailed with technical and economical criteria. In this study, a healthcare device selection problem is analyzed from the perspectives of clinicians, biomedical engineers, and healthcare investors. The case study is characterized through an evaluation process in which different experts’ perspectives are considered. Finally, a comparison of the results derived from different multi-criteria solution processes is presented.},
  archive      = {J_EAAI},
  author       = {A. Cagri Tolga and I. Burak Parlak and Oscar Castillo},
  doi          = {10.1016/j.engappai.2019.103352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finite-interval-valued type-2 gaussian fuzzy numbers applied to fuzzy TODIM in a healthcare problem},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel spherical fuzzy QFD method and its application to
the linear delta robot technology development. <em>EAAI</em>,
<em>87</em>, 103348. (<a
href="https://doi.org/10.1016/j.engappai.2019.103348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensions of ordinary fuzzy sets have been put forward one after the other in the literature. The latest extension is spherical fuzzy sets theory proposed by Kutlu Gündoğdu and Kahraman (2019a), which is based on three independent membership parameters defined on a unit sphere with a constraint related to their squared summation. This new extension presenting larger domains for each parameter is employed for production design in this paper. Quality Function Deployment (QFD) is a structured approach for defining customer needs or requirements, which translates them into the final product in order to satisfy these needs. Spherical fuzzy QFD (SF-QFD) under impreciness and vagueness involving linguistic evaluations rather than exact numerical values is proposed in this paper. The importance ratings and global weights of customer requirements (CR) and improvement directions of design requirements (DR) are successfully represented by using spherical fuzzy sets. Judgments of multi-customers/experts are aggregated by spherical fuzzy aggregation operators. A comparative analysis using SF-TOPSIS is applied for competitive firms. A linear delta robot technology design and evaluation is performed by the proposed SF-QFD and a competitive analysis is presented.},
  archive      = {J_EAAI},
  author       = {Fatma Kutlu Gündoğdu and Cengiz Kahraman},
  doi          = {10.1016/j.engappai.2019.103348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel spherical fuzzy QFD method and its application to the linear delta robot technology development},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault prognostics by an ensemble of echo state networks in
presence of event based measurements. <em>EAAI</em>, <em>87</em>,
103346. (<a
href="https://doi.org/10.1016/j.engappai.2019.103346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault prognostics aims at predicting the degradation of equipment for estimating the Remaining Useful Life ( RUL ). Traditional data-driven fault prognostic approaches face the challenge of dealing with incomplete and noisy data collected at irregular time steps, e.g. in correspondence of the occurrence of triggering events in the system. Since the values of all the signals are missing at the same time and the number of missing data largely exceeds the number of triggering events, missing data reconstruction approaches are difficult to apply. In this context, the objective of the present work is to develop a one-step method, which directly receives in input the event-based measurement and produces in output the system RUL with the associated uncertainty. Two strategies based on the use of ensembles of Echo State Networks ( ESNs ), properly adapted to deal with data collected at irregular time steps, have been proposed to this aim. A synthetic and a real-world case study are used to show their effectiveness and their superior performance with respect to state-of-the-art prognostic methods.},
  archive      = {J_EAAI},
  author       = {Mingjing Xu and Piero Baraldi and Sameer Al-Dahidi and Enrico Zio},
  doi          = {10.1016/j.engappai.2019.103346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault prognostics by an ensemble of echo state networks in presence of event based measurements},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group decision making under generalized fuzzy soft sets and
limited cognition of decision makers. <em>EAAI</em>, <em>87</em>,
103344. (<a
href="https://doi.org/10.1016/j.engappai.2019.103344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, the decision making process assumes that the decision maker’s cognition for all aspects of a problem is the same. However, inadequate experience, lack of knowledge, and time suggest otherwise. Therefore, to recognize the impact of the decision maker’s cognition on the validity of the information provided, this paper develops a fuzzy group decision making method based on the generalized fuzzy soft set (GFSS). We apply the Bonferroni mean operators to develop the GFSS Bonferroni mean operator, which can be used for aggregating the information gleaned from the decision makers into collective information, and we construct the GFSS to revise the information provided by the decision makers (DMs). A similarity measure between the GFSSs is proposed and is used to identify the DMs’ weights. Finally, an illustrative example highlights the proposed method and demonstrates the solution characteristics.},
  archive      = {J_EAAI},
  author       = {Weijie Chen and Yan Zou},
  doi          = {10.1016/j.engappai.2019.103344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Group decision making under generalized fuzzy soft sets and limited cognition of decision makers},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed robust data clustering in wireless sensor
networks using diffusion moth flame optimization. <em>EAAI</em>,
<em>87</em>, 103342. (<a
href="https://doi.org/10.1016/j.engappai.2019.103342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional K-Means based distributed clustering used in wireless sensor networks has limitation of getting stuck into local minima, thus many times results in giving inaccurate cluster partitions. To alleviate this drawback, evolutionary based robust distributed clustering techniques are proposed in this paper. These techniques have the capability to determine the global optima thus results in effective cluster partitioning. A moth flame optimization based method is proposed here which minimizes the intra-cluster distance to determine the optimal partition at every sensor node. A diffusion method of cooperation is employed by sharing the best moth position and corresponding fitness value (intra cluster distance) to the neighboring nodes. To introduce robustness, a weight based method for detection and removal of outliers is employed. In this method a weight based on volume and density is given to each data point for outlier detection, a larger weight is considered as an outlier. The simulation study is carried out on one synthetic and two real datasets. The performance of proposed approach is compared with diffusion particle swarm optimization (DPSO), diffusion whale optimization algorithm (DWOA), diffusion elephant herding optimization (DEHO) and distributed K-Means (DK-Means) in terms of Dunn’s index, Silhouette index and time complexity. The minimum average Euclidean deviation of proposed diffusion moth flame optimization is 7.16%, 3.25%, 5.24% and 21.70% lower compared to DPSO, DWOA, DEHO and DK-Means respectively for cook agronomy farm dataset.},
  archive      = {J_EAAI},
  author       = {Dinesh Kumar Kotary and Satyasai Jagannath Nanda},
  doi          = {10.1016/j.engappai.2019.103342},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103342},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Distributed robust data clustering in wireless sensor networks using diffusion moth flame optimization},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A grey-layered ANP based decision support model for
analyzing strategies of resilience in electronic supply chains.
<em>EAAI</em>, <em>87</em>, 103338. (<a
href="https://doi.org/10.1016/j.engappai.2019.103338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented globalizationand vertical integration have made contemporary supply chains an intricate network subject to a number of vulnerabilities. Preemptive measures are needed for dealing with mutable risks and vulnerabilities to safeguard robust supply chain systems. Supply chain risk management (SCRM) connotes a set of risk management responses essentially instigated to confront supply chain risks. As supply chain risks are intertwined, one resilient strategy for risk mitigation can moderate several supply chain risks. A complex decision making problem involving twelve major supply chain risks and twenty one resilient strategies for risk mitigation have been acknowledged in this research with archetypal focus on electronics manufacturing supply chains. A combination of Multi criteria decision aid (MCDA) and artificial intelligence (AI) is increasingly used in decision making of complex real world problems. A decision support model incorporating an amalgamation of grey theory and layered analytic network process (ANP) has been employed for quantifying various resilient strategies for risk mitigation. The proposed model was also applied in a practical setting taking a case study of an electronics manufacturing company. Sensitivity analysis was also conducted to ensure the robustness of obtained results. The combined methodology proposed in this research could be effectively used by top management, to pigeonhole the resilient supply chain strategies for better managing their supply chains.},
  archive      = {J_EAAI},
  author       = {R. Rajesh},
  doi          = {10.1016/j.engappai.2019.103338},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103338},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A grey-layered ANP based decision support model for analyzing strategies of resilience in electronic supply chains},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aircraft detection in remote sensing image based on corner
clustering and deep learning. <em>EAAI</em>, <em>87</em>, 103333. (<a
href="https://doi.org/10.1016/j.engappai.2019.103333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the variations of aircraft type, pose, size and complex background, it remains difficult to detect aircraft effectively in remote sensing images, which plays a great significance in civilian and military. Classical aircraft detection algorithms still produce thousands of candidate regions and extract the features of candidate regions manually, which affects the detection performance. To address these difficulties encountered, an aircraft detection scheme based on corner clustering and Convolutional Neural Network (CNN) is proposed in this paper. The scheme is divided into two main steps: region proposal and classification. First, candidate regions are generated by utilizing mean-shift clustering algorithm to the corners detected on binary images. Then, the CNN is used for the feature extraction and classification of candidate regions that possibly contain the aircraft, and the location of the aircraft is finally determined after further screening. Compared with other classical methods, such as selective search (SS) + CNN, Edgeboxes + CNN and histogram of oriented gradient (HOG) + support vector machine (SVM), the proposed approach has a high accuracy and efficiency since it can automatically learn the essential features of the object from a large amount of data and produce fewer high quality candidate regions.},
  archive      = {J_EAAI},
  author       = {Qiangwei Liu and Xiuqiao Xiang and Yuanfang Wang and Zhongwen Luo and Fang Fang},
  doi          = {10.1016/j.engappai.2019.103333},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103333},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aircraft detection in remote sensing image based on corner clustering and deep learning},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Barnacles mating optimizer: A new bio-inspired algorithm for
solving engineering optimization problems. <em>EAAI</em>, <em>87</em>,
103330. (<a
href="https://doi.org/10.1016/j.engappai.2019.103330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel bio-inspired optimization algorithm namely the Barnacles Mating Optimizer (BMO) algorithm to solve optimization problems. The proposed algorithm mimics the mating behaviour of barnacles in nature for solving optimization problems. The BMO is first benchmarked on a set of 23 mathematical functions to test the characteristics of BMO in finding the optimal solutions. It is then applied to optimal reactive power dispatch (ORPD) problem to verify the reliability and efficiency of BMO. Extensive comparative studies with other algorithms are conducted and from the simulation results, it is observed that BMO generally provides better results and exhibits huge potential of BMO in solving real optimization problems.},
  archive      = {J_EAAI},
  author       = {Mohd Herwan Sulaiman and Zuriani Mustaffa and Mohd Mawardi Saari and Hamdan Daniyal},
  doi          = {10.1016/j.engappai.2019.103330},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103330},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Barnacles mating optimizer: A new bio-inspired algorithm for solving engineering optimization problems},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Whale optimization algorithm-based sugeno fuzzy logic
controller for fault ride-through improvement of grid-connected variable
speed wind generators. <em>EAAI</em>, <em>87</em>, 103328. (<a
href="https://doi.org/10.1016/j.engappai.2019.103328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the extensive penetration of wind power plants (WPPs) into the grid, grid codes have been imposed such that the WPPs stay linked to the grid during faults for a period to maintain the grid stability. This paper designs optimal Sugeno fuzzy logic controllers (FLCs) to improve the fault ride-through (FRT) ability of grid-connected WPPs. The meta-heuristic algorithm, whale optimization algorithm (WOA), is utilized to design the control rules and the Gaussian memberships of eight Sugeno FLCs, simultaneously, by minimizing the high dimensional multi-objective fitness function. The WOA-FLCs and the grid-connected gearless permanent magnet synchronous generator driven by a variable-speed wind turbine (VSWT-PMSG) are modeled using PSCAD/EMTDC environment. The effectiveness of the FRT ability of grid-connected VSWT-PMSG is investigated during balanced and unbalanced grid fault conditions. The simulation results of using WOA-FLCs revealed fast time response, less overshoot, and small steady-state error compared with those achieved by using a genetic algorithm (GA) and grey wolf optimizer (GWO).},
  archive      = {J_EAAI},
  author       = {Mohammed H. Qais and Hany M. Hasanien and Saad Alghuwainem},
  doi          = {10.1016/j.engappai.2019.103328},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103328},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Whale optimization algorithm-based sugeno fuzzy logic controller for fault ride-through improvement of grid-connected variable speed wind generators},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Industry 4.0: Quo vadis? <em>EAAI</em>, <em>87</em>, 103324.
(<a href="https://doi.org/10.1016/j.engappai.2019.103324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Ajith Abraham ( Guest Editors ) and Edward Au and Alécio Binotto and Laura Garcia-Hernandez and Vladimir Marik and Felix Gomez Marmol and Vaclav Snasel and Thomas I. Strasser and Wolfgang Wahlster},
  doi          = {10.1016/j.engappai.2019.103324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industry 4.0: Quo vadis?},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Short-term natural gas consumption prediction based on
volterra adaptive filter and improved whale optimization algorithm.
<em>EAAI</em>, <em>87</em>, 103323. (<a
href="https://doi.org/10.1016/j.engappai.2019.103323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term natural gas consumption prediction is an important indicator of natural gas pipeline network planning and design, which is of great significance. The purpose of this study is to propose a novel hybrid forecast model in view of the Volterra adaptive filter and an improved whale optimization algorithm to predict the short-term natural gas consumption. Firstly, Gauss smoothing and C–C method is adopted to pretreat and reconstruct short-term natural gas consumption time series; secondly, to improve the performance of whale optimization algorithm, adaptive search-surround mechanism and spiral position and jumping behavior are introduced into it; Thirdly, Volterra adaptive filter is used to predict the short-term natural gas consumption, and the important parameters (e.g. embedding dimension) is optimized by improved whale optimization algorithm. Finally, an actual example is given to test the performance of the developed prediction model. The results indicate that (1) short-term natural gas consumption time series has chaotic characteristics; (2) performance of the improved whale optimization algorithm is better than some comparative algorithms (i.e. cuckoo optimization algorithm, etc. ) based on the different evaluation indicators; (3) exploration factor is the main operational factor; (4) the performance of the proposed prediction model is better than some advanced prediction models (e.g. back propagation neural network). It can be concluded that such an innovative hybrid prediction model may provide a reference for natural gas companies to achieve intelligent scheduling.},
  archive      = {J_EAAI},
  author       = {Weibiao Qiao and Zhe Yang and Zhangyang Kang and Zhen Pan},
  doi          = {10.1016/j.engappai.2019.103323},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103323},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term natural gas consumption prediction based on volterra adaptive filter and improved whale optimization algorithm},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding what the users say in chatbots: A case study
for the vietnamese language. <em>EAAI</em>, <em>87</em>, 103322. (<a
href="https://doi.org/10.1016/j.engappai.2019.103322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper 1 presents a study on understanding what the users say in chatbot systems: the situation where users input utterances bots would hopefully (1) detect intents and (2) recognize corresponding contexts implied by utterances. This helps bots better understand what users are saying, and act upon a much wider range of actions. To this end, we propose a framework which models the first task as a classification problem and the second one as a two-layer sequence labeling problem. The framework explores deep neural networks to automatically learn useful features at both character and word levels. We apply this framework to building a chatbot in a Vietnamese e-commerce domain to help retail brands better communicate with their customers. Experimental results on four newly-built datasets demonstrate that deep neural networks could be able to outperform strong conventional machine-learning methods. In detecting intents, we achieve the best F-measure of 82.32%. In extracting contexts, the proposed method yields promising F-measures ranging from 78% to 91% depending on specific types of contexts.},
  archive      = {J_EAAI},
  author       = {Oanh Thi Tran and Tho Chi Luong},
  doi          = {10.1016/j.engappai.2019.103322},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103322},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Understanding what the users say in chatbots: A case study for the vietnamese language},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improvement of bagging performance for classification of
imbalanced datasets using evolutionary multi-objective optimization.
<em>EAAI</em>, <em>87</em>, 103319. (<a
href="https://doi.org/10.1016/j.engappai.2019.103319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, classification of imbalanced datasets, in which the samples belonging to one class is more than the samples pertaining to other classes, has been paid much attention owing to its vast application in real-world problems. Bagging ensemble method, as one of the most favorite ensemble learning algorithms can provide better performance in solving imbalanced problems when is incorporated with undersampling methods. In Bagging method, diversity of classifiers, performance of classifiers, appropriate number of bags (classifiers) and balanced training sets to train the classifiers are important factors in successfulness of Bagging so as to deal with imbalanced problems. In this paper, through inspiring of evolutionary undersampling (the new undersampling method for seeking the subsets of majority class samples) and taking the mentioned factors into account, i.e., diversity, performance of classifiers, number of classifiers and balanced training set, a multi-objective optimization undersampling is proposed. The proposed method uses multi-objective evolutionary to produce set of diverse, well-performing and (near) balanced bags. Accordingly, the proposed method provides the possibility of generating diverse and well-performing classifiers and determining the number of classifiers in Bagging algorithm. Moreover, two different strategies are employed in the proposed method so as to improve the diversity. In order to confirm the proposed method’s efficiency, its performance is measured over 33 imbalanced datasets using AUC and then compared with 6 well-known ensemble learning algorithms. Investigating the obtained results of such comparisons using non-parametric statistical analysis demonstrate the dominancy of the proposed method compared to other employed techniques, as well.},
  archive      = {J_EAAI},
  author       = {Seyed Ehsan Roshan and Shahrokh Asadi},
  doi          = {10.1016/j.engappai.2019.103319},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103319},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improvement of bagging performance for classification of imbalanced datasets using evolutionary multi-objective optimization},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameters identification of bouc–wen hysteresis model for
piezoelectric actuators using hybrid adaptive differential evolution and
jaya algorithm. <em>EAAI</em>, <em>87</em>, 103317. (<a
href="https://doi.org/10.1016/j.engappai.2019.103317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nonlinearities hysteresis of the piezoelectric-PZT actuator can greatly degrade in precise positioning applications. Therefore, modeling and identifying the hysteresis parameter of PZT actuator are still many challenges nowadays. In this paper, the hybrid adaptive differential evolution and Jaya algorithm (aDE-Jaya) is proposed to identify the Bouc–Wen hysteresis model of a piezoelectric actuator. In the aDE-Jaya algorithm, the improvement is focused on a hybrid mutant operator “DE/rand/1” and Jaya operator tried to balance between two contradictory aspects of their performance: exploration and exploitation and adaptive control parameters (mutant factor F, crossover rate CR, population size NP) to enhance the convergence efficiency. To prove the effectiveness and robustness of the proposed aDE-Jaya algorithm, it is tested on 8 benchmark functions and compared with other state-of-the-art optimizations. The comparison results show that aDE-Jaya has better performance in convergence rate and accuracy. After that, aDE-Jaya is applied to identify the Bouc–Wen hysteresis model based on experimental input–output data. The identified Bouc–Wen hysteresis resulted is used to design the feedforward controller to test accurate identification. As a consequent, the proposed aDE-Jaya algorithm can successfully identify the highly hysteretic nonlinearity of the piezoelectric actuator with perfect precision.},
  archive      = {J_EAAI},
  author       = {Nguyen Ngoc Son and Cao Van Kien and Ho Pham Huy Anh},
  doi          = {10.1016/j.engappai.2019.103317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Parameters identification of Bouc–Wen hysteresis model for piezoelectric actuators using hybrid adaptive differential evolution and jaya algorithm},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval-valued fuzzy reasoning algorithms based on
schweizer–sklar t-norms and its application. <em>EAAI</em>, <em>87</em>,
103313. (<a
href="https://doi.org/10.1016/j.engappai.2019.103313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the normalized Minkowski distance in Hausdorff metrics, we study the sensitivity of interval-valued Schweizer-Sklar t-norms and their corresponding residual implications. Moreover, we investigate the robustness of interval-valued fuzzy reasoning triple I algorithms based on Schweizer–Sklar operators and illustrate the feasibility of the algorithms by a numerical example. Finally, the interval-valued fuzzy reasoning triple I algorithms are applied to medical diagnosis.},
  archive      = {J_EAAI},
  author       = {Minxia Luo and Ruirui Zhao and Bei Liu and Jingjing Liang},
  doi          = {10.1016/j.engappai.2019.103313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interval-valued fuzzy reasoning algorithms based on Schweizer–Sklar t-norms and its application},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The application of machine learning techniques for driving
behavior analysis: A conceptual framework and a systematic literature
review. <em>EAAI</em>, <em>87</em>, 103312. (<a
href="https://doi.org/10.1016/j.engappai.2019.103312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving Behavior (DB) is a complex concept describing how the driver operates the vehicle in the context of the driving scene and surrounding environment. Recently, DB assessment has become an emerging topic of great importance. However, in view of to the stochastic nature of driving, measuring and modeling, DB continues to be a challenging topic today. As such, this paper argues that to move forward in understanding the individual and organizational mechanisms influencing DB, a conceptual framework is outlined whereby DB is viewed in terms of different dimensions established within the Driver–Vehicle–Environment (DVE) system. Moreover, DB assessment has been approached by various machine learning (ML) models. Still, there has been no attempt to analyze the empirical evidence on ML models in a systematic way, furthermore, ML based DB models often face problems and raise questions that must be resolved. This article presents a systematic literature review (SLR) of the DB investigation concept; In the first phase, a framework for conceptualizing a holistic approach of the different facets in DB analysis is presented, as well as a scheme to guide the future development and implementation of DB assessment strategies. In the second phase, an overview of the literature on ML is designed, revealing a premier and unbiased survey of the existing empirical research of ML techniques that have been applied to DB analysis. The results of this study identify an interpretive framework incorporating multiple dimensions influencing the driver’s conduct, in an attempt to achieve a thorough understanding of the DB concept within the DVE system in which the drivers operate. Additionally, 82 primary studies published during the last decade and eight broadly used ML models were identified. The findings of this review prove the performance capability of the ML techniques for assessing DB. The models using the ML techniques outperform other conventional approaches. However, the application of ML models in DB analysis is still limited and more effort is needed to obtain well-formed and generalizable results. To this end, and based on the outcomes obtained in this work, future guidelines have been provided to practitioners and researchers to grasp the major contributions and challenges in the state-of-the-art research.},
  archive      = {J_EAAI},
  author       = {Zouhair Elamrani Abou Elassad and Hajar Mousannif and Hassan Al Moatassime and Aimad Karkouch},
  doi          = {10.1016/j.engappai.2019.103312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The application of machine learning techniques for driving behavior analysis: A conceptual framework and a systematic literature review},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing speed/accuracy trade-off for person
re-identification via knowledge distillation. <em>EAAI</em>,
<em>87</em>, 103309. (<a
href="https://doi.org/10.1016/j.engappai.2019.103309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a person across a camera network plays an important role in video surveillance. For a real-world person re-identification application, in order to guarantee an optimal time response, it is crucial to find the balance between accuracy and speed. We analyse this trade-off, comparing a classical method, that comprises hand-crafted feature description and metric learning, in particular, LOMO and XQDA, to deep learning based techniques, using image classification networks, ResNet and MobileNets. Additionally, we propose and analyse network distillation as a learning strategy to reduce the computational cost of the deep learning approach at test time. We evaluate both methods on the Market-1501 and DukeMTMC-reID large-scale datasets, showing that distillation helps reducing the computational cost at inference time while even increasing the accuracy performance.},
  archive      = {J_EAAI},
  author       = {Idoia Ruiz and Bogdan Raducanu and Rakesh Mehta and Jaume Amores},
  doi          = {10.1016/j.engappai.2019.103309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing speed/accuracy trade-off for person re-identification via knowledge distillation},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new multi-objective differential evolution approach for
simultaneous clustering and feature selection. <em>EAAI</em>,
<em>87</em>, 103307. (<a
href="https://doi.org/10.1016/j.engappai.2019.103307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s real-world data mostly involves incomplete, inconsistent, and/or irrelevant information that causes many drawbacks to transform it into an understandable format. In order to deal with such issues, data preprocessing is a proven discipline in data mining. One of the typical tasks in data preprocessing, feature selection aims to reduce the dimensionality in the data and thereby contributes to further processing. Feature selection is widely used to enhance the performance of a supervised learning algorithm (e.g., classification) but is rarely used in unsupervised tasks (e.g., clustering). This paper introduces a new multi-objective differential evolution approach in order to find relatively homogeneous clusters without the prior knowledge of cluster number using a smaller number of features from all available features in the data. To analyze the goodness of the introduced approach, several experiments are conducted on a various number of real-world and synthetic benchmarks using a variety of clustering approaches. From the analyzes through several different criteria, it is suggested that our method can significantly improve the clustering performance while reducing the dimensionality at the same time.},
  archive      = {J_EAAI},
  author       = {Emrah Hancer},
  doi          = {10.1016/j.engappai.2019.103307},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103307},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new multi-objective differential evolution approach for simultaneous clustering and feature selection},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pattern diagnosis for stochastic discrete event systems.
<em>EAAI</em>, <em>87</em>, 103305. (<a
href="https://doi.org/10.1016/j.engappai.2019.103305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, pattern diagnosis problem in stochastic discrete event system (SDES) is investigated. In a system, an abnormal state may be caused by the occurrence of several normal events. This kind of fault is called fault pattern. The diagnosis problem of fault pattern is defined as pattern diagnosis. Based on the notions of A-diagnosability and AA-diagnosability in SDES, the definitions of PA-diagnosability and PAA-diagnosability for pattern diagnosability in SDES are presented in this paper. In addition, a necessary and sufficient condition for an SDES to be PA-diagnosable is proposed. The goal of this paper is diagnosing fault pattern in the real systems. Three-Tank Water Level Control System and Heating, Ventilation, and Air-conditioning System are described to illustrate our algorithm. Experimental results demonstrate that pattern diagnosability in SDES is more accurate than that in DES.},
  archive      = {J_EAAI},
  author       = {Xuena Geng and Dantong Ouyang and Zhengang Jiang},
  doi          = {10.1016/j.engappai.2019.103305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pattern diagnosis for stochastic discrete event systems},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). SECUR-AMA: Active malware analysis based on monte carlo tree
search for android systems. <em>EAAI</em>, <em>87</em>, 103303. (<a
href="https://doi.org/10.1016/j.engappai.2019.103303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose SECUR-AMA, an Active Malware Analysis (AMA) framework for Android. (AMA) is a technique that aims at acquiring knowledge about target applications by executing actions on the system that trigger responses from the targets. The main strength of this approach is the capability of extracting behaviors that would otherwise remain invisible. A key difference from other analysis techniques is that the triggering actions are not selected randomly or sequentially, but following strategies that aim at maximizing the information acquired about the behavior of the target application. Specifically, we design SECUR-AMA as a framework implementing a stochastic game between two agents: an analyzer and a target application. The strategy of the analyzer consists in a reinforcement learning algorithm based on Monte Carlo Tree Search (MCTS) to efficiently search the state and action spaces taking into account previous interactions in order to obtain more information on the target. The target model instead is created online while playing the game, using the information acquired so far by the analyzer and using it to guide the remainder of the analysis in an iterative process. We conduct an extensive evaluation of SECUR-AMA analyzing about 1200 real Android malware divided into 24 families (classes) from a publicly available dataset, and we compare our approach with multiple state-of-the-art techniques of different types, including passive and active approaches. Results show that SECUR-AMA creates more informative models that allow to reach better classification results for most of the malware families in our dataset.},
  archive      = {J_EAAI},
  author       = {Riccardo Sartea and Alessandro Farinelli and Matteo Murari},
  doi          = {10.1016/j.engappai.2019.103303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SECUR-AMA: Active malware analysis based on monte carlo tree search for android systems},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-convex hull based anomaly detection in CPPS.
<em>EAAI</em>, <em>87</em>, 103301. (<a
href="https://doi.org/10.1016/j.engappai.2019.103301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Along with the constantly increasing complexity of industrial automation systems, machine learning methods have been widely applied to detecting abnormal states in such systems. Anomaly detection tasks can be treated as one-class classification problems in machine learning. Geometric methods can give an intuitive solution to such problems. In this paper, we propose a new geometric structure, oriented non-convex hulls, to represent decision boundaries used for one-class classification. Based on this geometric structure, a novel boundary based one-class classification algorithm is developed to solve the anomaly detection problem. Compared with traditional boundary-based approaches such as convex hulls based methods and one-class support vector machines, the proposed approach can better reflect the true geometry of target data and needs little effort for parameter tuning. The effectiveness of this approach is evaluated with artificial and real world data sets to solve the anomaly detection problem in Cyber–Physical-Production-Systems (CPPS). The evaluation results also show that the proposed approach has higher generality than the used baseline algorithms.},
  archive      = {J_EAAI},
  author       = {Peng Li and Oliver Niggemann},
  doi          = {10.1016/j.engappai.2019.103301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Non-convex hull based anomaly detection in CPPS},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Manta ray foraging optimization: An effective bio-inspired
optimizer for engineering applications. <em>EAAI</em>, <em>87</em>,
103300. (<a
href="https://doi.org/10.1016/j.engappai.2019.103300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new bio-inspired optimization technique, named Manta Ray Foraging Optimization (MRFO) algorithm, is proposed and presented, aiming to providing a novel algorithm that provides an alternate optimization approach for addressing real-world engineering issues. The inspiration of this algorithm is based on intelligent behaviors of manta rays. This work mimics three unique foraging strategies of manta rays, including chain foraging, cyclone foraging, and somersault foraging, to develop an efficient optimization paradigm for solving different optimization problems. The performance of MRFO is evaluated, through comparisons with other state-of-the-art optimizers, on benchmark optimization functions and eight real-world engineering design cases. The comparison results on the benchmark functions suggest that MRFO is far superior to its competitors. In addition, the real-world engineering applications show the merits of this algorithm in tackling challenging problems in terms of computational cost and solution precision. The MATLAB codes of the MRFO algorithm are available at https://www.mathworks.com/matlabcentral/fileexchange/73130-manta-ray-foraging-optimization-mrfo .},
  archive      = {J_EAAI},
  author       = {Weiguo Zhao and Zhenxing Zhang and Liying Wang},
  doi          = {10.1016/j.engappai.2019.103300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel supplier grading approach based on interval
probability hesitant fuzzy linguistic TOPSIS. <em>EAAI</em>,
<em>87</em>, 103299. (<a
href="https://doi.org/10.1016/j.engappai.2019.103299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The supplier grading, a typical multi-attribute linguistic group decision-making (MALGDM) problem, is one of the important research topic in the uncertain linguistic environment, especially its aggregation of evaluation information and the establishment of grading approaches. In this paper, first we introduce the generalized interval probability hesitant fuzzy linguistic IOWA weighted average (GVIOWAWA) operator to aggregate the uncertain linguistic information with incomplete reliability. The GVIOWAWA operator can allow decision makers to select the appropriate parameters according to their needs. Then the interval probability hesitant fuzzy linguistic TOPSIS (IPHFL-TOPSIS) based on the interval probability hesitant fuzzy linguistic Euclidean distance is established. The IPHFL-TOPSIS model can effectively and objectively help businesses find the strategic cooperation supplier. Eventually, we give the numerical examples concerning the comprehensive assessment of material supplier and energy supplier to illustrate validity and applicability of the proposed approach and compare the proposed method with different parameters and methods to perform its flexibility.},
  archive      = {J_EAAI},
  author       = {Sidong Xian and Hailin Guo},
  doi          = {10.1016/j.engappai.2019.103299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel supplier grading approach based on interval probability hesitant fuzzy linguistic TOPSIS},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approach based on linguistic spherical fuzzy sets for
public evaluation of shared bicycles in china. <em>EAAI</em>,
<em>87</em>, 103295. (<a
href="https://doi.org/10.1016/j.engappai.2019.103295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the booming sharing economy, shared bicycles as an important part of the sharing economy have been studied by many scholars, and these researches mainly focus on the socioeconomic characteristics of users and the system design level of shared bicycles, it is very necessary to study the evaluation method of shared bicycles which is a typical multi-attribute decision- making (MADM) problem. Firstly, the linguistic spherical fuzzy numbers (Lt-SFNs) is proposed to express the public’s language evaluation information. Compared with the linguistic intuitionistic fuzzy numbers (LIFNs) and the linguistic q-rung orthopair fuzzy numbers (Lq-ROFNs), Lt-SFNs have a wider information expression range. Then, in order to integrate the language evaluation information, the linguistic spherical fuzzy weighted averaging (Lt-SFSWA) operator is proposed, which can aggregate the group linguistic evaluation information. Further, the MABAC (Multi-Attributive Border Approximation area Comparison) method is extended to the linguistic spherical fuzzy environment and the Lt-SFS-MABAC method is proposed, which can process linguistic evaluation information and select an optimal alternative from a plurality of alternatives. At the same time, the TODIM (an acronym in Portuguese of Interactive and Multicriteria Decision Making) method is extended to the linguistic spherical fuzzy environment and the Lt-SFS-TODIM method is proposed. Lastly, we conducted sensitivity analysis and comparative analysis of the Lt-SFS-MABAC method, the Lt-SFS-TODIM method and the Lt-SFSWA method. The results show that the Lt-SFS-MABAC method is sensitive to weights, decision makers can use the Lt-SFS-MABAC method to make a realistic evaluation based on the actual environment.},
  archive      = {J_EAAI},
  author       = {Peide Liu and Baoying Zhu and Peng Wang and Mengjiao Shen},
  doi          = {10.1016/j.engappai.2019.103295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An approach based on linguistic spherical fuzzy sets for public evaluation of shared bicycles in china},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A powerful variant of symbiotic organisms search algorithm
for global optimization. <em>EAAI</em>, <em>87</em>, 103294. (<a
href="https://doi.org/10.1016/j.engappai.2019.103294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper suggests a new variation to the existing symbiotic organisms search (SOS) algorithm developed by simulating three symbiotic strategies of mutualism, commensalism and parasitism used by the organisms. In the revised version called improved SOS (ISOS), the theory of quasi-oppositional based learning is employed during generation of initial population and in the parasitism phase to raise the possibility of getting closer to high-quality solutions. An efficient alternative for parasitism phase is also presented. The two upgraded parasitism strategies avoid the over exploration issue of original parasitism phase that causes unwanted long-time search in the inferior search space as the solution is already refined. To guide the algorithm perform an exhaustive search around the best solution in attempting to further improve the search model of ISOS, a chaotic local search based on the piecewise linear chaotic map is coupled into the proposed algorithm. Twenty-six benchmark functions and three engineering design problems are tested and a contrast with other popular metaheuristics is widely established. Comparative results substantiate the great contribution of proposed ISOS algorithm in solving various optimization problems with superior global search capability and convergence characteristics which render it useful in handling global optimization problems.},
  archive      = {J_EAAI},
  author       = {Emre Çelik},
  doi          = {10.1016/j.engappai.2019.103294},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103294},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A powerful variant of symbiotic organisms search algorithm for global optimization},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A combined entropy-based approach for a proactive credit
scoring. <em>EAAI</em>, <em>87</em>, 103292. (<a
href="https://doi.org/10.1016/j.engappai.2019.103292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lenders, such as credit card companies and banks, use credit scores to evaluate the potential risk posed by lending money to consumers and, therefore, mitigating losses due to bad debt. Within the financial technology domain, an ideal approach should be able to operate proactively, without the need of knowing the behavior of non-reliable users. Actually, this does not happen because the most used techniques need to train their models with both reliable and non-reliable data in order to classify new samples. Such a scenario might be affected by the cold-start problem in datasets, where there is a scarcity or total absence of non-reliable examples, which is further worsened by the potential unbalanced distribution of the data that reduces the classification performances. In this paper, we overcome the aforementioned issues by proposing a proactive approach, composed of a combined entropy-based method that is trained considering only reliable cases and the sample under investigation. Experiments done in different real-world datasets show competitive performances with several state-of-art approaches that use the entire dataset of reliable and unreliable cases.},
  archive      = {J_EAAI},
  author       = {Salvatore Carta and Anselmo Ferreira and Diego Reforgiato Recupero and Marco Saia and Roberto Saia},
  doi          = {10.1016/j.engappai.2019.103292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A combined entropy-based approach for a proactive credit scoring},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A predictive model for the maintenance of industrial
machinery in the context of industry 4.0. <em>EAAI</em>, <em>87</em>,
103289. (<a
href="https://doi.org/10.1016/j.engappai.2019.103289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Industry 4.0 paradigm is being increasingly adopted in the production, distribution and commercialization chains worldwide. The integration of the cutting-edge techniques behind it entails a deep and complex revolution – changing from scheduled-based processes to smart, reactive ones – that has to be thoroughly applied at different levels. Aiming to shed some light on the path towards such evolution, this work presents an Industry 4.0 based approach for facing a key aspect within factories: the health assessment of critical assets. This work is framed in the context of the innovative project SiMoDiM , which pursues the design and integration of a predictive maintenance system for the stainless steel industry. As a case of study, it focuses on the machinery involved in the production of high-quality steel sheets, i.e. the Hot Rolling Process , and concretely on predicting the degradation of the drums within the heating coilers of Steckel mills (parts with an expensive replacement that work under severe mechanical and thermal stresses). This paper describes a predictive model based on a Bayesian Filter , a tool from the Machine Learning field, to estimate and predict the gradual degradation of such machinery, permitting the operators to make informed decisions regarding maintenance operations. For achieving that, the proposed model iteratively fuses expert knowledge with real time information coming from the hot rolling processes carried out in the factory. The predictive model has been fitted and evaluated with real data from ∼ 118k processes, proving its virtues for promoting the Industry 4.0 era.},
  archive      = {J_EAAI},
  author       = {Jose-Raul Ruiz-Sarmiento and Javier Monroy and Francisco-Angel Moreno and Cipriano Galindo and Jose-Maria Bonelo and Javier Gonzalez-Jimenez},
  doi          = {10.1016/j.engappai.2019.103289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A predictive model for the maintenance of industrial machinery in the context of industry 4.0},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on “novel scaled prioritized intuitionistic fuzzy
soft interaction averaging aggregation operators and their application
to multi criteria decision making.” <em>EAAI</em>, <em>87</em>, 103287.
(<a href="https://doi.org/10.1016/j.engappai.2019.103287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Garg and Arora (2018) pointed out that it is not appropriate to use the existing intuitionistic fuzzy soft (IFS) aggregations operators (Arora and Garg, 2018a,b), proposed by themselves, as these aggregation operators gives undesirable results under some circumstances. To resolve the flaws of these aggregation operators, Garg and Arora (2018) proposed the improved operational laws of IFS numbers and hence, proposed a new IFS aggregation operator (named as Scaled prioritized intuitionistic fuzzy soft interaction (SPIFSI) aggregation operator). Garg and Arora (2018) also proposed a SPIFSI aggregation operator based intuitionistic fuzzy soft multi criteria decision making (IFSMCDM) approach for solving IFSMCDM problems (Multi criteria decision making problems in which the rating value of each alternative over each criterion is represented by an IFS set). Although, Garg and Arora (2018) have claimed that their proposed SPIFSI aggregation operator is valid as it satisfies the idempotency, boundedness and monotonicity properties. But, in actual case, for the SPIFSI aggregation operator, proposed by Garg and Kumar (2018), the monotonicity property is not satisfying. Therefore, the SPIFSI aggregation operator, proposed by Garg and Arora (2018), and hence, the SPIFSI aggregation operator based IFSMCDM approach, are not valid. Since, in future, other researchers may use the SPIFSI aggregation operator in their research work. Also, the researchers may use the SPIFSI aggregation operator based IFSMCDM approach for solving real life IFSMCDM problems. Therefore, the aim of this note is to make the researchers aware about the discrepancies of the SPIFSI aggregation operator as well as the SPIFSI aggregation operator based IFMCDM approach. Furthermore, to make the researchers aware that improved operational laws of IFS numbers, proposed by Garg and Arora (2018), are also not valid.},
  archive      = {J_EAAI},
  author       = {Akansha Mishra and Amit Kumar and S.S. Appadoo},
  doi          = {10.1016/j.engappai.2019.103287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A note on “Novel scaled prioritized intuitionistic fuzzy soft interaction averaging aggregation operators and their application to multi criteria decision making”},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). ElHealth: Using internet of things and data prediction for
elastic management of human resources in smart hospitals. <em>EAAI</em>,
<em>87</em>, 103285. (<a
href="https://doi.org/10.1016/j.engappai.2019.103285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospitals play an important role towards ensuring proper health treatment to human beings. One of the major challenges faced in this context refers to the increasingly overcrowded patients queues, which contribute to a potential deterioration of patients health conditions. One of the reasons of such an inefficiency is a poor allocation of health professionals. In particular, such allocation process is usually unable to properly adapt to unexpected changes in the patients demand. As a consequence, it is frequently the case where underused rooms have idle professionals whilst overused rooms have less professionals than necessary. Previous works addressed this issue by analyzing the evolution of supply (doctors) and demand (patients) so as to better adjust one to the other, though none of them focused on proposing effective counter-measures to mitigate poor allocations. In this paper, we build upon the concept of smart hospitals and introduce elastic allocation of human resources in healthcare environments (ElHealth), an IoT-focused model able to monitor patients usage of hospital rooms and to adapt the allocation of health professionals to these rooms so as to meet patients needs. ElHealth employs data prediction techniques to anticipate when the demand of a given room will exceeds its capacity, and to propose actions to allocate health professionals accordingly. We also introduce the concept of multi-level predictive elasticity of human resources (which is an extension of the concept of resource elasticity , from cloud computing) to manage the use of human resources at different levels of a healthcare environment. Furthermore, we devise the concept of proactive human resources elastic speedup (which is an extension of the speedup concept, from parallel computing) to properly measure the gain of healthcare time with dynamic parallel use of human resources within hospital environments. ElHealth was thoroughly evaluated based on simulations of a hospital environment using data from a Brazilian polyclinic, and obtained promising results, decreasing the waiting time by up to 96.71%.},
  archive      = {J_EAAI},
  author       = {Gabriel Souto Fischer and Rodrigo da Rosa Righi and Gabriel de Oliveira Ramos and Cristiano André da Costa and Joel J.P.C. Rodrigues},
  doi          = {10.1016/j.engappai.2019.103285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ElHealth: Using internet of things and data prediction for elastic management of human resources in smart hospitals},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised feature selection via graph matrix learning and
the low-dimensional space learning for classification. <em>EAAI</em>,
<em>87</em>, 103283. (<a
href="https://doi.org/10.1016/j.engappai.2019.103283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection is a powerful tool to select a subset of features for effective representation of high-dimensional data. In this paper, we proposes a novel unsupervised feature selection method via the graph matrix learning and the low-dimensional space learning to obtain their individually optimized result. Furthermore, the global and local correlation of features have been taken into consideration through the low-rank constraint and the feature-level representation property on the graph matrix. Experimental analysis on 15 benchmark datasets verified that our proposed method outperformed the state-of-the-art feature selection methods in terms of classification performance.},
  archive      = {J_EAAI},
  author       = {Xiaohong Han and Ping Liu and Li Wang and Dengao Li},
  doi          = {10.1016/j.engappai.2019.103283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised feature selection via graph matrix learning and the low-dimensional space learning for classification},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Device free human gesture recognition using wi-fi CSI: A
survey. <em>EAAI</em>, <em>87</em>, 103281. (<a
href="https://doi.org/10.1016/j.engappai.2019.103281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Device-free sensing of human gestures has gained tremendous research attention with the recent advancements in wireless technologies. Channel State Information (CSI), a metric of Wi-Fi devices adopted for device-free sensing achieves better recognition performance. This survey classifies the state of the art recognition task into device-based and device-free sensing methods and highlights advancements with Wi-Fi CSI. This paper also comprehensively summarizes the recognition performance of device-free sensing using CSI under two approaches: model-based and learning based approaches. Machine Learning and Deep Learning algorithms are discussed under the learning based approaches with its corresponding recognition accuracy. Various signal pre-processing, feature extraction, selection, and classification techniques that are widely adopted for gesture recognition along with the environmental factors that influence the recognition accuracy are also discussed. This survey presents the conclusion spotting the challenges and opportunities that could be explored in the device free gesture recognition using the CSI metric of Wi-Fi devices.},
  archive      = {J_EAAI},
  author       = {Hasmath Farhana Thariq Ahmed and Hafisoh Ahmad and Aravind C.V.},
  doi          = {10.1016/j.engappai.2019.103281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Device free human gesture recognition using wi-fi CSI: A survey},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extracting and tracking hot topics of micro-blogs based on
improved latent dirichlet allocation. <em>EAAI</em>, <em>87</em>,
103279. (<a
href="https://doi.org/10.1016/j.engappai.2019.103279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-blog has changed people’s life, study, and work styles. Every day, we want to know what public opinion news happens and how it evolves. Extracting and tracking these topics correctly help us better understand the latest public opinions and pay attention to their evolution. To extract topics from Microblog posts accurately, we adopt five unique features of micro-blogs to drive the joint probability distributions of all words and topics, and improve LDA into our topic extraction model(named MF-LDA). To track evolution trend of the topic, we propose a hot topic life cycle model (named HTLCM). We divide the HTLCM into five stages, namely, birth, growth, maturity, decline, and disappearance. The HTLCM determines whether a topic is the candidate hot topic or not and estimates hot topic evolution stages. On the other hand, we propose a hot topic tracking (shorten for HTT) algorithm which integrates MF-LDA and HTLCM. First, the HTT assigns candidate hot topics, which are labeled by HTLCM, to the corresponding time window according to the release time. Second, to obtain the hot topic in each time window, we input Micro-blog posts of each time window into MF-LDA in order. By analyzing changes in these hot topics, we track the changes in their contents. The experiment results show that MF-LDA has a lower perplexity and higher coverage rate than LDA under the same conditions. We conclude parameters of the Transition regions of our proposed HTLCM model. The MR, FR of our proposed HTLCM model are lower than 18%. The average P, R, F of the HTT algorithm are 85.64%, 84.97%, 85.66%, respectively. A practical application on topicFemale driver beats male driver in chengdu shows an excellent effect and practical significance of HTLCM model and HTT algorithm in extracting and tracking hot topics.},
  archive      = {J_EAAI},
  author       = {YaJun Du and YongTao Yi and XianYong Li and XiaoLiang Chen and YongQuan Fan and FangHong Su},
  doi          = {10.1016/j.engappai.2019.103279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Extracting and tracking hot topics of micro-blogs based on improved latent dirichlet allocation},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Power prediction for electric vehicles using online machine
learning. <em>EAAI</em>, <em>87</em>, 103278. (<a
href="https://doi.org/10.1016/j.engappai.2019.103278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate range prediction of an electric vehicle is an important open problem, affecting among others the adoption and market penetration of electric vehicles. Current range prediction systems suffer several practical limitations. Most critically these systems employ models in which all vehicle-specific parameters are required to be known. In this paper, we propose a methodology for predicting power and mission energy of electric vehicles that does not require knowledge of vehicle-specific parameters nor a drive-train model. The proposed method uses a data-driven approach grounded entirely on available vehicle sensor data. In particular, the predictive model is obtained by applying machine learning techniques, and in order to adapt to changing conditions in real-time, the specific class of kernel adaptive filtering algorithms is employed. Kernel adaptive filtering extends the theory of linear filters with concepts from kernel methods in order to construct nonlinear adaptive filtering algorithms that exhibit properties such as universal approximation capabilities and convexity in training, requiring only modest computational complexity. After providing an overview of the most relevant properties of kernel adaptive filters, we evaluate the proposed prediction methodology on data obtained in nine vehicle trial runs, comparing the performance of one linear adaptive filter, one online trained neural network and two state-of-the-art kernel adaptive filters.},
  archive      = {J_EAAI},
  author       = {Stephan Rhode and Steven Van Vaerenbergh and Matthias Pfriem},
  doi          = {10.1016/j.engappai.2019.103278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Power prediction for electric vehicles using online machine learning},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel target threat assessment method based on three-way
decisions under intuitionistic fuzzy multi-attribute decision making
environment. <em>EAAI</em>, <em>87</em>, 103276. (<a
href="https://doi.org/10.1016/j.engappai.2019.103276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target threat assessment aims to rank targets threat based on their attributes and state information, which provide decision support for subsequent military decisions, e.g. weapon-target optimal assignment. Most existing threat assessment methods can only obtain ranking results, decision-makers usually need to subjectively choose priority targets to attack or interfere based on the preset threat level and ordering results, which does not meet the requirements of complex battlefield situation and uncertain information processing. A method is urgently needed, which can objectively produce threat classification results and automatically provide priority targets for combat. Therefore, we propose a novel target threat assessment method based on three-way decisions under intuitionistic fuzzy multi-attribute decision making environment. The core parts are the conditional probability of each target is estimated by intuitionistic fuzzy TOPSIS and the decision thresholds of each target are constructed by intuitionistic fuzzy evaluation values. The results of two numerical examples show that the proposed method can effectively deal with dynamic uncertain situation information, turn the traditional ranking results of two-way decisions to the objective classification results of three-way decisions and can flexibly reflect the acquisition of situation information by setting the risk avoidance coefficient.},
  archive      = {J_EAAI},
  author       = {Yang Gao and Dong-sheng Li and Hua Zhong},
  doi          = {10.1016/j.engappai.2019.103276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel target threat assessment method based on three-way decisions under intuitionistic fuzzy multi-attribute decision making environment},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General structure of interval type-2 fuzzy PI/PD controller
of takagi–sugeno type. <em>EAAI</em>, <em>87</em>, 103273. (<a
href="https://doi.org/10.1016/j.engappai.2019.103273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new configuration of Interval Type-2 (IT2) fuzzy Proportional–Integral (PI) or fuzzy Proportional–Derivative (PD) controller of Takagi–Sugeno (TS) type is presented. An attempt is made to generalize the IT2 fuzzy PI/PD controller structure using multiple fuzzy sets. Fuzzification of the inputs is done with three or more fuzzy sets having triangular/trapezoidal membership functions. The rule base consists of only three rules to reduce the number of tuneable parameters of the controller. Minimum (Min) triangular norm and Bounded Sum (BS) triangular co-norm are used as conjunction and disjunction operators to reduce the number of rules. Karnik–Mendel (KM) type reducer and Weighted Average (WA) defuzzifier are considered to derive the analytical structure of the fuzzy controller. Properties and gain variations of the fuzzy controller are investigated. Simulation study is carried out on nonlinear dynamical systems to verify the applicability of the fuzzy controllers.},
  archive      = {J_EAAI},
  author       = {Ritu Raj and B.M. Mohan},
  doi          = {10.1016/j.engappai.2019.103273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {General structure of interval type-2 fuzzy PI/PD controller of Takagi–Sugeno type},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic versus instance segmentation in microscopic algae
detection. <em>EAAI</em>, <em>87</em>, 103271. (<a
href="https://doi.org/10.1016/j.engappai.2019.103271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microscopic algae segmentation, specifically of diatoms, is an essential procedure for water quality assessment. The segmentation of these microalgae is still a challenge for computer vision. This paper addresses for the first time this problem using deep learning approaches to predict exactly those pixels that belong to each class, i.e., diatom and non diatom. A comparison between semantic segmentation and instance segmentation is carried out, and the performance of these methods is evaluated in the presence of different types of noise. The trained models are then evaluated with the same raw images used for manual diatom identification. A total of 126 images of the entire field of view at 60x magnification, with a size of 2592x1944 pixels, are analyzed. The images contain 10 different taxa plus debris and fragments. The best results were obtained with instance segmentation achieving an average precision of 85% with 86% sensitivity and 91% specificity (up to 92% precision with 98%, both sensitivity and specificity for some taxa). Semantic segmentation was able to improve the average sensitivity up to 95% but decreasing the specificity down to 60% and precision to 57%. Instance segmentation was also able to properly separate diatoms when overlap occurs, which helps estimate the number of diatoms, a key requirement for water quality grading.},
  archive      = {J_EAAI},
  author       = {Jesus Ruiz-Santaquiteria and Gloria Bueno and Oscar Deniz and Noelia Vallez and Gabriel Cristobal},
  doi          = {10.1016/j.engappai.2019.103271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semantic versus instance segmentation in microscopic algae detection},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interval type-2 fuzzy logic based transmission power
allocation strategy for lifetime maximization of WSNs. <em>EAAI</em>,
<em>87</em>, 103269. (<a
href="https://doi.org/10.1016/j.engappai.2019.103269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), it is critical to design an advisable transmission power allocation strategy for balancing the latency and energy efficiency, and prolonging the lifetime of WSNs. However, some measured key parameters, e.g., data latency, energy consumption and communication radius, are with high levels of uncertainties, which deteriorate the transmission power allocation performance greatly. How to employ an advanced method to deal with the uncertainties and to further improve the network performance is a pressing issue. Type-2 fuzzy logic system (T2FLS) as a powerful tool for handling the uncertainties provides an effective way for designing such advisable allocation strategies. Therefore, this paper adopts the interval T2FLS (IT2FLS) to design the transmission power allocation (TPA) strategy for lifetime maximization of WSNs. Firstly, the problem of lifetime enhancement in WSNs is formulated in detail, and then it is converted into a TPA problem. Secondly, the IT2FLS method is applied to the transmission power decision making process for maximizing the lifetime of WSNs. In the designed IT2FLS-based TPA strategy, expected latency, residual energy and distance between nodes are taken as input variables, while the transmission power and communication radius are considered as the output variables. Finally, both simulation and experiment results are given. The results indicate that the proposed TPA strategy using IT2FLS can effectively realize the tradeoff between the latency and energy efficiency, and can prolong the network lifetime of the WSNs. Moreover, compared with other TPA strategies, including the minimum total energy algorithm, the flow augmentation algorithm and the type-1 fuzzy logic method, the proposed IT2FLS-based TPA strategy has obvious advantages in terms of network lifetime, average latency and energy consumption.},
  archive      = {J_EAAI},
  author       = {Wei Peng and Chengdong Li and Guiqing Zhang and Jianqiang Yi},
  doi          = {10.1016/j.engappai.2019.103269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interval type-2 fuzzy logic based transmission power allocation strategy for lifetime maximization of WSNs},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A complex process fault diagnosis method based on manifold
distribution adaptation. <em>EAAI</em>, <em>87</em>, 103267. (<a
href="https://doi.org/10.1016/j.engappai.2019.103267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge for complex industrial processes is that the distribution of new process data is different from that of old process data, resulting in poor performance when monitoring the new process (target domain) using the model established by the old process (source domain) data. Moreover, new process data is often unlabeled, which is more common in actual industrial processes. Therefore, this paper proposes a novel fault diagnosis method for complex industrial processes based on Manifold Distribution Adaptation (MDA) to cope with this challenge. Specifically, in order to avoid feature degradation caused by feature transformation directly in the original feature space, MDA first maps source domain data and target domain data to Grassmann manifold through geodesic flow kernel. Second, dynamic distribution adaptation and source domain instance re-weighting are performed simultaneously on the Grassmann manifold to reduce the shift between the domains. Then, the base classifier trained by the adaptive source domain data can achieve accurate classification of the target domain data. Finally, the superiority of MDA is verified on the public transfer learning datasets and the actual industrial process datasets.},
  archive      = {J_EAAI},
  author       = {Xiaogang Wang and Jianwei Zhao},
  doi          = {10.1016/j.engappai.2019.103267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A complex process fault diagnosis method based on manifold distribution adaptation},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient hybrid multi-objective memetic algorithm for
the frequency assignment problem. <em>EAAI</em>, <em>87</em>, 103265.
(<a href="https://doi.org/10.1016/j.engappai.2019.103265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates hybridization of multi-objective memetic algorithm and artificial immune system (AIS) for the Frequency Assignment Problem (FAP) in cellular mobile networks. The considered objectives to minimize are the total interference, the maximal interference, and the number of used frequencies. The proposed approach integrates FAP-specific local search into the evolutionary process to overcome the shortcoming of the multi-objective genetic algorithm, as well as clonal selection and receptor editing, which aims to improve the algorithm exploration and exploitation abilities. Based on the hypervolume metric, the proposed hybrid multi-objective algorithm produces high quality solutions as proved by the tests performed over COST259 instances and corroborated by the comparisons with the most frequently referred algorithms in the related literature. Furthermore, the effect and the behaviour of the main parameters of our algorithm and the interaction between them are analysed using the Design of Experiment (DOE).},
  archive      = {J_EAAI},
  author       = {Abd Errahmane Kiouche and Malika Bessedik and Fatima Benbouzid-SiTayeb and Mohamed Reda Keddar},
  doi          = {10.1016/j.engappai.2019.103265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An efficient hybrid multi-objective memetic algorithm for the frequency assignment problem},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Super-resolved thermal imagery for high-accuracy facial
areas detection and analysis. <em>EAAI</em>, <em>87</em>, 103263. (<a
href="https://doi.org/10.1016/j.engappai.2019.103263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we evaluate various Convolutional Neural Networks based Super-Resolution (SR) models to improve facial areas detection in thermal images. In particular, we analyze the influence of selected spatiotemporal properties of thermal image sequences on detection accuracy. For this purpose, a thermal face database was acquired for 40 volunteers. Contrary to most of existing thermal databases of faces, we publish our dataset in a raw, original format (14-bit depth) to preserve all important details. In our experiments, we utilize two metrics usually used for image enhancement evaluation: Peak-Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Metric (SSIM). In addition, we present how to design a SR network with a widened receptive field to mitigate the problem of contextual information being spread over larger image regions due to the heat flow in thermal images. Finally, we determine whether there is a relation between achieved PSNR and accuracy of facial areas detection that can be analyzed for vital signs extraction (e.g. nostril region). The performed evaluation showed that PSNR can be improved even by 60% if full bit depth resolution data is used instead of 8 bits. Also, we showed that the application of image enhancement solution is necessary for low resolution images to achieve a satisfactory accuracy of object detection.},
  archive      = {J_EAAI},
  author       = {Alicja Kwasniewska and Jacek Ruminski and Maciej Szankin and Mariusz Kaczmarek},
  doi          = {10.1016/j.engappai.2019.103263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Super-resolved thermal imagery for high-accuracy facial areas detection and analysis},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FierClass: A multi-signal, cepstrum-based, time series
classifier. <em>EAAI</em>, <em>87</em>, 103262. (<a
href="https://doi.org/10.1016/j.engappai.2019.103262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of learning behaviors of dynamical systems heavily involves time series analysis. Most often, to set up a classification problem, the analysis in time is seen as the main and most natural option. In general, working in the time domain entails a manual, time-consuming phase dealing with signal processing, features engineering and selection processes. Extracted features may also lead to a final result that is heavily dependent of subjective choices, making it hard to state whether the current solution is optimal under any perspective. In this work, leveraging a recent proposal to use the cepstrum as a frequency-based learning framework for time series analysis, we show how such an approach can handle classification with multiple input signals, combining them to yield very accurate results. Notably, the approach makes the whole design flow automatic, freeing it from the cumbersome and subjective step of handcrafting and selecting the most effective features. The method is validated on experimental data addressing the automatic classification of whether a car driver is using the smartphone while driving.},
  archive      = {J_EAAI},
  author       = {S. Gelmini and S. Formentin and S. Strada and M. Tanelli and S. Savaresi},
  doi          = {10.1016/j.engappai.2019.103262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FierClass: A multi-signal, cepstrum-based, time series classifier},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some q-rung orthopair fuzzy hamacher aggregation operators
and their application to multiple attribute group decision making with
modified EDAS method. <em>EAAI</em>, <em>87</em>, 103259. (<a
href="https://doi.org/10.1016/j.engappai.2019.103259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To provide a larger space for decision makers, q-rung orthopair fuzzy sets (q-ROFS) can express their uncertain information. As a generalization of the algebraic operations, and the Einstein t-conorm and t-norm, Hamacher operations have become significant in aggregation theory. In order to accurately integrate the input arguments of decision makers, the relation pattern between the arguments must be considered. In this paper, we analyze both the independent and interdependent relationship that exist between the input arguments based on the arithmetic mean and the Maclaurin symmetric mean (MSM) respectively. To be specific, we develop some new Hamacher operations for q-ROFS. In light of these operational laws, we further propose some q-rung orthopair fuzzy Hamacher aggregation operators, i.e., the q-rung orthopair fuzzy Hamacher average (q-ROFHA) operator, the weighted q-rung orthopair fuzzy Hamacher average (Wq-ROFHA) operator, the q-rung orthopair fuzzy Hamacher Maclaurin symmetric mean (q-ROFHMSM) operator and the weighted q-rung orthopair fuzzy Hamacher Maclaurin symmetric mean (Wq-ROFHMSM) operator. Meanwhile, some special cases and properties are examined. To solve q-rung orthopair fuzzy multiple attribute group decision making (q-ROFMAGDM) problems, we design a novel approach according to the Evaluation Based on Distance from Average Solution (EDAS) method. At the same time, with the aid of the best-worst method (BWM), we propose a new way to determine the attribute weight information. With respect to a mobile payment platform selection problem, we test the robustness and reliability of our proposed methodology.},
  archive      = {J_EAAI},
  author       = {Adjei Peter Darko and Decui Liang},
  doi          = {10.1016/j.engappai.2019.103259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Some q-rung orthopair fuzzy hamacher aggregation operators and their application to multiple attribute group decision making with modified EDAS method},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy efficient multi-objective scheduling of tasks with
interval type-2 fuzzy timing constraints in an industry 4.0 ecosystem.
<em>EAAI</em>, <em>87</em>, 103257. (<a
href="https://doi.org/10.1016/j.engappai.2019.103257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial systems usually draw huge energy to run various machines. The amount of energy requirement has again increased due to the automation of the industrial plants to make them Industry 4.0 compliant. As a result, demand of energy is on the rise in almost all manufacturing and industrial plants. The necessity of critical and smart manufacturing processes in Industry 4.0 and its increased energy requirements force us to look for energy efficient techniques for running the deployed computing systems, which are often embedded and integrated within larger machines and have to function under time constraints. Computational efficiency of these real-time embedded systems (RTESs) depends solely on the timely completion of tasks. Task execution with less energy consumption within critical timing constraints is a challenging issue for the designers of RTESs. Thus, task scheduling in these systems require sophisticated energy efficient mechanisms. However, energy efficiency and timeliness are two mutually contradictory objectives, since the former is achieved only with a significant compromise of the later. In this paper, we propose a novel approach, based on the popular multi-objective evolutionary algorithm, Non-dominated sorting genetic algorithm-II, to solve this problem. Moreover, in RTESs, precise prediction of timing constraints is difficult before runtime which causes a form of imprecision or uncertainty in the system. Therefore, we use type-2 fuzzy sets (T2 FSs) to model the timing constraints in RTESs and introduce novel algorithms for membership function generation and calculation of fuzzy earliness. Numerical as well as real-life examples are included to demonstrate our proposed technique.},
  archive      = {J_EAAI},
  author       = {Amit K. Shukla and Rahul Nath and Pranab K. Muhuri and Q.M. Danish Lohani},
  doi          = {10.1016/j.engappai.2019.103257},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103257},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy efficient multi-objective scheduling of tasks with interval type-2 fuzzy timing constraints in an industry 4.0 ecosystem},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Therapy-driven deep glucose forecasting. <em>EAAI</em>,
<em>87</em>, 103255. (<a
href="https://doi.org/10.1016/j.engappai.2019.103255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic regulation of blood glucose for Type 1 diabetes patients is the main goal of the artificial pancreas, a closed-loop system that exploits continue glucose monitoring data to define an optimal insulin therapy. One of the most successful approaches for developing the artificial pancreas is the model predictive control, which exhibits promising results on both virtual and real patients. The performance of such controller is highly dependent on the reliability of the glucose–insulin model used for prediction purpose, which is usually implemented with classic mathematical models. The main limitation of these models consists in the difficulties of modeling the physiological nonlinear dynamics typical of this system. The availability of big amount of in silico and in vivo data moved the attention to new data-driven methods which are able to easily overcome this problem. In this paper we propose Deep Glucose Forecasting, a deep learning approach for forecasting glucose levels, based on a novel, two-headed Long-Short Term Memory implementation. It takes in input the previous values obtained through continue glucose monitoring, the carbohydrate intake, the suggested insulin therapy and forecasts the interstitial glucose level of the patient. The proposed architecture has been trained on 100 virtual adult patients of the UVA/Padova simulator, and tested on both virtual and real patients. The proposed solution is able to generalize to new unseen data, outperforms classical population models and reaches performance comparable to classical personalized models when fine-tuning is exploited on real patients.},
  archive      = {J_EAAI},
  author       = {Eleonora Maria Aiello and Giuseppe Lisanti and Lalo Magni and Mirto Musci and Chiara Toffanin},
  doi          = {10.1016/j.engappai.2019.103255},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103255},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Therapy-driven deep glucose forecasting},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A size-transferring radial basis function network for
aero-engine thrust estimation. <em>EAAI</em>, <em>87</em>, 103253. (<a
href="https://doi.org/10.1016/j.engappai.2019.103253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thrust regulation plays an important role in the aero-engine control. However, the thrust is unmeasurable in flight which poses a great challenge to the thrust control. Traditional thrust control methods are implemented by controlling the parameters tightly related to thrust and reserve enough safety margins to protect the engine. To realize the direct thrust control, the methods to estimate thrust is urgently required. In this paper, a new algorithm based on particle swarm optimization (PSO) and radial basis function neural network (RBFNN) is proposed to estimate the thrust. A strategy named “size-transferring” is developed to select and adjust the network size of the RBFNN. Besides, to solve the high-dimensional optimization problem during the estimation, a new approach based on the PSO algorithm is also illustrated. The successful application of the proposed algorithm to the aero-engine thrust estimation problem demonstrates its effectiveness.},
  archive      = {J_EAAI},
  author       = {Yong-Ping Zhao and Zhi-Qiang Li and Qian-Kun Hu},
  doi          = {10.1016/j.engappai.2019.103253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A size-transferring radial basis function network for aero-engine thrust estimation},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A polynomial-fuzzy-model-based synchronization methodology
for the multi-scroll chen chaotic secure communication system.
<em>EAAI</em>, <em>87</em>, 103251. (<a
href="https://doi.org/10.1016/j.engappai.2019.103251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a polynomial-fuzzy-model-based design methodology to synchronize multi-scroll Chen chaotic systems is proposed for secure communication. At first, the architecture of secure communication system (SCS) based on the synchronization of multi-scroll Chen chaotic systems is presented. Then, the master and slave multi-scroll Chen chaotic systems are transformed into the equivalent master and slave polynomial fuzzy models respectively. After that, the H ∞ polynomial fuzzy control design is proposed for synchronizing the master and slave multi-scroll Chen chaotic systems as well as restraining external disturbances. Moreover, for practical application, a constraint on the control input is also considered. The H ∞ polynomial fuzzy control design is represented in terms of sum-of-squares (SOS) conditions which can be efficiently solved by the polynomial optimization Matlab toolbox SOSOPT. Furthermore, simulation results show the effectiveness of the proposed polynomial-fuzzy-model-based control design methodology. After the control design, the polynomial-fuzzy-model-based chaotic synchronization methodology is applied to implement the SCS. Finally, three experiments are given to demonstrate the practicality of the implemented SCS.},
  archive      = {J_EAAI},
  author       = {Ying-Jen Chen and Hao-Gong Chou and Wen-June Wang and Shun-Hung Tsai and Kazuo Tanaka and Hua O. Wang and Kun-Ching Wang},
  doi          = {10.1016/j.engappai.2019.103251},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103251},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A polynomial-fuzzy-model-based synchronization methodology for the multi-scroll chen chaotic secure communication system},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Black widow optimization algorithm: A novel meta-heuristic
approach for solving engineering optimization problems. <em>EAAI</em>,
<em>87</em>, 103249. (<a
href="https://doi.org/10.1016/j.engappai.2019.103249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired optimization algorithms can solve different engineering and scientific problems owing to their easiness and flexibility. There is no need for structural modifications of optimization problems to apply meta-heuristic algorithms on them. Recently, meta-heuristic algorithms are becoming powerful methods for solving NP problems. In this paper, the authors propose a novel meta-heuristic algorithm suitable for continuous nonlinear optimization problems. The proposed method, Black Widow Optimization Algorithm (BWO), is inspired by the unique mating behavior of black widow spiders. This method includes an exclusive stage, namely, cannibalism. Due to this stage, species with inappropriate fitness are omitted from the circle, thus leading to early convergence. BWO algorithm is evaluated on 51 various benchmark functions to verify its efficiency in obtaining the optimal solutions for the problems. The obtained results indicate that the proposed algorithm has numerous advantages in different aspects such as early convergence and achieving optimized fitness value compared to other algorithms. Also, it has the capability of providing competitive and promising results. The research also solves three different challenging engineering design problems adopting BWO algorithm. The outcomes of the real case study problems prove the effectiveness of the proposed algorithm in solving real-world issues with unknown and challenging spaces.},
  archive      = {J_EAAI},
  author       = {Vahideh Hayyolalam and Ali Asghar Pourhaji Kazem},
  doi          = {10.1016/j.engappai.2019.103249},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103249},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Black widow optimization algorithm: A novel meta-heuristic approach for solving engineering optimization problems},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating the 2-tuple linguistic representation and soft
set to solve supplier selection problems with incomplete information.
<em>EAAI</em>, <em>87</em>, 103248. (<a
href="https://doi.org/10.1016/j.engappai.2019.103248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the information age, choosing suitable suppliers has become an important issue in supply chain management. Selection of the optimal supplier will ensure the competitiveness and customer satisfaction of the overall supply chain. However, assessment attribute values are sometimes missing or nonexistent in supplier selection. Moreover, experts often fail to confirm the rating values of assessment attributes, hesitating between linguistic term sets. Conversely, because experts have disparate expertise, experience, and backgrounds, they will use different linguistic term sets to evaluate the rating values of assessment attributes. These issues complicate supplier selection. To overcome these hurdles, this paper integrates the 2-tuple linguistic representation and soft set to solve supplier selection problems with incomplete information. To illustrate the application of the proposed approach, a real-life example of the selection of key anesthetic equipment is adopted. This paper also compares the results of this simulation with those of the arithmetic average, fuzzy VIKOR, and interval 2-tuple linguistic VIKOR methods. The proposed approach is more suitable and more accurate in solving supplier selection problems with uncertain and incomplete information.},
  archive      = {J_EAAI},
  author       = {Ta-Chun Wen and Kuei-Hu Chang and Hsin-Hung Lai},
  doi          = {10.1016/j.engappai.2019.103248},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103248},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating the 2-tuple linguistic representation and soft set to solve supplier selection problems with incomplete information},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study on leading machine learning techniques for high
order fuzzy time series forecasting. <em>EAAI</em>, <em>87</em>, 103245.
(<a href="https://doi.org/10.1016/j.engappai.2019.103245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy time series forecasting (FTSF) methods avoid the basic assumptions of traditional time series forecasting (TSF) methods. The FTSF methods consist of four stages namely determination of effective length of interval, fuzzification of crisp time series data, modeling of fuzzy logical relationships (FLRs) and defuzzification. All the four stages play a vital role in achieving better forecasting accuracy. This paper addresses two key issues such as modeling FLRs and determination of effective length of interval. Three leading machine learning (ML) techniques, namely deep belief network (DBN), long short-term memory (LSTM) and support vector machine (SVM) are first time used for modeling the FLRs. Additionally, a modified average-based method is proposed to estimate the effective length of interval. The proposed FTSF-DBN, FTSF-LSTM and FTSF-SVM methods are being compared with three papers from the literature along with four crisp TSF methods using multilayer perceptron (MLP), LSTM, DBN and SVM. A total of fourteen time series datasets (Sun Spot, Lynx, Mumps and 11 TAIEX time series datasets i.e. 2000–2010) are considered for comparative performance analysis. Results revealed the statistical superiority of FTSF-SVM method and proposed improved average-based method based on the popular Friedman and Nemenyi hypothesis test. It is also observed that the proposed FTSF methods provide statistical superior performance than their crisp TSF counterparts.},
  archive      = {J_EAAI},
  author       = {Sibarama Panigrahi and H.S. Behera},
  doi          = {10.1016/j.engappai.2019.103245},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103245},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on leading machine learning techniques for high order fuzzy time series forecasting},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-agent architecture for information retrieval and
intelligent monitoring by UAVs in known environments affected by
catastrophes. <em>EAAI</em>, <em>87</em>, 103243. (<a
href="https://doi.org/10.1016/j.engappai.2019.103243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consequences of natural or man-made catastrophes can be devastating. To minimize its impact, it is crucial to carry out a rapid analysis of the affected environment in the moments after they occur, especially from the perspective of alert notification or crisis management. In this context, the use of UAVs, understood as the technological basis on which intelligent systems capable of providing support to rescue teams is built, has positively contributed to face this challenge. In this article the design of a multi-agent architecture which enables the deployment of systems made up of intelligent agents that can monitor environments affected by a catastrophe and provide support to human staff in the decision-making process is proposed. These environments, known in advance, are characterized through a set of points of interests that are critical from the point of view of aerial surveillance and monitoring. To conduct an intelligent information analysis, a formal model of normality analysis is employed, which makes possible the definition of surveillance components. These represent the knowledge bases of the agents responsible for monitoring environments. Likewise, the architecture envisages communication and cooperation mechanisms between the different agents, as the basis for fusing information to assess the overall level of risk of the monitored environment. A case study is presented in which the spread of toxic smoke in an industrial complex which has just suffered a hypothetical earthquake is monitored.},
  archive      = {J_EAAI},
  author       = {D. Vallejo and J.J. Castro-Schez and C. Glez-Morcillo and J. Albusac},
  doi          = {10.1016/j.engappai.2019.103243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent architecture for information retrieval and intelligent monitoring by UAVs in known environments affected by catastrophes},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An agent-based model for plausible wayfinding in pedestrian
simulation. <em>EAAI</em>, <em>87</em>, 103241. (<a
href="https://doi.org/10.1016/j.engappai.2019.103241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling pedestrian decision making activities represents a serious challenge: different decisions are taken at distinct levels of abstraction, employing heterogeneous information and knowledge about the environment, from path planning to the regulation of distance from other pedestrians and obstacles present in the environment. Pedestrians, moreover, are not robots: although empirical observations show that they consider congestion when planning, there are also evidences that their decisions are not always optimal, even in normal situations. We present a model integrating and improving consolidated results mitigating the optimization effects of congestion aware path planning. In particular, we employ commonsense estimations of the effects of perceivable congestion instead of exact values, also embedding an imitation mechanism stimulating changes in planned decisions whenever another nearby pedestrian did the same. The model leads to improvements in quantitatively reproducing observed phenomena, both in a validation scenario as well as in a real-world situation: an interesting counterintuitive result, in which reducing available choices and exits actually reduces overall egress time, is also presented and discussed.},
  archive      = {J_EAAI},
  author       = {Giuseppe Vizzari and Luca Crociani and Stefania Bandini},
  doi          = {10.1016/j.engappai.2019.103241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An agent-based model for plausible wayfinding in pedestrian simulation},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective great deluge algorithm with two-stage archive
support. <em>EAAI</em>, <em>87</em>, 103239. (<a
href="https://doi.org/10.1016/j.engappai.2019.103239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A multiobjective great deluge algorithm with a two-stage external memory support and associated search operators exploiting the experience accumulated in memory are introduced. The level based acceptance criterion of the great deluge algorithm is implemented based on the dominance of a new solution against its parent and archive elements. The novel two-stage memory architecture and the use of dominance-based level approach make it possible to exploit promising solutions that both lie on better Pareto fronts in objective space and that are diversely separated in variable space. In this respect, the first stage of the external memory is managed as a short-term archive that is updated frequently when a solution that dominates its parent or some individuals over the current Pareto front is extracted whereas the second stage is organized as a long-term memory that is updated only after a number of first stage insertions. The use of memory-based search supported by effective move operators and dominance-based implementation of level mechanism within the great deluge algorithm resulted in a powerful multiobjective optimization method. The success of the presented approach is illustrated using unconstrained (bound constrained) multiobjective test instances used in the CEC’09 contest of multiobjective optimization algorithms. Using the evaluation framework described in CEC’09 contest and in comparison to published results of well-known modern algorithms, it is observed that the presented approach performs better than majority of its competitors and is a powerful alternative for multiobjective optimization.},
  archive      = {J_EAAI},
  author       = {Adnan Acan and Ahmet Ünveren},
  doi          = {10.1016/j.engappai.2019.103239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiobjective great deluge algorithm with two-stage archive support},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel hybrid multi-objective evolutionary algorithm for
the bi-objective minimum diameter-cost spanning tree (bi-MDCST) problem.
<em>EAAI</em>, <em>87</em>, 103237. (<a
href="https://doi.org/10.1016/j.engappai.2019.103237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a connected, weighted, undirected graph G = (V, E), the bi-objective Minimum Diameter-Cost Spanning Tree (bi-MDCST) Problem aims to find spanning trees on G with minimal total edge weight as well as minimal diameter. The problem is known to be NP-hard and finds application in domains ranging from transportation to network design. An exact algorithm for the problem is given in the literature, but is computationally very expensive and hence applicable to only very small graphs; some fast heuristics, a multi-objective genetic algorithm (MOGA) and a fast non-dominated sorting genetic algorithm (NSGA2) have also been proposed in the literature for solving the problem and their performance studied on larger sized full graphs containing up to 250 vertices and 31,125 edges. This paper presents a novel Hybrid Multi-objective Evolutionary Algorithm (HMOEA) for the bi-MDCST problem which uses a representation that captures the genetic information of several spanning trees of varying diameters in a single chromosome, thereby enhancing the representational power of the population. The algorithm uses heuristic-based population seeding and combines linear time recombination with a fast mutation operator to more effectively balance the exploration and exploitation of the search space. The proposed HMOEA computes the optimal Pareto-front solutions in time that is several orders of magnitude lesser than that taken by the exact method, and is shown to obtain superior performance in terms of the convergence and distribution of solutions vis-à-vis the other two extant meta-heuristics on a wide range of benchmark graph instances. Results obtained by the HMOEA are also reported for larger sized Euclidean instances than attempted hitherto in the literature, containing up to 500 vertices and 124,750 edges, and for a benchmark suite of large fully connected random edge-weight graph instances introduced in this work for more effectively comparing the performance of algorithms for the bi-MDCST problem.},
  archive      = {J_EAAI},
  author       = {V. Prem Prakash and C. Patvardhan and Anand Srivastav},
  doi          = {10.1016/j.engappai.2019.103237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel hybrid multi-objective evolutionary algorithm for the bi-objective minimum diameter-cost spanning tree (bi-MDCST) problem},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complex object detection using deep proposal mechanism.
<em>EAAI</em>, <em>87</em>, 103234. (<a
href="https://doi.org/10.1016/j.engappai.2019.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex object detection is one of the most important and challenging problems in computer vision tasks. To provide a high-performance complex object detection method, a deep proposal mechanism (DPM) is proposed. (1) A region proposal strategy is used to localize potential objects in most top methods; however, this process also represents an intractable computational bottleneck. Therefore, to localize potential complex effectively, a region proposal mechanism (RPM) is proposed. The mechanism shares common features with ResNet and achieves excellent performance. (2) To solve the problem of insufficient amount of labeled training data, an efficient semisupervised pretraining method, instead of traditional unsupervised pretraining, is carried out. (3) To further improve the computational speed, a novel joint learning strategy is introduced. Extensive experiments are performed, and the results show that DPM achieves much better performance than state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Juan Tan},
  doi          = {10.1016/j.engappai.2019.09.003},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complex object detection using deep proposal mechanism},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding the k shortest paths by ripple-spreading algorithms.
<em>EAAI</em>, <em>87</em>, 103229. (<a
href="https://doi.org/10.1016/j.engappai.2019.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k shortest paths problem ( k -SPP) is fundamentally important to both theoretical and application researches on computational intelligence. Inspired by the natural ripple-spreading phenomenon that occurs on a water surface, this paper proposes a novel ripple-spreading algorithm (RSA). RSA differs from many existing methods which need to reconstruct route networks or to sweep the network for k times, and it can identify the k shortest paths by a single run of ripple relay race in the original route network. Besides the k -SPP in normal route networks, the RSA can also be extended, without losing optimality and effectiveness, to some time-window networks (where various waiting behaviors at nodes are introduced) and dynamical networks (where the network topology and link costs may change over time due to factors such as moving obstacles and spreading disasters). For one-to-all k -SPP, which aims to find all the k shortest paths from a given source to every other node in a network (no matter with or without time windows at nodes, and no matter whether the network topology and link costs can change over time or not), the RSA can still find out all required solutions using only a single run, while the computational complexity is exactly the same as that for the one-to-one k -SPP, i.e., O ( k × N L × N A T U ) , where N L is the number of links in the network, and N A T U is the average simulated time units for a ripple to travel through a link. The comparative experimental results illustrate the effectiveness and efficiency of the proposed RSA.},
  archive      = {J_EAAI},
  author       = {Xiao-Bing Hu and Chi Zhang and Gong-Peng Zhang and Ming-Kong Zhang and Hang Li and Mark S. Leeson and Jian-Qin Liao},
  doi          = {10.1016/j.engappai.2019.08.023},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103229},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Finding the k shortest paths by ripple-spreading algorithms},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using fuzzy measures for modeling human perception of
uncertainty in artificial intelligence. <em>EAAI</em>, <em>87</em>,
103228. (<a
href="https://doi.org/10.1016/j.engappai.2019.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We observe the importance of modeling human perceptions of various types of information for the construction of A. I. systems and highlight the need for modeling human perceptions of uncertainty. We introduce the concept of a fuzzy measure, μ , and discuss its use as a general structure for the representation of knowledge about an uncertain variable. We note the ability of the fuzzy measure to model various formulations of uncertain information in a unified format. We look at various properties of fuzzy, particularly the ability to fuse multiple fuzzy measures to form new measures. We introduce various operations on fuzzy measures motivated from probability theory such as the determination of expected values and variances. We emphasize the importance of the Choquet integral in these operations. We discuss two characterizing features of a fuzzy measure, its entropy and attitudinal character, and note their usefulness in helping select an appropriate measure. We finally look at the issue of answering questions about variables having information about its value modeled by a fuzzy measure. Here we must come to grips with the fact that for most measures a fundamental property of the probability measure, Prob(A) + Prob( A ¯ ) = 1, does not hold.},
  archive      = {J_EAAI},
  author       = {Ronald R. Yager},
  doi          = {10.1016/j.engappai.2019.08.022},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103228},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using fuzzy measures for modeling human perception of uncertainty in artificial intelligence},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combined weightless neural network FPGA architecture for
deforestation surveillance and visual navigation of UAVs. <em>EAAI</em>,
<em>87</em>, 103227. (<a
href="https://doi.org/10.1016/j.engappai.2019.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a combined weightless neural network architecture for deforestation surveillance and visual navigation of Unmanned Aerial Vehicles (UAVs). Binary images, which are required for position estimation and UAV navigation, are provided by the deforestation surveillance circuit. Learned models are evaluated in a real UAV flight over a green countryside area, while deforestation surveillance is assessed with an Amazon forest benchmarking image data. Small utilization percentage of Field Programmable Gate Arrays (FPGAs) allows for a higher degree of parallelization and block processing of larger regions of input images.},
  archive      = {J_EAAI},
  author       = {Vitor A.M.F. Torres and Brayan R.A. Jaimes and Eduardo S. Ribeiro and Mateus T. Braga and Elcio H. Shiguemori and Haroldo F.C. Velho and Luiz C.B. Torres and Antonio P. Braga},
  doi          = {10.1016/j.engappai.2019.08.021},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {103227},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Combined weightless neural network FPGA architecture for deforestation surveillance and visual navigation of UAVs},
  volume       = {87},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
