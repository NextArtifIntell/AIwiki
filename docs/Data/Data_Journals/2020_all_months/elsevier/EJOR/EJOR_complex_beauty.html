<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EJOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ejor---643">EJOR - 643</h2>
<ul>
<li><details>
<summary>
(2020). Identifying production units with outstanding performance.
<em>EJOR</em>, <em>287</em>(3), 1191–1194. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications of data envelopment analysis, there are situations in which a central body manages a large set of similar units delivering some services. In such multi-unit organizations, the central management desires a mechanism by which the local management of each unit is incentivized to perform towards the improvement of the performance of the organization as a whole. In a recent paper, Afsharian et al. (2017) have proposed a system of incentives under these circumstances. In their approach, – which relies on the original concept of super-efficiency – units with outstanding performance are identified and incentivized by some reward compatible with the level of their impact on the overall performance of the organization. We discuss why the conventional super-efficiency approach may not be optimal in such situations. We revisit the definition of the collective impact and propose a new method, which can identify – in a controlled manner – a subset of k outstanding DMUs among n existing units in the system. The proposed approach is illustrated using data from a German retail bank.},
  archive      = {J_EJOR},
  author       = {Mohsen Afsharian and Peter Bogetoft},
  doi          = {10.1016/j.ejor.2020.04.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1191-1194},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying production units with outstanding performance},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revenge or continued attack and defense in defender–attacker
conflicts. <em>EJOR</em>, <em>287</em>(3), 1180–1190. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing literature has demonstrated that exacting revenge can have a self-deterrence effect and a value of revenge effect. The former means that each player will decrease effort when competing for a resource because of fear of a rival’s revenge while the latter implies that each player will increase effort in the revenge period. Moreover, the self-deterrence effect could outweigh the value of revenge effect, implying that revenge could be helpful in stabilizing conflicts, a phenomenon known as the paradox of revenge. We re-examine the two effects and the paradox of revenge in defender–attacker conflicts, considering a scenario in which a defender (and only the defender) who was attacked in the first period takes revenge on the attacker in the subsequent period. We demonstrate that whether or not these results hold, depends on how much the defender values revenge and the difference between the two players’ efficiencies of effort. More interestingly, we show that a sufficiently large revenge value for the defender can deter an attack from the attacker in the first place.},
  archive      = {J_EJOR},
  author       = {Liang Liang and Jingxian Chen and Kevin Siqueira},
  doi          = {10.1016/j.ejor.2020.05.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1180-1190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Revenge or continued attack and defense in defender–attacker conflicts},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic by-production framework for analyzing inefficiency
associated with corporate social responsibility. <em>EJOR</em>,
<em>287</em>(3), 1170–1179. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article integrates corporate social responsibility (CSR) into a dynamic by-production framework and examines the factors associated with CSR performance. The application focuses on panel data of European food and beverage firms over the period 2013-2017. The results show that material input, labour input and undesirable output can be contacted by 11.3\%, 12.0\% and 10.4\% respectively while marketable output can be expanded by 66.35\%, socially responsible output by 4.3\% and the potential of doing investment by 25.46\% of the value of the capital stock. Higher CSR performance was associated with a larger firm size, and a higher R&amp;D intensity. Furthermore, firms in network-oriented systems (Germanic or Latin) tend to have a better corporate social responsibility performance than firms in market oriented systems (Anglo-Saxon).},
  archive      = {J_EJOR},
  author       = {Tadesse Getacher Engida and Xudong Rao and Alfons G.J.M. Oude Lansink},
  doi          = {10.1016/j.ejor.2020.05.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1170-1179},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic by-production framework for analyzing inefficiency associated with corporate social responsibility},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fuzzy self-tuning differential evolution for optimal product
line design. <em>EJOR</em>, <em>287</em>(3), 1161–1169. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing a successful product line is a critical decision for a firm to stay competitive. By offering a line of products, the manufacturer can maximize profits or market share through satisfying more consumers than a single product would. The optimal Product Line Design (PLD) problem is classified as NP-hard. This paper proposes a Fuzzy Self-Tuning Differential Evolution (FSTDE) for PLD, which exploits Fuzzy Logic to automatically calculate the parameters independently for each solution during the optimization, thus resulting to a settings-free version of DE. The proposed method is compared to the most successful mutation strategies of the algorithm as well as previous approaches to the PLD problem, like Genetic Algorithm and Simulated Annealing, using both actual and artificial data of consumer preferences. The comparison results demonstrate that FSTDE is an attractive alternative approach to the PLD problem.},
  archive      = {J_EJOR},
  author       = {Stelios Tsafarakis and Konstantinos Zervoudakis and Andreas Andronikidis and Efthymios Altsitsiadis},
  doi          = {10.1016/j.ejor.2020.05.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1161-1169},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fuzzy self-tuning differential evolution for optimal product line design},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint pricing and matching in ride-sharing systems.
<em>EJOR</em>, <em>287</em>(3), 1149–1160. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ride-sharing firms use pricing and matching decisions to control the ride-sharing platforms. Those decisions can be made jointly or interchangeably, which raises the following questions: Is matching optimization necessary? Specifically, is fixing the matching decisions to a simple rule and optimizing only the pricing decisions enough to achieve the optimal performance? In order to answer these questions, we study the interplay between pricing and matching decisions of a ride-sharing firm. There are many studies in the ride-sharing literature that optimize the pricing decisions under an assumed matching policy. However, we show that ignoring matching optimization can result in subpar overall performance. We formulate a stylized ride-sharing model that captures customer and driver behaviors and geospatial nature of the system. Customers are both price and delay sensitive, and drivers are strategic and self-scheduling. We prove that optimizing the matching decisions have first-order effect on the system performance. We show that fixing the matching decisions and optimizing only the pricing decisions does not maximize the number of matchings in general. Similarly, we show that fixing the pricing decisions and optimizing only the matching decisions is not optimal in general. Finally, we show that optimizing in only one dimension (either pricing or matching) has no benefit to the firm under some conditions, whereas joint pricing and matching optimization can lead to a significant performance increase.},
  archive      = {J_EJOR},
  author       = {Erhun Özkan},
  doi          = {10.1016/j.ejor.2020.05.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1149-1160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Joint pricing and matching in ride-sharing systems},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel evolution and response decision method for public
sentiment based on system dynamics. <em>EJOR</em>, <em>287</em>(3),
1131–1148. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Governments face difficulties in policy making in many areas such as health, food safety, and large-scale projects where public perceptions can be misplaced. For example, the adoption of the MMR vaccine has been opposed due to the publicity indicating an erroneous link between the vaccine and autism. This research proposes the “Parallel Evolution and Response Decision Framework for Public Sentiments” as a real-time decision-making method to simulate and control the public sentiment evolution mechanisms. This framework is based on the theories of Parallel Control and Management (PCM) and System Dynamics (SD) and includes four iterative steps: namely, SD modelling, simulating, optimizing, and controlling. A concrete case of an anti-nuclear mass incident that sparked public sentiment in China is introduced as a study sample to test the effectiveness of the proposed method. In addition, the results indicate the effects by adjusting the key control variables of response strategies. These variables include response time, response capacity, and transparency of the government regarding public sentiment. Furthermore, the advantages and disadvantages of the proposed method will be analyzed to determine how it can be used by policy makers in predicting public opinion and offering effective response strategies.},
  archive      = {J_EJOR},
  author       = {Xie Tian and Wei Yao-yao and Chen Wei-fan and Huang Hai-nan},
  doi          = {10.1016/j.ejor.2020.05.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1131-1148},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Parallel evolution and response decision method for public sentiment based on system dynamics},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-objective districting problem applied to
agricultural machinery maintenance service network. <em>EJOR</em>,
<em>287</em>(3), 1120–1130. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prompt and reliable response to malfunctioning agricultural machinery of a maintenance service network is extremely critical for the safety and stability of agricultural production during the harvest. This research aims to cluster a set of given agricultural production areas into a specified number of service regions while assigning a service facility to maintenance demands in each region. The service region districting problem is formulated as a multi-objective mixed integer program (MIP) that seeks to minimize the total service mileage between facilities and demand points while minimizing the service demand overload in each service region. Additionally, we use modified contiguity constraints to enforce a single service region as geographically connected, which means that one can travel between any two locations in the region without leaving it. To solve our multi-objective MIP problem, the ɛ-constraint method is used to develop a set of non-inferior solutions that allow us to examine the trade-off between minimizing service mileage and minimizing demand overload and offer us a set of Pareto optimal decisions to consider for implementation. Lastly, our model and methodology are illustrated in handling a real-world problem in China. Computational results are presented that analyze the trade-off between objectives, examine the impact of selected parameters and demonstrate the advantage of implementing the modified contiguity constraints.},
  archive      = {J_EJOR},
  author       = {Jialin Han and Yaoguang Hu and Mingsong Mao and Shuping Wan},
  doi          = {10.1016/j.ejor.2020.05.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1120-1130},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective districting problem applied to agricultural machinery maintenance service network},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Market-based coordination of integrated electricity and
natural gas systems under uncertain supply. <em>EJOR</em>,
<em>287</em>(3), 1105–1119. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interdependence between electricity and natural gas systems has lately increased due to the wide deployment of gas-fired power plants (GFPPs). Moreover, weather-driven renewables introduce uncertainty in the operation of the integrated energy system, increasing the need for operational flexibility. Recently proposed stochastic dispatch models optimally use the available flexibility and minimize the total expected system cost. However, these models are incompatible with the current sequential market design. We propose a novel method to optimally define the available natural gas volume for power production scheduling, anticipating the real-time flexibility needs. This volume-based model is formulated as a stochastic bilevel program that aims to enhance the inter-temporal coordination of scheduling and balancing operations, while remaining compatible with the sequential clearing of day-ahead and real-time markets. The proposed model accounts for the inherent flexibility of the natural gas system via the proper modeling of linepack capabilities and reduces the total expected system cost by the optimal definition of natural gas volume availability for GFPPs at the forward phase. The volume-based coordination model is compared with a price-based coordination alternative, which was recently proposed. In the latter one, the natural gas price perceived by GFPPs is similarly adjusted to enhance the temporal coordination of scheduling and balancing stages. This comparison enables us to highlight the main properties and differences between the two coordination mechanisms.},
  archive      = {J_EJOR},
  author       = {Christos Ordoudis and Stefanos Delikaraoglou and Jalal Kazempour and Pierre Pinson},
  doi          = {10.1016/j.ejor.2020.05.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1105-1119},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Market-based coordination of integrated electricity and natural gas systems under uncertain supply},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of risk aversion on the optimal project resource
rate. <em>EJOR</em>, <em>287</em>(3), 1092–1104. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under resourcing a project increases the probability of a time overrun. Consequently, project contracts should be designed to encourage an appropriate allocation of resources to the project. A common way to encourage timely completion is to use contracts with time penalties and incentives linked to the completion time. If there are a number of competing contractors, then the project manager can employ a take it or leave it approach in designing the contract. However, where there are very few possible contractors, then a bargaining approach is more appropriate for the contract&#39;s construction. Therefore, this paper investigates how close the resource rate stemming from the Nash bargaining contract is to the optimal rate. Risk neutral and risk averse project managers and contractors are considered. It is found that when the contractor is risk neutral, the chosen resource rate is independent of the project completion time distribution no matter whether the project manager is risk neutral or risk averse, and it coincides with the optimal, i.e. centrally coordinated, rate. When the contractor is risk averse, the resource rate is dependent on the project completion time distribution. However, the results indicate that if the contractor is less risk averse than the project manager, then the resource rate is approximately the optimal one. Hence a time based contract designed using Nash bargaining is particularly suitable when the number of possible contractors is small and they are large enough with regard to the project size to be less risk averse than the project manager.},
  archive      = {J_EJOR},
  author       = {Niladri Palit and Andrew Brint},
  doi          = {10.1016/j.ejor.2020.05.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1092-1104},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of risk aversion on the optimal project resource rate},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Planning station capacity and fleet size of one-way electric
carsharing systems with continuous state of charge functions.
<em>EJOR</em>, <em>287</em>(3), 1075–1091. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method for determining the deployment of one-way electric carsharing services within a designated region that maximizes the total profit of the operator. A mixed integer non-linear program model is built, with a strategic planning level that decides the fleet size and the station capacity and an operational level that decides on the required relocation operations. The state of charge (SOC) of the vehicles parked in one station is assumed to follow a continuous distribution. A rolling horizon method is used to optimize the operational decisions over the course of a day, considering demand fluctuations and the limited battery capacity of the vehicles. A golden section line search method and a shadow price algorithm are developed to optimize the fleet size and station capacity, with the results feeding back to the carsharing operations. To demonstrate the applicability of the formulated models and solution algorithms, a large-scale case study is conducted for Suzhou Industrial Park, China as the region of operation. A two-step verification method that combines an optimization model via tracking of individual vehicle SOC and a discrete event simulation, demonstrates the accuracy of the SOC distribution model. Managerial insights from the application are also presented.},
  archive      = {J_EJOR},
  author       = {Kai Huang and Kun An and Gonçalo Homem de Almeida Correia},
  doi          = {10.1016/j.ejor.2020.05.001},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1075-1091},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Planning station capacity and fleet size of one-way electric carsharing systems with continuous state of charge functions},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The pallet loading problem: Three-dimensional bin packing
with practical constraints. <em>EJOR</em>, <em>287</em>(3), 1062–1074.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pallet loading requires the solution of a three-dimensional bin packing problem (3DBPP) with additional requirements. In particular, vertical support and load bearing, which are not enforced in 3DBPP, are essential in practice. In this work, we provide a complete solution approach for pallet loading problems where practical constraints of vertical support, load bearing, planogram sequencing, and weight limits are fully accounted for. Using a layer based column generation approach, we tackle vertical support using second order cone programming, and satisfy load bearing through a graph representation to trace load distribution. Additionally, we use industry data to propose an instance generator that produces realistic items with practical attributes such as support surface, load capacity, weight, and planogram sequence number. Extensive numerical testing reveals the ability of the approach to find high quality solutions for industry size instances in fast computational times.},
  archive      = {J_EJOR},
  author       = {Fatma Gzara and Samir Elhedhli and Burak C. Yildiz},
  doi          = {10.1016/j.ejor.2020.04.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1062-1074},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The pallet loading problem: Three-dimensional bin packing with practical constraints},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Job allocation and profits in service production.
<em>EJOR</em>, <em>287</em>(3), 1052–1061. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a decision situation in which a buyer&#39;s non-recurring allocation of two heterogeneous and independent service jobs to three different types of suppliers – two specialists and one generalist – depends on different profits (payments) of the parties (players) involved. The decision situation is modelled as a non-cooperative game with simultaneous one-shot moves. The optimal decisions assigning and accepting the jobs are derived by determining Nash-equilibria in pure and mixed strategies. In our approach, for the first time, the payments of the players are explicitly specified by quantities of production, costs, and sales. In addition, the necessary conditions for the existence of Nash-equilibria in mixed strategies for this case of service production are analysed. Strategic effects may become evident, since the probability of choosing an action by a player depends on the expected values of the outcome for the opponents’ strategies. In contrast to existing literature, we show under common assumptions made about the payment quantities that Nash-equilibria allocate jobs to the specialists or to the generalist but never in a mixed way to a specialist and a generalist.},
  archive      = {J_EJOR},
  author       = {Günter Fandel and Jan Trockel},
  doi          = {10.1016/j.ejor.2020.03.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1052-1061},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Job allocation and profits in service production},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multistage stochastic programming approach for preventive
maintenance scheduling of GENCOs with natural gas contract.
<em>EJOR</em>, <em>287</em>(3), 1036–1051. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A preventive maintenance scheduling problem is studied on behalf of generation companies (GENCOs) with natural gas power plants, while taking into account their signed natural gas contracts and the opportunities of purchasing and selling natural gas in the spot market. This paper considers the uncertain prices of both natural gas and electricity in the spot market, and proposes a multistage stochastic mixed integer programming (MSMIP) model seeking the optimal operations regarding maintenance outage scheduling and natural gas trading. Large-scale MSMIP problems suffer not only the curse of dimensionality, but also computational difficulties with both discrete and continuous variables at each stage. To this respect, this paper leverages the progressive hedging algorithm based on scenario-based decomposition to solve large MSMIP problems. The solutions obtained from the algorithm exhibit promising quality under our numerical studies. Due to the independence among all the subproblems after the decomposition, the algorithm is amenable to parallel computing, which leads to faster convergence as demonstrated in the numerical results. Computational experiments also show that it is beneficial to use MSMIP while considering both maintenance planning and natural gas contracting. In addition, the results also indicate the GENCOs with a larger number of small generators perform better than those with a smaller number of big generators.},
  archive      = {J_EJOR},
  author       = {Zhouchun Huang and Qipeng Phil Zheng},
  doi          = {10.1016/j.ejor.2020.03.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1036-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multistage stochastic programming approach for preventive maintenance scheduling of GENCOs with natural gas contract},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constitutive rules for guiding the use of the viable system
model: Reflections on practice. <em>EJOR</em>, <em>287</em>(3),
1014–1035. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Viable System Model (VSM) provides a well-established framework to aid the design and diagnosis of organisations to survive and thrive in complex operating environments. However, the cognitive accessibility of the VSM presents a significant barrier to its application with non-expert stakeholders. In the face of such difficulties, VSM practitioners will often take steps to adapt the classic presentation of VSM to suit the needs of their particular operational context. We propose a set of constitutive rules, including an explicit epistemology, that can both account for the variety of VSM practice reported in the literature and also be used to guide practitioners in their application of the VSM and thus make rigorous use of VSM theory. The epistemology is expressed as a performative model, expressed as a Hierarchical Process Model (HPM), of the practitioner&#39;s use of the VSM in an engagement. We use this model to describe, reflect upon, and learn about VSM practice by the cross-case analysis of three recent VSM interventions. The combination of variability in problem structuring and specificity to the VSM afforded by the constitutive rules and the performative epistemology in combination has provided insight into the social ontology of VSM practice and the boundaries of what should be considered acceptable practice from a competence perspective. Our approach is intended to encourage wider and better application of VSM theory in preparing organisations to maintain performance in uncertain futures.},
  archive      = {J_EJOR},
  author       = {David Lowe and Angela Espinosa and Mike Yearworth},
  doi          = {10.1016/j.ejor.2020.05.030},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1014-1035},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constitutive rules for guiding the use of the viable system model: Reflections on practice},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Balancing fairness and efficiency: Performance evaluation
with disadvantaged units in non-homogeneous environments. <em>EJOR</em>,
<em>287</em>(3), 1003–1013. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing fairness and efficiency has become an emerging issue in today&#39;s society. In this paper we propose a balanced benchmarking methodology to address the fairness issue in performance evaluation. The methodology used to create performance measures is data envelopment analysis (DEA), a tool designed to evaluate the relative efficiencies of comparable decision-making units (DMUs); i.e. all DMUs use the same inputs and outputs and experience the same general operating conditions. In many applications, however, the DMUs may experience non-homogenous operating conditions or environments. An example might be a set of manufacturing plants where some have been upgraded and others not. Such settings can necessitate modifying the DEA structure such as to make allowance for different environmental conditions. Such a model is developed herein to create a level playing field for performance evaluation in two different settings: a setting involving hybrid and conventional (non-hybrid) vehicles; and another setting involving bank branches located in poverty and non-poverty regions. Our model and empirical tests contribute not only to the advance of balanced benchmarking methodologies, but also to the practice of incorporating fairness in performance evaluation across multiple products and organizations.},
  archive      = {J_EJOR},
  author       = {Chailin Chen and Wade D. Cook and Raha Imanirad and Joe Zhu},
  doi          = {10.1016/j.ejor.2020.05.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1003-1013},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Balancing fairness and efficiency: Performance evaluation with disadvantaged units in non-homogeneous environments},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stable recycling networks under the extended producer
responsibility. <em>EJOR</em>, <em>287</em>(3), 989–1002. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recently emerging concept, Extended Producer Responsibility (EPR), is being adopted by the government in more and more countries and regions. It shifts the burden of proper disposal of end-of-life consumer products from (local) governments to the producers that bring the products to the market. To comply with governments’ EPR-type legislation, producers form coalitions to have their products recycled in a more efficient way. In this paper, we study how two important determinants of recycling costs, fixed recycling costs and material-stream heterogeneity, influence producers’ recycling network (structure of producers’ recycling coalitions). On one hand, large fixed recycling costs make the coalitions typically larger, due to the economies of scale. On the other hand, large coalitions generate typically more heterogeneous material streams, which increase the variable recycling costs due to additional separation and disassembly efforts. This paper discusses two currently existing scenarios: one exists prior to EPR-type legislation (referred to as the Disparate Problem, or DP) and the other is motivated by EPR-type legislation (referred to as the Endogenous Problem, or EP). In DP, the recycling of end-of-life products is not the responsibility of any producer but the government. Therefore, the recycling network is determined to minimize the total recycling cost, which also maximizes the social welfare, while the outputs are determined by producers without concerns about recycling. In EP, producers who compete in a horizontally differentiated primary market may also collaborate at the same time to organize proper disposal of their products. As each producer is only interested in maximizing its own payoff and there may exist conflict of interests, we use the game-theoretical methodology to analyze the endogenous process of coalition-formation. We find structural differences in these two scenarios and conclude by discussing implications for social welfare of imposing tax or subsidy.},
  archive      = {J_EJOR},
  author       = {Fang Tian and Greys Sošić and Laurens Debo},
  doi          = {10.1016/j.ejor.2020.05.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {989-1002},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stable recycling networks under the extended producer responsibility},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic capacity allocation for group bookings in live
entertainment. <em>EJOR</em>, <em>287</em>(3), 975–988. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A persistent problem within live entertainment is lost revenue due to unsold seats. One reason behind this problem is that venues generally permit customers, of varying group size, to freely choose seats, and thus causing a sub-optimal seating allocation with sparsely stranded single seats. Due to the experiential attribute of live entertainment, ticket requests are predominantly groups wishing sets of contiguous seats. Consequently, the sparse single seats remain unsold. To solve this operational problem we analyze a capacity based revenue management control problem that explicitly accounts for group size and customer choice. We formulate the problem as a discrete-time Markov Decision Process with the objective to maximize total expected profit. Each period, and for a given arriving group size, the manager decides which price-differentiated segments to make available. Given the offered segments, customers select seats from a particular segment or choose not to purchase any. We discuss three selection models and provide algorithms to determine the optimal solution for each. Motivated by ad hoc provisions observed in practice and due to the curse of dimensionality we provide and analyze via simulation a heuristic. Finally, based on transactional sales data from a large annual North American sporting event we showcase how the model parameters can empirically be estimated.},
  archive      = {J_EJOR},
  author       = {K.D.S. Maclean and F. Ødegaard},
  doi          = {10.1016/j.ejor.2020.02.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {975-988},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic capacity allocation for group bookings in live entertainment},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient truncated repetitive lot inspection using poisson
defect counts and prior information. <em>EJOR</em>, <em>287</em>(3),
964–974. (<a href="https://doi.org/10.1016/j.ejor.2020.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal truncated repetitive sampling plans for inspecting lots of manufactured material using Poisson defect count data and prior information are obtained by minimizing the expected sampling effort. The proposed plans outperform the repetitive and single inspection schemes and they are shown to be better in reducing the number of sample units drawn from the lot. In truncated repetitive plans, the lots can be reinspected, at most, an optimal number of times when their acceptance or rejection cannot be concluded from the original inspection. Assuming a gamma prior model to describe the uncertainty about the unknown defect rate, a computational procedure is proposed to determine the truncated repetitive sampling plans with minimum expected sampling effort by solving integer nonlinear programming problems. The inclusion of lot reinspections, as well as previous information into the decision criteria, also provides the practitioners with a more precise evaluation of the expected producer’s and consumer’s risks. The results obtained illustrate that truncated repetitive plans with expected risks produce important savings in inspection time and cost with respect to conventional sampling schemes based on the classical requirements of quality levels and risks. An application concerning the manufacturing of glass is provided for illustrative purposes.},
  archive      = {J_EJOR},
  author       = {Carlos J. Pérez-González and Arturo J. Fernández and Akram Kohansal},
  doi          = {10.1016/j.ejor.2020.05.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {964-974},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient truncated repetitive lot inspection using poisson defect counts and prior information},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Front-office multitasking between service encounters and
back-office tasks. <em>EJOR</em>, <em>287</em>(3), 946–963. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model the work of a front-line service worker as a queueing system. The server interacts with customers in a multi-stage process with random durations. Some stages require an interaction between server and customer, while other stages are performed by the customer as a self-service task or with the help of another resource. Random arrivals by customers at the beginning and during an encounter create random lengths of idle time in the work of the server (breaks and interludes respectively). The server considers treatment of an infinite amount of back-office tasks, or tasks that do not require interaction with the customer, during these idle times. We consider an optimal control problem for the server’s work. The main question we explore is whether to use the interludes in service encounters for treating back-office, when the latter incur switching times. Under certain operating environments, working on back-office during interludes is shown to be valuable. Switching times play a critical role in the optimal control of the server’s work, at times leading the server to prefer remaining idle during breaks and interludes, instead of working on back-office, and at others to continue back-office in the presence of waiting customers. The optimal policy for use of the interludes is one with multiple thresholds depending on both the customers queueing for service, and the ones who are in-service. We illustrate that in settings with multiple interludes in an encounter, if at all, the back-office work should be concentrated on fewer, longer and later interludes.},
  archive      = {J_EJOR},
  author       = {Benjamin Legros and Oualid Jouini and O. Zeynep Akşin and Ger Koole},
  doi          = {10.1016/j.ejor.2020.04.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {946-963},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Front-office multitasking between service encounters and back-office tasks},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extended two-stage sequential optimization approach:
Properties and performance. <em>EJOR</em>, <em>287</em>(3), 929–945. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper looks into nonlinear non convex stochastic unconstrained optimization with finite simulation budget. Our work builds upon the Two-Stage Sequential Optimization (TSSO) algorithm that addresses the class of problems of interest by using the modified nugget effect kriging (MNEK) meta-model and proposing a budget allocation followed by a two-stage sequential procedure. Despite its efficiency and performance, we have observed that, given a finite budget, the choice of the number of replications per iteration, currently left to the user, is particularly critical for the algorithm performance. A fixed a-priori assignment can affect the ability to control the algorithm making it particularly sensitive to the initial settings. In this paper, we propose the extended TSSO (eTSSO). Specifically, a general simulation budget allocation scheme is proposed with the objective to balance the need of accurate function estimations to improve the selection in the search stage, with the need to explore the solution space. The new scheme adaptively, and recursively, increases the simulation budget based upon information iteratively returned by the optimizer itself. We analyze the asymptotic properties of eTSSO. Subsequently, we propose four alternative variants of the general allocation that we empirically analyze by comparing the quality of the estimated optimum input combination and the corresponding estimated optimum output against TSSO and other state of the art algorithms.},
  archive      = {J_EJOR},
  author       = {Giulia Pedrielli and Songhao Wang and Szu Hui Ng},
  doi          = {10.1016/j.ejor.2020.04.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {929-945},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An extended two-stage sequential optimization approach: Properties and performance},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Energy-saving policies for temperature-controlled production
systems with state-dependent setup times and costs. <em>EJOR</em>,
<em>287</em>(3), 916–928. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are numerous practical examples of production systems with servers that require heating in order to process jobs. Such production systems may realize considerable energy savings by temporarily switching off the heater and building up a queue of jobs to be processed later, at the expense of extra queueing costs. In this paper, we optimize this trade-off between energy and queueing costs. We model the production system as an M / G /1 queue with a temperature controlled server that can only process jobs if a minimum production temperature is satisfied. The time and energy required to heat a server depend on its current temperature, hence the setup times and setup costs for starting production are state dependent. We derive the optimal policy structure for a fluid queue approximation, called a wait-heat-clear policy. Building upon these insights, for the M / G /1 queue we derive exact and approximate costs for various intuitive types of wait-heat-clear policies. Numerical results indicate that the optimal wait-heat-clear policy yields average cost savings of over 40\% compared to always keeping the server at the minimum production temperature. Furthermore, an encouraging result for practice is that simple heuristics, depending on the queue length only, have near-optimal performance.},
  archive      = {J_EJOR},
  author       = {Michiel A.J. uit het Broek and Gerlach Van der Heide and Nicky D. Van Foreest},
  doi          = {10.1016/j.ejor.2020.03.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {916-928},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Energy-saving policies for temperature-controlled production systems with state-dependent setup times and costs},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of base-stock perishable inventory systems with
general lifetime and lead-time. <em>EJOR</em>, <em>287</em>(3), 901–915.
(<a href="https://doi.org/10.1016/j.ejor.2020.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A base-stock inventory system for perishables with Markovian demand and general lead-time and lifetime distributions is investigated. Using a queueing network model, we derive explicit expressions of the stationary distribution of the inventory state together with the total expected cost in a base-stock system with lost-sales. Next, we show some monotonicity properties of the cost function and propose a procedure to derive the optimal base-stock. Extensions to the backorders case and to a dual-sourcing system with multiple warehouses are also provided. Our results generalize existing ones from the literature where the lifetime and the lead-time follow either deterministic or exponential distributions. Finally, we investigate the effect of the lifetime and lead-time variability on the system cost and the optimal base-stock level. In particular, we show the substantial errors made when assuming deterministic or exponential distributions for the lifetime. This further shows the need to have results beyond exponential or deterministic assumptions.},
  archive      = {J_EJOR},
  author       = {Chaaben Kouki and Benjamin Legros and M. Zied Babai and Oualid Jouini},
  doi          = {10.1016/j.ejor.2020.05.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {901-915},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of base-stock perishable inventory systems with general lifetime and lead-time},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tax or subsidy? Design and selection of regulatory policies
for remanufacturing. <em>EJOR</em>, <em>287</em>(3), 885–900. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates a regulatory policy design and selection problem for a social-welfare-maximizing regulator, whose policies influence the remanufacturing production of a profit-maximizing manufacturer. The decisions of the regulator and the manufacturer are characterized by a Stackelberg game model, where three regulatory policies, namely, a tax policy, a subsidy policy, and a tax-subsidy policy are considered. Analytical results show that regulatory policies cannot always promote remanufacturing, which goes against the original intention of the regulator who hopes to encourage remanufacturing via regulatory policies. Accordingly, we address regulatory policy design strategies to help the regulator make policy-making decisions on respective regulatory policies. We then propose a threshold-based regulatory policy selection strategy to aid the regulator in making policy-choice decisions between the three policies. Further analyses indicate that the quality of available cores and the environmental treatment cost essentially influence the policy selection decisions of the regulator. The selected policy helps the regulator achieve maximum social welfare with the best environmental performance in most cases. An interesting finding in this study is that when the subsidy policy is selected, it is superior to the tax policy in improving social welfare and economic benefit, but may lead to heavier environmental burdens.},
  archive      = {J_EJOR},
  author       = {Yunrong Zhang and Zhaofu Hong and Zhixiang Chen and Christoph H. Glock},
  doi          = {10.1016/j.ejor.2020.05.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {885-900},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tax or subsidy? design and selection of regulatory policies for remanufacturing},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Buyback contracts to solve upstream opportunism.
<em>EJOR</em>, <em>287</em>(3), 875–884. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide another explanation for the prevalence of buyback provisions in wholesale contracts. As opposed to the existing literature which focuses on demand uncertainty, we show that buyback provisions may help an upstream supplier to alleviate the opportunism problem which arises due to strategic uncertainty. Within two different industry structures, first with a vertically integrated manufacturer and an independent retailer, then with an upstream-only manufacturer and two competing retailers, we show that a buyback contract may yield the industry profit maximizing outcome. Upstream marginal costs and retailer demand elasticity play an important role in determining the success of the buyback clause. A dual-channel supply chain is more effective in achieving coordination via buybacks.},
  archive      = {J_EJOR},
  author       = {Toker Doganoglu and Firat Inceoglu},
  doi          = {10.1016/j.ejor.2020.05.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {875-884},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Buyback contracts to solve upstream opportunism},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). AI-based competition of autonomous vehicle fleets with
application to fleet modularity. <em>EJOR</em>, <em>287</em>(3),
856–874. (<a href="https://doi.org/10.1016/j.ejor.2020.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because operational environments change over time and technology upgrades are common in fleets of ground vehicles, a large number of vehicles quickly become obsolete. A possible solution is to develop fleets of modular vehicles, which are built with interchangeable components, i.e. modules. This paper evaluates the performance of a future reconfigurable and autonomous vehicle fleet in a high fidelity military operation scenario. The military fleet operates in a hostile environment under a high risk of damage and needs to react to adversarial actions in real-time. The operation decisions are numerous including vehicle reconfiguration, relocation, damage recovery, and dispatch decisions. Given the limited resources and time delays in the operation, decision effectiveness and foresightedness are necessities, which require a good understanding of the adversary, close collaboration among commanders, and breaking of the equilibrium between adversaries. To capture these characteristics, we formulate an intelligent agent-based model for the decision-making process during fleet operations by combining real-time optimization with artificial intelligence. With continuous updating of learning models, the intelligent agents refine their decisions during interactions with the environment and other agents, and evolve their competition strategies according to adversarial historical behaviors. With the same level of resources, the conventional fleet wins when the dispatch decisions are stochastic. However, once each fleets start to learn from each other’s behavior, the modular fleet outperforms the conventional fleet. The strategic and operational benefits of fleet modularity are revealed and discussed in terms of win rate, adaptability, unpredictability and damage recovery.},
  archive      = {J_EJOR},
  author       = {Xingyu Li and Bogdan I. Epureanu},
  doi          = {10.1016/j.ejor.2020.05.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {856-874},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {AI-based competition of autonomous vehicle fleets with application to fleet modularity},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A single-item lot-sizing problem with a by-product and
inventory capacities. <em>EJOR</em>, <em>287</em>(3), 844–855. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high pace of waste accumulation in landfills and the depletion of scarce natural resources lead us to seek pathways for converting unavoidable production outputs into useful and high added-value products. In this context, we formalize and propose a model for the single-item lot-sizing problem, which integrates the management of unavoidable production residues classified as by-products. During the production process of a main product, a by-product is generated, stored in a limited capacity and transported with a fixed transportation cost. This problem is investigated for two cases of the by-product inventory capacity: time-dependent and constant. We prove that the problem with inventory capacities is NP NP -Hard. To solve it optimally, we develop a pseudo-polynomial time dynamic programming algorithm. For the case with stationary inventory capacities, a polynomial time dynamic programming algorithm is proposed.},
  archive      = {J_EJOR},
  author       = {Elodie Suzanne and Nabil Absi and Valeria Borodin and Wilco van den Heuvel},
  doi          = {10.1016/j.ejor.2020.05.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {844-855},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A single-item lot-sizing problem with a by-product and inventory capacities},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Manufacturer vs. Consumer subsidy with green technology
investment and environmental concern. <em>EJOR</em>, <em>287</em>(3),
832–843. (<a href="https://doi.org/10.1016/j.ejor.2020.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the effect of environmental subsidies on the incentives of investing in emission-reducing technologies in manufacturing amid the environmental concerns of consumers. The study adopts a game theoretical approach with respect to the interactions of environmental subsidy policies, emissions abatement and other decisions between the government and manufacturer(s). We examine and compare two environmental subsidy policies, namely, consumer and manufacturer subsidies, and find that the former yields a lower abatement and higher consumption quantity than the latter by focusing on consumption quantity instead of production emissions abatement. The manufacturer takes advantage of the consumer subsidy to increase its profits by increasing its production quantity and setting a high price simultaneously. We also show that the manufacturer&#39;s practice of taking advantage of the consumer subsidy presents a higher financial burden for the government than under the manufacturer subsidy. Besides, the consumer subsidy results in higher net emissions than the manufacturer subsidy due to the larger production quantity and lower abatement level under this policy. Despite the result of higher emissions, the consumer subsidy generates a higher social welfare compared to the manufacturer subsidy given that the former can lead to a larger quantity supply and profit for the manufacturer. We also extend the base model to multiple other cases to check the robustness of our results and find that our main results still hold qualitatively in these extensions.},
  archive      = {J_EJOR},
  author       = {Junsong Bian and Guoqing Zhang and Guanghui Zhou},
  doi          = {10.1016/j.ejor.2020.05.014},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {832-843},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Manufacturer vs. consumer subsidy with green technology investment and environmental concern},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accounting for cost heterogeneity on the demand in the
context of a technician dispatching problem. <em>EJOR</em>,
<em>287</em>(3), 820–831. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the technician dispatching problem, a given number of repair teams must visit different locations to provide service support. Considering that there is a fixed vehicle capacity and variations in the demand, not all requests can be satisfied on time and therefore some of them must be delayed. Most implementations of the dispatching problem consider a penalty that might vary depending on the customers to internalize that they have heterogeneous costs for being postponed. In this research we analyze how such variations in costs affect the outcome of service planning in the context of an efficient technician dispatching problem. We focus our analysis on two objectives: first, to understand how cost heterogeneity affects the performance of optimal solutions, and second to illustrate how a firm could implement an ad-hoc methodology even in cases where only observable customers’ features can be traced. Specifically, we explore how the distribution of costs affects optimal solutions of allocating teams during a daily operation of the service provider, and then we propose a Markovian model to capture cost-heterogeneity for the case where the cost of failure can be traced to observable operational characteristics. In this model we explicitly consider the cost faced by the customer by having inferior service quality. Our results indicate that when customers are sufficiently different, transportation and total penalty costs decrease gaining in operational efficiency. Moreover, results from the Markovian model indicate that firms can take advantage of these operational gains even in cases where only few customer characteristics are observed.},
  archive      = {J_EJOR},
  author       = {Juan P. Cavada and Cristián E. Cortés and Marcel Goic and Andrés Weintraub and Juan I. Zambrano},
  doi          = {10.1016/j.ejor.2020.04.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {820-831},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Accounting for cost heterogeneity on the demand in the context of a technician dispatching problem},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mass casualty management in disaster scene: A systematic
review of OR&amp;MS research in humanitarian operations. <em>EJOR</em>,
<em>287</em>(3), 787–819. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disasters are usually managed through a four-phase cycle including mitigation, preparedness, response and recovery. The first two phases happen before a disaster and the last two after it. This survey focuses on casualty management (CM), which is one of the actions taken in the response phase of a disaster. Right after a severe disaster strikes, we may be confronted with a large number of casualties in a very short period of time. These casualties are in need of urgent treatment and their survival depends on a rapid response. Therefore, managing resources in the first few hours after a disaster is critical and efficient CM can significantly increase the survival rate of casualties. Uncertainty in the location of a disaster, disruption to transportation networks, scarcity of resources and possible deaths of rescue and medical teams due to the disaster in such situations make it hard to manage casualties. In this survey, we focus on CM for disasters where the following five steps are taken, respectively: (i) Resource dispatching/search and rescue, (ii) on-site triage, (iii) on-site medical assistance, (iv) transportation to hospitals and (v) triage and comprehensive treatment. With a special focus on Operations Research (OR) techniques, we categorize the existing research papers and case studies in each of these steps. Then, by critically observing and investigating gaps, trends and the practicality of the extant research studies, we suggest future directions for academics and practitioners.},
  archive      = {J_EJOR},
  author       = {Reza Zanjirani Farahani and M.M. Lotfi and Atefe Baghaian and Rubén Ruiz and Shabnam Rezapour},
  doi          = {10.1016/j.ejor.2020.03.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {787-819},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mass casualty management in disaster scene: A systematic review of OR&amp;MS research in humanitarian operations},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prudence and preference for flexibility gain. <em>EJOR</em>,
<em>287</em>(2), 776–785. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the properties of the premium that a risk-averse individual is willing to pay to benefit from flexibility before an irreversible decision is made. Her decision concerns the quantity of some specific good to be acquired, knowing that the unit cost of the acquisition is either the mean value of a uniform distribution, or it is drawn from that distribution. The benefit of the latter technology, which we call a “flexibility gain”, is that after choosing the technology and before choosing the quantity, the individual learns the true unit cost. A richer individual values the flexibility more than a poorer individual if and only if her coefficient of absolute prudence is larger than a coefficient that is directly proportional to the rate at which the monetary benefit decreases when the state of nature drawn from the uniform distribution is above its mean value. We apply this result to an investment timing problem and show that the optimal waiting period increases with the ratio between the two coefficients. We next show that when the decision consists of exerting a preventive effort, the individual is more likely to prefer flexibility when she is more risk averse, but less likely to prefer flexibility when she is more prudent. Finally, we show how the identified link between the flexibility gain and degree of prudence determines the preference over specific lotteries. Moreover, when the individual is risk-neutral, the flexibility gain increases with the mean value of the distribution if and only if the marginal benefit function with respect to the unit cost is convex. Consequently, the individual has a stronger preference for an interval with lower mean, or lower mean and higher spread, when the marginal benefit function is concave rather than convex.},
  archive      = {J_EJOR},
  author       = {Daniel Danau},
  doi          = {10.1016/j.ejor.2020.04.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {776-785},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Prudence and preference for flexibility gain},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the estimation of technical and allocative efficiency in
a panel stochastic production frontier system model: Some new
formulations and generalizations. <em>EJOR</em>, <em>287</em>(2),
762–775. (<a href="https://doi.org/10.1016/j.ejor.2020.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose some alternative formulations and estimation of technical and allocative inefficiency in the presence of some exogenous variables in the context of a panel stochastic frontier model which includes time-invariant firm effects (heterogeneity) along with time-varying technical inefficiency and random noise. These exogenous variables are used to explain technical and allocative inefficiency as well as firm heterogeneity. The presence of these exogenous variables allows us to relax some of the assumptions made in a recent paper by Lai and Kumbhakar (2019) . These variables also allow to add flexibility in estimating the model parameters as well as both technical and allocative inefficiency and costs therefrom. More specifically, the incidental parameters problem associated with firm heterogeneity in the production function as well in the first-order conditions of cost minimization can be avoided by parameterizing them in terms of the exogenous variables. We propose and implement model comparison based on Bayes factors and marginal likelihood.},
  archive      = {J_EJOR},
  author       = {Subal C. Kumbhakar and Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2020.04.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {762-775},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the estimation of technical and allocative efficiency in a panel stochastic production frontier system model: Some new formulations and generalizations},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial contagion in mortgage defaults: A spatial dynamic
survival model with time and space varying coefficients. <em>EJOR</em>,
<em>287</em>(2), 749–761. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a spatial discrete survival model to estimate the time to default for UK mortgages. The model includes a flexible parametric link function given by the Generalised Extreme Value Distribution and a dynamic spatially varying baseline hazard function to capture neighbourhood effects over time. We incorporate time and space varying variables into the model. The gains of the proposed model are illustrated through the analysis of a dataset on around 74,000 mortgage loans issued in England and Wales from 2006 to 2015.},
  archive      = {J_EJOR},
  author       = {Raffaella Calabrese and Jonathan Crook},
  doi          = {10.1016/j.ejor.2020.04.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {749-761},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Spatial contagion in mortgage defaults: A spatial dynamic survival model with time and space varying coefficients},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General multilevel monte carlo methods for pricing
discretely monitored asian options. <em>EJOR</em>, <em>287</em>(2),
739–748. (<a href="https://doi.org/10.1016/j.ejor.2020.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe general multilevel Monte Carlo methods that estimate the price of an Asian option monitored at m fixed dates. For a variety of processes that can be simulated exactly, we prove that, for the same computational cost, our method yields an unbiased estimator with variance lower than the variance of the standard Monte Carlo estimator by a factor of order m . We show how to combine our approach with the Milstein scheme for processes driven by scalar stochastic differential equations, and with the Euler scheme for processes driven by multidimensional stochastic differential equations. Numerical experiments confirm that our method outperforms the conventional Monte Carlo algorithm by a factor proportional to m .},
  archive      = {J_EJOR},
  author       = {Nabil Kahalé},
  doi          = {10.1016/j.ejor.2020.04.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {739-748},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {General multilevel monte carlo methods for pricing discretely monitored asian options},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reducing estimation risk using a bayesian posterior
distribution approach: Application to stress testing mortgage loan
default. <em>EJOR</em>, <em>287</em>(2), 725–738. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new stress testing method to model coefficient uncertainty in addition to macroeconomic stress. Based on U.S. mortgage loan data, we model the probability of default at account level using discrete time hazard analysis. We employ both the frequentist and Bayesian methods in parameter estimation and default rate (DR) stress testing. By applying the Bayesian parameter posterior distribution, which includes all ranges of possible parameter estimates, obtained in the Bayesian approach to simulating the DR distribution, we reduce the estimation risk coming from employing point estimates in stress testing. Since estimation risk, a commonly neglected source of risk, is addressed in our method, we obtain more prudential forecasts of credit losses. We find that the simulated DR distribution obtained using the Bayesian approach with the parameter posterior distribution has a standard deviation 10.7 times as large as that using the frequentist approach with parameter mean estimates. Moreover, the 99\% value at risk (VaR) using the Bayesian posterior distribution approach is around 6.5 times the VaR at the same probability level using the point estimate approach.},
  archive      = {J_EJOR},
  author       = {Zheqi Wang and Jonathan Crook and Galina Andreeva},
  doi          = {10.1016/j.ejor.2020.04.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {725-738},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Reducing estimation risk using a bayesian posterior distribution approach: Application to stress testing mortgage loan default},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mildly explosive dynamics in u.s. Fixed income markets.
<em>EJOR</em>, <em>287</em>(2), 712–724. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use a recently developed right-tail variation of the Augmented Dickey-Fuller unit root test to identify and date-stamp periods of mildly explosive behavior in the weekly time series of eight U.S. fixed income yield spreads between September 2002 and April 2018. We find statistically significant evidence of mildly explosive dynamics in six of these spreads, two of which are short/medium-term mortgage-related spreads. We show that the time intervals characterized by instability that we estimate from these yield spreads capture known episodes of financial and economic distress in the U.S. economy. Mild explosiveness migrates from short-term funding markets to medium- and long-term markets during the Great Financial Crisis of 2007-09. Furthermore, we statistically validate the conjecture that the initial panic of 2007 migrated from segments of the ABX market to other U.S. fixed income markets in the early phases of the financial crisis.},
  archive      = {J_EJOR},
  author       = {Silvio Contessi and Pierangelo De Pace and Massimo Guidolin},
  doi          = {10.1016/j.ejor.2020.03.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {712-724},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mildly explosive dynamics in U.S. fixed income markets},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating stochastic production frontiers: A one-stage
multivariate semiparametric bayesian concave regression method.
<em>EJOR</em>, <em>287</em>(2), 699–711. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a nonparametric Bayesian estimator for production frontiers that satisfies the axioms of monotonicity and concavity. An inefficiency term that allows for a departure from the homoscedastic prior distributional assumption is jointly estimated in a single stage with cross-sectional data. Our Monte Carlo simulation experiments demonstrate that the frontier and efficiency estimations are computationally competitive, align well with economic theory, and allow for the analysis of larger data sets than existing nonparametric methods. We use the proposed method to investigate Japan’s concrete industry, an important component of the nation’s construction sector, from 2007 to 2010. Our finding of a significant size-weighted inefficiency supports the argument that economic stimuli given to Japan’s concrete industry may result in large losses due to inefficiency.},
  archive      = {J_EJOR},
  author       = {José Luis Preciado Arreola and Andrew L. Johnson and Xun C. Chen and Hiroshi Morita},
  doi          = {10.1016/j.ejor.2020.01.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {699-711},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating stochastic production frontiers: A one-stage multivariate semiparametric bayesian concave regression method},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive large neighbourhood search heuristic for routing
and scheduling feeder vessels in multi-terminal ports. <em>EJOR</em>,
<em>287</em>(2), 682–698. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Adaptive Large Neighbourhood Search heuristic for solving the Port Scheduling Problem , the problem of scheduling feeder vessels’ operations in multi-terminal ports. Each vessel has a number of operations to perform at different terminals within the port, and each terminal can only serve a single vessel at a time. The resulting problem is a general shop-like problem, with a variety of additional operational constraints. The objective is to let the vessels depart from the port as early as possible, as this allows them to sail at reduced speed to the next port, saving large amounts of fuel; as well as scheduling operations early, which leaves more slack for later and hence makes the system more robust. The developed Adaptive Large Neighbourhood Search heuristic works with the order of operations, and assigns the start times of the operations first as part of the solution evaluation. To conduct the computational experiments, a large set of benchmark test instances, denoted PortLib , was developed, and the performance of the heuristic was compared to that of a commercial solver. The results show that the heuristic in general finds better solutions, even with significantly shorter run times.},
  archive      = {J_EJOR},
  author       = {Erik Orm Hellsten and David Sacramento and David Pisinger},
  doi          = {10.1016/j.ejor.2020.04.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {682-698},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An adaptive large neighbourhood search heuristic for routing and scheduling feeder vessels in multi-terminal ports},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytics for labor planning in systems with load-dependent
service times. <em>EJOR</em>, <em>287</em>(2), 668–681. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a generalized framework for labor planning in systems with load-dependent service times. Our approach integrates customer arrival forecasting, service time estimation, and staffing into an end to end process. More specifically, (i) we propose a hybrid model to forecast customer arrivals, that combines a traditional time-series technique with a state-of-the-art machine learning algorithm, thereby allowing to incorporate a rich set of predictors; (ii) we develop a methodology to estimate the distribution of load-dependent service times from past transactions data; and (iii) we present a stochastic programming formulation to determine staffing levels under quality-of-service constraints. Finally, we develop a heuristic solution algorithm that utilizes an embedded discrete event simulation to evaluate system performance. To demonstrate the practical applicability of our approach, we conduct a case study at a franchisee of a major international fast food chain. Our data set includes the number of transactions, average order value, average service times, and staffing levels recorded at the restaurant on an hourly level, as well as information on marketing activities of the fast food chain on a daily level for nine consecutive years. We show that by applying our approach, the personnel expenses could be reduced by 4.4\%, which would translate into an increase in earnings before interest and taxes by 13\% at the collaborating restaurant.},
  archive      = {J_EJOR},
  author       = {Dmitry Smirnov and Arnd Huchzermeier},
  doi          = {10.1016/j.ejor.2020.04.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {668-681},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analytics for labor planning in systems with load-dependent service times},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Do mutual fund managers earn their fees? New measures for
performance appraisal. <em>EJOR</em>, <em>287</em>(2), 653–667. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a methodology to assess whether a mutual fund (MF) manages its costs and expenses efficiently, relative to its peers, in generating returns to investors. We consider incurred costs and expenses as MF disbursements. We develop a network data envelopment analysis model to assess MF performance from disbursement management perspective and propose new measures of MF performance - disbursement efficiency and disbursement utilization . We do this by conceptualising overall MF management process as a two-stage production process. In a sample of 1,706 U.S. equity MFs, we find that disbursement management performance relative to their peers (disbursement efficiency) is generally poor. Less than one per cent of the MFs are disbursement efficient and they are more likely to be growth funds. MFs that charge high fees perform relatively poorly in disbursement management. Large funds, on average, outperform mid-size and small funds in technical efficiency. According to our modelling framework, technical efficiency does not imply disbursement efficiency. Approximately fifteen per cent of technical efficient MFs are disbursement efficient. This is an indication that MF disbursement inefficiency is an issue that require attention of all stakeholders. Disbursement under-utilization and technical inefficiency explain disbursement inefficiency. For disbursement inefficient MFs, we provide pathways to become efficient in disbursement management. We validate the proposed MF performance measures empirically.},
  archive      = {J_EJOR},
  author       = {Don U.A. Galagedera and Hirofumi Fukuyama and John Watson and Eric K.M. Tan},
  doi          = {10.1016/j.ejor.2020.04.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {653-667},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Do mutual fund managers earn their fees? new measures for performance appraisal},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Route-based approximate dynamic programming for dynamic
pricing in attended home delivery. <em>EJOR</em>, <em>287</em>(2),
633–652. (<a href="https://doi.org/10.1016/j.ejor.2020.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attended home delivery describes the delivery of goods by e-grocers or e-tailers to customers within an agreed time window. Because customers expect narrow time windows, offering such services may lead to expensive fulfillment operations. This has led to research on how to influence customers’ bookings using time window pricing or slotting. In this paper, we reconsider the problem of demand management through dynamic pricing for attended home delivery services. This problem is usually modeled as a stochastic dynamic program, but even small instances cannot be solved to optimality due to the curses of dimensionality. The major challenges consist of finding feasible time windows for an incoming customer, estimating the opportunity costs, i.e., the future monetary loss due to accepting a booking, and optimizing the time window prices in real time. In this paper, we propose a route-based approximate dynamic programming approach to tackle these challenges. The approach carefully combines and partially extends state-of-the-art methods in attended home delivery, dynamic pricing, and dynamic vehicle routing. In an extensive simulation study, we compare its performance with state-of-the-art benchmark heuristics. The results indicate a superior performance of our approach in terms of both profit and number of customers served.},
  archive      = {J_EJOR},
  author       = {Sebastian Koch and Robert Klein},
  doi          = {10.1016/j.ejor.2020.04.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {633-652},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Route-based approximate dynamic programming for dynamic pricing in attended home delivery},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Incorporating patient preferences in the design and
operation of cancer screening facility networks. <em>EJOR</em>,
<em>287</em>(2), 616–632. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High participation by target populations is one of the key success factors of publicly funded and population-based cancer screening programs. Patient preferences are a major factor distinguishing preventive screening from treatment, specifically regarding participation and choice of facility. Here, we explore the effect of facility attributes on patients’ choices for cancer screening and propose a quantitative modeling framework to study the impact of various system- and facility-level interventions by incorporating the choice behaviors of heterogeneous patient populations. EPPM integrates an empirical study on patient preferences and a simulation-based optimization model that incorporates the preferences of multiple patient types into an M/G/s queuing network of facilities, each working with appointment. Based on our framework&#39;s application via an extensive case study on the Quebec Breast Cancer Screening Program in Montreal, we provide insights into improving participation in cancer screening networks. Specifically, we identify trade-offs that women make when choosing facilities with different attribute configurations and show the heterogeneity in patient preferences. We also find that facility-level interventions, such as providing free parking and improving staff manners, are more effective and less expensive than system-level interventions.},
  archive      = {J_EJOR},
  author       = {Beste Kucukyazici and Yue Zhang and Amir Ardestani-Jaafari and Lijie Song},
  doi          = {10.1016/j.ejor.2020.03.082},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {616-632},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Incorporating patient preferences in the design and operation of cancer screening facility networks},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using favorite data to analyze asymmetric competition:
Machine learning models. <em>EJOR</em>, <em>287</em>(2), 600–615. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated data enable businesses to derive competitive intelligence from the perspective of customers. With the advent of favorite data, we propose a sparse biterm-based Dirichlet process model and bipartite graph model with a random walk algorithm to analyze asymmetric competition. Through investigating the asymmetric market structure, representativeness degree of each entity, and competition network, the proposed machine learning models provide managerial insights into market competition. Based on 832,897 customers’ favorite lists, we empirically employ the proposed models to analyze the competition among the 2,204 car models in China&#39;s automotive market. Drawing on the activities of many customers in the market, our models enhance firms’ understanding of how the market is segmented by customers, which segments are most popular, and how entities compete with each other within the competition network. We can also inform managers of the segments within which a product competes, the representativeness of its competitors, and the leaders in each segment. The empirical results demonstrate that our models are practical in deriving insights about asymmetric competition for managers.},
  archive      = {J_EJOR},
  author       = {Yezheng Liu and Yang Qian and Yuanchun Jiang and Jennifer Shang},
  doi          = {10.1016/j.ejor.2020.03.074},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {600-615},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using favorite data to analyze asymmetric competition: Machine learning models},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal emergency vehicles location: An approach considering
the hierarchy and substitutability of resources. <em>EJOR</em>,
<em>287</em>(2), 583–599. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decisions on where to locate emergency vehicles have a crucial impact on the quality of the emergency service that is provided to populations, with consequences in terms of mortality and quality of life. It is important to guarantee the access of the population to emergency care, not forgetting the need to guarantee the best possible use of all available resources. In this work a new integer linear programming model is presented that aims at optimizing the location of emergency vehicles, considering in an explicit way the substitutability possibilities among vehicles of different types, taken into account the type of care they can provide. Moreover, the assignment of variables to emergency episodes is also explicitly considered which allows the model to be more accurate when calculating the expected coverage obtained. Both deterministic and stochastic models are presented. In the stochastic model, uncertainty regarding emergency episodes is represented by using scenarios. The model is applied to a dataset built considering all the features which are present in real data.},
  archive      = {J_EJOR},
  author       = {José Nelas and Joana Dias},
  doi          = {10.1016/j.ejor.2020.03.067},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {583-599},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal emergency vehicles location: An approach considering the hierarchy and substitutability of resources},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling efficiency in regional innovation systems: A
two-stage data envelopment analysis problem with shared outputs within
groups of decision-making units. <em>EJOR</em>, <em>287</em>(2),
572–582. (<a href="https://doi.org/10.1016/j.ejor.2020.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regional Innovation Systems (RISs) literature usually focuses on the comparative performance of different regions and analyzes how each region is utilizing its own dedicated resources. The available resources can be shared by many firms which are grouped by industry, just as universities collaborate with many firms in many industries. This paper studies a region in Mexico and the firms within that region with the aim being to identify which of those firms are using the available resources in the best way. We use Data Envelopment Analysis (DEA) as a methodology for evaluating the relative efficiencies of the firms, based on their multiple inputs and outputs, and considering their processes as being divided into two stages. An important problem in this setting is that the two-stage process exhibits the characteristic of having outputs being shared among the firms in each industry; this makes it more challenging to determine independent efficiency scores for each firm in each industry, where we need to cater for this phenomenon. To address this, the current article presents a methodology for measuring efficiency in situations where Decision Making Units (DMUs) share outputs with other units within the same group. By solving this problem, we can identify the best-performers and their strategies regarding how they use the available resources in the region.},
  archive      = {J_EJOR},
  author       = {Sonia Valeria Avilés-Sacoto and Wade D. Cook and David Güemes-Castorena and Joe Zhu},
  doi          = {10.1016/j.ejor.2020.04.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {572-582},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling efficiency in regional innovation systems: A two-stage data envelopment analysis problem with shared outputs within groups of decision-making units},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modified slacks-based measure of efficiency in data
envelopment analysis. <em>EJOR</em>, <em>287</em>(2), 560–571. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The slacks-based measure (SBM) model can divide the set of observations into two mutually exclusive and collectively exhaustive sets: efficient and inefficient. However, it fails to provide more details about efficient DMUs, which reveals the lack of discrimination power in the SBM model. With the aim of addressing this issue, the super SBM (SupSBM) model has been suggested which can rank the SBM-efficient DMUs without providing any useful information about SBM-inefficient DMUs. As a result, in order to fully rank both efficient and inefficient DMUs, one needs to run both SBM and SupSBM models which leads to a significant increase in the number of required computations. This paper tackles this problem and modifies the SBM model which measures SBM-efficiency score for inefficient DMUs and SupSBM-efficiency score for strong efficient DMUs, simultaneously. Finally, a simulation study is presented to illustrate the superiority of our proposed model over the existing models with various problem sizes.},
  archive      = {J_EJOR},
  author       = {Kaoru Tone and Mehdi Toloo and Mohammad Izadikhah},
  doi          = {10.1016/j.ejor.2020.04.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {560-571},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A modified slacks-based measure of efficiency in data envelopment analysis},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consensus mechanism with maximum-return modifications and
minimum-cost feedback: A perspective of game theory. <em>EJOR</em>,
<em>287</em>(2), 546–559. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In group decision making, the interaction behaviors between the moderator and decision makers play a critical role in a consensus process. In this study, based on the essential architecture of Stackelberg game, we present a bi-level optimization model to describe the interaction behaviors between decision makers and moderator, and develop the c onsensus m echanism with m aximum- r eturn modifications and m inimum- c ost feedback (MRMCCM). In the MRMCCM, the moderator aims to guide decision makers to reach consensus with minimum cost, while decision makers modify their own opinions based on the maximization of individual return. We analyze the equilibrium strategy in the MRMCCM, including the modification and compensation strategies composed of the optimal suggested opinion and unit consensus cost. In addition, an adaptive differential evolution is presented to deal with the bi-level optimization model, and the detailed experimental studies are conducted to justify the performance of the MRMCCM.},
  archive      = {J_EJOR},
  author       = {Bowen Zhang and Yucheng Dong and Hengjie Zhang and Witold Pedrycz},
  doi          = {10.1016/j.ejor.2020.04.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {546-559},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consensus mechanism with maximum-return modifications and minimum-cost feedback: A perspective of game theory},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The 2-rank additive model with axiomatic design in multiple
attribute decision making. <em>EJOR</em>, <em>287</em>(2), 536–545. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the 2-rank multiple attribute decision making (MADM) problem where alternatives are divided into two preference-ordered categories. We begin our study by introducing five axioms that characterize an “ideal” 2-rank additive MADM method, and then present an impossibility theorem: Five axioms cannot be satisfied simultaneously due to the intrinsic conflict among them. Next, we propose two simple 2-rank MADM methods: Permutation-based 2-rank method (PRM) and Ranking-based 2-rank method (RRM), and explore their desired properties based on the axioms. Furthermore, we design detailed simulation experiments and find out that the PRM and the RRM share the same 2-rank result in most cases although these two methods violate different axioms. Finally, we illustrate the PRM and the RRM through a consumer preference analysis case study.},
  archive      = {J_EJOR},
  author       = {Siqi Wu and Meng Wu and Yucheng Dong and Haiming Liang and Sihai Zhao},
  doi          = {10.1016/j.ejor.2020.04.011},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {536-545},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The 2-rank additive model with axiomatic design in multiple attribute decision making},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fair elimination-type competitions. <em>EJOR</em>,
<em>287</em>(2), 528–535. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the impact of two basic principles of fairness on the structure of elimination-type competitions and perform our analysis by focusing on sports competitions. The first principle states that stronger players should have a larger chance of winning than weaker players, while the second principle provides equally strong players the same chances of being the final winner. We apply these requirements to different kinds of knockout competitions, and characterise the structures satisfying them. In our results, a new competition structure that we call an antler is found to play a referential role.},
  archive      = {J_EJOR},
  author       = {Ritxar Arlegi and Dinko Dimitrov},
  doi          = {10.1016/j.ejor.2020.03.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {528-535},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fair elimination-type competitions},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved forecasting approach to reduce inventory levels
in decentralized supply chains. <em>EJOR</em>, <em>287</em>(2), 511–527.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper covers forecast management in decentralized supply chains. For various reasons, companies do not always agree to disclose their information. To deal with this issue, we consider a downstream demand inference (DDI) strategy in a two-level supply chain. DDI was assessed using different forecasting methods and was successfully tested using only a simple moving average. In an investigatory context using other forecasting methods, we propose the introduction of the weighted moving average method, which affects nonequal weights to past observations. First, we verify the unique propagation of demand processes. Second, we consider the forecast mean squared errors, the average inventory levels and the bullwhip effect as the supply performance metrics. Third, we formalize the manufacturer&#39;s forecast optimization problem and apply Newton&#39;s method to solve it. The optimization results, based on the simulated demands, confirm the effectiveness of our approach to produce further enhanced solutions and to improve the results of DDI. We have shown that a little change in the weights of the forecast method improves the competitiveness in the market. Conversely, the bullwhip effect is affected due to the nonequal weighting in the forecast method.},
  archive      = {J_EJOR},
  author       = {Youssef Tliche and Atour Taghipour and Béatrice Canel-Depitre},
  doi          = {10.1016/j.ejor.2020.04.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {511-527},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An improved forecasting approach to reduce inventory levels in decentralized supply chains},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated method based on relevance vector machine for
short-term load forecasting. <em>EJOR</em>, <em>287</em>(2), 497–510.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term electricity load forecasting has become increasingly important due to the privatization and deregulation in the energy market. This study proposes a probabilistic learning method to predict hour-ahead and day-ahead load demand. Unlike methods in previous studies, the proposed method integrates wavelet transform and feature selection as key preprocessing steps. Features are divided into current state related features and historical information related features. Current state related features are forecasted by the regression model before being added into the load prediction model. The entire learning and prediction process is based on the relevance vector machine (RVM) that utilizes load data characteristics. A number of test cases are presented using benchmark datasets from the New York Independent System Operator (NYISO) and ISO New England. Based on the detailed empirical comparison, the proposed RVM-based integrated method outperforms classical time series approaches and state-of-the-art artificial intelligence methods on short-term load forecasting.},
  archive      = {J_EJOR},
  author       = {Jia Ding and Maolin Wang and Zuowei Ping and Dongfei Fu and Vassilios S. Vassiliadis},
  doi          = {10.1016/j.ejor.2020.04.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {497-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated method based on relevance vector machine for short-term load forecasting},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collecting mode selection in a remanufacturing supply chain
under cap-and-trade regulation. <em>EJOR</em>, <em>287</em>(2), 480–496.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a remanufacturing closed-loop supply chain under the cap-and-trade regulation, where the collecting operations can be carried out by a manufacturer or a retailer or a third party. We construct models with and without remanufacturing to show the value of remanufacturing. The results indicate that remanufacturing can effectively improve the level of carbon emission reduction and the profits of the manufacturer and the retailer. For models with remanufacturing, we find that, interestingly, the result in the previous literature does not always hold. Specifically, the manufacturer will choose the third-party collecting mode when the unit carbon emissions in take-back process in the retailer collecting mode are much larger than those in the third-party collecting mode and the unit cost savings are relatively low, otherwise the manufacturer will choose the retailer collecting mode. As the numerical analysis shown, when the manufacturer subjects to a stringent emission control, total carbon emissions are always the lowest in the third-party collecting mode. The manufacturer&#39;s optimal collecting mode, whether is the retailer collecting mode or the third-party collecting mode, may result in the most carbon emissions when the carbon price is relatively low or the carbon intensity is high.},
  archive      = {J_EJOR},
  author       = {Lei Yang and Yijuan Hu and Lijuan Huang},
  doi          = {10.1016/j.ejor.2020.04.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {480-496},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Collecting mode selection in a remanufacturing supply chain under cap-and-trade regulation},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Channel strategy for manufacturers in the presence of
service freeriders. <em>EJOR</em>, <em>287</em>(2), 460–479. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the case of a manufacturer that must decide whether to sell its product directly to the customer through its own store, and/or indirectly through an independent retailer; both the manufacturer and the retailer must decide on the level of service effort they will provide to the customer. When customers are dissatisfied with a product, they will make an extra trip to return that product. Pre-sales service improves customers’ satisfaction with the product and reduces customer returns, but providing that service may be costly for the seller, and not all service leads to immediate sales. In particular, when a channel provides a high level of service, some customers may first visit this channel&#39;s store to take advantage of the service, only to buy the product from a cheaper channel (freeriding). This paper examines the impact of customers’ freeriding behavior on a manufacturer&#39;s channel strategy. We find that the cost bearer of freeriding (the firm on which the customers freeride) can be better off, and the beneficiary of freeriding (the firm from which the freeriding customers purchase the product) can be worse off, when customers can freeride. We also find that when customers can freeride, the manufacturer is less likely to use the dual-channel structure, and total demand may be smaller, even though customers have the flexibility of choosing where to buy after experiencing pre-sales service.},
  archive      = {J_EJOR},
  author       = {Hubert Pun and Jing Chen and Wei Li},
  doi          = {10.1016/j.ejor.2020.04.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {460-479},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Channel strategy for manufacturers in the presence of service freeriders},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-cut algorithm for the restricted block
relocation problem. <em>EJOR</em>, <em>287</em>(2), 452–459. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Block Relocation Problem, that has a crucial role in the logistics of containers. It consists of minimizing the number of container relocations within a container bay/yard. Since the number of containers shipped worldwide grew dramatically in the last years, the problem has been widely investigated. Here we propose an exact algorithm for the restricted version of the Block Relocation Problem, based on a new integer linear programming formulation. We compare such new approach with the state-of-art exact methods. The computational results prove its effectiveness and show that it outperforms all the previously proposed procedures, in almost all the considered instances.},
  archive      = {J_EJOR},
  author       = {Tiziano Bacci and Sara Mattia and Paolo Ventura},
  doi          = {10.1016/j.ejor.2020.05.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {452-459},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for the restricted block relocation problem},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven optimization model customization. <em>EJOR</em>,
<em>287</em>(2), 438–451. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When embedded in software-based decision support systems, optimization models can greatly improve organizational planning. In many industries, there are classical models that capture the fundamentals of general planning decisions (e.g., designing a delivery route). However, these models are generic and often require customization to truly reflect the realities of specific operational settings. Yet, such customization can be an expensive and time-consuming process. At the same time, popular cloud computing software platforms such as Software as a Service (SaaS) are not amenable to customized software applications. We present a framework that has the potential to autonomously customize optimization models by learning mathematical representations of customer-specific business rules from historical data derived from model solutions and implemented plans. Because of the wide-spread use in practice of mixed integer linear programs (MILP) and the power of MILP solvers, the framework is designed for MILP models. It uses a common mathematical representation for different optimization models and business rules, which it encodes in a standard data structure. As a result, a software provider employing this framework can develop and maintain a single code-base while meeting the needs of different customers. We assess the effectiveness of this framework on multiple classical MILPs used in the planning of logistics and supply chain operations and with different business rules that must be observed by implementable plans. Computational experiments based on synthetic data indicate that solutions to the customized optimization models produced by the framework are regularly of high-quality.},
  archive      = {J_EJOR},
  author       = {Mike Hewitt and Emma Frejinger},
  doi          = {10.1016/j.ejor.2020.05.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {438-451},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven optimization model customization},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact solution algorithms for the maximum flow problem with
additional conflict constraints. <em>EJOR</em>, <em>287</em>(2),
410–437. (<a href="https://doi.org/10.1016/j.ejor.2020.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a variant of the maximum flow problem on a given directed graph where some arc pairs are incompatible or conflicting; in other words, they are not allowed to carry positive flow simultaneously. This problem, called the maximum flow problem with conflicts, is known to be strongly NP-hard. In this paper, we present mixed-integer linear programming formulations for the problem and develop exact solution methods based on Benders decomposition, branch-and-bound, and Russian Doll Search over the conflict graph which represents the conflict relations. The effectiveness of the proposed algorithms is tested on a large number of randomly generated instances. The results reveal that their performances are superior to solving the mixed-integer linear programming formulations with a commercial software.},
  archive      = {J_EJOR},
  author       = {Zeynep Şuvak and İ. Kuban Altınel and Necati Aras},
  doi          = {10.1016/j.ejor.2020.04.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {410-437},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact solution algorithms for the maximum flow problem with additional conflict constraints},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on conic relaxations of optimal power flow problem.
<em>EJOR</em>, <em>287</em>(2), 391–409. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conic optimization has recently emerged as a powerful tool for designing tractable and guaranteed algorithms for power system operation. On the one hand, tractability is crucial due to the large size of modern electricity transmission grids. This is a result of the numerous interconnections that have been built over time. On the other hand, guarantees are needed to ensure reliability and safety for consumers at a time when power systems are growing in complexity. This is in large part due to the high penetration of renewable energy sources and the advent of electric vehicles. The aim of this paper is to review the latest literature in order to demonstrate the success of conic optimization when applied to power systems. The main focus is on how linear programming, second-order cone programming, and semidefinite programming can be used to address a central problem named the optimal power flow problem. We describe how they are used to design convex relaxations of this highly challenging non-convex optimization problem. We also show how sum-of-squares can be used to strengthen these relaxations. Finally, we present advances in first-order methods, interior-point methods, and nonconvex methods for solving conic optimization. Challenges for future research are also discussed.},
  archive      = {J_EJOR},
  author       = {Fariba Zohrizadeh and Cedric Josz and Ming Jin and Ramtin Madani and Javad Lavaei and Somayeh Sojoudi},
  doi          = {10.1016/j.ejor.2020.01.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {391-409},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A survey on conic relaxations of optimal power flow problem},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 2020 editors’ awards for excellence in reviewing.
<em>EJOR</em>, <em>287</em>(2), 389–390. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Roman Slowinski Co-ordinating Editor},
  doi          = {10.1016/j.ejor.2020.03.063},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {389-390},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {2020 editors’ awards for excellence in reviewing},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving a large cutting problem in the glass manufacturing
industry. <em>EJOR</em>, <em>287</em>(1), 378–388. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The glass cutting problem proposed by Saint Gobain for the 2018 ROADEF challenge includes some specific constraints that prevent the direct application of procedures developed for the standard cutting problem. On the one hand, the sheets to be cut have defects that make them unique and they must be used in a given order. On the other hand, pieces are grouped in stacks and the pieces in each stack must be cut in order. There are also some additional characteristics due to the technology being used, especially the requirement for a three-stage guillotine cutting process. Taking into account the sequencing constraints on sheets and pieces, we have developed a beam search algorithm, using a tree structure in which at each level the partial solution is increased by adding some new elements until a complete solution is built. We have developed a randomized constructive algorithm for building these new elements and explored several alternatives for the local and the global evaluation. An improvement procedure, specifically designed for the problem, has also been added. The computational study, using the datasets provided by the company, shows the efficiency of the proposed algorithm for short and long running times.},
  archive      = {J_EJOR},
  author       = {F. Parreño and M.T. Alonso and R. Alvarez-Valdes},
  doi          = {10.1016/j.ejor.2020.05.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {378-388},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving a large cutting problem in the glass manufacturing industry},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated planning model in centralized power systems.
<em>EJOR</em>, <em>287</em>(1), 361–377. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of centralized electricity markets, we propose an integrated planning model for power pricing and network expansion, which endogenizes the scaling costs from power losses. While the substitutability pattern between pricing and expansion has been overlooked in the power flow optimization literature, this becomes particularly relevant in centralized electricity markets (where the headquarters are enabled to take decisions over a wide range of operational factors). In this paper, we tailor an optimization model and solution approach, that can be effectively applied to large-scale instances of centralized power systems. Specifically, we develop bounds to the optimal operator profit and use them within a mixed-integer linear programming problem, derived from the linearization of an extended power flow model. On the empirical side, we conduct computational tests on a comprehensive power system data set from the Saudi Electricity Company, uncovering the value of the proposed integrated planning. The results reveal the complex substitutability patterns which appear when deciding about integrated operational factors in centralized power systems and support the correctness and efficiency of the proposed resolution mechanism.},
  archive      = {J_EJOR},
  author       = {Francisco López-Ramos and Stefano Nasini and Mohamed H. Sayed},
  doi          = {10.1016/j.ejor.2020.05.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {361-377},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An integrated planning model in centralized power systems},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph coloring-based approach for railway station design
analysis and capacity determination. <em>EJOR</em>, <em>287</em>(1),
348–360. (<a href="https://doi.org/10.1016/j.ejor.2020.04.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an optimization model for strategic decision-making in railway station design, enabling the comparison and selection of a station layout that maximizes the theoretical infrastructure capacity, completely independent of timetables. The model, using well-known combinatorial problems, such as the weighted vertex coloring problem and traveling salesman problem, identifies a route sequence that occupies a minimum amount of infrastructure and calculates the theoretical capacity. The model is tested on six different layouts for a station in the design phase, as well as on one fully operating station. The test results demonstrate the simplicity of implementing the model.},
  archive      = {J_EJOR},
  author       = {Predrag Jovanović and Norbert Pavlović and Ivan Belošević and Sanjin Milinković},
  doi          = {10.1016/j.ejor.2020.04.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {348-360},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Graph coloring-based approach for railway station design analysis and capacity determination},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feed-in tariff contract schemes and regulatory uncertainty.
<em>EJOR</em>, <em>287</em>(1), 331–347. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel analysis of two feed-in tariffs (FIT) under market and regulatory uncertainty, namely a sliding premium with cap and floor and a minimum price guarantee. Regulatory uncertainty is modeled with a Poisson process, whereby a jump event may reduce the tariff before the signature of the contract. Using a semi-analytical real options framework, we derive the project value, the optimal investment threshold, and the value of the investment opportunity for these schemes. Taking into consideration the optimal investment threshold, we also compare the two aforementioned FITs with the fixed-price FIT and the fixed-premium FIT, which are policy schemes that have been extensively studied in the literature. Our results show that increasing the likelihood of a jump event lowers the investment threshold for all the schemes; moreover, the investment threshold also decreases when the tariff reduction increases. We also compare the four schemes in terms of the corresponding optimal investment thresholds. For example, we find that the investment threshold of the sliding premium is lower than the minimum price guarantee. This result suggests that the first regime is a better policy than the latter because it accelerates the investment while avoiding excessive earnings for producers or excessive payments for consumers.},
  archive      = {J_EJOR},
  author       = {Luciana Barbosa and Cláudia Nunes and Artur Rodrigues and Alberto Sardinha},
  doi          = {10.1016/j.ejor.2020.04.054},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {331-347},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Feed-in tariff contract schemes and regulatory uncertainty},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Productivity spillovers and human capital: A semiparametric
varying coefficient approach. <em>EJOR</em>, <em>287</em>(1), 317–330.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines whether there are productivity spillover effects among clustered firms and, if so, whether a firm’s human capital affects its absorption of spillovers. To analyze these questions, we use a semiparametric spatial autoregressive production function in which the coefficients are smooth unknown functions of firms’ human capital. The varying coefficients not only allow flexible interactions between human capital and other inputs, but also permit heterogeneous spatial dependence and spillover effects among firms. Although the commonly used spatial matrix captures the possible learning opportunities among firms, we hypothesize that a firm with more human capital is better at seizing these opportunities. We address the simultaneity issue arising from the endogeneity of inputs by using the proxy variable method. Finally, we apply the model to analyze the productivity spillovers and the human capital effect of China’s computer and peripheral equipment industry from 1998 to 2007.},
  archive      = {J_EJOR},
  author       = {Zhezhi Hou and Man Jin and Subal C. Kumbhakar},
  doi          = {10.1016/j.ejor.2020.04.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {317-330},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Productivity spillovers and human capital: A semiparametric varying coefficient approach},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adversarial risk analysis under partial information.
<em>EJOR</em>, <em>287</em>(1), 306–316. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial risk analysis provides one-sided decision support to decision makers faced with risks due to the actions of other parties who act in their own interest. It is therefore relevant for the management of security risks, because the likely actions of the adversary can, to some extent, be forecast by formulating and solving decision models which explicitly capture the adversary’s objectives, actions, and beliefs. Yet, while the development of these decision models sets adversarial risk analysis apart from other approaches, the exact specification of the adversary’s decision model can pose challenges. In response to this recognition, and with the aim of facilitating the use of adversarial risk analysis when the parameters of the decision model are not completely known, we develop methods for characterizing the adversary’s likely actions based on concepts of partial information, stochastic dominance and decision rules. Furthermore, we consider situations in which information about the beliefs and preferences of all parties may be incomplete. We illustrate our contributions with a realistic case study of military planning in which the Defender seeks to protect a supply company from the Attacker who uses unmanned aerial vehicles for surveillance and the acquisition of artillery targets.},
  archive      = {J_EJOR},
  author       = {Juho Roponen and David Ríos Insua and Ahti Salo},
  doi          = {10.1016/j.ejor.2020.04.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {306-316},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adversarial risk analysis under partial information},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An application of dynamic programming to assign pressing
tanks at wineries. <em>EJOR</em>, <em>287</em>(1), 293–305. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes an application of dynamic programming to determine the optimal strategy for assigning grapes to pressing tanks in one of the largest Portuguese wineries. To date, linear programming has been employed to generate proposed solutions to analogous problems, but this approach lacks robustness and may, in fact, result in severe losses in cases of sudden changes, which frequently occur in weather-dependent wine factories. Hence, we endowed our model with stochasticity, thereby rendering it less vulnerable to such changes. Our analysis, which is based on real-world data, demonstrates that the proposed algorithm is highly efficient and, after calibration, can be used to support winery’s decision-making. The solution proposed herein could also be applied in numerous other contexts where production processes rely on outside supplies.},
  archive      = {J_EJOR},
  author       = {Zbigniew Palmowski and Aleksandra Sidorowicz},
  doi          = {10.1016/j.ejor.2020.04.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {293-305},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An application of dynamic programming to assign pressing tanks at wineries},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing electricity mix for CO2 emissions reduction: A
robust input-output linear programming model. <em>EJOR</em>,
<em>287</em>(1), 280–292. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Input-Output Linear Programming (IO-LP) model has been recently used to identify a cost-effective strategy for reduction in economy-wide CO2 emissions through a shift in the electricity generation mix. As an extension, this study further develops a robust IO-LP model to address the data uncertainties of technology cost and final demand. Compared to the deterministic IO-LP model which seeks to minimize the levelized cost of electricity (LCOE), the robust IO-LP model aims to maximize the tolerance of data uncertainty under a dynamic uncertainty setting. The modelling results in case study of China show that coal-fired and hydro generation technologies should be greatly developed from 2020 to 2050 in the Business-As-Usual (BAU) scenario with no emissions target set. In order to mitigate accumulated economy-wide CO2 emissions by 30\% compared to the BAU emissions level, various types of clean generation technologies, i.e., gas-fired, hydro, nuclear, solar, wind, and biomass, should be introduced into the electricity mix. Along with the decrease in emissions target, the tolerance of data uncertainty will drop to a certain degree. Finally, we compared results of the robust IO-LP model with results of the stochastic and deterministic IO-LP models. The comparative analysis shows that the robust IO-LP model tends to select the generation technologies with smaller uncertainty in LCOE, and is able to improve the robustness of capacity planning solutions compared to the alternative models under data uncertainty.},
  archive      = {J_EJOR},
  author       = {Jidong Kang and Tsan Sheng Ng and Bin Su},
  doi          = {10.1016/j.ejor.2020.04.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {280-292},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing electricity mix for CO2 emissions reduction: A robust input-output linear programming model},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On pricing-based equilibrium for network expansion planning.
A multi-period bilevel approach under uncertainty. <em>EJOR</em>,
<em>287</em>(1), 262–279. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the development of a mixed binary primal-dual bilinear model for multi-period bilevel network expansion planning under uncertainty, where pricing-based equilibrated strategic and operational decisions are to be made. The periodwise dependent parameters’ uncertainty is represented by a finite set of scenarios. Pricing-based equilibrium is required in the models to be optimized at the nodes of a multi-period scenario tree. Given the size of the models, it is unrealistic to seek an optimal solution. Several versions of a Stochastic Nested Decomposition matheuristic algorithm are presented for problem solving. Additionally, an approach based on a stagewise-related Stochastic Lagrangean Decomposition is also considered together with a Frank-Wolfe Progressive Hedging-based algorithm. The state step variables device is key for the performance of both approaches. The solution’s optimality gap is computed for three out of the four solution providers that are presented. An extension of the Toll Assignment Problem is considered as a pilot case. A broad computational experience is reported.},
  archive      = {J_EJOR},
  author       = {Laureano F. Escudero and Juan F. Monge and Antonio M. Rodríguez-Chía},
  doi          = {10.1016/j.ejor.2020.03.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {262-279},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On pricing-based equilibrium for network expansion planning. a multi-period bilevel approach under uncertainty},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The newsvendor problem: The role of prospect theory and
feedback. <em>EJOR</em>, <em>287</em>(1), 251–261. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental studies on newsvendor ordering behavior offer conflicting explanations as to the cause of the deviation from the optimal risk-neutral behavior. With one exception, studies have neither explored prospect theory as possible explanations, nor investigated exactly how this prospecting behavior comes to be. We conduct two experiments and demonstrate that a newsvendor, indeed, exhibits prospecting behavior and that this behavior is triggered by the relative value of the overage and the underage costs. These relative values help create a frame of reference that puts the newsvendor in either a gain-frame or a loss-frame. When the overage cost is less than the underage cost, a newsvendor is in a loss-frame and acts in a risk-seeking manner by ordering more than the optimal, and when the overage cost is more than the underage cost, the newsvendor is in a gain-frame and acts in a risk-averse manner by ordering less than the optimal, as prospect theory suggests. We also show the newsvendor does not use mean demand anchoring with insufficient adjustment heuristic to determine either the initial or the subsequent order quantity. The newsvendor is willing to change the decision in response to changes in parameters, consistent with prospect theory. Two forms of feedback are also supplied; however, feedback does not result in improved decision-making with a commensurate reduction in either systematic bias or prospecting behavior. Surprisingly, the newsvendor becomes more risk-seeking over time rather than risk-neutral. We conclude with a discussion of our findings, managerial insights, and possible future directions.},
  archive      = {J_EJOR},
  author       = {Chirag Surti and Anthony Celani and Yuvraj Gajpal},
  doi          = {10.1016/j.ejor.2020.05.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {251-261},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The newsvendor problem: The role of prospect theory and feedback},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and pricing of extended warranty menus based on the
multinomial logit choice model. <em>EJOR</em>, <em>287</em>(1), 237–250.
(<a href="https://doi.org/10.1016/j.ejor.2020.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the design and pricing of an extended warranty menu, which offers multiple options with differentiated lengths and prices. The power law process is used to model product failures and evaluate warranty costs. The multinomial logit model is adopted to describe customer choice behaviors. From a warrantor’s perspective, the design and pricing problem is to determine which candidate options to offer and the associated prices so as to maximize the expected warranty profit. We show that the optimal strategy is to offer all candidate options associated with a cost-plus-margin pricing policy, with the same profit margins for all options. If only a limited number of options can be offered, then the options with the highest valuation margins should be selected. In addition, we present three extended models by incorporating heterogeneous warranty breadths, free preventive maintenance programs, and customers with heterogeneous perceptions of product failure probability. Major findings in the extended models include: (i ) a free preventive maintenance program should be attached to a warranty option only when it is feasible for that option; and (ii ) when the customer population is heterogeneous, the equal-margin pricing policy is no longer optimal. Overall, this work will equip practitioners with a quantitative tool to design and price extended warranty menus in various practical scenarios.},
  archive      = {J_EJOR},
  author       = {Xiaolin Wang and Xiujie Zhao and Bin Liu},
  doi          = {10.1016/j.ejor.2020.05.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {237-250},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Design and pricing of extended warranty menus based on the multinomial logit choice model},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal bargaining timing of a wholesale price for a
manufacturer with a retailer in a dual-channel supply chain.
<em>EJOR</em>, <em>287</em>(1), 225–236. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the optimal timing of when a manufacturer should bargain a wholesale price with a retailer in a dual-channel supply chain that consists of the manufacturer and the retailer. To address the problem, we construct a game-theoretic model in which the manufacturer can sell products directly to consumers (direct channel) and through the retailer (retail channel). We also assume that the manufacturer determines the direct price in the direct channel and the retailer determines the retail price in the retail channel, while the manufacturer and the retailer bargain the wholesale price. The analytical solution of our model yields the following clear-cut result: the manufacturer achieves its highest profit by bargaining the wholesale price earlier than determining the direct price. Moreover, we show that this result holds even if the control variables determined by the two supply chain members at the retail market level are not prices but quantities, proving the robustness of the result. Consequently, the result provides the managerial implication usable for practical decision-making that if a manufacturer using a dual-channel supply chain can choose the timing to negotiate the wholesale price with a retailer, the manufacturer should have the opportunity before determining the direct price or the quantity of products sold directly to consumers.},
  archive      = {J_EJOR},
  author       = {Kenji Matsui},
  doi          = {10.1016/j.ejor.2020.05.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {225-236},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal bargaining timing of a wholesale price for a manufacturer with a retailer in a dual-channel supply chain},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Alternating lagrangian decomposition for integrated airline
crew scheduling problem. <em>EJOR</em>, <em>287</em>(1), 211–224. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The airline crew scheduling problem is usually solved sequentially in two main steps because of its complexity: the crew pairing followed by the crew assignment. However, finding a globally optimal solution via the sequential approach may be impossible because the decision domain of the crew assignment problem is reduced by decisions made in the pairing problem. This study considers the crew scheduling problem in a personalized context where each pilot and copilot requests a set of preferred flights and vacations each month. We propose a model that completely integrates the crew pairing and personalized assignment problems to generate personalized monthly schedules for a given set of pilots and copilots simultaneously in a single optimization step. The model keeps the pairings in the two problems as similar as possible so that the propagation of perturbations arising during the operation is reduced. We develop an integrated algorithm that combines alternating Lagrangian decomposition, column generation, and dynamic constraint aggregation. We conduct computational experiments on a set of real instances from a major US carrier. Our integrated approach produces significant cost savings and better satisfaction of crew preferences compared with the traditional sequential approach.},
  archive      = {J_EJOR},
  author       = {Vahid Zeighami and Mohammed Saddoune and François Soumis},
  doi          = {10.1016/j.ejor.2020.05.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {211-224},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alternating lagrangian decomposition for integrated airline crew scheduling problem},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust optimization for premarshalling with uncertain
priority classes. <em>EJOR</em>, <em>287</em>(1), 191–210. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the premarshalling problem, where items in a storage area have to be sorted for convenient retrieval. A new model for uncertainty is introduced, where the priority values induced by the retrieval sequence of the items are uncertain. We develop a robust optimization approach for this setting, study complexity issues, and provide different mixed-integer programming formulations. In a computational study using a wide range of benchmark instances from the literature, we investigate both the efficiency of the approach as well as the benefit and cost of robust solutions. We find that it is possible to achieve a considerably improved level of robustness by using just a few additional relocations in comparison to solutions which do not take uncertainty into account.},
  archive      = {J_EJOR},
  author       = {Sven Boge and Marc Goerigk and Sigrid Knust},
  doi          = {10.1016/j.ejor.2020.04.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {191-210},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust optimization for premarshalling with uncertain priority classes},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards circular economy in production planning: Challenges
and opportunities. <em>EJOR</em>, <em>287</em>(1), 168–190. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the actual era of the international trade, global warming and depletion of Earth’s natural resources, the willingness to generate sustainable and competitive benefits determines us to stop thinking linearly (produce, consume and dispose) and to shift towards a circular approach by closing material loops. The latter falls within the concept of circular economy that, in turn, derives from reverse logistics . This paper proposes a comprehensive state-of-the-art review around the topic of circular economy and reverse logistics with a particular emphasis on mid-term production planning under discrete time settings. The broad spectrum of reviewed publications is categorized and discussed with respect to the main recovery operations, namely: (i) disassembly for recycling, (ii) from product to raw material recycling, and (iii) by-products and co-production. For each of the aforementioned recovery options, this paper elucidates the related definitions, reviews the mathematical formulations jointly with a structured overview of the solution methods, and discusses their industrial implications. Given the legislative pressure to mitigate environmental impacts caused by production processes, a special attention is paid to the greenhouse gas emissions and energy consumption. A cross-cutting analysis of the reviewed literature brought forward a number of research gaps and revealed multiple research opportunities to support the development of the circular economy. The key findings show an ever-growing interest in making sustainable the traditional linear industrial processes within a circular economy context.},
  archive      = {J_EJOR},
  author       = {Elodie Suzanne and Nabil Absi and Valeria Borodin},
  doi          = {10.1016/j.ejor.2020.04.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {168-190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Towards circular economy in production planning: Challenges and opportunities},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Condition-based maintenance for a k-out-of-n deteriorating
system under periodic inspection with failure dependence. <em>EJOR</em>,
<em>287</em>(1), 159–167. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with condition-based maintenance policy of a K -out-of- N deteriorating system with failure dependence. The intrinsic degradation of each component is modelled with a pure jump Lévy process. The idea of the failure dependence is motivated by complex engineering systems where the failure of one component may cause a momentary, transient shock to the system. The effect of the shock is modelled by a random magnitude of increment in the degradation level of each surviving component. Perfect periodic inspections are carried out on the system. Upon inspection, highly deteriorated or failed components are perfectly replaced and hence are restored to an as-good-as-new state. Nothing is done to the rest of the components. For such a system, the evaluation of the reliability and the assessment of the maintenance planning are quite complex due to the failure dependence as well as the imperfect maintenance at the system level. In this study, we address these problems by the implementation of Markov renewal theory. The maintenances costs in both the short-run and long-run horizons are derived and we validate these theoretical calculations by Monte-carlo simulations. Numerical example is given to illustrate the applicability of the proposed model. It can provide a reference for the decision-making when developing maintenance policies.},
  archive      = {J_EJOR},
  author       = {Nan Zhang and Mitra Fouladirad and Anne Barros and Jun Zhang},
  doi          = {10.1016/j.ejor.2020.04.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {159-167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Condition-based maintenance for a K-out-of-N deteriorating system under periodic inspection with failure dependence},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On metrics for supply chain resilience. <em>EJOR</em>,
<em>287</em>(1), 145–158. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilience, defined as the ability to recover quickly and effectively from a disruption, is critically important for supply chains. Yet, it has not been quantified as frequently as supply chain robustness. In this paper we review the existing metrics for supply chain resilience and introduce a new metric, titled the net present value of the loss of profit (NPV-LP). We test these metrics on a small supply chain problem consisting of one supply and one demand node for a perishable good over a multi-period horizon with a possible port shut-down. We use a stochastic programming formulation of the problem. We show how the different metrics cause different investment decisions for the supply chain, and hence why it is important to carefully pick the correct metric when modeling supply chain resilience.},
  archive      = {J_EJOR},
  author       = {Golnar Behzadi and Michael Justin O’Sullivan and Tava Lennon Olsen},
  doi          = {10.1016/j.ejor.2020.04.040},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {145-158},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On metrics for supply chain resilience},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal inventory control and design refresh selection in
managing part obsolescence. <em>EJOR</em>, <em>287</em>(1), 133–144. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a joint decision making of part inventory control and product design refresh planning for a manufacturer facing the part obsolescence problem, whereby the supply of a certain part stops early in the life cycle of a product. The part is used in both product assembly and warranty claims fulfillment, and spare part demand in warranty service is dependent on past sales. Design refresh and inventory control are two solutions proposed to resolve the obsolescence problem. In design refresh, alternative parts with ample supply are used as substitutes for obsolete parts; inventory control ensures sufficient stocks with approaches such as last-time buy (the final order delivered by the supplier). We formulate an optimal stopping model with additional decisions to investigate when design refresh should be initiated and how part procurement and inventory should be managed during the product life cycle after obsolescence. We establish the optimality of a threshold policy for the design refresh choice; well-structured policies, including target interval policies , are optimal for part inventory control. Through extensive analytical and numerical analyses, we discover that inventory control targets increases when more products are being used, and these targets are more sensitive to changes in more recently product sales. We also numerically identify the extra profits that a firm can earn by allowing for design refresh, and we develop a heuristic policy based on simple myopic decision rules, which exhibits good performance under various parameter settings.},
  archive      = {J_EJOR},
  author       = {Zhenyang Shi and Shaoxuan Liu},
  doi          = {10.1016/j.ejor.2020.04.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {133-144},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal inventory control and design refresh selection in managing part obsolescence},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Push verse pull: Inventory-leadtime tradeoff for managing
system variability. <em>EJOR</em>, <em>287</em>(1), 119–132. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a two-stage push–pull system in an assemble-to-order manufacturing environment. Modelling the system as an inventory-queue model, we construct a decision model to determine the optimal stock level of the semifinished base product and the optimal leadtime of the finished products that will minimize the total operational cost. We analytically characterize the structure of the optimal policy. For systems with moderate demand and upstream processing time variabilities, there exists a threshold determined purely by the tradeoff of operational costs so that when the upstream utilization is above the threshold, the push–pull strategy is optimal; otherwise the pure-pull strategy is optimal. When the inter-arrival time or the upstream service time follows a general probability distribution, the optimal policy depends on the demand or process variability at the upstream stage. Our results can be used to guide managers in selecting the right inventory and leadtime strategy to cope with system variability. We find that in comparison of the downstream variability, under some mild condition, the upstream variability has a more significant impact on the choice of the optimal policy, the corresponding inventory, and lead time. Further, the guaranteed/constant downstream processing time does not always benefit the supply chain performance.},
  archive      = {J_EJOR},
  author       = {Liming Liu and He Xu and Stuart X. Zhu},
  doi          = {10.1016/j.ejor.2020.04.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {119-132},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Push verse pull: Inventory-leadtime tradeoff for managing system variability},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Downward compatible loading optimization with inter-set cost
in automobile outbound logistics. <em>EJOR</em>, <em>287</em>(1),
106–118. (<a href="https://doi.org/10.1016/j.ejor.2020.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses an essential loading optimization problem arising in the outbound logistics of automobiles. The problem is to assign a set of orders of finished cars to a set of heterogeneous auto-carriers and to deliver these finished cars from a depot to multiple destinations. The involved destinations are located within a relatively small distance to the depot. A value corresponding to each order represents its urgency level, and an inter-set cost is defined among destinations to estimate the related transportation cost. The objective of the problem is to maximize the weighted total value of the assigned orders minus the total inter-set cost subject to a full-load constraint and a downward compatible loading structure. An integer programming model and a column generation based algorithm are proposed. The proposed algorithm is implemented based on serial and parallel programming, respectively. Computational results based on randomly generated instances and a case study with real data show that the proposed algorithm can generate near-optimality solutions efficiently, and outperforms solving the integer programming model by an IP solver and a rule-based method applied in practice.},
  archive      = {J_EJOR},
  author       = {Feng Chen and Yu Wang},
  doi          = {10.1016/j.ejor.2020.04.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {106-118},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Downward compatible loading optimization with inter-set cost in automobile outbound logistics},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pilotage planning in seaports. <em>EJOR</em>,
<em>287</em>(1), 90–105. (<a
href="https://doi.org/10.1016/j.ejor.2020.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vessel pilotage is compulsory in most seaports around the world. When traveling into or out of the terminal of a seaport, vessels should be navigated by sea pilots in order to follow correct and safe waterways. This paper studies a pilotage planning problem that involves decisions of scheduling the vessel traffic in a seaport, assigning work shifts to pilots, and scheduling the pilots in each work shift for vessel navigation. We formulate the problem as a linear mixed-integer programming (MIP) model that aims at minimizing the cost incurred by the pilotage operations, and show that the problem is strongly NP-hard. For solving the problem, we develop a branch-and-price (B&amp;P) algorithm in which the pricing problem is solved by a novel dynamic programming algorithm. We further propose several acceleration techniques to improve the efficiency of the B&amp;P algorithm. The computational performance of the B&amp;P algorithm is evaluated in extensive numerical experiments. Computational results demonstrate that the B&amp;P algorithm is able to solve problem instances of practical sizes, and that the algorithm outperforms a standard MIP solver and a solution method commonly used in practice.},
  archive      = {J_EJOR},
  author       = {Lingxiao Wu and Shuai Jia and Shuaian Wang},
  doi          = {10.1016/j.ejor.2020.05.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {90-105},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pilotage planning in seaports},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the exact solution of vehicle routing problems with
backhauls. <em>EJOR</em>, <em>287</em>(1), 76–89. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we are interested in the exact solution of the vehicle routing problem with backhauls (VRPB), a classical vehicle routing variant with two types of customers: linehaul (delivery) and backhaul (pickup) ones. We propose two branch-cut-and-price (BCP) algorithms for the VRPB. The first one follows the traditional approach with one pricing subproblem, whereas the second one exploits the linehaul/backhaul customer partitioning and defines two pricing subproblems. The methods incorporate elements of state-of-the-art BCP algorithms, such as rounded capacity cuts, limited-memory rank-1 cuts, strong branching, route enumeration, arc elimination using reduced costs and dual stabilization. Computational experiments show that the proposed algorithms are capable of obtaining optimal solutions for all existing instances with up to 200 customers, many of them for the first time. The approach involving two pricing subproblems appears to be more efficient than the traditional one. We introduce new large instances and find tight bounds for them. We finally evaluate the performance of the algorithms on benchmark instances of the heterogeneous fixed fleet VRPB and the VRPB with time windows.},
  archive      = {J_EJOR},
  author       = {Eduardo Queiroga and Yuri Frota and Ruslan Sadykov and Anand Subramanian and Eduardo Uchoa and Thibaut Vidal},
  doi          = {10.1016/j.ejor.2020.04.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {76-89},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the exact solution of vehicle routing problems with backhauls},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heuristic and exact algorithms for minimum-weight
non-spanning arborescences. <em>EJOR</em>, <em>287</em>(1), 61–75. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of finding an arborescence of minimum total edge weight rooted at a given vertex in a directed, edge-weighted graph. If the arborescence must span all vertices the problem is solvable in polynomial time, but the non-spanning version is NP-hard. We propose reduction rules which determine vertices that are required or can be excluded from optimal solutions, a modification of Edmonds algorithm to construct arborescences that span a given set of selected vertices, and embed this procedure into an iterated local search for good vertex selections. Moreover, we propose a cutset-based integer linear programming formulation, provide different linear relaxations to reduce the number of variables in the model and solve the reduced model using a branch-and-cut approach. We give extensive computational results showing that both the heuristic and the exact methods are effective and obtain better solutions on instances from the literature than existing approaches, often in much less time.},
  archive      = {J_EJOR},
  author       = {Marcus Ritt and Jordi Pereira},
  doi          = {10.1016/j.ejor.2020.03.073},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {61-75},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heuristic and exact algorithms for minimum-weight non-spanning arborescences},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The forward–backward–forward method from continuous and
discrete perspective for pseudo-monotone variational inequalities in
hilbert spaces. <em>EJOR</em>, <em>287</em>(1), 49–60. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tseng’s forward–backward–forward algorithm is a valuable alternative for Korpelevich’s extragradient method when solving variational inequalities over a convex and closed set governed by monotone and Lipschitz continuous operators, as it requires in every step only one projection operation. However, it is well-known that Korpelevich’s method converges and can therefore be used also for solving variational inequalities governed by pseudo-monotone and Lipschitz continuous operators. In this paper, we first associate to a pseudo-monotone variational inequality a forward–backward–forward dynamical system and carry out an asymptotic analysis for the generated trajectories. The explicit time discretization of this system results into Tseng’s forward–backward–forward algorithm with relaxation parameters, which we prove to converge also when it is applied to pseudo-monotone variational inequalities. In addition, we show that linear convergence is guaranteed under strong pseudo-monotonicity. Numerical experiments are carried out for pseudo-monotone variational inequalities over polyhedral sets and fractional programming problems.},
  archive      = {J_EJOR},
  author       = {R.I. Boţ and E.R. Csetnek and P.T. Vuong},
  doi          = {10.1016/j.ejor.2020.04.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {49-60},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The forward–backward–forward method from continuous and discrete perspective for pseudo-monotone variational inequalities in hilbert spaces},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous risk preferences in community-based
electricity markets. <em>EJOR</em>, <em>287</em>(1), 36–48. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organization in electricity markets is evolving from centralized pool-based to decentralized peer-to-peer structures. Within this decentralized framework, agents are expected to individually procure their energy, while directly negotiating with other market participants. Since distributed power generation is mostly based on non-dispatchable energy resources with zero marginal cost, any proposed decentralized negotiation mechanism needs to account for uncertainties. When operating uncertain assets, decision makers are affected by subjective attitudes towards uncertain payoffs, impacting not only their energy procurement but also the whole market equilibrium. We propose a new definition of fairness in risky environments and show that, in decentralized electricity markets, heterogeneous risk aversion of participants compromises fairness of the resulting market payments. Consequently, we introduce financial contracts as risk hedging mechanisms and evaluate their impact on market equilibrium and payments. We show that by trading financial products, fairness is restored.},
  archive      = {J_EJOR},
  author       = {Fabio Moret and Pierre Pinson and Athanasios Papakonstantinou},
  doi          = {10.1016/j.ejor.2020.04.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {36-48},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heterogeneous risk preferences in community-based electricity markets},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clusterwise support vector linear regression. <em>EJOR</em>,
<em>287</em>(1), 19–35. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clusterwise linear regression (CLR), the aim is to simultaneously partition data into a given number of clusters and to find regression coefficients for each cluster. In this paper, we propose a novel approach to model and solve the CLR problem. The main idea is to utilize the support vector machine (SVM) approach to model the CLR problem by using the SVM for regression to approximate each cluster. This new formulation of the CLR problem is represented as an unconstrained nonsmooth optimization problem, where we minimize a difference of two convex (DC) functions. To solve this problem, a method based on the combination of the incremental algorithm and the double bundle method for DC optimization is designed. Numerical experiments are performed to validate the reliability of the new formulation for CLR and the efficiency of the proposed method. The results show that the SVM approach is suitable for solving CLR problems, especially, when there are outliers in data.},
  archive      = {J_EJOR},
  author       = {Kaisa Joki and Adil M. Bagirov and Napsu Karmitsa and Marko M. Mäkelä and Sona Taheri},
  doi          = {10.1016/j.ejor.2020.04.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {19-35},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Clusterwise support vector linear regression},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel computational optimization in operations research:
A new integrative framework, literature review and research directions.
<em>EJOR</em>, <em>287</em>(1), 1–18. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving optimization problems with parallel algorithms has a long tradition in OR. Its future relevance for solving hard optimization problems in many fields, including finance, logistics, production and design, is leveraged through the increasing availability of powerful computing capabilities. Acknowledging the existence of several literature reviews on parallel optimization, we did not find reviews that cover the most recent literature on the parallelization of both exact and (meta)heuristic methods. However, in the past decade substantial advancements in parallel computing capabilities have been achieved and used by OR scholars so that an overview of modern parallel optimization in OR that accounts for these advancements is beneficial. Another issue from previous reviews results from their adoption of different foci so that concepts used to describe and structure prior literature differ. This heterogeneity is accompanied by a lack of unifying frameworks for parallel optimization across methodologies, application fields and problems, and it has finally led to an overall fragmented picture of what has been achieved and still needs to be done in parallel optimization in OR. This review addresses the aforementioned issues with three contributions: First, we suggest a new integrative framework of parallel computational optimization across optimization problems, algorithms and application domains. The framework integrates the perspectives of algorithmic design and computational implementation of parallel optimization. Second, we apply the framework to synthesize prior research on parallel optimization in OR, focusing on computational studies published in the period 2008–2017. Finally, we suggest research directions for parallel optimization in OR.},
  archive      = {J_EJOR},
  author       = {Guido Schryen},
  doi          = {10.1016/j.ejor.2019.11.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Parallel computational optimization in operations research: A new integrative framework, literature review and research directions},
  volume       = {287},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). A note on sigma–mu efficiency analysis as a methodology for
evaluating units through composite indicators. <em>EJOR</em>,
<em>286</em>(3), 1187–1196. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research introduces a methodology for constructing composite indicators, called σ − μ σ−μ efficiency analysis, illustrating its potential in a case study of world happiness. Building on the landmark research paper, we propose a novel model that allows statistical inference for both weights in the composite indicator as well as inefficiency, fully accounting for outliers in the data and unit-specific heterogeneity in weights. The new techniques are based on Bayesian analysis via Markov Chain Monte Carlo.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2020.03.076},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1187-1196},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A note on Sigma–Mu efficiency analysis as a methodology for evaluating units through composite indicators},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of dollar cost averaging and market timing
investment strategies. <em>EJOR</em>, <em>286</em>(3), 1168–1186. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present new theoretical and practical insights into the method of dollar cost averaging (DCA) and averaging-style investment timing strategies, with a formal analysis of the problem. Firstly, we provide a rigorous mathematical formulation for studying DCA and related strategies. This provides closed form formulae for the expected value and variance of the investor’s wealth process, which mathematically proves many properties that have been documented in the literature only by empirical studies. Secondly, we prove a counterintuitive, but important, result that the frequency of DCA investment has a non-monotonic and non-trivial impact on risk, risk-return trade-off and other important performance metrics (such as the Sharpe ratio).Thirdly, we provide a method of valuing the DCA risk for models which incorporate jumps. We also provide a method of hedging DCA risk based on applying Asian options. Finally, using the PROJ method of computation, we obtain a robust and computationally efficient method for calculating standard risk measures of generic and deterministic investment strategies, such as DCA. We provide numerical experiments to illustrate our conclusions, and conduct an empirical study on the S&amp;P500 index (from 1954 to 2019) to substantiate our results.},
  archive      = {J_EJOR},
  author       = {J. Lars Kirkby and Sovan Mitra and Duy Nguyen},
  doi          = {10.1016/j.ejor.2020.04.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1168-1186},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An analysis of dollar cost averaging and market timing investment strategies},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unifying gaussian dynamic term structure models from a
heath–jarrow–morton perspective. <em>EJOR</em>, <em>286</em>(3),
1153–1167. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show that most existing Gaussian dynamic term structure models (GDTSMs) can be nested as special cases under a unified Heath–Jarrow–Morton (HJM)-based framework of GDTSM construction. Our study provides not only a systematic way to examine the commonality of many seemingly distinct GDTSMs, but also a novel and convenient approach to constructing GDTSMs that are otherwise unavailable or intractable under the traditional approach. In our empirical study using the Euro area forward rates, we conduct a specification analysis based on this novel approach. The analysis reveals that the traditional models impose restrictive constraints limiting their flexibility in capturing key features of the correlations and volatilities of the forward rates.},
  archive      = {J_EJOR},
  author       = {Haitao Li and Xiaoxia Ye and Fan Yu},
  doi          = {10.1016/j.ejor.2020.04.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1153-1167},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Unifying gaussian dynamic term structure models from a Heath–Jarrow–Morton perspective},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonparametric estimation of the determinants of inefficiency
in the presence of firm heterogeneity. <em>EJOR</em>, <em>286</em>(3),
1142–1152. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the application of the profile least-squares method to estimate the impact of the determinants of inefficiency in the presence of panel data and unobserved individual specific heterogeneity for the stochastic frontier model. This method has the advantage over previous approaches in that the effect of the determinants of inefficiency on output can be recovered nonparametrically in the presence of heterogeneity at the firm level. We describe the estimator and offer a small set of Monte Carlo exercises that showcases the value of the method for the stochastic frontier model. Application of the method to assess insights generated compared to a pooled cross-section approach using data from the Taiwan banking system is also provided.},
  archive      = {J_EJOR},
  author       = {Jianhua Zhou and Christopher F. Parmeter and Subal C. Kumbhakar},
  doi          = {10.1016/j.ejor.2020.04.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1142-1152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonparametric estimation of the determinants of inefficiency in the presence of firm heterogeneity},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Service level provision in municipalities: A flexible
directional distance composite indicator. <em>EJOR</em>,
<em>286</em>(3), 1129–1141. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing decentralization of public activities to the municipalities, it has become imperative to deploy an enhanced service provision analysis at the local level. This paper suggests the innovative use of a composite indicator to measure the multidimensional aspects of the local public provision comprising of several commonly administered municipal tasks. We propose a robust conditional version of a directional distance composite indicator with weight restrictions based on the municipal expenditure composition. Specifically, we deal with the presence of “undesirable” municipal service indicators and with the heterogeneity among the municipalities in their political preferences, priority public activities and operating environment characteristics. To illustrate the applicability of the suggested method, we show the construction of the municipal service provision composite indicator for 307 Flemish municipalities over the year 2006–2011.},
  archive      = {J_EJOR},
  author       = {Giovanna D’Inverno and Kristof De Witte},
  doi          = {10.1016/j.ejor.2020.04.012},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1129-1141},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Service level provision in municipalities: A flexible directional distance composite indicator},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling the emission trading scheme from an agent-based
perspective: System dynamics emerging from firms’ coordination among
abatement options. <em>EJOR</em>, <em>286</em>(3), 1113–1128. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though sharing a similar practice form, the emission trading scheme is distinguished from traditional financial markets: firms coordinate three abatement options at the micro level, including allowance trading, output adjustment, and low-carbon technology adoption. Then, at the macro level, this leads to dynamic interactions among allowance market, output market, and low-carbon technology diffusion. This is the fundamental characteristic of the emission trading scheme, and modeling the dynamics behind is a major difficulty for relevant studies, especially when following complexities are considered: (1) different planning horizons of the three abatement options, (2) heterogeneity among sectors and firms, and (3) details of firms’ production and optional low-carbon technologies. Aiming at this difficulty, we establish an agent-based model for the emission trading scheme, and within a novel multi-level time frame, the fundamental characteristic is reflected and the complexities are considered. Firms’ production and low-carbon technologies are discretely modeled at a process level from a bottom-up perspective, and based on European data, our model is calibrated to cover 5 industrial sectors, 11 emission-intensive products, 25 production processes, and 52 low-carbon technologies. With this model, the emergence properties and uncertainty of the system are captured, and the non-linear impact of the abatement target is reflected and discussed. We find that, after a certain level, higher target leads to lower allowance price uncertainty but stronger output impact, which is a trade-off for setting the abatement target.},
  archive      = {J_EJOR},
  author       = {Song-min Yu and Ying Fan and Lei Zhu and Wolfgang Eichhammer},
  doi          = {10.1016/j.ejor.2020.03.080},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1113-1128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling the emission trading scheme from an agent-based perspective: System dynamics emerging from firms’ coordination among abatement options},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Credit scoring by incorporating dynamic networked
information. <em>EJOR</em>, <em>286</em>(3), 1103–1112. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the credit scoring problem is studied by incorporating networked information, where the advantages of such incorporation are investigated theoretically in two scenarios. Firstly, a Bayesian optimal filter is proposed to provide risk prediction for lenders assuming that published credit scores are estimated merely from structured financial data. Such prediction can then be used as a monitoring indicator for the risk management in lenders’ future decisions. Secondly, a recursive Bayes estimator is further proposed to improve the precision of credit scoring by incorporating the dynamic interaction topology of clients. It is shown theoretically that under the proposed evolution framework, the designed estimator has a higher precision than any efficient estimator, and the mean square errors are strictly smaller than the Cramér–Rao lower bound for clients within a certain range of scores. Finally, simulation results for a special case illustrate the feasibility and effectiveness of the proposed algorithms.},
  archive      = {J_EJOR},
  author       = {Yibei Li and Ximei Wang and Boualem Djehiche and Xiaoming Hu},
  doi          = {10.1016/j.ejor.2020.03.078},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1103-1112},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Credit scoring by incorporating dynamic networked information},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Column generation-based stochastic school bell time and bus
scheduling optimization. <em>EJOR</em>, <em>286</em>(3), 1087–1102. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a trip plan (a sequence of bus stops), the integrated school bell time and bus scheduling problem simultaneously optimizes the school bell time and bus routes (the assignment of buses to serve trips at a specific time) while maintaining the minimum level-of-service requirements. The objective is to minimize the total number of buses and the total vehicle time. The previous efforts focused on the deterministic problem. However, uncertainty is unavoidable in a real-world problem. Thus, we consider this integrated problem with stochastic travel times. Two Mixed Integer Programming (MIP) models and a Column Generation-based algorithm are proposed. The algorithm incorporates the merits of the Column Generation, Simulated Annealing, Insertion Algorithm, and Greedy Randomized Adaptive Search Procedure and gains the computational power that the existing methods do not have. The experiments on a real-world problem show that, after the bell time optimization, up to 41\% of current buses can be saved with even better service in terms of the higher punctuality and shorter student ride time.},
  archive      = {J_EJOR},
  author       = {Zhongxiang Wang and Ali Haghani},
  doi          = {10.1016/j.ejor.2020.03.071},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1087-1102},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Column generation-based stochastic school bell time and bus scheduling optimization},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of a limited budget on the corrective action
taking process. <em>EJOR</em>, <em>286</em>(3), 1070–1086. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of project control is to identify the deviations between the baseline schedule and the actual progress of the project by measuring the project performance in progress and using the project control methodologies to generate warning signals that act as triggers for corrective actions to bring the project back on track. To that purpose, tolerance limits are set on the required project performance, such that if the warning signals exceed these limits, they should result in appropriate corrective actions. In this paper, the Earned Value Management (EVM) control method and its extensions are used to test their abilities in taking corrective actions under a budget constraint. More precisely, four different approaches are proposed for allocating the limited budget along the different project phases, and whether a proper allocation of the budget results in an increase of the expected project outcome is measured. A large computational experiment is conducted on a set of artificial projects to assess the efficiency and effectiveness of the budget allocation models. Results show that simply allocating budget according to the time accrue of projects performs better than methods that take cost, time/cost or risk information into account. Moreover, results indicate that allocating a budget that increases in later stages of the project is beneficial for the outcome.},
  archive      = {J_EJOR},
  author       = {Jie Song and Annelies Martens and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2020.03.069},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1070-1086},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of a limited budget on the corrective action taking process},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Markov models of policy support for technology transitions.
<em>EJOR</em>, <em>286</em>(3), 1052–1069. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop and analyze two Markov models to obtain generalizable insights into technology policy decision making under uncertainty. The first model is a Markov reward process (MRP) that represents policy interventions with one-time, upfront costs, while the second is a Markov decision process (MDP) that represents interventions with recurring costs. For each model, we derive analytical expressions for the policymaker’s willingness to pay (WTP) to raise the probabilities of advancing a technology development or diffusion process at various stages and compare and contrast the behaviors of the MRP and MDP models. Then, we conduct numerical sensitivity analysis to explore how the optimal technology policy portfolio varies with certain parameters, and present a case study on lithium-ion batteries for electric vehicles. We find that the MRP and MDP models share some key similarities. Most notably, the possibility of regressing from a more advanced development or diffusion stage back to an earlier one reduces the value of earlier policy intervention and enhances the value of later intervention. This effect is stronger in the MDP because moving the process forward helps avoid incurring policy costs repeatedly by lingering in stages affected by the policy. Another consequence of the models’ different cost accounting schemes is that increases in WTP with respect to policy-enhanced transition probabilities exhibit diminishing returns in the MRP, but constant returns in the MDP. Lastly, our case study on the development of lithium-ion batteries demonstrates the practical application of our model to technology policy decision making.},
  archive      = {J_EJOR},
  author       = {Max T. Brozynski and Benjamin D. Leibowicz},
  doi          = {10.1016/j.ejor.2020.03.066},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1052-1069},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Markov models of policy support for technology transitions},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithmic trading for online portfolio selection under
limited market liquidity. <em>EJOR</em>, <em>286</em>(3), 1033–1051. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an optimal intraday trading algorithm to reduce overall transaction costs by absorbing price shocks when an online portfolio selection (OPS) method rebalances its portfolio. Having considered the real-time data of limit order books (LOBs), the trading algorithm optimally splits a sizeable market order into a number of consecutive market orders to minimise the overall transaction costs, including both the liquidity costs and the proportional transaction costs. The proposed trading algorithm, compatible with any OPS methods, optimises the number of intraday trades and finds an optimal intraday trading path. Backtesting results from the historical LOB data of NASDAQ-traded stocks show that the proposed trading algorithm significantly reduces the overall transaction costs when market liquidity is limited.},
  archive      = {J_EJOR},
  author       = {Youngmin Ha and Hai Zhang},
  doi          = {10.1016/j.ejor.2020.03.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1033-1051},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Algorithmic trading for online portfolio selection under limited market liquidity},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Individual antecedents of real options appraisal: The role
of national culture and ambiguity. <em>EJOR</em>, <em>286</em>(3),
1018–1032. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the antecedents of cognitive options appraisal in a cross-cultural sample of specialists and generalists. Examining the role of national culture and ambiguity in the real option logic, we show that individuals have more propensity to intuitively value options opportunities using ambiguity-based approaches than standard Bayesian benchmarks, and identify the drivers behind such behavioral deviations. We find that knowledge and cultural factors, along with age, gender and international life experience, influence subjective real options values and ambiguity attitudes. Results also confirm the higher tolerance for uncertainty of the Chinese relative to others.},
  archive      = {J_EJOR},
  author       = {Tarik Driouchi and Lenos Trigeorgis and Raymond H.Y. So},
  doi          = {10.1016/j.ejor.2020.03.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1018-1032},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Individual antecedents of real options appraisal: The role of national culture and ambiguity},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Product-closing approximation for ranking-based choice
network revenue management. <em>EJOR</em>, <em>286</em>(3), 1002–1017.
(<a href="https://doi.org/10.1016/j.ejor.2020.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recent research in network revenue management incorporates choice behavior that models the customers’ buying logic. These models are consequently more complex to solve, but they return a more robust policy that usually generates better expected revenue than an independent-demand model. Choice network revenue management has an exact dynamic programming formulation that rapidly becomes intractable. Approximations have been developed, and many of them are based on the multinomial logit demand model. However, this parametric model has the property known as the independence of irrelevant alternatives and is often replaced in practice by a nonparametric model. We propose a new approximation called the product closing program that is specifically designed for a ranking-based choice model representing a nonparametric demand. Numerical experiments show that our approach quickly returns expected revenues that are slightly better than those of other approximations, especially for large instances. Our approximation can also supply a good initial solution for other approaches.},
  archive      = {J_EJOR},
  author       = {Thibault Barbier and Miguel F. Anjos and Fabien Cirinei and Gilles Savard},
  doi          = {10.1016/j.ejor.2020.04.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1002-1017},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product-closing approximation for ranking-based choice network revenue management},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust hierarchical nominal multicriteria classification
method based on similarity and dissimilarity. <em>EJOR</em>,
<em>286</em>(3), 986–1001. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cat-SD (Categorization by Similarity-Dissimilarity) is a multiple criteria decision aiding method for dealing with nominal classification problems (predefined and non-ordered categories). Actions are assessed according to multiple criteria and assigned to one or more categories. A set of reference actions is used to define each category. The assignment of an action to a given category depends on the comparison of the action to each reference set according to likeness thresholds. Distinct sets of criteria weights, interaction coefficients, and likeness thresholds can be defined per category. When applying Cat-SD to complex decision problems, it may be useful to consider a hierarchy of criteria to give a more intelligible vision of the performances of the considered actions. We propose to apply Multiple Criteria Hierarchy Process to Cat-SD to take into account criteria structured in a hierarchical way. On the basis of the known deck of cards method, we also consider an imprecise elicitation of parameters permitting to consider interactions and antagonistic effects between criteria. The elicitation procedure we are proposing can be applied to any Electre method. With the purpose of exploring the assignments obtained by Cat-SD considering possible sets of parameters, we propose to apply the Stochastic Multicriteria Acceptability Analysis (SMAA). The SMAA methodology allows to draw statistical conclusions on the classification of the actions. The proposed method, SMAA-hCat-SD, helps the decision maker to check the effects of the variation of parameters on the classification at different levels of the hierarchy. We propose also a procedure, based on the concept of loss function, to get a deterministic classification fulfilling some requirements given by the decision maker and taking into account the hierarchy of criteria and the probabilistic assignments obtained through SMAA. Also this procedure can be applied to any classification Electre method. The application of the new proposal is shown through an example.},
  archive      = {J_EJOR},
  author       = {Ana Sara Costa and Salvatore Corrente and Salvatore Greco and José Rui Figueira and José Borbinha},
  doi          = {10.1016/j.ejor.2020.04.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {986-1001},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust hierarchical nominal multicriteria classification method based on similarity and dissimilarity},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A preference learning framework for multiple criteria
sorting with diverse additive value models and valued assignment
examples. <em>EJOR</em>, <em>286</em>(3), 963–985. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a preference learning framework for multiple criteria sorting. We consider sorting procedures applying an additive value model with diverse types of marginal value functions (including linear, piecewise-linear, splined, and general monotone ones) under a unified analytical framework. Differently from the existing sorting methods that infer a preference model from crisp decision examples, where each reference alternative is assigned to a unique class, our framework allows considering valued assignment examples in which a reference alternative can be classified into multiple classes with respective credibility degrees. We propose an optimization model for constructing a preference model from such valued examples by maximizing the credible consistency among reference alternatives. To improve the predictive ability of the constructed model on new instances, we employ the regularization techniques. Moreover, to enhance the capability of addressing large-scale datasets, we introduce a state-of-the-art algorithm that is widely used in the machine learning community to solve the proposed optimization model in a computationally efficient way. Using the constructed additive value model, we determine both crisp and valued assignments for non-reference alternatives. Moreover, we allow the Decision Maker to prioritize the importance of classes and give the method a flexibility to adjust classification performance across classes according to the specified priorities. The practical usefulness of the analytical framework is demonstrated on a real-world dataset by comparing it to several existing sorting methods.},
  archive      = {J_EJOR},
  author       = {Jiapeng Liu and Miłosz Kadziński and Xiuwu Liao and Xiaoxin Mao and Yao Wang},
  doi          = {10.1016/j.ejor.2020.04.013},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {963-985},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A preference learning framework for multiple criteria sorting with diverse additive value models and valued assignment examples},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constraint programming models for integrated container
terminal operations. <em>EJOR</em>, <em>286</em>(3), 945–962. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although operations in container terminals are highly interdependent, they are traditionally optimized by decomposing the overall problem into a sequence of smaller sub-problems, each focusing on a single operation. Recent studies, however, have demonstrated the need and potential of optimizing these interdependent operations jointly. This paper proposes the Integrated Port Container Terminal Problem (IPCTP) that considers the joint optimization of quay crane assignment and scheduling, yard crane assignment and scheduling, yard location assignments, and yard truck assignment and scheduling. The IPCTP aims at minimizing the turnover times of the vessels and maximize terminal throughput. It also considers inbound and outbound containers simultaneously and models the safety distance and the interference constraints for the quay cranes. To solve the IPCTP, the paper proposes several constraint programming (CP) models. Computational results show that CP provides exact solutions in acceptable time to IPCTP instances derived from an actual (small) container terminal in Turkey. For hard IPCTP instances, the CP model can be generalized in a two-stage optimization approach to produce high-quality solutions in reasonable times.},
  archive      = {J_EJOR},
  author       = {Damla Kizilay and Pascal Van Hentenryck and Deniz T. Eliiyi},
  doi          = {10.1016/j.ejor.2020.04.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {945-962},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Constraint programming models for integrated container terminal operations},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decorous combinatorial lower bounds for row layout problems.
<em>EJOR</em>, <em>286</em>(3), 929–944. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the Double-Row Facility Layout Problem (DRFLP). Given a set of departments and pairwise transport weights between them the DRFLP asks for a non-overlapping arrangement of the departments along both sides of a common path such that the weighted sum of the center-to-center distances between the departments is minimized. Despite its broad applicability in factory planning, only small instances can be solved to optimality in reasonable time. Apart from this even deriving good lower bounds using existing integer programming formulations and branch-and-cut methods is a challenging problem. We focus here on deriving combinatorial lower bounds which can be computed very fast. These bounds generalize the star inequalities of the Minimum Linear Arrangement Problem. Furthermore we exploit a connection of the DRFLP to some parallel identical machine scheduling problem. Our lower bounds can be further improved by combining them with a new distance-based mixed-integer linear programming model, which is not a formulation for the DRFLP, but can be solved close to optimality quickly. We compare the new lower bounds to some heuristically determined upper bounds on medium-sized and large DRFLP instances. Special consideration is given to the case when all departments have the same length. Furthermore we show that the lower bounds that we derive using adapted variants of our approaches for the Parallel Row Ordering Problem, a DRFLP variant where the row assignment of the departments is given in advance and spaces between neighboring departments are not allowed, are even better with respect to the gaps.},
  archive      = {J_EJOR},
  author       = {Mirko Dahlbeck and Anja Fischer and Frank Fischer},
  doi          = {10.1016/j.ejor.2020.04.010},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {929-944},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decorous combinatorial lower bounds for row layout problems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing late deliveries in a truck loading problem.
<em>EJOR</em>, <em>286</em>(3), 919–928. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we address the problem of determining the optimal types of products and their quantities that should be loaded on a fleet of heterogeneous one or two level trucks so that the weighted sum of delivered products is maximized, with the weights being an exponential function of the lateness computed for each unit shipped. We propose a mixed integer linear formulation followed by a two-phase solution approach. During phase one the formulation is solved aiming at maximizing the weighted sum of products delivered, whereas for the second phase, the formulation is solved aiming at minimizing the number of trucks, while ensuring that the objective function attained in phase one is not compromised. A greedy heuristic is also proposed in order to better quantify the advantages of adopting the proposed exact approach with respect to solution quality. To assess the performance of the proposed approach we used two sets of test instances, a large set of randomly generated instances that resemble the practical application that motivated this research, and a small set of real instances provided by the company. The results of our computational experiments suggest that the proposed exact solution approach is very effective in solving realistic sized instances.},
  archive      = {J_EJOR},
  author       = {Mario C. Vélez-Gallego and Alejandro Teran-Somohano and Alice E. Smith},
  doi          = {10.1016/j.ejor.2020.03.083},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {919-928},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing late deliveries in a truck loading problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Contract design when quality is co-created in a supply
chain. <em>EJOR</em>, <em>286</em>(3), 908–918. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates contract design by a firm in a supply chain where the quality of the product delivered to consumers is co-created by the quality decisions of the contract designer (platform firm) and the agent (the service provider) whose inputs need to be coordinated. Revenue is a function of the price charged to consumers, the product quality, and a market parameter which may be private information to the service provider. We focus on a contract with payment terms commonly used by large platforms such as Amazon. The platform firm adopts a menu-of-contracts approach to get the service provider to reveal its private information, resulting in optimal quality effort and price decisions that maximize the expected profit of the platform firm. We examine cases where the platform firm should disintermediate the service provider and make and sell the product itself. To study the coordination ability of the proposed contract, we compare the results with those obtained in the case of complete information via various benchmark scenarios.},
  archive      = {J_EJOR},
  author       = {Tal Avinadav and Tatyana Chernonog and Gila E. Fruchter and Ashutosh Prasad},
  doi          = {10.1016/j.ejor.2020.03.070},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {908-918},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Contract design when quality is co-created in a supply chain},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Non-monetary coordination mechanisms for time slot
allocation in warehouse delivery. <em>EJOR</em>, <em>286</em>(3),
897–907. (<a href="https://doi.org/10.1016/j.ejor.2020.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent empirical evidence suggests that delivery to retail warehouses suffers from a lack of coordination. While carriers try to optimize their routes, they often experience very long waiting times at loading docks, which renders their individual planning useless. To reduce such inefficiencies, carriers need to coordinate. This problem has received considerable attention in practice, but the design of coordination mechanisms is challenging for several reasons: First, the underlying package assignment problem is NP-hard. Second, efficiency, incentive-compatibility, and fairness are important design desiderata, but in most economic environments they are conflicting. Third, the market for logistics services is competitive and price-based mechanisms where carriers might have to pay for time slots suffer from low acceptance. We draw on recent advances in market design, more specifically randomized matching mechanisms, which set incentives for carriers to share information truthfully such that a central entity can coordinate their plans in a fair and approximately efficient way. We use and adapt the existing maximizing cardinal utilities (MAXCU) framework to a retail logistics problem, which yields a new and powerful approach for coordination. We report numerical experiments based on field data from a real-world logistics network to analyze the average reduction in waiting times and the computation times required and compare to first-come, first-served and an auction mechanism. Our results show that randomized matching mechanisms provide an effective means to reduce waiting times at warehouses without requiring monetary transfers by the carriers. They run in polynomial time and provide a practical solution to wide-spread coordination problems.},
  archive      = {J_EJOR},
  author       = {Paul Karaenke and Martin Bichler and Soeren Merting and Stefan Minner},
  doi          = {10.1016/j.ejor.2020.03.068},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {897-907},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Non-monetary coordination mechanisms for time slot allocation in warehouse delivery},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Game modes and investment cost locations in radio-frequency
identification (RFID) adoption. <em>EJOR</em>, <em>286</em>(3), 883–896.
(<a href="https://doi.org/10.1016/j.ejor.2020.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the effect of game modes and investment cost locations on firms’ profits and their incentives to adopt Radio-Frequency Identification (RFID) technology. We consider a supply chain, where one manufacturer places an RFID tag on each item and sells through one retailer. The two firms can play the Stackelberg game or the Bargaining game. Specifically, under the Stackelberg game, the manufacturer dictates the wholesale price first ( M ) or the retailer moves first to announce the retail markup ( R ); under the Bargaining game, firms can bargain over the wholesale price only ( O ) or over both the wholesale price and quantity ( B ). Adopting RFID incurs both a variable cost and a fixed cost, which can be borne by the manufacturer or the retailer, respectively. Our results show that under B , whether the retailer or the manufacturer bears the fixed cost does not affect both firms’ profits. Surprisingly, under O , we observe that the retailer earns more when he bears the fixed cost than when he does not if his bargaining power is strong. Although the chain under B is perfectly coordinated, the retailer gains more under B than under O only when his bargaining power is strong. Furthermore, the retailer&#39;s incentive to adopt RFID is stronger under R than under M , and his highest affordable variable cost is higher than the manufacturer&#39;s when the fixed cost is ignored under R . Finally, both firms’ highest affordable fixed costs under R are higher than the centralized level when the variable cost is high.},
  archive      = {J_EJOR},
  author       = {Huixiao Yang and Wenbo Chen},
  doi          = {10.1016/j.ejor.2020.02.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {883-896},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Game modes and investment cost locations in radio-frequency identification (RFID) adoption},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A MIP model and a biased random-key genetic algorithm based
approach for a two-dimensional cutting problem with defects.
<em>EJOR</em>, <em>286</em>(3), 867–882. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a two-dimensional ( 2D 2D ) non-guillotine cutting problem, where a set of small rectangular items of given types has to be cut from a large rectangular stock plate having defective regions so as to maximize the total value of the rectangles cut. The number of small items of each item type which can be cut from the large object is unrestricted. A novel MIP model and a hybrid approach combining a novel placement procedure with a biased random-key genetic algorithm ( BRKGA BRKGA ) are presented. The parameters used by the novel placement procedure for the development of a cutting plan are evolved by the BRKGA BRKGA . The management of the free spaces and of the defects uses a maximal-space representation. The approach is evaluated and compared to other approaches by means of a series of detailed numerical experiments using 5414 benchmark instances taken from the literature. The experimental results validate the quality of the solutions and the effectiveness of the proposed algorithm.},
  archive      = {J_EJOR},
  author       = {José Fernando Gonçalves and Gerhard Wäscher},
  doi          = {10.1016/j.ejor.2020.04.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {867-882},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A MIP model and a biased random-key genetic algorithm based approach for a two-dimensional cutting problem with defects},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-cut algorithm for the generalized traveling
salesman problem with time windows. <em>EJOR</em>, <em>286</em>(3),
849–866. (<a href="https://doi.org/10.1016/j.ejor.2020.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized traveling salesman problem with time windows (GTSPTW) is defined on a directed graph where the vertex set is partitioned into clusters. One cluster contains only the depot. Each vertex is associated with a time interval, the time window, during which the visit must take place if the vertex is visited. The objective is to find a minimum cost tour starting and ending at the depot such that each cluster is visited exactly once and time constraints are respected, i.e., for each cluster, one vertex is visited during its time window. In this paper, two integer linear programming formulations for GTSPTW are provided as well as several problem-specific valid inequalities. A branch-and-cut algorithm is developed in which the inequalities are separated dynamically. To reduce the computation times, an initial upper bound is provided by a simple and fast heuristic. We propose different sets of instances characterized by their time window structures. Experimental results show that our algorithm is effective and instances including up to 30 clusters can be solved to optimality within one hour.},
  archive      = {J_EJOR},
  author       = {Yuan Yuan and Diego Cattaruzza and Maxime Ogier and Frédéric Semet},
  doi          = {10.1016/j.ejor.2020.04.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {849-866},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for the generalized traveling salesman problem with time windows},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fresh view on the discrete ordered median problem based on
partial monotonicity. <em>EJOR</em>, <em>286</em>(3), 839–848. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents new results for the Discrete Ordered Median Problem (DOMP). It exploits properties of k -sum optimization to derive specific formulations for the monotone DOMP (MDOMP), that arises when the λ weights are non-decreasing monotone, and new formulations for the general non-monotone DOMP. The main idea in our approach is to express ordered weighted averages as telescopic sums whose terms are k -sums, with positive and negative coefficients. Formulations of k -sums with positive coefficients derive from the linear programming representations obtained by Ogryczack and Tamir (2003) and Blanco, Ali, and Puerto (2014). Valid formulations for k -sums with negative coefficients are more elaborated and we present 4 different approaches, all of them based on mixed integer programming formulations. An extensive computational experience based on a collection of well-known instances shows the usefulness of the new formulations to solve difficult problems such as trimmed and anti-trimmed mean.},
  archive      = {J_EJOR},
  author       = {Alfredo Marín and Diego Ponce and Justo Puerto},
  doi          = {10.1016/j.ejor.2020.04.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {839-848},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fresh view on the discrete ordered median problem based on partial monotonicity},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximating combinatorial optimization problems with the
ordered weighted averaging criterion. <em>EJOR</em>, <em>286</em>(3),
828–838. (<a href="https://doi.org/10.1016/j.ejor.2020.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with combinatorial optimization problems with K cost scenarios, inducing K linear objectives. The popular Ordered Weighted Averaging (OWA) criterion is used to aggregate the objectives and compute a solution. It is well-known that minimizing OWA for most basic combinatorial problems is weakly NP-hard even if the number of scenarios K equals two, and strongly NP-hard when K is a part of the input. In this paper, the problem with nonincreasing weights in the OWA criterion and a large K is first considered. A method of reducing the number of scenarios, by appropriately aggregating the costs before solving the problem, is proposed. It is shown that an optimal solution to the reduced problem has a guaranteed worst-case approximation ratio. Some new approximation results for the Hurwicz criterion, which is a special case of OWA, are also presented.},
  archive      = {J_EJOR},
  author       = {André Chassein and Marc Goerigk and Adam Kasperski and Paweł Zieliński},
  doi          = {10.1016/j.ejor.2020.04.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {828-838},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximating combinatorial optimization problems with the ordered weighted averaging criterion},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branch-relax-and-check: A tractable decomposition method for
order acceptance and identical parallel machine scheduling.
<em>EJOR</em>, <em>286</em>(3), 811–827. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model and solve an order acceptance and scheduling problem in an identical parallel machine setting. The goal is to maximize profit by making four decisions: (i) accept or reject an order, (ii) assign accepted orders to identical parallel machines, (iii) sequence accepted orders, and (iv) schedule order starting times. First , we develop a mixed-integer model that simultaneously optimizes the above four decisions. We enhance the model with pre-processing techniques, valid inequalities, and dominance rules. Second , we show that the model has a special structure that allows us to develop both classical and combinatorial Benders decomposition. We thus develop a classical Benders decomposition approach and two combinatorial Benders variants: (i) logic-based Benders decomposition and (ii) Branch-Relax-and-Check (BRC). The BRC, as the primary contribution of this paper, extends the literature in three ways: (1) it incorporates novel sequencing sub-problem relaxations that expedite convergence, (2) it employs a novel cutting-plane partitioning procedure that allows these sub-problem relaxations to be separately optimized outside the master problem, and (3) it uses temporary Benders cuts that communicate sub-problem relaxation solutions to the master problem. Third , we demonstrate that the BRC outperforms significantly other methods and finds integer feasible solutions for 100\% of instances, guarantees optimality in 50\% of instances, and achieves an average optimality gap of 3.20\% within our time limit.},
  archive      = {J_EJOR},
  author       = {Bahman Naderi and Vahid Roshanaei},
  doi          = {10.1016/j.ejor.2019.10.014},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {811-827},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Branch-relax-and-check: A tractable decomposition method for order acceptance and identical parallel machine scheduling},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Passenger demand forecasting in scheduled transportation.
<em>EJOR</em>, <em>286</em>(3), 797–810. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this review article is to provide a synoptic and critical evaluation of the extensive research that has been performed in demand forecasting in the scheduled passenger transportation industry, specifically in the last few decades. The review begins with an attempt to classify and tabulate the research according to the properties of proposed models, their objectives and application areas in industry in different stages of the planning cycle. This is followed by an assessment of forecast methodologies with suggestions on different methodologies that industry practitioners can adopt to suit their specific needs and recommendations towards future directions of research. We also provide a look into the cross cutting concerns that need to be addressed by all forecasting systems irrespective of the domain or planning stage, such as demand unconstraining, aggregation and the role of expert judgement to incorporate the effect of other extraneous factors that might affect the demand. We conclude from our study that there is a lack of standardization in the way in which methods are described and tested. As a result, there is a lack of cumulative knowledge building. To redress this concern, we propose open source testbeds to facilitate benchmarking of new models. We also propose a checklist as a guideline to standardize the research reports and suggest that when proposing newer models, researchers may consider including a comparative study with existing standard models in research report.},
  archive      = {J_EJOR},
  author       = {Nilabhra Banerjee and Alec Morton and Kerem Akartunalı},
  doi          = {10.1016/j.ejor.2019.10.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {797-810},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Passenger demand forecasting in scheduled transportation},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Corrigendum to “empirical orthogonal constraint generation
for multidimensional 0/1 knapsack problems.” <em>EJOR</em>,
<em>286</em>(2), 791–795. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This corrigendum presents corrected results regarding computational times, objective values and intrinsic dimensionalities reported in Section 5 (Computational Evaluation Design) of the above referenced manuscript and revises conclusions drawn from the section. While we are confident that the manuscript’s primary contribution, the mathematical derivation of the EOCG model, is correct and EOCG has been correctly implemented, errors in the code used to control the computational analysis and to capture and aggregate results led to the incorrect results reported in Section 5 of the referenced manuscript.},
  archive      = {J_EJOR},
  author       = {Thomas Setzer and Sebastian M. Blanc},
  doi          = {10.1016/j.ejor.2019.12.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {791-795},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “Empirical orthogonal constraint generation for multidimensional 0/1 knapsack problems”},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competitive search in a network. <em>EJOR</em>,
<em>286</em>(2), 781–790. (<a
href="https://doi.org/10.1016/j.ejor.2020.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the classic problem in which a Searcher must locate a hidden point, also called the Hider in a network, starting from a root point. The network may be either bounded or unbounded, thus generalizing well-known settings such as linear and star search. We distinguish between pathwise search, in which the Searcher follows a continuous unit-speed path until the Hider is reached, and expanding search, in which, at any point in time, the Searcher may restart from any previously reached point. The former has been the usual paradigm for studying search games, whereas the latter is a more recent paradigm that can model real-life settings such as hunting for a fugitive, demining a field, or search-and-rescue operations. We seek both deterministic and randomized search strategies that minimize the competitive ratio , namely the worst-case ratio of the Hider’s discovery time, divided by the length of the shortest path to it from the root. Concerning expanding search, we show that a simple search strategy that applies a “waterfilling” principle has optimal deterministic competitive ratio; in contrast, we show that the optimal randomized competitive ratio is attained by fairly complex strategies even in a very simple network of three arcs. Motivated by this observation, we present and analyze an expanding search strategy that is a 5 4 54 -approximation of the randomized competitive ratio. Our approach is also applicable to pathwise search, for which we give a strategy that is a 5-approximation of the randomized competitive ratio, and which improves upon strategies derived from previous work.},
  archive      = {J_EJOR},
  author       = {Spyros Angelopoulos and Thomas Lidbetter},
  doi          = {10.1016/j.ejor.2020.04.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {781-790},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive search in a network},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Opening the “black box” of environmental production
technology in a nonparametric analysis. <em>EJOR</em>, <em>286</em>(2),
769–780. (<a href="https://doi.org/10.1016/j.ejor.2020.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to rapid economic development, environmental pollution has become an increasingly serious issue for achieving sustainable economic growth. Appropriate measures of environmental efficiency are crucial for policy makers in order to balance economic and social development in line with constructing a more sustainable society. However, existing environmental efficiency measures suffer from shortcomings inherent in each methodology. To overcome these shortcomings, in this paper, a new environmental production technology is first proposed. We then we show that the weak-G disposability model, the by-production model and the natural/managerial disposability model are the environmental efficiency models based on special cases of our proposed environmental production technology. Next, based on the proposed environmental production technology, a new by-production model is developed. We explore its economic implications and clarify its advantages over existing environmental efficiency models. Finally, an empirical analysis of China&#39;s thermal power industry is conducted in order to illustrate the advantages and the applicability of our proposed approach.},
  archive      = {J_EJOR},
  author       = {Lei Fang},
  doi          = {10.1016/j.ejor.2020.03.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {769-780},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Opening the “black box” of environmental production technology in a nonparametric analysis},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Portfolio diversification based on stochastic dominance
under incomplete probability information. <em>EJOR</em>,
<em>286</em>(2), 755–768. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying efficient portfolio diversification strategies subject to stochastic dominance (SD) criteria usually assumes that the state-space of future asset returns can be captured by a fixed sample of equally probable historical returns. This paper relaxes this assumption by developing SD criteria under incomplete information on state probabilities. Specifically, we identify portfolios that dominate a given benchmark for any state probabilities in a given set. The proposed approach is applied to analyze if industrial diversification can be utilized to outperform the market portfolio. The results from this application demonstrate that the use of set-valued state probabilities can help to improve out-of-sample performance of SD-based portfolio optimization.},
  archive      = {J_EJOR},
  author       = {Juuso Liesiö and Peng Xu and Timo Kuosmanen},
  doi          = {10.1016/j.ejor.2020.03.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {755-768},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Portfolio diversification based on stochastic dominance under incomplete probability information},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Let’s meet as usual: Do games played on non-frequent days
differ? Evidence from top european soccer leagues. <em>EJOR</em>,
<em>286</em>(2), 740–754. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Balancing the allocation of games in sports competitions is an important organizational task that can have serious financial consequences. In this paper, we examine data from 10,142 soccer games played in the top German, Spanish, French, and English soccer leagues between 2007/2008 and 2016/2017. Using a machine learning technique for variable selection and applying a semi-parametric analysis of radius matching on the propensity score, we find that all four leagues have a lower attendance in games that take place on four non-frequently played days than those on three frequently played days. We also find that, in all leagues, there is a significantly lower home advantage for the underdog teams on non-frequent days. Our findings suggest that the current schedule favors underdog teams with fewer home games on non-frequent days. Therefore, to increase the fairness of the competitions, it is necessary to adjust the allocation of the home games on non-frequent days in a way that eliminates any advantage driven by the schedule. These findings have implications for the stakeholders of the leagues, referees’ and calendar committees as well as for coaches and players.},
  archive      = {J_EJOR},
  author       = {Daniel Goller and Alex Krumer},
  doi          = {10.1016/j.ejor.2020.03.062},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {740-754},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Let&#39;s meet as usual: Do games played on non-frequent days differ? evidence from top european soccer leagues},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Government subsidies for green technology development under
uncertainty. <em>EJOR</em>, <em>286</em>(2), 726–739. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the government’s subsidy design problem for firms’ green technology development in an evolving industry and the subsidy’s impact on environment and social welfare. Without subsidy, social welfare may either increase or decrease as more firms enter the industry over time, depending on the environmental benefit of the green technology. However, when the government provides a subsidy for green technology development, social welfare is always improved as the industry evolves. Furthermore, the optimal subsidy level is not affected by the firms’ technological efficiency. Interestingly, if the government only considers the environmental benefits of the technology and its costs, the subsidy policy may be detrimental to the environment, compared to the case where social welfare is considered for decision making. We derive further insights into the government’s subsidy policy, and its role in firms’ technology development decisions, and social welfare under different industry environments.},
  archive      = {J_EJOR},
  author       = {Seung Hwan Jung and Tianjun Feng},
  doi          = {10.1016/j.ejor.2020.03.047},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {726-739},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Government subsidies for green technology development under uncertainty},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A recursive simulation-optimization framework for the
ambulance location and dispatching problem. <em>EJOR</em>,
<em>286</em>(2), 713–725. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the Ambulance Location and Dispatching Problem (ALDP), which jointly determines the location of available ambulances and their dispatching policy. The latter takes the form of a dispatching list that defines, for each zone of the covered territory, an ordered list providing a hierarchy of ambulances to be chosen whenever a call arrives. While decisions concerning the ambulance locations are of a tactical nature and often based on static information (i.e. average demand), ambulance dispatching is a real-time decision that must take into consideration the current state of the system (i.e. busy and idle ambulances) when selecting the ambulance to respond to the incoming emergency call. Although only few works have considered these two decisions jointly, they all conclude that the system’s performance can be improved and the fleet management decisions streamlined by doing so. However, one of the challenges of the ALDP lies in the estimation of the ambulance availability, which has been addressed in previous papers by means of queueing approaches. In this paper, we propose a recursive simulation-optimization framework which encompasses a mathematical formulation for the ALDP and a discrete event simulation model that produces both empirical estimations of the ambulance availability and the system’s performance. Extensive numerical experiments on a set of realistic instances show the potential of the proposed approach as an effective tool for dealing with EMS decision-making.},
  archive      = {J_EJOR},
  author       = {V. Bélanger and E. Lanzarone and V. Nicoletta and A. Ruiz and P. Soriano},
  doi          = {10.1016/j.ejor.2020.03.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {713-725},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A recursive simulation-optimization framework for the ambulance location and dispatching problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calculating the relative importance of condition attributes
based on the characteristics of decision rules and attribute reducts:
Application to crowdfunding. <em>EJOR</em>, <em>286</em>(2), 689–712.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdfunding is the practice of funding a project or venture by raising monetary contributions from a large number of people, typically via the Internet. Lendwithcare is amongst the first crowdfunding platforms specifically dedicated to support individual and group entrepreneurs in developing countries through partner microfinance institutions. A key objective of Lendwithcare is to identify the attributes (i.e., the characteristics of crowdfunding projects in their online descriptions) that affect investors/potential investors when taking their investment decision. This paper proposes a decision rule-based approach to address this issue. This approach relies on the Dominance-Based Rough Approach (DRSA), which is a well-known multicriteria sorting method. The outputs of DRSA are a collection of if-then decision rules and a collection of attribute reducts. In this paper, new measures are proposed for calculating the relative importance of condition attributes based on the characteristics of decision rules and of attribute reducts. Decision rule-based measures are parameterised in order to consider the characteristics of decision rules using both learning and testing datasets. The proposed measures can be aggregated into a comprehensive measure indicating the overall importance of each condition attribute. Furthermore, the proposed measures are extended in order to compute the relative importance of a collection of condition attributes taken together. In addition, decision rule-based measures are extended to evaluate the relative importance of specific values of condition attributes. The proposed approach has been applied and validated using real-world data from Lendwithcare.},
  archive      = {J_EJOR},
  author       = {Salem Chakhar and Alessio Ishizaka and Andy Thorpe and Joe Cox and Thang Nguyen and Liz Ford},
  doi          = {10.1016/j.ejor.2020.03.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {689-712},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Calculating the relative importance of condition attributes based on the characteristics of decision rules and attribute reducts: Application to crowdfunding},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic thompson sampling hyper-heuristic framework for
learning activity planning in personalized learning. <em>EJOR</em>,
<em>286</em>(2), 673–688. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized learning is emerging in schools as an alternative to one-size-fits-all education. This study introduces and explores a weekly demand-driven flexible learning activity planning problem of own-pace own-method personalized learning. The introduced problem is a computationally intractable optimization problem involving many decision dimensions and also many soft constraints. We propose batch and decomposition methods to generate good-quality initial solutions and a dynamic Thompson sampling based hyper-heuristic framework, as a local search mechanism, which explores the large solution space of this problem in an integrative way. The characteristics of our test instances comply with average secondary schools in the Netherlands and are based on expert opinions and surveys. The experiments, which benchmark the proposed heuristics against Gurobi MIP solver on small instances, illustrate the computational challenge of this problem numerically. According to our experiments, the batch method seems quicker and also can provide better quality solutions for the instances in which resource levels are not scarce, while the decomposition method seems more suitable in resource scarcity situations. The dynamic Thompson sampling based online learning heuristic selection mechanism is shown to provide significant value to the performance of our hyper-heuristic local search. We also provide some practical insights; our experiments numerically demonstrate the alleviating effects of large school sizes on the challenge of satisfying high-spread learning demands.},
  archive      = {J_EJOR},
  author       = {Ayse Aslan and Ilke Bakir and Iris F.A. Vis},
  doi          = {10.1016/j.ejor.2020.03.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {673-688},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic thompson sampling hyper-heuristic framework for learning activity planning in personalized learning},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-objective optimization-simulation approach for real
time rescheduling in dense railway systems. <em>EJOR</em>,
<em>286</em>(2), 662–672. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rescheduling trains in dense railway systems to cope in real time with limited disturbances is a challenging problem with multiple conflicting objectives and various types of decisions. Based on the French railway system in the Paris region, this paper proposes an approach combining multi-objective optimization, to select rescheduling decisions, and macroscopic simulation, to compute the objectives associated to these decisions. Possible decisions include canceling or short-turning trains and skipping or adding stops. Three main objectives are optimized to propose multiple solutions to the decision makers: The recovery time, the quality of service for passengers and the number of decisions. Two greedy heuristics are presented whose results on actual data are compared with a full enumeration method. The multi-objective feature of the approach is also analyzed. The implementation and successful validation in real life of a decision-support tool, that is now implemented, is discussed.},
  archive      = {J_EJOR},
  author       = {Estelle Altazin and Stéphane Dauzère-Pérès and François Ramond and Sabine Tréfond},
  doi          = {10.1016/j.ejor.2020.03.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {662-672},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective optimization-simulation approach for real time rescheduling in dense railway systems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Theory and statistical properties of quantile data
envelopment analysis. <em>EJOR</em>, <em>286</em>(2), 649–661. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes Quantile Data Envelopment Analysis (qDEA) as a procedure that accounts for the sensitivity of Data Envelopment Analysis (DEA) to data or firm outliers when using DEA to estimate comparative efficiency or benchmarking performance metrics. The qDEA methodology endogenously identifies the distance to a qDEA- α hyperplane while allowing up to proportion q = 1 - α of the data observations to lie external to the qDEA- α hyperplane. The ability of qDEA to provide more conventional quantile-based benchmarking information is discussed. The statistical properties of the qDEA estimator are examined utilizing nCm subsampling and Monte Carlo procedures. Monte Carlo simulations indicate that qDEA distance estimates share the desirable root-n convergence and large sample normality properties of the robust Free Disposal Hull (FDH) based order-m and order- α estimators.},
  archive      = {J_EJOR},
  author       = {Joseph Atwood and Saleem Shaik},
  doi          = {10.1016/j.ejor.2020.03.077},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {649-661},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Theory and statistical properties of quantile data envelopment analysis},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group contributions in TU-games: A class of k-lateral
shapley values. <em>EJOR</em>, <em>286</em>(2), 637–648. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce the notion of group contributions in TU-games and propose a new class of values which we call the class of k -lateral Shapley values. Most of the values for TU-games implicitly assume that players are independent in deciding to leave or join a coalition. However, in many real life situations players are bound by the decisions taken by their peers. This leads to the idea of group contributions where we consider the marginality of groups upto a certain size. We show that group contributions can play an important role in determining players’ shares in the total resource they generate. The proposed value has the flavor of egalitarianism within group contributions. We provide two characterizations of our values.},
  archive      = {J_EJOR},
  author       = {Surajit Borkotokey and Dhrubajit Choudhury and Loyimee Gogoi and Rajnish Kumar},
  doi          = {10.1016/j.ejor.2020.03.054},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {637-648},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Group contributions in TU-games: A class of k-lateral shapley values},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient allocation of resources to a portfolio of decision
making units. <em>EJOR</em>, <em>286</em>(2), 619–636. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency analysis is widely employed to evaluate decision making units (DMUs) which convert input resources into outputs. In this paper, we develop models for allocating these resources to DMUs in order to maximize the overall efficiency of the portfolio formed by these DMUs. Our models do not require complete preference information about how valuable the inputs and outputs are relative to each other. Rather, based on incomplete preference information and explicit assumptions about the DMUs’ production possibilities, they determine all efficient DMUs portfolios which are then analyzed to provide robust decision recommendations on how much resources should be allocated to each DMU. We illustrate our models by revisiting earlier case studies and show that the use of conventional efficiency analysis in guiding resource allocation decisions can cause inefficiencies.},
  archive      = {J_EJOR},
  author       = {Juuso Liesiö and Juho Andelmin and Ahti Salo},
  doi          = {10.1016/j.ejor.2020.03.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {619-636},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Efficient allocation of resources to a portfolio of decision making units},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal unbiased estimation for expected cumulative
discounted cost. <em>EJOR</em>, <em>286</em>(2), 604–618. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider estimating an expected infinite-horizon cumulative discounted cost/reward contingent on an underlying stochastic process by Monte Carlo simulation. An unbiased estimator based on truncating the cumulative cost at a random horizon is proposed. Explicit forms for the optimal distributions of the random horizon are given, and explicit expressions for the optimal random truncation level are obtained, leading to a full analysis of the bias-variance tradeoff when comparing this new class of randomized estimators with traditional fixed truncation estimators. Moreover, we characterize when the optimal randomized estimator is preferred over a fixed truncation estimator by considering the tradeoff between bias and variance. This comparison provides guidance on when to choose randomized estimators over fixed truncation estimators in practice. Numerical experiments substantiate the theoretical results.},
  archive      = {J_EJOR},
  author       = {Zhenyu Cui and Michael C. Fu and Yijie Peng and Lingjiong Zhu},
  doi          = {10.1016/j.ejor.2020.03.072},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {604-618},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal unbiased estimation for expected cumulative discounted cost},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic bisection with spatial metamodels.
<em>EJOR</em>, <em>286</em>(2), 588–603. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic Bisection Algorithms perform root finding based on knowledge acquired from noisy oracle responses. We consider the generalized PBA setting (G-PBA) where the statistical distribution of the oracle is unknown and location-dependent, so that model inference and Bayesian knowledge updating must be performed simultaneously. To this end, we propose to leverage the spatial structure of a typical oracle by constructing a statistical surrogate for the underlying logistic regression step. We investigate several surrogates, including Binomial Gaussian Processes (B-GP), Polynomial, Kernel, and Spline Logistic Regression. In parallel, we develop sampling policies that adaptively balance learning the oracle distribution and learning the root. One of our proposals mimics active learning with B-GPs and provides a novel look-ahead predictive variance formula. The resulting gains of our Spatial PBA algorithm relative to earlier G-PBA models are illustrated with synthetic examples and a challenging stochastic root finding problem from Bermudan option pricing.},
  archive      = {J_EJOR},
  author       = {Sergio Rodriguez and Michael Ludkovski},
  doi          = {10.1016/j.ejor.2020.03.049},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {588-603},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Probabilistic bisection with spatial metamodels},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Balancing producer and consumer risks in optimal attribute
testing: A unified bayesian/frequentist design. <em>EJOR</em>,
<em>286</em>(2), 576–587. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unified Bayesian/frequentist approaches for the design of attributes sampling plans are introduced by minimizing and limiting a weighted-average of the classical or expected producer and consumer risks adopted by the decision maker. This change of paradigm in the construction of test plans for lot acceptance provides optimal inspection schemes from both frequentist and Bayesian perspectives. Classes of admissible test plans minimizing the weighted-average risks are first defined. Constrained optimization problems are then solved in order to determine sample sizes with smallest classical or expected weighted-average risks, as well as acceptance test plans with minimal inspection effort and controlled risks. The proposed methodology to determine optimal sample sizes and decision criteria for lot sentencing constitutes a plausible consensus between Frequentists and Bayesians. Moreover, the use of prior information on the fraction defective allows the practitioners to appreciably reduce the required sample size for lot screening. Optimal lot inspection schemes can also be easily updated using past performance of the sampling plans. Besides the advantages the suggested approach has for hypothesis testing, namely large sample consistency and reproducible results, it permits to make a trade-off between the opposite goals of customers and manufacturers. Some applications in reliability demonstration testing and industrial quality control are presented for illustrative purposes.},
  archive      = {J_EJOR},
  author       = {Arturo J. Fernández and Cristian D. Correa-Álvarez and Luis R. Pericchi},
  doi          = {10.1016/j.ejor.2020.03.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {576-587},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Balancing producer and consumer risks in optimal attribute testing: A unified Bayesian/Frequentist design},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The vehicle routing problem with arrival time
diversification on a multigraph. <em>EJOR</em>, <em>286</em>(2),
564–575. (<a href="https://doi.org/10.1016/j.ejor.2020.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency and security are the two major concerns in cash-in-transit transportation planning. Whereas efficiency is generally achieved by finding short routes, security can be improved by generating dissimilar visit patterns. To achieve a good balance between these two objectives, the vehicle routing problem with arrival time diversification (VRPATD) aims to find optimized routing plans, over multiple periods, subject to a minimum difference between visit times at each customer. Since the customer visits are constrained by time windows and no waiting time is allowed en route, the number of feasible solutions is generally limited. To explore a larger set of feasible route options, we propose to consider alternative paths with different distances between visit locations. The resulting multigraph VRPATD better captures the characteristics of urban networks. Moreover, the extra flexibility achieved with the alternative paths helps finding better routing plans while meeting time constraints. To solve this complex problem, we introduce an adaptive large neighborhood search, which exploits piecewise-linear penalty functions for insertion evaluations, efficient local searches, and an adaptive destruction rate. This method produces remarkable results on classical instances for the simple-graph VRPATD. Moreover, our theoretical results and our experiments on real-life instances obtained from an application case in Vienna show that the multigraph problem extension leads to very significant distance savings subject to the same arrival-time diversification constraints.},
  archive      = {J_EJOR},
  author       = {Adria Soriano and Thibaut Vidal and Margaretha Gansterer and Karl Doerner},
  doi          = {10.1016/j.ejor.2020.03.061},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {564-575},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The vehicle routing problem with arrival time diversification on a multigraph},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-dimensional skiving and cutting stock problem with setup
cost based on column-and-row generation. <em>EJOR</em>, <em>286</em>(2),
547–563. (<a href="https://doi.org/10.1016/j.ejor.2020.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a new variant of the cutting stock problem, in which skiving is allowed and setup costs are considered. Specifically, the output sheets are generally longer but narrower than the input coils. To satisfy the demand of each sheet, combining two or more coils is allowed. Moreover, because changing from one pattern to another involves considerable time and cost, minimizing the number of different patterns or setups is vital. Thus, the objective of our study is to minimize the material cost and the number of setups. We propose an integer programming (IP) formulation for the problem that contains an exponential number of binary variables and column-dependent constraints. The linear programming (LP) relaxation is solved using a column-and-row generation framework that involves a knapsack subproblem and a nonlinear IP subproblem. For the latter, we propose a decomposition-based exact solution method with pseudo-polynomial time. To obtain IP solutions, we develop a diving heuristic based on matching level. The computational experiments show that these algorithms are efficient and of high quality.},
  archive      = {J_EJOR},
  author       = {Danni Wang and Fan Xiao and Lei Zhou and Zhe Liang},
  doi          = {10.1016/j.ejor.2020.03.060},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {547-563},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two-dimensional skiving and cutting stock problem with setup cost based on column-and-row generation},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Steady-state imperfect repair models. <em>EJOR</em>,
<em>286</em>(2), 538–546. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imperfect maintenance models are widely used in reliability engineering. This paper discusses relevant asymptotic properties for the steady-state virtual age processes. It is shown that the limiting distributions of age, the residual lifetime and the spread that describe an ordinary renewal process can be generalized to the stable virtual age process, although the cycles of the latter are not independent. Asymptotic distributions of the virtual age at time t , as well as of the virtual ages at the start and the end of a cycle containing t (as t tends to infinity) are explicitly derived for two popular in practice imperfect maintenance models, namely, the Arithmetic Reduction of Age (ARA) and the Brown–Proschan (BP) models. Some applications of the obtained results to maintenance optimization are discussed.},
  archive      = {J_EJOR},
  author       = {Xingheng Liu and Maxim Finkelstein and Jørn Vatn and Yann Dijoux},
  doi          = {10.1016/j.ejor.2020.03.057},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {538-546},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Steady-state imperfect repair models},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A benders decomposition-based approach for logistics service
network design. <em>EJOR</em>, <em>286</em>(2), 523–537. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an exact solution method for a Logistics Service Network Design Problem (LSNDP) inspired by the management of restaurant supply chains. In this problem, a distributor seeks to source and fulfill customer orders of products (fruits, meat, napkins, etc.) through a multi-echelon distribution network consisting of supplier locations, warehouses, and customer locations in a cost-effective manner. As these products are small relative to vehicle capacity, an effective strategy for achieving low transportation costs is consolidation. Specifically, routing products so that vehicles transport multiple products at a time, with each product potentially sourced by a different supplier and destined for a different customer. As instances of this problem of sizes relevant to the operations of an industrial partner are too large for off-the-shelf optimization solvers, we propose a suite of techniques for enhancing a Benders decomposition-based algorithm, including a strengthened master problem, valid inequalities, and a heuristic. Together, these enhancements enable the resulting method to produce provably high-quality solutions to multiple variants of the problem in reasonable run-times.},
  archive      = {J_EJOR},
  author       = {Simon Belieres and Mike Hewitt and Nicolas Jozefowiez and Frédéric Semet and Tom Van Woensel},
  doi          = {10.1016/j.ejor.2020.03.056},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {523-537},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A benders decomposition-based approach for logistics service network design},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing the selection and scheduling of multi-class
projects using a stackelberg framework. <em>EJOR</em>, <em>286</em>(2),
508–522. (<a href="https://doi.org/10.1016/j.ejor.2020.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major causes of non-recurrent traffic congestion in urban areas is the implementation of transport infrastructure projects on city roads. The seeming ubiquity of work zones in cities causes road user frustration and safety hazards, and public relations problems for the transport agency. For this reason, transport agencies seek strategic ways to not only select urban projects but also schedule them in a manner that minimizes the effort associated with these functions. In other words, they seek to exploit the synergies between the tasks of project selection and project scheduling while duly accommodating the project interdependencies. This study introduces a general framework that simultaneously and optimally selects and schedules urban road projects subject to budgetary constraints over a given planning horizon. The project classes considered in this study are lane addition, new road construction, and road maintenance. Through a mimicry of the classic Stackelberg leader-follower game, this problem is formulated herein as a bi-level program. In the upper level, the leader (transport agency decision-makers) determines an optimal set of projects from a larger pool of candidate projects and decides an optimal schedule for their implementation. In the lower level, the followers (road users) seek to minimize their travel delays based on the two decisions made by the leader in the upper level. The numerical experiments show that if the decision-makers do not consider the peri-implementation capacity reduction, the resulting set of selected projects and their construction schedule can lead to significant travel delay cost for the road users.},
  archive      = {J_EJOR},
  author       = {Mohammad Miralinaghi and Sania E. Seilabi and Sikai Chen and Yu-Ting Hsu and Samuel Labi},
  doi          = {10.1016/j.ejor.2020.03.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {508-522},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing the selection and scheduling of multi-class projects using a stackelberg framework},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic location of modular manufacturing facilities with
relocation of individual modules. <em>EJOR</em>, <em>286</em>(2),
494–507. (<a href="https://doi.org/10.1016/j.ejor.2020.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meeting highly variable product demands in a cost-efficient manner is an essential task for the chemical industry. Small-scale, modular, and mobile production units allow for a more agile response to spacial and temporal changes in demand while reducing the need of building new units. In this work, we present a generic mixed-integer linear programming (MILP) framework for determining optimal location and relocation of mobile production modules given time-varying demands. We introduce a new metric, the value of module mobility, to quantify the economic benefits of mobile production modules, and we demonstrate how it changes as a function of various economic parameters. Moreover, multiple different solution methods are developed to solve large instances of this dynamic modular and mobile facility location problem. First, we reformulate the original MILP by adding auxiliary variables which track the numbers of modules active at each site at any given time. This augmented formulation can be solved either directly using an off-the-shelf MILP solver, using the same solver but with priority branching on the auxiliary variables, or applying a branch-and-price algorithm. In the proposed branch-and-price algorithm, pricing subproblems for different time periods are solved separately and in parallel to generate new columns for the restricted master problem. Results from an extensive computational study show that solving the full-space augmented formulation is best when the number of time periods is small; however, the branch-and-price algorithm becomes superior for instances with a large number of time periods.},
  archive      = {J_EJOR},
  author       = {Andrew Allman and Qi Zhang},
  doi          = {10.1016/j.ejor.2020.03.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {494-507},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic location of modular manufacturing facilities with relocation of individual modules},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary driver-customer familiarity in service routing.
<em>EJOR</em>, <em>286</em>(2), 477–493. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a growing number of services provided at or to a customer’s home, the familiarity of the service provider, or driver, with the customer’s location is increasingly important. One prominent example is retail distribution, where familiarity with the delivery location can save the driver time. In contrast to other kinds of familiarity (e.g., tasks, customer needs) that continually increase with a larger number of repetitions, location familiarity is primarily established with a driver’s first visit. Thus, familiarity results from operational routing decisions. However, as we show in this paper, there is potential value in considering the tactical value of familiarity and its development over a longer horizon. To this end, we develop and solve a tactical model to specify the long-term implications of improved driver-customer familiarity, introducing a solution methodology for the stochastic and dynamic multi-period routing problem with driver-customer familiarity. Our methodology utilizes a policy that explicitly invests in the familiarity between selected driver-customer pairs, encouraging the development of pairs that are tactically beneficial. We determine the appropriate investment dimensions for each pair, considering which locations a driver has visited and how many drivers have visited a location. We show that under the problem conditions tested this investment policy leads to a reduction in cost compared to a short term, myopic policy, while increasing the overall level of familiarity between drivers and customers and hedging against driver or customer turnover. We also find that focusing only on routing or on exploiting existing familiarity leads to substantial increases in cost.},
  archive      = {J_EJOR},
  author       = {Marlin Ulmer and Maciek Nowak and Dirk Mattfeld and Bogumił Kaminski},
  doi          = {10.1016/j.ejor.2020.03.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {477-493},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Binary driver-customer familiarity in service routing},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An o(n2) algorithm for time-bound adjustments for the
cumulative scheduling problem. <em>EJOR</em>, <em>286</em>(2), 468–476.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energetic Reasoning (ER) is one of the most powerful methods for efficient cumulative scheduling. It computes destructive bounds and adjustments of task time intervals. ER is not commonly used in practice due to its time complexity, and its efficiency is highly dependent on the tightness of the time intervals. Here, we present a new algorithm with a better complexity than previous algorithms for speeding up time bound adjustments. More precisely, we show how to reduce the complexity of heads and tails adjustments from O ( n 2 log n ) to O ( n 2 ), which is an important theoretical advance.},
  archive      = {J_EJOR},
  author       = {J. Carlier and E. Pinson and A. Sahli and A. Jouglet},
  doi          = {10.1016/j.ejor.2020.03.079},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {468-476},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An o(n2) algorithm for time-bound adjustments for the cumulative scheduling problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding the largest triangle in a graph in expected
quadratic time. <em>EJOR</em>, <em>286</em>(2), 458–467. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding the largest triangle in an n -nodes edge-weighted graph belongs to a set of problems all equivalent under subcubic reductions. Namely, a truly subcubic algorithm for any one of them would imply that they are all subcubic. A recent strong conjecture states that none of them can be solved in less than Θ( n 3 ) time, but this negative result does not rule out the possibility of algorithms with average, rather than worst-case, subcubic running time. Indeed, in this work we describe the first truly-subcubic average complexity procedure for this problem for graphs whose edge lengths are uniformly distributed in [0,1]. Our procedure finds the largest triangle in average quadratic time, which is the best possible complexity of any algorithm for this problem. We also give empirical evidence that the quadratic average complexity holds for many other random distributions of the edge lengths. A notable exception is when the lengths are distances between random points in Euclidean space, for which the algorithm takes average cubic time.},
  archive      = {J_EJOR},
  author       = {Giuseppe Lancia and Paolo Vidoni},
  doi          = {10.1016/j.ejor.2020.03.059},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {458-467},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Finding the largest triangle in a graph in expected quadratic time},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing maximum cost for a single machine under
uncertainty of processing times. <em>EJOR</em>, <em>286</em>(2),
444–457. (<a href="https://doi.org/10.1016/j.ejor.2020.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most known results in the machine scheduling is Lawler’s algorithm to minimize the maximum cost of jobs processed by a single machine subject to precedence constraints. We consider an uncertain version of the same min-max cost scheduling problem. The cost function of each job depends on the job completion time and on an additional generalized numerical parameter, which may be a tuple of parameters. For each job, both, its processing time and the additional parameter are uncertain, only intervals of possible values of these parameters are known. We analyse certain classes of cost functions and develop polynomial algorithms which construct min-max regret solutions. The considered problems cover the most general range of studied cases of interval uncertainty. In the only two papers that present algorithms for minimizing the maximum regret for the problem with uncertain job processing times, the algorithms are based on extremal scenarios, where some uncertain parameters take their maximum values, while all others take their minimum possible values. We show that it is impossible to always limit the search to extremal scenarios. Our approach is based on new ideas different from those underlying previous work. Finally, we show that our approach outperforms all known results for constructing min-max regret solutions for the min-max cost scheduling problem under uncertainty of job processing times.},
  archive      = {J_EJOR},
  author       = {Ilia Fridman and Erwin Pesch and Yakov Shafransky},
  doi          = {10.1016/j.ejor.2020.03.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {444-457},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing maximum cost for a single machine under uncertainty of processing times},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A truncated column generation algorithm for the parallel
batch scheduling problem to minimize total flow time. <em>EJOR</em>,
<em>286</em>(2), 432–443. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a column generation based decomposition method for the parallel batch scheduling of jobs on identical parallel machines. Jobs have different release dates, processing times and sizes while machines have limited capacity. The objective is the minimization of total flow time, i.e., sum of completion times of all processed jobs. The straightforward mixed integer linear programming model of the problem is efficient for small size instances. To deal with larger instances, we develop a time indexed column generation model in which each column represents the set of jobs processed together in the same batch and the time instant for the beginning of batch processing. We obtain approximate solutions with a rounding technique followed by another mathematical model to schedule batches on machines. Numerical test results show that the proposed model is able to return high quality solutions within short computation times.},
  archive      = {J_EJOR},
  author       = {Onur Ozturk},
  doi          = {10.1016/j.ejor.2020.03.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {432-443},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A truncated column generation algorithm for the parallel batch scheduling problem to minimize total flow time},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A beam search algorithm for the biobjective container
loading problem. <em>EJOR</em>, <em>286</em>(2), 417–431. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we deal with a biobjective variant of the single container loading problem. The problem consists in packing a set of boxes into a large box or container. In addition to the usual objective related to maximize the volume utilization, we include a second objective consisting on maximizing the total profit (e.g., weight or priority) of the loaded boxes. We propose to adapt bsg , a state-of-the-art single-objective algorithm for solving the biobjective problem. bsg can be seen as an incomplete version of a breadth first search in which each level of the search tree is restricted to a fixed number of promising nodes. In order to select the most promising nodes, the algorithm constructs a solution from them by using a greedy algorithm and evaluates the objectives. To deal with two objectives, we propose to select nodes by using well-known multi-objective criteria based on dominance and crowding distance related to the greedy evaluations. We go a little bit further and orient the greedy algorithm to one objective or the other by using a mechanism which changes the configuration of the heuristic function dynamically. The proposal is compared with bsg in a set of well-known instances reporting a 24\% increase in the hypervolume indicator. Compared to other biobjective approaches, the reported results are also promising. Codes and test instances are available in: https://github.com/rilianx/Metasolver#bo-bsg},
  archive      = {J_EJOR},
  author       = {Ignacio Araya and Mauricio Moyano and Cristobal Sanchez},
  doi          = {10.1016/j.ejor.2020.03.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {417-431},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A beam search algorithm for the biobjective container loading problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A concise guide to existing and emerging vehicle routing
problem variants. <em>EJOR</em>, <em>286</em>(2), 401–416. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing problems have been the focus of extensive research over the past sixty years, driven by their economic importance and their theoretical interest. The diversity of applications has motivated the study of a myriad of problem variants with different attributes. In this article, we provide a concise overview of existing and emerging problem variants. Models are typically refined along three lines: considering more relevant objectives and performance metrics, integrating vehicle routing evaluations with other tactical decisions, and capturing fine-grained yet essential aspects of modern supply chains. We organize the main problem attributes within this structured framework. We discuss recent research directions and pinpoint current shortcomings, recent successes, and emerging challenges.},
  archive      = {J_EJOR},
  author       = {Thibaut Vidal and Gilbert Laporte and Piotr Matl},
  doi          = {10.1016/j.ejor.2019.10.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {401-416},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A concise guide to existing and emerging vehicle routing problem variants},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A spatial stochastic frontier model with endogenous frontier
and environmental variables. <em>EJOR</em>, <em>286</em>(1), 389–399.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a spatial autoregressive stochastic frontier model, which allows for the endogeneity in both the frontier and environmental variables (i.e., endogeneity due to correlation of inefficiency term and two-sided error term). The model parameters are estimated using a single-stage control function approach. Monte Carlo simulations show that our proposed model and approach perform well in finite samples. We employed our methodology to the Chinese chemicals firm data and found evidence for both spatial effects and endogeneity.},
  archive      = {J_EJOR},
  author       = {Levent Kutlu and Kien C. Tran and Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2020.03.020},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {389-399},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A spatial stochastic frontier model with endogenous frontier and environmental variables},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nonparametric framework to detect outliers in estimating
production frontiers. <em>EJOR</em>, <em>286</em>(1), 375–388. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a large number of organizations, there is an ongoing need to evaluate performance. There is also a need to estimate the production frontier of best performers in such environments. Part of the difficulty in constructing this frontier is that massive amounts of data are generated daily with the result being that the set of best performers is constantly changing. Furthermore, measurement errors can influence datasets as well as the estimation of a production frontier. Outliers can also substantially affect the estimated production frontier. Efforts have been made in the past three decades to deal with datasets that might include such outliers; these methods are mostly semiautomatic or require significant computation time when a large dataset is involved. The few existing research on large datasets also focuses on the computational process of measuring a production frontier without identifying the possible influence of outliers to the estimated frontier. In the current paper, for the first time in the literature of data envelopment analysis (DEA), we develop an automatic framework with the computational capability and accuracy needed when big datasets (with multiple inputs and multiple outputs) are considered. Several examples, simulation experiments, and real-life applications are discussed to demonstrate the power of the proposed framework. A data analysis with illustrative graphs is provided to clearly show the methodology. In terms of estimating the production frontier, the method is robust, user-friendly, and substantially decreases the requirement of user judgment while at the same time allowing for the incorporation of such judgement.},
  archive      = {J_EJOR},
  author       = {Dariush Khezrimotlagh and Wade D. Cook and Joe Zhu},
  doi          = {10.1016/j.ejor.2020.03.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {375-388},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A nonparametric framework to detect outliers in estimating production frontiers},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Manufacturer competition in the nanostore retail channel.
<em>EJOR</em>, <em>286</em>(1), 360–374. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In emerging markets, a significant share of the revenue of Consumer Packaged Goods (CPG) manufacturers comes from the traditional retail channel, composed of millions of independent family-owned nanostores . Nanostore owners typically have limited cash flow and are driven by the modest goal of making a living. It is common practice for manufacturers to dispatch sales representatives to visit nanostores directly in order to drive product sales. We study the sales visit and pricing decisions of manufacturers supplying to a nanostore over an infinite time horizon. We first consider the case of a single manufacturer and show that the manufacturer should price the product such that the nanostore can earn enough to pay for his subsistence spending. Such a supplier-retailer mutual reliance relationship continues to hold for the two-manufacturer model where the manufacturers compete for the nanostore’s cash resources under shelf space limitations. Further, under some conditions, the two manufacturers can mutually benefit, that is, instead of jeopardizing each other through competition, they contribute collectively to satisfy the nanostore family’s subsistence needs such that nanostores are more likely to survive; besides, each can earn more profit than in a single-supplier setting. The results can help us understand the current industry dynamics in this vital sector.},
  archive      = {J_EJOR},
  author       = {Jiwen Ge and Dorothee Honhon and Jan C. Fransoo and Lei Zhao},
  doi          = {10.1016/j.ejor.2020.03.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {360-374},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Manufacturer competition in the nanostore retail channel},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaboration under outcome-based contracts for information
technology services. <em>EJOR</em>, <em>286</em>(1), 350–359. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accelerated expansion of markets and intense competition have motivated firms to collaborate closely with vendor firms by outsourcing critical aspects of the business, including Information Technology services. We analyze the interaction between a service provider and a client in which they collaborate to deliver services. We assume that revenue generated from the service depends on their efforts. The client determines retail price and marketing efforts while the service provider decides on quality improvement efforts in the services. We analyze the impact of revenue share proportion on the effort exerted by both firms and the impact of the capability of the service provider on the retail pricing of the service. We develop an analytical framework to characterize the actions of the service provider and the client.},
  archive      = {J_EJOR},
  author       = {Prakash Awasthy and Jishnu Hazra},
  doi          = {10.1016/j.ejor.2020.03.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {350-359},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Collaboration under outcome-based contracts for information technology services},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing bed occupancy variance by scheduling patients
under uncertainty. <em>EJOR</em>, <em>286</em>(1), 336–349. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of scheduling patients in allocated surgery blocks in a Master Surgical Schedule. We pay attention to both the available surgery blocks and the bed occupancy in the hospital wards. More specifically, large probabilities of overtime in each surgery block are undesirable and costly, while large fluctuations in the number of used beds requires extra buffer capacity and makes the staff planning more challenging. The stochastic nature of surgery durations and length of stay on a ward hinders the use of classical techniques. Transforming the stochastic problem into a deterministic problem does not result into practically feasible solutions. In this paper we develop a technique to solve the stochastic scheduling problem, whose primary objective it to minimize variation in the necessary bed capacity, while maximizing the number of patients operated, and minimizing the maximum waiting time, and guaranteeing a small probability of overtime in surgery blocks. The method starts with solving an Integer Linear Programming (ILP) formulation of the problem, and then simulation and local search techniques are applied to guarantee small probabilities of overtime and to improve upon the ILP solution. Numerical experiments applied to a Dutch hospital show promising results.},
  archive      = {J_EJOR},
  author       = {Anne van den Broek d’Obrenan and Ad Ridder and Dennis Roubos and Leen Stougie},
  doi          = {10.1016/j.ejor.2020.03.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {336-349},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing bed occupancy variance by scheduling patients under uncertainty},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision making on post-disaster rescue routing problems
from the rescue efficiency perspective. <em>EJOR</em>, <em>286</em>(1),
321–335. (<a href="https://doi.org/10.1016/j.ejor.2020.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of emergency responses is at the heart of post-disaster rescue routing problems. Previous rescue models address the efficiency issue primarily by minimizing the total travel time, while not taking into account other significant factors in the rescue process, such as the number of affected people and the degree of building damage. To overcome these shortcomings, this paper aims to solve the rescue routing problem by maximizing the arc-based rescue efficiency, which is redefined as the ratio between the primary rescue input and output factors to represent the efficiency of the rescue operations. Therefore, a systematic methodology is proposed to decompose the original rescue routing problem into two decision making phases. First, an extended data envelopment analysis (DEA) model is constructed to evaluate the rescue efficiency along each arc. Specifically, a group decision constraint cone, which refers to the combined output of a group decision from experts, is constructed to distinguish the features and rescue focus of each disaster. Second, an efficiency-based routing model is developed to determine a feasible rescue tour for the entire transportation network, thus achieving the goal of maximizing the total rescue efficiency. An empirical example of a real earthquake disaster in Wenchuan, China, is provided to demonstrate the novelty and practical capabilities of the proposed approach in post-disaster emergency rescue operations. Finally, a comparison analysis is conducted with the traditional time-oriented routing method, and the results show that the method proposed in this study can improve the rescue performance by 21.2\%.},
  archive      = {J_EJOR},
  author       = {Bingsheng Liu and Jiuh-Biing Sheu and Xue Zhao and Yuan Chen and Wei Zhang},
  doi          = {10.1016/j.ejor.2020.03.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {321-335},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision making on post-disaster rescue routing problems from the rescue efficiency perspective},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). University rankings from the revealed preferences of the
applicants. <em>EJOR</em>, <em>286</em>(1), 309–320. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A methodology is presented to rank universities on the basis of the lists of programmes the students applied for. We exploit a crucial feature of the centralised assignment system to higher education in Hungary: a student is admitted to the first programme where the score limit is achieved. This makes it possible to derive a partial preference order of each applicant. Our approach integrates the information from all students participating in the system, is free of multicollinearity among the indicators, and contains few ad hoc parameters. The procedure is implemented to rank faculties in the Hungarian higher education between 2001 and 2016. We demonstrate that the ranking given by the least squares method has favourable theoretical properties, is robust with respect to the aggregation of preferences, and performs well in practice. The suggested ranking is worth considering as a reasonable alternative to the standard composite indices.},
  archive      = {J_EJOR},
  author       = {László Csató and Csaba Tóth},
  doi          = {10.1016/j.ejor.2020.03.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {309-320},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {University rankings from the revealed preferences of the applicants},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum likelihood solutions for multicriterial choice
problems. <em>EJOR</em>, <em>286</em>(1), 299–308. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the notion of a maximum likelihood optimal decision alternative for the choice problem with a finite set of decision alternatives, assuming a general parametric preference model of the decision maker. We also develop an optimization-based method for the identification of such alternative for the cases in which the parametric preference model is based on uncertain intervals for criterion trade-offs. The suggested approach can be seen as generalising stochastic multicriteria acceptability analysis (SMAA) to a wider modelling setting. It also provides a maximum likelihood interpretation of the SMAA acceptability index.},
  archive      = {J_EJOR},
  author       = {Vladislav V. Podinovski},
  doi          = {10.1016/j.ejor.2020.03.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {299-308},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum likelihood solutions for multicriterial choice problems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multicriteria approach based on rough set theory for the
incremental periodic prediction. <em>EJOR</em>, <em>286</em>(1),
282–298. (<a href="https://doi.org/10.1016/j.ejor.2020.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a Multicriteria Approach for the Incremental Periodic Prediction ( MAI2P ). This approach is periodically applied while considering the sequential evolution of the dynamic information system under the variation of the set of actions in an ever-evolving learning sample. It is based on the Dominance-based Rough Set Approach (DRSA) and consists of three phases. The first aims at constructing a decision table and is based on three steps: (1) constructing a representative learning sample of “Actions of reference”, (2) constructing a coherent criteria family for the actions’ characterization and (3) building a decision table. The second consists in an incremental updating of the DRSA approximations in order to infer a preference model resulting in a set of decision rules. The third consists of classifying the potential actions in one of the predefined decision classes. The first two phases run at the end of the current period and the third phase runs at the beginning of the next period. The approach MAI2P has been applied in the context of Massive Open Online Courses (MOOCs). It has been validated on a French MOOC proposed by a Business School in France. Experiments showed that the pessimistic cumulative approach gives the most efficient preference model with an F-measure and an accuracy values reaching 0.66 and 0.89 respectively.},
  archive      = {J_EJOR},
  author       = {Sarra Bouzayane and Inès Saad},
  doi          = {10.1016/j.ejor.2020.03.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {282-298},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multicriteria approach based on rough set theory for the incremental periodic prediction},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When less is more: Recovery technology investment and
segmentation for uptime-centered services. <em>EJOR</em>,
<em>286</em>(1), 267–281. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the interplay between technology cost and consumer heterogeneity when a supplier optimizes an uptime-centered service portfolio and its operation schedule simultaneously. In the model, the supplier serves customers segmented by heterogeneous valuations for uptime with pooled capacity. The supplier needs to invest in failure recovery technology to increase the failure recovery rate and provide differentiated uptime levels to customers in different segments. If the customers’ preference is unobservable, customer self-selection has to be enforced and cannibalization can be an issue due to information asymmetry. We show that joint optimization of technology investment and segmentation strategies leads to several nontrivial results that differ from traditional product line design theory. First, capturing fewer customers rather than more can lead to higher payoffs for the supplier under certain conditions moderated by the information structure. Second, higher technology cost can lead to lower investment, but a higher resulting average uptime. When heterogeneity is large, the average uptime under asymmetric information can be higher than that under full information. Third, when segment dissimilarity increases, mitigating cannibalization can make the high-end customers better off, even if they must pay a higher price for a lower uptime. The insights derived from the model are robust to various payment schemes and the structure of the failure recovery system.},
  archive      = {J_EJOR},
  author       = {Dong Li},
  doi          = {10.1016/j.ejor.2020.03.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {267-281},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {When less is more: Recovery technology investment and segmentation for uptime-centered services},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single-period stochastic demand fulfillment in customer
hierarchies. <em>EJOR</em>, <em>286</em>(1), 250–266. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To maximize profits, given limited resources, companies commonly divide their overall customer base into different segments and use allocation policies to prioritize the most important segments. Determining the optimal allocations is challenging due to supply lead times and uncertain demand. Another challenge is the multilevel hierarchical structure of the customer segments. In general, available quotas are not determined by a central planner with full visibility of all individual customer segments but rather result from a sequence of allocation steps with an increasing level of granularity. In this paper, we investigate this sequential allocation process. Specifically, we identify crucial information for making allocation decisions in customer hierarchies and propose decentralized methods that lead to near-optimal allocations while respecting the requirements for information aggregation. We evaluate the methods by comparing their information requirements and reflect on the role of information sharing in hierarchical allocation decisions.},
  archive      = {J_EJOR},
  author       = {Moritz Fleischmann and Konstantin Kloos and Maryam Nouri and Richard Pibernik},
  doi          = {10.1016/j.ejor.2020.03.030},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {250-266},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single-period stochastic demand fulfillment in customer hierarchies},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel decomposition-based method for solving
general-product structure assemble-to-order systems. <em>EJOR</em>,
<em>286</em>(1), 233–249. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assemble-to-order (ATO) strategies are common to many industries. Despite their popularity, ATO systems remain challenging to analyze. We consider a general-product structure ATO problem modeled as an infinite horizon Markov decision process. As the optimal policy of such a system is computationally intractable, we develop a heuristic policy that is based on a decomposition of the original system, into a series of two-component ATO subsystems. We show that our decomposition heuristic policy (DHP) possesses many properties similar to those encountered in special-product structure ATO systems. Extensive numerical experiments show that the DHP is very efficient. In particular, we show that the DHP requires less than 10 −5 the time required to obtain the optimal policy, with an average percentage cost gap less than 4\% for systems with up to 5 components and 6 products. We also show that the DHP outperforms the state aggregation heuristic of Nadar et al. (2018), in terms of cost and computational effort. We further develop an information relaxation-based lower bound on the performance of the optimal policy. We show that such a bound is very efficient with an average percentage gap not exceeding 0.5\% for systems with up to 5 components and 6 products. Using this lower bound, we further show that the average suboptimality gap of the DHP is within 9\% for two special-product structure ATO systems, with up to 9 components and 10 products. Using a sophisticated computing platform, we believe the DHP can handle systems with a large number of components and products.},
  archive      = {J_EJOR},
  author       = {Mohsen ElHafsi and Jianxin Fang and Essia Hamouda},
  doi          = {10.1016/j.ejor.2020.03.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {233-249},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel decomposition-based method for solving general-product structure assemble-to-order systems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How taxes impact bank and trade financing for multinational
firms. <em>EJOR</em>, <em>286</em>(1), 218–232. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tax and capital play critical roles in the business of multinational firms. This study investigates the optimal financing strategy between bank credit financing and trade credit financing when a multinational firm invests in a capital-constrained retailer located in a low-tax jurisdiction. We find that tax differences and varying dividend rates have significant effects on a multinational firm&#39;s decisions. In a basic model, we show a tax-related dividends rate that is less than one but can eliminate double marginalization in bank credit. In trade credit, we find that the optimal wholesale price changes with tax and dividend rate. When both bank and trade credits are viable, we find that the differences in dividends rates and tax rates are two critical factors in determining the optimal strategy, and we investigate the joint effect of these rates on the optimal financing strategy. When examining the impact of tax asymmetry on both retailers’ and multinational firms’ decisions, under bank credit, multinational firms will reduce the wholesale price to induce higher orders, but they will never offer trade credit. When both bank and trade credits are viable alternatives, the optimal financing strategy is bank credit when tax asymmetry exists. Lastly, the production cost threshold value that separates the unique financing equilibrium is lower due to the impact of taxes. Our findings can offer financing insights to both multinational firms and capital-constrained divisions.},
  archive      = {J_EJOR},
  author       = {Xiangyuan Lu and Zhiqiao Wu},
  doi          = {10.1016/j.ejor.2020.03.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {218-232},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How taxes impact bank and trade financing for multinational firms},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Carbon pricing initiatives-based bi-level pollution routing
problem. <em>EJOR</em>, <em>286</em>(1), 203–217. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pollution-routing problem aims to route a number of vehicles and determines their speeds on each route segment to minimize total cost, including fuel, emission and driver costs. Recently, carbon pricing initiatives have been widely implemented worldwide. With consideration of the interactions between carbon pricing initiatives and freight schedules, this paper presents a carbon pricing initiatives-based bi-level pollution routing problem involving an authority and a freight company. An interactive solution approach integrating a fuzzy logic controlled particle swarm optimization and a modified adaptive large neighborhood search heuristic is designed to search for solutions for the carbon pricing initiatives-based bi-level pollution routing problem. Computational experiments and analysis are then conducted to shed light on the influence of carbon pricing initiatives on carbon emissions and the total cost of freight companies. In this part, extended models for the carbon pricing initiatives-based bi-level pollution routing problem with a freight company delivering to multiple regions and with multiple freight companies are proposed and computed using the algorithms based on the interactive solution approach. The results indicate that the proposed method can promote freight company improvements in emission performance, and assist authorities in making decisions for road freight transport carbon emission reduction.},
  archive      = {J_EJOR},
  author       = {Rui Qiu and Jiuping Xu and Ruimin Ke and Ziqiang Zeng and Yinhai Wang},
  doi          = {10.1016/j.ejor.2020.03.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {203-217},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Carbon pricing initiatives-based bi-level pollution routing problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grouping products for the optimization of production
processes: A case in the steel manufacturing industry. <em>EJOR</em>,
<em>286</em>(1), 190–202. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of a production process is often based on the efficient utilization of the production facility and equipment. In particular, reducing the time to change from producing one product to another is critical to the fulfillment of demand at a minimum cost. We study the production of steel coils in the context of searching for groups of products with similar characteristics in order to create production batches that minimize the cost of fulfilling production orders originated by a known demand. We formulate the problem as mixed-integer program and develop a heuristic solution procedure. We show that a simplified version of the problem is equivalent to the clique partition problem, which in turn is equivalent to the graph-coloring problem. Computational experiments show that the heuristic procedure is effective in finding high-quality solutions to both the clique partition problem and the original grouping problem that includes additional costs.},
  archive      = {J_EJOR},
  author       = {Silvia Casado and Manuel Laguna and Joaquín Pacheco and Julio C. Puche},
  doi          = {10.1016/j.ejor.2020.03.010},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {190-202},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Grouping products for the optimization of production processes: A case in the steel manufacturing industry},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal and simple approximate solutions to a
production-inventory system with stochastic and deterministic demand.
<em>EJOR</em>, <em>286</em>(1), 178–189. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a continuous review production-inventory system where demand is a mixture of a deterministic component and a random component which follows a compound Poisson process. Demand is satisfied by a production facility which may be in production or idle. While in production, the facility produces at a constant rate. A two-number ( s, S ) policy is used to control production. When inventory reaches level S , production is turned off and when inventory drops below level s , production is turned on. A level crossing approach is used to derive the steady-state distribution of inventory level from which the exact total expected cost function, consisting of setup, inventory holding and backorder costs, is determined. The optimal ( s, S ) policy can be found through a search of the expected cost function. We propose approximations that give simple closed-form solutions with near-optimal performance.},
  archive      = {J_EJOR},
  author       = {Katy S. Azoury and Julia Miyaoka},
  doi          = {10.1016/j.ejor.2020.03.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {178-189},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal and simple approximate solutions to a production-inventory system with stochastic and deterministic demand},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Delivery time quotation and pricing in two-stage supply
chains: Centralized decision-making with global and local managerial
approaches. <em>EJOR</em>, <em>286</em>(1), 164–177. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the delivery time quotation and pricing in a two-stage make-to-order supply chain facing a time- and price-sensitive demand. We consider different managerial approaches which results in different models. First, we study a global model where a pair of price and delivery time are quoted to customers to maximize the expected overall profit while satisfying a global service level on the whole system. Second, we study a local model where each stage is required to quote a local delivery time while satisfying a local service level, and the delivery time quoted to customers consists of both local delivery times and must satisfy the global service level. The objective is similar to that of the global model. When both stages target the same service level than the one imposed to the whole system, we demonstrate under realistic conditions that satisfying the local service constraints enables to satisfy the global service constraint. This allows to remove the global constraint from the local model and solve it analytically. With comparison to the global model, the local model presents several managerial advantages with a limited profit loss. The mean gap is only 1.68\% for a service level of 95\%. We perform sensitivity analyses to derive insights into the impact of market characteristics and capacities on the performance of each stage and the overall performance. Finally, we extend the local model by allowing each stage to targeting a different service level. This leads to closing the profit gap with the global model.},
  archive      = {J_EJOR},
  author       = {Ramzi Hammami and Yannick Frein and Abduh S. Albana},
  doi          = {10.1016/j.ejor.2020.03.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {164-177},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Delivery time quotation and pricing in two-stage supply chains: Centralized decision-making with global and local managerial approaches},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heterogeneous suppliers’ contract design in assembly systems
with asymmetric information. <em>EJOR</em>, <em>286</em>(1), 149–163.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a supply contract design problem in an assembly supply chain in which two heterogeneous suppliers produce complementary products and deliver them to the assembler. One supplier is more reliable and exhibits no supply risk, and the other is less reliable and exhibits supply risk. The assembler is better informed about demand and assembles these two types of components into final products. To elicit the assembler’s truthful report of private information, the more reliable supplier offers a contract to the assembler to determine the components’ quantities and the transfer payment. The less reliable supplier enduring a disruption designs a contract that includes the components’ quantities, the transfer payment and the unit penalty for any delivery shortfall. We study the cases where either supplier moves first and where they move simultaneously under symmetric and asymmetric demand information. We explore the values of the assembler’s information and find that the first mover is more reliant upon the existence of less asymmetric information and the second mover benefits more from the assembler’ information. Further, we find that a low reliability of the less reliable supplier enlarges the first mover’s value of information. We also examine the values of the contracting sequence and find that under symmetric information, the first mover benefits more from sequential contracting. However, interestingly, under asymmetric information, the first mover may benefit or be harmed by the first-mover right. We also find that a low reliability of the less reliable supplier discourages the supplier from using the first-mover right.},
  archive      = {J_EJOR},
  author       = {Yanfei Lan and Xiaoqiang Cai and Changjing Shang and Lianmin Zhang and Ruiqing Zhao},
  doi          = {10.1016/j.ejor.2020.03.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {149-163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heterogeneous suppliers’ contract design in assembly systems with asymmetric information},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rescheduling production and outbound deliveries when
transportation service is disrupted. <em>EJOR</em>, <em>286</em>(1),
138–148. (<a href="https://doi.org/10.1016/j.ejor.2020.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unexpected service disruptions in transportation systems caused by accidents, system breakdowns, poor weather conditions, etc., are quite common. When disruptions occur, rescheduling of vehicles is often needed in order to mitigate the damage caused by the disruptions. In integrated production and outbound distribution systems, a disruption in outbound distribution operation affects not only the delivery plan but also the production schedule. In this paper, we consider a simple integrated scheduling model of production and outbound deliveries with a minimum headway constraint between vehicle departures, and study the situation where an optimal solution of the integrated scheduling model has been obtained but the delivery service is suddenly unavailable for a certain time period due to some unexpected incidents. We would like to determine a new production and delivery schedule in which no delivery takes place during the unavailable period. The objective is to simultaneously maintain a low cost schedule and control the magnitude of changes in the delivery times of the finished goods. We consider three different ways to control the time disruption, and develop polynomial-time algorithms for the corresponding problems.},
  archive      = {J_EJOR},
  author       = {Chung-Lun Li and Feng Li},
  doi          = {10.1016/j.ejor.2020.03.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {138-148},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Rescheduling production and outbound deliveries when transportation service is disrupted},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A common approximation framework for early work, late work,
and resource leveling problems. <em>EJOR</em>, <em>286</em>(1), 129–137.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the approximability of four scheduling problems on identical parallel machines. In the late work minimization problem , the jobs have arbitrary processing times and a common due date, and the objective is to minimize the late work , defined as the sum of the portion of the jobs done after the due date. A related problem is the maximization of the early work , defined as the sum of the portion of the jobs done before the due date. We describe a polynomial time approximation scheme for the early work maximization problem, and we extended it to the late work minimization problem after shifting the objective function by a positive value that depends on the problem data. We also prove an inapproximability result for the latter problem if the objective function is shifted by a constant which does not depend on the input. These results remain valid even if the number of the jobs assigned to the same machine is bounded. This leads to an extension of our approximation scheme to two variants of the resource leveling problem with unit time jobs, for which no approximation algorithm is known.},
  archive      = {J_EJOR},
  author       = {Péter Györgyi and Tamás Kis},
  doi          = {10.1016/j.ejor.2020.03.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {129-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A common approximation framework for early work, late work, and resource leveling problems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing makespan on a single machine with release dates
and inventory constraints. <em>EJOR</em>, <em>286</em>(1), 115–128. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a single-machine scheduling problem with release dates and inventory constraints. Each job has a deterministic processing time and has an impact (either positive or negative) on the central inventory level. We aim to find a sequence of jobs such that the makespan is minimized while all release dates and inventory constraints are met. We show that the problem is strongly NP-hard even when the capacity of the inventory is infinite. To solve the problem, we introduce a time-indexed formulation and a sequence-based formulation, a branch-and-bound algorithm, and a dynamic-programming-based guess-and-check (GC) algorithm. From extensive computational experiments, we find that the GC algorithm outperforms all other alternatives.},
  archive      = {J_EJOR},
  author       = {Morteza Davari and Mohammad Ranjbar and Patrick De Causmaecker and Roel Leus},
  doi          = {10.1016/j.ejor.2020.03.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {115-128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing makespan on a single machine with release dates and inventory constraints},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cutoff time strategy based on the coupon collector’s
problem. <em>EJOR</em>, <em>286</em>(1), 101–114. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout the course of an optimization run, the probability of yielding further improvement becomes smaller as the search proceeds, and eventually the search stagnates. Under such a state, letting the algorithm continue to run is a waste of time as there is little hope that subsequent improvement can be made. The ability to detect the stagnation point is therefore of prime importance. If such a point can be detected reliably, then it is possible to make better use of the computing resources, perhaps restarting the algorithm at the stagnation point, either with the same or with a different parameter configuration. This paper proposes a cutoff time strategy. It presents a method that is able to reliably detect the stagnation point for one-point stochastic local search algorithms applied to combinatorial optimization problems. The strategy is derived from the coupon collector’s problem, and is scalable based on the employed perturbation operator and its induced neighbourhood size, as well as from feedback from the search. The suitability and scalability of the method is illustrated with the Late Acceptance Hill-Climbing algorithm on a comprehensive set of benchmark instances of three well-known combinatorial optimization problems: the Travelling Salesman Problem, the Quadratic Assignment Problem, and the Permutation Flowshop Scheduling Problem.},
  archive      = {J_EJOR},
  author       = {Fernando G. Lobo and Mosab Bazargani and Edmund K. Burke},
  doi          = {10.1016/j.ejor.2020.03.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {101-114},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A cutoff time strategy based on the coupon collector’s problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tightening big ms in integer programming formulations for
support vector machines with ramp loss. <em>EJOR</em>, <em>286</em>(1),
84–100. (<a href="https://doi.org/10.1016/j.ejor.2020.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers various models of support vector machines with ramp loss, these being an efficient and robust tool in supervised classification for the detection of outliers. The exact solution approaches for the resulting optimization problem are of high demand for large datasets. Hence, the goal of this paper is to develop algorithms that provide efficient methodologies to exactly solve these optimization problems. These approaches are based on three strategies for obtaining tightened values of the big M parameters included in the formulation of the problem. Two of them require solving a sequence of continuous problems, while the third uses the Lagrangian relaxation to tighten the bounds. The proposed resolution methods are valid for the ℓ 1 -norm and ℓ 2 -norm ramp loss formulations. They were tested and compared with existing solution methods in simulated and real-life datasets, showing the efficiency of the developed methodology.},
  archive      = {J_EJOR},
  author       = {Marta Baldomero-Naranjo and Luisa I. Martínez-Merino and Antonio M. Rodríguez-Chía},
  doi          = {10.1016/j.ejor.2020.03.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {84-100},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tightening big ms in integer programming formulations for support vector machines with ramp loss},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An opposition-based memetic algorithm for the maximum
quasi-clique problem. <em>EJOR</em>, <em>286</em>(1), 63–83. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G = ( V , E ) G=(V,E) and a constant γ , the γ -quasi-clique is defined as a subset of vertices that induces a subgraph with the edge density of at least γ . The maximum γ -quasi-clique problem (MQCP) is to find a γ -quasi-clique of the maximum cardinality in G . This problem has many practical applications, especially in social network analysis. We present an opposition-based memetic algorithm (OBMA) for MQCP, which relies on a backbone-based crossover operator to generate new offspring solutions and on a constrained neighborhood tabu search for local improvement. OBMA further integrates the concept of opposition-based learning (OBL) to enhance the search ability of the classic memetic algorithm. Computational results on a large set of both dense and sparse graphs show that the proposed heuristic competes very favorably with the current state-of-the-art algorithms from the MQCP literature. In particular, it is able to find improved best-known solutions for 47 out of the 100 dense graphs, while reaching the best-known solution for all but few of the remaining instances. Several essential components of the proposed approach are investigated to understand their impacts to the algorithm’s performance.},
  archive      = {J_EJOR},
  author       = {Qing Zhou and Una Benlic and Qinghua Wu},
  doi          = {10.1016/j.ejor.2020.03.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {63-83},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An opposition-based memetic algorithm for the maximum quasi-clique problem},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Next-day operating room scheduling with uncertain surgery
durations: Exact analysis and heuristics. <em>EJOR</em>,
<em>286</em>(1), 49–62. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operating rooms are units of particular interest in hospitals as they constitute more than 40\% of total expenses and revenues. Managing operating rooms is challenging due to conflicting priorities and preferences of various stakeholders and the inherent uncertainty of surgery durations. In this study, we consider the next-day scheduling problem of a hospital operating room. Given the list and the sequence of non-identical surgeries to be performed in the next day, one needs to determine the scheduled durations of surgeries where the actual duration of each surgery is uncertain. Our objective is to minimize the weighted sum of expected patient waiting times, room idle time and overtime. First, we provide a reformulation of the objective function in terms of auxiliary functions with a recursive pattern that enables exact analysis of the optimal surgery durations at the expense of high CPU time. Next, we develop and analyze simple-to-use and close-to-optimal scheduling heuristics motivated by practice, for the OR managers to deploy in the field. Our proposed hybrid heuristic attains 1.22\% average performance gap and worst average optimality gap of 2.77\%. Our solution is easy to implement as it does not require any advanced optimization tool, which is the reality of many operating room environments.},
  archive      = {J_EJOR},
  author       = {Taghi Khaniyev and Enis Kayış and Refik Güllü},
  doi          = {10.1016/j.ejor.2020.03.002},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {49-62},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Next-day operating room scheduling with uncertain surgery durations: Exact analysis and heuristics},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generalized newton method for a class of discrete-time
linear complementarity systems. <em>EJOR</em>, <em>286</em>(1), 39–48.
(<a href="https://doi.org/10.1016/j.ejor.2020.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a generalized Newton method for solving a class of discrete-time linear complementarity systems consisting of a system of linear equations and a linear complementarity constraints with a Z-matrix. We obtain a complete characterization of the least element solution of a linear complementarity problem with a Z-matrix that a solution is the least element solution if and only if the principal submatrix corresponding to the nonzero components of the solution is an M-matrix. We present a Newton method for solving a linear complementarity problem with a Z-matrix. We propose a generalized Newton method for solving the discrete-time linear complementarity system where the linear complementarity problem constraint is solved by the proposed Newton method. Under suitable conditions, we show that the generalized Newton method converges globally and finds a solution in finitely many iterations. Preliminary numerical results show the efficiency of the proposed method.},
  archive      = {J_EJOR},
  author       = {Zhe Sun and Xiaoqi Yang},
  doi          = {10.1016/j.ejor.2020.03.058},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {39-48},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generalized newton method for a class of discrete-time linear complementarity systems},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On convergence analysis of multi-objective particle swarm
optimization algorithm. <em>EJOR</em>, <em>286</em>(1), 32–38. (<a
href="https://doi.org/10.1016/j.ejor.2020.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective particle swarm optimization (MOPSO), a population-based stochastic optimization algorithm, has been successfully used to solve many multi-objective optimization problems. However, the analysis of algorithm convergence is still inadequate nowadays. In this paper, probability theory is applied to analyze the convergence of the original MOPSO. First, a convergence metric is defined. Afterwards, the global convergence of the original MOPSO is transformed into the convergence of the convergence metric sequence. Finally, the defined convergence metric is utilized to analyze the global convergence of the original MOPSO in terms of probability theory. Our results show that the original MOPSO cannot guarantee global convergence with probability one. Moreover, the analysis of the original MOPSO indicates that the improved vision of the original MOPSO is a global convergence algorithm. The proof of the original MOPSO convergence in this work is new, simple and more effective without specific implementation.},
  archive      = {J_EJOR},
  author       = {Gang Xu and Kun Luo and Guoxiu Jing and Xiang Yu and Xiaojun Ruan and Jun Song},
  doi          = {10.1016/j.ejor.2020.03.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {32-38},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On convergence analysis of multi-objective particle swarm optimization algorithm},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk neutral reformulation approach to risk averse
stochastic programming. <em>EJOR</em>, <em>286</em>(1), 21–31. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to show that in some cases risk averse multistage stochastic programming problems can be reformulated in a form of risk neutral setting. This is achieved by a change of the reference probability measure making “bad” (extreme) scenarios more frequent. As a numerical example we demonstrate advantages of such change-of-measure approach applied to the Brazilian Interconnected Power System operation planning problem.},
  archive      = {J_EJOR},
  author       = {Rui Peng Liu and Alexander Shapiro},
  doi          = {10.1016/j.ejor.2020.01.060},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {21-31},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk neutral reformulation approach to risk averse stochastic programming},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Liner shipping network design. <em>EJOR</em>,
<em>286</em>(1), 1–20. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maritime industry is one of the greenest modes of transportation, taking care of almost 90\% of the global trade. The maritime container business revolves around liner shipping, which consists of container vessels sailing on fixed itineraries. For the last 20 years, there has been an increasing number of publications regarding how to design such fixed routes (services), to ensure a high level of service while minimizing operational costs and environmental impact. The liner shipping network design problem can briefly be described as follows: Given a set of demands (defined by origin, destination, time limit) and a set of vessels with variable capacity, the task is to design a set of weekly services, assign vessels to the services, and flow the demand through the resulting network such that it arrives within the stated time constraints. The objective is to maximize revenue of transported demand subtracting the operational costs. We present an in-depth literature overview of existing models and solution methods for liner shipping network design, and discuss the four main families of solution methods: integrated mixed integer programming models; two-stage algorithms designing services in the first step and flowing containers in the second step; two-stage algorithms first flowing containers and then designing services; and finally algorithms for selecting a subset of proposed candidate services. We end the presentation by comparing the performance of leading algorithms using the public LINER-LIB instances. The paper is concluded by discussing future trends in liner shipping, indicating directions for future research.},
  archive      = {J_EJOR},
  author       = {Marielle Christiansen and Erik Hellsten and David Pisinger and David Sacramento and Charlotte Vilhelmsen},
  doi          = {10.1016/j.ejor.2019.09.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Liner shipping network design},
  volume       = {286},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “extended formulations and branch-and-cut
algorithms for the black-and-white traveling salesman problem” [european
journal of operational research, 262(3) 2017, 908–928]. <em>EJOR</em>,
<em>285</em>(3), 1199–1203. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a personal communication with Ruslan Sadykov from Inria, France, we found an implementation error in our code for importing the benchmark instance set MUT leading to wrong numerical results in our original article (Gouveia, Leitner, and Ruthmair, 2017). In this corrigendum we provide corrected results for all experiments on instance set MUT. The general findings and conclusions drawn from the results however do not change.},
  archive      = {J_EJOR},
  author       = {Luis Gouveia and Markus Leitner and Mario Ruthmair and Ruslan Sadykov},
  doi          = {10.1016/j.ejor.2020.02.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1199-1203},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to “Extended formulations and branch-and-cut algorithms for the black-and-white traveling salesman problem” [European journal of operational research, 262(3) 2017, 908–928]},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Symmetric decompositions of cost variation. <em>EJOR</em>,
<em>285</em>(3), 1189–1198. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a number of symmetric, empirically implementable decompositions of the cost variation (in difference and ratio form) of a production unit are developed. The components distinguished are price level change, technical efficiency change, allocative efficiency change, technological change, scale of activity change, and price structure change. Given data from a (balanced) panel of production units, all the necessary ingredients for the computation of the various decompositions can be obtained by using linear programming techniques (DEA). An application is provided.},
  archive      = {J_EJOR},
  author       = {Bert M. Balk and José L. Zofío},
  doi          = {10.1016/j.ejor.2020.02.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1189-1198},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Symmetric decompositions of cost variation},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measurement of technical inefficiency and total factor
productivity growth: A semiparametric stochastic input distance frontier
approach and the case of lithuanian dairy farms. <em>EJOR</em>,
<em>285</em>(3), 1174–1188. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a four-component stochastic frontier model in which the frontier function is represented by an unknown smooth input distance function, and inefficiency is decomposed into persistent and transient inefficiencies. Furthermore, the pre-truncation mean and variance of the transient inefficiency are functions of the environmental variables. By differentiating the four-component input distance frontier with respect to the time trend, total factor productivity (TFP) growth is estimated under the semiparametric smooth coefficient framework, and is decomposed into six components, i.e., technical change, scale component, allocative component, external component, efficiency change, and residual component. The empirical example focuses on the Lithuanian dairy sector with multiple outputs. Our results show that there are some persistent and transient inefficiencies in Lithuanian dairy farms. However, these farms maintained TFP growth of 2\% per annum on average during 2004–2016, and much of it is attributed to the technical change and scale components.},
  archive      = {J_EJOR},
  author       = {Tomas Baležentis and Kai Sun},
  doi          = {10.1016/j.ejor.2020.02.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1174-1188},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measurement of technical inefficiency and total factor productivity growth: A semiparametric stochastic input distance frontier approach and the case of lithuanian dairy farms},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A superlative indicator for the luenberger-hicks-moorsteen
productivity indicator: Theory and application. <em>EJOR</em>,
<em>285</em>(3), 1161–1173. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consisting of the difference between an output indicator and an input indicator, the Luenberger-Hicks-Moorsteen (LHM) productivity indicator allows straightforward interpretation. However, its computation requires estimating distance functions that are inherently unknown. This paper shows that a computationally simple Bennet indicator is a superlative indicator for the LHM indicator when one can assume profit-maximizing behavior and the input and output directional distance functions can be represented up to the second order by a quadratic functional form. We also show that the Luenberger- and LHM-approximating Bennet indicators coincide for an appropriate choice of directional vectors. Focusing on a large sample of Italian food and beverages companies for the years 1995 − 2007 , 1995−2007, we empirically investigate the extent to which this theoretical equivalence translates into similar estimates. We find that the Bennet indicator is a close empirical alternative to the LHM indicator for the sample.},
  archive      = {J_EJOR},
  author       = {Frederic Ang and Pieter Jan Kerstens},
  doi          = {10.1016/j.ejor.2020.02.030},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1161-1173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A superlative indicator for the luenberger-hicks-moorsteen productivity indicator: Theory and application},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Search and rescue in the face of uncertain threats.
<em>EJOR</em>, <em>285</em>(3), 1153–1160. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a search problem in which one or more targets must be rescued by a search party, or Searcher . The targets may be survivors of some natural disaster, or prisoners held by an adversary. The targets are hidden among a finite set of locations, but when a location is searched, there is a known probability that the search will come to an end, perhaps because the Searcher becomes trapped herself, or is captured by the adversary. If this happens before all the targets have been recovered, then the rescue attempt is deemed a failure. The objective is to find the search that maximizes the probability of recovering all the targets. We present and solve a game theoretic model for this problem, by placing it in a more general framework that encompasses another game previously introduced by the author. We also consider an extension to the game in which the targets are hidden on the vertices of a graph. In the case that there is only one target, we give a solution of the game played on a tree.},
  archive      = {J_EJOR},
  author       = {Thomas Lidbetter},
  doi          = {10.1016/j.ejor.2020.02.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1153-1160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Search and rescue in the face of uncertain threats},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). On a model of environmental performance and technology
gaps. <em>EJOR</em>, <em>285</em>(3), 1141–1152. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider a stochastic directional technology distance function to re-examine the results of recent research in which the authors estimate a generalized directional distance function using programming methods, derive technology gaps and, in a second stage, they fit a Markov process to the technology gaps. One problem is that in the second stage efficiencies and gaps are themselves estimated. Moreover, the authors consider two groups (Annex I and non-Annex I countries according to the Kyoto protocol). We allow for endogeneity of good and bad outputs and inputs, endogenously determined groups of countries, endogenous directions for each country and group, and a distribution of technological gaps (with respect to the meta-technology) which is based on a Markov process. We use a semi-parametric directional technology distance function and we propose stochastic envelopment of different frontiers allowing for its own “meta-inefficiency”. All quantities of interest are estimated jointly using numerical Bayesian techniques.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2020.02.025},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1141-1152},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On a model of environmental performance and technology gaps},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Speed optimizations for liner networks with business
constraints. <em>EJOR</em>, <em>285</em>(3), 1127–1140. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2018 the International Maritime Organization (IMO) agreed to cut the shipping sector’s overall CO2 output by 50\% by 2050. One of the key methods in reaching this goal is to improve operations to limit fuel consumption. However, it is difficult to optimize speed for a complete liner shipping network as routes interact with each other, and several business constraints must be respected. This paper presents a unified model for speed optimization of a liner shipping network, satisfying numerous real-life business constraints. The speed optimization is in this research achieved by rescheduling the port call times of a network, thus, the network is not changed. The business constraints are among others related to transit times, port work shifts and emission control areas. Other restrictions are fixed times for canal crossing, speed restrictions in the piracy areas and desire for robust solutions. Vessel sharing agreements and other collaboration between companies must also be included. The modeling of the different restrictions is described in detail and tested on real-life data. The scientific contribution of this paper is threefold: We present a unified model for speed optimization together with numerous business constraints. We present a general framework for handling routes with different frequencies. Moreover, we present a bi-objective model for balancing robustness of schedules against fuel consumption. The tests show that the real-life requirements can be handled by mixed integer programming and that the model finds significant reductions of bunker consumption and cost for large-scale real-life instances.},
  archive      = {J_EJOR},
  author       = {Line Blander Reinhardt and David Pisinger and Mikkel M. Sigurd and Jonas Ahmt},
  doi          = {10.1016/j.ejor.2020.02.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1127-1140},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Speed optimizations for liner networks with business constraints},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beyond expected utility: Subjective risk aversion and
optimal portfolio choice under convex shortfall risk measures.
<em>EJOR</em>, <em>285</em>(3), 1114–1126. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a decision-theoretic analysis of convex shortfall risk measures regarding their flexibility to represent subjective risk aversion, and discuss the implications for the choice of optimal portfolios. As convex shortfall risk measures are closely related to the expected utility functional, we draw upon the expected utility framework as our benchmark. First, we show that, unlike expected utility, convex shortfall risk measures do always represent constant absolute risk aversion. This constitutes a significant limitation when changing initial wealth of, e.g., investors, is relevant. Interestingly, though, it is exactly this limitation that provides additional degrees of freedom in representing subjective risk aversion beyond expected utility when initial wealth is fixed, as, e.g., in returned-based portfolio selection models in the tradition of Markowitz (1952). Second, we apply convex shortfall risk measures to the standard portfolio problem between a riskless and a risky asset. We provide a procedure that allows inferring the optimal portfolios under convex shortfall risk measures from certain optimal expected utility-portfolios. The procedure incorporates the additional degrees of freedom in modeling subjective risk aversion and, thus, allows more flexible and realistic portfolios compared to expected utility. Third, we address the optimal portfolio choice between a riskless and a risky asset in the presence of an additional background risk. Again, we prove a correspondence result between optimal portfolios under convex shortfall risk measures and expected utility and obtain more flexible and realistic portfolios compared to expected utility. We also compare the optimal risky investments without and with background risk and provide a necessary and sufficient condition for a reduction of the risky investment.},
  archive      = {J_EJOR},
  author       = {Mario Brandtner and Wolfgang Kürsten and Robert Rischau},
  doi          = {10.1016/j.ejor.2020.02.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1114-1126},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Beyond expected utility: Subjective risk aversion and optimal portfolio choice under convex shortfall risk measures},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing predictive precision in imbalanced datasets for
actionable revenue change prediction. <em>EJOR</em>, <em>285</em>(3),
1095–1113. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In business environments where an organization offers contract-based periodic services to its clients, one crucial task is to predict changes in revenues generated through different clients or specific service offerings from one time epoch to another. This is commonly known as the revenue change prediction problem. In practical real-world environments, the importance of having adequate revenue change prediction capability primarily stems from scarcity of resources (in particular, sales team personnel or technical consultants) that are needed to respond to different revenue change scenarios including predicted revenue growth or shrinkage. It becomes important to make actionable decisions; that is, decisions related to prioritizing clients or service offerings to which these scarce resources are to be allocated. The contribution of the current work is twofold. First, we propose a framework for conducting revenue change prediction through casting it as a classification problem. Second, since datasets associated with revenue change prediction are typically imbalanced, we develop a new methodology for solving the classification problem such that we achieve maximum prediction precision while minimizing sacrifice in prediction accuracy. We validate our proposed framework through real-world datasets acquired from a major global provider of cloud computing services, and benchmark its performance against standard classifiers from previous works in the literature.},
  archive      = {J_EJOR},
  author       = {Pravar Dilip Mahajan and Abhinav Maurya and Aly Megahed and Alaa Elwany and Ray Strong and Jeanette Blomberg},
  doi          = {10.1016/j.ejor.2020.02.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1095-1113},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing predictive precision in imbalanced datasets for actionable revenue change prediction},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing the changing locations of mobile parcel lockers
in last-mile distribution. <em>EJOR</em>, <em>285</em>(3), 1077–1094.
(<a href="https://doi.org/10.1016/j.ejor.2020.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce congestion, environmental damage, and negative health impact in large urban areas plenty of novel concepts for last-mile distribution have been innovated in the recent years. The concept treated in this paper are mobile parcel lockers that are able to change their locations during the day, either autonomously or moved by a human driver. By relocating lockers their reach towards addressees also varying their whereabouts over the day can be increased. This paper optimizes the changing locations of lockers, such that customers are at some time during the planning horizon within a predefined range of their designated locker. Our aim is to minimize the locker fleet when satisfying all customers. We formulate the resulting mobile locker location problem and provide suited exact solution procedures. To asses the potential whether mobile lockers are a promising last-mile concept, worth the investment required to develop it to a market-ready solution, we benchmark the necessary fleet size of mobile lockers with the required number of their stationary counterparts. Our results show that considerable reductions are possible.},
  archive      = {J_EJOR},
  author       = {Stefan Schwerdfeger and Nils Boysen},
  doi          = {10.1016/j.ejor.2020.02.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1077-1094},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing the changing locations of mobile parcel lockers in last-mile distribution},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Product assortment and space allocation strategies to
attract loyal and non-loyal customers. <em>EJOR</em>, <em>285</em>(3),
1058–1076. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assortment planning deserves much attention from practitioners and academics due to its direct impact on retailers’ commercial success. In this paper we focus on the increasingly popular retail practice to use combined product assortments with both “standard” and more fashionable and short-lived “variable” products for building up store traffic of “loyal” and “non-loyal” heterogeneous customers and enlarging the sales due to the potential cross-selling effect. Addressing the assortment planning as a bilevel optimization problem, we focus on decision-dependent uncertainties: the retailer’s binary decision about product inclusion influences the distribution of the product’s demand. Furthermore, our model accounts for customers’ optimal purchase quantities, which depend on budget constraints limiting the basket that a customer is able to purchase. We propose iterative heuristics using optimal quantization of demand and customers budget distributions to define the total assortment and the inventory level per product. These heuristics provide lower bounds on the optimal value. We conduct a comparison to other existing lower bounds and we formulate upper bounds via linear (LP) and semidefinite (SDP) relaxations for the performance evaluation of the heuristics and for an efficient numerical solution in high-dimensional cases. For managerial insights, we compare the proposed approach with three assortment planning strategies: (1) the retailer does not carry variable products; (2) the retailer ignores the cross-selling effect; and (3) the maximum space allocated to each product is fixed. Our results suggest that variable assortment boosts the retailers profits if the cross-selling effect is not neglected in the decision about products quantities.},
  archive      = {J_EJOR},
  author       = {Anna Timonina-Farkas and Argyro Katsifou and Ralf W. Seifert},
  doi          = {10.1016/j.ejor.2020.02.019},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1058-1076},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product assortment and space allocation strategies to attract loyal and non-loyal customers},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benchmarking the benchmarks – comparing the accuracy of data
envelopment analysis models in constant returns to scale settings.
<em>EJOR</em>, <em>285</em>(3), 1042–1057. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the massive use of Data Envelopment Analysis (DEA) models for efficiency estimations in scientific applications, no paper cared about identifying the DEA model, which is able to provide the most accurate efficiency estimates, so far. We develop an established method based on a Monte Carlo data generation process to create artificial data. As we use a Translog production function instead of the commonly utilized Cobb Douglas production function, we are able to construct meaningful scenarios for constant returns to scale. The decision-making units resulting from the generated data are then used to calculate DEA estimators using different DEA models. Finally, the quality of the resulting efficiency estimates is evaluated by five performance indicators and summarized in benchmark scores. With this procedure, we can postulate general statements on parameters that influence the quality of DEA studies in a positive/negative way and determine which DEA model operates in the most accurate way for a range of scenarios. Here, we can show that the Assurance Region and Slacks-Based-Measurement models outperform the CCR (Charnes–Cooper–Rhodes) model in constant returns to scale scenarios. We therefore recommend a reduced utilization of the CCR model in DEA applications.},
  archive      = {J_EJOR},
  author       = {Sebastian Kohl and Jens O. Brunner},
  doi          = {10.1016/j.ejor.2020.02.031},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1042-1057},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Benchmarking the benchmarks – comparing the accuracy of data envelopment analysis models in constant returns to scale settings},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new correlation coefficient for comparing and aggregating
non-strict and incomplete rankings. <em>EJOR</em>, <em>285</em>(3),
1025–1041. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a correlation coefficient that is designed to deal with a variety of ranking formats including those containing non-strict (i.e., with-ties) and incomplete (i.e., unknown) preferences. The correlation coefficient is designed to enforce a neutral treatment of incompleteness whereby no assumptions are made about individual preferences involving unranked objects. The new measure, which can be regarded as a generalization of the seminal Kendall tau correlation coefficient, is proven to satisfy a set of metric-like axioms and to be equivalent to a recently developed ranking distance function associated with Kemeny aggregation. In an effort to further unify and enhance both robust ranking methodologies, this work proves the equivalence of an additional distance and correlation-coefficient pairing in the space of non-strict incomplete rankings. These connections induce new exact optimization methodologies: a specialized branch and bound algorithm and an exact integer programming formulation. Moreover, the bridging of these complementary theories reinforces the singular suitability of the featured correlation coefficient to solve the general consensus ranking problem. The latter premise is bolstered by an accompanying set of experiments on random instances, which are generated via a herein developed sampling technique connected with the classic Mallows distribution of ranking data. Associated experiments with the branch and bound algorithm demonstrate that, as data becomes noisier, the featured correlation coefficient yields relatively fewer alternative optimal solutions and that the aggregate rankings tend to be closer to an underlying ground truth shared by a majority.},
  archive      = {J_EJOR},
  author       = {Yeawon Yoo and Adolfo R. Escobedo and J. Kyle Skolfield},
  doi          = {10.1016/j.ejor.2020.02.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1025-1041},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new correlation coefficient for comparing and aggregating non-strict and incomplete rankings},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A data envelopment analysis and local partial least squares
approach for identifying the optimal innovation policy direction.
<em>EJOR</em>, <em>285</em>(3), 1011–1024. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a novel two-step approach that evaluates countries’ innovation efficiency and their responsiveness to expansions in their innovation inputs, while addressing shortcomings associated with composite indicators. Based on our evaluations, we propose innovation policies tailored to take into account the diverse economic environments of the many countries in our study. Applying multidirectional efficiency analysis on data from the Global Innovation Index, we obtain separate efficiency scores for each innovation input and output. We then estimate different sensitivities for each country, by applying partial least squares on explanatory and response matrices which are determined by the nearest neighbors of the country under consideration. The findings reveal substantial asymmetries with respect to innovation efficiencies and sensitivities, which is indicative of the diversity of national innovation systems. Considering these two dimensions in combination, we outline three policy directions that can be followed, offering a platform for better-informed decision-making.},
  archive      = {J_EJOR},
  author       = {Panagiotis Tziogkidis and Dionisis Philippas and Alexandros Leontitsis and Robin C. Sickles},
  doi          = {10.1016/j.ejor.2020.02.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1011-1024},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A data envelopment analysis and local partial least squares approach for identifying the optimal innovation policy direction},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On justifying the norms underlying decision support.
<em>EJOR</em>, <em>285</em>(3), 1002–1010. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When decision sciences are applied to concrete problems, Decision Makers (DM), concerned stakeholders, and the general public typically expect clear recommendations. As emphasized in particular in the literature on ethical dimensions of Operational Research (OR) practice, such recommendations are unavoidably conditioned by norms or normative conceptions. Although an extensive literature is devoted to promoting certain norms designed to be largely accepted by decision analysts, studies specifically devoted to determine, at a general level, how decision analysts can decide which norms should underlie their work, are found lacking. To make up for this lacuna, we flesh out the concept of justification. We develop requirements that any justification should satisfy to qualify for being able to justify norms on which recommendations can rest. We then introduce and recommend a series of practical rules that decision analysts should abide by, on the basis of which, in a given decision situation, a decision analyst can decide, together with the DM, whether a given norm underlying a given recommendation can be adopted.},
  archive      = {J_EJOR},
  author       = {Y. Meinard and O. Cailloux},
  doi          = {10.1016/j.ejor.2020.02.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1002-1010},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On justifying the norms underlying decision support},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Some matheuristic algorithms for multistage stochastic
optimization models with endogenous uncertainty and risk management.
<em>EJOR</em>, <em>285</em>(3), 988–1001. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two matheuristic decomposition algorithms are introduced. The first one is a Progressive Hedging type so-named Regularized scenario Cluster Progressive Algorithm. The second one is a Frank-Wolfe PH type so-named Regularized scenario Cluster Simplicial Decomposition Progressive Algorithm. An extension of endogenous Type III uncertainty is considered for representing the decision-dependent scenario probability and outlook. Its performance is tested in the time-consistent Expected Conditional Stochastic Dominance risk averse environment. As a result of the modeling, the typical risk neutral multistage mixed 0–1 linear stochastic problem under uncertainty is replaced with an enlarged model that is equivalent to the required mixed 0–1 bilinear model. Based on the special features of the problem, it is unrealistic to seek the optimal solution for large-scale instances. Feasible solutions and lower bounds on the solution value of the original model are provided. In total, 48 strategies are considered, each one consists of a combination of a regularization norm, a calibration type for the PH pseudo-gradient computation, and a set of value intervals of the influential variables on a representative endogenous uncertainty-based piecewise function in the scenarios. Computational results are reported for a large-scale extension of a well-known real-life pilot case for preparedness resource allocation planning aiming to natural disaster relief. The matheuristics outperform the plain use of a state-of-the-art solver.},
  archive      = {J_EJOR},
  author       = {Laureano F. Escudero and M. Araceli Garín and Juan F. Monge and Aitziber Unzueta},
  doi          = {10.1016/j.ejor.2020.02.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {988-1001},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Some matheuristic algorithms for multistage stochastic optimization models with endogenous uncertainty and risk management},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A correspondence between voting procedures and stochastic
orderings. <em>EJOR</em>, <em>285</em>(3), 977–987. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In voting theory, two different settings are commonplace: either voters express a preference ordering on the set of candidates or they express an individual evaluation of each candidate. In either case, the aim may be to obtain a global ranking of the candidates and, in particular, to determine the winner of the election. We introduce a probabilistic framework that allows us to explore a correspondence between some usual voting procedures based on either preference orderings (e.g. the Borda count and the Condorcet procedure) or individual evaluations (e.g. the Borda majority count and the majority judgment) and some classical stochastic orderings (e.g. comparison of expected values, comparison of medians and statistical preference). We also consider a recently-introduced multivariate stochastic ordering, called probabilistic preference, and show its connection with the plurality and veto procedures.},
  archive      = {J_EJOR},
  author       = {Ignacio Montes and Michael Rademaker and Raúl Pérez-Fernández and Bernard De Baets},
  doi          = {10.1016/j.ejor.2020.02.038},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {977-987},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A correspondence between voting procedures and stochastic orderings},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Search and delivery man problems: When are depth-first paths
optimal? <em>EJOR</em>, <em>285</em>(3), 965–976. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let h be a probability measure on the nodes and arcs of a network Q , viewed either as the location of a hidden object to be found or as the continuous distribution of customers receiving packages. We wish to find a trajectory starting from a specified root, or depot O that minimizes the expected search or delivery time. We call such a trajectory optimal. When Q is a tree, we ask for which h there is an optimal trajectory that is depth-first, and we find sufficient conditions and in some cases necessary and sufficient conditions on h . A consequence of our analysis is a determination of the optimal depot location in the Delivery Man Problem, correcting an error in the literature. We concentrate mainly on the search problem, with the Delivery Man Problem arising as a special case.},
  archive      = {J_EJOR},
  author       = {Steve Alpern and Thomas Lidbetter},
  doi          = {10.1016/j.ejor.2020.02.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {965-976},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Search and delivery man problems: When are depth-first paths optimal?},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Biased random-key genetic algorithm for scheduling identical
parallel machines with tooling constraints. <em>EJOR</em>,
<em>285</em>(3), 955–964. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of scheduling a set of n jobs on m parallel machines, with the objective of minimizing the makespan in a flexible manufacturing system. In this context, each job takes the same processing time in any machine. However, jobs have different tooling requirements, implying that setup times depend on all jobs previously scheduled on the same machine, owing to tool configurations. In this study, this NP NP -hard problem is addressed using a parallel biased random-key genetic algorithm hybridized with local search procedures organized using variable neighborhood descent. The proposed genetic algorithm is compared with the state-of-the-art methods considering 2,880 benchmark instances from the literature reddivided into two sets. For the set of small instances, the proposed method is compared with a mathematical model and better or equal results for 99.86\% of instances are presented. For the set of large instances, the proposed method is compared to a metaheuristic and new best solutions are presented for 93.89\% of the instances. In addition, the proposed method is 96.50\% faster than the compared metaheuristic, thus comprehensively outperforming the current state-of-the-art methods.},
  archive      = {J_EJOR},
  author       = {Leonardo Cabral R. Soares and Marco Antonio M. Carvalho},
  doi          = {10.1016/j.ejor.2020.02.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {955-964},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Biased random-key genetic algorithm for scheduling identical parallel machines with tooling constraints},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Value of by-product synergy: A supply chain perspective.
<em>EJOR</em>, <em>285</em>(3), 941–954. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By-product synergy (BPS) is an innovative method to dispose of waste and create value from waste. We examine a supply chain composed of two competing manufacturers and one downstream processing plant with limited BPS capacity. The plant generates a by-product with waste from manufacturers and sells the by-product in a market with uncertain prices. We derive each manufacturer’s equilibrium decisions (production quantity and disposal amount) and the plant’s capacity investment plan (ex ante) and optimal transfer price (ex post). We show that BPS always benefits manufacturers, and although two opposite effects (competition effect and cost saving effect) appear, each manufacturer’s profit in limited BPS capacity is always lower than that in infinite BPS capacity. The reason is that the plant has the power to determine the transfer price and manufacturers prefer highest cost saving (enough BPS capacity) at the expense of highest competition effect. The effects of BPS technology parameters (i.e., processing cost of waste and investment cost of capacity) on supply chain performance are also discussed. Finally, we further explore the scenario that the plant determines the transfer price before the by-product’s price uncertainty is realized.},
  archive      = {J_EJOR},
  author       = {Pin Zhou and He Xu and Hongwei Wang},
  doi          = {10.1016/j.ejor.2020.02.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {941-954},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Value of by-product synergy: A supply chain perspective},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Alliance formation in assembly systems with
quality-improvement incentives. <em>EJOR</em>, <em>285</em>(3), 931–940.
(<a href="https://doi.org/10.1016/j.ejor.2020.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an assembly system where n upstream complementary suppliers produce components and sell them to a downstream manufacturer. The manufacturer assembles all the components into final products and sells them in the final market. The demand for final products is assumed to be deterministic and sensitive to both the selling price set by the manufacturer and the quality-improvement effort levels of all suppliers. The suppliers may form coalitions to better coordinate their wholesale pricing and quality-improvement effort decisions. We analyze the stability of coalition structures by adopting farsighted stability concepts. To characterize supplier’s profit allocation in a coalition, we consider three allocation rules, including the equal allocations, the proportional allocations and the Shapley value allocations. The results show that the grand coalition is always stable under both the equal allocations and the proportional allocations. However, under the Shapley value allocations, the grand coalition is stable only when the suppliers’ quality efficiencies have relatively small differences. Conditions under which the suppliers will not act independently are presented as well. Because of the positive externalities of quality improvements, we demonstrate that coalitions of suppliers with lower quality efficiencies could benefit from free-riding on the investments of coalitions of suppliers with higher quality efficiencies in the system.},
  archive      = {J_EJOR},
  author       = {Tingting Li and Junlin Chen},
  doi          = {10.1016/j.ejor.2020.02.041},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {931-940},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Alliance formation in assembly systems with quality-improvement incentives},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Channel coordination under nash bargaining fairness concerns
in differential games of goodwill accumulation. <em>EJOR</em>,
<em>285</em>(3), 916–930. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a supply chain coordination problem with an upstream manufacturer and a downstream retailer that have Nash bargaining fairness concerns. The evolution of consumer goodwill is assumed to be influenced by the final product&#39;s quality improvement level (from the manufacturer) and advertising effort level (from the retailer). We determine the optimal strategies by differential game models for centralized, fairness-neutral decentralized, and fairness-concerned decentralized channels under different power structures. A revenue- and cost-sharing contract is also developed to coordinate the fairness-concerned decentralized channels. We show that decision-makers will accept the proposed contract only if the revenue-sharing rate satisfies certain conditions. Comparison discussions, sensitivity analyses of some key parameters, and numerical studies are conducted to provide further insights. We observe that a dominant channel member&#39;s sensitivity to fairness is relatively more significant in the decision-making process and channel efficiency. Specifically, each member has a greater incentive to adjust the investment and pricing strategies in the channel that it dominates. Additionally, we find that when the supply chain members are fairness-neutral, no power structure exists that can simultaneously be the most beneficial to the channel with the greatest profit, the lowest selling price, and the most improved quality. However, when the supply chain members are fairness-concerned, conditions exist under which either the retailer- or manufacturer-dominated channel can exhibit optimum performance in all three aspects.},
  archive      = {J_EJOR},
  author       = {Zhimin Guan and Tong Ye and Rui Yin},
  doi          = {10.1016/j.ejor.2020.02.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {916-930},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Channel coordination under nash bargaining fairness concerns in differential games of goodwill accumulation},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Value of audit for supply chains with hidden action and
information. <em>EJOR</em>, <em>285</em>(3), 902–915. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outsourcing can provide firms with a competitive advantage by realizing the benefits of suppliers’ low labor, better quality and improved innovation. Yet, the supply chain managers have several concerns about outsourcing which are mainly due to lack of critical information regarding the actions of their suppliers. In this paper, we study the effectiveness of auditing the supplier’s hidden actions for the buyer (principal) when the supplier (agent) is privately informed about the extent of the supply risk. In order to accomplish this, we first extend the standard principal-agent model by considering a case in which the agent’s hidden action affects the extent of information asymmetry between principal and agent. By comparing the agency costs associated with the optimal menu of contracts with and without audit, we then completely characterize the value of audit from the perspectives of both buyer and supplier as well as total supply chain. First, the analysis of value of audit from the buyer’s perspective shows that the buyer can strictly benefit from auditing the supplier’s actions. Second, we find that not only the buyer but also the supplier can strictly benefit from an audit. Third, the audit enables the buyer to customize her contract offerings based on the reliability of the supplier. Finally, by analyzing the impact of problem parameters on the value of the audit, we identify the conditions under which an audit would be beneficial for individual supply chain parties as well as the overall supply chain.},
  archive      = {J_EJOR},
  author       = {Mohammad E. Nikoofal and Mehmet Gümüş},
  doi          = {10.1016/j.ejor.2020.02.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {902-915},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Value of audit for supply chains with hidden action and information},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining mixed integer programming and constraint
programming to solve the integrated scheduling problem of container
handling operations of a single vessel. <em>EJOR</em>, <em>285</em>(3),
884–901. (<a href="https://doi.org/10.1016/j.ejor.2020.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the container terminals of seaports, the container handling system consists of a variety of container handling machines such as quay cranes, internal yard trucks, and yard cranes. This study applies a holistic approach to the integrated scheduling of these machines for the container handling operations of a single vessel. We formulate this special hybrid flow shop scheduling problem through both mixed integer programming (MIP) and constraint programming (CP) techniques. Then we develop an easily-implemented approach that combines the strengths of MIP and CP. First, the MIP model, which only considers quay crane scheduling, is solved by an MIP solver, and a quay crane allocation plan is retrieved from the MIP solution. Then, this quay crane allocation plan is fed to the CP model, warm-starting the branch-and-prune algorithm built in a CP optimizer. Our numerical experiments reveal that this hybrid MIP/CP approach can solve the large-sized instances with up to 1000 containers, 6 quay cranes, 36 yard trucks, and 15 yard cranes to optimality with a gap of less than 3.31\%, within a solution time of 2 minutes. If we increase the solution time to 5 minutes, this hybrid approach solves larger instances with up to 1400 containers to optimality with a gap of less than 1.41\%. The state-of-the-art dedicated algorithms reported in the literature (which address an easier version of the same problem by ignoring non-crossing constraints and safety margins between quay cranes) are only able to find solutions for real-life instances with up to 500 containers within the solution time of 2930 or 5221 seconds, leaving a 4\% or an unknown optimality gap. Thus, this study improves the solution of this integrated scheduling problem in terms of the instance size, solution efficiency, and solution optimality.},
  archive      = {J_EJOR},
  author       = {Tianbao Qin and Yuquan Du and Jiang Hang Chen and Mei Sha},
  doi          = {10.1016/j.ejor.2020.02.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {884-901},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining mixed integer programming and constraint programming to solve the integrated scheduling problem of container handling operations of a single vessel},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Packing rectangles into a fixed size circular container:
Constructive and metaheuristic search approaches. <em>EJOR</em>,
<em>285</em>(3), 865–883. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the orthogonal packing of rectangular objects into a circular container of fixed radius. We propose a new constructive heuristic called pack which builds a feasible packing starting from an ordered list of rectangles. This decoding procedure is polynomial and permits to move from the permutations search space to the packings search space by means of simple combinatorial moves combined with powerful geometrical analytical forms. The pack procedure is integrated into two well known metaheuristics, namely, a variable neighbourhood search (VNS) and a simulated annealing (SA). Two variants, namely xVNS and xSA, which stand as accelerated versions of VNS and SA are also presented. The proposed methodology produces 32 new best solutions out of the 54 benchmark instances while requiring less computational effort than the state-of-the-art method. In addition, we conduct experiments on newly generated larger instances which we have made publicly available alongside their respective results obtained from the proposed metaheuristics.},
  archive      = {J_EJOR},
  author       = {Mouaouia Cherif Bouzid and Said Salhi},
  doi          = {10.1016/j.ejor.2020.02.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {865-883},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Packing rectangles into a fixed size circular container: Constructive and metaheuristic search approaches},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two heuristics for the rainbow spanning forest problem.
<em>EJOR</em>, <em>285</em>(3), 853–864. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rainbow spanning forest (say RF) of a given connected, undirected and edge-colored graph ( G ) is a spanning forest of a set of rainbow components, where a rainbow component is a tree whose edges have different colors. The rainbow spanning forest problem (RSFP) of G aims to find a RF of G with the minimum number of rainbow components. The RSFP which is recently introduced is NP NP -hard on general graphs and trees, but finds its applications in many situations in which one requires to distinguish between different types of connections in network. To the best of our knowledge, there exists only one paper (Carrabs et al. 2018b) that presents a problem-specific heuristic called greedy algorithm (say GH) and a multi-start scheme embedding this GH (say MSGH) in order to further improve the results. This paper presents a novel and fast problem-specific heuristic Heu_RSF . With the intent of improving solution quality at the cost of higher computational time, we present an artificial bee colony algorithm (ABC_RSFP) for the RSFP. Main components of ABC_RSFP such as randomized version of Heu_RSF in solution initialization and grouping-based neighborhood strategies in conjunction with the use of Heu_RSF as a repair operator help in making ABC_RSFP more effective framework. On a set of benchmark instance scenarios, experimental results suggest that Heu_RSF is effective particularly on instances of larger scenarios with higher density and is computationally much faster than GH and MSGH. ABC_RSFP outperforms MSGH on almost all instance scenarios and shows its effectiveness in terms of computational time.},
  archive      = {J_EJOR},
  author       = {Sudishna Ghoshal and Shyam Sundar},
  doi          = {10.1016/j.ejor.2020.02.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {853-864},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two heuristics for the rainbow spanning forest problem},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On optimal coverage of a tree with multiple robots.
<em>EJOR</em>, <em>285</em>(3), 844–852. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the algorithmic problem of optimally covering a tree with k mobile robots. The tree is known to all robots, and our goal is to assign a walk to each robot in such a way that the union of these walks covers the whole tree. We assume that the edges have the same length, and that traveling along an edge takes a unit of time. Two objective functions are considered: the cover time and the cover length. The cover time is the maximum time a robot needs to finish its assigned walk and the cover length is the sum of the lengths of all the walks. We also consider a variant in which the robots must rendezvous periodically at the same vertex in at most a certain number of moves. We show that the problem is different for the two cost functions. For the cover time minimization problem, we prove that the problem is NP-hard when k is part of the input, regardless of whether periodic rendezvous are required or not. For the cover length minimization problem, we show that it can be solved in polynomial time when periodic rendezvous are not required, and it is NP-hard otherwise.},
  archive      = {J_EJOR},
  author       = {I. Aldana-Galván and J.C. Catana-Salazar and J.M. Díaz-Báñez and F. Duque and R. Fabila-Monroy and M.A. Heredia and A. Ramírez-Vigueras and J. Urrutia},
  doi          = {10.1016/j.ejor.2020.02.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {844-852},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On optimal coverage of a tree with multiple robots},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of diversified package tours for the digital travel
industry: A branch-cut-and-price approach. <em>EJOR</em>,
<em>285</em>(3), 825–843. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the revolution brought by the internet and communication technology in daily life, this paper examines how the online travel agencies (OTA) can use these technologies to improve customer value. We consider the design of a fixed number of package tours offered to customers in the digital travel industry. This can be formulated as a Team Orienteering Problem (TOP) with restrictions on budget and time. Different from the classical TOP, our work is the first one to introduce controlled diversity between tours. This enables the OTA to offer tourists a diversified portfolio of tour packages for a given period of time, each potential customer choosing a single tour in the selected set, rather than multiple independent tours over several periods as in the classical TOP. Tuning the similarity parameter between tours enables to manage the trade-off between individual preferences in consumers’ choices and economies of scale in agencies’ bargaining power. We propose compact and extended formulations and solve the master problem by a branch-and-price method, and an alternative branch-cut-and-price method. The latter uses a delayed dominance rule in the shortest path pricing problem solved by dynamic programming. Our methods are tested over benchmark TOP instances of the literature, and a real dataset collected from a Chinese OTA. We explore the impact of tours diversity on all stakeholders, and assess the computational performance of various approaches.},
  archive      = {J_EJOR},
  author       = {Yanlu Zhao and Laurent Alfandari},
  doi          = {10.1016/j.ejor.2020.02.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {825-843},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Design of diversified package tours for the digital travel industry: A branch-cut-and-price approach},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review on maintenance optimization. <em>EJOR</em>,
<em>285</em>(3), 805–824. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To this day, continuous developments of technical systems and increasing reliance on equipment have resulted in a growing importance of effective maintenance activities. During the last couple of decades, a substantial amount of research has been carried out on this topic. In this study, we review more than two hundred papers on maintenance modeling and optimization that have appeared in the period 2001 to 2018. We begin by describing terms commonly used in the modeling process. Then, in our classification, we first distinguish single-unit and multi-unit systems. Further sub-classification follows, based on the state space of the deterioration process modeled. Other features that we discuss in this review are discrete and continuous condition monitoring, inspection, replacement, repair, and the various types of dependencies that may exist between units within systems. We end with the main developments during the review period and with potential future research directions.},
  archive      = {J_EJOR},
  author       = {Bram de Jonge and Philip A. Scarf},
  doi          = {10.1016/j.ejor.2019.09.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {805-824},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review on maintenance optimization},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Do banks change their liquidity ratios based on network
characteristics? <em>EJOR</em>, <em>285</em>(2), 789–803. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By applying interbank network simulation, this paper investigates the impact of interbank network topology on bank liquidity ratios. Whereas regulators have put more emphasis on liquidity requirements since the global financial crisis of 2007–2008, how differently shaped interbank networks affect individual bank liquidity behavior remains an open issue. We look at how banks&#39; interconnectedness within interbank loan and deposit networks affects their decisions to hold more or less liquidity during normal times and distress times. Our sample consists of commercial, investment, and real estate and mortgage banks in 28 European countries and allows us to differentiate large and small networks. Our results show that accounting for bank connections within a network is important to understand how banks set their liquidity ratios. Our findings have critical implications for the implementation of Basel III liquidity requirements and bank supervision more generally.},
  archive      = {J_EJOR},
  author       = {Aref Mahdavi Ardekani and Isabelle Distinguin and Amine Tarazi},
  doi          = {10.1016/j.ejor.2020.02.011},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {789-803},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Do banks change their liquidity ratios based on network characteristics?},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncovering spatial productivity centers using asymmetric
bidirectional spillovers. <em>EJOR</em>, <em>285</em>(2), 767–788. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The principal contribution of this paper is to present the first method to sift through a large number of firms in an industry to uncover which firms act as large spatial total factor productivity (TFP) growth centers. We define a large spatial TFP growth center as a firm that is a large net generator of spatial TFP growth spillovers, i.e., it is a source of large TFP growth spill-outs to other firms vis-à-vis the size of the TFP growth spill-ins that permeate to the firm from other firms. We use this definition because, other things being equal, firms would want to locate near a firm that is a net generator of TFP growth spillovers. In the process of presenting the above method we make three further contributions, two of which are methodological and the other relates to our application. First, rather than follow the literature on spatial frontier modeling by considering spatial interaction between firms in a single network, we introduce a more sophisticated model that is able to account for spatial interaction in multiple networks. Second, we obtain bidirectional spatial TFP growth decompositions by complementing a unidirectional decomposition in the literature, where the spillover components are spill-ins to a firm, with a decomposition that includes spill-out components. Third, from a spatial revenue frontier for U.S. banks (1998–2015), we find a number of cases where banks that represent large spatial TFP growth centers have branches that cluster together, while in several states we find no such clusters.},
  archive      = {J_EJOR},
  author       = {Anthony J. Glass and Karligash Kenjegalieva and Mustapha Douch},
  doi          = {10.1016/j.ejor.2020.02.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {767-788},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Uncovering spatial productivity centers using asymmetric bidirectional spillovers},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Early exercise boundaries for american-style knock-out
options. <em>EJOR</em>, <em>285</em>(2), 753–766. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel representation for the early exercise boundary of American-style double knock-out options in terms of the simpler optimal stopping boundary of a nested single barrier contract. Such representation only requires the existence, continuity and monotonicity (in time) of the nested single barrier exercise boundary, and these requirements are proved for the whole class of single-factor exponential-Lévy processes. To illustrate the practical relevance of our results, a new put-call duality relation is obtained, a real options application is provided and the Fourier space time-stepping method, the COS approximation , and the static hedging portfolio approach are all adapted to the valuation of American-style double knock-out options.},
  archive      = {J_EJOR},
  author       = {João Pedro Vidal Nunes and João Pedro Ruas and José Carlos Dias},
  doi          = {10.1016/j.ejor.2020.02.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {753-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Early exercise boundaries for american-style knock-out options},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The value of cooperation in interregional transmission
planning: A noncooperative equilibrium model approach. <em>EJOR</em>,
<em>285</em>(2), 740–752. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization methods for regional transmission planning overlook boundaries between transmission planning entities and do not account for their lack of coordination. The practical result of those boundaries is inefficient plans because one planning region may disregard the costs and benefits that its network changes impose on other regions. We develop a bi-level EPEC (Equilibrium Problem with Equilibrium Constraints) model that represents a game among multiple noncooperative transmission planners in the upper level together with consumers and generators for the entire region in the lower level. We find that the equilibrium transmission plans from such a framework can differ significantly from those from a cooperative framework and have fewer net benefits. Importantly, we find that cooperation among transmission planners leads to increased competition among generators from adjoining regions, which in turn leads to more efficient generator investments. We prove that the system-wide benefit from cooperation among transmission planners is always positive. We then calculate the value of this cooperation for a small test case with two transmission planners, while also identifying the market parties who gain — and those who lose — from this cooperation.},
  archive      = {J_EJOR},
  author       = {Saamrat Kasina and Benjamin F. Hobbs},
  doi          = {10.1016/j.ejor.2020.02.018},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {740-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The value of cooperation in interregional transmission planning: A noncooperative equilibrium model approach},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal crop allocation including market trends and water
availability. <em>EJOR</em>, <em>285</em>(2), 728–739. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a multi-period mixed integer nonlinear programming model for determining the optimal crop allocation for several planting cycles based on future crop prices and fresh water availability. An autoregressive moving average model is implemented to predict prices, and a new superstructure that includes all configurations of interest for the reuse, recycling, storage, and regeneration of water is employed. Two characteristic examples considering maize, wheat, alfalfa, and beans and their optimal scheduling for the years 2020, 2021, and 2022 are solved with the objective of maximizing the total annual profit. In determining the profit, the operating costs include fresh water, fresh fertilizer, and pumping and the capital costs include storage tanks, treatment units, pipelines, and pumps.},
  archive      = {J_EJOR},
  author       = {Maritza E. Cervantes-Gaxiola and Erik F. Sosa-Niebla and Oscar M. Hernández-Calderón and José M. Ponce-Ortega and Jesús R. Ortiz-del-Castillo and Eusiel Rubio-Castro},
  doi          = {10.1016/j.ejor.2020.02.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {728-739},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal crop allocation including market trends and water availability},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The median routing problem for simultaneous planning of
emergency response and non-emergency jobs. <em>EJOR</em>,
<em>285</em>(2), 712–727. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a setting in emergency logistics where emergency responders must also perform a set of known, non-emergency jobs in the network when there are no active emergencies going on. These jobs typically have a preventive function, and allow the responders to use their idle time much more productively than in the current standard. When an emergency occurs, the nearest responder must abandon whatever job he or she is doing and go to the emergency. This leads to the optimisation problem of timetabling jobs and moving responders over a discrete network such that the expected emergency response time remains minimal. Our model, the Median Routing Problem, addresses this complex problem by minimising the expected response time to the next emergency and allowing for re-solving after this. We describe a mixed-integer linear program and a number of increasingly refined heuristics for this problem. We created a large set of benchmark instances, both from real-life case study data and from a generator. On the real-life case study instances, the best performing heuristic finds on average a solution only 3.4\% away from optimal in a few seconds. We propose an explanation for the success of this heuristic, with the most pivotal conclusion being the importance of solving the underlying p -Medians Problem.},
  archive      = {J_EJOR},
  author       = {Dylan Huizing and Guido Schäfer and Rob D. van der Mei and Sandjai Bhulai},
  doi          = {10.1016/j.ejor.2020.02.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {712-727},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The median routing problem for simultaneous planning of emergency response and non-emergency jobs},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic master surgery scheduling. <em>EJOR</em>,
<em>285</em>(2), 695–711. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of the Master Surgery Scheduling Problem (MSSP) is to schedule the medical specialties to the different operating rooms available, such that surgeries may be performed efficiently. We consider a MSSP where elective and emergency patients can be treated in the same operating rooms. In addition to elective-dedicated operating room slots, flexible operating room slots are introduced to handle the fluctuating demand of emergency patients. To solve the MSSP, we propose a simulation-optimization approach consisting of a two-stage stochastic optimization model and a discrete-event simulation model. For the two-stage stochastic optimization model, uncertain arrivals of emergency patients are represented by discrete scenarios. The discrete-event simulation model is developed to address uncertainty related to the surgery duration and the length of stay at the hospital, and to test the Master Surgery Schedule (MSS) developed by the optimization model in a stochastic operational-level environment. In addition, the simulation model is used to generate scenarios for the optimization model. We present some general advice for surgery scheduling based on testing the optimization model in a numerical study. The simulation-optimization approach is applied to a case study from a hospital department that treats both elective and emergency patients. The optimized MSS outperforms the manually generated MSS, both in terms of emergency waiting time for surgery, and emergency interruptions to the flow of electives.},
  archive      = {J_EJOR},
  author       = {Thomas Reiten Bovim and Marielle Christiansen and Anders N. Gullhav and Troels Martin Range and Lars Hellemo},
  doi          = {10.1016/j.ejor.2020.02.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {695-711},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic master surgery scheduling},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic programming model with endogenous and exogenous
uncertainty for reliable network design under random disruption.
<em>EJOR</em>, <em>285</em>(2), 670–694. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing and maintaining a reliable and efficient transportation network is an important industrial problem. Integrating infrastructure protection with the network design model is efficient as these models provide strategic decisions to make a transportation network simultaneously efficient and reliable. We studied a combined network design and infrastructure protection problem subject to random disruptions where the protection is imperfect and multi-level and the effect of disruption is imperfect. In this research, we modeled a resource-constrained decision maker seeking to optimally allocate protection resources to the facilities, and construct links in the network to minimize the expected post-disruption transportation cost (PDTC). We modeled the problem as a two-stage stochastic program with both endogenous and exogenous uncertainty: a facility’s post-disruption capacity depends probabilistically on the protection decision, making the uncertainty endogenous, while the link construction decision directly affects the transportation decision. We implemented an accelerated L-shaped algorithm to solve the model and predictive modeling techniques to estimate the probability of a facility’s post-disruption capacity for a given protection and disruption intensity. Numerical results show that solution quality is sensitive to the number of protection levels modeled; average reduction in the expected PDTC is 18.7\% as the number of protection levels increases from 2 to 5. Results demonstrate that the mean value model performs very poorly as the uncertainty increases. Results also indicate that the stochastic programming model is sensitive to the estimation error of the predictive modeling techniques; on average the expected PDTC becomes 6.38\% higher for using the least accurate prediction model.},
  archive      = {J_EJOR},
  author       = {Tanveer Hossain Bhuiyan and Hugh R. Medal and Sarah Harun},
  doi          = {10.1016/j.ejor.2020.02.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {670-694},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A stochastic programming model with endogenous and exogenous uncertainty for reliable network design under random disruption},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On systems of quotas from bankruptcy perspective: The
sampling estimation of the random arrival rule. <em>EJOR</em>,
<em>285</em>(2), 655–669. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a sampling procedure for estimating the random arrival rule in bankruptcy situations. It is based on simple random sampling with replacement and it adapts an estimation method of the Shapley value for transferable utility games, especially useful when dealing with large-scale problems. Its performance is analysed through the establishment of theoretical statistical properties and bounds for the incurred error. Furthermore, this tool is evaluated on two well-studied examples in literature where this allocation rule can be exactly calculated. Finally, we apply this sampling method to provide a new quota for the milk market in Galicia (Spain). After the abolition of the milk European quota system in April 2015, this region represents an example where dairy farmers suffered a massive economic impact after investing heavily in modernising their farms. The resulting quota estimator is compared with two classical rules in bankruptcy literature.},
  archive      = {J_EJOR},
  author       = {Alejandro Saavedra-Nieves and Paula Saavedra-Nieves},
  doi          = {10.1016/j.ejor.2020.02.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {655-669},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On systems of quotas from bankruptcy perspective: The sampling estimation of the random arrival rule},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weighted-additive fuzzy multi-choice goal programming
(WA-FMCGP) for supporting renewable energy site selection decisions.
<em>EJOR</em>, <em>285</em>(2), 642–654. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel weighted-additive fuzzy multi-choice goal programming (WA-FMCGP) model for the imprecise decision context wherein several conflicting goals are present but each goal has multiple-choice aspiration levels (MCALs) and, around them, the fuzzinesses are expressed in terms of membership functions (MFs). The main contribution of this model is its use of an objective function that minimises the weighted-additive summation of the normalised deviations; thus, the model can adopt any minimisation process from any goal programming (GP) variant. The advantages of this FGP-MCGP (fuzzy GP – multi-choice GP) model are shown by using it to solve a numerical example from F-MODM (fuzzy MODM) literature and comparing the results with those of a recent FP-MCGP (fuzzy programming – multi-choice GP) study. The application of the model is also verified using real data (i.e., it can model and support renewable energy site selection (RESS) where the decision context is imprecise). As WA-FMCGP is largely a MODM model, through its application, this study also provides a supplementary method in contrast to the multi-attribute decision-making (MADM) model applications used thus far for RESS.},
  archive      = {J_EJOR},
  author       = {Amin Hocine and Zhuang Zheng-Yun and Noureddine Kouaissah and Li Der-Chiang},
  doi          = {10.1016/j.ejor.2020.02.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {642-654},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weighted-additive fuzzy multi-choice goal programming (WA-FMCGP) for supporting renewable energy site selection decisions},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonparametric advertising budget allocation with inventory
constraint. <em>EJOR</em>, <em>285</em>(2), 631–641. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the optimization problem of the advertising budget allocation for revenue management faced by a marketer. Besides the advertising budget, the marketer is subject to an inventory constraint during the promotion season. The marketer can affect sales by spending on advertising but does not initially know the relationship between the advertising expense and consequent sales. We propose a nonparametric learning-while-doing budget allocation policy for the problem. Specifically, we first conduct a sequence of advertising experiments to learn (predict) the market sales response through observing realized sales (exploration), then based on the learned sales function determine the following budget allocation planning (exploitation). In particular, during the exploration and exploitation phases, we need to balance the advertising and inventory budgets simultaneously. We show that our policy is asymptotically optimal as the size of the market increases. By constructing a worst-case example, we show that our policy achieves near-best asymptotic performance. We also provide numerical illustrations to show how our policy works, and discuss how its performance changes as the system parameters vary. We also glen some managerial implications of our model and policy from the numerical results.},
  archive      = {J_EJOR},
  author       = {Chaolin Yang and Yi Xiong},
  doi          = {10.1016/j.ejor.2020.02.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {631-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nonparametric advertising budget allocation with inventory constraint},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost-sensitive business failure prediction when
misclassification costs are uncertain: A heterogeneous ensemble
selection approach. <em>EJOR</em>, <em>285</em>(2), 612–630. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to assess risks associated with establishing relationships with corporate partners such as clients, suppliers, debtors or contractors, decision makers often turn to business failure prediction models. While a large body of literature has focused on optimizing and evaluating novel methods in terms of classification accuracy, recent research has acknowledged the existence of asymmetric misclassification costs associated with prediction errors and thus, advocates the usage of alternative evaluation metrics. However, these papers often assume a misclassification cost matrix to be known and fixed for both the training and the evaluation of models, whereas in reality these costs are often uncertain. This paper presents a methodological framework based upon heterogeneous ensemble selection and multi-objective optimization for cost-sensitive business failure prediction that accommodates uncertainty at the level of misclassification costs. The framework assumes unknown costs during model training and accommodates varying degrees of uncertainty during model deployment. Specifically, NSGA-II is deployed to optimize cost space resulting in a set of pareto-optimal ensemble classifiers where every learner minimizes expected misclassification cost for a specific range of cost ratios. An extensive set of experiments evaluates the method on multiple data sets and for different scenarios that reflect the extent to which cost ratios are known during model deployment. Results clearly demonstrate the ability of our method to minimize cost under the absence of exact knowledge of misclassification costs.},
  archive      = {J_EJOR},
  author       = {Koen W. De Bock and Kristof Coussement and Stefan Lessmann},
  doi          = {10.1016/j.ejor.2020.01.052},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {612-630},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cost-sensitive business failure prediction when misclassification costs are uncertain: A heterogeneous ensemble selection approach},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identifying the market areas of port-centric logistics and
hinterland intermodal transportation. <em>EJOR</em>, <em>285</em>(2),
599–611. (<a href="https://doi.org/10.1016/j.ejor.2020.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many port authorities have developed ambitious strategies to foster hinterland intermodal transportation. In addition, port-centric logistics, that is, the provision of distribution facilities and value-adding activities in the port area, has expanded in multiple ports. Obviously, such port-centric logistics may impact the operations in the hinterland substantially and could potentially reduce opportunities for intermodal transport in the hinterland. We analyze the interaction between port-centric logistics and hinterland intermodal transportation. We take a logistics service provider&#39;s perspective and we include some key elements in the model, such as detention fees, extra handling, transport efficiency and empty container repositioning. We develop new analytical results identifying the optimal market areas of truck-only transportation, port-centric logistics and hinterland intermodal transportation. Our results show that tension between port-centric logistics and hinterland intermodal transportation is quite likely to happen in practice. We additionally study the use of continental containers as a way to reconcile port-centric logistics and hinterland intermodal transportation and we derive further results. We illustrate our results via an example and we highlight managerial insights.},
  archive      = {J_EJOR},
  author       = {Yann Bouchery and Johan Woxenius and Jan C. Fransoo},
  doi          = {10.1016/j.ejor.2020.02.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {599-611},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Identifying the market areas of port-centric logistics and hinterland intermodal transportation},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic dispatching and repositioning policies for
fast-response service networks. <em>EJOR</em>, <em>285</em>(2), 583–598.
(<a href="https://doi.org/10.1016/j.ejor.2020.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of dispatching and pro-actively repositioning service resources in service networks such that fast responses to service requests are realized in a cost-efficient way. By formulating this problem as a Markov decision process, we are able to investigate the structure of the optimal policy in the application domain of service logistics. Using these insights, we then propose scalable dynamic heuristics for both the dispatching and repositioning sub-problem, based on the minimum weighted bipartite matching problem and the maximum expected covering location problem, respectively. The dynamic dispatching heuristic takes into account real-time information about both the state of equipment and the fleet of service engineers, while the dynamic repositioning heuristic maximizes the expected weighted coverage of future service requests. In a test bed with a small network, we show that our most advanced heuristic performs well with an average optimality gap of 4.3\% for symmetric instances and 5.8\% for asymmetric instances. To show the practical value of our proposed heuristics, extensive numerical experiments are conducted on a large test bed with service logistics networks of real-life size where significant savings of up to 56\% compared to a state-of-the-art benchmark policy are attained.},
  archive      = {J_EJOR},
  author       = {Collin Drent and Minou Olde Keizer and Geert-Jan van Houtum},
  doi          = {10.1016/j.ejor.2020.02.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {583-598},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic dispatching and repositioning policies for fast-response service networks},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fleet sizing of reusable articles under uncertain demand and
turnaround times. <em>EJOR</em>, <em>285</em>(2), 566–582. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reusable Articles (RAs) are vital for supply chain logistics as they provide for the safe, economical and environmentally friendly movement of products and materials. The existing literature related to RAs has focused on the design aspects, fleet sizing, allocation of RAs, repositioning of empty RAs, and their end-of-life stages. This paper focuses on the fleet-sizing problem of RAs under uncertain demand and turnaround times. Probability theory-based analytical models are developed to determine the optimal fleet size of RAs in both lost-sales and back-order cases. The proposed analytical procedure can be used to develop models to find the optimal fleet sizes for any demand scenario with a known distribution. In the lost-sales case, analytical models are developed for uniform and normally distributed demand scenarios. A simulation model is developed to test the effectiveness of the average on-hand inventory in service-level estimation. Sensitivity analysis of the average on-hand inventory for the changes in demand and turnaround times have also been conducted and the key managerial insights are summarized. Analytical models are also developed for the back-order case and some specific managerial insights are presented.},
  archive      = {J_EJOR},
  author       = {Ratnaji Vanga and Jayendran Venkateswaran},
  doi          = {10.1016/j.ejor.2020.02.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {566-582},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fleet sizing of reusable articles under uncertain demand and turnaround times},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaborative product development: Managing supplier
incentives for key component testing. <em>EJOR</em>, <em>285</em>(2),
553–565. (<a href="https://doi.org/10.1016/j.ejor.2020.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supplier involvement in new product development has become increasingly common. When developing an innovative component for a new product, it may be sufficient for the component supplier to merely follow the buyer’s specifications and release the component without a good understanding of how well it will fit the final product. While this approach meets reasonable expectations of supplier involvement, it may increase the probability of the final product’s failure. The alternative for the supplier is to exceed expectations by learning more about the final product, performing extra tests, and gathering more information about component fit. This paper studies supplier incentives to exceed expectations before releasing the component for mass production. We develop a sequential non-cooperative game with endogenous information asymmetry. We then solve the game for reward-only and residual claimant contracts and compare the outcomes against the first-best outcome. We find that offering a higher reward to the supplier toward component success does not always lead to greater effort on the supplier side. Instead, this approach may backfire on the buyer by making the supplier less likely to test the component and, in some cases, more likely to release a low-quality component. We also find that introducing a penalty for component failure does not lead to coordination of the supply chain either. However, an efficient contract exists, but it requires the buyer to introduce a penalty for non-release of the component.},
  archive      = {J_EJOR},
  author       = {Timofey Shalpegin},
  doi          = {10.1016/j.ejor.2020.02.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {553-565},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Collaborative product development: Managing supplier incentives for key component testing},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of 3D printing on manufacturer–retailer supply
chains. <em>EJOR</em>, <em>285</em>(2), 538–552. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the impact of 3D printing, or additive manufacturing, on a simple supply chain, consisting of a manufacturer and retailer, that serves stochastic customer demand. 3D printing is a relatively new manufacturing technology that is attracting attention from many firms. However, the impact of 3D printing on operations and firm relationships in a supply chain is relatively unexplored in academic research. A unique aspect of 3D printers is that they can be installed at the retailer in a supply chain, a characteristic that we highlight in our paper since it enables the supply chain to be more responsive to demand. Consequently, 3D printers can be adopted by either the manufacturer or, in a more novel situation, the retailer; we analyze the equilibrium of Stackelberg games in both cases. We characterize the economic and competitive conditions where either firm adopts 3D printing, and show that under either scenario, it is possible for both firms to earn more profit than a benchmark system without 3D printing. We identify and quantify the positive benefits associated with 3D printing, for both firms in a simple supply chain, when either firm adopts this new manufacturing technology. In many cases, the scenario where the manufacturer adopts 3D printing and installs 3D printers at the retailer results in the best profit outcomes for the manufacturer. The retailer’s preference, however, depends on problem parameters. Therefore, supply chain managers should carefully consider the possibility of 3D printing products in their supply chain.},
  archive      = {J_EJOR},
  author       = {Mohammad E. Arbabian and Michael R. Wagner},
  doi          = {10.1016/j.ejor.2020.01.063},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {538-552},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of 3D printing on manufacturer–retailer supply chains},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A learning-based metaheuristic for a multi-objective agile
inspection planning model under uncertainty. <em>EJOR</em>,
<em>285</em>(2), 513–537. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an agile integrated inspection-operation planning model wherein inspection actions are planned alongside the machining operations to make the production process agile. Such an agile integrated plan can respond quickly to inspection-machining needs while still controlling costs and quality. A tri-objective mixed-integer nonlinear programming (TMINLP) model is developed for planning the integrated process in a serial multi-stage production (MSP) system. This model addresses several inter-related decisions; (1) what is the most appropriate inspection process for a quality characteristic, (2) at which stage the inspection of these quality characteristics should be performed, (3) how these inspections should be performed, (4) which inspection tools should be used, and (5) which machine should operate on products. The three objectives are: (1) minimizing the total manufacturing cost, (2) minimizing the number of nonconforming products shipped, and (3) minimizing the total manufacturing time for each product. We also address the uncertainty of manufacturing parameters and equipment disruptions. To solve the model, a novel learning-based metaheuristic is developed based on Multi-Objective Differential Evolution (MODE) algorithm, k -Means clustering method, and an Iterated Local Search (ILS) algorithm. The proposed learning-based metaheuristic algorithm is then integrated with the Taguchi Loss Function and Monte Carlo methods to address the input parameters’ uncertainty. The proposed model and solution algorithm are validated through a set of experiments against optimal solutions, and benchmarked against four existing well-known approaches, i.e. NSGA-II, MODE and two learning-based metaheuristics. The proposed approach is applied to a real industrial case and insights are provided.},
  archive      = {J_EJOR},
  author       = {Maryam Karimi-Mamaghan and Mehrdad Mohammadi and Payman Jula and Amir Pirayesh and Hadi Ahmadi},
  doi          = {10.1016/j.ejor.2020.01.061},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {513-537},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A learning-based metaheuristic for a multi-objective agile inspection planning model under uncertainty},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An efficient and general approach for the joint order
batching and picker routing problem. <em>EJOR</em>, <em>285</em>(2),
497–512. (<a href="https://doi.org/10.1016/j.ejor.2020.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order picking is the process of retrieving products from inventory. It is mostly done manually by dedicated employees called pickers and is considered the most expensive of warehouse operations. To reduce the picking cost, customer orders can be grouped into batches that are then collected by traveling the shortest possible distance. This work presents an exponential linear programming formulation to tackle the joint order batching and picker routing problem. Variables, or columns, are related to the picking routes in the warehouse. Computing such routes is generally an intractable routing problem and relates to the well known traveling salesman problem (TSP). Nonetheless, the rectangular warehouse’s layouts can be used to efficiently solve the corresponding TSP and take into account in the development of an efficient subroutine, called oracle. We therefore investigate whether such an oracle allows for an effective exponential formulation. Experimented on a publicly available benchmark, the algorithm proves to be very effective. It improves many of the best known solutions and provides very strong lower bounds. Finally, this approach is applied to another industrial case to demonstrate its interest for this field of application.},
  archive      = {J_EJOR},
  author       = {Olivier Briant and Hadrien Cambazard and Diego Cattaruzza and Nicolas Catusse and Anne-Laure Ladier and Maxime Ogier},
  doi          = {10.1016/j.ejor.2020.01.059},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {497-512},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An efficient and general approach for the joint order batching and picker routing problem},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A self-tuning variable neighborhood search algorithm and an
effective decoding scheme for open shop scheduling problems with
travel/setup times. <em>EJOR</em>, <em>285</em>(2), 484–496. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study Open Shop Scheduling Problems (OSSPs) that involve (1) travel times between machines and/or (2) sequence-dependent setup times. First, we propose a new decoding scheme on the well-known permutation list representation and study its properties. Second, we describe an effective Variable Neighborhood Search (VNS) algorithm which incorporates the proposed decoding scheme and that uses a self-tuning routine to set its most important parameter. Last, we tested the performance of the algorithm on several sets of instances: the first two sets consisted of classical instances of OSSPs extended with randomly generated both travel times and anticipatory sequence-dependent setup times. The third set of problems were instances of OSSPs with travel times previously presented in the literature. The last set of problems consisted of classical OSSP of the literature and was used mainly to corroborate our results. The solutions of the proposed VNS were compared with the solutions of constraint programming (CP) algorithms, previous solutions and with the optimal solutions where available. The results revealed three important things: First, the decoding strategy was the factor that had the greatest influence on the performance of the VNS algorithm. Second, the proposed self-tuning VNS algorithm was robust and very easy to adapt to a variety of OSSPs. Third, the algorithm exhibited consistent and very competitive performance in terms of computer time and solution quality in all sets of instances.},
  archive      = {J_EJOR},
  author       = {Gonzalo Mejía and Francisco Yuraszeck},
  doi          = {10.1016/j.ejor.2020.02.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {484-496},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A self-tuning variable neighborhood search algorithm and an effective decoding scheme for open shop scheduling problems with travel/setup times},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact algorithms to minimize makespan on single and parallel
batch processing machines. <em>EJOR</em>, <em>285</em>(2), 470–483. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Batch-processing machine scheduling problem is one of the challenging problems in the machine scheduling literature where machines are capable of processing a batch of jobs simultaneously. In this paper, we tackle single and parallel batch processing machine scheduling problems with the objective of minimizing makespan. We propose a reformulation for parallel batch processing machine scheduling, which is based on decomposition in two levels, and an exact algorithm for its solution. To the best of our knowledge, there is no exact algorithm to solve this problem in the literature, except for its formulations solved by off-the-shelf solvers. In the first part of the proposed algorithm, we solve the single batch processing machine problem by a column-and-cut generation algorithm that provides a lower bound for the parallel machine problem. The second part of our proposed algorithm employs a search mechanism to find the minimum makespan for the parallel machine problem, which entails the solution of the reformulation of this problem by column generation at every iteration. The novel aspect of this column generation algorithm is the integration of batch generation and machine schedule generation in a single pricing subproblem. We test the performance of the proposed algorithms on randomly generated instances and show that, on average, they outperform the off-the-shelf solver. The major findings are that the single machine problem provides tight lower and upper bounds for the parallel machine problem, and the proposed algorithm for the parallel machine problem solves more instances to optimality than that for the single machine problem.},
  archive      = {J_EJOR},
  author       = {İbrahim Muter},
  doi          = {10.1016/j.ejor.2020.01.065},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {470-483},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact algorithms to minimize makespan on single and parallel batch processing machines},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Chinese postman games with multi-located players.
<em>EJOR</em>, <em>285</em>(2), 458–469. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyses Chinese postman games with multi-located players, which generalize Chinese postman games by dropping the one-to-one relation between edges and players. In our model, we allow players to be located on more than one edge, but at most one player is located on each edge. The one-to-one relation between edges and players is essential for the equivalence between Chinese postman-totally balanced and Chinese postman-submodular graphs shown in the literature. We illustrate the invalidity of this result in our model. Besides, the location of the post office has a relevant role in the submodularity and totally balancedness of Chinese postman games with multi-located players. Therefore, we focus on sufficient conditions on the assignment of players to edges to ensure submodularity of Chinese postman games with multi-located players, independently of the associated travel costs. Moreover, we provide some insights on the difficulty of finding necessary conditions on assignment functions to this end.},
  archive      = {J_EJOR},
  author       = {Arantza Estévez-Fernández and Herbert Hamers},
  doi          = {10.1016/j.ejor.2020.01.062},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {458-469},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Chinese postman games with multi-located players},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A transformation technique for the clustered generalized
traveling salesman problem with applications to logistics.
<em>EJOR</em>, <em>285</em>(2), 444–457. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clustered generalized traveling salesman problem (CGTSP) is an extension of the classical traveling salesman problem (TSP), where the set of nodes is divided into clusters of nodes, and the clusters are further divided into subclusters of nodes. The objective is to find the minimal route that visits exactly one node from each subcluster in such a way that all subclusters of each cluster are visited consecutively. Due to the additional flexibility of the CGTSP compared to the classical TSP, CGTSP can incorporate a wider range of complexities arising from some practical applications. However, the absence of a good solution method for CGTSP is currently a major impediment in the use of the framework for modeling. Accordingly, the main objective of this paper is to enable the powerful framework of CGTSP for applied problems. To attain this goal, we first develop a solution method by an efficient transformation from CGTSP to TSP. We then demonstrate that not only the solution method provides far superior solution quality compared to existing methods for solving CGTSP, but also it enables practical solutions to far larger CGTSP instances. Finally, to illustrate that the modeling framework and the solution method apply to some practical problems of realistic sizes, we conduct a computational experiment by considering the application of CGTSP to two modern logistics problems; namely, automated storage and retrieval systems (logistics inside the warehouse) and drone-assisted parcel delivery service (logistics outside the warehouse).},
  archive      = {J_EJOR},
  author       = {Pouya Baniasadi and Mehdi Foumani and Kate Smith-Miles and Vladimir Ejov},
  doi          = {10.1016/j.ejor.2020.01.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {444-457},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A transformation technique for the clustered generalized traveling salesman problem with applications to logistics},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Packing ellipsoids in an optimized cylinder. <em>EJOR</em>,
<em>285</em>(2), 429–443. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper studies packing ellipsoids of revolution in a cylindrical container of minimum volume. Ellipsoids can be continuously rotated and translated. Two nonlinear mathematical programming models are introduced: exact and approximated. The latter uses an optimized multi-spherical approximation of ellisoids. For both models the phi-function technique is employed to describe analytically non-overlapping and containment constraints. Two solution approaches are proposed to solve the packing problem. Computational results for up to 500 ellipsoids are provided to demonstrate efficiency of the proposed approaches.},
  archive      = {J_EJOR},
  author       = {Tatiana Romanova and Igor Litvinchev and Alexander Pankratov},
  doi          = {10.1016/j.ejor.2020.01.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {429-443},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Packing ellipsoids in an optimized cylinder},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recent advances in selection hyper-heuristics.
<em>EJOR</em>, <em>285</em>(2), 405–428. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyper-heuristics have emerged as a way to raise the level of generality of search techniques for computational search problems. This is in contrast to many approaches, which represent customised methods for a single problem domain or a narrow class of problem instances. The term hyper-heuristic was defined in the early 2000s as a heuristic to choose heuristics , but the idea of designing high-level heuristic methodologies can be traced back to the early 1960s. The current state-of-the-art in hyper-heuristic research comprises a set of methods that are broadly concerned with intelligently selecting or generating a suitable heuristic for a given situation. Hyper-heuristics can be considered as search methods that operate on lower-level heuristics or heuristic components, and can be categorised into two main classes: heuristic selection and heuristic generation. Here we will focus on the first of these two categories, selection hyper-heuristics. This paper gives a brief history of this emerging area, reviews contemporary selection hyper-heuristic literature, and discusses recent selection hyper-heuristic frameworks. In addition, the existing classification of selection hyper-heuristics is extended, in order to reflect the nature of the challenges faced in contemporary research. Unlike the survey on hyper-heuristics published in 2013, this paper focuses only on selection hyper-heuristics and presents critical discussion, current research trends and directions for future research.},
  archive      = {J_EJOR},
  author       = {John H. Drake and Ahmed Kheiri and Ender Özcan and Edmund K. Burke},
  doi          = {10.1016/j.ejor.2019.07.073},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {405-428},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Recent advances in selection hyper-heuristics},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Assessing sustainability performance of global supply
chains: An input-output modeling approach. <em>EJOR</em>,
<em>285</em>(1), 393–404. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring the sustainability performance of supply chains is fundamental to sustainable supply chain management. Sustainability performance is usually evaluated from multiple aspects within the triple bottom line framework. With globalization, supply chains have also been characterized by the complex and global natures. Ignoring the multidimensional and transnational features imposes challenges on the performance assessment of global supply chains (GSCs). To resolve this issue, we propose an input-output modeling approach based on the multi-region input-output (MRIO) model and the data envelopment analysis (DEA) technique, which is able to account for the multidimensional characteristic of supply chains in a global context. Two indices are introduced to measure the status and evolvement of environmental sustainability performance of GSCs. We apply the proposed approach to empirically examine the environmental performance of GSCs of the manufacturing sectors in 16 major economies during 2005–2014. The average environmental inefficiency of the economies was considerable, and roughly 40\% of the pollution could potentially be reduced along GSCs. Overall the environmental performance of GSCs averagely rose by 20.6\% during the study period with fluctuations and regional/sectoral heterogeneities observed.},
  archive      = {J_EJOR},
  author       = {H. Wang and Chen Pan and Qunwei Wang and P. Zhou},
  doi          = {10.1016/j.ejor.2020.01.057},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {393-404},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Assessing sustainability performance of global supply chains: An input-output modeling approach},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Technology adoption in a declining market. <em>EJOR</em>,
<em>285</em>(1), 380–392. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid technological developments are inducing the shift in consumer demand from existing products towards new alternatives. When operating in a declining market, the profitability of incumbent firms is largely dependent on the ability to correctly time the introduction of product innovations. This paper contributes to the existing literature on technology adoption by determining the optimal time to innovate in the context of a declining market. We study the problem of a firm that has an option to undertake the innovation investment and thereby either to add a new product to its portfolio (add strategy) or to replace the established product by the new one (replace strategy). We find that it can be optimal for the firm to innovate not only because of the significant technological improvement, but also due to demand saturation. In the latter case profits of the established product may become so low that the firm will adopt a new technology even if the newest available innovation has not improved for some time. This way, our approach allows to explicitly account for the effect of a decline in the established market on technology adoption. Furthermore, we find that a substantial cannibalization effect occurring under the add strategy results in an inaction region. In this region the firm waits with innovation until the current technology level becomes either low enough to apply the add strategy, or the new technology becomes advanced enough to apply the replace strategy.},
  archive      = {J_EJOR},
  author       = {Verena Hagspiel and Kuno J.M. Huisman and Peter M. Kort and Maria N. Lavrutich and Cláudia Nunes and Rita Pimentel},
  doi          = {10.1016/j.ejor.2020.01.056},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {380-392},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technology adoption in a declining market},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling the dynamics of online review life cycle: Role of
social and economic moderations. <em>EJOR</em>, <em>285</em>(1),
360–379. (<a href="https://doi.org/10.1016/j.ejor.2020.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online review system (ORS) can unite members who share similar interests in topic discussion or knowledge exchange that entails dynamics and complexity. In this work, we propose a multiagent system to replicate the evolution of social bonds and online reviews in ORS. To validate the proposed method, we use big data from a real-world ORS collected over a period of 153 months. Results show that the proposed agent-based model can accurately predict the construction of bonds and the volumes of online reviews. Moreover, social moderation, economic moderation, and the combined moderating mechanism can motivate ORS members to post reviews. The stage (phase) of the review life cycle and the degree of moderation significantly impact the effectiveness of the mechanisms. Depending on the stage of the review life cycle, social and economic moderators have different degrees of success in generating online reviews. In the early stage, economic moderation is effective, whereas social moderation works better in the late stage. When the moderating levels are medium or high, the combined social and economic moderation is much better than the stand-alone mechanism. Although social bonds are positively associated with more posting, none of the moderating mechanisms (economic, social, or combined) can significantly enhance the bond. To manage ORS effectively, managers need to switch from the conventional static view (relying on single theory) to the dynamic view. In addition, they should incorporate social exchange, motivation, and social network concepts at different stages of the ORS life cycle.},
  archive      = {J_EJOR},
  author       = {Guoyin Jiang and Jennifer Shang and Wenping Liu and Xiaodong Feng and Junli Lei},
  doi          = {10.1016/j.ejor.2020.01.054},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {360-379},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling the dynamics of online review life cycle: Role of social and economic moderations},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uncertain bidding zone configurations: The role of
expectations for transmission and generation capacity expansion.
<em>EJOR</em>, <em>285</em>(1), 343–359. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ongoing policy discussions on the reconfiguration of bidding zones in European electricity markets induce uncertainty about the future market design. This paper deals with the question of how this uncertainty affects market participants and their long-run investment decisions in generation and transmission capacity. Generalizing the literature on pro-active network expansion planning, we propose a stochastic multilevel model which incorporates generation capacity investment, network expansion, and market operation, taking into account uncertainty about the future bidding zone configuration. Using a stylized two-node network, we disentangle different effects that uncertainty has on market outcomes. If there is a possibility that future bidding zone configurations provide improved regional price signals, welfare gains materialize even if the change does not actually take place. As a consequence, welfare gains of an actual change of the bidding zone configuration are substantially lower due to those anticipatory effects. Additionally, we show substantial distributional effects in terms of both expected gains and risks, between producers and consumers and between different generation technologies.},
  archive      = {J_EJOR},
  author       = {M. Ambrosius and J. Egerer and V. Grimm and A.H. van der Weijde},
  doi          = {10.1016/j.ejor.2020.01.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {343-359},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Uncertain bidding zone configurations: The role of expectations for transmission and generation capacity expansion},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Management of online server congestion using optimal demand
throttling. <em>EJOR</em>, <em>285</em>(1), 324–342. (<a
href="https://doi.org/10.1016/j.ejor.2020.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bandwidth throttling is widely employed in practice by online-service-providers (OSPs) as a server/network congestion management tool. However, this topic has been largely neglected in the academic literature. To the best of our knowledge, this is the first analytical study that aims at achieving an optimal (non-discriminatory) throttling mechanism for bandwidth when user demand is stochastic. In our setting, the demand dynamics of the OSP is governed by a geometric Brownian process. There are costs associated with maintaining and throttling demand; in particular, throttling cost includes both fixed and proportional costs. As users experience inferior service speeds during throttling, the proposed model modifies the demand dynamics to adequately capture users’ reactions to throttling. OSP’s objective is to determine the optimal throttling strategy that minimizes the total expected discounted cost of maintaining and throttling demand. By assuming the existence of an optimal strategy, we use a dynamic programming (Quasi-Variational Inequality) approach to show that it is optimal for the OSP to throttle the demand whenever it reaches a threshold level and downgrade the service speed by a fixed factor while the throttling is employed. Our numerical computations strongly suggest that it is always optimal for OSPs to induce negative (demand) growth rates during throttling to reduce unfavorable future demand. Moreover, our comparative statics analysis explains how OSPs should handle user demand with higher growth rates and volatility, service networks that face higher demand fluctuations/volatility during throttling, and the trade-off between non-monetary fixed and proportional cost associated with throttling.},
  archive      = {J_EJOR},
  author       = {Sandun Perera and Varun Gupta and Winston Buckley},
  doi          = {10.1016/j.ejor.2020.02.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {324-342},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Management of online server congestion using optimal demand throttling},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local gaussian correlations in financial and commodity
markets. <em>EJOR</em>, <em>285</em>(1), 306–323. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the increased correlations between commodity and U.S. financial markets, as well as among commodity markets from 1992 to 2017 under a non-linear framework. We study how far the phenomenon of financialization is sustainable, given the several significant events that shaped the 2000s. We use a new measure of asymmetric dependence, namely the local Gaussian correlation which distinguishes between positive and negative local dependence, to detect whether the dependence between commodities and securities and with each other has become stronger. By examining the local Gaussian correlation before and after the break dates, we can apply the contagion test with a bootstrap procedure. Several robustness checks have been performed. The contagion tests give consistent results with the local Gauss correlation estimates. Our findings confirm the existence of the financialization phenomenon between stock markets and commodity markets particularly after the 08/2008 break date. A remarkable exception to financialization remains the gold market.},
  archive      = {J_EJOR},
  author       = {Quynh Nga Nguyen and Sofiane Aboura and Julien Chevallier and Lyuyuan Zhang and Bangzhu Zhu},
  doi          = {10.1016/j.ejor.2020.01.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {306-323},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Local gaussian correlations in financial and commodity markets},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic VAR model-based control charts for batch process
monitoring. <em>EJOR</em>, <em>285</em>(1), 296–305. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of Statistical Process Control (SPC) there are several different approaches to deal with monitoring of batch processes. Such processes present a three-way data structure ( batches × variables × time-instants ) , (batches×variables×time-instants), so that for each batch a multivariate time series is available. Traditional approaches do not take into account the time series nature of the data. They deal with this kind of data by applying multivariate techniques in a reduced two-way data structure, in order to capture variables dynamics in some way. Recent developments in SPC have proposed the use of the Vector Autoregressive (VAR) time series model considering the original three-way structure. However, they are restricted to control approaches focused on VAR residuals. This paper proposes a new approach to deal with batch processes focusing on VAR coefficients instead of residuals. In short, we estimate VAR coefficients from historical in-control reference batch samples and build two multivariate control charts to monitoring new batches. We showcase the advantages of the proposed methodology for offline and online monitoring in a simulate example comparing it with the residual-based approach.},
  archive      = {J_EJOR},
  author       = {Danilo Marcondes Filho and Marcio Valk},
  doi          = {10.1016/j.ejor.2019.12.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {296-305},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic VAR model-based control charts for batch process monitoring},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated location and inventory planning in service parts
logistics with customer-based service levels. <em>EJOR</em>,
<em>285</em>(1), 279–295. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the integrated logistics network design and inventory stocking problem in service parts logistics, where each customer requires a certain response time-based service level. We introduce a non-linear mixed integer optimization model that explicitly captures the interdependency between network design (locating facilities, and allocating customers’ demands to facilities) and inventory stocking decisions (stock levels and their corresponding stochastic fill rates). We then provide two different linearized mixed integer formulations for this problem that can solve small and medium size problems. We show that it is still a challenging problem in general, for which we have a Lagrangian-relaxation based approach that provides extremely tight lower and upper bounds. Our extensive computational study shows the effectiveness of the proposed approach for a variety of problem instances, producing provably near-optimal integrated solutions.},
  archive      = {J_EJOR},
  author       = {Mehmet Ferhat Candas and Erhan Kutanoglu},
  doi          = {10.1016/j.ejor.2020.01.058},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {279-295},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated location and inventory planning in service parts logistics with customer-based service levels},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Increasing electric vehicle adoption through the optimal
deployment of fast-charging stations for local and long-distance travel.
<em>EJOR</em>, <em>285</em>(1), 263–278. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a new strategic multi-period optimization problem for the siting of electric vehicle (EV) charging stations. One main novelty in this problem is that EV adoption over time is influenced by the availability of charging opportunities, as well as by local EV diffusion. Furthermore, to the best of our knowledge, this is the first contribution where the distribution of charging demand is modeled with a combination of node-based - more appropriate for urban or suburban settings - and flow-based approaches - with which we can model the needs of EVs to recharge on intermediary stops on long-haul travels. We propose a mixed-integer linear programming (MILP) formulation for this problem. Our computational experiments show that by simply implementing it in state-of-art MILP solvers, we are unable to obtain feasible solutions for realistically-sized instances. As such, we propose a rolling horizon-based heuristic that efficiently provides provably good solutions to instances based on much larger territories (namely the province of Quebec and the state of California) than those tackled by the methods proposed in the literature for the location of EV charging stations.},
  archive      = {J_EJOR},
  author       = {Miguel F. Anjos and Bernard Gendron and Martim Joyce-Moniz},
  doi          = {10.1016/j.ejor.2020.01.055},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {263-278},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Increasing electric vehicle adoption through the optimal deployment of fast-charging stations for local and long-distance travel},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A coordination mechanism for supply chains with capacity
expansions and order-dependent lead times. <em>EJOR</em>,
<em>285</em>(1), 247–262. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a supply chain consisting of a retailer for short life cycle products facing stochastic customer demand and a manufacturer that initiates production upon receipt of retail orders. Departing from the common view of the newsvendor problem, we assume that the delivery lead time is not fixed, but that both the retailer and the manufacturer have the option to shorten it. Shorter lead times enable the retailer to place orders closer to the start of the selling season where additional information on customer preferences has become available, reducing demand uncertainty. In the work at hand, lead time is assumed to depend on the order quantity, on the supplier&#39;s production capacity, and a fixed transportation delay. This paper proposes a model for determining the optimal order quantity and production capacity in centralized and decentralized settings. For the uncoordinated case, we show that if the retailer&#39;s ability to gather and analyze additional demand information is revealed to the manufacturer, the arising information asymmetry between the two parties can aggravate the double marginalization effect and, in turn, erode supply chain efficiency. In a coordinated supply chain, however, both parties have an incentive to align both order quantity and investments in lead time reduction. To coordinate the decentralized supply chain, we propose a buy-back contract that helps to leverage supply chain profitability. We conclude with an outlook on future research opportunities.},
  archive      = {J_EJOR},
  author       = {Christoph H. Glock and Yacine Rekik and Jörg M. Ries},
  doi          = {10.1016/j.ejor.2020.01.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {247-262},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A coordination mechanism for supply chains with capacity expansions and order-dependent lead times},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Is a “free lunch” a good lunch? The performance of zero
wholesale price-based supply-chain contracts. <em>EJOR</em>,
<em>285</em>(1), 237–246. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, some manufacturers supply their products to retailers at a zero wholesale price (ZWP), and receive compensation by sharing the revenue or receiving some side payment from the retailers. In this paper, we analyse this kind of ZWP-based supply-chain contract. In the basic model, ordering is done either by the manufacturer or the retailer. For both of these cases, we explore ZWP-revenue-sharing (ZR) contracts, ZWP-side-payment (ZS) contracts, and ZWP-revenue-sharing-plus-side-payment (ZRS) contracts. We prove that, irrespective of the ordering scenario being retailer-led or manufacturer-led, only a ZRS contract can achieve win-win coordination. In the extended models, we first study the scenario with multiple products and discuss how a generalised ZRS contract can coordinate the supply chain efficiently. We then investigate greedy wholesale price (GWP)–based contracts, in which the manufacturer charges the retailer a wholesale price equal to the retail price. We find that a GWP-based revenue-sharing-plus-side-payment (GRS) contract and a ZRS contract can both achieve win-win coordination. However, the ZRS contract mean-variance dominates the GRS contract in bringing a lower level of risk to both the retailer and manufacturer if the unit production cost is sufficiently small. We further discuss cases of differences in the perception of ZWP versus non-ZWP contracts. Important managerial insights are derived from the findings.},
  archive      = {J_EJOR},
  author       = {Tsan-Ming Choi and Shu Guo},
  doi          = {10.1016/j.ejor.2020.01.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {237-246},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Is a ‘free lunch’ a good lunch? the performance of zero wholesale price-based supply-chain contracts},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Entropy based risk measures. <em>EJOR</em>, <em>285</em>(1),
223–236. (<a href="https://doi.org/10.1016/j.ejor.2019.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entropy is a measure of self-information which is used to quantify information losses. Entropy was developed in thermodynamics, but is also used to compare probabilities based on their deviating information content. Corresponding model uncertainty is of particular interest and importance in stochastic programming and its applications like mathematical finance, as complete information is not accessible or manageable in general. This paper extends and generalizes the Entropic Value-at-Risk by involving Rényi entropies. We provide explicit relations among different entropic risk measures, we elaborate their dual representations and present their relations explicitly. We consider the largest spaces which allow studying the impact of information in detail and it is demonstrated that these do not depend on the information loss. The dual norms and Hahn–Banach functionals are characterized explicitly.},
  archive      = {J_EJOR},
  author       = {Alois Pichler and Ruben Schlotter},
  doi          = {10.1016/j.ejor.2019.01.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {223-236},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Entropy based risk measures},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal selection and release problem in software testing
process: A continuous time stochastic control approach. <em>EJOR</em>,
<em>285</em>(1), 211–222. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a joint selection of test cases and release problem for a software under test with predetermined classes of test cases and release time deadline. The software test manager can make three alternative choices dynamically during software testing progress before the deadline: continue testing and select a class of test cases, release the software, or scrap the software, with the objective of minimizing the cumulative testing cost plus penalty cost after releasing or scrapping the software. We formulate the problem as a continuous time stochastic control model and provide a mathematically rigorous method to establish the concavity of the optimal cost function. Based on this property, we are able to characterize that the optimal release policy has a threshold structure. Moreover, the thresholds are founded to be monotone in the residual time length in the case of homogeneous release cost. Besides, we put forward a method based on low convex envelope and discover that the optimal selection policy also has a threshold or other simple structure, if the running cost or the removal cost is the same for all classes. Finally, we present an approximation algorithm of computing the optimal cost function, by which some numerical examples are studied to justify our theoretical results and the robustness of our policy. We also conduct a case study to compare our dynamic selection and release testing policy with two other commonly used testing policies and find that our policy is the best in most instances.},
  archive      = {J_EJOR},
  author       = {Ping Cao and Ke Yang and Ke Liu},
  doi          = {10.1016/j.ejor.2019.01.075},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {211-222},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal selection and release problem in software testing process: A continuous time stochastic control approach},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An online stochastic algorithm for a dynamic nurse
scheduling problem. <em>EJOR</em>, <em>285</em>(1), 196–210. (<a
href="https://doi.org/10.1016/j.ejor.2018.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the problem studied in the second international nurse rostering competition: a personalized nurse scheduling problem under uncertainty. The schedules must be computed week by week over a planning horizon of up to eight weeks. We present the work that the authors submitted to this competition and which was awarded the second prize. At each stage, the dynamic algorithm is fed with the staffing demand and nurses preferences for the current week and computes an irrevocable schedule for all nurses without knowledge of future inputs. The challenge is to obtain a feasible and near-optimal schedule at the end of the horizon. The online stochastic algorithm described in this paper draws inspiration from the primal-dual algorithm for online optimization and the sample average approximation, and is built upon an existing static nurse scheduling software. The procedure generates a small set of candidate schedules, rank them according to their performance over a set of test scenarios, and keeps the best one. Numerical results show that this algorithm is very robust, since it has been able to produce feasible and near optimal solutions on most of the proposed instances ranging from 30 to 120 nurses over a horizon of 4 or 8 weeks. Finally, the code of our implementation is open source and available in a public repository.},
  archive      = {J_EJOR},
  author       = {Antoine Legrain and Jérémy Omer and Samuel Rosat},
  doi          = {10.1016/j.ejor.2018.09.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {196-210},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An online stochastic algorithm for a dynamic nurse scheduling problem},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Meso-parametric value function approximation for dynamic
customer acceptances in delivery routing. <em>EJOR</em>,
<em>285</em>(1), 183–195. (<a
href="https://doi.org/10.1016/j.ejor.2019.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of mobile communication, ample computing power, and Amazon’s training of customers has led to last-mile delivery challenges and created struggles for companies seeking to budget their limited delivery resources efficiently to generate enough revenue. In this paper, we examine the capacitated customer acceptance problem with stochastic requests (CAPSR), a problem in which a company seeks to maximize expected revenue by accepting or rejecting requests. Each accepted request generates revenue and must be routed, consuming driver time and vehicle capacity. To solve the problem, we introduce a novel method of value function approximation (VFA). Conventionally, VFAs are either parametric (P-VFAs) or non-parametric (N-VFAs). Both VFAs have advantages and shortcomings and their performances rely significantly on the structure of the underlying problem. To combine the advantages and to alleviate the shortcomings of P-VFA and N-VFA used individually, we present a novel method, meso-parametric value function approximation (M-VFA). The results of computational experiments show that the M-VFA outperforms benchmarks for the CAPSR and show M-VFA offers the advantages of the individual VFAs while alleviating their shortcomings. Most importantly, we demonstrate that simultaneous approximations lead to better outcomes than either N- and P-VFA individually or some ex-post combination.},
  archive      = {J_EJOR},
  author       = {Marlin W. Ulmer and Barrett W. Thomas},
  doi          = {10.1016/j.ejor.2019.04.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {183-195},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Meso-parametric value function approximation for dynamic customer acceptances in delivery routing},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal a priori tour and restocking policy for the
single-vehicle routing problem with stochastic demands. <em>EJOR</em>,
<em>285</em>(1), 172–182. (<a
href="https://doi.org/10.1016/j.ejor.2018.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a model for the single-vehicle routing problem with stochastic demands (SVRPSD) with optimal restocking. The model is derived from a characterization of the SVRPSD as a Markov decision process (MDP) controlled by a certain class of policies, and is valid for general discrete demand probability distributions. We transform this MDP into an equivalent mixed-integer linear model, which is then used to solve small instances to optimality. By doing so, we are able to quantify the drawbacks associated with the detour-to-depot restocking policy, an assumption of many exact approaches for the (multivehicle) VRPSD. We also examine the tradeoff between the deterministic a priori cost and the stochastic restocking cost for varying route load scenarios. Finally, a wait-and-see model for the SVRPSD is proposed, and is used within a parallel heuristic to solve larger literature instances with up to 150 nodes and Poisson distributed demands. Computational experiments demonstrate the effectiveness of the heuristic approach, and also indicate under which circumstances near-optimal solutions can be obtained by the myopic strategy of a priori route cost minimization.},
  archive      = {J_EJOR},
  author       = {Alexandre M. Florio and Richard F. Hartl and Stefan Minner},
  doi          = {10.1016/j.ejor.2018.10.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {172-182},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal a priori tour and restocking policy for the single-vehicle routing problem with stochastic demands},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust routing, its price, and the tradeoff between routing
robustness and travel time reliability in road networks. <em>EJOR</em>,
<em>285</em>(1), 159–171. (<a
href="https://doi.org/10.1016/j.ejor.2018.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose in this article an adaptive algorithm for optimal and robust guidance for the users of the road networks. The algorithm is based on the Stochastic On Time Arrival (SOTA) family of routing algorithms, which is appropriate for taking into account the variability of travel times through the road networks. The SOTA approach permits the derivation of the maximum cumulative probability distribution of the time arrival toward a given destination in the network. Those distributions allow the selection of the most reliable origin-destination paths under given travel time budgets. We investigate here the introduction of robustness against link and path failures in the criterion of the guidance strategy selection. Our algorithm takes into account the reliability of itinerary travel times, since it is based on a SOTA approach. In addition, the algorithm takes into account itinerary robustness, by favoring itineraries with possible and reliable alternative diversions, in case of link failures, with respect to itineraries without or with less reliable alternatives. We first analyze the algorithm in its static version, without considering the traffic dynamics, and show some interesting properties. We then combine the robust guidance algorithm with a dynamic traffic model by using the traffic simulator SUMO (Simulation of Urban Mobility), and illustrate its effectiveness in some dynamic scenarios.},
  archive      = {J_EJOR},
  author       = {Farida Manseur and Nadir Farhi and Cyril Nguyen Van Phu and Habib Haj-Salem and Jean-Patrick Lebacque},
  doi          = {10.1016/j.ejor.2018.10.053},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {159-171},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust routing, its price, and the tradeoff between routing robustness and travel time reliability in road networks},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The stochastic shortest path problem: A polyhedral
combinatorics perspective. <em>EJOR</em>, <em>285</em>(1), 148–158. (<a
href="https://doi.org/10.1016/j.ejor.2018.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give a new framework for the stochastic shortest path problem in finite state and action spaces. Our framework generalizes both the frameworks proposed by Bertsekas and Tsitsiklis (1991) and by Bertsekas and Yu (2016). We prove that the problem is well-defined and (weakly) polynomial when (i) there is a way to reach the target state from any initial state and (ii) there is no transition cycle of negative costs (a generalization of negative cost cycles). These assumptions generalize the standard assumptions for the deterministic shortest path problem and our framework encapsulates the latter problem (in contrast with prior works). In this new setting, we can show that (a) one can restrict to deterministic and stationary policies, (b) the problem is still (weakly) polynomial through linear programming, (c) Value Iteration and Policy Iteration converge, and (d) we can extend Dijkstra’s algorithm.},
  archive      = {J_EJOR},
  author       = {Matthieu Guillot and Gautier Stauffer},
  doi          = {10.1016/j.ejor.2018.10.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {148-158},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The stochastic shortest path problem: A polyhedral combinatorics perspective},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Valuing portfolios of interdependent real options under
exogenous and endogenous uncertainties. <em>EJOR</em>, <em>285</em>(1),
133–147. (<a href="https://doi.org/10.1016/j.ejor.2019.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the value of portfolios of real options is often affected by both exogenous and endogenous sources of uncertainty, most existing valuation approaches consider only the former and neglect the latter. In this paper, we introduce an approach for valuing portfolios of interdependent real options under both types of uncertainty. In particular, we study a large portfolio of options (deferment, staging, mothballing, abandonment) under conditions of four underlying uncertainties. Two of the uncertainties, decision-dependent cost to completion and state-dependent salvage value, are endogenous, the other two, operating revenues and their growth rate, are exogenous. Assuming that endogenous uncertainties can be exogenised, we formulate the valuation problem as a discrete stochastic dynamic program. To approximate the value of this optimisation problem, we apply a simulation-and-regression-based approach and present an efficient valuation algorithm. The key feature of our algorithm is that it exploits the problem structure to explicitly account for reachability – that is the sample paths in which resource states can be reached. The applicability of the approach is illustrated by valuing an urban infrastructure investment. We conduct a reachability analysis and show that the presence of the decision-dependent uncertainty has adverse computational effects as it increases algorithmic complexity and reduces simulation efficiency. We investigate the way in which the value of the portfolio and its individual options are affected by the initial operating revenues, and by the degrees of exogenous and endogenous uncertainty. The results demonstrate that ignoring endogenous, decision- and state-dependent uncertainty can lead to substantial over- and under-valuation, respectively.},
  archive      = {J_EJOR},
  author       = {Sebastian Maier and Georg C. Pflug and John W. Polak},
  doi          = {10.1016/j.ejor.2019.01.055},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {133-147},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Valuing portfolios of interdependent real options under exogenous and endogenous uncertainties},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal investment decision under switching regimes of
subsidy support. <em>EJOR</em>, <em>285</em>(1), 120–132. (<a
href="https://doi.org/10.1016/j.ejor.2019.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of making a managerial decision when the investment project is subsidized, which results in the resolution of an infinite-horizon optimal stopping problem of a switching diffusion driven by either a homogeneous or an inhomogeneous continuous-time Markov chain. We provide a characterization of the value function (and optimal strategy) of the optimal stopping problem. On the one hand, broadly, we can prove that the value function is the unique viscosity solution to a system of HJB equations. On the other hand, when the Markov chain is homogeneous and the switching diffusion is one-dimensional, we obtain stronger results: the value function is the difference between two convex functions.},
  archive      = {J_EJOR},
  author       = {Carlos Oliveira and Nicolas Perkowski},
  doi          = {10.1016/j.ejor.2019.02.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {120-132},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal investment decision under switching regimes of subsidy support},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Importance sampling in stochastic optimization: An
application to intertemporal portfolio choice. <em>EJOR</em>,
<em>285</em>(1), 106–119. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an approach to construct an analytical approximation of the zero-variance importance sampling distribution. We show specifically how this can be designed for the classic intertemporal portfolio choice problem with proportional transaction costs and constant relative risk aversion preferences. We compare the method to standard variance reduction techniques in single-period optimization and multi-stage stochastic programming formulations of the problem. The numerical experiments show that the method produces significant improvements in solution quality. In the single-period setting, the number of scenarios can be reduced by a factor of 400 with maintained solution quality compared to the best standard method; Latin hypercube sampling. Using importance sampling in multi-stage formulations, the gaps between lower and upper bound estimates are reduced by a factor of 26-500 with maintained scenario tree size. On a higher level, we consider analytical approximations of the zero-variance importance sampling distribution to be a promising method to improve solution quality in stochastic optimization.},
  archive      = {J_EJOR},
  author       = {J. Ekblom and J. Blomvall},
  doi          = {10.1016/j.ejor.2019.01.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {106-119},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Importance sampling in stochastic optimization: An application to intertemporal portfolio choice},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic bank closure and deposit insurance valuation.
<em>EJOR</em>, <em>285</em>(1), 96–105. (<a
href="https://doi.org/10.1016/j.ejor.2018.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study formulates the deposit insurance valuation problem as a zero-sum optimal stopping game using Israeli option with bankruptcy cost. Specifically, closure of a bank is framed as a game between the insured bank and the deposit insurer, in which a bank with financial difficulties is choosing an optimal self-closure point to maximize its benefits from the deposit insurance scheme; and the deposit insurer is choosing an optimal regulatory closure point to minimize their cost of offering the insurance. In such setting, the deposit insurance itself could be regarded as an Israeli put option. With bankruptcy costs taken into consideration, we managed to derive the closed-form solutions to the deposit insurance premium together with the endogenous closure points. Our model could also be used to justify the scenarios of too big to fail, reorganization of problematic bank, and regulator’s forbearance.},
  archive      = {J_EJOR},
  author       = {Tat Wing Wong and Ka Wai Terence Fung and Kwai Sun Leung},
  doi          = {10.1016/j.ejor.2018.09.032},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {96-105},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic bank closure and deposit insurance valuation},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust multi-period portfolio selection based on downside
risk with asymmetrically distributed uncertainty set. <em>EJOR</em>,
<em>285</em>(1), 81–95. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the asymmetrical attitudes of investors towards downside losses and upside gains, this paper proposes a robust multi-period portfolio selection model based on downside risk with asymmetrically distributed uncertainty set, in which the downside losses of a portfolio are controlled by the lower partial moment (LPM). A computationally tractable approximation approach based on second-order cone optimization is used for solving the proposed model. We show in theory that the optimal solution of the robust model can generate a given probability guarantee for individual and joint stochastic constraints. The effect of the asymmetrically distributed uncertainty set on performance of the optimal solution is analyzed by the usual comparative static method. Comprehensive numerical comparisons with real market data are reported and indicate that the proposed model can obtain the smaller standard deviation and turnover ratios which reduce the Sharpe ratios of optimal portfolio, compared with some well-known models in the literature.},
  archive      = {J_EJOR},
  author       = {Aifan Ling and Jie Sun and Meihua Wang},
  doi          = {10.1016/j.ejor.2019.01.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {81-95},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust multi-period portfolio selection based on downside risk with asymmetrically distributed uncertainty set},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Singular dividend optimization for a linear diffusion model
with time-inconsistent preferences. <em>EJOR</em>, <em>285</em>(1),
66–80. (<a href="https://doi.org/10.1016/j.ejor.2019.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of behavioral economics, the use of exponential discounting for decision making in neoclassical economics has been questioned since it cannot provide a realistic way to explain certain decision-making behavior.The purpose of this paper is to investigate strategic decision making on dividend distribution policies of insurance companies when the management adopts a more realistic way for discounting, namely stochastic quasi-hyperbolic discounting. The use of this more realistic way for discounting is motivated by some recent developments in behavioral economics. A game theoretic approach is adopted to establish economic equilibrium results, namely subgame perfect Markov equilibrium strategies. It is shown that (1) under certain mild technical conditions, the barrier strategy with an optimal barrier, which is widely used in the traditional approach to optimal dividend problems, is a perfect Markov equilibrium strategy, (2) the optimal barrier is lower than the barrier of an optimal strategy obtained from the respective time-consistent optimal dividend problem, and (3) the solution based on the barrier strategy does not exist in some situations.},
  archive      = {J_EJOR},
  author       = {Jinxia Zhu and Tak Kuen Siu and Hailiang Yang},
  doi          = {10.1016/j.ejor.2019.04.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {66-80},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Singular dividend optimization for a linear diffusion model with time-inconsistent preferences},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated dynamic models for hedging international
portfolio risks. <em>EJOR</em>, <em>285</em>(1), 48–65. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop scenario-based stochastic programming models for hedging the risks of international portfolios using options. The models provide increasing level of integration in managing market and foreign exchange (FX) risks. We start with a single-stage model with currency options for selective hedging of FX risks, while market risk is addressed through diversification, we add stock options to hedge market risks, and add quantos and currency options to develop an integrated model, using an innovative method to price quantos on the scenario tree underpinning the stochastic program. The models are extended to multi-stage settings. Backtesting on market data over a 14-year period that includes the global financial crisis of 2008, we demonstrate the effectiveness of taking increasingly integrated views of risk management. Simultaneous hedging of market and FX risks using stock and currency options has the best ex post performance. The differences are economically significant, and statistical significance is established through rigorous hypothesis testing. The models are particularly effective during the crisis. Test results show that two-stage models outperform their single-stage counterparts, regardless of the hedging strategy.},
  archive      = {J_EJOR},
  author       = {Nikolas Topaloglou and Hercules Vladimirou and Stavros A. Zenios},
  doi          = {10.1016/j.ejor.2019.01.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {48-65},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated dynamic models for hedging international portfolio risks},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal procurement of flexibility services within
electricity distribution networks. <em>EJOR</em>, <em>285</em>(1),
34–47. (<a href="https://doi.org/10.1016/j.ejor.2018.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased injection of volatile renewable energy at local levels into the electricity grid is forcing the distribution network operators to seek participation in emerging service markets in order to obtain the flexibility required to balance their systems. However, the distribution companies lack experience in designing new market arrangements. We consider a market framework wherein a proactive distribution company is willing to purchase reserve capacity for overload management, using a two-part tariff. The problem is modelled as a three-stage stochastic market including Day-Ahead, Intra-Day and Real-Time, with uncertainty on both demand and generation. After assessing our formulation, we discuss the impact of risk-aversion at each stage with an objective function based on CVaR. Finally, different Intra-Day clearing horizons and delivery settings are evaluated. The results show that risk-aversion close to Real-Time becomes the main driver for decision makers and that early hedging strategies lead to sub-optimal solutions.},
  archive      = {J_EJOR},
  author       = {Arnaud Laur and Jesus Nieto-Martin and Derek W. Bunn and Alejandro Vicente-Pastor},
  doi          = {10.1016/j.ejor.2018.11.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {34-47},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal procurement of flexibility services within electricity distribution networks},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural estimation of switching costs for peaking power
plants. <em>EJOR</em>, <em>285</em>(1), 23–33. (<a
href="https://doi.org/10.1016/j.ejor.2019.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We estimate costs associated with mothballing, restarting, abandoning and maintaining peaking power plants. We develop a real options model to explain switching and maintenance behavior of plant managers. The constrained optimization approach to estimate crucial costs accommodates non-parametric dynamics for the expectations of the plant managers regarding future profitability. The empirical analysis is based on the status of power plants reported annually to the United States Energy Information Administration (EIA) during 2001–2009. We arrive at economically meaningful estimates of maintenance costs and switching costs, and discuss these in light of rates used in the Pennsylvania-New Jersey-Maryland capacity market.},
  archive      = {J_EJOR},
  author       = {Stein-Erik Fleten and Erik Haugom and Alois Pichler and Carl J. Ullrich},
  doi          = {10.1016/j.ejor.2019.03.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {23-33},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Structural estimation of switching costs for peaking power plants},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal trading of imbalance options for power systems using
an energy storage device. <em>EJOR</em>, <em>285</em>(1), 3–22. (<a
href="https://doi.org/10.1016/j.ejor.2018.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy storage devices are coming online in electricity markets around the world but are still considered an expensive solution to the load balancing problem. We propose a new market framework in which the owner of an electricity storage facility is able to optimally sell options and trade in the electricity market to add flexibility for the system operator at different times of the day. The storage operator has the possibility to optimally decide which option to offer, with the restriction of having the storage device in the appropriate mode and only at particular times. The system operator accepts these offers as possible long-term real-time balancing resorts. With the storage device in place, either electricity consumption or generated electricity can be increased in the network and in our framework this happens accordingly via the exercise of the corresponding option. Using a stochastic model for the imbalance, we calculate the real value of the optimal trading strategy for the storage operator and at the same time we can calculate the balancing cost of this resort compared to a so called “target cost” for the system operator. These results reveal that with proper parameter choices, mutual benefit is available, i.e. a financial profit for the storage operator whilst the balancing cost can also be reduced for the electricity system operator. Our results are illustrated via numerical calculations which are carried out after having the parameters of the model fit to real UK data. Optimal operational strategies are also described using our analysis.},
  archive      = {J_EJOR},
  author       = {Dávid Zoltán Szabó and Peter Duck and Paul Johnson},
  doi          = {10.1016/j.ejor.2018.09.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {3-22},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal trading of imbalance options for power systems using an energy storage device},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Guest editorial to the featured cluster “advances in
stochastic optimization.” <em>EJOR</em>, <em>285</em>(1), 1–2. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Raimund Kovacevic and Carlo Meloni and Dario Pacciarelli and Warren B. Powell},
  doi          = {10.1016/j.ejor.2019.11.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Guest editorial to the featured cluster “Advances in stochastic optimization”},
  volume       = {285},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general control variate method for lévy models in finance.
<em>EJOR</em>, <em>284</em>(3), 1190–1200. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new control variate method for Lévy models in finance. Our method generates a process of the control variate whose initial and terminal values coincide with those of the target Lévy model process, with both processes being driven by the same Brownian motion in the simulation. These features efficiently reduce the variance of the Monte Carlo simulation. As a typical application of this method, we provide the calculation scheme for pricing path-dependent exotic options. We use numerical experiments to examine the validity of our method for both continuously and discretely monitored path-dependent options under variance gamma and normal inverse Gaussian models.},
  archive      = {J_EJOR},
  author       = {Kenichiro Shiraya and Hiroki Uenishi and Akira Yamazaki},
  doi          = {10.1016/j.ejor.2020.01.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1190-1200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A general control variate method for lévy models in finance},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding multiple nash equilibria via machine
learning-supported gröbner bases. <em>EJOR</em>, <em>284</em>(3),
1178–1189. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates a new approach to yield all potential equilibria in a system with multiple actors by computing the Gröbner basis of the original problem. Further, it discusses the advantages of choosing this method over traditional numerical approaches. In addition, it provides a concept that applies machine learning, specifically evolution strategies, to approximate utility functions. This is done in order to remove the requirement for solving the dual problem of the system and thus allows to scale the equilibrium computation method to larger, more complex problem setups. This is demonstrated by a novel case study on non-convex players in form of hydropower generators operating simultaneously on spot and reserve markets whilst considering startups and shutdowns, periodical inflows and non-linear water conversion head effects. The model is further extended by considering uncertainty under unknown distributions and solved for a large-scale example in form of a multi-area network resembling the Scandinavian power system.},
  archive      = {J_EJOR},
  author       = {Markus Löschenbrand},
  doi          = {10.1016/j.ejor.2020.01.041},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1178-1189},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Finding multiple nash equilibria via machine learning-supported gröbner bases},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary approach to fraud management. <em>EJOR</em>,
<em>284</em>(3), 1167–1177. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building on several contributions to the analysis of insurance fraud, we propose a dynamical model of the fraudulence game , where three typologies of players interact: the insurance company, the fraudsters and the honest insured (who may be tempted to become dishonest), each one taking decisions on the basis of an adaptive strategy. It follows from the mathematical analysis that several scenarios and different asymptotic outcomes of the game are possible. In all cases, managerial/actuarial interpretations and implications are provided, suggesting how insurers can adapt proper control policies both to evolving behaviours of policyholders and to different external (economical, geographical, social) contexts.},
  archive      = {J_EJOR},
  author       = {Marcello Galeotti and Giovanni Rabitti and Emanuele Vannucci},
  doi          = {10.1016/j.ejor.2020.01.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1167-1177},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An evolutionary approach to fraud management},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple criteria decision aiding as a prediction tool for
migration potential of regions. <em>EJOR</em>, <em>284</em>(3),
1154–1166. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the potential of multiple criteria decision aiding (MCDA) as a tool for prediction analysis. We apply MCDA methodology for the determination of internal migration potential of regions within a country. The ELECTRE Tri-C together with the Multiple Criteria Hierarchy Process (MCHP), the imprecise SRF method and the Stochastic Multicriteria Acceptability Analysis (SMAA) will be applied to investigate the case of the internal migrations in Serbia. We shall give recommendations regarding the migration potential of Serbian municipalities in the following years. In particular, the ELECTRE Tri-C will be applied to classify the regions in four classes ordered with respect to regions’ migration potential, MCHP will be used to take into account the hierarchical structure of criteria on which the municipalities are evaluated. Finally, the imprecise SRF method, as well as the SMAA methodology, will be used to take into account the preferences of numerous economic agents.},
  archive      = {J_EJOR},
  author       = {Mihail Arandarenko and Salvatore Corrente and Maja Jandrić and Mladen Stamenković},
  doi          = {10.1016/j.ejor.2020.01.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1154-1166},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multiple criteria decision aiding as a prediction tool for migration potential of regions},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic offering of a flexible producer in day-ahead and
intraday power markets. <em>EJOR</em>, <em>284</em>(3), 1136–1153. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in intraday electricity market volumes due to intermittent renewable generation may give a strategic producer an opportunity to exert market power. We study offering strategies of a flexible producer in day-ahead and intraday markets using a bi-level model in which the upper level represents the profit-maximization problem of the producer and the lower-level problems clear the day-ahead and intraday markets sequentially. Using a three-node network, we first demonstrate that a flexible producer with perfect forecasts can increase its profit in both markets by coordinating its offer so as to cause transmission grid congestion or lack of competitive generation capacity. Moreover, we show that strategic behavior is possible even when the day-ahead and intraday markets are cleared simultaneously to lower balancing costs. We next assess these market designs in a Nordic test network and offer an explanation for high Nordic intraday prices. Finally, via an annual simulation using the Nordic market data, we verify that strategic offering in day-ahead and intraday markets under imperfect forecasts leads to increased profits vis-à-vis perfect competition but are mitigated through simultaneous market clearing.},
  archive      = {J_EJOR},
  author       = {Tuomas Rintamäki and Afzal S. Siddiqui and Ahti Salo},
  doi          = {10.1016/j.ejor.2020.01.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1136-1153},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic offering of a flexible producer in day-ahead and intraday power markets},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fair shift change penalization scheme for nurse rescheduling
problems. <em>EJOR</em>, <em>284</em>(3), 1121–1135. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nurse rescheduling problem denotes the problem of finding a new, feasible schedule when a disruption occurs during schedule operation. In most cases, rescheduling is needed when a nurse requires short-term absence and a substitution is essential to maintain care. Basically, rescheduling focuses on minimizing the shift changes between the current and the new schedule in order to best avoid disturbing the schedule operation and so prevent nurse dissatisfaction due to shift changes. Constraints within the nurse rescheduling problem may differ depending on the case. In this study, we develop a general optimization model that can be adjusted to various cases with different characteristics. The model incorporates a fair shift change penalization scheme, in which the type, timing and distribution of shift changes among nurses are taken into account. In addition, information from previous periods is considered, using an individual penalty score to distribute the shift changes fairly among the nurses. Based on the proposed penalization scheme and model, optimized schedules are generated in a short computational time for instances from literature, real-world based instances from a Portuguese hospital, and real instances from a care facility from Germany. The results of the computational study demonstrate the practical applicability of the approach. For most problem instances, the number of shift changes corresponds to the minimum number or deviates only slightly from it. At the same time, a much fairer distribution of these changes among nurses can be achieved.},
  archive      = {J_EJOR},
  author       = {Lena Wolbeck and Natalia Kliewer and Inês Marques},
  doi          = {10.1016/j.ejor.2020.01.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1121-1135},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fair shift change penalization scheme for nurse rescheduling problems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust portfolio decision analysis: An application to the
energy research and development portfolio problem. <em>EJOR</em>,
<em>284</em>(3), 1107–1120. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by challenges in designing energy technology policy in the face of climate change, we address the problem of decision making under “deep uncertainty.” We introduce an approach we call Robust Portfolio Decision Analysis, building on Belief Dominance as a prescriptive operationalization of a concept that has appeared in the literature under a number of names. The Belief Dominance concept synthesizes multiple conflicting sources of information to uncover alternatives that are intelligent responses in the presence of many beliefs. We use this concept to determine the set of non-dominated portfolios and to identify corresponding robust individual alternatives, thereby uncovering viable alternatives that may not be revealed otherwise. Our approach is particularly appropriate with multiple stakeholders, as it helps identify common ground while leaving flexibility for negotiation. We develop a proof-of-concept application aimed at informing decisions over investments into clean energy technology R&amp;D portfolios in the context of climate change and illustrate how Robust Portfolio Decision Analysis helps identify robust individual investments.},
  archive      = {J_EJOR},
  author       = {Erin Baker and Valentina Bosetti and Ahti Salo},
  doi          = {10.1016/j.ejor.2020.01.038},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1107-1120},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust portfolio decision analysis: An application to the energy research and development portfolio problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate dynamic programming for planning a ride-hailing
system using autonomous fleets of electric vehicles. <em>EJOR</em>,
<em>284</em>(3), 1088–1106. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a comprehensive ride-hailing system taking into account many of the decisions required to operate it in reality. The ride-hailing system is formed of a centrally managed fleet of autonomous electric vehicles which is creating a transformative new technology with significant cost savings. This problem involves a dispatch problem for assigning riders to cars, a surge pricing problem for deciding on the price per trip and a planning problem for deciding on the fleet size. We use approximate dynamic programming to develop high-quality operational dispatch strategies to determine which car is best for a particular trip, when a car should be recharged, when it should be re-positioned to a different zone which offers a higher density of trips and when it should be parked. These decisions have to be made in the presence of a highly dynamic call-in process, and assignments have to take into consideration the spatial and temporal patterns in trip demand which are captured using value functions. We prove that the value functions are monotone in the battery and time dimensions and use hierarchical aggregation to get better estimates of the value functions with a small number of observations. Then, surge pricing is discussed using an adaptive learning approach to decide on the price for each trip. Finally, we discuss the fleet size problem.},
  archive      = {J_EJOR},
  author       = {Lina Al-Kanj and Juliana Nascimento and Warren B. Powell},
  doi          = {10.1016/j.ejor.2020.01.033},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1088-1106},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximate dynamic programming for planning a ride-hailing system using autonomous fleets of electric vehicles},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Allocating costs in set covering problems. <em>EJOR</em>,
<em>284</em>(3), 1074–1087. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of allocating costs in set covering situations. In particular, we focus on set covering situations where the optimal covering is given in advance. Thus, we take into account only the facilities that have to be opened and look for rules distributing their cost. We define a cooperative game and study the core and the nucleolus. We also introduce two new rules: the equal split rule on facilities and the serial rule. We axiomatically characterize the core, the nucleolus, and the two rules. Finally, we study several monotonicity properties of the rules.},
  archive      = {J_EJOR},
  author       = {Gustavo Bergantiños and María Gómez-Rúa and Natividad Llorca and Manuel Pulido and Joaquín Sánchez-Soriano},
  doi          = {10.1016/j.ejor.2020.01.031},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1074-1087},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Allocating costs in set covering problems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The prisoner transportation problem. <em>EJOR</em>,
<em>284</em>(3), 1058–1073. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prisoners often require transportation to and from services such as hospital appointments, court proceedings and family visits during their imprisonment. Organising daily prisoners transportation consumes a huge amount of resources. A large fleet of highly protected vehicles, their drivers and security guards must be assigned to all prisoner transports such that all safety and time-related constraints are satisfied while inter-prisoner (inter-passenger) conflicts are avoided. It is beyond human planners’ capabilities to minimize costs while attempting to feasibly schedule all prisoner transportation requests. Whereas the prisoner transportation problem (PTP) bears resemblance with vehicle routing, common software systems for vehicle routing fail to address the intricacies associated with the PTP. A dedicated decision support system is required to both support human planners as well as reduce operational costs. The considerable computational challenge due to problem-specific components (inter-passenger conflicts and simultaneous servicing) also makes the PTP interesting from an academic point of view. We formally introduce the problem by providing mixed integer programming models. We implement exact iterative procedures to solve these formulations and evaluate their performance on small instances. In order to solve instances of a realistic size, we present a heuristic. Academic PTP instances generated and employed for experimentation are made publicly available with a view towards encouraging further follow-up research. The heuristic presented in this paper provides all the necessary components to solve the PTP adequately and sets initial benchmarks for the new public instance set.},
  archive      = {J_EJOR},
  author       = {Jan Christiaens and Hatice Çalik and Tony Wauters and Reshma Chirayil Chandrasekharan and Greet Vanden Berghe},
  doi          = {10.1016/j.ejor.2020.01.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1058-1073},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The prisoner transportation problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). What drives decarbonization of new passenger cars?
<em>EJOR</em>, <em>284</em>(3), 1043–1057. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transition towards a low-carbon transport sector fundamentally depends on decarbonization of the passenger car fleet. Therefore, it is critically important to understand the driving factors behind decreasing CO 2 emissions of new passenger cars. This paper develops a new decomposition method to break down the change in the average CO 2 emissions of new passenger cars into components representing changes in available technology, carbon efficiency of consumer choices, vehicle attributes, fuel mix, and the gap between type-approval and on-road CO 2 emissions of passenger cars. Our decomposition draws insights from the traditional index decomposition analysis and frontier-based decomposition of productivity growth. It satisfies such desirable properties as factor reversal, time reversal, and zero-value robustness. An empirical application to a unique data set that covers all registered passenger cars in Finland sheds light on why and how the CO 2 emissions of new cars decreased from year 2002 to year 2014.},
  archive      = {J_EJOR},
  author       = {Xun Zhou and Timo Kuosmanen},
  doi          = {10.1016/j.ejor.2020.01.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1043-1057},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {What drives decarbonization of new passenger cars?},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal pricing in on-demand-service-platform-operations
with hired agents and risk-sensitive customers in the blockchain era.
<em>EJOR</em>, <em>284</em>(3), 1031–1042. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {On-demand service platforms are popular nowadays. Many platforms hire agents to serve customers who are risk sensitive towards the waiting-time. In this paper, we apply the mean-risk theory to analytically explore how the risk attitude of customers affects the optimal service pricing decision of the on-demand platform, consumer surplus (CS) of customers, the expected profit (EP) and profit risk (PR) of the platform (and the hired service agents). In the basic model, assuming consumers are homogeneous, we find that if the customers are more risk averse (risk seeking), the optimal service price will drop (increase). Comparing among the three different risk attitudes of customers, we find that when the customers are risk seeking, the CS and the platform&#39;s EP are highest, even though the platform&#39;s PR is also highest. While the opposite happens when the customers are risk averse. In the extended model with a market including customers with different risk attitudes, the blockchain technology helps the platform assess the proportion of risk seeking, risk neutral and risk averse customers accurately. We explore the optimal service prices under both the common pricing policy and the customized pricing policy (with-respect-to customer&#39;s risk attitude), and derive the value of blockchain technology mediated customized service pricing strategy. We conclude by highlighting that the risk attitudes of customers play a critical role in determining the optimal on-demand service pricing, and the blockchain technology is a valuable technological tool to help.},
  archive      = {J_EJOR},
  author       = {Choi Tsan-Ming and Guo Shu and Liu Na and Shi Xiutian},
  doi          = {10.1016/j.ejor.2020.01.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1031-1042},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal pricing in on-demand-service-platform-operations with hired agents and risk-sensitive customers in the blockchain era},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using a choquet integral-based approach for incorporating
decision-maker’s preference judgments in a data envelopment analysis
model. <em>EJOR</em>, <em>284</em>(3), 1016–1030. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a world in permanent (r)evolution that revolves around money, seeking new ways to contain costs, better allocate resources, and, overall, improve performance is a constant across all fields. Hence, the use of computational methods based on operational research and statistical science is crucial for achieving an appropriate combination of efficiency and effectiveness, especially in domains where the decision-making process is a complex task. This is where Data Envelopment Analysis (DEA) comes in. However, as a non-parametric and, usually, purely objective technique, DEA makes up for what it lacks in incorporating preference information with flexibility and adaptability, which is particularly important in areas where the decision-makers’ judgments are crucial. This work proposes a cutting-edge and original approach to fill in this knowledge gap by linking DEA and multiple criteria decision-making with an additive DEA model that takes into account criteria interactivity, by using an inference methodology to determine their weights, and decision-makers’ preference information incorporation, by taking advantage of the Choquet multiple criteria preference aggregation model. Thus, this approach was applied to a case study of performance assessment of Portuguese National Healthcare Service secondary healthcare providers across robustness-testing perspectives, generating credible weights stemmed from the decision-maker’s judgments and yielding acceptable and valid results.},
  archive      = {J_EJOR},
  author       = {Miguel Alves Pereira and José Rui Figueira and Rui Cunha Marques},
  doi          = {10.1016/j.ejor.2020.01.037},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1016-1030},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using a choquet integral-based approach for incorporating decision-maker’s preference judgments in a data envelopment analysis model},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving finite sample approximation by central limit
theorems for estimates from data envelopment analysis. <em>EJOR</em>,
<em>284</em>(3), 1002–1015. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an improvement of the finite sample approximation of the central limit theorems (CLTs) that were recently derived for statistics involving production efficiency scores estimated via Data Envelopment Analysis (DEA) or Free Disposal Hull (FDH) approaches. The improvement is very easy to implement since it involves a simple correction of the variance estimator with an estimate of the bias of the already employed statistics without any additional computational burden and reserves the original asymptotic results such as consistency and asymptotic normality. The proposed approach persistently showed improvement in all the scenarios that we tried in various Monte-Carlo experiments, especially for relatively small samples or relatively large dimensions (measured by total number of inputs and outputs) of the underlying production model. This approach therefore is expected to produce more accurate estimates of confidence intervals of aggregates of individual efficiency scores in empirical research using DEA or FDH approaches and so must be valuable for practitioners. We also illustrate this method using a popular real data set to confirm that the difference in the estimated confidence intervals can be substantial. A step-by-step implementation algorithm of the proposed approach is included in the Appendix.},
  archive      = {J_EJOR},
  author       = {Léopold Simar and Valentin Zelenyuk},
  doi          = {10.1016/j.ejor.2020.01.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1002-1015},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving finite sample approximation by central limit theorems for estimates from data envelopment analysis},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling the impact of product quality on dynamic pricing
and advertising policies. <em>EJOR</em>, <em>284</em>(3), 990–1001. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The marketing-mix of price–quality and advertising–quality relationship is well studied. Less understood is the price–advertising–quality relationship. This article fills the gap, investigating the interplay between price, advertising, and quality in an optimal control model. Our results generalize the condition of Dorfman–Steiner in a dynamic context. Also, they point to the impact of greater product quality on the dynamic policies of pricing and advertising. Furthermore, a phase diagram analysis shows that quality develops monotonically in time and converges to a unique steady state. We also show that quality investment could either decrease or increase over time but this depends on its effectiveness. Our results spot the profitable opportunities of a firm managing a more complex marketing-mix.},
  archive      = {J_EJOR},
  author       = {Régis Y. Chenavaz and Gustav Feichtinger and Richard F. Hartl and Peter M. Kort},
  doi          = {10.1016/j.ejor.2020.01.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {990-1001},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling the impact of product quality on dynamic pricing and advertising policies},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bundling decisions in a two-product duopoly – lead or
follow? <em>EJOR</em>, <em>284</em>(3), 980–989. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We evaluate the impact of bundling on firms’ product and pricing strategies by developing and solving a multi-stage game theoretic model to represent strategic interactions between two competing firms. Each firm is able to produce two homogeneous products and can opt to bundle them together, which may have the dual benefits of providing added value to consumers and reducing marginal cost for firms. One firm (the leader) determines its product offering before the other (the follower), and both then simultaneously set prices. We demonstrate the existence and uniqueness of a Nash equilibrium and show that the option to bundle can benefit all competitors simultaneously. When mixed bundling is not an option, we characterize and quantify the leader’s advantage in terms of profitability. However, when mixed bundling is an option, the follower may reverse its profit disadvantage by using it as a potential threat. Furthermore, our numerical results show that (i) bundling enhances the balance between firms’ total profit and consumer surplus; (ii) for the firm that bundles, value addition and cost saving brought by bundling act as strategic complements in that their combined benefit is larger than the sum of individual benefits; and (iii) value addition and cost saving improve the market demand, firms’ total profit as well as consumer surplus.},
  archive      = {J_EJOR},
  author       = {Shu Zhou and Boqian Song and Srinagesh Gavirneni},
  doi          = {10.1016/j.ejor.2020.01.030},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {980-989},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bundling decisions in a two-product duopoly – lead or follow?},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On a high-dimensional model representation method based on
copulas. <em>EJOR</em>, <em>284</em>(3), 967–979. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article provides an alternative to High-Dimensional Model Representation using a Copula approximation of an unknown functional form. We apply our methodology in the context of an extensive Monte Carlo study and to a sample of large US commercial banks. In the Monte Carlo experiment, the approximations errors of the Copula approach are small and behave randomly. In our empirical application, we find that the Copula Approximation performs much better, in terms of Bayes factors for model comparison, compared to High-Dimensional Model Representation, which, in turn, provides better results when compared with standard flexible functional forms, like the translog, the minflex Laurent, and the Generalized Leontief, or a Multilayer Perceptron. Moreover, the choice of approximation has significant implications for productivity and its components (returns to scale, technical inefficiency, technical change, and efficiency change).},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas and Athanasios Andrikopoulos},
  doi          = {10.1016/j.ejor.2020.01.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {967-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On a high-dimensional model representation method based on copulas},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing strategies and mechanism choice in reward-based
crowdfunding. <em>EJOR</em>, <em>284</em>(3), 951–966. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With consideration of the ambiguity and overfunding effects, this study develops generalized models to compare the sequential and simultaneous mechanisms in reward-based crowdfunding. Ambiguity effect is a negative psychological perception of customers since they lack the information to infer the product’s quality, however, overfunding effect is a positive psychological perception that enhances customers’ confidence in the product’s quality. Theoretically, we show that the two mechanisms may dominate each other in terms of entrepreneur and the two opposite effects can play significant roles in deciding the optimal crowdfunding mechanism. Furthermore, we propose a simple compensation mechanism to improve entrepreneur’s expected payoff and the crowdfunding’s success rate under both mechanisms. Finally, we analyse the informational cascade in crowdfunding and show how entrepreneur can use this phenomenon to maximize her expected payoff.},
  archive      = {J_EJOR},
  author       = {Shaofu Du and Jing Peng and Tengfei Nie and Yugang Yu},
  doi          = {10.1016/j.ejor.2020.01.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {951-966},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing strategies and mechanism choice in reward-based crowdfunding},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal policies for information sharing in information
system security. <em>EJOR</em>, <em>284</em>(3), 934–950. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing has become a significant part of information system security endeavor, as many firms have come to realize that it is difficult to defend against the increasingly sophisticated information security attacks with the limited resources of one single firm. The sharing of information security related knowledge and experience helps firms better prepare for the upcoming information security challenges. However, the practice of information sharing is far less prevalent when compared with other information security methods. In this paper, we develop a framework for information sharing decisions of a firm in the context of information system security. We find through analytical and numerical analyses that the optimal level information sharing is a function of the cost, budget and expected cost of perfect protection for a given firm. We also examine the value of information sharing in information security, and identify how such value varies over different investment environments.},
  archive      = {J_EJOR},
  author       = {Senay Solak and Yueran Zhuo},
  doi          = {10.1016/j.ejor.2019.12.016},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {934-950},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal policies for information sharing in information system security},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Profit driven decision trees for churn prediction.
<em>EJOR</em>, <em>284</em>(3), 920–933. (<a
href="https://doi.org/10.1016/j.ejor.2018.11.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer retention campaigns increasingly rely on predictive models to detect potential churners in a vast customer base. From the perspective of machine learning, the task of predicting customer churn can be presented as a binary classification problem. Using data on historic behavior, classification algorithms are built with the purpose of accurately predicting the probability of a customer defecting. The predictive churn models are then commonly selected based on accuracy related performance measures such as the area under the ROC curve (AUC). However, these models are often not well aligned with the core business requirement of profit maximization, in the sense that, the models fail to take into account not only misclassification costs, but also the benefits originating from a correct classification. Therefore, the aim is to construct churn prediction models that are profitable and preferably interpretable too. The recently developed expected maximum profit measure for customer churn (EMPC) has been proposed in order to select the most profitable churn model. We present a new classifier that integrates the EMPC metric directly into the model construction. Our technique, called ProfTree, uses an evolutionary algorithm for learning profit driven decision trees. In a benchmark study with real-life datasets from various telecommunication service providers, we show that ProfTree achieves significant profit improvements compared to classic accuracy driven tree-based methods.},
  archive      = {J_EJOR},
  author       = {Sebastiaan Höppner and Eugen Stripling and Bart Baesens and Seppe vanden Broucke and Tim Verdonck},
  doi          = {10.1016/j.ejor.2018.11.072},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {920-933},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Profit driven decision trees for churn prediction},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact algorithms for the multi-pickup and delivery problem
with time windows. <em>EJOR</em>, <em>284</em>(3), 906–919. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the multi-pickup and delivery problem with time windows (MPDPTW) a set of vehicles must be routed to satisfy a set of client requests between given origins and destinations. A request is composed of several pickups of different items, followed by a single delivery at the client location. This paper introduces two new formulations for the MPDPTW, the 2-index formulation, and the asymmetric representatives formulation. In addition, we also present an existing 3-index formulation for this problem and improve it by means of several preprocessing and valid inequalities. We solve the problem exactly via a branch-and-cut algorithm. We introduce several families of valid inequalities to strengthen the LP relaxations of the proposed formulations. Computational results are reported on different types of instances to firstly highlight the advantage of adding different families of valid inequalities then to compare the performance of the different formulations presented in this paper. While the heuristic and exact algorithms of the literature prove optimality for 16 instances containing up to 50 nodes, we prove optimality for 41 instances for cases containing up to 100 nodes from the existing benchmark set.},
  archive      = {J_EJOR},
  author       = {Imadeddine Aziez and Jean-François Côté and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2020.01.040},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {906-919},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact algorithms for the multi-pickup and delivery problem with time windows},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branch, bound and remember algorithm for two-sided assembly
line balancing problem. <em>EJOR</em>, <em>284</em>(3), 896–905. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a new branch, bound and remember (BBR) algorithm to minimize the number of mated-stations in two-sided assembly lines. The proposed methodology modifies the Hoffman heuristic to achieve high-quality upper bounds, and employs two new dominance rules, referred to as memory-based maximal load rule and memory-based extended Jackson rule, to prune the sub-problems. The BBR algorithm also employs several other improvements to enhance the performance, including renumbering the tasks and new lower bounds. Computational results demonstrate that BBR achieves the optimal solutions for all the tested instances within 1.0 s on average, including two optimal solutions for the first time. Comparative study shows that BBR outperforms the current best exact method (branch and bound algorithm) and the current best heuristic algorithm (iterated greedy search algorithm). As a consequence, the proposed BBR can be regarded as the state-of-the-art method for TALBP.},
  archive      = {J_EJOR},
  author       = {Zixiang Li and Ibrahim Kucukkoc and Zikai Zhang},
  doi          = {10.1016/j.ejor.2020.01.032},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {896-905},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Branch, bound and remember algorithm for two-sided assembly line balancing problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using judgment to select and adjust forecasts from
statistical models. <em>EJOR</em>, <em>284</em>(3), 882–895. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting support systems allow users to choose different statistical forecasting methods. But how well do they make this choice? We examine this in two experiments. In the first one ( N = 191), people selected the model that they judged to perform the best. Their choice outperformed forecasts made by averaging the model outputs and improved with a larger difference in quality between models and a lower level of noise in the data series. In a second experiment ( N = 161), participants were asked to make a forecast and were then offered advice in the form of a model forecast. They could then re-adjust their forecast. Final forecasts were more influenced by models that made better forecasts. As forecasters gained experience, they followed input from high-quality models more readily. Thus, both experiments show that forecasters have ability to use and learn from visual records of past performance to select and adjust model-based forecasts appropriately.},
  archive      = {J_EJOR},
  author       = {Shari De Baets and Nigel Harvey},
  doi          = {10.1016/j.ejor.2020.01.028},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {882-895},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using judgment to select and adjust forecasts from statistical models},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multicut outer-approximation approach for competitive
facility location under random utilities. <em>EJOR</em>,
<em>284</em>(3), 874–881. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work concerns the maximum capture facility location problem with random utilities, i.e., the problem of seeking to locate new facilities in a competitive market such that the captured demand of users is maximized, assuming that each individual chooses among all available facilities according to a random utility maximization model. The main challenge lies in the nonlinearity of the objective function. Motivated by the convexity and separable structure of such an objective function, we propose an enhanced implementation of the outer approximation scheme. Our algorithm works in a cutting plane fashion and allows to separate the objective function into a number of sub-functions and create linear cuts for each sub-function at each outer-approximation iteration. We compare our approach with the state-of-the-art method and, for the first time in an extensive way, with other existing nonlinear solvers using three data sets from recent literature. Our experiments show the robustness of our approach, especially on large instances, in terms of both computing time and number instances solved to optimality.},
  archive      = {J_EJOR},
  author       = {Tien Mai and Andrea Lodi},
  doi          = {10.1016/j.ejor.2020.01.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {874-881},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multicut outer-approximation approach for competitive facility location under random utilities},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A heuristic based on mathematical programming for a
lot-sizing and scheduling problem in mold-injection production.
<em>EJOR</em>, <em>284</em>(3), 861–873. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a lot-sizing and scheduling problem to maximize the profit of assembled products over several periods. The setting involves a plastic injection production environment where pieces are produced using auxiliary equipment (molds) to form finished products. Each piece may be processed in a set of molds with different production rates on various machines. The production rate varies according to the piece, mold and machine assignments. The novelty lies on the problem definition, where the focus is on finished products. We developed a two-stage iterative heuristic based on mathematical programming. First the lot-size of the products is determined together with the mold-machine assignments. The second stage determines if there is a feasible schedule of the molds with no overlapping. If unsuccessful, it goes back to the first stage and restricts the number of machines that a mold can visit, until a feasible solution is found. This decomposition approach allows us to deal with a more complex environment that incorporates idle times and assembly line considerations. We show the advantages of this methodology on randomly generated instances and on data from real companies. Experimental results show that our heuristic converges to a feasible solution with few iterations, obtaining solutions that the companies find competitive both in terms of quality and running times.},
  archive      = {J_EJOR},
  author       = {Yasmín Á Ríos-Solís and Omar J. Ibarra-Rojas and Marta Cabo and Edgar Possani},
  doi          = {10.1016/j.ejor.2020.01.016},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {861-873},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A heuristic based on mathematical programming for a lot-sizing and scheduling problem in mold-injection production},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of cancelled appointments on outpatient clinic
operations. <em>EJOR</em>, <em>284</em>(3), 847–860. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies how appointment cancellations affect scheduling strategies in outpatient healthcare clinics. While cancellation rates in outpatient clinics have been reported to be as high as 27\%, cancelled appointments are often ignored, or grouped with no-shows in healthcare scheduling models. We find that there exists a value of total demand that, when calculated over a scheduling horizon, marks the boundary between where cancellations hurt or help a clinic. We refer to that value as the switch point . Up to the switch point, clinics can achieve a greater reward when patients do not cancel. However, for values of expected total demand greater than the switch point, the clinic reward is reduced if more patients retain (do not cancel) appointments. To assist us in evaluating the switch point, we construct a mixed-integer nonlinear programming model to solve a multi-day outpatient scheduling problem. The model accounts for both inter-day (appointment day) and intra-day (appointment time slot) scheduling decisions, while balancing service benefits against service costs. We include probabilities of no-show and cancellation, which allows us to discuss how cancellations affect scheduling decisions through the switch point. The knowledge of the switch point allows a clinic to understand when appointment no-shows and cancellations negatively affect clinic service, and can assist the clinic in determining the number of patients for which it is committed to provide service, i.e., its panel size. In this paper, we discuss methodologies for calculating the switch point, and discuss its sensitivity to model parameters.},
  archive      = {J_EJOR},
  author       = {Shannon L. Harris and Jerrold H. May and Luis G. Vargas and Krista M. Foster},
  doi          = {10.1016/j.ejor.2020.01.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {847-860},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of cancelled appointments on outpatient clinic operations},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Single facility siting involving allocation decisions.
<em>EJOR</em>, <em>284</em>(3), 834–846. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single facility siting is often viewed as the most basic of location planning problems. It has been approached by many researchers, across a range of disciplines, and has a rich and distinguished history. Much of this interest reflects the general utility of single facility siting, but also the mathematical and computational advancements that have been made over past decades to support better decision making. This paper discusses a recently rediscovered form of Weber&#39;s classic single facility location problem that is both important and relevant in contemporary planning and decision making. This form of the Weber problem involves locating a production plant where there are multiple sources of each needed raw material (input) distributed throughout a region. This means that the selection of a given raw material source may vary depending on the plant location. In essence, this makes the problem non-convex, even when locating only one production plant. We review elements of the Weber problem that have been addressed in the literature along with proposed solution techniques. In doing so, we highlight elements of the problem originally noted by Weber, but to date have not been operationalized in practice––allocation selection among multiple sources of given raw material inputs. A problem formulation involving allocation decisions for this generalization is derived and an optimal solution approach is developed. Application results demonstrate the significance of addressing important planning characteristics and the associated nuances that result.},
  archive      = {J_EJOR},
  author       = {Alan T. Murray and Richard L. Church and Xin Feng},
  doi          = {10.1016/j.ejor.2020.01.047},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {834-846},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Single facility siting involving allocation decisions},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computationally efficient branch-and-bound algorithm for
the permutation flow-shop scheduling problem. <em>EJOR</em>,
<em>284</em>(3), 814–833. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we propose an efficient branch-and-bound (B&amp;B) algorithm for the permutation flow-shop problem (PFSP) with makespan objective. We present a new node decomposition scheme that combines dynamic branching and lower bound refinement strategies in a computationally efficient way. To alleviate the computational burden of the two-machine bound used in the refinement stage, we propose an online learning-inspired mechanism to predict promising couples of bottleneck machines. The algorithm offers multiple choices for branching and bounding operators and can explore the search tree either sequentially or in parallel on multi-core CPUs. In order to empirically determine the most efficient combination of these components, a series of computational experiments with 600 benchmark instances is performed. A main insight is that the problem size, as well as interactions between branching and bounding operators substantially modify the trade-off between the computational requirements of a lower bound and the achieved tree size reduction. Moreover, we demonstrate that parallel tree search is a key ingredient for the resolution of large problem instances, as strong super-linear speedups can be observed. An overall evaluation using two well-known benchmarks indicates that the proposed approach is superior to previously published B&amp;B algorithms. For the first benchmark we report the exact resolution – within less than 20 minutes – of two instances defined by 500 jobs and 20 machines that remained open for more than 25 years, and for the second a total of 89 improved best-known upper bounds, including proofs of optimality for 74 of them.},
  archive      = {J_EJOR},
  author       = {Jan Gmys and Mohand Mezmaz and Nouredine Melab and Daniel Tuyttens},
  doi          = {10.1016/j.ejor.2020.01.039},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {814-833},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A computationally efficient branch-and-bound algorithm for the permutation flow-shop scheduling problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of data envelopment analysis applications in the
insurance industry 1993–2018. <em>EJOR</em>, <em>284</em>(3), 801–813.
(<a href="https://doi.org/10.1016/j.ejor.2019.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently in the insurance sector, efficiency measurement of insurance firms has attracted great interest from investors, financial market analysts, insurance regulators, and researchers alike. Among several performance assessment approaches, Data Envelopment Analysis (DEA) has become one of the tools that have been commonly adopted to evaluate firms in various fields. Given the increasing interest in applying DEA to assessing relative efficiency or performance of insurance firms and that there has been a growing body of literature on DEA applications in the insurance industry since the last comprehensive published review in the field (i.e., Cummins and Weiss, 2013), an updated survey of DEA applications focusing on the insurance industry is necessary. In this study, we review and analyze 132 DEA application studies in the insurance industry published from 1993 through July 2018, covering both applications and methodologies. Regarding the applications, we show that the impact of recent changes such as Insurtechs, market transparency, and micro-insurance institutions on the efficiency of insurance firms has not yet been touched. As to methodologies, we pinpoint that the newly-developed DEA approaches such as shared resources dynamic network DEA, modified directional distance function, satisficing DEA, and fuzzy DEA lack in the extant literature. Through the analyses, we highlight the existing gaps in the DEA applications in the insurance industry for future research.},
  archive      = {J_EJOR},
  author       = {Sepideh Kaffash and Roza Azizi and Ying Huang and Joe Zhu},
  doi          = {10.1016/j.ejor.2019.07.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {801-813},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A survey of data envelopment analysis applications in the insurance industry 1993–2018},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interface between logical analysis of data and formal
concept analysis. <em>EJOR</em>, <em>284</em>(2), 792–800. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical Analysis of Data and Formal Concept Analysis are separately developed methodologies based on different mathematical foundations. We show that the two methodologies utilize the same basic building blocks. That enables us to develop an interface between the two methodologies. We provide some preliminary benefits of the interface; most notably efficient algorithms for computing spanned patterns in Logical Analysis of Data using algorithms of Formal Concept Analysis.},
  archive      = {J_EJOR},
  author       = {Radek Janostik and Jan Konecny and Petr Krajča},
  doi          = {10.1016/j.ejor.2020.01.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {792-800},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interface between logical analysis of data and formal concept analysis},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hedge fund’s dynamic leverage decisions under
time-inconsistent preferences. <em>EJOR</em>, <em>284</em>(2), 779–791.
(<a href="https://doi.org/10.1016/j.ejor.2019.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the continuous-time hedge fund framework to model the dynamic leverage choice of a hedge fund manager with time-inconsistent preferences. While time-inconsistency discourages the manager from investing when facing high liquidation risk, the payment of incentive fees may induce a time-inconsistent manager to be more aggressive with leverage. For the special case with no management fees, we derive the closed-form solutions and find that a time-inconsistent manager always chooses higher leverage than a time-consistent manager. The impact on the dynamic leverage strategy also depends on such factors as whether managers are sophisticated or naive in their expectations regarding future time-inconsistent behavior.},
  archive      = {J_EJOR},
  author       = {Jiangyuan Li and Bo Liu and Jinqiang Yang and Zhentao Zou},
  doi          = {10.1016/j.ejor.2019.12.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {779-791},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hedge fund’s dynamic leverage decisions under time-inconsistent preferences},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple explicit formula for near-optimal stochastic
lifestyling. <em>EJOR</em>, <em>284</em>(2), 769–778. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In life-cycle economics, the Samuelson paradigm (Samuelson, 1969) states that the optimal investment is in constant proportions out of lifetime wealth composed of current savings and the present value of future income. It is well known that in the presence of credit constraints this paradigm no longer applies. Instead, optimal life-cycle investment gives rise to so-called stochastic lifestyling (Cairns, Blake, and Dowd, 2006), whereby for low levels of accumulated capital it is optimal to invest fully in stocks and then gradually switch to safer assets as the level of savings increases. In stochastic lifestyling not only does the ratio between risky and safe assets change but also the mix of risky assets varies over time. While the existing literature relies on complex numerical algorithms to quantify optimal lifestyling, the present paper provides a simple formula that captures the main essence of the lifestyling effect with remarkable accuracy.},
  archive      = {J_EJOR},
  author       = {Aleš Černý and Igor Melicherčík},
  doi          = {10.1016/j.ejor.2019.12.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {769-778},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Simple explicit formula for near-optimal stochastic lifestyling},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Bounded rationality and thick frontiers in stochastic
frontier analysis. <em>EJOR</em>, <em>284</em>(2), 762–768. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has proposed a statistical test based on the notion that agents have bounded rationality, if and only if more attractive states are chosen with larger probability. We propose and implement a statistical test for bounded rationality in the context of stochastic cost frontiers. Bounded rationality is related to probabilistically cost-efficient distributions. The test is based on comparing a discrete set of probabilities with the theoretical distribution under bounded rationality. Implementation is shown to be quite easy in a Bayesian framework using the Bayes factor for model comparison between estimated and theoretical probabilities. The bounded-rationality model introduces only an extra parameter in frontier models and, therefore, it is quite practical to use in applications as a general semi-parametric model for inefficiency.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2019.12.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {762-768},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bounded rationality and thick frontiers in stochastic frontier analysis},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing temporary work and overtime in the time cost
quality trade-off problem. <em>EJOR</em>, <em>284</em>(2), 743–761. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of its significant contribution to project success, quality has been scarcely addressed in the literature on deterministic project scheduling problems. Although it is recognized that higher qualities are associated with longer processing times, no relationship between quality and resource consumption has been analytically derived to support this statement. As manufacturing projects can be accelerated using additional manpower such as overtime and temporary workers, we derive an analytical relationship between quality and manpower since overtime and overmanning negate quality. We also take into account productivity losses due to overmanning. Contrary to most previous contributions that focus on the project overall quality as an aggregation of quality levels attained at the individual activities, we impose each activity to reach a minimum quality threshold, which is consistent with project management practices. Consequently, we develop a mixed integer linear programming (MILP) to optimize temporary work and overtime so as to accelerate a project with quality and productivity considerations. The objective is to simultaneously determine for each activity the number of permanent, temporary and overtime workers over the processing periods in order to minimize the makespan, the total cost and the overall quality losses subject to individual quality constraints, precedence relationships, nonpreemption and availability of resources. Our approach is successfully applied on numerous instances based on a real project of a high speed locomotive as well as on other projects taken from the literature.},
  archive      = {J_EJOR},
  author       = {Jully Jeunet and Mayassa Bou Orm},
  doi          = {10.1016/j.ejor.2020.01.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {743-761},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing temporary work and overtime in the time cost quality trade-off problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparison of tail dependence estimators. <em>EJOR</em>,
<em>284</em>(2), 728–742. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We review several commonly used methods for estimating the tail dependence in a given data sample. In simulations, we show that especially static estimators produce severely biased estimates of tail dependence when applied to samples with time-varying extreme dependence. In some instances, using static estimators for time-varying data leads to estimates more than twice as high as the true tail dependence. Our findings attenuate the need to account for the time-variation in extreme dependence by using dynamic models. Taking all simulations into account, the dynamic tail dependence estimators perform best with the Dynamic Symmetric Copula (DSC) taking the lead. We test our findings in an empirical study and show that the choice of estimator significantly affects the importance of tail dependence for asset prices.},
  archive      = {J_EJOR},
  author       = {Hendrik Supper and Felix Irresberger and Gregor Weiß},
  doi          = {10.1016/j.ejor.2019.12.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {728-742},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A comparison of tail dependence estimators},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Portfolio problems with two levels decision-makers: Optimal
portfolio selection with pricing decisions on transaction costs.
<em>EJOR</em>, <em>284</em>(2), 712–727. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel bilevel leader-follower portfolio selection problems in which the financial intermediary becomes a decision-maker. This financial intermediary decides on the unit transaction costs for investing in some securities, maximizing its benefits, and the investor chooses his optimal portfolio, minimizing risk and ensuring a given expected return. Hence, transaction costs become decision variables in the portfolio problem, and two levels of decision-makers are incorporated: the financial intermediary and the investor. These situations give rise to general Nonlinear Programming formulations in both levels of the decision process. We present different bilevel versions of the problem: financial intermediary-leader, investor-leader, and social welfare; besides, their properties are analyzed. Moreover, we develop Mixed Integer Linear Programming formulations for some of the proposed problems and effective algorithms for some others. Finally, we report on some computational experiments performed on data taken from the Dow Jones Industrial Average, and analyze and compare the results obtained by the different models.},
  archive      = {J_EJOR},
  author       = {Marina Leal and Diego Ponce and Justo Puerto},
  doi          = {10.1016/j.ejor.2019.12.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {712-727},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Portfolio problems with two levels decision-makers: Optimal portfolio selection with pricing decisions on transaction costs},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spatial scale and product mix economies in u.s. Banking with
simultaneous spillover regimes. <em>EJOR</em>, <em>284</em>(2), 693–711.
(<a href="https://doi.org/10.1016/j.ejor.2019.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on bank scale economies focuses on the familiar type of returns to scale that are internal to the firm. Using a spatial approach, we analyze returns to scale for banks that are made up of external (i.e., spillover) economies. We extend ray-scale economies (RSE), expansion-path scale economies (EPSE) and expansion-path subadditivity (EPSU) to the spatial case. This involves introducing direct and composite and decomposed indirect RSE, EPSE and EPSU. These direct and indirect measures relate to the cost implications for a firm from a change in: (i) the firm’s output levels that are, as is standard, under its control; and (ii) the composite/decomposed spillover effect on the firm’s output levels, which is primarily, but not entirely, outside its control. We include an application to U.S. banks (1998–2015) that allows a bank to simultaneously belong to a number of spatial networks, which is typically what we observe for firms. For large banks we find constant direct RSE and EPSE, and zero composite indirect RSE and constant composite indirect EPSE. These composite indirect results do not counteract any policy suggestions from the direct RSE and EPSE concerning the debate on whether there should be size caps on very large U.S. banks. The direct RSE and EPSE for large banks suggest that these banks use society’s resources efficiently to provide their services. Size caps on very large banks would place downward pressure on these direct RSE and EPSE results, which could lead to large banks using society’s resources inefficiently.},
  archive      = {J_EJOR},
  author       = {Anthony J. Glass and Amangeldi Kenjegaliev and Karligash Kenjegalieva},
  doi          = {10.1016/j.ejor.2019.12.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {693-711},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Spatial scale and product mix economies in U.S. banking with simultaneous spillover regimes},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The hybrid electric vehicle—traveling salesman problem with
time windows. <em>EJOR</em>, <em>284</em>(2), 675–692. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend the Hybrid Electric Vehicle – Traveling Salesman Problem (HEV-TSP) that deploys hybrid electric vehicles for customer delivery tours, by considering that customers must be served within given time windows. This feature makes the problem very difficult to solve. We developed a Variable Neighborhood Search based heuristic solution method, which is able to handle hybrid electric vehicle problems with a realistic number of customers. We introduce a large set of benchmark instances, representing typical delivery areas for small package shipping companies. Exact solutions for instances with a small number of customers are calculated by formulating the problem as an integer linear program and solving the instances with the standard solver CPLEX. The proposed heuristic achieves optimal solutions on the small and good quality solutions on larger instances. Furthermore, the results show that the profitability of hybrid electric vehicles highly depends on the structure of the delivery area and the number of customers to serve. Therefore, our heuristic does not only serve to support decision makers in the daily tour planning, but also in the evaluation of the profitability of hybrid electric vehicles for a specific delivery area structure.},
  archive      = {J_EJOR},
  author       = {Christian Doppstadt and Achim Koberstein and Daniele Vigo},
  doi          = {10.1016/j.ejor.2019.12.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {675-692},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The hybrid electric Vehicle—Traveling salesman problem with time windows},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recommendation generation using personalized weight of
meta-paths in heterogeneous information networks. <em>EJOR</em>,
<em>284</em>(2), 660–674. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s era of electronic markets with information overload, generating personalized recommendations for e-commerce users is a challenging and interesting problem. Recommending top- N items of interest to e-commerce users is more challenging using binary implicit feedback. The training data is usually highly sparse and has binary values capturing a user&#39;s action or inaction. Due to the sparseness of data and lack of explicit user preferences, neighborhood-based and model-based approaches may not be effective to generate accurate recommendations. Of late, network-based item recommendation methods, which utilize item related meta-information, have started getting attention. In this work, we propose a heterogeneous information network-based recommendation model called HeteroPRS for personalized top- N recommendations using binary implicit feedback. To utilize the potential of meta-information related to items, we use the concept of meta-path. To improve the effectiveness of the recommendations, the popularity of items and interest of users are leveraged simultaneously. Personalized weight learning of various meta-paths in the network is performed to determine the intrinsic interests of users from the binary implicit feedback. The proposed model is experimentally evaluated and compared with various recommendation techniques for implicit feedback using real-world datasets, and the results show the effectiveness of the proposed model.},
  archive      = {J_EJOR},
  author       = {Mukul Gupta and Pradeep Kumar},
  doi          = {10.1016/j.ejor.2020.01.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {660-674},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Recommendation generation using personalized weight of meta-paths in heterogeneous information networks},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pareto uncertainty index for evaluating and comparing
solutions for stochastic multiple objective problems. <em>EJOR</em>,
<em>284</em>(2), 644–659. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering problems have multiple conflicting objectives, and they are also stochastic due to inherent uncertainties. One way to represent the multi-objective nature of problems is to use the Pareto optimality to show the trade-off between objectives. Pareto optimality involves the identification of solutions that are not dominated by other solutions based on their respective objective functions. However, the Pareto optimality concept does not contain any information about the uncertainty of solutions. Evaluation and comparison of solutions becomes difficult when the objective functions are subjected to uncertainty. A new metric, the Pareto Uncertainty Index (PUI), is presented. This metric includes uncertainty due to the stochastic coefficients in the objective functions as part of the Pareto optimality concept to form an extended probabilistic Pareto set, we define as the p -Pareto set. The decision maker can observe and assess the randomness of solutions and compare the promising solutions according to their performance of satisfying objectives and any undesirable uncertainty. The PUI is an effective and convenient decision-making tool to compare promising solutions with multiple uncertain objectives.},
  archive      = {J_EJOR},
  author       = {Saltuk Buğra Selçuklu and David W. Coit and Frank A. Felder},
  doi          = {10.1016/j.ejor.2020.01.004},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {644-659},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pareto uncertainty index for evaluating and comparing solutions for stochastic multiple objective problems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distribution based representative sets for multi-objective
integer programs. <em>EJOR</em>, <em>284</em>(2), 632–643. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study and exploit the characteristics of the nondominated sets of Multi-objective Integer Programs (MOIPs). We introduce a density measure and search for common properties of the distributions of nondominated points for different MOIPs. We design a procedure that categorizes the nondominated set into regions based on the densities of nondominated points. We develop an approach that generates representative sets of nondominated points using the estimated density information in different regions for general MOIPs. Experiments show that our approach is robust across different types of MOIPs.},
  archive      = {J_EJOR},
  author       = {Sami Serkan Özarık and Banu Lokman and Murat Köksalan},
  doi          = {10.1016/j.ejor.2020.01.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {632-643},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Distribution based representative sets for multi-objective integer programs},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Affordance-based problem structuring for workplace
innovation. <em>EJOR</em>, <em>284</em>(2), 617–631. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Problem structuring methods (PSMs) are operational research (OR) techniques commonly used to investigate and capture the multidimensional and complex nature of situations. This article proposes a novel PSM, termed the situational affordance structuring approach (SASA), for structuring work situations with a view to identifying opportunities for workplace innovation. SASA involves a series of sense-making principles to define work systems, source operational data, gather domain information, and represent situational knowledge using an abstraction-decomposition space (ADS) diagram. The ADS representation is premised on the theory of affordances which posits that objects and events possess inherent meaning as detected and exploited by users. The article intends to support the OR community by introducing the ADS as a novel approach to represent situations during problem structuring and presents findings from a case example involving the use of SASA for industrial design. The case involves an expert-led approach to unravelling perceived messiness in work situations with particular emphasis on representing the situational knowledge of the industrial domain using an ADS. SASA is a novel and unique PSM in two main ways: (i) it is inspired by ecological psychology with an emphasis on the affordances of work situations, and (ii) it uses the ADS as an artefact to illustrate the superior-subordinate arrangements associated with perceived messiness in structured (or semi-structured) work situations. The article also discusses the research implications, practical relevance of the study for the OR field, research limitations and possible future research directions.},
  archive      = {J_EJOR},
  author       = {Christopher M. Durugbo},
  doi          = {10.1016/j.ejor.2019.12.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {617-631},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Affordance-based problem structuring for workplace innovation},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Urban land use and transportation planning for climate
change mitigation: A theoretical framework. <em>EJOR</em>,
<em>284</em>(2), 604–616. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cities account for 75\% of global greenhouse gas (GHG) emissions from energy use, and their share is increasing due to rapid urbanization. While compact urban forms with public transit are viewed as important strategies for reducing emissions, environmental benefits must be weighed against the costs of public transit infrastructure, road improvements to alleviate congestion in dense urban space, and more expensive housing resulting from land use restrictions. The literature largely lacks a theoretical framework for assessing these tradeoffs. This paper derives analytical insights into urban land use and transportation planning for climate change mitigation by formulating a social planner’s utility maximization problem. The planner chooses the residential densities of urban zones as well as investments in road and public transit infrastructures that link these zones to the city center. Road travel is subject to congestion. Any feasible solution must accommodate a fixed total population and ensure that residents of all zones have the same maximum utility. GHG emissions associated with housing, road travel, and public transit generate damages. Analytical results show that incorporating GHG damages into urban planning always leads to an optimal solution with a more compact urban form, and reduces automobile travel in each zone if a specific condition involving the marginal congestion cost and the marginal effectiveness of road investment is satisfied. Numerical examples demonstrate that near-optimal emissions reductions and utility improvements can be achieved via public transit investment and mode shifting even if the planner inherits and cannot modify a suboptimal land use and road configuration.},
  archive      = {J_EJOR},
  author       = {Benjamin D. Leibowicz},
  doi          = {10.1016/j.ejor.2019.12.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {604-616},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Urban land use and transportation planning for climate change mitigation: A theoretical framework},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modelling distributed decision-making in command and control
using stochastic network synchronisation. <em>EJOR</em>,
<em>284</em>(2), 588–603. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We advance a mathematical representation of Command and Control as distributed decision makers using the Kuramoto model of networked phase oscillators. The phase represents a continuous Perception-Action cycle of agents at each network node; the network the formal and informal communications of human agents and information artefacts; coupling the strength of relationship between agents; native frequencies the individual decision speeds of agents when isolated; and stochasticity temporal noisiness in intrinsic agent behaviour. Skewed heavy-tailed noise captures that agents may randomly ‘jump’ forward (rather than backwards) in their decision state under time stress; there is considerable evidence from organisational science that experienced decision-makers behave in this way in critical situations. We present a use-case for the model using data for military headquarters staff tasked to drive a twenty-four hour ‘battle-rhythm’. This serves to illustrate how such a mathematical model may be used realistically. We draw on a previous case-study where headquarters’ networks were mapped for routine business and crisis scenarios to provide advice to a military sponsor. We tune the model using the first data set to match observations that staff performed synchronously under such conditions. Testing the impact of the crisis scenario using the corresponding network and heavy-tailed stochasticity, we find increased probability of decision incoherence due to the high information demand of some agents in this case. This demonstrates the utility of the model to identify risks in headquarters design, and potential means of identifying points to change. We compare to qualitative organisational theories to initially validate the model.},
  archive      = {J_EJOR},
  author       = {Alexander C. Kalloniatis and Timothy A. McLennan-Smith and Dale O. Roberts},
  doi          = {10.1016/j.ejor.2019.12.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {588-603},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modelling distributed decision-making in command and control using stochastic network synchronisation},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-sided competition with vertical differentiation in both
acquisition and sales in remanufacturing. <em>EJOR</em>,
<em>284</em>(2), 572–587. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the competition between two remanufacturers in the acquisition of used products and the sales of remanufactured products. One firm has a market advantage; we consider two separate cases where either firm could have an acquisition advantage. The problem is formulated as a simultaneous game on a market that is vertically differentiated in both acquisition and sales, where both firms decide on their respective acquisition prices for used products, and selling prices for remanufactured products. A key finding is that a market advantage is significantly more powerful than an acquisition advantage. The firm with a market advantage can preempt the entry of the other firm, even if that firm has a significant acquisition advantage, but not the other way around. This is accomplished through an aggressive acquisition strategy, where the firm with a market advantage sets significantly higher acquisition prices.},
  archive      = {J_EJOR},
  author       = {Rainer Kleber and Marc Reimann and Gilvan C. Souza and Weihua Zhang},
  doi          = {10.1016/j.ejor.2020.01.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {572-587},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Two-sided competition with vertical differentiation in both acquisition and sales in remanufacturing},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A memory-based iterated local search algorithm for the
multi-depot open vehicle routing problem. <em>EJOR</em>,
<em>284</em>(2), 559–571. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem studied in this paper is the multi-depot open vehicle routing problem, which has the following two differences in relation to the classical vehicle routing problem: there are several depots; the vehicles do not return to the depot after delivering the goods to the customers, i.e., the end of the route is not the starting point. There are many practical applications for this problem, however the great majority of the studies have only addressed the open vehicle routing problem with a single depot. In this paper, we present an iterated local search algorithm, in which the moves performed during the local search are recalled and this historical search information is then used to define the moves executed inside the perturbation procedures. Therefore, it is recorded the number of times that each customer is moved during the local search. Since this information is continuously updated and changes in each iteration, the search is driven to potentially better regions of the solution space, and increases the chance of avoiding cycling, even when using deterministic perturbations. The performance of this algorithm was tested using a large set of benchmark problems and was compared with other algorithms, and the results show that it is very competitive.},
  archive      = {J_EJOR},
  author       = {José Brandão},
  doi          = {10.1016/j.ejor.2020.01.008},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {559-571},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A memory-based iterated local search algorithm for the multi-depot open vehicle routing problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalizing the theta method for automatic forecasting.
<em>EJOR</em>, <em>284</em>(2), 550–558. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Theta method became popular due to its superior performance in the M3 forecasting competition. Since then, although it has been shown that Theta provides accurate forecasts for various types of data, being a solid benchmark to beat, limited research has been conducted to exploit its full potential and generalize its reach. This paper examines three extensions on Theta’s framework to boost its performance. This includes (i) considering both linear and non-linear trends, (ii) allowing to adjust the slope of such trends, and (iii) introducing a multiplicative expression of the underlying forecasting model along with the existing, additive one. The proposed modifications transform Theta into a generalized forecasting algorithm, suitable for automatic time series predictions. The proposed algorithm is evaluated using the series of the M, M3, and M4 competitions. Such an evaluation shows that the proposed approach produces more accurate forecasts than the original, classic Theta, both in terms of point forecasts and prediction intervals, and is also more accurate than other well-known methods for yearly series.},
  archive      = {J_EJOR},
  author       = {Evangelos Spiliotis and Vassilios Assimakopoulos and Spyros Makridakis},
  doi          = {10.1016/j.ejor.2020.01.007},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {550-558},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generalizing the theta method for automatic forecasting},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal ordering policy for complementary components with
partial backordering and emergency replenishment under spectral risk
measure. <em>EJOR</em>, <em>284</em>(2), 538–549. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A firm (assembler) faces random demand for a final product which is made up of multiple complementary components. Before demand is realized, the firm purchases the components via a regular channel. After demand realization, unsatisfied demand is allowed to be partially backordered in case of component shortages, where the firm is assumed to have an option to purchase the components via an emergency channel with a relatively higher unit cost. The firm needs to adopt an appropriate ordering policy to maximize the spectral risk measure of its profit. We formulate and transform the newsvendor problem into a concise optimization problem which can be further decomposed into two sub-problems. We provide optimality properties and show that the objective function of each sub-problem is separable, which enables us to determine the optimal order quantity of each component independently. We show that the optimal order quantity of each component decreases in the firm&#39;s level of risk-aversion. Numerical experiments are conducted to illustrate the effectiveness of our solution method and examine the impacts of lost sales and risk attitude on the optimal solutions.},
  archive      = {J_EJOR},
  author       = {Li Yanhai and Ou Jinwen},
  doi          = {10.1016/j.ejor.2020.01.006},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {538-549},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal ordering policy for complementary components with partial backordering and emergency replenishment under spectral risk measure},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Liability cost sharing, product quality choice, and
coordination in two-echelon supply chains. <em>EJOR</em>,
<em>284</em>(2), 514–537. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a two-echelon supply chain in which an upstream manufacturer (M) and a downstream retailer (R) share the product liability cost caused by quality defects. We assume that M and R share the expected liability cost per unit of the low-quality product (the ULQ liability cost). We use two respective Stackelberg games to model two different channel leadership structures: the manufacturer-led Stackelberg (MS) and the retailer-led Stackelberg (RS). We first obtain the analytical subgame perfect equilibria for the games. Subsequently, we investigate the impacts of the ULQ liability cost sharing on the product quality and the pricing decisions and on the profitability for supply chain members and the entire supply chain in equilibrium. We find that (1) in response to a shift of the share of the ULQ liability cost from R to M, the leader M under the MS structure is able to use a higher wholesale price to transfer its increased ULQ liability cost completely to R without the need to improve its product quality, while the leader R under the RS structure would decrease its retail margin to incentivize M to improve its product quality; (2) such a shift of the ULQ liability cost sharing does not have any impact on the supply chain efficiency under the MS structure, but it enhances the supply chain efficiency under the RS structure; (3) despite the different responses of the leaders under the MS and the RS structures, we are able to establish a same set of contracts combining quantity discounts with quality improvement cost sharing to coordinate the supply chain, regardless of the channel leadership structures.},
  archive      = {J_EJOR},
  author       = {Jianchang Fan and Debing Ni and Xiang Fang},
  doi          = {10.1016/j.ejor.2020.01.003},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {514-537},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Liability cost sharing, product quality choice, and coordination in two-echelon supply chains},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Role of resource flexibility and responsive pricing in
mitigating the uncertainties in production systems. <em>EJOR</em>,
<em>284</em>(2), 498–513. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two effective strategies that mitigate a firm’s demand risk are resource flexibility investment and responsive pricing. In addition to demand uncertainties firms also face capacity uncertainties and capacity disruptions and the effectiveness of these strategies under these risks are less clear. We investigate the value of resource flexibility and responsive pricing under different risk settings for a firm that produces two substitutable products each with its own dedicated resource that can be optionally reconfigured to produce the other product. Reconfiguration or cross-production incurs efficiency loss which can be mitigated by choosing the degree of flexibility of these resources, at a cost, in the planning stage along with capacity levels. In the production stage, after capacities and market potentials are realized, the firm allocates resources and sets prices. We find that under only demand uncertainties the value of flexibility is very low and only a moderate degree of flexibility is sufficient under high demand risk. Responsive pricing is the dominant strategy as the firm avoids investment in costly flexibility. When facing both demand and capacity uncertainties the firm invests in higher levels of flexibility but the value of flexibility is lower than the value of responsive pricing. However, under demand and capacity disruptions flexibility arises as the dominant strategy due to the resource risk pooling effect and the value of flexibility eclipses the value of pricing as the firm invests in full flexibility. For a firm with responsive pricing investment in flexibility is economically justified under high capacity uncertainties and capacity disruptions.},
  archive      = {J_EJOR},
  author       = {Sharethram Hariharan and Tieming Liu and Zuo-Jun Max Shen},
  doi          = {10.1016/j.ejor.2019.12.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {498-513},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Role of resource flexibility and responsive pricing in mitigating the uncertainties in production systems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hybrid stochastic and robust optimization model for
lot-sizing and scheduling problems under uncertainties. <em>EJOR</em>,
<em>284</em>(2), 485–497. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty is among the significant concerns in production scheduling. It has become increasingly important to take uncertainties into consideration for lot-sizing and scheduling. In this paper, we adopt the Hybrid Stochastic and Robust Optimization (HSRO) approach in lot-sizing and scheduling problems in which suppliers have the flexibility of satisfying a fraction of demand based on the market and their policies. Two types of uncertainties have been considered simultaneously: demand and overtime processing cost. Robust optimization is adopted for uncertain demand and Sample Average Approximation (SAA) technique is applied to solve the stochastic program for uncertain overtime processing cost. Numerical results based on a manufacturing company has been conducted to not only validate the proposed hybrid model but also quantitatively demonstrate the merit of our approach. Sample size stability test and sensitivity analyses on various parameters have also been conducted.},
  archive      = {J_EJOR},
  author       = {Zhengyang Hu and Guiping Hu},
  doi          = {10.1016/j.ejor.2019.12.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {485-497},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Hybrid stochastic and robust optimization model for lot-sizing and scheduling problems under uncertainties},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Order batching using an approximation for the distance
travelled by pickers. <em>EJOR</em>, <em>284</em>(2), 460–484. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the problem of order batching for picker routing. Our approach is applicable to warehouses (storage areas) arranged in the standard rectangular grid layout, so with parallel aisles and two or more cross-aisles. The motivation underlying our work is online grocery shopping in which orders may be composed of dozens of items. The approach presented directly addresses order batching, but uses a distance approximation to influence the batching of orders without directly addressing the routing problem. We present a basic formulation based on deciding the orders to be batched together so as to optimise an objective that approximates the picker routing distance travelled. We extend our formulation by improving the approximation for cases where we have more than one block in the warehouse. We present constraints to remove symmetry in order to lessen the computational effort required, as well as constraints that significantly improve the value of the linear programming relaxation of our formulation. A heuristic algorithm based on partial integer optimisation of our mathematical formulation is also presented. Once order batching has been decided we optimally route each individual picker using a previous approach presented in the literature. Extensive computational results for publicly available test problems involving up to 75 orders are given for both single and multiple block warehouse configurations.},
  archive      = {J_EJOR},
  author       = {Cristiano Arbex Valle and John E Beasley},
  doi          = {10.1016/j.ejor.2020.01.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {460-484},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Order batching using an approximation for the distance travelled by pickers},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Grouping tasks to save energy in a cyclic scheduling
problem: A complexity study. <em>EJOR</em>, <em>284</em>(2), 445–459.
(<a href="https://doi.org/10.1016/j.ejor.2020.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is motivated by the repetitive and periodic transmission of messages in Wireless Sensor Networks (WSNs) given by the ZigBee standard. In order to save energy, communication tasks are grouped in time. The WSN applications, such as control loops used in production lines, impose deadlines on the message delivery time. By introducing a grouping constraint, this paper extends the polynomial cyclic scheduling problem of building a periodic schedule with uniform precedence constraints and no resource constraints. We consider that each task belongs to one group, and each group is to be scheduled as a super-task in every period. We show two examples issued from different applications of such grouping constraints, using uniform constraints to model the deadlines expressed in the number of periods. We tackle the feasibility problem (the existence of a periodic schedule), which has shown to be independent of the processing times. We propose a graph formulation of the problem using the retiming technique. In the ZigBee case, we prove that the particular tree structure of the groups and of the uniform precedences based upon the communication tree, lead to a polynomial algorithm to solve the problem. But the general problem is proven to be NP-complete even if no additional resource constraints are considered, and unit processing times are assumed. This extension of the cyclic scheduling leads to a new range of grouping problems with applications, not only in communication networks but also in production and logistics scheduling.},
  archive      = {J_EJOR},
  author       = {Claire Hanen and Zdenek Hanzalek},
  doi          = {10.1016/j.ejor.2020.01.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {445-459},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Grouping tasks to save energy in a cyclic scheduling problem: A complexity study},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The proportionate flow shop total tardiness problem.
<em>EJOR</em>, <em>284</em>(2), 439–444. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the proportionate flow shop total tardiness problem and show how to implement Lawler&#39;s (1977) pseudo-polynomial dynamic programming (DP) algorithm for the single-machine total tardiness problem to the multi-machine environment of proportionate flow shop. We also present solvable special cases including one with small/big jobs that has not been considered for the corresponding single-machine problem. We then convert the DP algorithm for the proportionate flow shop to a fully polynomial time approximation scheme (FPTAS). Finally, we show by a counterexample that Pinedo&#39;s (2002, p. 140) statement that “the elimination criteria for the single-machine total weighted tardiness problem also apply to the proportionate flow shop total weighted tardiness problem” does not always hold and present an appropriately revised statement.},
  archive      = {J_EJOR},
  author       = {Christos Koulamas},
  doi          = {10.1016/j.ejor.2020.01.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {439-444},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The proportionate flow shop total tardiness problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The consecutive multiprocessor job scheduling problem.
<em>EJOR</em>, <em>284</em>(2), 427–438. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a variant of the multiprocessor job scheduling problem, where jobs are processed by several identical machines. The machines are ordered in a sequence, and each job is processed by several consecutive machines simultaneously. The jobs are characterized by their processing time, the number of required consecutive machines, and their ready time. The objective function is to minimize the sum of general functions defined over the completion time of each job. This study is motivated by a real problem in the semiconductor industry. We present a time-indexed integer programming and a constraint programming formulations for the problem and demonstrate their applicability through an extensive numerical study and an industrial case study.},
  archive      = {J_EJOR},
  author       = {Yossi Bukchin and Tal Raviv and Ilya Zaides},
  doi          = {10.1016/j.ejor.2019.12.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {427-438},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The consecutive multiprocessor job scheduling problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic intersection of multiple implicit dantzig–wolfe
decompositions applied to the adjacent only quadratic minimum spanning
tree problem. <em>EJOR</em>, <em>284</em>(2), 413–426. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a dynamic Dantzig–Wolfe (DW) reformulation framework for the Adjacent Only Quadratic Minimum Spanning Tree Problem (AQMSTP). The approach is dynamic in the sense that the structures over which the DW reformulation takes place are defined on the fly and not beforehand. The idea is to dynamically convexify multiple promising regions of the domain, without explicitly formulating DW master programs over extended variable spaces and applying column generation. Instead, we use the halfspace representation of polytopes as an alternative to mathematically represent the convexified region in the original space of variables. Thus, the numerical machinery we devise for computing AQMSTP lower bounds operates in a cutting plane setting, separating projection cuts associated to the projection of the variables used in the extended DW reformulations. Our numerical experience indicates that the bounds are quite strong and the computational times are mostly spent by linear programming reoptimization and not by the separation procedures. Thus, we introduce a Lagrangian Relax-and-cut algorithm for approximating these bounds. The method is embedded in a Branch-and-Bound algorithm for the AQMSTP. Although it does not strictly dominate the previous state-of-the-art exact method, it is able to solve more instances to proven optimality and is significantly faster for the hardest AQMSTP instances in the literature.},
  archive      = {J_EJOR},
  author       = {Dilson Lucas Pereira and Alexandre Salles da Cunha},
  doi          = {10.1016/j.ejor.2019.12.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {413-426},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic intersection of multiple implicit Dantzig–Wolfe decompositions applied to the adjacent only quadratic minimum spanning tree problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of revenue management: Recent generalizations and
advances in industry applications. <em>EJOR</em>, <em>284</em>(2),
397–412. (<a href="https://doi.org/10.1016/j.ejor.2019.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Originating from passenger air transport, revenue management has evolved into a general and indispensable methodological framework over the last decades, comprising techniques to manage demand actively and to further improve companies’ profits in many different industries. This article is the second and final part of a paper series surveying the scientific developments and achievements in revenue management over the past 15 years. The first part focused on the general methodological advances regarding choice-based theory and methods of availability control over time. In this second part, we discuss some of the most important generalizations of the standard revenue management setting: product innovations (opaque products and flexible products), upgrading, overbooking, personalization, and risk-aversion. Furthermore, to demonstrate the broad use of revenue management, we survey important industry applications beyond passenger air transportation that have received scientific attention over the years, covering air cargo, hotel, car rental, attended home delivery, and manufacturing. We work out the specific revenue management-related challenges of each industry and portray the key contributions from the literature. We conclude the paper with some directions for future research.},
  archive      = {J_EJOR},
  author       = {Robert Klein and Sebastian Koch and Claudius Steinhardt and Arne K. Strauss},
  doi          = {10.1016/j.ejor.2019.06.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {397-412},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of revenue management: Recent generalizations and advances in industry applications},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Technology choice under emission regulation uncertainty in
international container shipping. <em>EJOR</em>, <em>284</em>(1),
383–396. (<a href="https://doi.org/10.1016/j.ejor.2019.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a real options approach to evaluate technology and capacity choices under regulatory uncertainty. Our two-phase, regime-switching model includes the option of investing in different technologies as well as a charter and layup option, respectively. For a base-case version of this model, we derive an analytical solution before studying the effect of regulatory uncertainty in a numerical extension that relaxes certain restrictive assumptions. We then describe three regulatory regimes, an emissions cap, an emissions tax and a cap-and-trade market, and compare how effectively each reduces emissions. Applying the model to maritime container shipping, we develop insights on the optimal technology choice for reducing SO x emissions. We find that regulatory uncertainty can increase not only project values but also owned capacity. From a regulatory perspective, an emissions cap reduces emissions more effectively whereas an emissions tax reduces the cost of regulation. The cap-and-trade market emerges in many respects as superior to an emissions tax. Finally, we show that setting the emissions cap level—or deciding on the level above which an emissions tax or emissions trade apply—is critical because reduction in total industry emissions are not necessarily continuous.},
  archive      = {J_EJOR},
  author       = {Christian Haehl and Stefan Spinler},
  doi          = {10.1016/j.ejor.2019.12.025},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {383-396},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technology choice under emission regulation uncertainty in international container shipping},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The noncooperative fixed charge transportation problem.
<em>EJOR</em>, <em>284</em>(1), 373–382. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the noncooperative fixed charge transportation problem (NFCTP), which is a game-theoretic extension of the fixed charge transportation problem. In the NFCTP, competing players solve coupled fixed charge transportation problems simultaneously. Three versions of the NFCTP are discussed and compared which differ in the treatment of shared social costs. This may be used from central authorities in order to find a socially balanced framework which is illustrated in a numerical study. Using techniques from generalized Nash equilibrium problems with mixed-integer variables we show the existence of Nash equilibria for these models and examine their structural properties. Since there is no unique equilibrium for the NFCTP, we also discuss how to solve the Nash selection problem and, finally, propose numerical methods for the computation of Nash equilibria which are based on mixed-integer programming.},
  archive      = {J_EJOR},
  author       = {Simone Sagratella and Marcel Schmidt and Nathan Sudermann-Merx},
  doi          = {10.1016/j.ejor.2019.12.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {373-382},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The noncooperative fixed charge transportation problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Management estimation in banking. <em>EJOR</em>,
<em>284</em>(1), 355–372. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and estimate a model of management practices as an unobserved (latent) input in a standard production function of banks. We derive estimates of management at the bank-quarter level, using data for all U.S. banks from 1984 to 2016 and Bayesian techniques. We show that management practices are an important missing input in banks’ operational processes. We validate our approach using repeated random sampling (Monte Carlo simulation) within a rather unfavorable environment. We also show that management is highly correlated with bank profitability (positively) and the probability of default (negatively). Our new measure compares favorably with existing measures of management derived from the residual of the regression of frontier efficiency on bank characteristics that are beyond management&#39;s capacity to change. Our model can be considered a benchmark to estimate good management practices, to analyze their sources, and to establish good management as an important determinant of efficient and sound banking.},
  archive      = {J_EJOR},
  author       = {Manthos D. Delis and Maria Iosifidi and Mike Tsionas},
  doi          = {10.1016/j.ejor.2019.12.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {355-372},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Management estimation in banking},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal control of water distribution networks without
storage. <em>EJOR</em>, <em>284</em>(1), 345–354. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates the problem of optimal control of water distribution networks without storage capacity. Using mathematical optimization, we formulate and solve the problem as a non-convex NLP, in order to obtain optimal control curves for both variable speed pumps and pressure reducing valves of the network and thus propose a methodology for the automated control of real operational networks. We consider both single-objective and multi-objective problems with average zonal pressure, pump energy consumption and water treatment cost as objectives. Furthermore, we investigate global optimality bounds for the calculated solutions using global optimization techniques. The proposed approach is shown to outperform state-of-the-art global optimization solvers. The described procedure is demonstrated in a case study using a large size operational network.},
  archive      = {J_EJOR},
  author       = {Dimitrios Nerantzis and Filippo Pecci and Ivan Stoianov},
  doi          = {10.1016/j.ejor.2019.12.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {345-354},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal control of water distribution networks without storage},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Loading tow trains ergonomically for just-in-time part
supply. <em>EJOR</em>, <em>284</em>(1), 325–344. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with an aging workforce, many manufacturing companies consider alleviating the ergonomic strain of material handling on their workers increasingly important. This is one of the reasons why frequent small-lot deliveries of parts to the assembly stations on the shop floor via small electric delivery vehicles – so-called tow trains – have become widespread in many industries. Deploying tow trains, however, does not automatically ease the ergonomic burden on logistics workers, but requires careful stowage planning in addition. In this paper, we consider the following problem. Given a set of bins of differing weight to be carried by tow train to a given set of stations on the shop floor, where should each bin be stowed on the tow train such that it can be unloaded efficiently from an economic perspective while also minimizing the ergonomic strain during loading and unloading? We investigate the physiological stress of handling bins on different levels of a tow train wagon by applying an established ergonomic evaluation method from the human factors engineering literature. We model the ensuing optimization problem as a special type of assignment problem and propose suitable exact and heuristic solution methods. In a computational study, our approaches are shown to perform well, delivering optimal solutions for instances of realistic size within fractions of a second in many cases. We show that optimal stowage plans can significantly ease the physiological burden on the workforce without compromising economic efficiency. We also derive some insights into the ideal layout of the tow train from an ergonomics perspective.},
  archive      = {J_EJOR},
  author       = {Heiko Diefenbach and Simon Emde and Christoph H. Glock},
  doi          = {10.1016/j.ejor.2019.12.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {325-344},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Loading tow trains ergonomically for just-in-time part supply},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Endogenous dynamic efficiency in the intertemporal
optimization models of firm behavior. <em>EJOR</em>, <em>284</em>(1),
313–324. (<a href="https://doi.org/10.1016/j.ejor.2019.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods for the measurement of technical efficiency in the dynamic production models obtain it from the implied distance functions without making use of the information about intertemporal economic behavior in the estimation beyond an indirect appeal to duality. The main limitation of such an estimation approach is that it does not allow for the dynamic evolution of efficiency that is explicitly optimized by the firm. This paper introduces a new conceptualization of efficiency that directly enters the firm’s intertemporal production decisions and is both explicitly costly and endogenously determined. We build a moment-based multiple-equation system estimation procedure that incorporates both the dynamic and static optimality conditions derived from the firm’s intertemporal expected cost minimization. We operationalize our methodology using a modified version of a Bayesian Exponentially Tilted Empirical Likelihood adjusted for the presence of dynamic latent variables in the model, which we showcase using the 1960–2004 U.S. agricultural farm production data. We find that allowing for potential endogenous adjustments in efficiency over time produces significantly higher estimates of technical efficiency, which is likely due to inherent inability of the more standard exogenous-efficiency model to properly credit firms for incurring efficiency-improvement adjustment costs. Our results also suggest material improvements in efficiency over time at an about 2.6\% average annual rate, which contrasts with near-zero estimates of the exogenous efficiency change.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas and Emir Malikov and Subal C. Kumbhakar},
  doi          = {10.1016/j.ejor.2019.12.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {313-324},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Endogenous dynamic efficiency in the intertemporal optimization models of firm behavior},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Marginality and myerson values. <em>EJOR</em>,
<em>284</em>(1), 301–312. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to analyze the relationship between marginality and the Myerson value, the within groups Myerson value (WG-Myerson value) and the between groups Myerson value (BG-Myerson value). We enlarge the idea of the classical marginal contribution of a player to a coalition in a cooperative game. Besides this type of contribution, in games with cooperation restricted by a graph, a player can contribute to a coalition in other ways. For example, lending his links to the coalition but without joining it. We will call it the marginal contribution of the player’s links (L-marginal contribution). Also he can contribute to a coalition by joining it with his communication possibilities. This is the marginal contribution of the player with his links (PL-marginal contribution). According to this, we define the strong monotonicity of the allocation rules with respect to the L-marginal contributions (and the L-marginality); and similarly, the strong monotonicity with respect to the PL-marginal contributions (and the PL-marginality). We prove that the Myerson value, the WG-Myerson value and the BG-Myerson value can be characterized using as requirement PL-marginality, marginality and L-marginality, respectively (as well as other properties).},
  archive      = {J_EJOR},
  author       = {C. Manuel and E. Ortega and M. del Pozo},
  doi          = {10.1016/j.ejor.2019.12.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {301-312},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Marginality and myerson values},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A graph-based formulation for the shift rostering problem.
<em>EJOR</em>, <em>284</em>(1), 285–300. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a shift rostering problem – the assignment of staff to shifts over a planning horizon such that work rules are observed. Traditional integer-programming models are not able to solve shift rostering problems effectively for large number of staff and feasible shift patterns. We formulate work rules in terms of newly-proposed prohibited meta-sequences and resource constraints. A graph-based formulation and a specialized graph construction algorithm are proposed where the set of feasible shift patterns is represented by paths of a graph. The formulation size depends on the structure of the work-rule constraints and is independent of the number of staff. This approach results in smaller networks allowing large-scale rostering problems with hard constraints to be solved efficiently using standard commercial solvers. Moreover, it allows finding multiple optimal solutions which are beneficial for managerial decision makers. Computational results show that the proposed approach can obtain new best-known solutions and identify proven optimal solutions for almost all NSPLIB instances at significantly lower CPU times.},
  archive      = {J_EJOR},
  author       = {David S.W. Lai and Janny M.Y. Leung and Wout Dullaert and Inês Marques},
  doi          = {10.1016/j.ejor.2019.12.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {285-300},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A graph-based formulation for the shift rostering problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Profit-based churn prediction based on minimax probability
machines. <em>EJOR</em>, <em>284</em>(1), 273–284. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose three novel profit-driven strategies for churn prediction. Our proposals extend the ideas of the Minimax Probability Machine, a robust optimization approach for binary classification that maximizes sensitivity and specificity using a probabilistic setting. We adapt this method and other variants to maximize the profit of a retention campaign in the objective function, unlike most profit-based strategies that use profit metrics to choose between classifiers, and/or to define the optimal classification threshold given a probabilistic output. A first approach is developed as a learning machine that does not include a regularization term, and subsequently extended by including the LASSO and Tikhonov regularizers. Experiments on well-known churn prediction datasets show that our proposal leads to the largest profit in comparison with other binary classification techniques.},
  archive      = {J_EJOR},
  author       = {Sebastián Maldonado and Julio López and Carla Vairetti},
  doi          = {10.1016/j.ejor.2019.12.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {273-284},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Profit-based churn prediction based on minimax probability machines},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparsity in optimal randomized classification trees.
<em>EJOR</em>, <em>284</em>(1), 255–272. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees are popular Classification and Regression tools and, when small-sized, easy to interpret. Traditionally, a greedy approach has been used to build the trees, yielding a very fast training process; however, controlling sparsity (a proxy for interpretability) is challenging. In recent studies, optimal decision trees, where all decisions are optimized simultaneously, have shown a better learning performance, especially when oblique cuts are implemented. In this paper, we propose a continuous optimization approach to build sparse optimal classification trees, based on oblique cuts, with the aim of using fewer predictor variables in the cuts as well as along the whole tree. Both types of sparsity, namely local and global, are modeled by means of regularizations with polyhedral norms. The computational experience reported supports the usefulness of our methodology. In all our data sets, local and global sparsity can be improved without harming classification accuracy. Unlike greedy approaches, our ability to easily trade in some of our classification accuracy for a gain in global sparsity is shown.},
  archive      = {J_EJOR},
  author       = {Rafael Blanquero and Emilio Carrizosa and Cristina Molero-Río and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2019.12.002},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {255-272},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Sparsity in optimal randomized classification trees},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). High price or low price? An experimental study on a markdown
pricing policy. <em>EJOR</em>, <em>284</em>(1), 240–254. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines whether strategic customers’ behavioral patterns remain consistent in different pricing scenarios under a markdown pricing policy. These customers’ decision patterns have been widely discussed because they significantly influence the expected monetary output. Contrary to rational assumptions, the behavioral research literature indicates that customers’ behavioral biases manifest in their reference dependency, risk and loss attitudes, and fill rate misperceptions. However, the relationship between behavioral biases and various pricing scenarios has not been carefully examined; accordingly, we conducted laboratory experiments to observe customers’ behavioral performance in a series of pricing scenarios to provide pricing suggestions for sellers. Our experimental results demonstrate that behavioral factors reflecting risk and loss attitudes as well as reference dependency can clearly describe customers’ behavioral biases. Meanwhile, our estimation shows that the degrees of risk and loss attitude are not constant, but depend on price settings: the lower the full price in the initial period, the higher the degrees of aversion to both risk and loss. Given such behavioral patterns, we suggest that sellers should set their full prices lower than the normative value when the fill rate in period two is low, and set them higher than the normative value when the fill rate in period two is high.},
  archive      = {J_EJOR},
  author       = {Junlin Chen and Yingshuai Zhao},
  doi          = {10.1016/j.ejor.2019.12.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {240-254},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {High price or low price? an experimental study on a markdown pricing policy},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the dynamic allocation of assets subject to failure.
<em>EJOR</em>, <em>284</em>(1), 227–239. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by situations arising in surveillance, search and monitoring, in this paper we study dynamic allocation of assets which tend to fail, requiring replenishment before once again being available for operation on one of the available tasks. We cast the problem as a closed-system continuous-time Markov decision process with impulsive controls, maximising the long-term time-average sum of per-task reward rates. We then formulate an open-system continuous-time approximative model, whose Lagrangian relaxation yields a decomposition (innovatively extending the restless bandits approach), from which we derive the corresponding Whittle index. We propose two ways of adapting the Whittle index derived from the open-system model to the original closed-system model, a naïve one and a cleverly modified one. We carry out extensive numerical performance evaluation of the original closed-system model, which indicates that the cleverly modified Whittle index rule is nearly optimal, being within 1.6\% (0.4\%, 0.0\%) of the optimal reward rate 75\% (50\%, 25\%) of the time, and significantly superior to uniformly random allocation which is within 22.0\% (16.2\%, 10.7\%) of the optimal reward rate. Our numerical results also suggest that the Whittle index must be cleverly modified when adapting it from the open-system, as the naïve Whittle index rule is not superior to a myopic greedy policy.},
  archive      = {J_EJOR},
  author       = {Stephen Ford and Michael P. Atkinson and Kevin Glazebrook and Peter Jacko},
  doi          = {10.1016/j.ejor.2019.12.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {227-239},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the dynamic allocation of assets subject to failure},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiobjective stochastic simulation optimization
algorithm. <em>EJOR</em>, <em>284</em>(1), 212–226. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of kriging metamodels in simulation optimization has become increasingly popular during recent years. The majority of the algorithms so far uses the ordinary (deterministic) kriging approach for constructing the metamodel, assuming that solutions have been sampled with infinite precision. This is a major issue when the simulation problem is stochastic: ignoring the noise in the outcomes may not only lead to an inaccurate metamodel, but also to potential errors in identifying the optimal points among those sampled. Moreover, most algorithms so far have focused on single-objective problems. In this article, we test the performance of a multiobjective simulation optimization algorithm that contains two crucial elements: the search phase implements stochastic kriging to account for the inherent noise in the outputs when constructing the metamodel, and the accuracy phase uses a well-known multiobjective ranking and selection procedure in view of maximizing the probability of selecting the true Pareto-optimal points by allocating extra replications on competitive designs. We evaluate the impact of these elements on the search and identification effectiveness, for a set of test functions with different Pareto front geometries, and varying levels of heterogeneous noise. Our results show that the use of stochastic kriging is essential in improving the search efficiency; yet, the allocation procedure appears to lose effectiveness in settings with high noise. This emphasizes the need for further research on multiobjective ranking and selection methods.},
  archive      = {J_EJOR},
  author       = {Sebastian Rojas Gonzalez and Hamed Jalali and Inneke Van Nieuwenhuyse},
  doi          = {10.1016/j.ejor.2019.12.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {212-226},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multiobjective stochastic simulation optimization algorithm},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Versatile sequential sampling algorithm using kernel density
estimation. <em>EJOR</em>, <em>284</em>(1), 201–211. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the physical mechanisms governing scientific and engineering systems requires performing experiments. Therefore, the construction of the Design of Experiments (DoE) is paramount for the successful inference of the intrinsic behavior of such systems. There is a vast literature on one-shot designs such as low discrepancy sequences and Latin Hypercube Sampling (LHS). However, in a sensitivity analysis context, an important property is the stochasticity of the DoE which is partially addressed by these methods. This work proposes a new stochastic, iterative DoE – named KDOE – based on a modified Kernel Density Estimation (KDE). It is a two-step process: (i) candidate samples are generated using Markov Chain Monte Carlo (MCMC) based on KDE, and (ii) one of them is selected based on some metric. The performance of the method is assessed by means of the C 2 -discrepancy space-filling criterion. KDOE appears to be as performant as classical one-shot methods in low dimensions, while it presents increased performance for high-dimensional parameter spaces. It is a versatile method which offers an alternative to classical methods and, at the same time, is easy to implement and offers customization based on the objective of the DoE.},
  archive      = {J_EJOR},
  author       = {Pamphile T. Roy and Lluís Jofre and Jean-Christophe Jouhaud and Bénédicte Cuenot},
  doi          = {10.1016/j.ejor.2019.11.070},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {201-211},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Versatile sequential sampling algorithm using kernel density estimation},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Population-based risk equilibration for the multimode hazmat
transport network design problem. <em>EJOR</em>, <em>284</em>(1),
188–200. (<a href="https://doi.org/10.1016/j.ejor.2019.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shipment of hazardous materials is important and many of these products are flammable, explosive or radioactive. Despite high security standards, accidents still happen and the transportation of hazmat causes fear among the population. Therefore, the society expects authorities to distribute the risk fairly. To support such a fair distribution, we propose a new population-based risk definition that evaluates the risk for the population in any given area with respect to its multimodal transportation network. Moreover, we propose different objective functions for equilibrating the risk and extend the bilevel Hazmat Transport Network Design Problem by considering several transportation modes. In this problem, the government wants to equilibrate the risk among the population centers by restricting links to the shipment of hazardous goods. When taking that decision, the government has to anticipate the reaction of the carriers who want to minimize the transportation costs. This bilevel problem is transformed into a single-level mixed-integer linear program. The numerical results give insights to authorities (1) on how to evaluate risk for a fair distribution, and (2) that there is a positive convex relation between risk minimization and risk equilibration. The zones with high risk will initially benefit from the risk redistribution. However, pure equality just penalizes zones with low risk. Therefore, a significant improvement in risk distribution can be achieved at the cost of just a small increase in total risk. Moreover, compared to classical approaches in the literature, we achieve a better risk distribution among the population without increasing the total risk.},
  archive      = {J_EJOR},
  author       = {Pirmin Fontaine and Teodor Gabriel Crainic and Michel Gendreau and Stefan Minner},
  doi          = {10.1016/j.ejor.2019.12.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {188-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Population-based risk equilibration for the multimode hazmat transport network design problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Contract design for equipment after-sales service with
business interruption insurance. <em>EJOR</em>, <em>284</em>(1),
176–187. (<a href="https://doi.org/10.1016/j.ejor.2019.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {After-sales service is strategically important for mission-critical equipment due to the high operational risks involved (e.g., machine breakdowns). To address this challenge, the operators of such equipment often purchase business interruption (BI) insurance to mitigate operational risks. In this paper, we develop a principal-agent model to study an after-sales service contracting problem with an insurance option. Two prevailing contract forms are considered: a resource-based contract (RBC) and a performance-based contract (PBC). We first show that, in the presence of insurance, a PBC outperforms an RBC in terms of system performance due to the skewed incentives inherent in an RBC. More important, our results show that insurance plays contrasting roles in incentivizing a service supplier under the two contracting mechanisms. Under an RBC, insurance improves the service supplier’s effort provision and hence benefits the operator because insurance provides a risk-sharing mechanism that better aligns the incentives of the service supplier and the operator. Under a PBC, although the supplier’s equilibrium effort remains at the first-best level regardless of the insurance coverage level, the use of insurance changes the operator’s optimal contract and the risk allocation between the operator and the supplier. Our findings provide important insights into the interplay of insurance and contract incentives in an after-sales service context.},
  archive      = {J_EJOR},
  author       = {Xuwei Qin and Lusheng Shao and Zhong-Zhong Jiang},
  doi          = {10.1016/j.ejor.2019.12.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {176-187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Contract design for equipment after-sales service with business interruption insurance},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Operational level planning of a multi-item two-echelon spare
parts inventory system with reactive and proactive interventions.
<em>EJOR</em>, <em>284</em>(1), 164–175. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate operational spare parts planning in a multi-item two-echelon distribution system, taking into account real-time supply information in the system. We consider a broad range of operational interventions, either reactive (to solve a shortage) or proactive (to avoid a shortage). These interventions particularly include lateral transshipments between warehouses (local warehouses), emergency shipments from the depot (central warehouse), and doing nothing and waiting for pipeline inventory. We propose an integrated approach to determine the optimal timing and size of each intervention type to minimize the total downtime and shipment costs associated with interventions. Data from a leading original equipment manufacturer of high-tech systems is used to test the performance of our approach. We find that our integrated approach reduces total downtime considerably with a very limited increase in total shipment costs. Proactive emergency shipments contribute most to downtime reduction. The benefit of our approach is higher for high demand parts. Allowing complete pooling between warehouses increases downtime savings and usage of proactive emergency shipments even further. Our approach is efficient enough to solve practical size problems. We also propose a heuristic based on a greedy algorithm, which is well known in the literature. We find that the gap between the heuristic and the optimal solution is relatively large.},
  archive      = {J_EJOR},
  author       = {E. Topan and M.C. van der Heijden},
  doi          = {10.1016/j.ejor.2019.12.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {164-175},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operational level planning of a multi-item two-echelon spare parts inventory system with reactive and proactive interventions},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust global sourcing under compliance legislation.
<em>EJOR</em>, <em>284</em>(1), 152–163. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerns about the environment, public health, and safety are driving governments around the world to restrict access to their markets of products, which may present environmental/health risks. As a result, legislation in many countries requires that firms comply with specific environmental and safety standards before introducing their products in these markets. However, there is no unified global standard, and a set of local rules governs most of the markets. Therefore, products complying with the regulations of one market may not be compliant with the standards laid out in the other. This means that large firms must include the local regulatory requirements of their targeted markets into account when making their sourcing decisions. The rise in the enforcement of compliance legislation has overlapped with an increase in the trend of global sourcing, where manufacturers have opted for a diversified and offshore supplier base. With the issue of compliance legislation in place, the suppliers who otherwise would produce functionally identical products become differentiable based on their ability to fulfill compliance requirements of the targeted markets. Also, the suppliers have incentives to exaggerate their compliance ability or may lack the technical capability to ascertain this information completely. Therefore, there always resides a degree of uncertainty about a supplier’s actual compliance capability. On the market side, there is uncertainty concerning product demand in individual markets. These two sources of uncertainty make this a rather challenging problem. We propose a formulation of supplier selection and product allocation decisions in this problem based on a two-stage robust optimization method. Through a set of numerical experiments, we discuss some exciting insights about the role of uncertainty in compliance failure on overall profitability and flexibility in the supply chain. We show that 3\% supply-side uncertainty has almost the same effect on the quality of worst-case profit as 30\% deviation from the nominal demand.},
  archive      = {J_EJOR},
  author       = {Shumail Mazahir and Amir Ardestani-Jaafari},
  doi          = {10.1016/j.ejor.2019.12.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {152-163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust global sourcing under compliance legislation},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling and solving a bi-objective airport slot scheduling
problem. <em>EJOR</em>, <em>284</em>(1), 135–151. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strategic airport slot allocation problem concerns the scheduling of airlines’ requests for landings and take-offs at congested airports for a series of days within a given scheduling season. Relevant scheduling models dealing with the strategic airport slot allocation problem have employed various combinations of the total schedule displacement criterion with several variations of acceptability metrics. However, most variations of schedule displacement pursued in existing literature do not thoroughly capture the real-world scheduling practice, and, most importantly, do not guarantee the allocation of acceptable/tolerable or viable displacement among competing airlines’ slot requests. In this paper, we propose the formulation of the strategic airport slot allocation problem as a bi-objective resource constrained project scheduling problem with partially renewable resources and non-regular objective functions. We employ two non-regular performance criteria: (i) the total earliness-tardiness and (ii) a dispersion measure aiming to alleviate over-displaced requests. Α novel hybrid heuristic algorithm integrating the Objective Feasibility Pump (FP) algorithm with the Large Neighborhood Search technique (LNS) is proposed. We generate a set of new problem instances originating from the patterns of a data set of actual slot requests for a Greek Regional Airport (GRA) to assess the performance of the algorithm. The computational results indicate that the proposed algorithm is reasonably accurate, and it has the capability to approximate the entire efficient frontier of the problem.},
  archive      = {J_EJOR},
  author       = {Konstantinos N. Androutsopoulos and Eleftherios G. Manousakis and Michael A. Madas},
  doi          = {10.1016/j.ejor.2019.12.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {135-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling and solving a bi-objective airport slot scheduling problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spare parts or buffer? How to design a transfer line with
unreliable machines. <em>EJOR</em>, <em>284</em>(1), 121–134. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the design of a transfer line consisting of two unreliable machines in series and an interstage buffer. In addition to the buffer capacity, the system planner can decide on the inventory levels for spare parts in order to reduce the time to repair failed machines. Our work aims to find cost-efficient combinations of buffer capacity and spare parts inventory. We formulate discrete-time Markov chains for two different situations in order to analyse the trade-off between buffer capacity, spare parts inventory and throughput. By means of numerical examples, we illustrate that the effect of a spare part on the efficiency of a transfer line is much greater than the effect of additional buffer places. We conclude that it is necessary to optimize buffer capacity and spare parts inventory levels simultaneously. For systems with identical critical components, our results show that not only is there a pooling effect of safety stocks but also between the buffer places and spare parts inventory levels. We conclude that planners who select a standardised component for the system design and optimize spare parts levels as well as buffer capacity can significantly reduce costs or increase the throughput of a transfer line.},
  archive      = {J_EJOR},
  author       = {G.P. Kiesmüller and F.E. Sachs},
  doi          = {10.1016/j.ejor.2019.12.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {121-134},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Spare parts or buffer? how to design a transfer line with unreliable machines},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal inventory decisions for a risk-averse retailer when
offering layaway. <em>EJOR</em>, <em>284</em>(1), 108–120. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layaway allows economically disadvantaged budget-constrained consumers to purchase expensive items through amortized payments and nominal program fees, as opposed to using high-interest financing options such as credit cards and payday loans. We consider a risk-averse retailer’s ordering decisions when offering a layaway program. We use the net loss and total loss functions, found in the literature, to determine a risk-averse retailer’s optimal order quantity under conditional value-at-risk (CVaR). We next analyze the effects of the model parameters, retailer’s risk aversion, the market default rate, enrollment fee, cancellation fee and so on, on the optimal order quantity decisions. We show that the optimal order quantity depends on different loss functions and different demand distribution functions. Further, we show that as market default rate increases or the retailer becomes more risk averse, then a rational retailer will not offer a layaway program.},
  archive      = {J_EJOR},
  author       = {Daao Wang and Stanko Dimitrov and Lirong Jian},
  doi          = {10.1016/j.ejor.2019.12.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {108-120},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal inventory decisions for a risk-averse retailer when offering layaway},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The exact solutions of several types of container loading
problems. <em>EJOR</em>, <em>284</em>(1), 87–107. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address multiple container loading problems, consisting of placing rectangular boxes, orthogonally and without overlapping, inside containers in order to optimize a given objective function, generally maximizing the value of the packed boxes or minimizing the number of containers required to pack all available boxes. Four techniques to enumerate the possible locations of boxes inside a container, some of them not yet tested in the literature, are evaluated. We also propose new techniques to obtain primal and dual bounds for these problems. In addition, we study the constraints related to box orientation, load stability, and separation of boxes. Detailed analysis on well-known benchmark instances shows that our method is very competitive, generating mathematical models containing significantly fewer variables and constraints than the traditional approach existing in the literature. We test our methods on five different benchmark sets. We provide a detailed comparison with different approaches from the CLP literature, proving new optimal solutions and improving the best-known results for several instances.},
  archive      = {J_EJOR},
  author       = {Deidson Vitorio Kurpel and Cassius Tadeu Scarpin and José Eduardo Pécora Junior and Cleder Marcos Schenekemberg and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2019.12.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {87-107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The exact solutions of several types of container loading problems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid heuristic of variable neighbourhood descent and
great deluge algorithm for efficient task scheduling in grid computing.
<em>EJOR</em>, <em>284</em>(1), 75–86. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve the ultimate success of global collaborative resource sharing in Grid computing, an effective and efficient Grid resource management system is necessary and it is only possible if its core component, the scheduler, can perform scheduling in an efficient manner. Scheduling tasks to resources in Grid computing is a challenging task and known as a NP hard problem. In this paper, we propose a novel hybrid heuristic-based algorithm, which synergised the excellent diversification capability of Great Deluge (GD) algorithm with the powerful systematic multi-neighbourhood search strategy captured in Variable Neighbourhood Descent (VND) algorithm, to efficiently schedule independent tasks in Grid computing environment with an objective of minimising the makespan. Simulation experiments have been conducted to examine the impact of hybridising GD and VND. In addition, the performance of the proposed algorithm has been evaluated and compared with some other recent meta-heuristics in the literature. The experimental simulation results show that our proposed algorithm outperforms the other algorithms in the literature and the performance improvement achieved by this hybrid strategy is effective and efficient with respect to makespan and computational time as it can obtain good quality (makespan) of solutions while obviating the drawback of requiring high computational cost from the VND.},
  archive      = {J_EJOR},
  author       = {KaiLun Eng and Abdullah Muhammed and Mohamad Afendee Mohamed and Sazlinah Hasan},
  doi          = {10.1016/j.ejor.2019.12.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {75-86},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid heuristic of variable neighbourhood descent and great deluge algorithm for efficient task scheduling in grid computing},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully polynomial time approximation scheme to maximize early
work on parallel machines with common due date. <em>EJOR</em>,
<em>284</em>(1), 67–74. (<a
href="https://doi.org/10.1016/j.ejor.2019.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the scheduling problem on parallel identical machines in order to maximize the total early work, i.e. the parts of non-preemptive jobs executed before a common due date, and investigate mainly the model with a fixed number of machines, for which a dynamic programming approach and a fully polynomial time approximation scheme ( FPTAS ) are proposed. The proposal of these methods allowed us to establish the complexity and approximability status of this problem more exactly. Moreover, since our FPTAS can be also applied for the two-machine case, we improve considerably the result known in the literature for this model, in which a polynomial time approximation scheme ( PTAS ) was given. The new FPTAS has not only the best computational complexity, but also the much better approximation ratio than the PTAS . Finally, the theoretical studies are completed with computational experiments, performed for dynamic programming, PTAS and FPTAS , showing the high efficiencies of FPTAS both in terms of time consumption and solution quality.},
  archive      = {J_EJOR},
  author       = {Xin Chen and Yage Liang and Małgorzata Sterna and Wen Wang and Jacek Błażewicz},
  doi          = {10.1016/j.ejor.2019.12.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {67-74},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fully polynomial time approximation scheme to maximize early work on parallel machines with common due date},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extension of the non-inferior set estimation algorithm
for many objectives. <em>EJOR</em>, <em>284</em>(1), 53–66. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a novel multi-objective optimization approach that globally finds a representative non-inferior set of solutions, also known as Pareto-optimal solutions, by automatically formulating and solving a sequence of weighted sum method scalarization problems. The approach is called MONISE (Many-Objective NISE) because it represents an extension of the well-known non-inferior set estimation (NISE) algorithm, which was originally conceived to deal with two-dimensional objective spaces. The proposal is endowed with the following characteristics: (1) uses a mixed-integer linear programming formulation to operate in two or more dimensions, thus properly supporting many (i.e., three or more) objectives; (2) relies on an external algorithm to solve the weighted sum method scalarization problem to optimality; and (3) creates a faithful representation of the Pareto frontier in the case of convex problems, and a useful approximation of it in the non-convex case. Moreover, when dealing specifically with two objectives, some additional properties are portrayed for the estimated non-inferior set. Experimental results validate the proposal and indicate that MONISE is competitive, in convex and non-convex (combinatorial) problems, both in terms of computational cost and the overall quality of the non-inferior set, measured by the acquired hypervolume.},
  archive      = {J_EJOR},
  author       = {Marcos M. Raimundo and Paulo A.V. Ferreira and Fernando J. Von Zuben},
  doi          = {10.1016/j.ejor.2019.11.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {53-66},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An extension of the non-inferior set estimation algorithm for many objectives},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving oligopolistic equilibrium problems with convex
optimization. <em>EJOR</em>, <em>284</em>(1), 44–52. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approach of choice to analyze markets with oligopolistic competition has traditionally been complementarity modeling. In this paper we show that the majority of partial equilibrium models under imperfect competition in the (energy-)economic literature can in fact be cast as optimization models, not requiring the derivation and implementation of Karush–Kuhn–Tucker conditions. This is achieved by adding appropriate terms accounting for market power exertion to the well-known social welfare maximization objective. The method is applicable to both spatial Cournot oligopoly models and hybrid competition forms often implemented using conjectural variation approaches. We show how optimization and complementarity problems are equivalent, and provide a rationale for the terms accounting for market power exertion. Resulting models are solved orders of magnitude faster using off-the-shelf optimization software, compared to solving complementarity problems. Large problem instances take minutes rather than hours, and one instance solves 640 times faster. The drastically reduced solution times greatly enhance modeling capabilities as they allow increased geographical scope and represent economic, technical and other characteristics in much more detail in equilibrium problems with imperfect competition. We present practical implications for the partial and multi-level equilibrium modeling community.},
  archive      = {J_EJOR},
  author       = {Ruud Egging-Bratseth and Tobias Baltensperger and Asgeir Tomasgard},
  doi          = {10.1016/j.ejor.2020.01.025},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {44-52},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving oligopolistic equilibrium problems with convex optimization},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wasserstein distributionally robust shortest path problem.
<em>EJOR</em>, <em>284</em>(1), 31–43. (<a
href="https://doi.org/10.1016/j.ejor.2020.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a data-driven distributionally robust shortest path (DRSP) model where the distribution of the travel time in the transportation network can only be partially observed through a finite number of samples. Specifically, we aim to find an optimal path to minimize the worst-case α -reliable mean-excess travel time (METT) over a Wasserstein ball, which is centered at the empirical distribution of the sample dataset and the ball radius quantifies the level of its confidence. In sharp contrast to the existing DRSP models, our model is equivalently reformulated as a tractable mixed 0–1 convex problem, e.g., 0–1 linear program or 0–1 second-order cone program. Moreover, we also explicitly derive the distribution achieving the worst-case METT by simply perturbing each sample. Experiments demonstrate the advantages of our DRSP model in terms of the out-of-sample performance and computational complexity. Finally, our DRSP model is easily extended to solve the distributionally robust bi-criteria shortest path problem and the minimum cost flow problem.},
  archive      = {J_EJOR},
  author       = {Zhuolin Wang and Keyou You and Shiji Song and Yuli Zhang},
  doi          = {10.1016/j.ejor.2020.01.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {31-43},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Wasserstein distributionally robust shortest path problem},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate cutting plane approaches for exact solutions to
robust optimization problems. <em>EJOR</em>, <em>284</em>(1), 20–30. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we deal with cutting plane approaches for robust optimization. Such approaches work iteratively by solving a robust problem with reduced uncertainty set ( robustification step ) and determining a worst-case scenario in each iteration ( pessimization step ) which is then added to the reduced uncertainty set. We propose to enhance this scheme by solving the robustification and/or the pessimization step not exactly, but only approximately, that is, until an improvement to the current solution is possible. The resulting iterative approach is called approximate cutting plane approach. We prove that convergence to an optimal solution for approximate cutting plane approaches is still guaranteed under similar assumptions as for classical cutting plane approaches, in which both robustification and pessimization problem are solved exactly in each iteration. Experimentally, we investigate robust mixed integer linear optimization problems for mixed-integer polyhedral uncertainty sets of different difficulties. Solving the robustification or pessimization problem only approximately increases the number of iterations. Nevertheless, our results show that the approximate cutting plane approach becomes more efficient, in particular, if the robustification or the pessimization problem is hard.},
  archive      = {J_EJOR},
  author       = {Julius Pätzold and Anita Schöbel},
  doi          = {10.1016/j.ejor.2019.11.059},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {20-30},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Approximate cutting plane approaches for exact solutions to robust optimization problems},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prepositioning of assets and supplies in disaster operations
management: Review and research gap identification. <em>EJOR</em>,
<em>284</em>(1), 1–19. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prepositioning of assets and supplies prior to a disaster strike accelerates the response activities as it reduces the supply chain burden associated with humanitarian relief items. Unlike prior survey papers on pre-disaster and post-disaster humanitarian logistics, our paper has a specific focus on prepositioning of assets and supplies in the domain of natural disasters. The first aim of our paper is to review the main Operations Research and Management Science (OR/MS) journal papers published between 2000 and 2018 on this topic. We have statistically analyzed these papers based on contributions in different journals, number of papers per year, and type of disaster. We have also categorized the papers based on their decision variables into three categories: Allocation papers (“A”), Location papers (“L”), and Location-Allocation papers (“LA”). After that, we have assessed our current literature based on some of the methodological issues in Humanitarian Operations that gathered by Kovacs and Moshtari (2018). The second aim of our paper is research gap identification. Our key findings in this domain are that there is a lack of papers that: consider demand-side costs in their proposed model objectives; deal with uncertainty in funding, budget, asset and supply quantities, and infrastructure; considering prepositioning as a risk mitigation strategy; take reliability into account for reducing the risk of loss; consider prepositioning of medical staff and emergency crew; discuss the best time to start prepositioning of supplies and assets in confronting a foreseen disaster; use social media to better prepare for upcoming disasters.},
  archive      = {J_EJOR},
  author       = {Monir Sabbaghtorkan and Rajan Batta and Qing He},
  doi          = {10.1016/j.ejor.2019.06.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Prepositioning of assets and supplies in disaster operations management: Review and research gap identification},
  volume       = {284},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competitive difference analysis of the cash management
problem with uncertain demands. <em>EJOR</em>, <em>283</em>(3),
1183–1192. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cash management problem with uncertain demands belongs to the class of online problems which are free of any distribution assumptions. The demands can either be globally bounded or interrelated. We consider the performance measure competitive difference. This measure can be interpreted as maximum regret for online problems. The minimization of maximum regret is a major point of interest in the area of combinatorial optimization. We derive new algorithms which aim at minimizing the maximum regret incurred. Their experimental performance is compared to already established solutions, which consider the performance measure competitive ratio. From this comparison we confirm the practicability of our solutions for real-case scenarios. Hence, our algorithms are particularly relevant for risk averse cash managers, who are interested in minimizing their maximum regret while ensuring a solid performance in non-worst case scenarios.},
  archive      = {J_EJOR},
  author       = {Pascal Schroeder and Imed Kacem},
  doi          = {10.1016/j.ejor.2019.11.065},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1183-1192},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive difference analysis of the cash management problem with uncertain demands},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Firm-heterogeneous biased technological change: A
nonparametric approach under endogeneity. <em>EJOR</em>,
<em>283</em>(3), 1172–1182. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fully nonparametric framework to test to what extent technological change is factor-biased and heterogeneous. We show in a Monte Carlo simulation that our framework resolves the endogeneity issue between productivity and input choice and provides accurate estimates of firm-specific biases. For all Belgian manufacturing industries analyzed, we reject the predominant assumption of Hicks-neutral technological change over the period 1996–2015. We find that technological change is skill-biased, capital saving and domestic materials using. Moreover, we find significant heterogeneity in the pattern of technological change between and within industries. Relying on a rich dataset of firm characteristics, we provide robust indications that firm-level technological change can be attributed to specific firm strategies and technological characteristics.},
  archive      = {J_EJOR},
  author       = {Ruben Dewitte and Michel Dumont and Bruno Merlevede and Glenn Rayp and Marijn Verschelde},
  doi          = {10.1016/j.ejor.2019.11.063},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1172-1182},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Firm-heterogeneous biased technological change: A nonparametric approach under endogeneity},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural recovery of face value at default. <em>EJOR</em>,
<em>283</em>(3), 1148–1171. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We carefully study the transmission mechanisms from default-free rates to corporate bond prices within structural models of endogenous default risk. The transmission critically depends on whether the model is value-based or cashflow-based, on the assumptions made for the drift of the state variable, and on the way the residual value at default is shared among bondholders. The recovery assumption is crucial: Recovery of Face Value, which entails receiving the same share of residual value at default regardless of the remaining maturity, greatly helps explaining the empirical evidence on bond-price sensitivities to interest rates.},
  archive      = {J_EJOR},
  author       = {Rajiv Guha and Alessandro Sbuelz and Andrea Tarelli},
  doi          = {10.1016/j.ejor.2019.11.057},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1148-1171},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Structural recovery of face value at default},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A parametrized variational inequality approach to track the
solution set of a generalized nash equilibrium problem. <em>EJOR</em>,
<em>283</em>(3), 1136–1147. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a numerical method to describe the solution set of a generalized Nash equilibrium problem (GNEP). Previous approaches show how to reformulate the GNEP as a family of parametric variational inequalities in the special case where the game has shared constraints. We extend this result to generalized Nash problems by means of an umbrella shared constraint approximation of the game. We show the validity of our approach on numerical examples from the literature, and we provide new results that pinpoint the handling of the algorithm’s parameters for its implementation. Last but not least, we extend, solve, and discuss an applied example of a generalized Nash equilibrium problem of environmental accords between countries.},
  archive      = {J_EJOR},
  author       = {Tangi Migot and Monica-G. Cojocaru},
  doi          = {10.1016/j.ejor.2019.11.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1136-1147},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A parametrized variational inequality approach to track the solution set of a generalized nash equilibrium problem},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quality manipulation and limit corruption in competitive
procurement. <em>EJOR</em>, <em>283</em>(3), 1124–1135. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study competitive procurement administered by an agent who is supposed to evaluate bids on both price and quality by a scoring rule designed by the principal. Since the agent is in charge of verifying delivered quality, he has an opportunity to manipulate his evaluation of quality proposals in exchange for a bribe. In the presence of corruption, the optimal mechanism can be implemented by both first-score and second-score auctions in such a way that the scoring rule should deemphasize quality relative to price. We further identify factors that influence equilibrium corruption: (1) more efficient suppliers are willing to pay higher bribe; (2) the probability of corruption is decreasing in competition and increasing in the agent’s manipulation power; (3) compared to the first-score auction, the second-score auction leads to higher equilibrium bribe and thus is more vulnerable to corruption.},
  archive      = {J_EJOR},
  author       = {Hong Wang},
  doi          = {10.1016/j.ejor.2019.11.053},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1124-1135},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quality manipulation and limit corruption in competitive procurement},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heat and electricity market coordination: A scalable
complementarity approach. <em>EJOR</em>, <em>283</em>(3), 1107–1123. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large penetration of stochastic and non-dispatchable renewable energy sources increases the need for operational flexibility in power systems. Flexibility can be unlocked by aligning the existing interactions and synergies between heat and power systems. However, in the current sequential order of heat and electricity market clearings, the heat market is myopic to its interactions with the electricity market. This paper designs a heat market, aimed at achieving the optimal coordination of heat and power systems while respecting the current market regulations. The proposed electricity-aware heat market yields a soft coordination between heat and power systems by endogenously modeling their interactions in the day-ahead heat market clearing. The proposed market framework requires to solve a hierarchical optimization problem under uncertainty, which can be computationally challenging in large-scale energy systems with many scenarios. To resolve this potential scalability issue, this paper develops an augmented regularized Benders decomposition algorithm. The performance of the proposed market framework is compared against the fully integrated and sequential market frameworks using an ex-post out-of-sample simulation. This comparison reveals that there is a significant room for improvement in the cost-effective operation of the overall energy system. In particular, the proposed electricity-aware heat market framework provides a trade-off between the sequential and fully integrated market frameworks by significantly reducing the inefficiencies in both heat and electricity systems while respecting the current sequence of clearing heat and electricity markets.},
  archive      = {J_EJOR},
  author       = {Lesia Mitridati and Jalal Kazempour and Pierre Pinson},
  doi          = {10.1016/j.ejor.2019.11.072},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1107-1123},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heat and electricity market coordination: A scalable complementarity approach},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed oligopoly, cost-reducing research and development, and
privatisation. <em>EJOR</em>, <em>283</em>(3), 1094–1106. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a mixed oligopoly model to examine the role of R&amp;D subsidies and evaluate the welfare effects of privatisation. In solving the oligopoly model we propose a novel use of aggregative games techniques. Our analysis reveals that privatisation reduces the optimal R&amp;D subsidy. Furthermore, privatisation improves social welfare but only when the number of firms is sufficiently large. Implementing solely a subsidy to R&amp;D does not lead to a ‘privatisation neutrality theorem’ or ‘irrelevance result’.},
  archive      = {J_EJOR},
  author       = {Maria José Gil-Moltó and Joanna Poyago-Theotoky and José A. Rodrigues-Neto and Vasileios Zikos},
  doi          = {10.1016/j.ejor.2019.11.071},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1094-1106},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed oligopoly, cost-reducing research and development, and privatisation},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk management of renewable power producers from
co-dependencies in cash flows. <em>EJOR</em>, <em>283</em>(3),
1081–1093. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increasing adoption of renewable energy, which is inherently intermittent, poses several business risks for renewable energy producers. We identify the core co-dependencies of electricity demand, temperature and radiation risk exposures of a solar energy producer at different times of the year, which offer a valuable risk mitigation opportunity. By capturing the co-dependencies in a vector autoregressive, multivariate GARCH model, we investigate the extent of natural hedge embedded in the solar energy producer’s cash flows. We further develop the framework to use explicit optimal cross hedging strategies for risk mitigation using temperature-based weather derivatives. We find that there is significant benefit of natural hedge in certain months of the year, while in others, explicit hedges can effectively modify risk exposure.},
  archive      = {J_EJOR},
  author       = {Saptarshi Bhattacharya and Aparna Gupta and Koushik Kar and Abena Owusu},
  doi          = {10.1016/j.ejor.2019.11.069},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1081-1093},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Risk management of renewable power producers from co-dependencies in cash flows},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrating the ambulance dispatching and relocation
problems to maximize system’s preparedness. <em>EJOR</em>,
<em>283</em>(3), 1064–1080. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Emergency Medical Service (EMS) context, the decision-making process plays a very important role since some decisions highly impact patients’ health. This work focuses on the operational level by solving the dispatching and relocation ambulance problems. Dispatching decisions assign ambulances to emergencies and the relocation problem decides on the base to which available ambulances should be (re)assigned. To improve effectiveness and efficiency in the EMS response, integrated optimization approaches are proposed: a mathematical model and a pilot method heuristic. The aim is to maximize system’s coverage using a time-preparedness measure allowing relocations to any base. Experiments are performed using EMS data from Lisbon, Portugal, where solving these problems is still a handmade task. The optimization approaches are adapted to compare the proposed strategy with the current Portuguese EMS strategy which dispatches the closest available ambulance for each emergency and relocates ambulances to their home bases. Results highlight the potential of the mathematical model and of the proposed strategy to be applied in real-time contexts since key performance indicators (KPIs) are, in general, better than the ones obtained through the heuristic and the current Portuguese EMS strategy. The heuristic should be used when more emergencies occur in the same time period since a solution can be obtained almost immediately in contrast to the MIP usage.},
  archive      = {J_EJOR},
  author       = {A.S. Carvalho and M.E. Captivo and I. Marques},
  doi          = {10.1016/j.ejor.2019.11.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1064-1080},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrating the ambulance dispatching and relocation problems to maximize system’s preparedness},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Do charities spend more on their social programs when they
cooperate than when they compete? <em>EJOR</em>, <em>283</em>(3),
1055–1063. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two charities whose revenues are used on advertising to attract market share, on administrative expenditures to manage the charity, and on program expenditures. Assuming a finite planning horizon, we seek to answer the following research question: are there any circumstances under which the charities devote less funds to their programs when they cooperate than when they compete? We obtain that this may well be the case for some parameter values. In particular, if the charities are myopic, that is, if they disregard the future benefits they can earn after the current planning cycle, then they will always spend less on their social programs when they cooperate than when they do not.},
  archive      = {J_EJOR},
  author       = {Bertrand Crettez and Naila Hayek and Georges Zaccour},
  doi          = {10.1016/j.ejor.2019.11.044},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1055-1063},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Do charities spend more on their social programs when they cooperate than when they compete?},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-price heuristic for the crew pairing problem
with language constraints. <em>EJOR</em>, <em>283</em>(3), 1040–1054.
(<a href="https://doi.org/10.1016/j.ejor.2019.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In large commercial airlines, the monthly schedule (roster) of the crew members is usually determined by solving two problems sequentially, namely, the crew pairing problem (CPP) and the crew rostering problem (CRP). While the CPP finds a set of low-cost feasible anonymous pairings, the CRP assigns these pairings to the crew members to create a valid roster. The CRP often involves language constraints, which request language qualifications among the crew members operating some flights. In this case, the pairings returned by the CPP are not necessarily compatible with the qualifications of the available crew members, resulting in a large number of violated language constraints in the CRP. In this paper, we propose a new CPP variant, called the CPP with language constraints (CPPLC), that takes into account two types of soft language constraints that help producing more suitable pairings for satisfying the CRP language constraints. To solve the CPPLC, we develop a branch-and-price heuristic that includes an efficient partial pricing strategy for handling the large number of subproblems needed to model the language constraints. We also propose an acceleration technique to compute a high-quality (usually fractional) solution at the root node of the search tree. The proposed algorithm is tested on seven real-world datasets. We show that pairings produced by the CPPLC are better-suited for the CRP, resulting in a reduction of the number of violated CRP language constraints that varies between 61\% and 96\%, when compared to the pairings obtained from the traditional CPP.},
  archive      = {J_EJOR},
  author       = {Frédéric Quesnel and Guy Desaulniers and François Soumis},
  doi          = {10.1016/j.ejor.2019.11.043},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1040-1054},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-price heuristic for the crew pairing problem with language constraints},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing and product-bundling strategies for e-commerce
platforms with competition. <em>EJOR</em>, <em>283</em>(3), 1026–1039.
(<a href="https://doi.org/10.1016/j.ejor.2019.11.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider pricing and product-bundling strategies for two competing platforms with two groups of agents, customers and sellers (independent content developers). In this paper, two such groups are required to pay the platforms fixed (subscription) fees to gain access; each platform also produces its own integrated content. We investigate the impacts of installed base, mixed bundling, and competition on the platforms’ pricing and product-bundling strategies. We find that in the presence of both installed base and competition, each platform will charge sellers the same fee, regardless of whether the unbundling or mixed-bundling strategy is chosen. However, if the mixed-bundling strategy is used, the prices charged to customers may be higher relative to the unbundling equilibrium. Importantly, our results reveal that the mixed product-bundling strategy can be used as a strategic competitive tool for the competing platforms to seize more market share and induce the platforms to subsidize customers who buy the bundle by charging customers who only access the platforms (without bundling) a higher price. Moreover, we find that the proposed mixed product-bundling strategy is a dominant equilibrium solution for two competing platforms. We also show that under certain conditions, the mixed-bundling strategy can always bring larger value for both platforms if the intrinsic value of the integrated content (the fractions of the installed base) becomes smaller (higher) relative to the unbundling strategy. These results offer valuable implications for relevant practices.},
  archive      = {J_EJOR},
  author       = {Xiaogang Lin and Yong-Wu Zhou and Wei Xie and Yuanguang Zhong and Bin Cao},
  doi          = {10.1016/j.ejor.2019.11.066},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1026-1039},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing and product-bundling strategies for E-commerce platforms with competition},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Buyer’s optimal information revelation strategy in
procurement auctions. <em>EJOR</em>, <em>283</em>(3), 1011–1025. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a procurement auction where the buying firm can manipulate the distribution of the uncertainty facing competing suppliers via reducing subjectivity in the scoring rule announced before the auction, and we examine the optimal choice of information revelation for the buyer. Specifically, we model a multi-attribute scoring auction in which the suppliers submit bids involving both price and non-price attributes and the buyer selects one supplier according to a weighted scoring system. Although the scoring rule is preannounced and the buyer commits to it during the bid evaluation, it contains elements that are subjective in nature and not precisely defined, so the suppliers still do not have full information about the exact score that will be awarded. It may be possible for the buyer to reduce the subjective component in the scoring rule by giving unusually detailed descriptions of what corresponds to specific scores. We demonstrate that it is beneficial for the buyer to limit the information revealed by retaining some subjective or imprecisely defined components in the announced scoring rule, so that the suppliers continue to be uncertain about their final scores. It is also shown that the buyer can gain more from this type of imprecision (i.e., releasing less information) if the suppliers are more different in terms of their costs to achieve a given quality level or other aspects of utility for the buyer. We consider both sealed bid and open auction formats.},
  archive      = {J_EJOR},
  author       = {Cheng Qian and Edward Anderson},
  doi          = {10.1016/j.ejor.2019.11.061},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1011-1025},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Buyer’s optimal information revelation strategy in procurement auctions},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Allocating common costs of multinational companies based on
arm’s length principle and nash non-cooperative game. <em>EJOR</em>,
<em>283</em>(3), 1002–1010. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allocating common costs among the subsidiaries of multinational companies (MNCs) is widely conducted in practice. It is of paramount importance that optimal allocation plans can be developed. In this study, we propose an allocation method based on the arm&#39;s length principle (ALP), which is well accepted for the internal transactions between MNCs and subsidiaries. Unlike the available studies addressing efficiencies, this study considers profits in common cost allocation. We first deduce a general mathematical expression of the ALP for common cost allocation. Based on it, allocation models are developed, aiming to maximize the profits of both MNCs and subsidiaries. We further develop a solution approach including an algorithm based on the Nash non-cooperative game theory. We prove several interesting characteristics of the algorithm, including (i) the algorithm is convergent, (ii) the optimal solution is a Nash equilibrium and unique, and iii) the optimal solution is not affected by any initial allocation plan. The results of a case application highlight the applicability of our allocation method and solution approach. Through the study, we obtain several important practical insights, including (i) both the ALP and cooperate tax rates affect MNCs’ profit maximization, and (ii) subsidiaries’ profit maximization is affected by the ALP only.},
  archive      = {J_EJOR},
  author       = {Li Yongjun and Lin Lin and Dai Qianzhi and Zhang Linda},
  doi          = {10.1016/j.ejor.2019.11.049},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1002-1010},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Allocating common costs of multinational companies based on arm&#39;s length principle and nash non-cooperative game},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improvement of technical efficiency of firm groups.
<em>EJOR</em>, <em>283</em>(3), 991–1001. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation between firms can never improve the technical efficiency of any firm coalition. The directional distance function, by virtue of its additive nature, is a useful tool that outlines this impossibility. In this paper, the additive aggregation scheme of input/output vectors is generalized according to an aggregator. Accordingly, cooperation between firms may increase the technical efficiency of the firm group. This improvement is shown to be compatible with nonjoint semilattice technologies that bring out either output or input (weak) complementarity. Firm games are investigated to show that firms may merge on the basis of their inputs due to constraints imposed on outputs. Conversely, they may merge with respect to the outputs they can produce because of limitations imposed on inputs.},
  archive      = {J_EJOR},
  author       = {Walter Briec and Stéphane Mussard},
  doi          = {10.1016/j.ejor.2019.11.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {991-1001},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improvement of technical efficiency of firm groups},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Industrial and tramp ship routing problems: Closing the gap
for real-scale instances. <em>EJOR</em>, <em>283</em>(3), 972–990. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies in maritime logistics have introduced a general ship routing problem and a benchmark suite based on real shipping segments, considering pickups and deliveries, cargo selection, ship-dependent starting locations, travel times and costs, time windows, and incompatibility constraints, among other features. Together, these characteristics pose considerable challenges for exact and heuristic methods, and some cases with as few as 18 cargoes remain unsolved. To face this challenge, we propose an exact branch-and-price (B&amp;P) algorithm and a hybrid metaheuristic. Our exact method generates elementary routes, but exploits decremental state-space relaxation to speed up column generation, heuristic strong branching, as well as advanced preprocessing and route enumeration techniques. Our metaheuristic is a sophisticated extension of the unified hybrid genetic search. It exploits a set-partitioning phase and uses problem-tailored variation operators to efficiently handle all the problem characteristics. As shown in our experimental analyses, the B&amp;P optimally solves 239/240 existing instances within one hour. Scalability experiments on even larger problems demonstrate that it can optimally solve problems with around 60 ships and 200 cargoes (i.e., 400 pickup and delivery services) and find optimality gaps below 1.04\% on the largest cases with up to 260 cargoes. The hybrid metaheuristic outperforms all previous heuristics and produces near-optimal solutions within minutes. These results are noteworthy, since these instances are comparable in size with the largest problems routinely solved by shipping companies.},
  archive      = {J_EJOR},
  author       = {Gabriel Homsi and Rafael Martinelli and Thibaut Vidal and Kjetil Fagerholt},
  doi          = {10.1016/j.ejor.2019.11.068},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {972-990},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Industrial and tramp ship routing problems: Closing the gap for real-scale instances},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing pre-processing and relocation moves in the
stochastic container relocation problem. <em>EJOR</em>, <em>283</em>(3),
954–971. (<a href="https://doi.org/10.1016/j.ejor.2019.11.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In container terminals, containers are often moved to other stacks in order to access containers that need to leave the terminal earlier. We propose a new optimization model in which the containers can be moved in two different phases: a pre-processing and a relocation phase. To solve this problem, we develop an optimal branch-and-bound algorithm. Furthermore, we develop a local search heuristic because the problem is NP-hard. Besides that, we give a rule-based method to estimate the number of relocation moves in a bay. The local search heuristic produces solutions that are close to the optimal solution. Finally, for instances in which the benefits of moving containers in the two different phases are in balance, the solution of the heuristic yields significant improvement compared to the existing methods in which containers are only moved in one of the two phases.},
  archive      = {J_EJOR},
  author       = {Bernard G. Zweers and Sandjai Bhulai and Rob D. van der Mei},
  doi          = {10.1016/j.ejor.2019.11.067},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {954-971},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing pre-processing and relocation moves in the stochastic container relocation problem},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mean-variance analysis of the newsvendor problem with
price-dependent, isoelastic demand. <em>EJOR</em>, <em>283</em>(3),
942–953. (<a href="https://doi.org/10.1016/j.ejor.2019.11.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a mean-variance analysis of the single-product, single-period newsvendor problem with two decision variables, price and stock quantity. The demand is price-dependent, multiplicative, and isoelastic, and the product sold is price-elastic. The main goal of this paper is to completely characterize a framework where most risk sensitivities can be studied and find conditions under which the unimodality of this mean-variance performance measure is guaranteed. We aim at presenting these conditions in terms of a metric that can capture managerial attention. To this end we use the lost sales rate (LSR) elasticity, as it relates directly to the retailer’s level of service. The main contribution of this paper is that, with very few and mild assumptions, we complement currently existing results for the uniqueness of the solution in the presence of price-inelastic products by extending the applicability of the LSR elasticity to the problem with price-elastic goods and assess its unimodality when the decision maker is risk-neutral or risk-sensitive. Finally, we compare the results under this model with others previously obtained for additive demand models, and we emphasize the reasons that make it difficult to attain similar results with an isoelastic demand model.},
  archive      = {J_EJOR},
  author       = {Javier Rubio-Herrero and Melike Baykal-Gürsoy},
  doi          = {10.1016/j.ejor.2019.11.064},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {942-953},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mean-variance analysis of the newsvendor problem with price-dependent, isoelastic demand},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proprietary parts as a secondary market strategy.
<em>EJOR</em>, <em>283</em>(3), 929–941. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introducing proprietary parts to gain a competitive edge is a well-known, yet poorly understood strategy original equipment manufacturers (OEMs) adopt. In this paper, we consider an OEM who sells new products and competes with an independent remanufacturer (IR) selling remanufactured products. The OEM contemplates proprietary parts to manage the secondary market for remanufactured products. Thereby, the OEM designs its product to balance the trade-off between the cost of proprietariness and the extra income from selling the proprietary spare parts to the IR. Deterring market entry by the IR through prohibitively pricing the proprietary spare parts, an OEM strategy observed in several industries, is only optimal when the willingness-to-pay for remanufactured products is low. Otherwise, the OEM benefits more from sharing the secondary market profits with the IR through the use of proprietary parts. Finally, we find that the OEM can also use proprietary parts to strategically deter entry by the IR, discouraging her from collecting cores. This can support the OEM’s decisions to engage in remanufacturing even in the case of a collection cost disadvantage. While the introduction of proprietary parts is detrimental to both IRs and consumers, we show that for consumers such loss is reduced when the OEM engages in product remanufacturing.},
  archive      = {J_EJOR},
  author       = {Rainer Kleber and João Quariguasi Frota Neto and Marc Reimann},
  doi          = {10.1016/j.ejor.2019.11.062},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {929-941},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Proprietary parts as a secondary market strategy},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exact approach for cyclic inbound inventory routing in a
level production system. <em>EJOR</em>, <em>283</em>(3), 915–928. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an inbound inventory routing problem concerned with the minimal-cost collection of distinct components from a network of suppliers and subsequent delivery to a manufacturing plant. We assume known and constant production of end products at the plant that generates a synchronized production of components at each supplier. The lean production philosophy motivates two distinctive features of our formulation. To facilitate standardized work, we consider inventory collection plans that are cyclic and repeatable into the near future. To support the notion of level production planning, we consider inventory collection plans such that the pickup amount at each supplier is a multiple of the daily demand and in exact proportion to the number of days since the last pickup. We study the polyhedron of the convex hull of our mathematical formulation and define new valid inequalities that we implement within our branch-and-cut algorithm for the problem. As our computational experiments confirm, our cyclic formulation is significantly more difficult to solve to optimality than the standard non-cyclic formulation. Regardless, our three-phase approach obtains competitive results for one-, two-, and three-vehicle instances over three- and six-period planning horizons.},
  archive      = {J_EJOR},
  author       = {Luca Bertazzi and Demetrio Laganà and Jeffrey W. Ohlmann and Rosario Paradiso},
  doi          = {10.1016/j.ejor.2019.11.060},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {915-928},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact approach for cyclic inbound inventory routing in a level production system},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tax or subsidy? An analysis of environmental policies in
supply chains with retail competition. <em>EJOR</em>, <em>283</em>(3),
901–914. (<a href="https://doi.org/10.1016/j.ejor.2019.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the impact of two environmental policies: emissions abatement subsidy and emissions tax, on a three-tier supply chain where the manufacturer distributes through competitive retailers and invests in emissions abatement manufacturing technology. The government pursues social welfare maximization, while the manufacturer and retailers are profit driven. We find that the subsidy policy offers the manufacturer greater incentives to abate pollution and yields higher profits for channel members; however, when emissions abatement is very costly and production emissions are highly damaging, the tax policy should be implemented, as the subsidy policy leads to lower social welfare and environmental performance. Interestingly, we show that the manufacturer has no incentive to improve emissions abatement efficiency if the environmental damage of its production is high under the subsidy policy or low under the tax policy. The manufacturer always welcomes more downstream entry under the subsidy policy but not necessarily under the tax policy; each retailer always fares worse with more competition. More competition enhances social welfare under the tax policy but not necessarily under the subsidy policy. Furthermore, caution should be exercised when adopting the subsidy policy, because a “hazard zone” exists where society suffers but does not under the tax policy.},
  archive      = {J_EJOR},
  author       = {Junsong Bian and Zhao Xuan},
  doi          = {10.1016/j.ejor.2019.11.052},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {901-914},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Tax or subsidy? an analysis of environmental policies in supply chains with retail competition},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dual sourcing inventory model for modal split transport:
Structural properties and optimal solution. <em>EJOR</em>,
<em>283</em>(3), 883–900. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shifting freight volumes from road to rail transport increases the economic performances of freight logistics. However, compared to road transport, rail transport generally lacks the flexibility in delivery quantity and frequency, and exhibits economies of scale in its shipment volume. This often leads to high inventory levels in the destination after deliveries. We generalize the tailored base-surge dual sourcing inventory model by introducing a fixed cost in rail transport, adding an extra decision in its delivery frequency, and relaxing the assumption of the base stock control of road transport, to support firms’ modal split transport optimization. The objective is to optimize the controls of the two transport modes and the corresponding inventory management at the destination, which minimize the combined average transport and inventory costs per period in the steady state. Using stochastic dynamic programming, we find that when the delivery quantity and frequency of rail transport is fixed, the optimal shipment volume via the road transport indeed follows a base stock control. This allows to solve the relevant Bellman equation via an efficient policy iteration approach. We also find that the total cost is convex in the delivery quantity of rail transport, and a bi-section search can be applied. Finally, we analyze the sensitivity and robustness of our model using values suggested by a consumer goods firm.},
  archive      = {J_EJOR},
  author       = {Chuanwen Dong and Sandra Transchel},
  doi          = {10.1016/j.ejor.2019.11.050},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {883-900},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dual sourcing inventory model for modal split transport: Structural properties and optimal solution},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimally solving a versatile traveling salesman problem on
tree networks with soft due dates and multiple congestion scenarios.
<em>EJOR</em>, <em>283</em>(3), 863–882. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a versatile Traveling Salesman Problem (TSP) on tree networks with soft due date restrictions. Data unreliability is handled by introducing multiple congestion scenarios. The objective function sums up customizable monotonous cost assessments of the scenario-dependent total tardiness. Due to its generality, this covers a versatile application of different concepts including several robustness issues. Various complexity results are derived for the minimization of total tardiness: While the problem is proven to be at least binary N P NP -hard in all cases, strongly N P NP -hardness is shown if either the number of congestion scenarios or the number of roads are allowed to increase linearly with the number of requests. The same applies if non-zero unloading times occur. In order to efficiently solve the problem, a best-first Branch&amp;Bound approach is proposed that attains a pseudo-polynomial running time if none of the three aforementioned cases applies. The Branch&amp;Bound approach is evaluated by a computational study.},
  archive      = {J_EJOR},
  author       = {Stefan Bock},
  doi          = {10.1016/j.ejor.2019.11.058},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {863-882},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimally solving a versatile traveling salesman problem on tree networks with soft due dates and multiple congestion scenarios},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selecting algorithms for large berth allocation problems.
<em>EJOR</em>, <em>283</em>(3), 844–862. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers algorithm selection for the berth allocation problem (BAP) under algorithm runtime limits. BAP consists in scheduling ships on berths subject to ship ready times and size constraints, for a certain objective function. For the purposes of strategic port capacity planning, BAP must be solved many times in extensive simulations, needed to account for ship traffic and handling times uncertainties, and alternative terminal designs. The algorithm selection problem (ASP) consists in selecting algorithms with the best performance for a considered application. We propose a new method of selecting a portfolio of algorithms that will solve the considered BAP instances and return good solutions. The portfolio selection is based on the performance on the training instances. The performance is measured by the runtime and solution quality. In order to select the portfolio, a linear program minimizing the solution quality loss, subject to overall runtime limit is used. Thus, the portfolio evolves with the runtime limit, which is a key parameter in designing the port capacity simulations. For the training and validating datasets, random instances and real ship traffic logs are used. A portfolio of heuristics is developed which can be used for solving large instances of BAP, emerging when time horizons of months or years are considered. The evolution of the algorithm portfolios under changing runtime limits is studied. The portfolio abilities to solve new instances are assessed.},
  archive      = {J_EJOR},
  author       = {Jakub Wawrzyniak and Maciej Drozdowski and Éric Sanlaville},
  doi          = {10.1016/j.ejor.2019.11.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {844-862},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Selecting algorithms for large berth allocation problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Models and algorithms for the traveling salesman problem
with time-dependent service times. <em>EJOR</em>, <em>283</em>(3),
825–843. (<a href="https://doi.org/10.1016/j.ejor.2019.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesman Problem with Time-dependent Service times (TSP-TS) is a generalization of the Asymmetric TSP, in which the service time at each customer is given by a (linear or quadratic) function of the corresponding start time of service. TSP-TS calls for determining a Hamiltonian tour (i.e. a tour visiting each customer exactly once) that minimizes the total tour duration, given by the sum of travel and service times. We propose a new Mixed Integer Programming model for TSP-TS, that is enhanced by lower and upper bounds that improve previous bounds from the literature, and by incorporating exponentially many subtour elimination constraints, that are separated in a dynamic way. In addition, we develop a multi-operator genetic algorithm and two Branch-and-Cut methods, based on the proposed model. The algorithms are tested on benchmark symmetric instances from the literature, and compared with an existing approach. The computational results show that the proposed exact methods are able to prove the optimality of the solutions found for a larger set of instances in shorter computing times. We also tested the Branch-and-Cut algorithms on larger size symmetric instances with up to 58 nodes and on asymmetric instances with up to 45 nodes, demonstrating the effectiveness of the proposed algorithms. In addition, we tested the genetic algorithm on symmetric and asymmetric instances with up to 200 nodes.},
  archive      = {J_EJOR},
  author       = {Valentina Cacchiani and Carlos Contreras-Bolton and Paolo Toth},
  doi          = {10.1016/j.ejor.2019.11.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {825-843},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Models and algorithms for the traveling salesman problem with time-dependent service times},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact methods for mono-objective and bi-objective
multi-vehicle covering tour problems. <em>EJOR</em>, <em>283</em>(3),
812–824. (<a href="https://doi.org/10.1016/j.ejor.2019.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-vehicle Covering Tour Problem and the Bi-Objective Multi-vehicle Covering Tour Problem have been studied for more than thirty years. Both problems have several practical applications in industry. In this paper, we propose an effective exact method for the Multi-vehicle Covering Tour Problem based on column generation techniques. The effectiveness of the exact method is owed to tailored dominance rules and completion bounds. To validate our approach, we conducted extensive computational experiments on instances from literature. The comparison with state-of-the-art methods shows the effectiveness of the proposed method. In particular, seven open instances are closed to optimality for the first time, and the best lower bounds of the six open instances are improved. The exact method for the Multi-vehicle Covering Tour Problem is also embedded in a ϵ-constraint exact method to solve its bi-objective counterpart. Computational results show that the lower bound set provided by this bi-objective exact method is stronger than those provided by the state-of-the-art method from the literature.},
  archive      = {J_EJOR},
  author       = {Estèle Glize and Roberto Roberti and Nicolas Jozefowiez and Sandra Ulrich Ngueveu},
  doi          = {10.1016/j.ejor.2019.11.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {812-824},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact methods for mono-objective and bi-objective multi-vehicle covering tour problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of network interdiction models and algorithms.
<em>EJOR</em>, <em>283</em>(3), 797–811. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the development of interdiction optimization models and algorithms, with an emphasis on mathematical programming techniques and future research challenges in the field. After presenting basic interdiction concepts and notation, we recount the motivation and models behind founding research in the network interdiction field. Next, we examine some of the most common means of solving interdiction problems, focusing on dualization models and extended formulations solvable by row-generation techniques. We then examine contemporary interdiction problems involving incomplete information, information asymmetry, stochasticity, and dynamic play. We conclude by discussing several emerging applications in the field of network interdiction.},
  archive      = {J_EJOR},
  author       = {J. Cole Smith and Yongjia Song},
  doi          = {10.1016/j.ejor.2019.06.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {797-811},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A survey of network interdiction models and algorithms},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “a new method to solve the fully connected
reserve network design problem” [european journal of operational
research, 231(1), 2013, 202–209]. <em>EJOR</em>, <em>283</em>(2), 795.
(<a href="https://doi.org/10.1016/j.ejor.2019.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  author       = {Nahid Jafari and John Hearne},
  doi          = {10.1016/j.ejor.2019.12.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {795},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Corrigendum to ‘A new method to solve the fully connected reserve network design problem’ [European journal of operational research, 231(1), 2013, 202–209]},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Search for an immobile hider on a stochastic network.
<em>EJOR</em>, <em>283</em>(2), 783–794. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Harry hides on an edge of a graph and does not move from there. Sally, starting from a known origin, tries to find him as soon as she can. Harry’s goal is to be found as late as possible. At any given time, each edge of the graph is either active or inactive, independently of the other edges, with a known probability of being active. This situation can be modeled as a zero-sum two-person stochastic game. We show that the game has a value and we provide upper and lower bounds for this value. Finally, by generalizing optimal strategies of the deterministic case, we provide more refined results for trees and Eulerian graphs.},
  archive      = {J_EJOR},
  author       = {Tristan Garrec and Marco Scarsini},
  doi          = {10.1016/j.ejor.2019.11.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {783-794},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Search for an immobile hider on a stochastic network},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). VIX derivatives, hedging and vol-of-vol risk. <em>EJOR</em>,
<em>283</em>(2), 767–782. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the empirical hedging performance of alternative VIX option pricing models. Recent advances in the literature find evidence of asymmetric volatility-of-volatility (similar to the leverage effect in equity markets), stochastic mean-reversion and jumps. Using such findings in our model framework, we show that while sophisticated models have superior pricing performance and can explain a range of stylized facts in the VIX derivatives market, their hedging performance is inferior to a simple Black model hedge. We also study the empirical performance of regime-dependent hedge ratio adjustments commonly applied in equity markets.},
  archive      = {J_EJOR},
  author       = {Andreas Kaeck and Norman J. Seeger},
  doi          = {10.1016/j.ejor.2019.11.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {767-782},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {VIX derivatives, hedging and vol-of-vol risk},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Idiosyncratic risk, risk-taking incentives and the relation
between managerial ownership and firm value. <em>EJOR</em>,
<em>283</em>(2), 748–766. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addition to its well-documented alignment effect, managerial ownership can also have value-destroying effects by shifting risk to managers and encouraging risk-substitution; that is, managers with relatively unhedged personal portfolios tend to pass up profitable projects with high idiosyncratic (firm-specific) risk in favor of less-profitable projects that have greater aggregate (market) risk. Using parametric and semi-parametric estimation methods, we examine how managerial ownership influences firm value in light of the trade-off between the alignment and the risk-substitution effects. We find that risk-substitution offsets the alignment effect of managerial ownership in firms that are exposed to severe risk-substitution problems, leading to a weak (or non-existent) association between managerial ownership and firm value. We identify a plausible channel for these effects by showing that firms exposed to risk-substitution exhibit more “conservative” investment and financing policies. We also show that the risk-substitution problem is partially mitigated by the inclusion of stock options in managerial compensation packages. Finally, our findings suggest that semi-parametric methods may prove useful for future studies aiming at capturing nonlinear features in the data.},
  archive      = {J_EJOR},
  author       = {Chris Florackis and Angelos Kanas and Alexandros Kostakis and Sushil Sainani},
  doi          = {10.1016/j.ejor.2019.11.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {748-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Idiosyncratic risk, risk-taking incentives and the relation between managerial ownership and firm value},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Metafrontier productivity indices: Questioning the common
convexification strategy. <em>EJOR</em>, <em>283</em>(2), 737–747. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the construction of metafrontiers based on the union of underlying group frontiers normally yields a non-convex metaset, a large majority in the literature seems to assume that a convexification strategy leads to a reasonable convex approximation of this non-convex metafrontier. However, Kerstens, O’Donnell, and Van de Woestyne (2019) recently deliver new results on the union operator on technologies under a variety of assumptions and empirically illustrate that such a convexification strategy is doubtful. The purpose of this contribution is to verify to which extent such a convexification strategy is tenable when computing the Malmquist and Hicks–Moorsteen productivity indices with respect to a metafrontier. Furthermore, the differences between the Malmquist and Hicks–Moorsteen productivity indices are investigated at the metafrontier level. This existing methodology is empirically applied on a secondary data under a wide variety of assumptions: we explore balanced and unbalanced data as well as constant and variable returns to scale. Anticipating our key results, we provide statistical evidence on the potential bias arising from applying the convexification strategy for the metafrontier productivity indices.},
  archive      = {J_EJOR},
  author       = {Qianying Jin and Kristiaan Kerstens and Ignace Van de Woestyne},
  doi          = {10.1016/j.ejor.2019.11.019},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {737-747},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Metafrontier productivity indices: Questioning the common convexification strategy},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Plus–minus player ratings for soccer. <em>EJOR</em>,
<em>283</em>(2), 726–736. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents plus–minus ratings for use in association football (soccer). We first describe the general plus–minus methodology as used in basketball and ice-hockey and then adapt it for use in soccer. The usual goal-differential plus–minus is considered before two new variations are proposed. For the first variation, we present a methodology to calculate an expected goals plus–minus rating. The second variation makes use of in-play probabilities of match outcome to evaluate an expected points plus–minus rating. We use the ratings to examine who are the best players in European football, and demonstrate how the players’ ratings evolve over time. Finally, we shed light on the debate regarding which is the strongest league. The model suggests the English Premier League is the strongest, with the German Bundesliga a close runner-up.},
  archive      = {J_EJOR},
  author       = {Tarak Kharrat and Ian G. McHale and Javier López Peña},
  doi          = {10.1016/j.ejor.2019.11.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {726-736},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Plus–minus player ratings for soccer},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal influenza vaccine distribution with equity.
<em>EJOR</em>, <em>283</em>(2), 714–725. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the optimal influenza vaccine distribution in a heterogeneous population consisting of multiple subgroups. We employ a compartmental model for influenza transmission and formulate a mathematical program to minimize the number of vaccine doses distributed to effectively extinguish an emerging outbreak in its early stages. We propose an equity constraint to help public health authorities consider fairness when making vaccine distribution decisions. We develop an exact solution approach that generates a vaccine distribution policy with a solution quality guarantee. We perform sensitivity analyses on key epidemic parameters in order to illustrate the application of the proposed model. We then analyze the scalability of the solution approach for a population consisting of subgroups based on geographic location and age. We finally demonstrate the proposed model’s ability to consider vaccine coverage inequity and discuss a derivative-free optimization approach, as an alternative solution method which can consider various different objective functions and constraints. Our results indicate that consideration of group-specific transmission dynamics is paramount to the optimal distribution of influenza vaccines.},
  archive      = {J_EJOR},
  author       = {Shakiba Enayati and Osman Y. Özaltın},
  doi          = {10.1016/j.ejor.2019.11.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {714-725},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal influenza vaccine distribution with equity},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A gamma process based in-play prediction model for national
basketball association games. <em>EJOR</em>, <em>283</em>(2), 706–713.
(<a href="https://doi.org/10.1016/j.ejor.2019.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an in-play prediction model based on the gamma process for the scoring processes of the National Basketball Association matches. The model is team-specific, i.e. , it takes account of the relative strengths of the two teams playing in a match. The dependence between the home and away scoring processes is characterized by a common latent variable. A Bayesian dynamic forecasting procedure for future games is developed, which utilizes the in-match information to update the scale parameter of the model as the match progresses. An evaluation against baseline models is provided in an empirical study. Our proposed model can predict the final score and total points, while the baseline models are unable to make such predictions. Furthermore, our model can produce positive returns on the point spread betting market and the over-under betting market.},
  archive      = {J_EJOR},
  author       = {Kai Song and Jian Shi},
  doi          = {10.1016/j.ejor.2019.11.012},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {706-713},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A gamma process based in-play prediction model for national basketball association games},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the fuzzy maximal covering location problem.
<em>EJOR</em>, <em>283</em>(2), 692–705. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the maximal covering location problem, assuming imprecise knowledge of all data involved. The considered problem is modeled from a fuzzy perspective producing suitable fuzzy Pareto solutions. Some properties of the fuzzy model are studied, which validate the equivalent mixed-binary linear multiobjective formulation proposed. A solution algorithm is developed, based on the augmented weighted Tchebycheff method, which produces solutions of guaranteed Pareto optimality. The effectiveness of the algorithm has been tested with a series of computational experiments, whose numerical results are presented and analyzed.},
  archive      = {J_EJOR},
  author       = {Manuel Arana-Jiménez and Víctor Blanco and Elena Fernández},
  doi          = {10.1016/j.ejor.2019.11.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {692-705},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the fuzzy maximal covering location problem},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inroad into omni-channel retailing: Physical showroom
deployment of an online retailer. <em>EJOR</em>, <em>283</em>(2),
676–691. (<a href="https://doi.org/10.1016/j.ejor.2019.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of mobile E-commerce and omni-channel consumers has powered the pure-play online retailer&#39;s expansion towards omni-channel operations. In conjunction with the online selling channel, our research explores the retailer&#39;s deployment of physical showrooms which mitigates consumer fit uncertainty. Beyond asking whether the deployment of physical showrooms can improve the retailer&#39;s profit and which assortment strategy is more profitable for the retailer, our analysis also addresses the questions of how the showroom deployment strategy impacts the product prices and the information service provision. The main findings are threefold. First, the effect of physical showroom deployment on retailer&#39;s performance is determined by the showroom feasibility. A high level of showroom feasibility (i.e., relatively low setup cost and high proportion of local consumers) is more likely to increase the profit of the retailer who establishes physical showrooms, and vice versa. Second, the profitability of different assortment strategies is closely related to consumers’ showrooming behaviors (i.e., intra-product showrooming and inter-product showrooming). Whether or not the partial assortment strategy is more profitable than the full assortment strategy is determined by the intensity of consumer inter-product showrooming (or the weight of consumers’ valuation on the common attribute of different products). Third, our findings reveal that the expected return cost of pure-online shopping is critical to the retailer&#39;s omni-channel pricing and information service decisions. Our research provides implications for online retailers on how to benefit from offline information delivery and consumer showrooming behavior.},
  archive      = {J_EJOR},
  author       = {Li Gang and Zhang Tao and Giri Kumar Tayi},
  doi          = {10.1016/j.ejor.2019.11.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {676-691},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inroad into omni-channel retailing: Physical showroom deployment of an online retailer},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed cost allocation based on the principle of efficiency
invariance in two-stage systems. <em>EJOR</em>, <em>283</em>(2),
662–675. (<a href="https://doi.org/10.1016/j.ejor.2019.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fixed cost allocation among groups of entities is a prominent issue in numerous organisations. Addressing this issue has become one of the most important topics of the data envelopment analysis (DEA) methodology. In this study, we propose a fixed cost allocation approach for basic two-stage systems based on the principle of efficiency invariance and then extend it to general two-stage systems. Fixed cost allocation in cooperative and noncooperative scenarios are investigated to develop the related allocation plans for two-stage systems. The model of fixed cost allocation under the overall condition of efficiency invariance is first developed when the two stages have a cooperative relationship. Then, the model of fixed cost allocation under the divisional condition of efficiency invariance wherein the two stages have a noncooperative relationship is studied. Finally, the validation of the proposed approach is demonstrated by a real application of 24 nonlife insurance companies, in which a comparative analysis with other allocation approaches is included.},
  archive      = {J_EJOR},
  author       = {An Qingxian and Wang Ping and Ali Emrouznejad and Hu Junhua},
  doi          = {10.1016/j.ejor.2019.11.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {662-675},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fixed cost allocation based on the principle of efficiency invariance in two-stage systems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Response transformation and profit decomposition for revenue
uplift modeling. <em>EJOR</em>, <em>283</em>(2), 647–661. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uplift models support decision-making in marketing campaign planning. Estimating the causal effect of a marketing treatment, an uplift model facilitates targeting marketing actions to responsive customers and efficient allocation of marketing budget. Research into uplift models focuses on conversion models to maximize incremental sales. The paper introduces uplift models for maximizing incremental revenues. If customers differ in their spending behavior, revenue maximization is a more plausible business objective compared to maximizing conversions. The proposed methodology entails a transformation of the prediction target, customer-level revenues, that facilitates implementing a causal uplift model using standard machine learning algorithms. The distribution of campaign revenues is typically zero-inflated because of many non-buyers. Remedies to this modeling challenge are incorporated in the proposed revenue uplift strategies in the form of two-stage models. Empirical experiments using real-world e-commerce data confirm the merits of the proposed revenue uplift strategy over relevant alternatives, including uplift models for conversion and recently developed causal machine learning algorithms. To quantify the degree to which improved targeting decisions raise return on marketing, the paper develops a decomposition of campaign profit. Applying the decomposition to a digital coupon targeting campaign, the paper provides evidence that revenue uplift modeling, as well as causal machine learning, can improve campaign profit substantially.},
  archive      = {J_EJOR},
  author       = {Robin M. Gubela and Stefan Lessmann and Szymon Jaroszewicz},
  doi          = {10.1016/j.ejor.2019.11.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {647-661},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Response transformation and profit decomposition for revenue uplift modeling},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust university course timetabling problem subject to
single and multiple disruptions. <em>EJOR</em>, <em>283</em>(2),
630–646. (<a href="https://doi.org/10.1016/j.ejor.2019.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {University course timetables are often finalized in stages, in between which, changes in the data make the earlier version infeasible. As each version is announced to the community, it is desirable to have a robust initial timetable, i.e. one that can be repaired with limited number of changes and yielding a new solution whose quality is degraded as little as possible. We define two versions of the robust timetabling problem, first one assuming that only one lecture is disrupted (its scheduled period ceasing to be feasible) and the second one assuming multiple lectures are disrupted. The objective of the algorithms is to identify a good Pareto front defined by the solution quality (penalty associated with soft-constraint violations) and the robustness measure. Two versions of a multi-objective simulated annealing (MOSA) algorithm is developed (MOSA-SD and MOSA-SAA, for single and multiple disruptions, respectively), with the difference being in the way robustness of a solution is estimated within the MOSA algorithm. Extensive computational experiments done using the International Timetabling Competition ITC-2007 data set confirm that MOSA-SD outperforms a genetic algorithm from the literature, and MOSA-SAA outperforms MOSA-SD when there are multiple disruptions. For MOSA-SAA an innovative solution network to structure feasible solutions for a set of disruption scenarios has been developed to efficiently perform sample average approximation (SAA) calculations, which can be adopted for other stochastic combinatorial optimization problems.},
  archive      = {J_EJOR},
  author       = {Ayla Gülcü and Can Akkan},
  doi          = {10.1016/j.ejor.2019.11.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {630-646},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust university course timetabling problem subject to single and multiple disruptions},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analysis of the hypervolume sharpe-ratio indicator.
<em>EJOR</em>, <em>283</em>(2), 614–629. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Set-quality indicators have been used in Evolutionary Multiobjective Optimization Algorithms (EMOAs) to guide the search process. Recently, a new class of set-quality indicators combining the selection of solutions with fitness assignment has been proposed. This class is based on a formulation of fitness assignment as a Portfolio Selection Problem, where solutions are seen as assets whose returns are random variables, and fitness represents the investment in such assets/solutions. The Hypervolume Sharpe Ratio (HSR) Indicator is an instance of this class of indicators which has led to promising results as part of an EMOA denominated the Portfolio Optimization Selection Evolutionary Algorithm (POSEA). In this paper, the class of Sharpe-Ratio Indicators is formalized, and the HSR indicator is studied in regard to monotonicity, sensitivity to objective scaling, and dependence on its parameters. In addition, optimal μ -distributions on two-objective linear fronts, and the corresponding fitness assignments, are characterized. Such optimal μ -distributions turn out to be identical to those of the Hypervolume Indicator on the same fronts. Experimental results complement the analysis.},
  archive      = {J_EJOR},
  author       = {Andreia P. Guerreiro and Carlos M. Fonseca},
  doi          = {10.1016/j.ejor.2019.11.023},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {614-629},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An analysis of the hypervolume sharpe-ratio indicator},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic supply chain decisions under environmental
regulations: When to invest in end-of-pipe and green technology.
<em>EJOR</em>, <em>283</em>(2), 601–613. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the green technology and end-of-pipe abatement decisions of a multi-facility firm along with its facility size decisions. We utilize a model that captures three different environmental regulations: (1) emissions tax, (2) emissions permit-trading, and (3) command-and-control. Our results show that if the variable emissions tax, permit price or emissions penalty is nonzero, the firm should always invest in green technology emissions reductions. In general, we observe an all-or-nothing trend regarding end-of-pipe abatement investment. In particular, the firm invests in best available end-of-pipe abatement technology (BACT-EOP) when the variable emissions tax, permit price or emission penalty is greater than the per unit cost of end-of-pipe abatement. Moreover, we show that investments in end-of-pipe abatement can enhance investments in green technology, but that investments in end-of-pipe abatement should be pursued secondarily. Furthermore, we find that while the facility size, and consequently the local and global transportation emissions, are not impacted by an emissions tax regulation, facility size is impacted by an emissions permit trading or command-and-control emissions regulation. With regards to emissions, frequently there is a direct trade-off between local vs. global transportation and production emissions. To illustrate, we show that regulations that yield the lowest local production emissions, i.e. emissions from a single facility, do not always yield the lowest global production, and local and global transportation emissions. In fact, the conditions that yield the lowest local transportation emissions yield the largest global transportation emissions, and vice versa.},
  archive      = {J_EJOR},
  author       = {Nazli Turken and Janice Carrillo and Vedat Verter},
  doi          = {10.1016/j.ejor.2019.11.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {601-613},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic supply chain decisions under environmental regulations: When to invest in end-of-pipe and green technology},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Decomposition of slacks-based efficiency measures in
network data envelopment analysis. <em>EJOR</em>, <em>283</em>(2),
588–600. (<a href="https://doi.org/10.1016/j.ejor.2019.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One objective of the efficiency measurement of multi-division systems is to find the least efficient divisions such that making improvements to them will increase the efficiency of the system most effectively. To accomplish this task, it is desirable to find the relationship between the system and division efficiencies. This issue has been addressed for the radial efficiency measures. This paper explores the relationship for a non-radial efficiency measure known as the slacks-based measure. The idea is to transform the network system into an equivalent one that is composed of a series of subsystems with parallel structures. Based on the property that the system efficiency is the product of the division efficiencies adjusted by the linkage efficiencies for series systems and is a linear combination of the division efficiencies for parallel systems, the system efficiency can be decomposed into a function of the division and linkage efficiencies. The decomposition of the slacks-based efficiency measure works not only for the technology of constant returns to scale, but also for the case of variable returns to scale. In addition, the proposed model produces suitable efficiency scores for weakly efficient units and for those using weakly efficient units as the target to calculate efficiencies, which makes it possible to obtain reliable rankings for the assessed units.},
  archive      = {J_EJOR},
  author       = {Kao Chiang},
  doi          = {10.1016/j.ejor.2019.11.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {588-600},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decomposition of slacks-based efficiency measures in network data envelopment analysis},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal joint dynamic pricing, advertising and inventory
control model for perishable items with psychic stock effect.
<em>EJOR</em>, <em>283</em>(2), 576–587. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a joint pricing, advertising and inventory control problem will be investigated for a firm selling perishable products with psychic stock effect. The proposed problem is analyzed in the deterministic multi-period setting in which demand at each period depends on not only the amount of inventory displayed and advertising goodwill affected by the firm’s current and past advertising efforts but also selling price and freshness index. The objective is to determine the optimal pricing, advertising, and psychic stock strategies maximizing the discount total profit over the infinite planning horizon. Our theoretical results prove that the firm would adopt a static pricing strategy, and then demonstrate that the optimal paths of the advertising goodwill and psychic stock can be determined uniquely. We also show that the convergence of the advertising goodwill towards its equilibrium is from above or below, depending on the relative location of the initial stock of advertising goodwill with respect to the unique equilibrium stock of advertising goodwill. Moreover, a set of structural properties is developed to explore the relationships among the optimal decisions. Finally, the concluding remarks and suggestions will be provided for future studies.},
  archive      = {J_EJOR},
  author       = {Chung-Yuan Dye},
  doi          = {10.1016/j.ejor.2019.11.008},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {576-587},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal joint dynamic pricing, advertising and inventory control model for perishable items with psychic stock effect},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Comparison of fluid approximations for service systems with
state-dependent service rates and return probabilities. <em>EJOR</em>,
<em>283</em>(2), 562–575. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We compare two models of a multi-server queueing system with state-dependent service rates and return probabilities. In both models, upon completing service, customers are delayed prior to possibly returning to service. In one model, the determination of whether a customer will return occurs immediately upon service completion, at the beginning of the delay. In the other, that determination is made at the end of the delay, capturing the idea that it takes time for the customer’s condition and needs to evolve or assess, before it becomes known whether a return to service is needed. Our comparison focuses on fluid approximations of the two models. The fluid approximation for the first model, which has been studied previously, consists of a system of two ordinary differential equations. The fluid approximation for the second model, which is new, consists of a delay differential equation. We find that the two fluid approximations have the same set of equilibrium points, but their transient behavior can differ markedly. Both fluid approximations can exhibit bistability for certain parameter values. We use discrete event simulation to illustrate the extent to which the findings from the fluid approximations carry over to the underlying stochastic models.},
  archive      = {J_EJOR},
  author       = {Armann Ingolfsson and Eman Almehdawe and Ali Pedram and Monica Tran},
  doi          = {10.1016/j.ejor.2019.11.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {562-575},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Comparison of fluid approximations for service systems with state-dependent service rates and return probabilities},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributionally robust optimization approach for
outpatient colonoscopy scheduling. <em>EJOR</em>, <em>283</em>(2),
549–561. (<a href="https://doi.org/10.1016/j.ejor.2019.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the outpatient colonoscopy scheduling problem, recognizing the impact of pre-procedure bowel preparation ( prep ) quality on the variability in colonoscopy duration. Data from a large academic medical center indicates that colonoscopy durations are bimodal, i.e., depending on the prep quality they can follow two different probability distributions, one for those with adequate prep and the other for those with inadequate prep. We therefore define a distributionally robust outpatient colonoscopy scheduling (DROCS) problem that seeks optimal appointment sequence and schedule to minimize the worst-case weighted expected sum of patient waiting, provider idling, and provider overtime, where the worst-case is taken over an ambiguity set (a family of distributions) characterized through the known mean and support of the prep quality and durations. We derive an equivalent mixed-integer linear programming formulation to solve DROCS. Finally, we present a case study based on extensive numerical experiments in which we draw several managerial insights into colonoscopy scheduling.},
  archive      = {J_EJOR},
  author       = {Karmel S. Shehadeh and Amy E.M. Cohn and Ruiwei Jiang},
  doi          = {10.1016/j.ejor.2019.11.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {549-561},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A distributionally robust optimization approach for outpatient colonoscopy scheduling},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Retrieving a contingency table from a correspondence
analysis solution. <em>EJOR</em>, <em>283</em>(2), 541–548. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correspondence analysis (CA) is a dimension reduction technique for categorical data. In particular, CA is typically applied to a contingency matrix in order to visualize the relationships within and between the categories of the two variables as represented by its rows and columns. The CA solution can be obtained by considering a singular value decomposition of the so-called matrix of standardized residuals. Inverse correspondence analysis considers the problem of retrieving the data underlying a given low-dimensional CA solution. Using the specific structure of the CA solutions as well as the characteristics of the original data we formulate the inverse CA problem in an integer linear programming context. Considering various conditions involving the dimensions of the original data matrix, the number of observations, the precision and dimensionality of the CA solution, we show that by solving the integer linear programs, the original data can be retrieved.},
  archive      = {J_EJOR},
  author       = {Michel van de Velden and Wilco van den Heuvel and Hugo Galy and Patrick J.F. Groenen},
  doi          = {10.1016/j.ejor.2019.11.014},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {541-548},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Retrieving a contingency table from a correspondence analysis solution},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Where in the supply chain network does ISO 9001 improve firm
productivity? <em>EJOR</em>, <em>283</em>(2), 530–540. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations management scholars have long suggested that processes play a critical role in a firm&#39;s competitive advantage. ISO 9001, in particular, provides a standard to improve the effectiveness and efficiency of processes. Similarly, network researchers argue that a firm&#39;s embedded position in the network plays a critical role in their competitiveness. Taking a network perspective, this research investigates if the productivity benefits of ISO 9001 depend, in part, on the network topology that connects the firm to their network partners. Using customer disclosure data from COMPUSTAT and ISO 9001, this study finds that network closure, industry homophily, and network centrality each moderate the effect of ISO 9001 on firm productivity. We find that ISO 9001 is more effective when firms are well embedded in the supply chain network and least effective when they are isolated . The overall results provide managers guidance on the strategic benefit of network position with regards to ISO 9001 effectiveness.},
  archive      = {J_EJOR},
  author       = {Su Hung-Chung and Kao Ta-Wei (Daniel) and Kevin Linderman},
  doi          = {10.1016/j.ejor.2019.11.042},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {530-540},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Where in the supply chain network does ISO 9001 improve firm productivity?},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formulations, branch-and-cut and a hybrid heuristic
algorithm for an inventory routing problem with perishable products.
<em>EJOR</em>, <em>283</em>(2), 511–529. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an inventory routing problem in which goods are perishable. In this problem, a single supplier is responsible for delivering a perishable product to a set of customers during a given finite planning horizon. The product is assumed to have a fixed shelf-life during which it is usable and after which it must be discarded. We introduce four mathematical formulations for the problem, two with a vehicle index and two without a vehicle index, and propose branch-and-cut algorithms to solve them. In addition, we propose a hybrid heuristic based on the combination of an iterated local search metaheuristic and two mathematical programming components. We present the results of extensive computational experiments using instances from the literature as well as new larger instances. The results show the different advantages of the introduced formulations and show that the hybrid method is able to provide high-quality solutions in relatively short running times for small- and medium-sized instances while good quality solutions are found within reasonable running times for larger instances. We also adapted the proposed hybrid heuristic to solve the basic variant of the inventory routing problem. The results using standard instances show that our heuristic is also able to find good quality solutions for this problem when compared to the state-of-the-art methods from the literature.},
  archive      = {J_EJOR},
  author       = {Aldair Alvarez and Jean-François Cordeau and Raf Jans and Pedro Munari and Reinaldo Morabito},
  doi          = {10.1016/j.ejor.2019.11.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {511-529},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Formulations, branch-and-cut and a hybrid heuristic algorithm for an inventory routing problem with perishable products},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic and steady-state performance analysis for
multi-state repairable reconfigurable manufacturing systems with
buffers. <em>EJOR</em>, <em>283</em>(2), 491–510. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconfigurable manufacturing systems (RMSs) are considered the solution of choice when variable production capacity and functionality are required. A combinational approach, which integrates the steady-state probabilities of repairable reconfigurable machine tools (RMTs) and inventory-state probabilities of buffers through an improved universal generating function, is introduced in this study to assess the compound performance indicators (CPIs) of a repairable RMS. This paper contributes to the existing literature by considering the availability of buffers to calculate the CPIs of an RMS. In the proposed approach, the dynamic-state probability for each RMT is determined with a homogeneous continuous-time Markov model, and steady-state probability is obtained as the limit of the dynamic probability as time tends to infinity. In addition, a descriptive input-output information flow, which combines the conveying processes of the machined parts through buffers with the Poisson process, is proposed to determine the inventory-state probabilities of the buffers. Moreover, the explicit expressions of the CPI and expected performance rate (for the RMS and its constituent RMTs) are determined, and the validation procedure and technical details of the performance analysis for the Monte Carlo simulation are presented. Finally, a non-serial, repairable, multi-state RMS with multiple buffers that produces three types of engine cylinder heads is presented to validate the proposed approach. The simulation results verify the accuracy of the performance assessment of the RMS. It is useful for performance improvement in terms of machine reliability, resource utilisation efficiency, and decision-making concerning the configuration of RMS with buffers.},
  archive      = {J_EJOR},
  author       = {Yongjin Zhang and Ming Zhao and Yanjun Zhang and Ruilin Pan and Jing Cai},
  doi          = {10.1016/j.ejor.2019.11.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {491-510},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic and steady-state performance analysis for multi-state repairable reconfigurable manufacturing systems with buffers},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On carriers collaboration in hub location problems.
<em>EJOR</em>, <em>283</em>(2), 476–490. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a hub location problem where several carriers operate on a shared network to satisfy a given demand represented by a set of commodities. Possible cooperative strategies are studied where carriers can share resources or swap their respective commodities to produce tangible cost savings while fully satisfying the existing demand. Three different collaborative policies are introduced and discussed, and mixed integer programming formulations are provided for each of them. Theoretical analyses are developed in order to assess the potential savings of each model with respect to traditional non-collaborative approaches. An empirical performance comparison on state-of-art sets of instances offers a complementary viewpoint. The influence of several diverse problem parameters on the performance is analyzed to identify those operational settings enabling the highest possible savings for the considered collaborative hub location models. The number of carriers and the number of open hubs have shown to play a key role; depending on the collaborative strategy, savings of up to 50\% can be obtained as the number of carriers increases or the number of open hubs decreases.},
  archive      = {J_EJOR},
  author       = {Elena Fernández and Antonino Sgalambro},
  doi          = {10.1016/j.ejor.2019.11.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {476-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On carriers collaboration in hub location problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Detecting a most closeness-central clique in complex
networks. <em>EJOR</em>, <em>283</em>(2), 461–475. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Centrality is a powerful concept for detecting influential components of a network applicable to various areas such as analysis of social, collaboration, and biological networks. In this study, we employ one of the well-known centrality measures, closeness centrality, to detect a group of pairwise connected members (a highly connected community known as a clique) with the highest accessibility to the entire network. To measure the accessibility of a clique, we use two metrics, the maximum distance and the total distance to the clique from other members of the network. Hence, we are dealing with two variants of the most central clique problem referred to as maximum-distance-closeness-central clique and total-distance-closeness-central clique problems. We study the computational complexity of these two problems and prove that their decision versions are NP-complete. We also propose new mixed 0–1 integer programming formulations and the first combinatorial branch-and-bound algorithms to solve these problems exactly. We show that our algorithmic approaches offer at least 83-fold speed-up on over 96\% of benchmark instances in comparison to existing approaches.},
  archive      = {J_EJOR},
  author       = {Farzaneh Nasirian and Foad Mahdavi Pajouh and Balabhaskar Balasundaram},
  doi          = {10.1016/j.ejor.2019.11.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {461-475},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Detecting a most closeness-central clique in complex networks},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective optimisation in flexible assembly job shop
scheduling using a distributed ant colony system. <em>EJOR</em>,
<em>283</em>(2), 441–460. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the production scheduling problem in a flexible manufacturing system with two adjacent working areas, whose products are incorporated with flexible non-linear process plans and assembling operations. The basic parts are produced in one area before they are transported to the other area for assembly. The assembling structures of products are either flat or multi-levelled. Sequence-dependent setup times of operations and transition times of jobs between machines are considered separately from processing times. Lot streaming is considered beforehand such that each job represents a basic part instead of a batch of identical parts. Identical subassemblies are shared by all possible assembling operations, instead of being pre-associated with any product. Makespan, total tardiness and total workload are taken as objectives to be optimised. We propose a distributed ant colony system to solve the problem and explore the Pareto front. The approach is first compared with other methods, using several sets of hypothetical test cases with different sizes and complexities; then, it is applied to solve a ball valve production scheduling problem under different scenarios. We show that the proposed approach outperforms most of the other methods for the tested problems, especially for large-scale instances, making it a valuable and competitive approach for solving practical production scheduling problems.},
  archive      = {J_EJOR},
  author       = {Sicheng Zhang and Xiang Li and Bowen Zhang and Shouyang Wang},
  doi          = {10.1016/j.ejor.2019.11.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {441-460},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-objective optimisation in flexible assembly job shop scheduling using a distributed ant colony system},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A greedy randomized adaptive search procedure for the
orienteering problem with hotel selection. <em>EJOR</em>,
<em>283</em>(2), 426–440. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Orienteering Problem with Hotel Selection (OPHS) is one of the most recent variants of the Orienteering Problem (OP). The sequence of hotels has a significant effect on the quality of the OPHS solutions. According to prior studies, it is not efficient to consider all feasible sequences of hotels for constructing a tour. For this reason, solution methods for this problem should be independent of the Total Number of Feasible Sequences of hotels (TNFS). This paper proposes a novel approach based on a well-known metaheuristic called Greedy Randomized Adaptive Search Procedure (GRASP) to tackle the OPHS. In the previously introduced algorithms for this problem, the OP solutions among all feasible pairs of hotels are considered to construct a proper sequence of hotels. Our suggested GRASP algorithm does not follow this policy; instead, it uses a novel, potent, and fast dynamic programming method for hotel selection. This dynamic idea makes the introduced GRASP approach independent of the TNFS and solving the OPs. Considering 400 benchmark instances with and five instances without known optimal values, the proposed method in this article obtains the optimal solutions for 231 instances (57.75\%), as opposed to 174 instances (43.5\%) for the best formerly suggested algorithm. GRASP constructs better tours than the state-of-the-art algorithm for 142 instances (35.5\%) and finds new best results for three out of five instances with unknown optimal values. Moreover, GRASP can produce high quality solutions for 76 new large instances constructed using the instances of a similar problem to the OPHS.},
  archive      = {J_EJOR},
  author       = {Somayeh Sohrabi and Koorush Ziarati and Morteza Keshtkaran},
  doi          = {10.1016/j.ejor.2019.11.010},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {426-440},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A greedy randomized adaptive search procedure for the orienteering problem with hotel selection},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Railway crew scheduling: Models, methods and applications.
<em>EJOR</em>, <em>283</em>(2), 405–425. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The railway crew scheduling problem consists of finding the most efficient duty combination for railway crews to cover all trains and related activities for a defined period of time. Crew scheduling problems in transportation originate in airline and bus industries. In the 1990s, researchers developed sophisticated algorithms which were capable of solving the larger and more complex problem instances of railway operators. Practical implementations and decision support tools received very satisfying feedback from the industry. Since then, numerous real-world problems have been studied requiring innovative algorithmic approaches to the NP-hard problem. In this paper, we review 123 articles on railway crew scheduling focusing on more recent publications since 2000. After depicting crew scheduling in railway including the differences between transportation modes, our goal is to classify the literature according to model formulations, objectives, constraints and solution methods. By systematizing the collected articles, we identify research opportunities including integrated approaches with other planning stages, real-time re-scheduling and a further investigation of the impact of robustness and employee satisfaction on the cost of railway crew schedules.},
  archive      = {J_EJOR},
  author       = {Julia Heil and Kirsten Hoffmann and Udo Buscher},
  doi          = {10.1016/j.ejor.2019.06.016},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {405-425},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Railway crew scheduling: Models, methods and applications},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nurse scheduling with quick-response methods: Improving
hospital performance, nurse workload, and patient experience.
<em>EJOR</em>, <em>283</em>(1), 390–403. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hospitals continue to face the challenge of providing high-quality patient care in an environment of rising healthcare costs. In response, a great deal of attention has been given to advance planning decisions such as nurse staffing, bed mix, scheduling, and patient flow. However, less attention has been given to incorporating quick-response methods in the nurse scheduling process by both anticipating and responding to patient demand fluctuations. Therefore, in this paper, we present a model that incorporates two classes of quick-response decisions in hospitals’ nurse scheduling: (i) adjustments to the unit assignments of cross-trained float nurses and (ii) transfers of patients between units and off-unit admissions. Analyzing three hospitals that are subject to different regulations with respect to patient-to-nurse ratios allows us to draw conclusions on how these hotly debated ratios impact hospital performance, nurse workload, and patient experience. We find that quick-response via cross-trained nurses may lead to higher total costs in settings where an upper limit on patient-to-nurse ratios is enforced. This result has significant managerial and political relevance in locations such as California. Another takeaway is that only a small number of patient transfers or off-unit admissions provides close to the full potential benefit, thus minimizing the negative impact on patient satisfaction and quality of care. Moreover, our proposed scheduling approach reduces the number of undesired assigned shifts. Finally, bed and nurse capacity utilization are shown to be important considerations when determining how and whether to use quick-response methods.},
  archive      = {J_EJOR},
  author       = {Jan Schoenfelder and Kurt M. Bretthauer and P. Daniel Wright and Edwin Coe},
  doi          = {10.1016/j.ejor.2019.10.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {390-403},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nurse scheduling with quick-response methods: Improving hospital performance, nurse workload, and patient experience},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coordination contract design for the newsvendor model.
<em>EJOR</em>, <em>283</em>(1), 380–389. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design contracts to coordinate the newsvendor setting with a supplier and a retailer. Traditional approaches begin with a restricted set of contracts. However, we design mechanisms in a more general way by directly constructing payment schemes to satisfy incentive-compatibility and individual-rationality. Under symmetric information, coordinating contracts in the literature can be interpreted by this method. Under asymmetric information, we model the retailer’s private demand information as a space of either continuous or discrete states. In the continuous case, wholesale price contracts cause system inefficiency and there exists a unique optimal wholesale price for the supplier if the distribution of forecast error has IFR (Increasing Failure Rate) property. We further characterize the structure of coordinating payment, and find that the set of coordinating contracts is restricted to special two-part tariffs where wholesale price equals unit production cost. In the discrete case, contrary to expectation, linear wholesale price contracts achieve coordination. With demand forecast distributed more and more densely on its support, the interval of coordinating wholesale prices gradually shrinks to the unit production cost.},
  archive      = {J_EJOR},
  author       = {Linqiu Li and Ke Liu},
  doi          = {10.1016/j.ejor.2019.10.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {380-389},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordination contract design for the newsvendor model},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Electric vehicle battery capacity allocation and recycling
with downstream competition. <em>EJOR</em>, <em>283</em>(1), 365–379.
(<a href="https://doi.org/10.1016/j.ejor.2019.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the optimal channel choice and battery capacity allocation strategies of an electric vehicle (EV) manufacturer in the presence of battery recycling. The EV manufacturer also produces EV batteries. As an upstream manufacturer, this firm has the option to supply batteries to its competitor, a downstream EV manufacturer which is unable to produce batteries. We characterise the equilibrium decisions of the two EV manufacturers under different channel structures. One finding is that the optimal channel choice of each EV manufacturer depends on the procurement cost from an external battery supplier. If the procurement cost is moderate , the downstream manufacturer prefers to order from the upstream manufacturer and the upstream manufacturer will supply batteries to satisfy the order. In addition, we investigate the effects of key parameters on the equilibrium capacity allocation decisions and manufacturers’ profits using numerical experiments. We also show that to maximise social welfare, the upstream EV manufacturer should not supply batteries to its competitor if the procurement cost from the external supplier is low, which is contrary to the case of profit maximisation.},
  archive      = {J_EJOR},
  author       = {Mengping Zhu and Zhixue Liu and Jianbin Li and Stuart X. Zhu},
  doi          = {10.1016/j.ejor.2019.10.040},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {365-379},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Electric vehicle battery capacity allocation and recycling with downstream competition},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inference in the spatial autoregressive efficiency model
with an application to dutch dairy farms. <em>EJOR</em>,
<em>283</em>(1), 356–364. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article extends the conventional spatial autoregressive efficiency model by including firm characteristics that may impact efficiency. This extension allows performing the typical inference in spatial autoregressive models that involves the derivation of direct and indirect marginal effects, with the latter revealing the nature and magnitude of spatial spillovers. Furthermore, this study accounts for the endogeneity of the spatial autoregressive efficiency model using a lag spatial lag efficiency component, which makes inference to be performed in a long-run framework. The case study concerns specialized Dutch dairy farms observed over the period 2009–2016 and for which exact geographical coordinates of latitude and longitude are available. The results reveal that the efficiency scores are spatially dependent. The derived marginal effects further suggest that farmers’ long-run efficiency is driven by changes in both their own and their neighbors’ characteristics, highlighting the existence of motivation and learning domino effects between neighboring producers.},
  archive      = {J_EJOR},
  author       = {Ioannis Skevas},
  doi          = {10.1016/j.ejor.2019.10.033},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {356-364},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inference in the spatial autoregressive efficiency model with an application to dutch dairy farms},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New conditions for testing necessarily/possibly efficiency
of non-degenerate basic solutions based on the tolerance approach.
<em>EJOR</em>, <em>283</em>(1), 341–355. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a specific type of multiobjective linear programming problem with interval objective function coefficients is studied. Usually, in such problems, it is not possible to obtain an optimal solution which optimizes simultaneously all objective functions in the interval multiobjective linear programming (IMOLP) problem, requiring the selection of a compromise solution. In conventional multiobjective programming problems these compromise solutions are called efficient solutions. However, the efficiency cannot be defined in a unique way in IMOLP problems. Necessary efficiency and possible efficiency have been considered as two natural extensions of efficiency to IMOLP problems. In this case, necessarily efficient solutions may not exist and the set of possibly efficient solutions usually has an infinite number of elements. Furthermore, it has been concluded that the problem of checking necessary efficiency is co-NP-complete even for the case of only one objective function. In this paper, we explore new conditions for testing necessarily/possibly efficiency of basic non-degenerate solutions in IMOLP problems. We show properties of the necessarily efficient solutions in connection with possibly and necessarily optimal solutions to the related single objective problems. Moreover, we utilize the tolerance approach and sensitivity analysis for testing the necessary efficiency. Finally, based on the new conditions, a procedure to obtain some necessarily efficient and strictly possibly efficient solutions to multiobjective problems with interval objective functions is suggested.},
  archive      = {J_EJOR},
  author       = {C.O. Henriques and M. Inuiguchi and M. Luque and J.R. Figueira},
  doi          = {10.1016/j.ejor.2019.11.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {341-355},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {New conditions for testing necessarily/possibly efficiency of non-degenerate basic solutions based on the tolerance approach},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stakeholder identification and engagement in problem
structuring interventions. <em>EJOR</em>, <em>283</em>(1), 321–340. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the under-researched issue of stakeholder identification and engagement in problem structuring interventions. A concise framework is proposed to aid critical reflection in the design and reporting of stakeholder identification and engagement. This is grounded in a critical-systemic epistemology, and is informed by social identity theory. We illustrate the utility of the framework with an example of a problem structuring workshop, which was part of a green innovation project on the development of a technology for the recovery of rare metals from steel slag. The workshop was initially going to be designed to surface stakeholder views on the technology itself. However, it became apparent that a range of other strategic issues concerning the future of the site were going to impact on decision making about the use of steel slag. It therefore became important to evolve the agenda for the problem structuring, and this is where the critical-systemic approach made a difference. It enabled the workshop to be reframed as a community-based event looking at how the former steelworks site could be developed for new purposes. Evaluation of this problem structuring intervention revealed significant stakeholder learning about the issues needing to be accounted for, and a range of possible options for the development of the steelworks site were explored. The paper ends with a discussion of the utility of social identity theory for understanding the processes and outcomes of the workshop, and reflections are provided on its implications for operational research practice more generally.},
  archive      = {J_EJOR},
  author       = {Amanda J. Gregory and Jonathan P. Atkins and Gerald Midgley and Anthony M. Hodgson},
  doi          = {10.1016/j.ejor.2019.10.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {321-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stakeholder identification and engagement in problem structuring interventions},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Necessary and possible interaction between criteria in a
2-additive choquet integral model. <em>EJOR</em>, <em>283</em>(1),
308–320. (<a href="https://doi.org/10.1016/j.ejor.2019.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the interpretation of the 2-additive Choquet integral model in the context of Multiple Criteria Decision Making. When the set of alternatives is discrete, using classical interaction indices proposed in the literature may lead to interpretations that are not robust. Indeed, the sign of these indices may depend upon the arbitrary choice of a numerical representation within the set of all possible numerical representations. We tackle this problem in two ways. First, in the context of binary alternatives, we characterize the preference relations for which the problem does not occur. Outside the framework of binary alternatives, we propose a simple linear programming model allowing one to test for robust conclusions concerning the sign of interaction indices. We illustrate our results on a real world example in the domain of health.},
  archive      = {J_EJOR},
  author       = {Brice Mayag and Denis Bouyssou},
  doi          = {10.1016/j.ejor.2019.10.036},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {308-320},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Necessary and possible interaction between criteria in a 2-additive choquet integral model},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consistency and consensus modeling of linear uncertain
preference relations. <em>EJOR</em>, <em>283</em>(1), 290–307. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval operations, as currently defined, suffer from the problem of not satisfying the conditions of global complementarity and consistency of interval fuzzy preference relations (IFPRs). In this paper, we resolve this difficulty by constructing linear uncertain preference relations (LUPRs). By considering all the information and the uncertain distribution of an interval, we propose the concept of uncertain preference relations (UPRs) for the first time. Then we apply uncertainty distributions to characterize interval judgments that are considered as a whole to participate in the uncertain operation to achieve the desired conditions of global complementarity and consistency. Based on this, we prove that IFPRs and the definitions of their additive consistency are special cases of those of LUPRs. Moreover, we investigate two types of consensus models developed based on LUPRs between the minimum deviation and belief degree. We prove that the minimum deviation is a linear, increasing function of the belief degree, and then establish sufficient and necessary conditions for the consensus model to satisfy additive consistency. Finally, the LUPRs models presented in this paper is applied, incorporating with expert assistance in decision-making, to the sensitivity assessment of the meteorological industry in a region of China, and the LUPRs models can be utilized to obtain results with smaller deviations.},
  archive      = {J_EJOR},
  author       = {Zaiwu Gong and Weiwei Guo and Enrique Herrera-Viedma and Zejun Gong and Guo Wei},
  doi          = {10.1016/j.ejor.2019.10.035},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {290-307},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consistency and consensus modeling of linear uncertain preference relations},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum probabilistic all-or-nothing paths. <em>EJOR</em>,
<em>283</em>(1), 279–289. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of a maximum probabilistic all-or-nothing network path. Each arc is associated with a profit and a probability and the objective is to select a path with maximum value for the product of probabilities multiplied by the sum of arc profits. The problem can be motivated by applications including serial-system design or subcontracting of key project activities that may fail. When subcontracting such critical success activities, each must be completed on time, according to the specs, and in a satisfactory manner in order for the entire project to be deemed successful. We develop a dynamic programming (DP) method for this problem in the acyclic graph setting, under an independence assumption. Two different fully-polynomial approximation schemes are developed based on the DP formulations, one of which applies repeated rounding and scaling to the input data, while the other uses only rounding. In experiments we compare the DP approach with mixed-integer nonlinear programming (MINLP) using a branch-and-cut method, on synthetic randomly generated instances as well as realistic ones.},
  archive      = {J_EJOR},
  author       = {Noam Goldberg and Michael Poss},
  doi          = {10.1016/j.ejor.2019.11.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {279-289},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum probabilistic all-or-nothing paths},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive policies for perimeter surveillance problems.
<em>EJOR</em>, <em>283</em>(1), 265–278. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of sequentially choosing observation regions along a line, with an aim of maximising the detection of events of interest. Such a problem may arise when monitoring the movements of endangered or migratory species, detecting crossings of a border, policing activities at sea, and in many other settings. In each case, the key operational challenge is to learn an allocation of surveillance resources which maximises successful detection of events of interest. We present a combinatorial multi-armed bandit model with Poisson rewards and a novel filtered feedback mechanism - arising from the failure to detect certain intrusions - where reward distributions are dependent on the actions selected. Our solution method is an upper confidence bound approach and we derive upper and lower bounds on its expected performance. We prove that the gap between these bounds is of constant order, and demonstrate empirically that our approach is more reliable in simulated problems than competing algorithms.},
  archive      = {J_EJOR},
  author       = {James A. Grant and David S. Leslie and Kevin Glazebrook and Roberto Szechtman and Adam N. Letchford},
  doi          = {10.1016/j.ejor.2019.11.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {265-278},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive policies for perimeter surveillance problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A discrete-time single-server poisson queueing game:
Equilibria simulated by an agent-based model. <em>EJOR</em>,
<em>283</em>(1), 253–264. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a discrete-time single-server queue with a single acceptance period for a Poissonian population of homogeneous customers. Customers are served on a first-come first-served (FCFS) basis, and their service times are independent and identically distributed with a general distribution. We assume that each customer chooses her/his arrival-time slot with the goal of minimizing her/his expected waiting time in competition with other customers. For this queueing game, we derive a symmetric (mixed-strategy) Nash equilibrium; that is, an equilibrium arrival-time distribution of homogeneous customers, where their expected waiting times are identical. We also propose an agent-based model, which simulates the dynamics of customers who try to minimize their waiting times for service. Through numerical experiments, we confirm that this agent-based model achieves, in steady state, an arrival-time distribution similar to the equilibrium arrival-time distribution analytically obtained.},
  archive      = {J_EJOR},
  author       = {Yutaka Sakuma and Hiroyuki Masuyama and Emiko Fukuda},
  doi          = {10.1016/j.ejor.2019.11.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {253-264},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A discrete-time single-server poisson queueing game: Equilibria simulated by an agent-based model},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal aborting rule in multi-attempt missions performed by
multicomponent systems. <em>EJOR</em>, <em>283</em>(1), 244–252. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the risk of a system&#39;s failure during a mission increases with time, it may be reasonable to abort a mission and to attempt it again after the corresponding rescue procedures. This risk can increase with time either when a system&#39;s lifetime is characterized by the increasing failure rate, or due to a hostile environment. In this paper, a random environment is modeled by the point process of shocks. Each shock increases the failure probability, thus exhibiting the aging effect. We generalize some recent results reported in the literature to the multi-attempt case when each of statistically identical system&#39;s components can independently complete a mission. The corresponding probabilistic model is developed and the tradeoff between a mission success probability and the expected number of lost components is discussed. The problem of minimization of the overall expected operational losses is formulated. Different types of abort policies have been compared in the detailed illustrative example. It was shown that the smallest expected operational losses can be achieved when the mission abort rule depends on the number of an attempt and on the number of components starting this attempt.},
  archive      = {J_EJOR},
  author       = {Gregory Levitin and Maxim Finkelstein and Xiang Yanping},
  doi          = {10.1016/j.ejor.2019.10.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {244-252},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal aborting rule in multi-attempt missions performed by multicomponent systems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the service time in a workload-barrier m/g/1 queue with
accepted and blocked customers. <em>EJOR</em>, <em>283</em>(1), 235–243.
(<a href="https://doi.org/10.1016/j.ejor.2019.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an M/G/1 queue with a workload barrier at finite level K &gt; 0. Arriving customers are accepted into the system only if their waiting time plus service time does not exceed K ; otherwise they are blocked and cleared immediately. This ‘accept/block’ regulation causes the pre-arrival ‘prior’ pdf (probability density function) of service time for all arrivals, to transform into the pdf of the ‘posterior’ service time reflecting the effect of the barrier at level K on both accepted and blocked customers. We derive the pdf of the posterior service time, its expected value, the expected numbers of customers accepted or blocked in a busy cycle, and a specific value of K which is greater than the median of the prior pdf, where equal expected numbers of customers are accepted and blocked in a busy cycle. We propose an expression for distance, to measure the discrepancy between the posterior and prior pdfs. Examples are given. This service-time viewpoint is of theoretical interest, and has potential applications in various related stochastic models.},
  archive      = {J_EJOR},
  author       = {P.H. Brill and M.L. Huang and M. Hlynka},
  doi          = {10.1016/j.ejor.2019.10.028},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {235-243},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the service time in a workload-barrier M/G/1 queue with accepted and blocked customers},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Can deep learning predict risky retail investors? A case
study in financial risk behavior forecasting. <em>EJOR</em>,
<em>283</em>(1), 217–234. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper examines the potential of deep learning to support decisions in financial risk management. We develop a deep learning model for predicting whether individual spread traders secure profits from future trades. This task embodies typical modeling challenges faced in risk and behavior forecasting. Conventional machine learning requires data that is representative of the feature-target relationship and relies on the often costly development, maintenance, and revision of handcrafted features. Consequently, modeling highly variable, heterogeneous patterns such as trader behavior is challenging. Deep learning promises a remedy. Learning hierarchical distributed representations of the data in an automatic manner (e.g. risk taking behavior), it uncovers generative features that determine the target (e.g., trader’s profitability), avoids manual feature engineering, and is more robust toward change (e.g. dynamic market conditions). The results of employing a deep network for operational risk forecasting confirm the feature learning capability of deep learning, provide guidance on designing a suitable network architecture and demonstrate the superiority of deep learning over machine learning and rule-based benchmarks.},
  archive      = {J_EJOR},
  author       = {A. Kim and Y. Yang and S. Lessmann and T. Ma and M.-C. Sung and J.E.V. Johnson},
  doi          = {10.1016/j.ejor.2019.11.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {217-234},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Can deep learning predict risky retail investors? a case study in financial risk behavior forecasting},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A conditional fuzzy inference approach in forecasting.
<em>EJOR</em>, <em>283</em>(1), 196–216. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a Conditional fuzzy inference (CF) approach in forecasting. The proposed approach is able to deduct Fuzzy Rules (FRs) conditional on a set of restrictions. This conditional rule selection discards weak rules and the generated forecasts are based only on the most powerful ones. Through this process, it is capable of achieving higher forecasting performance and improving the interpretability of the underlying system. The CF concept is applied in a series of forecasting exercises on stocks and football games datasets. Its performance is benchmarked against a Relevance Vector Machine (RVM), an Adaptive Neuro-Fuzzy Inference System (ANFIS), an Ordered Probit (OP), a Multilayer Perceptron Neural Network (MLP), a k-Nearest Neighbour (k-NN), a Decision Tree (DT) and a Support Vector Machine (SVM) model. The results demonstrate that the CF is providing higher statistical accuracy than its benchmarks.},
  archive      = {J_EJOR},
  author       = {Arman Hassanniakalager and Georgios Sermpinis and Charalampos Stasinakis and Thanos Verousis},
  doi          = {10.1016/j.ejor.2019.11.006},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {196-216},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A conditional fuzzy inference approach in forecasting},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cold chain transportation decision in the vaccine supply
chain. <em>EJOR</em>, <em>283</em>(1), 182–195. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vaccines are a special kind of drug, the quality of which is highly sensitive to temperature and directly related to public health. Recently, numerous vaccine-related adverse events have occurred in the world, especially in developing countries, due to vaccines being exposed to inappropriate temperatures during their transportation. This paper considers the vaccine supply chain including a distributor and a retailer (hospital or clinic). The distributor decides to use a cold chain or non-cold chain to transport the vaccines. The retailer performs an inspection when receiving the vaccines. First, a basic model is developed to study the conditions under which the distributor will transport the vaccines via a cold chain or non-cold chain. Then, two common inspection policies (a single-step one and a two-step one) are introduced into the basic model to explore the impact of the retailer&#39;s inspection at the end of transportation on the distributor&#39;s original decision. We show that the retailer&#39;s single-step inspection influences the distributor to choose the cold chain option. Interestingly, we prove that the two-step inspection policy is less effective than the single-step one in this effect. We suggest that the retailer&#39;s role in improving the distributor&#39;s non-cold chain transportation behavior should be fully used.},
  archive      = {J_EJOR},
  author       = {Qi Lin and Qiuhong Zhao and Benjamin Lev},
  doi          = {10.1016/j.ejor.2019.11.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {182-195},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cold chain transportation decision in the vaccine supply chain},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic selective maintenance optimization for multi-state
systems over a finite horizon: A deep reinforcement learning approach.
<em>EJOR</em>, <em>283</em>(1), 166–181. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective maintenance, which aims to choose a subset of feasible maintenance actions to be performed for a repairable system with limited maintenance resources, has been extensively studied over the past decade. Most of the reported works on selective maintenance have been dedicated to maximizing the success of a single future mission. Cases of multiple consecutive missions, which are oftentimes encountered in engineering practices, have been rarely investigated to date. In this paper, a new selective maintenance optimization for multi-state systems that can execute multiple consecutive missions over a finite horizon is developed. The selective maintenance strategy can be dynamically optimized to maximize the expected number of future mission successes whenever the states and effective ages of the components become known at the end of the last mission. The dynamic optimization problem, which accounts for imperfect maintenance, is formulated as a discrete-time finite-horizon Markov decision process with a mixed integer-discrete-continuous state space. Based on the framework of actor-critic algorithms, a customized deep reinforcement learning method is put forth to overcome the “curse of dimensionality” and mitigate the uncountable state space. In our proposed method, a postprocess is developed for the actor to search the optimal maintenance actions in a large-scale discrete action space, whereas the techniques of the experience replay and the target network are utilized to facilitate the agent training. The performance of the proposed method is examined by an illustrative example and an engineering example of a coal transportation system.},
  archive      = {J_EJOR},
  author       = {Yu Liu and Yiming Chen and Tao Jiang},
  doi          = {10.1016/j.ejor.2019.10.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {166-181},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic selective maintenance optimization for multi-state systems over a finite horizon: A deep reinforcement learning approach},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simple game theoretical analysis for incentivizing
multi-modal transportation in freight supply chains. <em>EJOR</em>,
<em>283</em>(1), 152–165. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal transportation, as a highly efficient approach, can economize many intermediate links in the supply chain and save social operating costs. However, at present, multi-modal transportation accounts for only a small portion of the total traffic volume, and there are few multi-modal carriers. To analyze the incentives of ocean shipping companies to provide multi-modal transportation, this paper considers a freight supply chain composed of two upstream ocean shipping companies and two downstream railway transportation companies. After depicting a Nash game between the two competing ocean shipping companies in terms of whether to integrate downstream railway transportation services to provide multi-modal transportation, we analyze the performance of the participants in sub-games for each integration strategy. The results indicate that regardless of competitor behavior, ocean shipping companies may have an incentive to provide multi-modal transportation. Although the two ocean shipping companies are unlikely to agree on the optimal strategy, the only effective equilibrium they can achieve is both providing multi-modal transportation. Moreover, in this equilibrium, the supply chain’s profit, consumer utility and social welfare are likely to be maximized. In addition, although the provision of multi-modal transportation will attract more shippers to the market, whether more shippers can ultimately be retained depends on the integration efficiency and competitive intensity.},
  archive      = {J_EJOR},
  author       = {Zhuzhu Song and Wansheng Tang and Ruiqing Zhao},
  doi          = {10.1016/j.ejor.2019.10.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {152-165},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A simple game theoretical analysis for incentivizing multi-modal transportation in freight supply chains},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic dual-channel pricing games with e-retailer
finance. <em>EJOR</em>, <em>283</em>(1), 138–151. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small and medium-sized enterprises (SMEs) often face obstacles in reaching consumers and obtaining sufficient capital for their production and operations processes. Owning channel advantages and rich transaction data regarding suppliers’ sales, inventory, and credits, e-commerce platforms (henceforth, e-retailers) can offer online distribution channels and online financing service for SMEs to facilitate their distribution and alleviate their capital constraints. This study analyzes the pricing competition in a dual-channel supply chain consisting of one capital-constrained supplier and one e-retailer providing finance. The supplier can sell her products either through the e-retailer using the online channel or through her direct offline channel. The e-retailer offers finance to the supplier if she is capital-constrained. We examine the equilibrium price and the associated optimal quantity and profits in dual channels when supplier may face capital constraint and compete with e-retailer horizontally or vertically. We find that e-retailer finance is a value-added service for e-retailer and that the increased profits generated from financing offerings can offset the lowered revenue in the online distribution channel. E-retailer finance can increase market share, which also benefits the supplier. Participating in the vertical competition through announcing pricing decisions earlier than does the supplier can help the e-retailer seize the first-mover advantage. Further, we present the value of e-retailer finance and examine the impact of various financing, operational, and consumer-related factors on pricing and channel structure. We also provide guidelines for e-retailers and financing-constrained suppliers to utilize e-retailer finance to optimize their dual-channel structure and to make optimal pricing decisions.},
  archive      = {J_EJOR},
  author       = {Yan Nina and Liu Yang and Xu Xun and He Xiuli},
  doi          = {10.1016/j.ejor.2019.10.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {138-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic dual-channel pricing games with e-retailer finance},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The price-setting newsvendor with poisson demand.
<em>EJOR</em>, <em>283</em>(1), 125–137. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The price-setting newsvendor (PSN) model has received considerable attention since it was first introduced by Whitin (1955). However, the existing publications that study this model consistently assume the existence of a continuous density function of demand. In this paper, we study the PSN model with Poisson demand — that is, a discrete demand distribution without density function. The Poisson PSN has an important property, it combines price-dependency of variance and coefficient of variation of the (standard) additive and multiplicative models: demand variance decreases and the coefficient of variation increases in the selling price. We develop an analytical solution approach that covers a broad class of demand models, including linear and logit demand, explain how to apply our approach to more general demand functions via piece-wise linear approximation, and develop analytical and numerical insights. We characterize the behavior of the optimal price and we analyze the performance gap of different price-setting heuristics. Among other insights, we observe some instances in which a significant share of profits would be lost if the discrete nature of demand were not modeled explicitly. To help companies overcome this risk, we present an easily applicable decision rule with which to determine when to use simple heuristics and when to solve the associated discrete optimization problem.},
  archive      = {J_EJOR},
  author       = {Benedikt Schulte and Anna-Lena Sachs},
  doi          = {10.1016/j.ejor.2019.10.039},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {125-137},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The price-setting newsvendor with poisson demand},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bidirectional labeling for solving vehicle routing and truck
driver scheduling problems. <em>EJOR</em>, <em>283</em>(1), 108–124. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the vehicle routing and truck driver scheduling problem where routes and schedules must comply with hours of service regulations for truck drivers. It presents a backward labeling method for generating feasible schedules and shows how the labels generated with the backward method can be combined with labels generated by a forward labeling method. The bidirectional labeling is embedded into a branch-and-price-and-cut approach and evaluated for hours of service regulations in the United States and the European Union. Computational experiments show that the resulting bidirectional branch-and-price-and-cut approach is significantly faster than unidirectional counterparts and previous approaches.},
  archive      = {J_EJOR},
  author       = {Christian Tilk and Asvin Goel},
  doi          = {10.1016/j.ejor.2019.10.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {108-124},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bidirectional labeling for solving vehicle routing and truck driver scheduling problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of demand parameter uncertainty on the bullwhip
effect. <em>EJOR</em>, <em>283</em>(1), 94–107. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bullwhip effect is a very important issue for supply chains, impacting on costs and effectiveness. Academic researchers have studied this phenomenon and modelled it analytically, showing that it affects many real world industries. The analytical models generally assume that the final demand process and its parameters are known. This paper studies a two-echelon single-product supply chain with final demand distributed according to a known AR(1) process but with unknown parameters. The results show that the bullwhip effect is affected by unknown parameters and is influenced by the frequency with which parameter estimates are updated. For unknown parameters, the strength of the bullwhip effect is also influenced by the number of demand observations available to estimate the parameters. Furthermore, a negative autoregressive parameter does not always imply an anti-bullwhip effect when the parameters are unknown. An analytical approximation is proposed to mitigate the poor accuracy of existing models when the parameters of an AR(1) process are unknown, forecasts are updated but parameter estimates remain unchanged.},
  archive      = {J_EJOR},
  author       = {Erica Pastore and Arianna Alfieri and Giulio Zotteri and John E. Boylan},
  doi          = {10.1016/j.ejor.2019.10.031},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {94-107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The impact of demand parameter uncertainty on the bullwhip effect},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective evolutionary algorithms for a reliability
location problem. <em>EJOR</em>, <em>283</em>(1), 83–93. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some location problems with unreliable facilities present two different objectives, one consisting of minimizing the opening and transportation costs if none of the facilities fail and another consisting of minimizing the expected transportation costs. Usually, these different targets are combined in a single objective function and the decision maker can obtain some different solutions weighting both objectives. However, if the decision maker prefers to obtain a diverse set of non-dominated optimal solutions, then such procedure would not be effective. We have designed and implemented two multi-objective evolutionary algorithms for the realibility fixed-charge location problem by exploiting the peculiarities of this problem in order to obtain sets of solutions that are properly distributed along the Pareto-optimal frontier. The computational results demonstrate the outstanding efficiency of the proposed algorithms, although they present clear differences.},
  archive      = {J_EJOR},
  author       = {Javier Alcaraz and Mercedes Landete and Juan F. Monge and José L. Sainz-Pardo},
  doi          = {10.1016/j.ejor.2019.10.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {83-93},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-objective evolutionary algorithms for a reliability location problem},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution algorithms for minimizing the total tardiness with
budgeted processing time uncertainty. <em>EJOR</em>, <em>283</em>(1),
70–82. (<a href="https://doi.org/10.1016/j.ejor.2019.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate algorithms that solve exactly the robust single machine scheduling problem that minimizes the total tardiness. We model the processing times as uncertain and let them take any value in a budgeted uncertainty set. Therefore, the objective seeks to minimize the worst-case tardiness over all possible values. We compare, through computational experiments, two types of solution algorithms. The first combines classical MILP formulations with row-and-column generation algorithms. The second generalizes the classical branch-and-bound algorithms to the robust context, extending state-of-the-art concepts used for the deterministic version of the problem. By generalizing the classical branch-and-bound algorithm we are able to assemble and discuss good algorithmic decisions steps that once put together make our robust branch-and-bound case attractive. For example, we extend and adapt dominance rules to our uncertain problem, making them an important component of our robust algorithms. We assess our algorithms on instances inspired by the scientific literature and identify under what conditions an algorithm has better performance than others. We introduce a new classifying parameter to group our instances, also extending existing methods for the deterministic problem case.},
  archive      = {J_EJOR},
  author       = {Marco Silva and Michael Poss and Nelson Maculan},
  doi          = {10.1016/j.ejor.2019.10.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {70-82},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solution algorithms for minimizing the total tardiness with budgeted processing time uncertainty},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branching with hyperplanes in the criterion space: The
frontier partitioner algorithm for biobjective integer programming.
<em>EJOR</em>, <em>283</em>(1), 57–69. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an algorithm for finding the complete Pareto frontier of biobjective integer programming problems. The method is based on the solution of a finite number of integer programs. The feasible sets of the integer programs are built from the original feasible set, by adding cuts that separate efficient solutions. Providing the existence of an oracle to solve suitably defined single objective integer subproblems, the algorithm can handle biobjective nonlinear integer problems, in particular biobjective convex quadratic integer optimization problems. Our numerical experience on a benchmark of biobjective integer linear programming instances shows the efficiency of the approach in comparison with existing state-of-the-art methods. Further experiments on biobjective integer quadratic programming instances are reported.},
  archive      = {J_EJOR},
  author       = {Marianna De Santis and Giorgio Grani and Laura Palagi},
  doi          = {10.1016/j.ejor.2019.10.034},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {57-69},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Branching with hyperplanes in the criterion space: The frontier partitioner algorithm for biobjective integer programming},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A gradient descent based algorithm for ℓp minimization.
<em>EJOR</em>, <em>283</em>(1), 47–56. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the linearly constrained ℓ p minimization problem with p ∈ (0, 1). Unlike those known works in the literature that propose solving relaxed ϵ-KKT conditions, we introduce a scaled KKT condition without involving any relaxation of the optimality conditions. A gradient-descent-based algorithm that works only on the positive entries of variables is then proposed to find solutions satisfying the scaled KKT condition without invoking the nondifferentiability issue. The convergence proof and complexity analysis of the proposed algorithm are provided. Computational experiments support that the proposed algorithm is capable of achieving much better sparse recovery in reasonable computational time compared to state-of-the-art interior-point based algorithms.},
  archive      = {J_EJOR},
  author       = {Shan Jiang and Shu-Cherng Fang and Tiantian Nie and Wenxun Xing},
  doi          = {10.1016/j.ejor.2019.11.051},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {47-56},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A gradient descent based algorithm for ℓp minimization},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new convergent hybrid learning algorithm for two-stage
stochastic programs. <em>EJOR</em>, <em>283</em>(1), 33–46. (<a
href="https://doi.org/10.1016/j.ejor.2019.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new hybrid learning algorithm to approximate the expected recourse function for two-stage stochastic programs. The proposed algorithm, which is called projected stochastic hybrid learning algorithm, is a hybrid of piecewise linear approximation and stochastic subgradient methods. Piecewise linear approximations are updated adaptively by using stochastic subgradient and sample information on the objective function itself. In order to achieve a global optimum, a projection step that implements the stochastic subgradient method is performed to jump out from a local optimum. For general two-stage stochastic programs, we prove the convergence of the algorithm. Furthermore, the algorithm can drop the projection steps for two-stage stochastic programs with network recourse. Therefore, the pure piecewise linear approximation method is convergent when the initial piecewise linear functions are properly constructed. Computational results indicate that the algorithm exhibits rapid convergence.},
  archive      = {J_EJOR},
  author       = {Shaorui Zhou and Hui Zhang and Ning Shi and Zhou Xu and Fan Wang},
  doi          = {10.1016/j.ejor.2019.11.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {33-46},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new convergent hybrid learning algorithm for two-stage stochastic programs},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A moment and sum-of-squares extension of dual dynamic
programming with application to nonlinear energy storage problems.
<em>EJOR</em>, <em>283</em>(1), 16–32. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a finite-horizon optimization algorithm that extends the established concept of Dual Dynamic Programming (DDP) in two ways. First, in contrast to the linear costs, dynamics, and constraints of standard DDP, we consider problems in which all of these can be polynomial functions. Second, we allow the state trajectory to be described by probability distributions rather than point values, and return approximate value functions fitted to these. The algorithm is in part an adaptation of sum-of-squares techniques used in the approximate dynamic programming literature. It alternates between a forward simulation through the horizon, in which the moments of the state distribution are propagated through a succession of single-stage problems, and a backward recursion, in which a new polynomial function is derived for each stage using the moments of the state as fixed data. The value function approximation returned for a given stage is the point-wise maximum of all polynomials derived for that stage. This contrasts with the piecewise affine functions derived in conventional DDP. We prove key convergence properties of the new algorithm, and validate it in simulation on two case studies related to the optimal operation of energy storage devices with nonlinear characteristics. The first is a small borehole storage problem, for which multiple value function approximations can be compared. The second is a larger problem, for which conventional discretized dynamic programming is intractable.},
  archive      = {J_EJOR},
  author       = {Marc Hohmann and Joseph Warrington and John Lygeros},
  doi          = {10.1016/j.ejor.2019.10.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {16-32},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A moment and sum-of-squares extension of dual dynamic programming with application to nonlinear energy storage problems},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The generalized minimum spanning tree problem: An overview
of formulations, solution procedures and latest advances. <em>EJOR</em>,
<em>283</em>(1), 1–15. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, some of the main known results relative to the generalized minimum spanning tree problem are surveyed. The principal feature of this problem is related to the fact that the vertices of the graph are partitioned into a certain number of clusters and we are interested in finding a minimum-cost tree spanning a subset of vertices with precisely one vertex considered from every cluster. The paper is structured around the following main headings: problem definition, variations and practical applications, complexity aspects, integer programming formulations, exact and heuristic solution approaches developed for solving this problem. Furthermore, we also discuss some open problems and possible research directions.},
  archive      = {J_EJOR},
  author       = {Petrică C. Pop},
  doi          = {10.1016/j.ejor.2019.05.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The generalized minimum spanning tree problem: An overview of formulations, solution procedures and latest advances},
  volume       = {283},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General lattice methods for arithmetic asian options.
<em>EJOR</em>, <em>282</em>(3), 1185–1199. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, we develop a new discrete-time model approach with flexibly changeable driving dynamics for pricing Asian options, with possible early exercise, and a fixed or floating strike price. These options are ubiquitous in financial markets but can also be recast in the framework of real options. Moreover, we derive an accurate lower bound to the price of the European Asian options under stochastic volatility. We also survey theoretical aspects; more specifically, we prove that our tree method for the European Asian option in the binomial model is unconditionally convergent to the continuous-time equivalent. Numerical experiments confirm smooth, monotonic convergence, highly precise performance, and robustness with respect to changing driving dynamics and contract features.},
  archive      = {J_EJOR},
  author       = {Anna Maria Gambaro and Ioannis Kyriakou and Gianluca Fusai},
  doi          = {10.1016/j.ejor.2019.10.026},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1185-1199},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {General lattice methods for arithmetic asian options},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). Quantile stochastic frontiers. <em>EJOR</em>,
<em>282</em>(3), 1177–1184. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, based on Jradi and Ruggiero (2019). Stochastic Data Envelopment Analysis: A Quantile Regression Approach to Estimate the Production Frontier. European Journal of Operational Research, 278 (2), 385–393] we propose a novel quantile Stochastic Frontier Model (SFM) and develop Markov Chain Monte Carlo techniques for numerical Bayesian inference. In an empirical application to US large banks we document important differences between the Quantile and the traditional SFM, in terms of several aspects of the data. We also document considerable heterogeneity among different quantiles in terms of returns to scale, technical change, efficiency change, technical efficiency, as well as productivity growth.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2019.10.012},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1177-1184},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Quantile stochastic frontiers},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Technical, allocative and overall efficiency: Estimation and
inference. <em>EJOR</em>, <em>282</em>(3), 1164–1176. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric data envelopment analysis and free-disposal hull estimators are frequently used to estimate cost, revenue and profit efficiency as well as the corresponding allocative efficiencies. Papers in the literature often report sample means of such estimates along with sample standard deviations, inviting readers to make inference about means of these efficiencies using classical methods based on the standard Lindeberg–Feller central limit theorem (CLT). A number of papers explicitly make inference using the classical methods. However, the statistical properties of these estimators are (until now) unknown. This paper establishes rates of convergence and existence of limiting distributions for the various estimators. These properties are needed in order to make inference about individual producers using subsampling methods. In addition, properties of the first two moments of the estimators are derived, and these results are subsequently used to establish new CLTs for the estimators, providing formal justification for inference-making. The results reveal that the classical CLTs and methods do not provide valid inference when FDH estimators are used, and provide valid inference when DEA estimators only in a few restrictive, special cases.},
  archive      = {J_EJOR},
  author       = {Léopold Simar and Paul W. Wilson},
  doi          = {10.1016/j.ejor.2019.10.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1164-1176},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technical, allocative and overall efficiency: Estimation and inference},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating the term structure of commodity market
preferences. <em>EJOR</em>, <em>282</em>(3), 1146–1163. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The commodity futures curve is viewed as a market-based path forecast, a term structure, optimizing multivariate loss preferences. Based on the forecast decision setting, we apply estimation of flexible multivariate loss functions, which reveal the preference term structure along the futures curve, which can be flat, smoothly sloping or oscillating, rotating among optimism, pessimism and symmetry. Evidence from the thirty main world commodities around the global crisis period, accommodates the futures curve forecast rationality questioned in the literature, suggesting the presence of joint preference asymmetries for longer maturities and symmetries for shorter ones. This reveals joint optimistic preferences for most commodities until 2004, evolving into oscillating preferences rotating within the term structure from symmetry to pessimism and optimism in 2005–2008 and finally back to weaker optimism until 2013.},
  archive      = {J_EJOR},
  author       = {George Christodoulakis},
  doi          = {10.1016/j.ejor.2019.10.009},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1146-1163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating the term structure of commodity market preferences},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Does risk aversion affect bank output loss? The case of the
eurozone. <em>EJOR</em>, <em>282</em>(3), 1127–1145. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new model to infer the evolution of bank-specific output losses due to the uncertainty in bank output prices. Losses are based on bank risk aversion with micro foundations tethered to the uncertainty regarding prices. Our model allows us to measure time-varying bank-specific output losses and risk aversion while taking into account all bank cross-sectional heterogeneity. We employ a panel data set to estimate the input and output elasticities with both parametric and non-parametric techniques. We are the first to document that increasing risk aversion among Eurozone banks during the financial crisis resulted in sizable output losses. Although subdued thereafter, losses have been resurging in recent years. Both conventional and unconventional monetary policy responses by the European Central Bank (ECB) mitigated uncertainty in bank output prices, though unequally so across countries. Certain measures of unconventional monetary policy may have even enhanced bank risk aversion and thereby output losses, but mainly so for large countries.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas and Emmanuel Mamatzakis and Steven Ongena},
  doi          = {10.1016/j.ejor.2019.10.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1127-1145},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Does risk aversion affect bank output loss? the case of the eurozone},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-objective monte carlo tree search for forest harvest
scheduling. <em>EJOR</em>, <em>282</em>(3), 1115–1126. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the objectives of forest management vary widely and include the protection of resources in protected forests and nature reserves, the primary objective has often been the production of wood products. However, even in this case, forests play a key role in the conservation of living resources. Constraining the areas of clearcuts contributes to this conservation, but if it is too restrictive, a dispersion of small clearcuts across the forest might occur, and forest fragmentation might be a serious ecological problem. Forest fragmentation leads to habitat loss, not only because the forest area is reduced, but also because the core area of the habitats and the connectivity between them decreases. This study presents a Monte Carlo tree search method to solve a bi-objective harvest scheduling problem with constraints on the clearcut area, total habitat area and total core area inside habitats. The two objectives are the maximization of both the net present value and the probability of connectivity index. The method is presented as an approach to assist the decision maker in estimating efficient alternative solutions and the corresponding trade-offs. This approach was tested with instances for forests ranging from some dozens to over a thousand stands and temporal horizons from three to eight periods. In general, multi-objective Monte Carlo tree search was able to find several efficient alternative solutions in a reasonable time, even for medium and large instances.},
  archive      = {J_EJOR},
  author       = {Teresa Neto and Miguel Constantino and Isabel Martins and João Pedro Pedroso},
  doi          = {10.1016/j.ejor.2019.09.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1115-1126},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective monte carlo tree search for forest harvest scheduling},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel minimal cut-based algorithm to find all minimal
capacity vectors for multi-state flow networks. <em>EJOR</em>,
<em>282</em>(3), 1107–1114. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real systems, such as computer systems, can be modeled as network topologies with vertices and edges. Owing to equipment failures and maintenance requirements, the capacities of edges have several states. Such systems are regarded as multi-state flow networks (MSFN). System reliability of an MSFN is the probability that the required flow (i.e., demand) can successfully be sent from the source to the sink. By adopting a minimal path (MP) approach, system reliability can be computed in terms of all minimal capacity vectors meeting the demand d . A minimal capacity vector is called a d -MP. Although several algorithms have been presented in the literature for finding all d -MP, improving efficiency in the search for all d -MP is always a challenge. A group approach with both the concepts of minimal cut and MP is developed in this study, narrowing the search range of feasible flow vectors. An algorithm based on the group approach is then proposed to improve the efficiency of the d -MP search. According to the structure of the proposed algorithm, parallel computing can be implemented with significant improvement in the efficiency of the d -MP generation, where the proposed algorithm is compared with previous ones based on three benchmarks, in terms of CPU time.},
  archive      = {J_EJOR},
  author       = {Ding-Hsiang Huang and Cheng-Fu Huang and Yi-Kuei Lin},
  doi          = {10.1016/j.ejor.2019.10.030},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1107-1114},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A novel minimal cut-based algorithm to find all minimal capacity vectors for multi-state flow networks},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on the regularity of a new metric for measuring
even-flow in forest planning. <em>EJOR</em>, <em>282</em>(3), 1101–1106.
(<a href="https://doi.org/10.1016/j.ejor.2019.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we deal with the mathematical analysis of a new metric for measuring even-flow in even-aged forest management planning. We begin writing the most used way of measuring even-flow, and showing the main disadvantages of this classical procedure. Next, we introduce the new metric and study the regularity of the corresponding function, which results to be continuous and to have continuous derivatives in almost all points. We give an explicit expression for these derivatives and analyze its usefulness by comparing a gradient-type method with a derivative-free algorithm (widely used in forestry) to maximize even-flow in a forest of 51 Eucalyptus globulus Labill. stands in Galicia (NW Spain). We observe that gradient-type methods work well with the new even-flow metric, which enables this type of methods for solving the multi-objective problems that can be formulated in forest planning.},
  archive      = {J_EJOR},
  author       = {José M. González-González and Miguel E. Vázquez-Méndez and Ulises Diéguez-Aranda},
  doi          = {10.1016/j.ejor.2019.10.029},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1101-1106},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A note on the regularity of a new metric for measuring even-flow in forest planning},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing a rural network of dialysis facilities.
<em>EJOR</em>, <em>282</em>(3), 1088–1100. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kidney specialists treat chronic kidney failure with dialysis until transplant or death. Patients travel to in-centre or satellite hemodialysis facilities for each four-hour treatment, three times per week or participate in home peritoneal dialysis or home hemodialysis. We observe through a patient preference survey that regardless of the travel burden, many patients will always opt to go to an in-centre or satellite facility, while some will always opt for home dialysis. For others, the choice will vary depending on the location of available facilities. We propose a mathematical model for the Dialysis Facility Network Design Problem, where long travel times impact access to care, especially for patients who live in rural areas. The proposed model can help identify the best network of dialysis facilities with consideration for budget and capacity management constraints as well as patient preferences for facility or home dialysis. In the application of our proposed model through a case study, we find that with the same budget as the existing facility network, it is possible to achieve considerable reductions in maximum and mean patient travel times with less variability. Due to the potential cost savings from home dialysis, we compare further improvements from increasing the proportion of patients who will consider home dialysis with similar improvements from increases in budget. For larger size problem instances, we provide a tabu search heuristic that can be used to find optimal or near-optimal solutions in a fraction of the computation time required by a commercial solver.},
  archive      = {J_EJOR},
  author       = {Michael G. Klein and Vedat Verter and Brian G. Moses},
  doi          = {10.1016/j.ejor.2019.10.024},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1088-1100},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing a rural network of dialysis facilities},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The effect of monetary policy on bank competition using the
boone index. <em>EJOR</em>, <em>282</em>(3), 1070–1087. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interesting strand of the theoretical literature on measuring competition posits that when competition increases in an industry, output is reallocated to more efficient firms. Our first contribution is on the methodology for the empirical implementation of this theoretical test of a change in competition. This contribution moves from the relationship between a change in competition and a single all-encompassing efficiency, to a set of relationships between a change in competition and multiple efficiencies that measure different components of economic performance. Our second contribution is to apply our empirical methodology to large U.S. banks. The results suggest that competition intensified between these banks during the financial crisis and beyond ( 2008 − 15 2008−15 ), vis-à-vis our pre-crisis period ( 1994 − 07 1994−07 ). This points to an increase in competition that has exogenous origins such as the decrease in the loan-deposit rate spread, which represented the collateral damage to banks from monetary policy to moderate the Great Recession.},
  archive      = {J_EJOR},
  author       = {Anthony J. Glass and Karligash Kenjegalieva and Thomas Weyman-Jones},
  doi          = {10.1016/j.ejor.2019.10.022},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1070-1087},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The effect of monetary policy on bank competition using the boone index},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compulsory licenses in the pharmaceutical industry: Pricing
and r&amp;d strategies. <em>EJOR</em>, <em>282</em>(3), 1053–1069. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pharma manufacturer enters a developing country with a new drug after investing some R&amp;D in the first period. The firm can be subjected to a compulsory license mechanism that allows a generic manufacturer to produce an imitated version of the patented product in exchange of a fixed royalty. When the patent expires, a traditional price competition ensues between the patent-holder and the generic manufacturer. We compare two deterministic scenarios wherein the patent-holder has full information regarding the compulsory license. We identify the conditions under which the license is socially and economically beneficial. Our analyses suggest that the patent-holder is seldom economically better-off. We next model a stochastic compulsory license decision rule whereby the patent-holder is exposed to a certain probability that the compulsory license is issued. We show that uncertainty renders the patent-holder more willing to operate in that market.},
  archive      = {J_EJOR},
  author       = {Archita Sarmah and Domenico De Giovanni and Pietro De Giovanni},
  doi          = {10.1016/j.ejor.2019.10.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1053-1069},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Compulsory licenses in the pharmaceutical industry: Pricing and R&amp;D strategies},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimising lung imaging for cancer radiation therapy.
<em>EJOR</em>, <em>282</em>(3), 1038–1052. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective radiotherapy is dependent on being able to (i) visualise the tumour clearly, and (ii) deliver the correct dose to the cancerous tissue, whilst sparing the healthy tissue as much as possible. In the presence of tumour motion, both of these tasks become increasingly difficult to perform accurately. This increases the likelihood of an incorrect dose being delivered to cancerous tissue and exposure of healthy tissue to unnecessary radiation. For tumours in the lung and thoracic region subject to respiratory-induced motion, 4D Cone-Beam CT (4D-CBCT) is a novel approach for producing a sequence of 3D images of the patient’s anatomy throughout different phases of the respiratory cycle. However, current implementations involve sub-optimal heuristic approaches to acquire the imaging data required to account for tumour motion. This leads to undersampling of images for particular phases in the respiratory cycle (such as peak inhale and exhale), resulting in noisy or poorly reconstructed 3D images. In this paper we present a novel Mixed Integer Program (MIP) to optimise the timing and angles for the acquisition of imaging data. The result is greatly enhanced image quality for each image across the respiratory cycle, whilst minimising motion blur. Numerical experiments indicate that our approach universally improves over the conventional acquisition process by 93\% and simultaneously reduces unnecessary dose to the patient and can be solved in under a minute.},
  archive      = {J_EJOR},
  author       = {Michelle Dunbar and Ricky O’Brien and Gary Froyland},
  doi          = {10.1016/j.ejor.2019.10.020},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1038-1052},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimising lung imaging for cancer radiation therapy},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fuzzy cooperative game theoretic approach for
multinational water resource spatiotemporal allocation. <em>EJOR</em>,
<em>282</em>(3), 1025–1037. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water resource allocation in multinational river basins has been a major concern for all riparian countries. From the perspective of cooperative and sustainable water resource development, considering the spatiotemporal characteristics of the water demand, namely, the priority of water use due to the geographic location of each riparian country, the seasonality of water demand, and the differences in the net utility of water utilization, this paper constructs a fuzzy coalition game model for multinational water resource allocation and provides the optimal allocation strategy using the example of the Lancang-Mekong River. The study indicates that considering the geographic locations and the differences in the water utility of each country compared with the initial allocation strategy based on agricultural water demand, the cooperative strategy increases the allocated water resources in high-utility countries (expect countries near the estuary) and the overall water utility in the entire basin. Then, considering the seasonality of the water resource reallocation, the fuzzy coalition among riparian countries further increases the net water utility of each country and achieves the optimal allocation. As the preconditions for the establishment of cooperative relationships, upstream countries need to transfer partial water rights to downstream countries in certain seasons. The basic idea that is presented in this paper, the fuzzy coalition model of water resource allocation with spaciotemporal constraints, can be applied to the water allocation of other multinational rivers.},
  archive      = {J_EJOR},
  author       = {Liu Dehai and Ji Xiaoxian and Tang Jiafu and Li Hongyi},
  doi          = {10.1016/j.ejor.2019.10.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1025-1037},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fuzzy cooperative game theoretic approach for multinational water resource spatiotemporal allocation},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From one-class to two-class classification by incorporating
expert knowledge: Novelty detection in human behaviour. <em>EJOR</em>,
<em>282</em>(3), 1011–1024. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class classification is the standard procedure for novelty detection. Novelty detection aims to identify observations that deviate from a determined normal behaviour. Only instances of one class are known, whereas so called novelties are unlabelled. Traditional novelty detection applies methods from the field of outlier detection. These standard one-class classification approaches have limited performance in many real business cases. The traditional techniques are mainly developed for industrial problems such as machine condition monitoring. When applying these to human behaviour, the performance drops significantly. This paper proposes a method that improves existing approaches by creating semi-synthetic novelties in order to have labelled data for the two classes. Expert knowledge is incorporated in the initial phase of this data generation process. The method was deployed on a real-life test case where the goal was to detect fraudulent subscriptions to a telecom family plan. This research demonstrates that the two-class expert model outperforms a one-class model on the semi-synthetic dataset. In a next step the model was validated on a real dataset. A fraud detection team of the company manually checked the top predicted novelties. The results show that incorporating expert knowledge to transform a one-class problem into a two-class problem is a valuable method.},
  archive      = {J_EJOR},
  author       = {Dieter Oosterlinck and Dries F. Benoit and Philippe Baecke},
  doi          = {10.1016/j.ejor.2019.10.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1011-1024},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {From one-class to two-class classification by incorporating expert knowledge: Novelty detection in human behaviour},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lean holistic fuzzy methodology employing cross-functional
worker teams for new product development projects: A real case study
from high-tech industry. <em>EJOR</em>, <em>282</em>(3), 989–1010. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a lean holistic fuzzy methodology for the new product development (NPD) projects to cope with the uncertainties encountered in the projects by placing an emphasis on the cross-functional worker teams along with utility workers’ impact on the lead time and total operational cost. To this end, the fuzzy design structure matrix (FDSM), the fuzzy value stream mapping (FVSM), and a novel fuzzy optimization model are combined and employed sequentially for visualizing all processes, decreasing lead time and operational cost, and determining the improvement points. While the whole methodology focuses on reducing the lead time by creating the worker teams, the fuzzy optimization model aims to decrease the total operational costs. The study is conducted in a startup, which has begun to reorganize its NPD projects according to lean principles by implementing the proposed methodology. The effectiveness of the methodology to reduce the lead time and the operational cost is shown in the results based on the data taken from the startup. To analyze the impact of parameters on the total operational cost in terms of the total number of workers ( w.r.t. normal and utility ) and the lead time as well, the computational experiments are carried out through a set of parameter values and α-cut levels. According to the results, the proposed methodology leads to a decrease in both the lead time and the total operational cost thanks to employing the utility worker concept.},
  archive      = {J_EJOR},
  author       = {Omer Faruk Yilmaz and Gokhan Ozcelik and Fatma Betul Yeni},
  doi          = {10.1016/j.ejor.2019.09.048},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {989-1010},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Lean holistic fuzzy methodology employing cross-functional worker teams for new product development projects: A real case study from high-tech industry},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Measuring efficiency in a general production possibility
set allowing for negative data. <em>EJOR</em>, <em>282</em>(3), 980–988.
(<a href="https://doi.org/10.1016/j.ejor.2019.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional data envelopment analysis (DEA) models for measuring efficiency are developed for positive data. However, difficulties are encountered when data has negative values. Several models have been proposed to calculate efficiency in the presence of negative data. While efficiencies can be calculated from these models, most of them are biased and lack underlying supporting theories. This paper proposes a generalized radial model defined on a more general production possibility set that only requires the aggregate input and aggregate output to be positive. The model can be used to identify unrealistic production processes. It works under the assumptions of both constant and variable returns to scale. It can thus be used to measure scale efficiency in addition to the conventional productive efficiency. This model can also be extended to network systems, and the simplest extension of the two-stage system is discussed. The property of the conventional two-stage DEA model in which the system efficiency is the product of the two stage efficiencies is also satisfied by the generalized radial model. A case of twenty-nine supply chains is used to demonstrate how the proposed model can be applied to calculating efficiency for a conventional whole-unit (black-box) system and a two-stage system.},
  archive      = {J_EJOR},
  author       = {Kao Chiang},
  doi          = {10.1016/j.ejor.2019.10.027},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {980-988},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring efficiency in a general production possibility set allowing for negative data},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weighted committee games. <em>EJOR</em>, <em>282</em>(3),
972–979. (<a href="https://doi.org/10.1016/j.ejor.2019.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many binary collective choice situations can be described as weighted simple voting games. We introduce weighted committee games to model decisions on an arbitrary number of alternatives in analogous fashion. We compare the effect of different voting weights (shareholdings, party seats, etc.) under plurality, Borda, Copeland, and antiplurality rule. The number and geometry of weight equivalence classes differ widely across the rules. Decisions can be much more sensitive to weights in Borda committees than (anti-)plurality or Copeland ones.},
  archive      = {J_EJOR},
  author       = {Sascha Kurz and Alexander Mayer and Stefan Napel},
  doi          = {10.1016/j.ejor.2019.10.023},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {972-979},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weighted committee games},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adaptive consensus reaching process with hybrid strategies
for large-scale group decision making. <em>EJOR</em>, <em>282</em>(3),
957–971. (<a href="https://doi.org/10.1016/j.ejor.2019.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale group decision making, which involves dozens to hundreds of experts, is attracting increasing attention and has become an important topic in the field of decision making. Because of the clustering process, a large-scale group decision making problem can be divided into two levels: inter sub-group and intra sub-group. In existing consensus models under the large-scale group decision making environment, the degree of consensus within the intra sub-group is not truly taken into account. To deal with this issue, this work develops an adaptive consensus model for the sub-groups composed of hybrid strategies, with or without a feedback mechanism, according to the different levels of inter and intra degrees of consensus. These different levels of consensus are divided into four scenarios (high–high, high–low, low–high, low–low), and different feedback suggestions are generated corresponding to different cases. This hybrid mechanism can reduce the cost of supervision for the moderator. The fuzzy c-means clustering algorithm is used to classify experts. A weight-determining method combining the degree of cohesion and the size of a sub-group is introduced. Finally, an illustrative example is offered to verify the practicability of the proposed model. Some discussions and comparisons are provided to reveal the advantages and features of the proposed model.},
  archive      = {J_EJOR},
  author       = {Tang Ming and Liao Huchang and Xu Jiuping and Dalia Streimikiene and Zheng Xiaosong},
  doi          = {10.1016/j.ejor.2019.10.006},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {957-971},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Adaptive consensus reaching process with hybrid strategies for large-scale group decision making},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The multilinear model in multicriteria decision making: The
case of 2-additive capacities and contributions to parameter
identification. <em>EJOR</em>, <em>282</em>(3), 945–956. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In several multicriteria decision making problems, it is important to consider interactions among criteria in order to satisfy the preference relations provided by the decision maker. This can be achieved by using aggregation functions based on fuzzy measures, such as the Choquet integral and the multilinear model. Although the Choquet integral has been studied in a large number of works, one does not find the same literature with respect to the multilinear model. In this context, the contribution of this work is twofold. We first provide a formulation of the multilinear model by means of a 2-additive capacity. A second contribution lies in the problem of capacity identification. We consider a supervised approach and apply optimization models with and without regularization terms. Results obtained in numerical experiments with both synthetic and real data attest the performance of the considered approaches.},
  archive      = {J_EJOR},
  author       = {Guilherme Dean Pelegrina and Leonardo Tomazeli Duarte and Michel Grabisch and João Marcos Travassos Romano},
  doi          = {10.1016/j.ejor.2019.10.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {945-956},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multilinear model in multicriteria decision making: The case of 2-additive capacities and contributions to parameter identification},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monotonicity properties for two-action partially observable
markov decision processes on partially ordered spaces. <em>EJOR</em>,
<em>282</em>(3), 936–944. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates monotonicity properties of optimal policies for two-action partially observable Markov decision processes when the underlying (core) state and observation spaces are partially ordered. Motivated by the desirable properties of the monotone likelihood ratio order in imperfect information settings, namely the preservation of belief ordering under conditioning on any new information, we propose a new stochastic order (a generalization of the monotone likelihood ratio order) that is appropriate for when the underlying space is partially ordered. The generalization is non-trivial, requiring one to impose additional conditions on the elements of the beliefs corresponding to incomparable pairs of states. The stricter conditions in the proposed stochastic order reflect a conservation of structure in the problem – the loss of structure from relaxing the total ordering of the state space to a partial order requires stronger conditions with respect to the ordering of beliefs. In addition to the proposed stochastic order, we introduce a class of matrices, termed generalized totally positive of order 2, that are sufficient for preserving the order. Our main result is a set of sufficient conditions that ensures existence of an optimal policy that is monotone on the belief space with respect to the proposed stochastic order.},
  archive      = {J_EJOR},
  author       = {Erik Miehling and Demosthenis Teneketzis},
  doi          = {10.1016/j.ejor.2019.10.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {936-944},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Monotonicity properties for two-action partially observable markov decision processes on partially ordered spaces},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling negative data in slacks-based measure data
envelopment analysis models. <em>EJOR</em>, <em>282</em>(3), 926–935.
(<a href="https://doi.org/10.1016/j.ejor.2019.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes slacks-based measure (SBM) data envelopment analysis (DEA) models that handle negative data. Unlike existing negative data allowable DEA models, the proposed SBM DEA models are consistent with ordinary SBM models and units invariant, they handle various types of returns to scale, and they avoid division by zero. These new SBM DEA models transform original negative inputs and outputs into positive counterparts based on a newly defined “base point”. Hence, these models are referred to as the BP-SBM DEA models. In addition to the basic BP-SBM DEA models, this research further develops data-oriented and application-oriented BP-SBM DEA-type models for different application problems involving negative data. Numerical examples are provided to illustrate various aspects and implementation details of these models.},
  archive      = {J_EJOR},
  author       = {Kaoru Tone and Chang Tsung-Sheng and Wu Chen-Hui},
  doi          = {10.1016/j.ejor.2019.09.055},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {926-935},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Handling negative data in slacks-based measure data envelopment analysis models},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing and hedging in incomplete markets with model
uncertainty. <em>EJOR</em>, <em>282</em>(3), 911–925. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We search for a trading strategy and the associated robust price of unhedgeable assets in incomplete markets under the acknowledgement of model uncertainty. Our set-up is that we postulate the management of a firm that wants to maximise the expected surplus by choosing an optimal investment strategy. Furthermore, we assume that the firm is concerned about model misspecification. This robust optimal control problem under model uncertainty leads to (i) risk-neutral pricing for the traded risky assets, and (ii) adjusting the drift of the nontraded risk drivers in a conservative direction. The direction depends on the firm’s long or short position, and the adjustment that ensures a robust strategy leads to what is known as “actuarial” or “prudential” pricing. Our results extend to a multivariate setting. We prove existence and uniqueness of the robust price in an incomplete market via the link between the semilinear partial differential equation and backward stochastic differential equations for viscosity and classical solutions.},
  archive      = {J_EJOR},
  author       = {Anne G. Balter and Antoon Pelsser},
  doi          = {10.1016/j.ejor.2019.09.054},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {911-925},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing and hedging in incomplete markets with model uncertainty},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-cut algorithm for an assembly routing problem.
<em>EJOR</em>, <em>282</em>(3), 896–910. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an integrated planning problem that combines production, inventory and inbound transportation decisions in a context where several suppliers each provide a subset of the components necessary for the production of a final product at a central plant. We provide a mixed integer programming formulation of the problem and propose several families of valid inequalities to strengthen the linear programming relaxation. We propose two new algorithms to separate the subtour elimination constraints for fractional solutions. The inequalities and separation procedures are used in a branch-and-cut algorithm. Computational experiments on a large set of generated test instances show that both the valid inequalities and the new separation procedures significantly improve the performance of the branch-and-cut algorithm.},
  archive      = {J_EJOR},
  author       = {Masoud Chitsaz and Jean-François Cordeau and Raf Jans},
  doi          = {10.1016/j.ejor.2019.10.007},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {896-910},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for an assembly routing problem},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-cut algorithm for the inventory routing problem
with pickups and deliveries. <em>EJOR</em>, <em>282</em>(3), 886–895.
(<a href="https://doi.org/10.1016/j.ejor.2019.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the Inventory Routing Problem with Pickups and Deliveries ( IRP-PD ). A single commodity has to be picked up from several origins and distributed to several destinations. The commodity is made available at the supplier depot and at the pickup customers, with known amounts in each period of a discretized time horizon. The commodity is consumed by the delivery customers, whose demand, in each period of the time horizon, is known. The vehicles start and end their routes at the supplier depot. The objective is to determine a collection and distribution plan minimizing the sum of routing and inventory costs, satisfying inventory and capacity constraints. A mixed integer linear programming model is presented for the IRP-PD . Valid inequalities are proposed that are adapted from the inventory routing, the vehicle routing and the lot-sizing problems literature. Moreover, a new set of valid inequalities, called interval inequalities, is presented. A branch-and-cut algorithm is designed and tested on a large set of instances. Computational results show that the proposed approach is able to solve to optimality 946 out of 1280 instances. Moreover, the approach outperforms the state-of-the art method for the single vehicle case, increasing the number of instances solved to optimality from 473 to 538 out of 640 instances tested, with 133 new best known solutions.},
  archive      = {J_EJOR},
  author       = {Claudia Archetti and M. Grazia Speranza and Maurizio Boccia and Antonio Sforza and Claudio Sterle},
  doi          = {10.1016/j.ejor.2019.09.056},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {886-895},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for the inventory routing problem with pickups and deliveries},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Matheuristics for slot planning of container vessel bays.
<em>EJOR</em>, <em>282</em>(3), 873–885. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stowage planning is an NP-hard combinatorial problem concerned with loading a container vessel in a given port, such that a number of constraints regarding the physical layout of the vessel and its seaworthiness are satisfied, and a number of objectives with regard to the quality of the placement are optimized. State-of-the-art methods decompose the problem into phases, the latter of which, known as slot planning, involves loading the containers into slots of a bay. This article presents an efficient matheuristic for the slot planning problem. Matheuristics are algorithms using mathematical programming techniques within a heuristic framework. The method finds solutions for 96\% of 236 instances based on real stowage plans, 90\% of them optimally, with an average optimality gap of 4.34\% given a limit of one second per instance. This is an improvement over the results provided by previous works.},
  archive      = {J_EJOR},
  author       = {Aleksandra Korach and Berit Dangaard Brouer and Rune Møller Jensen},
  doi          = {10.1016/j.ejor.2019.09.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {873-885},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Matheuristics for slot planning of container vessel bays},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalised accelerations for insertion-based heuristics in
permutation flowshop scheduling. <em>EJOR</em>, <em>282</em>(3),
858–872. (<a href="https://doi.org/10.1016/j.ejor.2019.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scheduling literature is abundant on approximate methods for permutation flowshop scheduling, as this problem is NP-hard for the majority of objectives usually considered. Among these methods, some of the most efficient ones use an insertion-type of neighbourhood to construct high-quality solutions. It is not then surprising that using accelerations to speed up the computation of the objective function can greatly reduce the running time of these methods, since a good part of their computational effort is spent in the evaluation of the objective function. Undoubtedly, the best-known of these accelerations has been employed for makespan minimisation (commonly denoted as Taillard’s accelerations). These accelerations have been extended to other related problems, but they cannot be employed for the classical permutation flowshop problem if the objective is other than the makespan. In these cases, other types of accelerations have been proposed, but they are not able to achieve a substantial reduction of the computational effort. In this paper, we propose a new speed-up procedure for permutation flowshop scheduling using objectives related to completion times. We first present some theoretical insights based on the concept of critical path. We also provide an efficient way to compute the critical path (indeed Taillard’s accelerations appear as a specific case of these results). The results show that the computational effort is substantially reduced for total completion time, total tardiness, and total earliness and tardiness, thus outperforming the existing accelerations for these problems.},
  archive      = {J_EJOR},
  author       = {Victor Fernandez-Viagas and Jose M. Molina-Pariente and Jose M. Framinan},
  doi          = {10.1016/j.ejor.2019.10.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {858-872},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generalised accelerations for insertion-based heuristics in permutation flowshop scheduling},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch and price algorithm to solve the quickest
multicommodity k-splittable flow problem. <em>EJOR</em>,
<em>282</em>(3), 846–857. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature on Network Optimization, k -splittable flows were introduced to enhance modeling accuracy in cases where an upper bound on the number of supporting paths for each commodity needs to be imposed, thus extending the suitability of network flow tools for an increased number of practical applications. Such modeling feature has recently been extended to dynamic flows with the introduction of the novel strongly NP -hard Quickest Multicommodity k -splittable Flow Problem ( QMCkFP ). Such a flows over time problem asks for routing and scheduling of each commodity demand through at most k different paths in a dynamic network with arc capacities per time step, while minimizing the time required by the overall process. In this work, we propose the first exact algorithm for solving the QMCkSFP . The developed technique falls within the Branch and Price class and is based on original relaxation, pricing and branching procedures. Linearization and variable substitution are used to obtain the relaxation problem from the path-based formulation of the QMCkSFP . The pricing problem is modeled as a Shortest Path Problem with Forbidden Paths with additional node-set resources on a time expansion of the original digraph and is solved via a tailored dynamic programming algorithm. Two branching rules are designed for restoring feasibility whenever k -splittable or binary variable domain constraints are violated. The results of an extensive batch of computational experiments conducted on small to medium-size reference instances are presented, showing a highly satisfactory performance of the proposed algorithm. The paper concludes with a discussion on further lines of research.},
  archive      = {J_EJOR},
  author       = {Anna Melchiori and Antonino Sgalambro},
  doi          = {10.1016/j.ejor.2019.10.016},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {846-857},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch and price algorithm to solve the quickest multicommodity k-splittable flow problem},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automatic algorithm design for hybrid flowshop scheduling
problems. <em>EJOR</em>, <em>282</em>(3), 835–845. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial production scheduling problems are challenges that researchers have been trying to solve for decades. Many practical scheduling problems such as the hybrid flowshop are NP NP -hard. As a result, researchers resort to metaheuristics to obtain effective and efficient solutions. The traditional design process of metaheuristics is mainly manual, often metaphor-based, biased by previous experience and prone to producing overly tailored methods that only work well on the tested problems and objectives. In this paper, we use an Automatic Algorithm Design (AAD) methodology to eliminate these limitations. AAD is capable of composing algorithms from components with minimal human intervention. We test the proposed AAD for three different optimization objectives in the hybrid flowshop. Comprehensive computational and statistical testing demonstrates that automatically designed algorithms outperform specifically tailored state-of-the-art methods for the tested objectives in most cases.},
  archive      = {J_EJOR},
  author       = {Pedro Alfaro-Fernández and Rubén Ruiz and Federico Pagnozzi and Thomas Stützle},
  doi          = {10.1016/j.ejor.2019.10.004},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {835-845},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Automatic algorithm design for hybrid flowshop scheduling problems},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heuristics for packing semifluids. <em>EJOR</em>,
<em>282</em>(3), 823–834. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical properties of materials are seldom studied in the context of packing problems. In this work we study the behavior of semifluids: materials with particular characteristics that share properties both with solids and with fluids. We describe the importance of some specific semifluids in an industrial context, and propose methods for tackling the problem of packing them, taking into account several practical requirements and physical constraints. The problem dealt with here can be reduced to a variant of two-dimensional knapsack problem with guillotine cuts, where items are splittable in one of the dimensions and the number of cuts is not limited. Although the focus of this paper is on the computation of practical solutions, it also uncovers interesting mathematical properties of this problem, which differentiate it from other packing problems. A thorough computational experiment is used to assess the quality of the approaches proposed, which is analyzed and compared to relevant methods from the literature.},
  archive      = {J_EJOR},
  author       = {João Pedro Pedroso},
  doi          = {10.1016/j.ejor.2019.10.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {823-834},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Heuristics for packing semifluids},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Irregular packing problems: A review of mathematical models.
<em>EJOR</em>, <em>282</em>(3), 803–822. (<a
href="https://doi.org/10.1016/j.ejor.2019.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irregular packing problems (also known as nesting problems) belong to the more general class of cutting and packing problems and consist of allocating a set of irregular and regular pieces to larger rectangular or irregular containers, while minimizing the waste of material or space. These problems combine the combinatorial hardness of cutting and packing problems with the computational difficulty of enforcing the geometric non-overlap and containment constraints. Unsurprisingly, nesting problems have been addressed, both in the scientific literature and in real-world applications, by means of heuristic and metaheuristic techniques. However, more recently a variety of mathematical models has been proposed for nesting problems. These models can be used either to provide optimal solutions for nesting problems or as the basis of heuristic approaches based on them (e.g. matheuristics). In both cases, better solutions are sought, with the natural economic and environmental positive impact. Different modeling options are proposed in the literature. We review these mathematical models under a common notation framework, allowing differences and similarities among them to be highlighted. Some insights on weaknesses and strengths are also provided. By building this structured review of mathematical models for nesting problems, research opportunities in the field are proposed.},
  archive      = {J_EJOR},
  author       = {Aline A.S. Leao and Franklina M.B. Toledo and José Fernando Oliveira and Maria Antónia Carravilla and Ramón Alvarez-Valdés},
  doi          = {10.1016/j.ejor.2019.04.045},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {803-822},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Irregular packing problems: A review of mathematical models},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An ordinal classification framework for bank failure
prediction: Methodology and empirical evidence for US banks.
<em>EJOR</em>, <em>282</em>(2), 786–801. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bank failure prediction models usually combine financial attributes through binary classification approaches. In this study we extend this standard framework in three main directions. First, we explore the predictive power of attributes that describe the diversification of banking operations. Second, we consider the prediction of failure in a multi-period context. Finally, an enhanced ordinal classification framework is introduced, which considers multiple instances of failed banks prior to failure (up to three years prior to bankruptcy). Various ordinal models are developed using techniques from multiple criteria decision analysis, statistics, and machine learning. Moreover, ensemble models based on error-correcting output codes are examined. The analysis is based on a sample consisting of approximately 60,000 observations for banks in the United States over the period 2006–2015. The results show that diversification attributes improve the predictive power of bank failure prediction models, mainly for mid to long-term prediction horizons. Moreover, ordinal classification models provide a better description of the state of the banks prior to failure and are competitive to standard binary classification models.},
  archive      = {J_EJOR},
  author       = {Georgios Manthoulis and Michalis Doumpos and Constantin Zopounidis and Emilios Galariotis},
  doi          = {10.1016/j.ejor.2019.09.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {786-801},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An ordinal classification framework for bank failure prediction: Methodology and empirical evidence for US banks},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Proactive and reactive strategies for football league
timetabling. <em>EJOR</em>, <em>282</em>(2), 772–785. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to unforeseen events (e.g. bad weather conditions), association football league schedules are not necessarily played as they were announced in the beginning of the season. This paper analyses the impact of uncertainty on the quality of football league schedules by examining fifteen seasons of ten major European football leagues. We describe several quality measures, related to breaks, the fairness of the ranking, and cancelled matches. The empirical study reveals that matches that were rescheduled to another date have a profound impact on the quality of the resulting schedule, indicating that football schedules in Europe deal poorly with uncertainty. Moreover, we present several proactive and reactive approaches in order to mitigate this problem. The former determine where to insert so-called catch-up rounds as buffers in the schedule, while the latter reschedule matches to these catch-up rounds when uncertain events occur. We evaluate combinations of proactive and reactive approaches, and provide recommendations to practitioners (e.g. four catch-up rounds usually suffice, and immediate irrevocable rescheduling is not beneficial).},
  archive      = {J_EJOR},
  author       = {Xiajie Yi and Dries Goossens and Fabrice Talla Nobibon},
  doi          = {10.1016/j.ejor.2019.09.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {772-785},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Proactive and reactive strategies for football league timetabling},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Peer-to-peer electricity market analysis: From variational
to generalized nash equilibrium. <em>EJOR</em>, <em>282</em>(2),
753–771. (<a href="https://doi.org/10.1016/j.ejor.2019.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a network of prosumers involved in peer-to-peer energy exchanges, with differentiation price preferences on the trades with their neighbors, and we analyze two market designs: (i) a centralized market, used as a benchmark, where a global market operator optimizes the flows (trades) between the nodes, local demand and flexibility activation to maximize the system overall social welfare; (ii) a distributed peer-to-peer market design where prosumers in local energy communities optimize selfishly their trades, demand, and flexibility activation. We first characterize the solution of the peer-to-peer market as a Variational Equilibrium and prove that the set of Variational Equilibria coincides with the set of social welfare optimal solutions of market design (i). We give several results that help understanding the structure of the trades at an equilibrium or at the optimum. We characterize the impact of preferences on the network line congestion and renewable energy surplus under both designs. We provide a reduced example for which we give the set of all possible generalized equilibria, which enables to give an approximation of the price of anarchy. We provide a more realistic example which relies on the IEEE 14-bus network, for which we can simulate the trades under different preference prices. Our analysis shows in particular that the preferences have a large impact on the structure of the trades, but that one equilibrium (variational) is optimal. Finally, the learning mechanism needed to reach an equilibrium state in the peer-to-peer market design is discussed together with privacy issues.},
  archive      = {J_EJOR},
  author       = {Hélène Le Cadre and Paulin Jacquot and Cheng Wan and Clémence Alasseur},
  doi          = {10.1016/j.ejor.2019.09.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {753-771},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Peer-to-peer electricity market analysis: From variational to generalized nash equilibrium},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling surgery groups considering multiple downstream
resources. <em>EJOR</em>, <em>282</em>(2), 741–752. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surgery groups are clustered surgery procedure types that share comparable characteristics (e.g. expected duration). Scheduling OR blocks leaves many options for operational surgery scheduling and this increases the variation in usage of both the OR and downstream beds. Therefore, we schedule surgery groups to reduce the options for operational scheduling, ultimately bridging the gap between tactical and operational scheduling. We propose a single step mixed integer linear programming (MILP) approach that approximates the bed and OR usage and a simulated annealing approach. Both approaches are compared on a real-life data set and results show that the MILP performs best in terms of solution quality and computation time. Furthermore, the results show that our model may improve the OR utilization from 71\% to 85\% and decrease the bed usage variation from 53 beds to 11 beds compared to historical data. To show the potential and robustness of our model, we discuss several variants of the model requiring minor modifications. The use of surgery groups makes it easier to implementation our model in practice and, for operational planners, it is instantly clear where to schedule different types of surgery.},
  archive      = {J_EJOR},
  author       = {A.J. Thomas Schneider and J. Theresia van Essen and Mijke Carlier and Erwin W. Hans},
  doi          = {10.1016/j.ejor.2019.09.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {741-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling surgery groups considering multiple downstream resources},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective evolutionary algorithms for strategic
deployment of resources in operational units. <em>EJOR</em>,
<em>282</em>(2), 729–740. (<a
href="https://doi.org/10.1016/j.ejor.2019.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale infrastructure networks require frequent maintenance, often performed by a team of skilled engineers spread over a large area. The set of tasks allocated to an engineer can have a huge impact on overall efficiency, whether that be in terms of time taken to complete all tasks, staffing costs or environmental costs in terms of emissions. When required to efficiently allocate a set of geographically distributed tasks to a maintenance engineering workforce, one approach is to define working areas for which teams of engineers are responsible. Often a key obstacle to overcome when looking for solutions is ensuring a balance between multiple competing objectives. In this paper, we employ a number of multiobjective evolutionary algorithms to analyse a simulation model for a real-world workforce optimisation problem used by BT. We provide a detailed analysis of the class of problems to be solved, where the workforce and a set of service distribution points must be split into smaller working areas, referred to as operational units. As the choice of how many operational units to split a larger working area into is critical, some of the practical considerations that must be made when addressing such problems are highlighted. This research has allowed the planning team at BT to understand the unique complexities of the nature of the problems they face in different areas of the UK, particularly with respect to the choice of number of operational units, and has strengthened their ability to design operational units effectively.},
  archive      = {J_EJOR},
  author       = {John H. Drake and Andrew Starkey and Gilbert Owusu and Edmund K. Burke},
  doi          = {10.1016/j.ejor.2019.02.002},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {729-740},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multiobjective evolutionary algorithms for strategic deployment of resources in operational units},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Units of measurement and directional distance functions with
optimal endogenous directions in data envelopment analysis.
<em>EJOR</em>, <em>282</em>(2), 712–728. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The virtual profit efficiency model is sensitive with respect to units of measurement as is the related directional distance function. It is shown that the model can be made invariant with respect to changes in units of measurement in a similar vein as the directional distance function. The geometric interpretation of changes in units of measurement in input output space is uncovered and shown to be similar to the interpretation of the underlying base model. A weighted virtual profit efficiency model with focus on input contractions and output expansions in selected dimensions is developed, and differences and similarities between the working of the weighted versus the unweighted base model are uncovered. It is demonstrated how to incorporate Assurance Regions and Cone Ratios in the virtual profit efficiency model.},
  archive      = {J_EJOR},
  author       = {Niels Christian Petersen},
  doi          = {10.1016/j.ejor.2019.09.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {712-728},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Units of measurement and directional distance functions with optimal endogenous directions in data envelopment analysis},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning and pricing models for repeated generalized
second-price auction in search advertising. <em>EJOR</em>,
<em>282</em>(2), 696–711. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In search advertising how much an advertiser is willing to pay for a click or tap on his search ad is private information, which hampers an ad seller’s ability to set the best reserve price to increase the revenue for the generalized second-price (GSP) auctions used to allocate ad slots. We present a series of learning and pricing models for repeated GSP auctions selling multiple heterogeneous items. This paper contributes to the literature in dynamic pricing with learning and complements the existing off-line studies on impact of the reserve price in the multi-billion dollar online advertising business. With few restrictions on the distribution function of the unknown parameter, algorithms are developed to estimate the empirical distribution function and determine the best reserve price to reduce the revenue loss (regret) over time. When bidders bid in the locally envy-free equilibrium, we present an algorithm that has the best attainable regret upper bound. When bidders do not bid in the locally envy-free equilibrium, we propose a GSP auction with position-specific reserve prices and develop an algorithm with the same regret bound to mitigate the risk of strategic bidding. With a high volatility involved, learning becomes more active while earning is more effective. When bidders coordinate bidding, the properly selected starting reserve prices can substantially reduce the revenue loss from possible collusive bidding behaviors.},
  archive      = {J_EJOR},
  author       = {Wei Yang and Baichun Xiao and Lifang Wu},
  doi          = {10.1016/j.ejor.2019.09.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {696-711},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Learning and pricing models for repeated generalized second-price auction in search advertising},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal acquisition and retention strategies in a duopoly
model of competition. <em>EJOR</em>, <em>282</em>(2), 677–695. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an optimal customer relationship marketing policy in a duopolistic market, where each firm’s market share depends on the CRM decisions of its own and of its competitors. The evolution process of the number of customers served by each firm is governed by a differential equation in which customer acquisition and retention processes are considered. A differential game model is presented to determine the optimal acquisition and retention expenditures of players. We derive a Nash equilibrium of a duopolistic differential game using the Hamilton–Jacobi–Bellman equations. Our results can be summarized mainly by the following three points. First, the optimal acquisition and retention expenditure strategies depend on each firm’s marginal customer equity, but not on the market share or the number of customers. Second, in response to the variation of the firm’s parameters, if its acquisition effectiveness is greater than its retention effectiveness, the firm would take action by making the same investment decision as its rival’s; instead, if its acquisition effectiveness is lower than its retention effectiveness, its rival would take action by making the different investment decision from the firm’s. Last, besides a mature product market, we also consider a market with remaining potential. In this case, a firm’s marginal customer equity can be decomposed into two components: the marginal customer equity from its own and from its rival’s. We show that the firm’s optimal investments in retention and acquisition are both positively related with a weighted difference between two components of the marginal customer equity.},
  archive      = {J_EJOR},
  author       = {Shuhua Chang and Zhaowei Zhang and Xinyu Wang and Yan Dong},
  doi          = {10.1016/j.ejor.2019.09.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {677-695},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal acquisition and retention strategies in a duopoly model of competition},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum excess dominance: Identifying impractical solutions
in linear problems with interval coefficients. <em>EJOR</em>,
<em>282</em>(2), 660–676. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the concept of maximum excess dominance (MED) and illustrate how it can be used to compare solutions in linear optimization problems with interval objective coefficients. When a solution dominates another solution with MED, the expected outcome of the former is guaranteed to be better than that of the latter across a wide range of probability distributions. Hence, MED can be used to eliminate dominated solutions from consideration. Furthermore, we provide an efficient way to check if a solution is dominated by another feasible solution in binary optimization problems and illustrate how dominated solutions can be pruned away by introducing MED constraints to the original binary optimization formulation. We also propose an algorithm to find the best non-dominated solution and conduct computational experiments to evaluate its performance.},
  archive      = {J_EJOR},
  author       = {Chunling Luo and Chin Hon Tan and Xiao Liu},
  doi          = {10.1016/j.ejor.2019.09.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {660-676},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maximum excess dominance: Identifying impractical solutions in linear problems with interval coefficients},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variable selection in data envelopment analysis.
<em>EJOR</em>, <em>282</em>(2), 644–659. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The selection of inputs and outputs in Data Envelopment Analysis (DEA) is regarded as an important step that is normally conducted before the DEA model is implemented. In this paper, we introduce cardinality constraints directly into the DEA program in order to select the relevant inputs and outputs automatically, without any previous statistical analysis, heuristic decision making or expert judgement (though our method is not incompatible with these other approaches and indeed may help to choose among them). The selection of variables is obtained solving a mixed integer linear program (MILP) which specifies the maximal number of variables to be used. The computational time of the program is fast in all practical situations. We explore the performance of the method via Monte Carlo simulations. Some empirical applications are considered in order to illustrate the usefulness of the method.},
  archive      = {J_EJOR},
  author       = {Antonio Peyrache and Christiern Rose and Gabriela Sicilia},
  doi          = {10.1016/j.ejor.2019.09.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {644-659},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Variable selection in data envelopment analysis},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Organizational vulnerability of digital threats: A first
validation of an assessment method. <em>EJOR</em>, <em>282</em>(2),
627–643. (<a href="https://doi.org/10.1016/j.ejor.2019.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Strengths, Vulnerability, and Intervention Assessment related to Digital Threats (SVIDT) method, which provides a problem structuring and decision support for organizational vulnerability and resilience management with respect to changes of the digital transition. The method starts from (i) a multi-level actor analysis, (ii) identifies strengths and weaknesses of organizations, (iii) constructs digital threat scenarios and provides judgment-based expert assessments on the organization&#39;s vulnerability, (iv) develops intervention scenarios for tangible threat scenarios, and (v) suggests win-win action scenarios when referring to the multi actor system analysis as for strategic management. A first validation and application includes a structural analysis of the response patterns and a quantitative and qualitative appraisal of the organizations’ managers. This validation is based on an application of the method to 18 German and Austrian organizations of different types and magnitude. We show how the basic concepts of vulnerability (i.e., sensitivity, exposure adaptive capacity) can be quantitatively operationalized when constructing consistent combinations of threat and intervention scenarios. The validation approaches indicate that the method provides meaningful data and assessments and that the managers provided a positive feedback on the method and the recommendations which they received. It is further deliberated whether the assessment method supports organizations’ specified resilience management in an overly complex, systemic digital transition in a (semi) quantitative manner. In addition, we discuss needs for future research regarding practical utility of SVIDT, as well as the positioning of SVIDT in relation to soft operational methods and other methods of operational research.},
  archive      = {J_EJOR},
  author       = {Roland W. Scholz and Reiner Czichos and Peter Parycek and Thomas J. Lampoltshammer},
  doi          = {10.1016/j.ejor.2019.09.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {627-643},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Organizational vulnerability of digital threats: A first validation of an assessment method},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bounded rationality in clearing service systems.
<em>EJOR</em>, <em>282</em>(2), 614–626. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a clearing service system where customers arrive according to a Poisson process, and decide to join the system or to balk in a boundedly rational manner. It assumes that all customers in the system are served at once when the server is available and times between consecutive services are independently and identically distributed random variables. Using logistic quantal-response functions to model bounded rationality, it first characterizes customer utility and system revenue for fixed price and degree of rationality, then solves the pricing problem of a revenue-maximizing system administrator. The analysis of the resulting expressions as functions of the degree of rationality yields several insights including: (i) for an individual customer, it is best to be perfectly rational if the price is fixed; however, when customers have the same degree of rationality and the administrator prices the service accordingly, a finite nonzero degree of rationality uniquely maximizes customer utility, (ii) system revenue grows arbitrarily large as customers tend to being irrational, (iii) social welfare is maximized when customers are perfectly rational, (iv) in all cases, at least 78\% of social welfare goes to the administrator. The paper also considers a model where customers are heterogeneous with respect to their degree of rationality, explores the effect of changes in distributional parameters of the degree of rationality for fixed service price, provides a characterization for the revenue-maximizing price, and discusses the analytical difficulties arising from heterogeneity in the degree of bounded rationality.},
  archive      = {J_EJOR},
  author       = {Pelin G. Canbolat},
  doi          = {10.1016/j.ejor.2019.10.013},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {614-626},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bounded rationality in clearing service systems},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On double-boundary non-crossing probability for a class of
compound processes with applications. <em>EJOR</em>, <em>282</em>(2),
602–613. (<a href="https://doi.org/10.1016/j.ejor.2019.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop an efficient method for computing the probability that a non-decreasing, pure jump (compound) stochastic process stays between arbitrary upper and lower boundaries (i.e., deterministic functions, possibly discontinuous) within a finite time period. The compound process is composed of a process modelling the arrivals of certain events (e.g., demands for a product in inventory systems, customers in queuing, or claims/capital gains in insurance/dual risk models), and a sequence of independent and identically distributed random variables modelling the sizes of the events. The events arrival process is assumed to belong to the wide class of point processes with conditional stationary independent increments which includes (non-)homogeneous Poisson, binomial, negative binomial, mixed Poisson and doubly stochastic Poisson (i.e., Cox) processes as special cases. The proposed method is based on expressing the non-exit probability through Chapman–Kolmogorov equations, re-expressing them in terms of a circular convolution of two vectors which is then computed applying fast Fourier transform (FFT). We further demonstrate that our FFT-based method is computationally efficient and can be successfully applied in the context of inventory management (to determine an optimal replenishment policy), ruin theory (to evaluate ruin probabilities and related quantities) and double-barrier option pricing or simply computing non-exit probabilities for Brownian motion with general boundaries.},
  archive      = {J_EJOR},
  author       = {Dimitrina S. Dimitrova and Zvetan G. Ignatov and Vladimir K. Kaishev and Senren Tan},
  doi          = {10.1016/j.ejor.2019.09.058},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {602-613},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On double-boundary non-crossing probability for a class of compound processes with applications},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing expected discounted cost in a queueing loss model
with discriminating arrivals. <em>EJOR</em>, <em>282</em>(2), 593–601.
(<a href="https://doi.org/10.1016/j.ejor.2019.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a queuing loss system with heterogeneous skill based servers and Poisson arrivals. We first assume that each arrival has a vector ( X 1 , … , X n X1,…,Xn ) of independent binary random variables with X i = 1 Xi=1 if server i is eligible to serve that arrival. The service time at server i is exponential with rate μ i . Arrivals finding no servers that are both idle and eligible to serve them are lost. Assuming the system incurs a cost of one unit for each lost customer, our goal is to find the optimal policy for assigning arrivals to idle and eligible servers so as to minimize the expected discounted cost of the system. Later, we generalize our model by considering k server pools where each pool i is eligible to serve arrivals with probability p i and all servers within this pool provide service at an exponential rate μ i .},
  archive      = {J_EJOR},
  author       = {Babak Haji and Sheldon Ross},
  doi          = {10.1016/j.ejor.2019.09.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {593-601},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Minimizing expected discounted cost in a queueing loss model with discriminating arrivals},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Considering emissions in the transit network design and
frequency setting problem with a heterogeneous fleet. <em>EJOR</em>,
<em>282</em>(2), 580–592. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban transportation contributes significantly to CO 2 emissions. Public transport systems are a good strategy to reduce these, but the emissions generated by public transport vehicles should not be neglected during the design of the service. The Transit Network Design and Frequency Setting Problem (TNDFSP) has usually been addressed considering only the passengers’ and the operator&#39;s point of view. However, we show it is worthwhile to consider also the emissions already during this planning phase. This paper proposes a memetic algorithm to address the bi-objective TNDFSP where both the total travel time and the CO 2 emissions are minimized. The analysis considers a heterogeneous fleet, meaning that buses of different sizes and technologies can be assigned under a budget constraint. The results on benchmark instances show that the proposed memetic algorithm performs as well as state-of-the-art algorithms where CO 2 emissions are not considered. In addition, several experiments are carried out to observe the effect of incorporating emissions and heterogeneous fleet into the model. The heterogeneous fleet allows reducing travel times and emissions at the same time, compared to solutions without a heterogeneous fleet. Moreover, the explicit minimization of CO 2 emissions within a bi-objective framework allows illustrating the trade-off between both objectives. Reductions of about 30\% in the emissions can be achieved by increasing the travel time only 1\%, while the costs for the operator remain the same. This clearly demonstrates the benefits of considering both the CO 2 emissions and a heterogeneous fleet during the design stage of public transport systems.},
  archive      = {J_EJOR},
  author       = {Javier Duran-Micco and Evert Vermeir and Pieter Vansteenwegen},
  doi          = {10.1016/j.ejor.2019.09.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {580-592},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Considering emissions in the transit network design and frequency setting problem with a heterogeneous fleet},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Should a manufacturer sell refurbished returns on the
secondary market to incentivize retailers to reduce consumer returns?
<em>EJOR</em>, <em>282</em>(2), 569–579. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumer electronics returns are typically returned by the retailer to the manufacturer for a full refund of the wholesale price. This practice does not sufficiently motivate the retailer to reduce the volume of returns. Different mechanisms have been proposed to incentivize the retailer to reduce returns, such as a reduced wholesale price for returns below a target, but they do not consider the subsequent disposition of returns. The high value of returns usually justifies refurbishment and resale. We study how competition between refurbished returns sold by the manufacturer and new products sold at the retailer affects retailer behavior. We find that the retailer never exerts more effort to reduce returns when faced with competition through the online store. The manufacturer’s profitability, however, is always higher with an online store. The online store is also preferable to a strategy where the manufacturer only partially refunds the retailer for returns.},
  archive      = {J_EJOR},
  author       = {Andrea Borenich and Yanick Dickbauer and Marc Reimann and Gilvan C. Souza},
  doi          = {10.1016/j.ejor.2019.09.049},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {569-579},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Should a manufacturer sell refurbished returns on the secondary market to incentivize retailers to reduce consumer returns?},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combating product label misconduct: The role of traceability
and market inspection. <em>EJOR</em>, <em>282</em>(2), 559–568. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traceability has become an important feature in supply chain management. It can be adopted to identify the sources of many quality problems. In this paper, we develop a game theoretical model to study the role of traceability in combating product label misconduct. Specifically, we consider an industrial organization that assigns product labels to its members to certify their products in an output market. However, a member of the organization may choose to sell its product label to an unregulated party that makes unqualified units. The organization can choose between a traceable product label system and an untraceable one. The former has the advantage of identifying the responsible member when the inspection detects an unqualified unit. We derive the optimal inspection polices of the two product label systems and demonstrate that the organization may incur a higher cost by adopting the traceable rather than untraceable label system. This non-intuitive result indicates that without a proper management mechanism in place, the adoption of a traceable product label system may backfire. We extend our base model and show that our main insights are robust in various settings.},
  archive      = {J_EJOR},
  author       = {Shiqing Yao and Kaijie Zhu},
  doi          = {10.1016/j.ejor.2019.09.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {559-568},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combating product label misconduct: The role of traceability and market inspection},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The split delivery vehicle routing problem with
three-dimensional loading constraints. <em>EJOR</em>, <em>282</em>(2),
545–558. (<a href="https://doi.org/10.1016/j.ejor.2019.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Split Delivery Vehicle Routing Problem with three-dimensional loading constraints (3L-SDVRP) combines vehicle routing and three-dimensional loading with additional packing constraints. In the 3L-SDVRP splitting deliveries of customers is basically possible, i.e. a customer can be visited in two or more tours. We examine essential problem features and introduce two problem variants. In the first variant, called 3L-SDVRP with forced splitting, a delivery is only split if the demand of a customer cannot be transported by a single vehicle. In the second variant, termed 3L-SDVRP with optional splitting, splitting customer deliveries can be done any number of times. We propose a hybrid algorithm consisting of a local search algorithm for routing and a genetic algorithm and several construction heuristics for packing. Numerical experiments are conducted using three sets of instances with both industrial and academic origins. One of them was provided by an automotive logistics company in Shanghai; in this case some customers per instance have a total freight volume larger than the loading space of a vehicle. The results prove that splitting deliveries can be beneficial not only in the one-dimensional case but also when goods are modeled as three-dimensional items.},
  archive      = {J_EJOR},
  author       = {Andreas Bortfeldt and Junmin Yi},
  doi          = {10.1016/j.ejor.2019.09.024},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {545-558},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The split delivery vehicle routing problem with three-dimensional loading constraints},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic mixed-model assembly line sequencing problem:
Mathematical modeling and q-learning based simulated annealing
hyper-heuristics. <em>EJOR</em>, <em>282</em>(2), 530–544. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a mixed-model sequencing problem with stochastic processing times (MMSPSP) in a multi-station assembly line. A new mixed-integer nonlinear programing model is developed to minimize weighted sum of expected total work-overload and idleness, which is converted into a mixed-integer linear programming model to deal with small-sized instances optimally. Due to the NP-hardness of the problem, this paper develops a novel hyper simulated annealing (HSA). The HSA employs a Q-learning algorithm to select appropriate heuristics through its search process. Numerical results are presented on several test instances and benchmark problems from the related literature. The results of statistical analysis indicate that the HSA is quite competitive in comparison with optimization software packages, and is significantly superior to several SA-based algorithms. The results highlight the advantages of the MMSPSP in comparison with traditional deterministic approaches in mixed-model sequencing contexts.},
  archive      = {J_EJOR},
  author       = {H. Mosadegh and S.M.T. Fatemi Ghomi and G.A. Süer},
  doi          = {10.1016/j.ejor.2019.09.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {530-544},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stochastic mixed-model assembly line sequencing problem: Mathematical modeling and Q-learning based simulated annealing hyper-heuristics},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The multi-visit team orienteering problem with precedence
constraints. <em>EJOR</em>, <em>282</em>(2), 515–529. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new variant of the Team Orienteering Problem (TOP) where precedence constraints are introduced. Each customer has a set of tasks that have to be accomplished according to a predefined order by an heterogeneous fleet of vehicles. If a customer is selected, then all the tasks have to be completed by possibly different vehicles. To tackle the problem, we propose an enhancement of the Kernel Search (KS) framework that makes use of different sorting strategies and compare its performance to a Branch-and-Cut algorithm embedding the dynamic separations of different valid inequalities and the use of a simplified KS as primal heuristic. The Branch-and-Cut strongly improves the performance of Gurobi when used to solve the compact problem formulation, whereas the variant of KS comes up to be an extremely effective approach also as primal heuristic embedded into a MIP solver. New benchmark instances and corresponding best known values are provided. Both solution approaches have also been tested on instances of the special case TOP providing extremely good results.},
  archive      = {J_EJOR},
  author       = {Saïd Hanafi and Renata Mansini and Roberto Zanotti},
  doi          = {10.1016/j.ejor.2019.09.045},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {515-529},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The multi-visit team orienteering problem with precedence constraints},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-cut algorithm for mixed-integer bilinear
programming. <em>EJOR</em>, <em>282</em>(2), 506–514. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the Mixed-Integer Bilinear Programming problem, a widely-used reformulation of the classical mixed-integer quadratic programming problem. For this problem we describe a branch-and-cut algorithm for its exact solution, based on a new family of intersection cuts derived from bilinear-specific disjunctions. We also introduce a new branching rule that is specifically designed for bilinear problems. We computationally analyze the behavior of the proposed algorithm on a large set of mixed-integer quadratic instances from the MINLPlib problem library. Our results show that our method, even without intersection cuts, is competitive with a state-of-the-art mixed-integer nonlinear solver. As to intersection cuts, their extensive use at each branching node tends to slow down the solver for most problems in our test bed, but they are extremely effective for some specific instances.},
  archive      = {J_EJOR},
  author       = {Matteo Fischetti and Michele Monaci},
  doi          = {10.1016/j.ejor.2019.09.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {506-514},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-cut algorithm for mixed-integer bilinear programming},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Machine scheduling with soft precedence constraints.
<em>EJOR</em>, <em>282</em>(2), 491–505. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new concept, soft precedence constraint (SPC), in machine scheduling problems. Similar to the conventional precedence constraint, SPC specifies some partial order over the jobs; however, an SPC can be violated, but with a certain penalty or cost. The scheduling problem is to balance the tradeoff between the SPC violation penalty and other criteria relative to job completion times. We focus on studying a special case where SPC is defined by a bipartite network. This case is motivated by the berth allocation problem at a transshipment port, where the SPC models any missed container connections from feeder vessels to ocean-going vessels. We discuss the complexity of the problems for different scenarios and develop approximation algorithms.},
  archive      = {J_EJOR},
  author       = {An Zhang and Xiangtong Qi and Guanhua Li},
  doi          = {10.1016/j.ejor.2019.09.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {491-505},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Machine scheduling with soft precedence constraints},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flow shops with reentry: Reversibility properties and
makespan optimal schedules. <em>EJOR</em>, <em>282</em>(2), 478–490. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider flow shops with job reentry. We first discuss how reversibility properties of conventional flow shops can be generalized to flow shop models with job reentry. We show under which conditions the makespan and job flow times are reversible. Second, we examine the problem of minimizing the makespan in ordered flow shops with job reentry. In particular, we focus on two special cases of the ordered flow shop that are referred to as machine-ordered and proportionate flow shops. We specify a class of cyclic schedules that have a makespan invariance property and minimize the makespan when each job follows the same route. We then examine makespan optimal schedules in a more generalized processing environment with loop effects on job processing times for which the makespan invariance property does not hold. Lastly, we present a dispatching rule that minimizes the makespan when considering a more general form of job recirculation with the route of each job not necessarily being the same.},
  archive      = {J_EJOR},
  author       = {Tae-Sun Yu and Michael Pinedo},
  doi          = {10.1016/j.ejor.2019.09.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {478-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flow shops with reentry: Reversibility properties and makespan optimal schedules},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shared processor scheduling of multiprocessor jobs.
<em>EJOR</em>, <em>282</em>(2), 464–477. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a problem of shared processor scheduling of multiprocessor weighted jobs. Each job can be executed on its private processor and simultaneously on possibly many processors shared by all jobs. This simultaneous execution reduces their completion times due to the processing time overlap. Each of the m shared processors may charge a different fee but otherwise the processors are identical. The goal is to maximize the total weighted overlap of all jobs. This is a key problem in subcontractor scheduling in extended enterprises and supply chains, and in divisible load scheduling in computing. We introduce synchronized schedules that complete each job that uses some shared processor at the same time on its private and on the shared processors. We prove that, quite surprisingly, the synchronized schedules include optimal ones. We obtain an α -approximation algorithm that runs in strongly polynomial time for the problem, where α = 1 / 2 + 1 / ( 4 ( m + 1 ) ) α=1/2+1/(4(m+1)) . This improves the 1/2-approximation reported recently in the literature to 5/8-approximation for a single shared processor problem, m = 1 m=1 . The computational complexity of the problem, both in case of single and multi-shared processor, remains open. We show however an LP-based optimal algorithm for antithetical instances where for any pair of jobs j and i , if the processing time of j is smaller than or equal to the processing time of i , then the weight of j is greater than or equal to the weight of i .},
  archive      = {J_EJOR},
  author       = {Dariusz Dereniowski and Wiesław Kubiak},
  doi          = {10.1016/j.ejor.2019.09.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {464-477},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Shared processor scheduling of multiprocessor jobs},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exact algebraic ϵ-constraint method for bi-objective
linear integer programming based on test sets. <em>EJOR</em>,
<em>282</em>(2), 453–463. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new exact algorithm for bi-objective linear integer problems is presented, based on the classic ϵ-constraint method and algebraic test sets for single-objective linear integer problems. Our method provides the complete Pareto frontier N N of non-dominated points and, for this purpose, it considers exactly | N | |N| single-objective problems by using reduction with test sets instead of solving with an optimizer. Although we use Gröbner bases for the computation of test sets, which may provoke a bottleneck in principle, the computational results are shown to be promising, especially for unbounded knapsack problems, for which any usual branch-and-cut strategy could be much more expensive. Nevertheless, this algorithm can be considered as a potentially faster alternative to IP-based methods when test sets are available.},
  archive      = {J_EJOR},
  author       = {María Isabel Hartillo-Hermoso and Haydee Jiménez-Tafur and José María Ucha-Enríquez},
  doi          = {10.1016/j.ejor.2019.09.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {453-463},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An exact algebraic ϵ-constraint method for bi-objective linear integer programming based on test sets},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A standard branch-and-bound approach for nonlinear
semi-infinite problems. <em>EJOR</em>, <em>282</em>(2), 438–452. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers nonlinear semi-infinite problems, which contain at least one semi-infinite constraint (SIC). The standard branch-and-bound algorithm is adapted to such problems by extending usual upper and lower bounding techniques for nonlinear inequality constraints to SICs. This is achieved by defining the interval evaluation of parametrized functions and their generalized gradients, by also adapting numerical constraint programming techniques to quantified inequalities, and by introducing linear relaxations and restrictions for SICs. The overall efficiency of our algorithm is demonstrated on a standard set of benchmarks from the literature, in comparison with the best state of the art alternative.},
  archive      = {J_EJOR},
  author       = {Antoine Marendet and Alexandre Goldsztejn and Gilles Chabert and Christophe Jermann},
  doi          = {10.1016/j.ejor.2019.10.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {438-452},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A standard branch-and-bound approach for nonlinear semi-infinite problems},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed point quasiconvex subgradient method. <em>EJOR</em>,
<em>282</em>(2), 428–437. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained quasiconvex optimization problems appear in many fields, such as economics, engineering, and management science. In particular, fractional programming, which models ratio indicators such as the profit/cost ratio as fractional objective functions, is an important instance. Subgradient methods and their variants are useful ways for solving these problems efficiently. Many complicated constraint sets onto which it is hard to compute the metric projections in a realistic amount of time appear in these applications. This implies that the existing methods cannot be applied to quasiconvex optimization over a complicated set. Meanwhile, thanks to fixed point theory, we can construct a computable nonexpansive mapping whose fixed point set coincides with a complicated constraint set. This paper proposes an algorithm that uses a computable nonexpansive mapping for solving a constrained quasiconvex optimization problem. We provide convergence analyses for constant diminishing step-size rules. Numerical comparisons between the proposed algorithm and an existing algorithm show that the proposed algorithm runs stably and quickly even when the running time of the existing algorithm exceeds the time limit.},
  archive      = {J_EJOR},
  author       = {Kazuhiro Hishinuma and Hideaki Iiduka},
  doi          = {10.1016/j.ejor.2019.09.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {428-437},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fixed point quasiconvex subgradient method},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inverse optimization for the recovery of constraint
parameters. <em>EJOR</em>, <em>282</em>(2), 415–427. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most inverse optimization models impute unspecified parameters of an objective function to make an observed solution optimal for a given optimization problem with a fixed feasible set. We propose two approaches to impute unspecified left-hand-side constraint coefficients in addition to a cost vector for a given linear optimization problem. The first approach identifies parameters minimizing the duality gap, while the second minimally perturbs prior estimates of the unspecified parameters to satisfy strong duality, if it is possible to satisfy the optimality conditions exactly. We apply these two approaches to the general linear optimization problem. We also use them to impute unspecified parameters of the uncertainty set for robust linear optimization problems under interval and cardinality constrained uncertainty. Each inverse optimization model we propose is nonconvex, but we show that a globally optimal solution can be obtained either in closed form or by solving a linear number of linear or convex optimization problems.},
  archive      = {J_EJOR},
  author       = {Timothy C.Y. Chan and Neal Kaw},
  doi          = {10.1016/j.ejor.2019.09.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {415-427},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Inverse optimization for the recovery of constraint parameters},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of operational spare parts service logistics in
service control towers. <em>EJOR</em>, <em>282</em>(2), 401–414. (<a
href="https://doi.org/10.1016/j.ejor.2019.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we provide an overview of operational spare parts planning in service control towers. We conduct company surveys to identify the issues, the challenges, and the needs in practice. We propose a classification framework to reveal the key aspects of operational planning decisions, and to provide an overview of the scientific literature. We identify promising research directions. These include incorporating service level agreements in operational decision making, managing exception messages, integrating tactical and operational plans, using advance supply and demand information for operational interventions, and developing a unified and holistic approach for selecting interventions in large scale systems.},
  archive      = {J_EJOR},
  author       = {E. Topan and A.S. Eruguz and Ma W. and M.C. van der Heijden and R. Dekker},
  doi          = {10.1016/j.ejor.2019.03.026},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {401-414},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A review of operational spare parts service logistics in service control towers},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the denominator rule and a theorem by janos aczél.
<em>EJOR</em>, <em>282</em>(1), 398–400. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note we compare and contrast arithmetic and geometric share-weighting aggregations of ratio expressions (i.e., relative scores) and we provide conditions under which they result in approximately the same value of the aggregate measure. We also provide some comparative empirical results about the differences among the suggested alternative aggregate measures.},
  archive      = {J_EJOR},
  author       = {Rolf Färe and Giannis Karagiannis},
  doi          = {10.1016/j.ejor.2019.09.013},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {398-400},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the denominator rule and a theorem by janos aczél},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weak comonotonicity. <em>EJOR</em>, <em>282</em>(1),
386–397. (<a href="https://doi.org/10.1016/j.ejor.2019.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical notion of comonotonicity has played a pivotal role when solving diverse problems in economics, finance, and insurance. In various practical problems, however, this notion of extreme positive dependence structure is overly restrictive and sometimes unrealistic. In the present paper, we put forward a notion of weak comonotonicity, which contains the classical notion of comonotonicity as a special case, and gives rise to necessary and sufficient conditions for a number of optimization problems, such as those arising in portfolio diversification, risk aggregation, and premium calculation. In particular, we show that a combination of weak comonotonicity and weak antimonotonicity with respect to some choices of measures is sufficient for the maximization of Value-at-Risk aggregation, and weak comonotonicity is necessary and sufficient for the Expected Shortfall aggregation. Finally, with the help of weak comonotonicity acting as an intermediate notion of dependence between the extreme cases of no dependence and strong comonotonicity, we give a natural solution to a risk-sharing problem.},
  archive      = {J_EJOR},
  author       = {Ruodu Wang and Ričardas Zitikis},
  doi          = {10.1016/j.ejor.2019.09.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {386-397},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Weak comonotonicity},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). American step options. <em>EJOR</em>, <em>282</em>(1),
363–385. (<a href="https://doi.org/10.1016/j.ejor.2019.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the valuation of American knock-out and knock-in step options. The structures of the immediate exercise regions of the various contracts are identified. Typical properties of American vanilla calls, such as uniqueness of the optimal exercise boundary, up-connectedness of the exercise region or convexity of its t-section, are shown to fail in some cases. Early exercise premium representations of step option prices, involving the Laplace transforms of the joint laws of Brownian motion and its occupation times, are derived. Systems of coupled integral equations for the components of the exercise boundary are deduced. Numerical implementations document the behavior of the price and the hedging policy. The paper is the first to prove that finite maturity exotic American options written on a single underlying asset can have multiple disconnected exercise regions described by a triplet of coupled boundaries.},
  archive      = {J_EJOR},
  author       = {Jérôme Detemple and Souleymane Laminou Abdou and Franck Moraux},
  doi          = {10.1016/j.ejor.2019.09.009},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {363-385},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {American step options},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal dynamic reinsurance policies under a generalized
denneberg’s absolute deviation principle. <em>EJOR</em>,
<em>282</em>(1), 345–362. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the optimal dynamic reinsurance policy for an insurance company whose surplus is modeled by the diffusion approximation of the classical Cramér–Lundberg model. We assume the reinsurance premium is calculated according to a proposed Mean-CVaR premium principle which generalizes Denneberg’s absolute deviation principle and expected value principle. Moreover, we require that both ceded loss and retention functions are non-decreasing to rule out moral hazard. Under the objective of minimizing the ruin probability, we obtain the optimal reinsurance policy explicitly and we denote the resulting treaty as the dual excess-of-loss reinsurance. This form of the optimal treaty is new to the literature and lends support to the fact that reinsurance contracts in practice often involve layers. It also demonstrates that reinsurance treaties such as the proportional and the standard excess-of-loss, which are typically found to be optimal in the dynamic reinsurance model, need not be optimal when we consider a more general optimization model. We also consider other generalizations including (i) allowing the insurer to manage its business through both reinsurance and investment; and (ii) N -piecewise Mean-CVaR premium principle. In the former case, we not only show that the dual excess-of-loss reinsurance policy remains optimal, but also demonstrate that investing in stock can further enhance insurer’s financial stability with lower ruin probability. For the latter case, we establish that the optimal reinsurance treaty can have at most N layers, which is also more consistent with practice.},
  archive      = {J_EJOR},
  author       = {Ken Seng Tan and Pengyu Wei and Wei Wei and Sheng Chao Zhuang},
  doi          = {10.1016/j.ejor.2019.08.053},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {345-362},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal dynamic reinsurance policies under a generalized denneberg’s absolute deviation principle},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shortest path tour problem with time windows. <em>EJOR</em>,
<em>282</em>(1), 334–344. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at studying a new variant of the shortest path tour problem, where time window constraints are taken into account. This is the first work dealing with the shortest path tour problem with time windows. The problem is formally described and its theoretical properties are analyzed. We prove that it belongs to the NP-hard class of complexity by polynomial reduction from the knapsack problem. An optimal solution approach based on the dynamic programming paradigm is devised. Labelling algorithms are defined along with well-tailored pruning strategies based on cost and time. The correctness of the bounding strategies is proven and the empirical behavior is analyzed in depth. In order to evaluate the performance of the proposed approach, extensive computational experiments have been carried out on a significant set of test problems derived from benchmarks for the shortest path tour problem. Sensitivity analysis is carried out by considering both algorithmic and instance parameters.},
  archive      = {J_EJOR},
  author       = {Luigi Di Puglia Pugliese and Daniele Ferone and Paola Festa and Francesca Guerriero},
  doi          = {10.1016/j.ejor.2019.08.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {334-344},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Shortest path tour problem with time windows},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring and decomposing productivity change in the
presence of mergers. <em>EJOR</em>, <em>282</em>(1), 319–333. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managers and policymakers often encourage mergers and acquisitions of companies with the aim of increasing the productivity of the involved firms. However, problems with the measurement of productivity change usually occur when analyzing companies that merged during the period under consideration: while only individual predecessor firms exist in the base period, in the following period only the integrated company is observable. We therefore propose a new adaptation of the Malmquist index that is appropriate in the presence of mergers, which also allows for a detailed analysis of their effects on productivity change. Moreover, we believe that our methodological approach provides a useful widely applicable tool to identify the contribution of past mergers to productivity growth. We illustrate our merger consistent productivity decomposition, by using a sample of Japanese water supply systems observed in 2003, and the resulting consolidated and non-consolidated systems observed in 2009. On average, we find that mergers contributed positively to productivity change and that our merger consistent decomposition contributes to a better understanding of the determinants of productivity performance in the Japanese water sector.},
  archive      = {J_EJOR},
  author       = {Pablo Arocena and David S. Saal and Takuya Urakami and Michael Zschille},
  doi          = {10.1016/j.ejor.2019.08.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {319-333},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring and decomposing productivity change in the presence of mergers},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An unpunctual preventive maintenance policy under
two-dimensional warranty. <em>EJOR</em>, <em>282</em>(1), 304–318. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the business-to-consumer context, e.g., the automobile industry, preventive maintenance (PM) of warranted items usually relies upon customers to return their items to authorized maintenance centers according to prescribed schedules. However, item owners may be unpunctual, causing actual maintenance instants deviating from scheduled instants. This paper studies the impact of customer unpunctuality on the optimization of PM policy and the resultant warranty expenses. An unpunctual imperfect PM policy, which allows customers to advance or postpone scheduled PM activities in a tolerated range, is proposed for repairable items sold with a two-dimensional warranty. The expected total warranty costs of the unpunctual (and punctual) PM policies are derived under the assumption that customer unpunctuality is governed by a specific probability distribution. The optimization and comparison of the two policies are investigated in different scenarios regarding the product’s failure rate function. The results for two possible unpunctuality distributions—uniform and triangular—are discussed and compared. Numerical studies show that the expected total warranty cost of the unpunctual policy could be either higher or lower than that of the punctual policy, depending on customer behaviors and the shape of failure rate function. Accordingly, manufacturers could induce customers to adjust their unpunctuality behaviors by modifying PM policies or introducing penalty/bonus mechanisms.},
  archive      = {J_EJOR},
  author       = {Xiaolin Wang and Lishuai Li and Min Xie},
  doi          = {10.1016/j.ejor.2019.09.025},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {304-318},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An unpunctual preventive maintenance policy under two-dimensional warranty},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-period orienteering with uncertain adoption likelihood
and waiting at customers. <em>EJOR</em>, <em>282</em>(1), 288–303. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a multi-period orienteering problem in which a salesperson visits customers to provide information on product and service offerings that may lead to eventual adoptions at the end of the problem horizon. Upon arriving at a customer, the salesperson may experience uncertain wait time that delays or prevents the salesperson from meeting with the customer within the customer’s time window. A customer’s adoption probability evolves stochastically from period to period depending on whether the salesperson meets with the customer. To maximize the expected sales accrued from product adoptions at the end of the horizon, the salesperson must decide in which period(s) to visit the customers and what sequence to visit the customers within each period. We formally model this problem as a Markov decision process. To overcome the computational challenges induced by the large state and action space, we propose a two-stage heuristic approach to facilitate decision making. In the first stage, we solve an assignment problem to determine which customers to visit in the current period. In the second stage, we solve a routing problem to determine the sequence to visit the selected customers. In the computational experiments, we demonstrate the effectiveness of our heuristic methods.},
  archive      = {J_EJOR},
  author       = {Shu Zhang and Jeffrey W. Ohlmann and Barrett W. Thomas},
  doi          = {10.1016/j.ejor.2019.09.023},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {288-303},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-period orienteering with uncertain adoption likelihood and waiting at customers},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A generalization of the aumann–shapley value for risk
capital allocation problems. <em>EJOR</em>, <em>282</em>(1), 277–287.
(<a href="https://doi.org/10.1016/j.ejor.2019.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a new method to allocate risk capital to divisions or lines of business within a firm. Existing literature advocates an allocation rule that, in game-theoretic terms, is equivalent to using the Aumann–Shapley value as allocation mechanism. The Aumann–Shapley value, however, is only well-defined if a specific differentiability condition is satisfied. The rule that we propose is characterized as the limit of an average of path-based allocation rules with grid size converging to zero. The corresponding allocation rule is equal to the Aumann–Shapley value if it exists. If the Aumann–Shapley value does not exist, the allocation rule is equal to the weighted average of the Aumann–Shapley values of “nearby” capital allocation problems.},
  archive      = {J_EJOR},
  author       = {Tim J. Boonen and Anja De Waegenaere and Henk Norde},
  doi          = {10.1016/j.ejor.2019.09.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {277-287},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A generalization of the Aumann–Shapley value for risk capital allocation problems},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the importance of variability when managing metrology
capacity. <em>EJOR</em>, <em>282</em>(1), 267–276. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-line quality control is a crucial and increasingly constraining activity, in particular in high technology manufacturing. In this paper, we study a single metrology tool assigned to control the production quality of multiple heterogeneous machines. We introduce, model and study the tradeoff between the quality loss resulting from the sampling policy, and the quality loss induced by delays in the metrology queue. An iterative approach is proposed to optimize sampling periods using the solution of a relaxed problem which assumes full synchronization between production and metrology, and which has been previously formalized and solved. Based on computational and simulation results, and a prediction model, the paper ends with recommendations to better manage metrology capacity utilization under various levels of variability.},
  archive      = {J_EJOR},
  author       = {Stéphane Dauzère-Pérès and Michael Hassoun},
  doi          = {10.1016/j.ejor.2019.09.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {267-276},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the importance of variability when managing metrology capacity},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical approach to the shelf-space allocation and
replenishment problem with heterogeneously sized shelves. <em>EJOR</em>,
<em>282</em>(1), 252–266. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the shelf-space and replenishment problem where a retailer must decide how much shelf space to assign to items and how frequently to replenish retail shelves. Since space is limited, these two decisions are interdependent. Existing optimization models approximate shelf sizes by reducing the shelf to a one-dimensional space. However, in practice shelf sizes and their shelf segments vary in width, height and depth. Without considering the actual shelf dimensions, results from optimization models cannot be transferred to actual shelves. To account for these constraints, we propose the first shelf-space model capable of modeling three-dimensional shelf characteristics. Our model determines optimal shelf quantities, an item’s optimal shelf segment, as well as optimal replenishment frequencies. To do this we include a space-elastic function that impacts the customer demand for an item depending on its allocated shelf space. We also consider different shelf segments in different positions. To solve the non-linear integer problem (NLIP), we develop an optimal solution approach based on precalculations to transfer the model into a binary-integer problem that considers logical item-specific bounds to significantly reduce computation time. We conduct various numerical analyses. First, we show that results are generated time-efficiently, even for large-scale data instances. We then analyze the extent to which the stylized assumption of a one-dimensional space results in non-feasible solutions in practice, thus underlining the necessity of our multi-dimensional model. Finally, the results of a field test in which model solutions were actually applied in practice show how one of the largest German grocery retailers was able to increase its profits across different categories and stores by 9.1\% on average compared to a control group by using the approach.},
  archive      = {J_EJOR},
  author       = {Tobias Düsterhöft and Alexander Hübner and Kai Schaal},
  doi          = {10.1016/j.ejor.2019.09.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {252-266},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A practical approach to the shelf-space allocation and replenishment problem with heterogeneously sized shelves},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing of reusable resources under ambiguous distributions
of demand and service time with emerging applications. <em>EJOR</em>,
<em>282</em>(1), 235–251. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monopolistic pricing models for revenue management are widely used in practice to set prices of multiple products with uncertain demand arrivals. The literature often assumes deterministic time of serving each demand and that the distribution of uncertainty is fully known. In this paper, we consider a new class of revenue management problems inspired by emerging applications such as cloud computing and city parking, where we dynamically determine prices for multiple products sharing limited resource and aim to maximize the expected revenue over a finite horizon. Random demand of each product arrives in each period, modeled by a function of the arrival time, product type, and price. Unlike the traditional monopolistic pricing, here each demand stays in the system for uncertain time. Both demand and service time follow ambiguous distributions, and we formulate robust deterministic approximation models to construct efficient heuristic fixed-price pricing policies. We conduct numerical studies by testing cloud computing service pricing instances based on data published by the Amazon Web Services (AWS) and demonstrate the efficacy of our approach for managing revenue and risk under various distributions of demand and service time.},
  archive      = {J_EJOR},
  author       = {Xuan Vinh Doan and Xiao Lei and Siqian Shen},
  doi          = {10.1016/j.ejor.2019.09.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {235-251},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing of reusable resources under ambiguous distributions of demand and service time with emerging applications},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the learning patterns and adaptive behavior of terrorist
organizations. <em>EJOR</em>, <em>282</em>(1), 221–234. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The threat to national security posed by terrorists makes the design of evidence-based counter-terrorism strategies paramount. As terrorist organizations are purposeful entities, it is crucial to understand their decision processes if we want to plan defenses and counter-measures. In particular, there is evidence that terrorist organizations are both adaptive in their behavior and driven by multiple objectives in their actions. In this paper, we use insights from learning theory and compare several different reinforcement learning models regarding their ability to predict terrorist organizations’ actions. Using data on target choices of terrorist attacks and two different objectives (renown and revenge), we show that a total reinforcement learning with power (Luce) choice probabilities and information discounting can be used to model the adaptive behavior of terrorist organizations. The model renders out-of-sample predictions which are comparable in their validity to those observed for learning in laboratory studies. We draw implications for counter-terrorism strategies by comparing the predictive validity of the different models and their calibrated parameters. Our results also offer a starting point for studying the convergence process in game theoretic analyses of conflicts involving terrorists.},
  archive      = {J_EJOR},
  author       = {Johannes G. Jaspersen and Gilberto Montibeller},
  doi          = {10.1016/j.ejor.2019.09.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {221-234},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the learning patterns and adaptive behavior of terrorist organizations},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competitive bidding in asymmetric multidimensional public
procurement. <em>EJOR</em>, <em>282</em>(1), 211–220. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multidimensional procurement auction, such as a most economically advantageous tender, asymmetric opponents, with different cost structure and predetermined quality, compete for the highest score, which combines price and quality. Production inefficiency characterizes each tenderer. We derive the equilibrium equations and boundary conditions, for which closed-form solutions are not available. We compare the bidding behavior of any pair of rival tenderers and demonstrate that equilibrium prices critically depend on the comparison of the cost difference Δ c with respect to the increment of score attribute s . For the same production inefficiency, a tenderer with a relatively higher Δ c compared to s , stands in weak competitive position and is forced to bid more aggressively. We show how the opposing advantage of each bidder with respect to cost or score attribute induces the extent of competition. Under a different perspective, we analyze bidding by a pair of tenderers for a given maximum score, achieved when pricing is at cost. Our analysis reveals that the player with consistently higher percentage change of the probability of being more efficient than the rival, is in a disadvantageous position and receives lower score in the awarding process. Our results are useful for tenderers in assessing their competitive position. The findings enable contracting authorities to evaluate competition at the preliminary stage of design and to examine the effects of the awarding criterion on pricing.},
  archive      = {J_EJOR},
  author       = {Panos L. Lorentziadis},
  doi          = {10.1016/j.ejor.2019.09.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {211-220},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive bidding in asymmetric multidimensional public procurement},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On preference elicitation processes which mitigate the
accumulation of biases in multi-criteria decision analysis.
<em>EJOR</em>, <em>282</em>(1), 201–210. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the practice of multi-criteria decision analysis, biased responses to the preference elicitation questions may impact the outcome of the process. In particular, there is a risk that the effects of biases accumulate in favor of a single alternative or a subset of alternatives. In this paper, we develop new bias mitigation techniques for multi-criteria decision analysis, which are based on the idea that the effects of biases can cancel out each other in the preference elicitation process. The benefits of the techniques include that the decision maker does not need to try to change her behavior to avoid biases, and there are no numerical adjustments of her judgements. The new techniques that we propose are: (1). Introducing a virtual reference alternative in the decision problem. (2). Introducing an auxiliary measuring stick attribute. (3). Rotating the reference point. (4). Restarting the decision process at an intermediate step with a reduced set of alternatives. We simulate computationally how these techniques help mitigate biases in the Even Swaps process when the decision maker exhibits the loss aversion bias, the measuring stick bias, and makes random response errors. The techniques can also be applied in weight elicitation using the SWING and trade-off methods to reduce the aforementioned biases.},
  archive      = {J_EJOR},
  author       = {Tuomas J. Lahtinen and Raimo P. Hämäläinen and Cosmo Jenytin},
  doi          = {10.1016/j.ejor.2019.09.004},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {201-210},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On preference elicitation processes which mitigate the accumulation of biases in multi-criteria decision analysis},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competitive location and pricing on a line with metric
transportation costs. <em>EJOR</em>, <em>282</em>(1), 188–200. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a three-level non-capacitated location/pricing problem: a firm first decides which facilities to open, out of a finite set of candidate sites, and sets service prices with the aim of revenue maximization; then a second firm makes the same decisions after checking competing offers; finally, customers make individual decisions trying to minimize costs that include both purchase and transportation. A restricted two-level problem can be defined to model an optimal reaction of the second firm to known decision of the first. For non-metric costs, the two-level problem corresponds to Envy-free Pricing or to a special Network Pricing problem, and is APX APX -complete even if facilities can be opened at no fixed cost. Our focus is on the metric 1-dimensional case, a model where customers are distributed on a main communication road and transportation cost is proportional to distance. We describe polynomial-time algorithms that solve two- and three-level problems with opening costs and single 1 st level facility. Quite surprisingly, however, even the two-level problem with no opening costs becomes NP NP -hard when two 1 st level facilities are considered.},
  archive      = {J_EJOR},
  author       = {Claudio Arbib and Mustafa Ç. Pınar and Matteo Tonelli},
  doi          = {10.1016/j.ejor.2019.08.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {188-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competitive location and pricing on a line with metric transportation costs},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aggregation of inputs and outputs prior to data envelopment
analysis under big data. <em>EJOR</em>, <em>282</em>(1), 172–187. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to explore the possible solutions to a ‘big data’ problem related to the very large dimensions of input–output data. In particular, we focus on the cases of severe ‘curse of dimensionality’ problem that require dimension-reduction prior to using Data Envelopment Analysis. To achieve this goal, we have presented some theoretical grounds and performed a new to the literature simulation study where we explored the price-based aggregation as a solution to address the problem of very large dimensions.},
  archive      = {J_EJOR},
  author       = {Valentin Zelenyuk},
  doi          = {10.1016/j.ejor.2019.08.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {172-187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Aggregation of inputs and outputs prior to data envelopment analysis under big data},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cybersecurity investments in the supply chain: Coordination
and a strategic attacker. <em>EJOR</em>, <em>282</em>(1), 161–171. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybersecurity poses a difficult challenge to supply chains, as a firm may be affected by an attack on another firm in the supply chain. For example, a retailer’s consumer data might be compromised via an attack on a supplier. In general, individual nodes in a supply chain bear the entire cost of their own cybersecurity investments, but some of the benefits of the investments may be enjoyed by the other nodes as well. We analyze the differences between coordinated and uncoordinated cybersecurity investments, as well as the differences resulting from a strategic and a non-strategic attacker. We find that lack of coordination leads to underinvestment with a non-strategic attacker, but that this is somewhat counterbalanced by an attacker being strategic. Lack of coordination may lead to either underinvestment or overinvestment with a strategic attacker, depending on how large the indirect damages from attacks are relative to the direct damages; overinvestment is more likely if indirect damages are relatively minor. A numerical example is provided to illustrate the impacts of and relationships between coordinated investments and a strategic attacker.},
  archive      = {J_EJOR},
  author       = {Jay Simon and Ayman Omar},
  doi          = {10.1016/j.ejor.2019.09.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {161-171},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Cybersecurity investments in the supply chain: Coordination and a strategic attacker},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Measuring and mitigating the effects of cost disturbance
propagation in multi-echelon apparel supply chains. <em>EJOR</em>,
<em>282</em>(1), 148–160. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supply chains operating in informal sector of emerging economies are mostly characterised by inefficiencies, highly price sensitive customers, fragmented markets, frequent operational disturbances, and members with irrational profit seeking behaviour (naïve members). We focus on cost disturbances and measure their effects in terms of demand variation (QV) in muti-echelon informal supply chain. We show how naïve members contribute to amplification and transmission of QV across the supply chain. Strategic members (characterised by rational profit seeking behaviour) on the contrary, dampens the transmission of QV. Efficient reconfiguration solutions are proposed which minimize the QV for a specific cost disturbance scenario. Rational profit seeking behaviour is one of the criteria for selecting members in this reconfiguration. Rapid reconfiguration in these supply chains is possible due to the existence of informal contracts. A robust deviation reconfiguration solution is also proposed which performs satisfactorily over entire disturbance scenario set. Goodness of this solution is evaluated according to two metrics; namely cost penalty and robust efficiency. Lastly, an illustrative case study on apparel supply chain is presented and it is inferred from the discussion that large aggregators are both cost and robust efficient, hence their presence in supply chain improves performance of robust solution along the two metrics (cost penalty, robust efficiency).},
  archive      = {J_EJOR},
  author       = {Priyank Sinha and Sameer Kumar and Surya Prakash},
  doi          = {10.1016/j.ejor.2019.09.015},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {148-160},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring and mitigating the effects of cost disturbance propagation in multi-echelon apparel supply chains},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A lexicographic minimax approach to the vehicle routing
problem with route balancing. <em>EJOR</em>, <em>282</em>(1), 129–147.
(<a href="https://doi.org/10.1016/j.ejor.2019.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing problems generally aim at designing routes that minimize transportation costs. However, in practical settings, many companies also pay attention at how the workload is distributed among its drivers. Accordingly, two main approaches for balancing the workload have been proposed in the literature. They are based on minimizing the duration of the longest route, or the difference between the longest and the shortest routes, respectively. Recently, it has been shown on several occasions that both approaches have some flaws. In order to model equity we investigate the lexicographic minimax approach, which is rooted in social choice theory. We define the leximax vehicle routing problem which considers the bi-objective optimization of transportation costs and of workload balancing. This problem is solved by a heuristic based on the multi-directional local search framework. It involves dedicated large neighborhood search operators. Several LNS operators are proposed and compared in experimentations.},
  archive      = {J_EJOR},
  author       = {Fabien Lehuédé and Olivier Péton and Fabien Tricoire},
  doi          = {10.1016/j.ejor.2019.09.010},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {129-147},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A lexicographic minimax approach to the vehicle routing problem with route balancing},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Capacity and assortment planning under one-way
supplier-driven substitution for pharmacy kiosks with low drug demand.
<em>EJOR</em>, <em>282</em>(1), 108–128. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MedAvail Technologies Inc. is a healthcare technology company that develops new technologies for self-serve pharmacy solutions. The technology, called MedCenter, is a pharmacy kiosk that provides 24/7, easy, and reliable access to pre-packaged prescription drugs and over the counter medications. To meet its business goals of having the right medication in the right kiosk at the right quantity, MedAvail faces several challenges related to assortment and stocking decisions of medications in the kiosk limited by kiosk capacity. This research addresses these decisions through an analytics project aimed at analyzing pharmaceutical sales, determining optimized kiosk storage capacity and service levels, and recommending assortment, stocking, and supplier-driven product substitution guidelines. We developed several mixed integer optimization models that use sales data to obtain robust solutions with respect to randomness in demand. We perform extensive testing using real as well as randomly generated data, and under multiple substitution rules, replenishment guidelines, and demand prediction strategies. Our results show that supplier-driven product substitution could save up to 9\% in storage capacity depending on the desired service level and characteristics of product demand. We also propose a column-generation based heuristic approach that, on average, obtains near optimal solutions within 1.1\% of optimality gap while reducing computational times by a factor of three.},
  archive      = {J_EJOR},
  author       = {Gohram Baloch and Fatma Gzara},
  doi          = {10.1016/j.ejor.2019.09.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {108-128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capacity and assortment planning under one-way supplier-driven substitution for pharmacy kiosks with low drug demand},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coordination mechanism, risk sharing, and risk aversion in a
five-level textile supply chain under demand and supply uncertainty.
<em>EJOR</em>, <em>282</em>(1), 93–107. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The textile supply chain has attracted worldwide attention because of its high volatility in apparel and cotton production due to coordination issue and yield uncertainty. In this context, existing analytical works related to coordination are restricted to a dyadic apparel retailer–manufacturer setting under demand uncertainty for the conventional manufacturer-led scenario. Several issues, such as the holistic depiction of the textile supply chain, impact of cotton production uncertainty, coordination mechanism for the emerging retailer-led scenario, and profitability issue of cotton firms, have not been paid enough attention. We propose an analytical model for a textile supply chain by adopting a five-level structure that comprises an apparel retailer, apparel manufacturer, textile firm, fiber firm, and cotton firm under simultaneous demand and supply uncertainty using a wholesale price contract. The wholesale price contract fails to coordinate the supply chain. Next, we show how the buyback contract and option contract coordinate this supply chain under manufacturer-led and retailer-led scenarios, respectively. Additionally, we discuss the improvement of cotton firm&#39;s profitability using a risk-sharing mechanism between the cotton firm and the fiber firm for the high loss-making scenarios. Also, we demonstrate how the risk-averse attitude of both the apparel retailers and the cotton firms can lead to the unsold cotton inventory problem. As extensions, first, we devise joint pricing and order quantity decision of apparel. Finally, we consider production uncertainties for all middle-level members in our proposed model and devise a buyback bidirectional sales rebate penalty contract for coordination.},
  archive      = {J_EJOR},
  author       = {Arnab Adhikari and Arnab Bisi and Balram Avittathur},
  doi          = {10.1016/j.ejor.2019.08.051},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {93-107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordination mechanism, risk sharing, and risk aversion in a five-level textile supply chain under demand and supply uncertainty},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic auto-adaptive predictive maintenance policy for
degradation with unknown parameters. <em>EJOR</em>, <em>282</em>(1),
81–92. (<a href="https://doi.org/10.1016/j.ejor.2019.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of monitoring equipment, research on condition-based maintenance (CBM) is rapidly growing. CBM optimization aims to find an optimal CBM policy which minimizes the average cost of the system over a specified duration of time. This paper proposes a dynamic auto-adaptive predictive maintenance policy for single-unit systems whose gradual deterioration is governed by an increasing stochastic process. The parameters of the degradation process are assumed to be unknown and Bayes’ theorem is used to update the prior information. The time interval between two successive inspections is scheduled based on the remaining useful life (RUL) of the system and is updated along with the degradation parameters. A procedure is proposed to dynamically adapt the maintenance decision variables accordingly. Finally, different possible maintenance policies are considered and compared to illustrate their performance.},
  archive      = {J_EJOR},
  author       = {E. Mosayebi Omshi and A. Grall and S. Shemehsavar},
  doi          = {10.1016/j.ejor.2019.08.050},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {81-92},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic auto-adaptive predictive maintenance policy for degradation with unknown parameters},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Under what conditions can an application service firm with
in-house computing benefit from cloudbursting? <em>EJOR</em>,
<em>282</em>(1), 71–80. (<a
href="https://doi.org/10.1016/j.ejor.2018.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloudbursting, a hybrid cloud computing model, helps firms supplement their internal computing capacity from a private cloud by using external computing resources from a public cloud to meet increased demand. This paper examines whether cloudbursting benefits an application service firm that uses only its in-house capacity. Cloudbursting provides computing scalability and cost-effectiveness, but poses potential risks from data leakage when bursting into a public cloud. A private cloud reduces such risks, however, is constrained by resource limitations. We develop quantitative models under both non-competitive and competitive systems, and then determine the best choice between cloudbursting and a private cloud. Overall, we show that a profit-maximizing firm will benefit from migrating to cloudbursting if risk is considerably low and will maintain a private cloud if risk is considerably high. Interestingly, one exception occurs in a competition system whereby two competing firms access external resources as needed from the same public cloud. In this case, one firm will counterintuitively remain in a private cloud even though risk is considerably low while its competitor will migrate to cloudbursting. The numerical study conducts a sensitivity analysis to link a firm&#39;s profit performance with its best cloud choice.},
  archive      = {J_EJOR},
  author       = {Chen Li-Ming and Chang Wei-Lun},
  doi          = {10.1016/j.ejor.2018.11.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {71-80},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Under what conditions can an application service firm with in-house computing benefit from cloudbursting?},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Empirical orthogonal constraint generation for
multidimensional 0/1 knapsack problems. <em>EJOR</em>, <em>282</em>(1),
58–70. (<a href="https://doi.org/10.1016/j.ejor.2019.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing techniques for solving large Multidimensional Knapsack Problems (MKP) aim at reducing the number of variables (items). While these approaches solve problems with many items efficiently, their performance declines with increasing number of constraints. We propose empirical orthogonal constraint generation (EOCG) to reduce the number of constraints. The intuition is that, geometrically, each constraint is a dimension of a hypercube, with capacity as side length, while items correspond to vectors with their weights as coordinates along the dimensions–the basis vectors. MKP problems guarantee the feasibility of a solution by one constraint on the coordinate sum for each dimension. In contrast, EOCG aims at reducing the number of dimensions to be constrained by using new basis vectors to represent the optimal item set with less coordinates. The key challenge is that a concise problem representation has to be formulated so that its solution also solves the original MKP. EOCG allows for this transfer by successively choosing new dimensions so that capacity violations on the next dimension added decline with a steep descent until a valid and optimal solution is found. We evaluate EOCG on established benchmark instances, which EOCG often solves in lower dimensions. EOCG finds the currently best-known solutions to all high-dimensional Chu and Beasley instances, improves the best-known solutions to two Glover and Kochenberger instances, and proves the optimality of a solution to another instance.},
  archive      = {J_EJOR},
  author       = {Thomas Setzer and Sebastian M. Blanc},
  doi          = {10.1016/j.ejor.2019.09.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {58-70},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Empirical orthogonal constraint generation for multidimensional 0/1 knapsack problems},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust optimization approach for humanitarian needs
assessment planning under travel time uncertainty. <em>EJOR</em>,
<em>282</em>(1), 40–57. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on rapid needs assessment operations conducted immediately after a disaster to identify the urgent needs of the affected community groups, and address the problem of selecting the sites to be visited by the assessment teams during a fixed assessment period and constructing assessment routes under travel time uncertainty. Due to significant uncertainties in post-disaster transportation network conditions, only rough information on travel times may be available during rapid needs assessment planning. We represent uncertain travel times simply by specifying a range of values, and implement robust optimization methods to ensure that each constructed route is feasible for all realizations of the uncertain parameters that lie in a predetermined uncertainty set. We present a tractable robust optimization formulation with a coaxial box uncertainty set due to its advantages in handling uncertainty in our selective assessment routing problem, in which the dimension of the uncertainty (number of arcs traversed) is implicitly determined. To solve the proposed model efficiently, we develop a practical method for evaluating route feasibility with respect to the robust route duration constraints, and embed this feasibility check procedure in a tabu search heuristic. We present computational results to evaluate the effectiveness of our solution method, and illustrate our approach on a case study based on a real-world post-disaster network.},
  archive      = {J_EJOR},
  author       = {Burcu Balcik and İhsan Yanıkoğlu},
  doi          = {10.1016/j.ejor.2019.09.008},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {40-57},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust optimization approach for humanitarian needs assessment planning under travel time uncertainty},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coupled task scheduling with exact delays: Literature review
and models. <em>EJOR</em>, <em>282</em>(1), 19–39. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The coupled task scheduling problem concerns scheduling a set of jobs, each with at least two tasks and there is an exact delay period between two consecutive tasks, on a set of machines to optimize a performance criterion. While research on the problem dates back to the 1980s, interests in the computational complexity of variants of the problem and solution methodologies have been evolving in the past few years. This motivates us to present an up-to-date and comprehensive literature review on the topic. Aiming to provide a complete road map for future research on the coupled task scheduling problem, we discuss all the relevant studies and potential research opportunities. In addition, we propose several sets of benchmark instances for the problem in various settings and provide a detailed evaluation of all the available mathematical models with a view to facilitating future research on the solution methods.},
  archive      = {J_EJOR},
  author       = {Mostafa Khatami and Amir Salehipour and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2019.08.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {19-39},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coupled task scheduling with exact delays: Literature review and models},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Advances in bayesian decision making in reliability.
<em>EJOR</em>, <em>282</em>(1), 1–18. (<a
href="https://doi.org/10.1016/j.ejor.2019.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Starting in the late 80s Bayesian methods have gained increasing attention in the reliability literature. The focus of most of the earlier Bayesian work in reliability involved statistical inference and thus the main emphasis was on modeling and analysis. Advances in Bayesian computing after the 90’s have significantly contributed not only to the use of Bayesian inference and prediction but also to the implementation of Bayesian decision-theoretic approaches in reliability problems. In this review we present an overview of Bayesian methods to solve decision problems in reliability some of which involve two or more decision makers with conflicting objectives. We consider problems in areas such as design, life testing, preventive maintenance, reliability certification, or warranty policies. In doing so, we present key aspects of the decision problems, give a brief review of earlier methods and finally discuss recent advances in Bayesian approaches to solve them.},
  archive      = {J_EJOR},
  author       = {David Rios Insua and Fabrizio Ruggeri and Refik Soyer and Simon Wilson},
  doi          = {10.1016/j.ejor.2019.03.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Advances in bayesian decision making in reliability},
  volume       = {282},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Merging anomalous data usage in wireless mobile
telecommunications: Business analytics with a strategy-focused
data-driven approach for sustainability. <em>EJOR</em>, <em>281</em>(3),
687–705. (<a href="https://doi.org/10.1016/j.ejor.2019.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile internet usage has exploded with the mass popularity of smartphones that offer more convenient and efficient ways of doing anything from watching movies, playing games, and streaming music. Understanding the patterns of data usage is thus essential for strategy-focused data-driven business analytics. However, data usage has several unique stylized facts (such as high dimensionality, heteroscedasticity, and sparsity) due to a great variety of user behaviour. To manage these facts, we propose a novel density-based subspace clustering approach (i.e., a three-stage iterative optimization procedure) for intelligent segmentation of consumer data usage/demand. We discuss the characteristics of the proposed method and illustrate its performance in both simulation with synthetic data and business analytics with real data. In a field experiment of wireless mobile telecommunications for data-driven strategic design and managerial implementation, we show that our method is adequate for business analytics and plausible for sustainability in search of business value.},
  archive      = {J_EJOR},
  author       = {Yi-Ting Chen and Edward W. Sun and Yi-Bing Lin},
  doi          = {10.1016/j.ejor.2019.02.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {687-705},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Merging anomalous data usage in wireless mobile telecommunications: Business analytics with a strategy-focused data-driven approach for sustainability},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Understanding the impact of business analytics on
innovation. <em>EJOR</em>, <em>281</em>(3), 673–686. (<a
href="https://doi.org/10.1016/j.ejor.2018.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in Business Analytics in the era of Big Data have provided unprecedented opportunities for organizations to innovate. With insights gained from Business Analytics, companies are able to develop new or improved products/services. However, few studies have investigated the mechanism through which Business Analytics contributes to a firm&#39;s innovation success. This research aims to address this gap by theoretically and empirically investigating the relationship between Business Analytics and innovation. To achieve this aim, absorptive capacity theory is used as a theoretical lens to inform the development of a research model. Absorptive capacity theory refers to a firm&#39;s ability to recognize the value of new, external information, assimilate it and apply it to commercial ends. The research model covers the use of Business Analytics, environmental scanning, data-driven culture, innovation (new product newness and meaningfulness), and competitive advantage. The research model is tested through a questionnaire survey of 218 UK businesses. The results suggest that Business Analytics directly improves environmental scanning which in turn helps to enhance a company&#39;s innovation. Business Analytics also directly enhances data-driven culture that in turn impacts on environmental scanning. Data-driven culture plays another important role by moderating the effect of environmental scanning on new product meaningfulness. The findings demonstrate the positive impact of business analytics on innovation and the pivotal roles of environmental scanning and data-driven culture. Organizations wishing to realize the potential of Business Analytics thus need changes in both their external and internal focus.},
  archive      = {J_EJOR},
  author       = {Duan Yanqing and Cao Guangming and John S. Edwards},
  doi          = {10.1016/j.ejor.2018.06.021},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {673-686},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Understanding the impact of business analytics on innovation},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using business analytics to enhance dynamic capabilities in
operations research: A case analysis and research agenda. <em>EJOR</em>,
<em>281</em>(3), 656–672. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the topic of analytics is rapidly growing in popularity across various domains, there is still a relatively low amount of empirical work in the field of operations research (OR). While studies of various technical and business aspects of analytics are emerging in OR, little has been done to address how the OR community can leverage business analytics in dynamic and uncertain environments – the very place where OR is supposed to play a key role. To address this gap, this study draws on the dynamic capabilities view of the firm and builds on eight selected case studies of operations research activity in large organisations, each of which have invested significantly in analytics technology and implementation. The study identifies fourteen analytics-enabled micro-foundations of dynamic capabilities, essentially highlighting how organisations can use analytics to manage and enhance their OR activities in dynamic and uncertain environments. This study also identifies six key cross-cutting propositions emerging from the data and develops a roadmap for future OR researchers to address these issues and improve the use and value of analytics as enablers of organisational dynamic capabilities.},
  archive      = {J_EJOR},
  author       = {Kieran Conboy and Patrick Mikalef and Denis Dennehy and John Krogstie},
  doi          = {10.1016/j.ejor.2019.06.051},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {656-672},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Using business analytics to enhance dynamic capabilities in operations research: A case analysis and research agenda},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Actualizing business analytics for organizational
transformation: A case study of rovio entertainment. <em>EJOR</em>,
<em>281</em>(3), 642–655. (<a
href="https://doi.org/10.1016/j.ejor.2018.11.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased access to data and affordable technologies today has made business analytics within the reach of most organizations. However, many organizations are unsure of how to translate their analytics use into organizational value. While the area of business analytics value creation has become a popular point of discussion amongst practitioners, much research is needed to provide insights into the effective use of business analytics. The objective of this paper is to deepen understanding in the effective implementation of analytics within organizations. Specifically, we performed an in-depth case study at Rovio Entertainment to investigate how a pioneer in mobile games initiated an analytics-driven transformation. This study contributes to the theory and practice of business analytics in two ways. First, drawing on the perspective of technology affordances, this study sheds light on the varying affordances of business analytics. Second, this study presents empirically-informed insights on how these affordances could be effectively actualized for an analytics-driven transformation in an organization. Collectively, this study opens up the black-box of effective implementation of business analytics for organizational value creation.},
  archive      = {J_EJOR},
  author       = {Tim Yenni and Petri Hallikainen and Pan Shan L and Tamm Toomas},
  doi          = {10.1016/j.ejor.2018.11.074},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {642-655},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Actualizing business analytics for organizational transformation: A case study of rovio entertainment},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning in business analytics and operations research:
Models, applications and managerial implications. <em>EJOR</em>,
<em>281</em>(3), 628–641. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Business analytics refers to methods and practices that create value through data for individuals, firms, and organizations. This field is currently experiencing a radical shift due to the advent of deep learning: deep neural networks promise improvements in prediction performance as compared to models from traditional machine learning. However, our research into the existing body of literature reveals a scarcity of research works utilizing deep learning in our discipline. Accordingly, the objectives of this overview article are as follows: (1) we review research on deep learning for business analytics from an operational point of view. (2) We motivate why researchers and practitioners from business analytics should utilize deep neural networks and review potential use cases, necessary requirements, and benefits. (3) We investigate the added value to operations research in different case studies with real data from entrepreneurial undertakings. All such cases demonstrate improvements in operational performance over traditional machine learning and thus direct value gains. (4) We provide guidelines and implications for researchers, managers and practitioners in operations research who want to advance their capabilities for business analytics with regard to deep learning. (5) Our computational experiments find that default, out-of-the-box architectures are often suboptimal and thus highlight the value of customized architectures by proposing a novel deep-embedded network.},
  archive      = {J_EJOR},
  author       = {Mathias Kraus and Stefan Feuerriegel and Asil Oztekin},
  doi          = {10.1016/j.ejor.2019.09.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {628-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Deep learning in business analytics and operations research: Models, applications and managerial implications},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting product return volume using machine learning
methods. <em>EJOR</em>, <em>281</em>(3), 612–627. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2015, U.S. consumers returned goods worth $261 billion and the return rates for online sales sometimes exceeded 30\%. Manufacturers and retailers have an interest in predicting return volume to address operational challenges in managing product returns. In this paper, we develop and test data-driven models for predicting return volume at the retailer, product type and period levels using a rich data set comprised of detailed operations on each product, and retailer information. The goal is to achieve a good prediction accuracy out of sample. We consider main effects and detailed interaction effects models using various machine learning methods. We find that Least Absolute Shrinkage and Selection Operator (LASSO) yields a predictive model achieving the best prediction accuracy for future return volume due to its ability to select informative interaction terms out of more than one thousand possible combinations. The LASSO model also turns in consistent performance based on several robustness tests and is easy to implement in practice. Our work provides a general predictive model framework for manufacturers to track product returns.},
  archive      = {J_EJOR},
  author       = {Hailong Cui and Sampath Rajagopalan and Amy R. Ward},
  doi          = {10.1016/j.ejor.2019.05.046},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {612-627},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predicting product return volume using machine learning methods},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data-driven analytics to support scheduling of
multi-priority multi-class patients with wait time targets.
<em>EJOR</em>, <em>281</em>(3), 597–611. (<a
href="https://doi.org/10.1016/j.ejor.2018.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Image (MRI) uses powerful magnetic forces and radio frequencies to create detailed images of the organs and tissues within the body. In this paper, we first conduct descriptive analytics on MRI data of over 3.7 million patient records and determine the main factors affecting the waiting time and conduct predictive analytics to forecast the daily arrivals and the number of procedures performed at each hospital. It is the hospital’s goal to serve 90\% of patients within their wait time targets. Therefore, we prescribe two simple scheduling policies based on a balance between the FIFO (First-In First-Out) and strict priority policies; namely, weight accumulation and priority promotion to improve the wait time management. Under the weight accumulation policy, patients from different priority levels start with varying initial weights, which then accumulates as a linear function of their waiting time. Under the priority promotion policy, a strict priority policy is applied to priority levels where patients are promoted to a higher priority level after waiting for a predetermined threshold of time. We evaluate the proposed policies against two performance measures: total exceeding time (the number of days by which patients exceed their wait target), and overflow proportion (the percentage of patients that exceed the wait target). To investigate the value of information, we schedule patients at different points of time from their day of arrival. The results show that hospitals can enhance their wait time management by delaying patient scheduling. We demonstrate that effective scheduling policies may result in significant reduction in patient waiting time without any costly capacity expansion.},
  archive      = {J_EJOR},
  author       = {Yangzi Jiang and Hossein Abouee-Mehrizi and Yuhe Diao},
  doi          = {10.1016/j.ejor.2018.05.017},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {597-611},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven analytics to support scheduling of multi-priority multi-class patients with wait time targets},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A machine learning framework for customer purchase
prediction in the non-contractual setting. <em>EJOR</em>,
<em>281</em>(3), 588–596. (<a
href="https://doi.org/10.1016/j.ejor.2018.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting future customer behavior provides key information for efficiently directing resources at sales and marketing departments. Such information supports planning the inventory at the warehouse and point of sales, as well strategic decisions during manufacturing processes. In this paper, we develop advanced analytics tools that predict future customer behavior in the non-contractual setting. We establish a dynamic and data driven framework for predicting whether a customer is going to make purchase at the company within a certain time frame in the near future. For that purpose, we propose a new set of customer relevant features that derives from times and values of previous purchases. These customer features are updated every month, and state of the art machine learning algorithms are applied for purchase prediction. In our studies, the gradient tree boosting method turns out to be the best performing method. Using a data set containing more than 10 000 customers and a total number of 200 000 purchases we obtain an accuracy score of 89\% and an AUC value of 0.95 for predicting next moth purchases on the test data set.},
  archive      = {J_EJOR},
  author       = {Andrés Martínez and Claudia Schmuck and Sergiy Pereverzyev Jr. and Clemens Pirker and Markus Haltmeier},
  doi          = {10.1016/j.ejor.2018.04.034},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {588-596},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A machine learning framework for customer purchase prediction in the non-contractual setting},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of a bayesian belief network-based DSS for
predicting and understanding freshmen student attrition. <em>EJOR</em>,
<em>281</em>(3), 575–587. (<a
href="https://doi.org/10.1016/j.ejor.2019.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Student attrition – the departure from an institution of higher learning prior to the achievement of a degree or earning due educational credentials – is an administratively important, scientifically interesting and yet practically challenging problem for decision makers and researchers. This study aims to find the prominent variables and their conditional dependencies/interrelations that affect student attrition in college settings. Specifically, using a large and feature-rich dataset, proposed methodology successfully captures the probabilistic interactions between attrition (the dependent variable) and related factors (the independent variables) to reveal the underlying, potentially complex/non-linear relationships. The proposed methodology successfully predicts the individual students&#39; attrition risk through a Bayesian Belief Network-driven probabilistic model. The findings suggest that the proposed probabilistic graphical/network method is capable of predicting student attrition with 84\% in AUC – Area Under the Receiver Operating Characteristics Curve. Using a 2-by-2 investigational design framework, this body of research also compares the impact and contribution of data balancing and feature selection to the resultant prediction models. The results show that (1) the imbalanced dataset produces similar predictive results in detecting the at-risk students, and (2) the feature selection, which is the process of identifying and eliminating unnecessary/unimportant predictors, results in simpler, more understandable, interpretable, and actionable results without compromising on the accuracy of the prediction task.},
  archive      = {J_EJOR},
  author       = {Dursun Delen and Kazim Topuz and Enes Eryarsoy},
  doi          = {10.1016/j.ejor.2019.03.037},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {575-587},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Development of a bayesian belief network-based DSS for predicting and understanding freshmen student attrition},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An analytic infrastructure for harvesting big data to
enhance supply chain performance. <em>EJOR</em>, <em>281</em>(3),
559–574. (<a href="https://doi.org/10.1016/j.ejor.2018.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data has already received a tremendous amount of attention from managers in every industry, policy and decision makers in governments, and researchers in many different areas. However, the current big data analytics have conspicuous limitations, especially when dealing with information silos. In this paper, we synthesise existing researches on big data analytics and propose an integrated infrastructure for breaking down the information silos, in order to enhance supply chain performance. The analytic infrastructure effectively leverages rich big data sources (i.e. databases, social media, mobile and sensor data) and quantifies the related information using various big data analytics. The information generated can be used to identify a required competence set (which refers to a collection of skills and knowledge used for specific problem solving) and to provide roadmaps to firms and managers in generating actionable supply chain strategies, facilitating collaboration between departments, and generating fact-based operational decisions. We showcase the usefulness of the analytic infrastructure by conducting a case study in a world-leading company that produces sports equipment. The results indicate that it enabled managers: (a) to integrate information silos in big data analytics to serve as inputs for new product ideas; (b) to capture and interrelate different competence sets to provide an integrated perspective of the firm&#39;s operations capabilities; and (c) to generate a visual decision path that facilitated decision making regarding how to expand competence sets to support new product development.},
  archive      = {J_EJOR},
  author       = {Zhan Yuanzhu and Tan Kim Hua},
  doi          = {10.1016/j.ejor.2018.09.018},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {559-574},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An analytic infrastructure for harvesting big data to enhance supply chain performance},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting customer demand for remanufactured products: A
data-mining approach. <em>EJOR</em>, <em>281</em>(3), 543–558. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing has received increasing attention from researchers over the last decade. While many associated operational issues have been extensively studied, research into the prediction customer demand for, and the market development of, remanufactured products is still in its infancy. The majority of the existing research into remanufactured product demand is largely based on conventional statistical models that fail to capture the non-linear behaviour of customer demand and market factors in real-world business environments, in particular e-marketplaces. Therefore, this paper aims to develop a comprehensible data-mining prediction approach, in order to achieve two objectives: (1) to provide a highly accurate and robust demand prediction model of remanufactured products; and (2) to shed light on the non-linear effect of online market factors as predictors of customer demand. Based on the real-world Amazon dataset, the results suggest that predicting remanufactured product demand is a complex, non-linear problem, and that, by using advanced machine-learning techniques, our proposed approach can predict the product demand with high accuracy. In terms of practical implications, the importance of market factors is ranked according to their predictive powers of demand, while their effects on demand are analysed through their partial dependence plots. Several insights for management are revealed by a thorough comparison of the sales impact of these market factors on remanufactured and new products.},
  archive      = {J_EJOR},
  author       = {Van Nguyen Truong and Zhou Li and Chong Alain Yee Loong and Li Boying and Pu Xiaodie},
  doi          = {10.1016/j.ejor.2019.08.015},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {543-558},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predicting customer demand for remanufactured products: A data-mining approach},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid model for predicting human physical activity status
from lifelogging data. <em>EJOR</em>, <em>281</em>(3), 532–542. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One trend in the recent healthcare transformations is people are encouraged to monitor and manage their health based on their daily diets and physical activity habits. However, much attention of the use of operational research and analytical models in healthcare has been paid to the systematic level such as country or regional policy making or organisational issues. This paper proposes a model concerned with healthcare analytics at the individual level, which can predict human physical activity status from sequential lifelogging data collected from wearable sensors. The model has a two-stage hybrid structure (in short, MOGP-HMM) – a multi-objective genetic programming (MOGP) algorithm in the first stage to reduce the dimensions of lifelogging data and a hidden Markov model (HMM) in the second stage for activity status prediction over time. It can be used as a decision support tool to provide real-time monitoring, statistical analysis and personalized advice to individuals, encouraging positive attitudes towards healthy lifestyles. We validate the model with the real data collected from a group of participants in the UK, and compare it with other popular two-stage hybrid models. Our experimental results show that the MOGP-HMM can achieve comparable performance. To the best of our knowledge, this is the very first study that uses the MOGP in the hybrid two-stage structure for individuals’ activity status prediction. It fits seamlessly with the current trend in the UK healthcare transformation of patient empowerment as well as contributing to a strategic development for more efficient and cost-effective provision of healthcare.},
  archive      = {J_EJOR},
  author       = {Ji Ni and Bowei Chen and Nigel M. Allinson and Xujiong Ye},
  doi          = {10.1016/j.ejor.2019.05.035},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {532-542},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid model for predicting human physical activity status from lifelogging data},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Latent topic ensemble learning for hospital readmission cost
optimization. <em>EJOR</em>, <em>281</em>(3), 517–531. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unplanned hospital readmission is a costly problem in the United States, and in 2013 the U.S. federal government began to reduce payments to hospitals with preventable patient readmissions. Predictive modeling using machine learning and data analytics can be a useful decision support tool to help identify patients most likely to be readmitted. However, current systems have several shortcomings, such as difficulties in utilizing unstructured data and combining data from multiple hospitals. In this paper, we propose Latent Topic Ensemble Learning, which uses an ensemble of topic specific models to leverage data from multiple hospitals, as key data analytic algorithm for predicting hospital readmission. Models are built and evaluated incorporating federal financial penalties and tested using dataset containing data collected from 16 regional hospitals. It is found that LTEL significantly outperforms the best performing baseline method for readmission cost optimization.},
  archive      = {J_EJOR},
  author       = {Christopher Baechle and Huang C. Derrick and Ankur Agarwal and Ravi S. Behara and Goo Jahyun},
  doi          = {10.1016/j.ejor.2019.05.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {517-531},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Latent topic ensemble learning for hospital readmission cost optimization},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Who will use augmented reality? An integrated approach based
on text analytics and field survey. <em>EJOR</em>, <em>281</em>(3),
502–516. (<a href="https://doi.org/10.1016/j.ejor.2018.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation technologies such as Augmented Reality and Virtual Reality are fast permeating many industry and society sectors. Their market is projected to reach $95 billion by 2025, representing a large portion of the economy within the next decade. With these technologies gaining wide popularity, it is critical to understand their usage in the context of the various benefits and perils that they offer. Even though top-rated mobile applications face an increasing challenge to retain users, few studies have attempted to decipher the dilemma in their continuance momentum. In this study, we focus on Pokémon GO, a top-rated Augmented Reality app, using it as a special case to investigate factors influencing user continuance and more use intention. We extend expectation confirmation theory by incorporating the effects of subjective norm, perceived risk, technical features and sense of direction. To increase the relevance and richness of our understanding of risks and benefits, we integrate the text analytics and survey-based theory-validating research methodology to build and test our research model. Our findings suggest that rational risk/benefit calculus and satisfaction are two primary inputs for continuance intention. Besides physical health benefits, users also value the benefits in mental health and relationship building. The risks in performance, time and safety are salient risk dimensions that negatively impact satisfaction. Furthermore, we find technical features play a strong role in influencing perceived benefits and user satisfaction. The findings also provide important practical implications for the designers of next-generation mobile apps enabled by Augmented Reality.},
  archive      = {J_EJOR},
  author       = {Li Han and Ashish Gupta and Zhang Jie and Nick Flor},
  doi          = {10.1016/j.ejor.2018.10.019},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {502-516},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Who will use augmented reality? an integrated approach based on text analytics and field survey},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring the ethical implications of business analytics
with a business ethics canvas. <em>EJOR</em>, <em>281</em>(3), 491–501.
(<a href="https://doi.org/10.1016/j.ejor.2019.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ethical aspects of data science and artificial intelligence have become a major issue. Organisations that deploy data scientists and operational researchers (OR) must address the ethical implications of their use of data and algorithms. We review the OR and data science literature on ethics and find that this work is pitched at the level of guiding principles and frameworks and fails to provide a practical and grounded approach that can be used by practitioners as part of the analytics development process. Further, given the advent of the General Data Protection Regulation (GDPR) an ethical dimension is likely to become an increasingly important aspect of analytics development. Drawing on the business analytics methodology (BAM) developed by Hindle and Vidgen (2018) we tackle this challenge through action research with a pseudonymous online travel company, EuroTravel. The method that emerges uses an opportunity canvas and a business ethics canvas to explore value creation and ethical aspects jointly. The business ethics canvas draws on the Markkula Center&#39;s five ethical principles (utility, rights, justice, common good, and virtue) to which explicit consideration of stakeholders is added. A contribution of the paper is to show how an ethical dimension can be embedded in the everyday exploration of analytics development opportunities, as distinct from a stand-alone ethical decision-making tool or as an overlay of a general set of guiding principles. We also propose that value and ethics should not be viewed as separate entities, rather they should be seen as inseparable and intertwined.},
  archive      = {J_EJOR},
  author       = {Richard Vidgen and Giles Hindle and Ian Randolph},
  doi          = {10.1016/j.ejor.2019.04.036},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {491-501},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exploring the ethical implications of business analytics with a business ethics canvas},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Business analytics: Defining the field and identifying a
research agenda. <em>EJOR</em>, <em>281</em>(3), 483–490. (<a
href="https://doi.org/10.1016/j.ejor.2019.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special issue on business analytics has been a great endeavor with more than 100 papers received. The call for papers highlighted that business analytics has a clear role to generate competitive advantage in organizations and our focus has been to demonstrate this role through the papers finally selected for the special issue. The editorial aims to provide not only a summary of the papers but also presents our perspective on the current situation of the field through a computational literature review and comparison with the papers in the special issue. Our findings, and discussions on the papers included in the special issue, suggest that business analytics is maturing as a field with significant synergies and opportunities for the operational research community.},
  archive      = {J_EJOR},
  author       = {Giles Hindle and Martin Kunc and Michael Mortensen and Asil Oztekin and Richard Vidgen},
  doi          = {10.1016/j.ejor.2019.10.001},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {483-490},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Business analytics: Defining the field and identifying a research agenda},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the integer programming formulation for the relaxed
restricted container relocation problem. <em>EJOR</em>, <em>281</em>(2),
475–482. (<a href="https://doi.org/10.1016/j.ejor.2019.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper entitled “A new binary formulation of the restricted container relocation problem based on a binary encoding of configurations”, Galle, Barnhart and Jaillet (2018) introduced a new variant of the container relocation problem (CRP), named the relaxed restricted CRP, where every container can be relocated at most once for retrieving each target container. The authors also proposed a binary integer programming model for formulating the relaxed restricted CRP. In this paper, it is first shown that the proposed model contains two deficiencies in formulating the “last in, first out” (LIFO) policy. These deficiencies will cause the solutions obtained by the model to correspond to infeasible configurations or infeasible relocation sequences. Then, the LIFO policy is analyzed in detail and reformulated as linear constraints correctly. Lastly, the corrected integer programming formulation is presented. Computational experiments show that the corrected model dramatically reduces complexity and improves performance.},
  archive      = {J_EJOR},
  author       = {Bo Jin},
  doi          = {10.1016/j.ejor.2019.08.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {475-482},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the integer programming formulation for the relaxed restricted container relocation problem},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stratified breast cancer follow-up using a continuous state
partially observable markov decision process. <em>EJOR</em>,
<em>281</em>(2), 464–474. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency and duration of follow-up for breast cancer patients is still under discussion. Currently, in the Netherlands follow-up consists of annual mammography for the first five years after treatment and does not depend on the personal risk of developing a locoregional recurrence or a second primary tumor. The aim of this study is to gain insight in how to allocate resources for optimal and personalized follow-up. We formulate a discrete-time Partially Observable Markov Decision Process (POMDP) over a finite horizon with both discrete and continuous states, in which the size of the tumor is modeled as a continuous state. Transition probabilities are obtained from data of the Netherlands Cancer Registry. We show that the optimal value function of the POMDP is piecewise linear and convex and provide an alternative representation for it. Under the assumption that the tumor growth follows an exponential distribution and that the model parameters can be described by exponential functions, the optimal value function can be obtained from the parameters of the underlying probability distributions only. Finally, we present results for a stratification of the patients based on their age to show how this model can be applied in practice.},
  archive      = {J_EJOR},
  author       = {Maarten Otten and Judith Timmer and Annemieke Witteveen},
  doi          = {10.1016/j.ejor.2019.08.046},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {464-474},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Stratified breast cancer follow-up using a continuous state partially observable markov decision process},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Capital regulation under price impacts and dynamic financial
contagion. <em>EJOR</em>, <em>281</em>(2), 449–463. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a continuous time model for price-mediated contagion precipitated by a common exogenous stress to the banking book of all firms in the financial system. In this setting, firms are constrained so as to satisfy a risk-weight based capital ratio requirement. We use this model to find analytical bounds on the risk-weights for assets as a function of the market liquidity. Under these appropriate risk-weights, we find existence and uniqueness for the joint system of firm behavior and the asset prices. We further consider an analytical bound on the firm liquidations, which allows us to construct exact formulas for stress testing the financial system with deterministic or random stresses. Numerical case studies are provided to demonstrate various implications of this model and analytical bounds.},
  archive      = {J_EJOR},
  author       = {Zachary Feinstein},
  doi          = {10.1016/j.ejor.2019.08.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {449-463},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Capital regulation under price impacts and dynamic financial contagion},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). A coherent approach to bayesian data envelopment analysis.
<em>EJOR</em>, <em>281</em>(2), 439–448. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitropoulos et al. (2015) suggested the use of a Bayesian approach in Data Envelopment Analysis (DEA) which can be used to obtain posterior distributions of efficiency scores. In this paper, we avoid their assumption that alternative data sets are simulated from the predictive distribution obtained from their simple data generating process of a normal distribution for the data. The new approach has two significant advantages. First, the posterior proposed in this paper is coherent or principled in the sense that it is consistent with the DEA formulation. Second, and perhaps surprisingly, it is not necessary to solve linear programming problems for each observation in the sample. Bayesian inference is organized around Markov Chain Monte Carlo techniques that can be implemented quite easily. We conduct extensive Monte Carlo experiments to investigate the finite-sample properties of the new approach. We also provide an application to a large U.S banking data set. The sample is an unbalanced panel of US banks with 2,397 bank–year observations for 285 banks. The main purpose of the analysis is to compare distributions of efficiency scores. Relative to DEA, Bayes DEA provides different efficiency scores and their sample distribution has significantly less probability concentration around unity. The comparison with bootstrap-DEA shows that results from Bayes DEA are in broad agreement.},
  archive      = {J_EJOR},
  author       = {Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2019.08.039},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {439-448},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A coherent approach to bayesian data envelopment analysis},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Social collateral, soft information and online peer-to-peer
lending: A theoretical model. <em>EJOR</em>, <em>281</em>(2), 428–438.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional credit markets have been criticized as inefficient in allocating credits to borrowers. Powered by advanced Internet technology, online Peer-to-Peer (P2P) lending has emerged as an attractive alternative, especially for small borrowers who have limited assets and are in need of funds urgently. Although several empirical studies have examined factors influencing the micro-level lending outcome, there is a lack of understanding on the overall business model of P2P lending, especially its screening mechanism, and how it helps address the deficiency of the traditional credit market. This paper fills this void. First, we develop a theoretical model incorporating two unique features of P2P lending (soft information and social collateral) and show that in P2P, low-risk borrowers could force high-risk ones off the market under very general conditions. As a result, P2P complements traditional credit markets by serving the unserved (low-risk borrowers with little assets) in the traditional credit markets. Second, we further identify the critical operational settings for P2P success, and the impacts of these settings on borrowers’ welfare. Overall, our model and analyses not only contribute to the literature by showing analytically that P2P and the traditional credit markets are complementary, but also provide practical guidance to P2P platform managers regarding their platform design to help reshape business strategies and enhance business opportunities.},
  archive      = {J_EJOR},
  author       = {Zhengchi Liu and Jennifer Shang and Shin-yi Wu and Pei-yu Chen},
  doi          = {10.1016/j.ejor.2019.08.038},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {428-438},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Social collateral, soft information and online peer-to-peer lending: A theoretical model},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the construction of a feasible range of multidimensional
poverty under benchmark weight uncertainty. <em>EJOR</em>,
<em>281</em>(2), 415–427. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are infinitely many alternative benchmark weights that decision makers could choose to measure multidimensional poverty. To overcome the resulting uncertainty, we derive a feasible range of multidimensional poverty that considers all admissible weights within the chosen lower and upper bounds of weights. We use Kenyan and Canadian data to illustrate the use of our methodology, which is an adaptation of existing methods for portfolio analysis based on stochastic dominance. These two-empirical analyses suggest that different weights allocated to poverty dimensions can produce very different multidimensional poverty outcomes for a given population even in cases with small weight perturbations.},
  archive      = {J_EJOR},
  author       = {Mehmet Pinar and Thanasis Stengos and Nikolas Topaloglou},
  doi          = {10.1016/j.ejor.2019.08.047},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {415-427},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the construction of a feasible range of multidimensional poverty under benchmark weight uncertainty},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid simulation-based optimization framework supporting
strategic maintenance development to improve production performance.
<em>EJOR</em>, <em>281</em>(2), 402–414. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing maintenance and its impact on business results is increasingly complex, calling for more advanced operational research methodologies to address the challenge of sustainable decision-making. This problem-based research has identified a framework of methods to supplement the operations research/management science literature by contributing a hybrid simulation-based optimization framework (HSBOF), extending previously reported research. Overall, it is the application of multi-objective optimization (MOO) with system dynamics (SD) and discrete-event simulation (DES) respectively which allows maintenance activities to be pinpointed in the production system based on analyzes generating less reactive work load on the maintenance organization. Therefore, the application of the HSBOF informs practice by a multiphase process, where each phase builds knowledge, starting with exploring feedback behaviors to why certain near-optimal maintenance behaviors arise, forming the basis of potential performance improvements, subsequently optimized using DES+MOO in a standard software, prioritizing the sequence of improvements in the production system for maintenance to implement. Studying literature on related hybridizations using optimization the proposed work can be considered novel, being based on SD+MOO industrial cases and their application to a DES+MOO software.},
  archive      = {J_EJOR},
  author       = {Gary Linnéusson and Amos H.C. Ng and Tehseen Aslam},
  doi          = {10.1016/j.ejor.2019.08.036},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {402-414},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A hybrid simulation-based optimization framework supporting strategic maintenance development to improve production performance},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach for identifying the kemeny median ranking.
<em>EJOR</em>, <em>281</em>(2), 388–401. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Condorcet consistent rules were originally developed for preference aggregation in the theory of social choice. Nowadays these rules are applied in a variety of fields such as discrete multi-criteria analysis, defence and security decision support, composite indicators, machine learning, artificial intelligence, queries in databases or internet multiple search engines and theoretical computer science. The cycle issue, known also as Condorcet&#39;s paradox, is the most serious problem inherent in this type of rules. Solutions for dealing with the cycle issue properly already exist in the literature; the most important one being the identification of the median ranking, often called the Kemeny ranking. Unfortunately its identification is a NP-hard problem. This article has three main objectives: (1) to clarify that the Kemeny median order has to be framed in the context of Condorcet consistent rules; this is important since in the current practice sometimes even the Borda count is used as a proxy for the Kemeny ranking. (2) To present a new exact algorithm, this identifies the Kemeny median ranking by providing a searching time guarantee. (3) To present a new heuristic algorithm identifying the Kemeny median ranking with an optimal trade-off between convergence and approximation.},
  archive      = {J_EJOR},
  author       = {Ivano Azzini and Giuseppe Munda},
  doi          = {10.1016/j.ejor.2019.08.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {388-401},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new approach for identifying the kemeny median ranking},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Contingent preference disaggregation model for multiple
criteria sorting problem. <em>EJOR</em>, <em>281</em>(2), 369–387. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional preference disaggregation approaches for multiple criteria sorting aim at reconstructing an entire set of assignment examples provided by a Decision Maker (DM) with a single preference model instance. In case the DM’s holistic preference information is not consistent with an assumed model, one needs to accept that some assignment examples are not reproduced. We propose a new approach for handling inconsistency in the context of a threshold-based value-driven sorting procedure. Specifically, we introduce preference disaggregation methods for reconstructing all assignment examples with a set of complementary preference models. The proposed approach builds on the assumption that the importance of particular criteria or, more generally, the shape of marginal value functions and their maximal shares in the comprehensive value are contingent (i.e., dependent) on the performance profile of a given alternative. Therefore, in case of inconsistency, the set of assignment examples is divided into subsets, each of which is reconstructed by a unique model to be used only if certain circumstances are valid. We present three methods for learning a set of contingent models, allowing different degrees of variation in the contingent models along two dimensions: the shape of marginal value functions and interrelations between the models. To apply such a set for classification of non-reference alternatives, we learn a decision tree which makes the application of a given model dependent on the alternatives’ profiles represented by the performances on particular criteria, hence allowing to select an appropriate model among the competing models to evaluate a non-reference alternative. The method’s applicability is demonstrated on a problem of evaluating research units representing different fields of science.},
  archive      = {J_EJOR},
  author       = {Miłosz Kadziński and Mohammad Ghaderi and Maciej Dąbrowski},
  doi          = {10.1016/j.ejor.2019.08.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {369-387},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Contingent preference disaggregation model for multiple criteria sorting problem},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pareto solutions in multicriteria optimization under
uncertainty. <em>EJOR</em>, <em>281</em>(2), 357–368. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present and analyze several definitions of Pareto optimality for multicriteria optimization or decision problems with uncertainty primarily in their objective function values. In comparison to related notions of Pareto robustness, we first provide a full characterization of an alternative efficient set hierarchy that is based on six different ordering relations both with respect to the multiple objectives and a possibly finite, countably infinite or uncountable number of scenarios. We then establish several scalarization results for the generation of the corresponding efficient points using generalized weighted-sum and epsilon-constraint techniques. Finally, we leverage these scalarization results to also derive more general conditions for the existence of efficient points in each of the corresponding optimality classes, under suitable assumptions.},
  archive      = {J_EJOR},
  author       = {Alexander Engau and Devon Sigler},
  doi          = {10.1016/j.ejor.2019.08.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {357-368},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pareto solutions in multicriteria optimization under uncertainty},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal investment with s-shaped utility and trading and
value at risk constraints: An application to defined contribution
pension plan. <em>EJOR</em>, <em>281</em>(2), 341–356. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate an optimal investment problem under loss aversion (S-shaped utility) and with trading and Value-at-Risk (VaR) constraints faced by a defined contribution (DC) pension fund manager. We apply the concavification and dual control method to solve the problem and derive the closed-form representation of the optimal terminal wealth in terms of a controlled dual state variable. We propose a simple and effective algorithm for computing the initial dual state value, the Lagrange multiplier and the optimal terminal wealth. Theoretical and numerical results show that the VaR constraint can significantly impact the distribution of the optimal terminal wealth and may greatly reduce the risk of losses in bad economic states due to loss aversion.},
  archive      = {J_EJOR},
  author       = {Yinghui Dong and Harry Zheng},
  doi          = {10.1016/j.ejor.2019.08.034},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {341-356},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal investment with S-shaped utility and trading and value at risk constraints: An application to defined contribution pension plan},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bioeconomic modeling of seasonal fisheries. <em>EJOR</em>,
<em>281</em>(2), 332–340. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seasonality or periodicity–biological, environmental, or economic–are fundamental properties of most marine fisheries. We propose a generic infinite horizon discrete time fisheries management model by modifying existing models and frameworks of analysis to reflect seasonal variation or more general multiperiodicity in parameters, variables, or functional forms. Our model captures such variations via repeated cycles of multiple intervals with differing characteristics. The framework offers a simple and intuitive set up of arbitrary periodicity and seasonality in any feature, which significantly increases model realism. Further, it distances itself from continuous time modeling approaches where uniqueness and solvability of periodic models generally are difficult to assert. In our setting, the governing equations for the time-dependent value function of the management optimization problem are shown to be equivalent to a high-dimensional contraction and hence ensure uniqueness and a feasible solution algorithm. We illustrate our approach using a simple example to demonstrate that accounting for seasonality in fisheries management can improve outcomes considerably. Our framework also provides for analysis of seasonal regulatory measures. Ultimately, our approach applies to renewable resource management more generally and to many infinite-horizon, discrete time optimization problems with periodic features.},
  archive      = {J_EJOR},
  author       = {Sturla F. Kvamsdal and José M. Maroto and Manuel Morán and Leif K. Sandal},
  doi          = {10.1016/j.ejor.2019.08.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {332-340},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Bioeconomic modeling of seasonal fisheries},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A cost consensus metric for consensus reaching processes
based on a comprehensive minimum cost model. <em>EJOR</em>,
<em>281</em>(2), 316–331. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus Reaching Processes (CRPs) have recently acquired much more importance within Group Decision Making real-world problems because of the demand of either agreed or consensual solutions in such decision problems. Hence, many CRP models have been proposed in the specialized literature, but so far there is not any clear objective to evaluate their performance in order to choose the best CRP model. Therefore, this research aims at developing an objective metric based on the cost of modifying experts’ opinions to evaluate CRPs in GDM problems. First, a new and comprehensive minimum cost consensus model that considers distance to global opinion and consensus degree is presented. This model obtains an optimal agreed solution with minimum cost but this solution is not dependent on experts’ opinion evolution. Therefore, this optimal solution will be used to evaluate CRPs in which experts’ opinion evolution is considered to achieve an agreed solution for the GDM. Eventually, a comparative performance analysis of different CRPs on a GDM problem will be provided to show the utility and validity of this cost metric.},
  archive      = {J_EJOR},
  author       = {Álvaro Labella and Hongbin Liu and Rosa M. Rodríguez and Luis Martínez},
  doi          = {10.1016/j.ejor.2019.08.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {316-331},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A cost consensus metric for consensus reaching processes based on a comprehensive minimum cost model},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trilevel model for best response in energy demand-side
management. <em>EJOR</em>, <em>281</em>(2), 299–315. (<a
href="https://doi.org/10.1016/j.ejor.2019.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand-side management (DSM) is a powerful tool to efficiently manage the consumption of energy. DSM relies on various techniques and means. In this work, we propose a trilevel energy market model for load shifting induced by time-of-use pricing. Four kinds of actors are involved: electricity suppliers (sell energy), local agents (buy, sell and consume), aggregators (buy and sell) and end users (consume). The interactions among these actors lead to a trilevel multi-leader–multi-follower game. Solving such games is known to be hard, thus we assume that the decision variables of all electricity suppliers but one are known and optimize the decisions of the remaining supplier. This leads to a single-leader–multi-follower game, which aims to compute the leader’s best response to the decisions of his competitors. The trilevel model is first formulated as a bilevel problem using an explicit formula for the lowest optimization level. Solution algorithms are developed in the optimistic case and in a variant named “semi-optimistic” approach leading to more robust solutions. Finally, numerical results highlight the efficiency of the methods and the sensitivity of the solutions with respect to the model parameters.},
  archive      = {J_EJOR},
  author       = {Didier Aussel and Luce Brotcorne and Sébastien Lepaul and Léonard von Niederhäusern},
  doi          = {10.1016/j.ejor.2019.03.005},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {299-315},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A trilevel model for best response in energy demand-side management},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An aggregation-based approximate dynamic programming
approach for the periodic review model with random yield. <em>EJOR</em>,
<em>281</em>(2), 286–298. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A manufacturer places orders periodically for products that are shipped from a supplier. During transit, orders get damaged with some probability, that is, the order is subject to random yield. The manufacturer has the option to track orders to receive information on damages and to potentially place additional orders. Without tracking, the manufacturer identifies potential damages after the order has arrived. With tracking, the manufacturer is informed about the damage when it occurs and can respond to this information. We model the problem as a dynamic program with stochastic demand, tracking cost, and random yield. For small problem sizes, we provide an adjusted value iteration algorithm that finds the optimal solution. For moderate problem sizes, we propose a novel aggregation-based approximate dynamic programming (ADP) algorithm and provide solutions for instances for which it is not possible to obtain optimal solutions. For large problem sizes, we develop a heuristic that takes tracking costs into account. In a computational study, we analyze the performance of our approaches. We observe that our ADP algorithm achieves savings of up to 16\% compared to existing heuristics. Our heuristic outperforms existing ones by up to 8.1\%. We show that dynamic tracking reduces costs compared to tracking always or never and identify savings of up to 3.2\%.},
  archive      = {J_EJOR},
  author       = {Michael A. Voelkel and Anna-Lena Sachs and Ulrich W. Thonemann},
  doi          = {10.1016/j.ejor.2019.08.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {286-298},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An aggregation-based approximate dynamic programming approach for the periodic review model with random yield},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Determining optimal parameters for expediting policies under
service level constraints. <em>EJOR</em>, <em>281</em>(2), 274–285. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Order expediting is an inventory control practice that allows companies to reduce inventory while maintaining service levels. However, expediting outstanding orders is costly and a trade-off must be made between expediting orders and holding inventory. We model the problem as a periodic-review inventory system with the option to move outstanding units forward in the replenishment pipeline. The objective is to minimize the sum of expected inventory holding and expediting costs per period subject to a minimum expected service level constraint. We consider a generalized base-stock policy where outstanding units are expedited when the inventory level drops below a certain threshold. We develop structural properties and present an efficient procedure to determine the optimal policy parameters. In a numerical study with real-world data, we show that our expediting policy offers substantial savings compared to other policies. We also provide managerial insights by numerically analyzing how the model parameters impact the savings.},
  archive      = {J_EJOR},
  author       = {Simon J. Höller and Raik Özsen and Ulrich W. Thonemann},
  doi          = {10.1016/j.ejor.2019.08.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {274-285},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Determining optimal parameters for expediting policies under service level constraints},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A practical dynamic programming based methodology for
aircraft maintenance check scheduling optimization. <em>EJOR</em>,
<em>281</em>(2), 256–273. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a practical dynamic programming based methodology to optimize the long-term maintenance check schedule for a fleet of heterogeneous aircraft. It is the first time that the long-term aircraft maintenance check schedule is optimized, integrating different check types in a single schedule solution. The proposed methodology aims at minimizing the wasted interval between checks. By achieving this goal, one is also reducing the number of checks over time, increasing aircraft availability and, therefore, reducing maintenance costs, while respecting safety regulations. The model formulation takes aircraft type, status, maintenance capacity, and other operational constraints into consideration. We also validate and demonstrate the proposed methodology using fleet maintenance data from a European airline. The outcomes show that, when compared with the current practice, the number of maintenance checks can be reduced by around 7\% over a period of 4 years, while computation time is less than 15 minutes. This could result in saving worth $1.1M–$3.4M in maintenance costs for a fleet of about 40 aircraft and generating more than $9.8M of revenue due to higher aircraft availability.},
  archive      = {J_EJOR},
  author       = {Qichen Deng and Bruno F. Santos and Richard Curran},
  doi          = {10.1016/j.ejor.2019.08.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {256-273},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A practical dynamic programming based methodology for aircraft maintenance check scheduling optimization},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crowdsourcing contests. <em>EJOR</em>, <em>281</em>(2),
241–255. (<a href="https://doi.org/10.1016/j.ejor.2019.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a crowdsourcing contest a requester posts a task (e.g. logo design, programming task) on a platform and announces a monetary reward that he is willing to pay for a winning solution. Contestants (e.g. designers or programmers) submit solutions on the platform and the requester chooses the best solution (possibly more than one) and awards the prize. On-line platforms for crowdsourcing contests are already abundant and growing rapidly in market size. In this survey we present two streams of literature that study crowdsourcing contests. The first is theoretical research, which tries to capture the characteristics of these contests, describe them as a game and then analyze the equilibrium behavior of contestants. The second is the empirical research which collects crowdsourcing data and analyzes the behavior of the contestants in these platforms. The aim of this survey is to clarify the current status of the research of incentives and behavior of contestants, organizers and the platform in crowdsourcing contests and to highlight the many questions that are still open.},
  archive      = {J_EJOR},
  author       = {Ella Segev},
  doi          = {10.1016/j.ejor.2019.02.057},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {241-255},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Crowdsourcing contests},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strategic contracting and hybrid use of agency and wholesale
contracts in e-commerce platforms. <em>EJOR</em>, <em>281</em>(1),
231–239. (<a href="https://doi.org/10.1016/j.ejor.2019.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines strategic contracting between a monopoly platform and suppliers that sell their goods through the platform. I consider two competing suppliers: a high-volume supplier with the larger potential demand and a low-volume supplier with the smaller one. Each supplier chooses one of two contracts: wholesale or agency. The platform has to strategically determine the royalty rate for the agency contract by taking into account which contracts the suppliers will choose. I show that the platform offers a low (high) royalty rate to induce the suppliers to adopt the agency (wholesale) contract when product substitutability is low (high) enough. More interestingly, when the degree of substitution is at an intermediate level, asymmetric contracting, in which only the low-volume supplier adopts the agency contract, can arise in equilibrium. This result is related to the fact that many long-tail and niche products with lower potential market sizes are traded on platform-based marketplaces, such as Amazon Marketplace and Walmart Marketplace.},
  archive      = {J_EJOR},
  author       = {Yusuke Zennyo},
  doi          = {10.1016/j.ejor.2019.08.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {231-239},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic contracting and hybrid use of agency and wholesale contracts in e-commerce platforms},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Defining a new graph inefficiency measure for the
proportional directional distance function and introducing a new
malmquist productivity index. <em>EJOR</em>, <em>281</em>(1), 222–230.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A natural multiplicative efficiency measure for the Constant Returns to Scale proportional directional distance function (pDDF) is derived, relating its associated linear program to that of the well-known output-oriented radial efficiency measurement model. Based on this relationship, a traditional CCD (Caves, Christensen and Diewert) Malmquist index is introduced to show that, when it is based on the new efficiency measure associated with the pDDF, rather than on a radial efficiency measure associated with an oriented distance function, it becomes a Total Factor Productivity (TFP) index. This constitutes a new result, because heretofore the traditional CCD Malmquist index has not been considered a TFP index. Additionally, a new decomposition of the CCD Malmquist index is proposed that expresses productivity change as the ratio of two components, productivity change due to output change in the numerator and productivity change due to input change in the denominator. In an Appendix the efficiency measure is extended to include any returns to scale pDDF.},
  archive      = {J_EJOR},
  author       = {Jesus T. Pastor and C.A. Knox Lovell and Juan Aparicio},
  doi          = {10.1016/j.ejor.2019.08.021},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {222-230},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Defining a new graph inefficiency measure for the proportional directional distance function and introducing a new malmquist productivity index},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A nonlinear multidimensional knapsack problem in the optimal
design of mixture experiments. <em>EJOR</em>, <em>281</em>(1), 201–221.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixture experiments usually involve various constraints on the proportions of the ingredients of the mixture under study. In this paper, inspired by the fact that the available stock of certain ingredients is often limited, we focus on a new type of constraint, which we refer to as an ingredient availability constraint. This type of constraint substantially complicates the search for optimal designs for mixture experiments. One difficulty, for instance, is that the optimal number of experimental runs is not known a priori. The resulting optimal experimental design problem belongs to the class of nonlinear nonseparable multidimensional knapsack problems. We present a variable neighborhood search algorithm as well as a mixed integer nonlinear programming approach to tackle the problem to identify D- and I-optimal designs for mixture experiments when there is a limited stock of certain ingredients, and we show that the variable neighborhood search algorithm is highly competitive in terms of solution quality and computing time.},
  archive      = {J_EJOR},
  author       = {P. Goos and U. Syafitri and B. Sartono and A.R. Vazquez},
  doi          = {10.1016/j.ejor.2019.08.020},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {201-221},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A nonlinear multidimensional knapsack problem in the optimal design of mixture experiments},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-process production scheduling with variable renewable
integration and demand response. <em>EJOR</em>, <em>281</em>(1),
186–200. (<a href="https://doi.org/10.1016/j.ejor.2019.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating renewable energy sources to power manufacturing facilities is one approach to achieve low carbon economy. The contribution of this paper is to propose a way to facilitate and assess renewable sources’ integration into manufacturing systems, by exploring an optimization model that obtains a production schedule adapted to match the onsite renewable energy supply, with energy storage systems and the power grid as backups. A multi-process production scheme as well as demand side management policies such as Time-and-Level-of-Use and power consumption reduction requests are considered. To capture renewable uncertainties, a two-stage robust optimization model is formulated to optimize the production scheduling under the worst-case scenario of renewable generation. A nested Column-and-Constraint Generation algorithm is applied to solve this formulation. Numerical experiments are performed on a benchmark case, and sensitivity analysis is conducted by modifying renewable integration, uncertainty, data granularity, scheduling horizon, switch of on-peak prices hours, and zero-inventory policy. Obtained results validate the proposed model and algorithm.},
  archive      = {J_EJOR},
  author       = {José Luis Ruiz Duarte and Neng Fan and Tongdan Jin},
  doi          = {10.1016/j.ejor.2019.08.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {186-200},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-process production scheduling with variable renewable integration and demand response},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A second-order cone model of transmission planning with
alternating and direct current lines. <em>EJOR</em>, <em>281</em>(1),
174–185. (<a href="https://doi.org/10.1016/j.ejor.2019.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a model for transmission planning with both alternating and direct current lines, the latter of which can be interfaced via either line-commutated converters or voltage-source converters. The transmission expansion problem is nonlinear and nonconvex. Thus, nonlinear solvers cannot guarantee their convergence to the global optimum of the problem. We use relaxations and approximations to formulate a mixed-integer second-order cone transmission expansion model, which can be solved to optimality by current industrial solvers. We base our formulation on the branch flow relaxation. We include losses and reactive power placement, and consider direct current lines connected by both line-commutated converters and voltage-sourced converters. We show that our approach lowers the expansion cost on 6-bus and 24-bus system examples. We evaluate the feasibility of our formulation using a semidefinite relaxation of optimal power flow and find that the resulting plan admits feasible or close to feasible power flows.},
  archive      = {J_EJOR},
  author       = {Antoine Lesage-Landry and Joshua A. Taylor},
  doi          = {10.1016/j.ejor.2019.08.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {174-185},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A second-order cone model of transmission planning with alternating and direct current lines},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Considering short-term and long-term uncertainties in
location and capacity planning of public healthcare facilities.
<em>EJOR</em>, <em>281</em>(1), 152–173. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a real-world problem faced by the public healthcare sector. The problem consists of both the patients’ and service provider&#39;s requirements (i.e., accessibility vs. costs) for locating healthcare facilities, allocating service units to those facilities, and determining the facilities’ capacities. The main contribution of this study is capturing both short-term and long-term uncertainties at the modelling stage. The queuing theory is incorporated to consider stochastic demand and service time as a short-term uncertainty, as well as a service level measurement. The developed nonlinear model is then converted into a linear model after introducing a new set of decision variables and proving the properties of the service level constraints. We also demonstrate a way in which a linearized model can become more efficient by eliminating excessive binary variables when service level constraints are approximated using their properties. Additionally, long-term demographic variations are captured through robust optimization in order to create a robust model. To solve the problem under investigation, an evolutionary solution method is designed, and its performance is investigated under different settings. We apply this solution method to determine the location and capacity of healthcare facilities in one of the provinces of Iran. The results illustrate that the suggested network can significantly improve the performance measures compared to the existing network. Furthermore, the importance of robust solution in maintaining the desired service level is demonstrated through examining three levels of demographic variations.},
  archive      = {J_EJOR},
  author       = {Alireza Motallebi Nasrabadi and Mehdi Najafi and Hossein Zolfagharinia},
  doi          = {10.1016/j.ejor.2019.08.014},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {152-173},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Considering short-term and long-term uncertainties in location and capacity planning of public healthcare facilities},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The value of flexible selling: Power production with storage
for spinning reserve provision. <em>EJOR</em>, <em>281</em>(1), 141–151.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A stored commodity is sold under a capacity constraint depending on an exogenous random market price, and, alternatively, a service contract can be provided in which the selling amount must be held constant over time independent of price changes. The seller of the commodity is assumed to optimize the trade-off between the received payment for the provision of the service and the loss of flexibility by the reduced selling on the market. The chosen setup allows for closed-form solutions, such that the analysis is of theoretical interest. A potential application is hydropower storage optimization against exogenous electricity prices with the option to enter contracts for providing spinning reserve; spinning reserve is needed to stabilize large-scale power systems. A single-period model is considered, and the storage level of the commodity is bounded from below in expectation. These simplifications allow a closed-form solution of bang-bang type, even under our assumption of an infinite probability space.},
  archive      = {J_EJOR},
  author       = {M. Densing},
  doi          = {10.1016/j.ejor.2019.08.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {141-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The value of flexible selling: Power production with storage for spinning reserve provision},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equilibria in investment and spot electricity markets: A
conjectural-variations approach. <em>EJOR</em>, <em>281</em>(1),
129–140. (<a href="https://doi.org/10.1016/j.ejor.2019.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study generation-capacity planning in a restructured oligopolistic electricity market, taking a conjectural-variations approach. We do this through a two-stage model that captures an initial set of investments followed by equilibria in a series of spot electricity markets, in which firms make production decisions. Although we model the generating firms as being quantity-setters, we do not model a Nash–Cournot equilibrium. Instead, we assume that the firms endogenize the impacts of their production decisions on rivals through reaction parameters, giving a conjectural-variations model of the spot-market equilibrium. Equilibrium conditions in each spot market, as a function of the investment decisions, are derived. This allows characterizing an equilibrium at the investment stage. The proposed model allows the derivation of analytical expressions that characterize such multi-stage equilibria. This proposed model provides insights on the outcomes and characteristics of investment decisions in an imperfectly competitive market setting. Such insights may allow policymakers to understand the efficiency implications of oligopolistic market structures.},
  archive      = {J_EJOR},
  author       = {Seyedamirabbas Mousavian and Antonio J. Conejo and Ramteen Sioshansi},
  doi          = {10.1016/j.ejor.2019.07.054},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {129-140},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Equilibria in investment and spot electricity markets: A conjectural-variations approach},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The influence of coupon duration on consumers’ redemption
behavior and brand profitability. <em>EJOR</em>, <em>281</em>(1),
114–128. (<a href="https://doi.org/10.1016/j.ejor.2019.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes an analytical model of the joint optimization of coupon face value and duration together with the product price, and determines the impact of coupon design on consumers’ redemption behavior. A model of rational forward-looking consumers’ redemption behavior is derived that incorporates forgetting (to redeem) and stochastic redemption costs. Results show that when product price is exogenous, long-duration coupons may result in increased seller profits and always increase consumer surplus. Moreover, a one-period coupon is never optimal when (1) the difference in valuations for high-value (loyal) and low-value (non-loyal) consumers or (2) the coupon face value is larger than the redemption costs of high-value consumers. Long-duration coupons tend to be optimal when the level of recall of high-value consumers is sufficiently low, which reduces redemption by high-value consumers. Coupon duration together with face value plays an important role in coupons’ ability to price discriminate between different consumer segments and to avoid head-on competition with other sellers. Results can replicate empirically observed redemptions patterns, which has important implications for the strategic targeting of coupons to different consumer segments. A coupon may result in an increase or decrease in price. When the difference in valuation between high-value and low-value consumers is high (relative to the redemption costs), a seller can either reduce price and lower face value or increase coupon duration for the purpose of avoiding redemption by high-value consumers.},
  archive      = {J_EJOR},
  author       = {Zhang Zelin and Ma Minghui and Peter T.L. Popkowski Leszczyc and Zhuang Hejun},
  doi          = {10.1016/j.ejor.2019.08.029},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {114-128},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The influence of coupon duration on consumers’ redemption behavior and brand profitability},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An alternative efficient representation for the project
portfolio selection problem. <em>EJOR</em>, <em>281</em>(1), 100–113.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Project portfolio selection problem (PPSP) is usually formulated as a mixed integer polynomial program with cross-product terms. The problem is hard to solve due to the non-convex cross-product terms involved. To find an exact optimal solution, currently available methods adopt different linearization techniques to handle the cross-product terms and then utilize a branch-and-bound scheme for computations. This study proposes an alternative efficient representation for PPSP using fewer continuous variables than the current methods to achieve global optimum. Numerical experiments are presented to demonstrate the effectiveness and efficiency of the proposed method. In addition, the proposed method is integrated with a general binary cut scheme for identifying all alternative solutions for decision makers to consider better options.},
  archive      = {J_EJOR},
  author       = {Xingmei Li and Yao-Huei Huang and Shu-Cherng Fang and Youzhong Zhang},
  doi          = {10.1016/j.ejor.2019.08.022},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {100-113},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An alternative efficient representation for the project portfolio selection problem},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A critical analysis of multi-criteria models for the
prioritisation of health threats. <em>EJOR</em>, <em>281</em>(1), 87–99.
(<a href="https://doi.org/10.1016/j.ejor.2019.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria assessments are increasingly being employed in the prioritisation of health threats, supporting decision processes related to health risk management. The use of multi-criteria analysis in this context is welcome, as it facilitates the consideration of multiple impacts of health threats, it can encompass the use of expert judgment to complement and amalgamate the evidence available, and it permits the modelling of policy makers’ priorities. However, these assessments often lack a clear multi-criteria conceptual framework, in terms of both axiomatic rigour and adequate procedures for preference modelling. Such assessments are ad hoc from a multi-criteria decision analysis perspective, despite the strong health expertise used in constructing these models. In this paper we critically examine some key assumptions and modelling choices made in these assessments, comparing them with the best practices of multi-attribute value analysis. Furthermore, we suggest a set of guidelines on how simulation studies might be employed to assess the impact of these modelling choices. We apply these guidelines to two relevant studies available in the health threat prioritisation domain. We identify severe variability in our simulations due to poor modelling choices, which could cause changes in the ranking of threats being assessed and thus lead to alternative policy recommendations than those suggested in their reports. Our results confirm the importance of carefully designing multi-criteria evaluation models for the prioritisation of health threats.},
  archive      = {J_EJOR},
  author       = {Gilberto Montibeller and Pratik Patel and Victor J. del Rio Vilas},
  doi          = {10.1016/j.ejor.2019.08.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {87-99},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A critical analysis of multi-criteria models for the prioritisation of health threats},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranking flexibility structures in queueing systems.
<em>EJOR</em>, <em>281</em>(1), 77–86. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of comparing flexibility structures in queueing systems. We find that an important issue in evaluating flexibility is that one cannot separately consider the design of a flexibility structure and the choice of a server scheduling policy. We propose a policy that leverages flexibility in a more predictable (and typically more effective) manner than several common policies and find that the proposed policy is a useful basis for comparisons. In terms of evaluating flexibility, we take as a starting point the CF index of Iravani, Kolfal, and van Oyen (2011) and find that by breaking it down to its components, we are able to identify scenarios in which the CF index may incorrectly compare flexibility structures in systems with heterogeneous variability in the underlying interarrival time and service requirement distributions. For such scenarios, we propose a distribution-dependent metric for performing the ranking. A consequence of our observations is the ability to construct partial rankings that appear to be relatively insensitive to the underlying distributions.},
  archive      = {J_EJOR},
  author       = {Sigrún Andradóttir and Hayriye Ayhan and Douglas G. Down},
  doi          = {10.1016/j.ejor.2019.09.002},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {77-86},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Ranking flexibility structures in queueing systems},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Late-rejection, a strategy to perform an overflow policy.
<em>EJOR</em>, <em>281</em>(1), 66–76. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by overflow policies implemented in service systems, we consider a multi-server queue with customers’ abandonment where rejection control is exercised on customers currently waiting in the queue. Our aim is to find a good balance between conflicting goals, namely, the rate of rejected customers and a cost function which may involve wait and abandonment metrics like percentiles of the waiting time or rate of abandonment. We develop a Markov decision process approach where the waiting time of the first customer in line is used in a discretized form to define the system state. We show that a time-based threshold policy is optimal, and develop a procedure to compute the optimal threshold. Our analysis explains some known behaviors in practice. For instance, if the cost function is constant in the system state like with wait percentiles, then the optimal threshold is one of the time limits defining the percentiles. Also, abandonment is shown to have beneficial or detrimental effect depending on the system manager’s objective.},
  archive      = {J_EJOR},
  author       = {Benjamin Legros},
  doi          = {10.1016/j.ejor.2019.08.037},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {66-76},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Late-rejection, a strategy to perform an overflow policy},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic network model with persistent links and
node-specific latent variables, with an application to the interbank
market. <em>EJOR</em>, <em>281</em>(1), 50–65. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a dynamic network model where two mechanisms control the probability of a link between two nodes: (i) the existence or absence of this link in the past, and (ii) node-specific latent variables (dynamic fitnesses) describing the propensity of each node to create links. Assuming a Markov dynamics for both mechanisms, we propose an Expectation-Maximization algorithm for model estimation and inference of the latent variables. The estimated parameters and fitnesses can be used to forecast the presence of a link in the future. We apply our methodology to the e-MID interbank network for which the two linkage mechanisms are associated with two different trading behaviors in the process of network formation, namely preferential trading and trading driven by node-specific characteristics. The empirical results allow to recognize preferential lending in the interbank market and indicate how a method that does not account for time-varying network topologies tends to overestimate preferential linkage.},
  archive      = {J_EJOR},
  author       = {P. Mazzarisi and P. Barucca and F. Lillo and D. Tantari},
  doi          = {10.1016/j.ejor.2019.07.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {50-65},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dynamic network model with persistent links and node-specific latent variables, with an application to the interbank market},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parametric convex quadratic relaxation of the quadratic
knapsack problem. <em>EJOR</em>, <em>281</em>(1), 36–49. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a parametric convex quadratic programming (CQP) relaxation for the quadratic knapsack problem (QKP). This relaxation maintains partial quadratic information from the original QKP by perturbing the objective function to obtain a concave quadratic term. The nonconcave part generated by the perturbation is then linearized by a standard approach that lifts the problem to matrix space. We present a primal-dual interior point method to optimize the perturbation of the quadratic function, in a search for the tightest upper bound for the QKP. We prove that the same perturbation approach, when applied in the context of semidefinite programming (SDP) relaxations of the QKP, cannot improve the upper bound given by the corresponding linear SDP relaxation. The result also applies to more general integer quadratic problems. Finally, we propose new valid inequalities on the lifted matrix variable, derived from cover and knapsack inequalities for the QKP, and present separation problems to generate cuts for the current solution of the CQP relaxation. Our best bounds are obtained alternating between optimizing the parametric quadratic relaxation over the perturbation and applying cutting planes generated by the valid inequalities proposed.},
  archive      = {J_EJOR},
  author       = {M. Fampa and D. Lubke and F. Wang and H. Wolkowicz},
  doi          = {10.1016/j.ejor.2019.08.027},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {36-49},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Parametric convex quadratic relaxation of the quadratic knapsack problem},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-price algorithm for the two-dimensional vector
packing problem. <em>EJOR</em>, <em>281</em>(1), 25–35. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional vector packing problem is a well-known generalization of the classical bin packing problem. It considers two attributes for each item and bin. Two capacity constraints must be satisfied in a feasible packing solution for each bin. The objective is to minimize the number of bins used. To compute optimal solutions for the problem, we propose a new branch-and-price algorithm. A goal cut that sets a lower bound to the objective is used. It is effective in speeding up column generation by reducing the number of iterations. To efficiently solve the pricing problem, we develop a branch-and-bound method with dynamic programming, which first eliminates conflicts between two items through branching, and then solves the two-constraint knapsack problem at leaf nodes through dynamic programming. Extensive computational experiments were conducted based on 400 test instances from existing literature. Our algorithm significantly outperformed the existing branch-and-price algorithms. Most of the test instances were solved within just a few seconds.},
  archive      = {J_EJOR},
  author       = {Lijun Wei and Minghui Lai and Andrew Lim and Qian Hu},
  doi          = {10.1016/j.ejor.2019.08.024},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {25-35},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A branch-and-price algorithm for the two-dimensional vector packing problem},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A polynomial-time approximation scheme for an arbitrary
number of parallel two-stage flow-shops. <em>EJOR</em>, <em>281</em>(1),
16–24. (<a href="https://doi.org/10.1016/j.ejor.2019.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the approximability of the m parallel two-stage flow-shop (mP2FS) problem, where a set of jobs is scheduled on the multiple identical two-stage flow-shops to minimize the makespan , i.e., the finishing time of the last job. Each job needs to be processed non-preemptively on one flow-shop without switching to the other flow-shops. This problem is a hybrid of the classic parallel machine scheduling and two-stage flow-shop scheduling problems. Its strong NP-hardness follows from the parallel machine scheduling problem when the number of machines is part of the input. Our main contribution is a polynomial-time approximation scheme (PTAS) for the mP2FS problem when the number of shops is part of the input, which improves the previous best approximation algorithm of a ratio ( 2 + ϵ ) (2+ϵ) . Owing to the strong NP-hardness, our PTAS achieves the best possible approximation ratio.},
  archive      = {J_EJOR},
  author       = {Jianming Dong and Ruyan Jin and Taibo Luo and Weitian Tong},
  doi          = {10.1016/j.ejor.2019.08.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {16-24},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A polynomial-time approximation scheme for an arbitrary number of parallel two-stage flow-shops},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Carbon-constrained firm decisions: From business strategies
to operations modeling. <em>EJOR</em>, <em>281</em>(1), 1–15. (<a
href="https://doi.org/10.1016/j.ejor.2019.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic literature review on carbon-constrained operations models. First, carbon constraints are defined and categorized into three genres: policy-driven, market-driven, and nature-driven. Second, business strategies for fulfilling carbon constraints are summarized and classified into three main groups: internal emissions abatement, collaborative emissions abatement, and carbon compensation. Subsequently, ten specific types of carbon-constrained operations models are studied in support of these business strategies. Lastly, the research trend is analyzed and a conceptual studying framework is proposed. The results show that the policy-driven carbon constraints are the primary carbon considerations in operations models, with the emissions trading scheme and the carbon tax taking first and second place, respectively. In addition, the focus of carbon-constrained operations models evolves from short-term to long-term strategies, from internal to collaborative abatement strategies, and from simple to more practical models. From the carbon constraint modeling perspective, future studies regarding the coexistence of multiple carbon constraints and their interactive effects might have interesting results. From the business strategy perspective, the collaborative emissions abatement models, especially horizontal co-opetition mechanisms, remain to be further explored.},
  archive      = {J_EJOR},
  author       = {Zhou P. and Wen Wen},
  doi          = {10.1016/j.ejor.2019.02.050},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Carbon-constrained firm decisions: From business strategies to operations modeling},
  volume       = {281},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bayesian approach to continuous type principal-agent
problems. <em>EJOR</em>, <em>280</em>(3), 1188–1192. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Singham (2019) proposed an important advance in the numerical solution of continuous type principal-agent problems using Monte Carlo simulations from the distribution of agent “types” followed by bootstrapping. In this paper, we propose a Bayesian approach to the problem which produces nearly the same results without the need to rely on optimization or lower and upper bounds for the optimal value of the objective function. Specifically, we cast the problem in terms of maximizing the posterior expectation with respect to a suitable posterior measure. In turn, we use efficient Markov Chain Monte Carlo techniques to perform the computations.},
  archive      = {J_EJOR},
  author       = {A. George Assaf and Ruijun Bu and Mike G. Tsionas},
  doi          = {10.1016/j.ejor.2019.07.058},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1188-1192},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A bayesian approach to continuous type principal-agent problems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effects of proactive decision making on life satisfaction.
<em>EJOR</em>, <em>280</em>(3), 1171–1187. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proactive decision making, a concept recently introduced to behavioral operational research and decision analysis, addresses effective decision making during its phase of generating alternatives. It is measured on a scale comprising six dimensions grouped into two categories: proactive personality traits and proactive cognitive skills . Personality traits are grounded on theoretical constructs such as proactive attitude and proactive behavior; cognitive skills reflect value-focused thinking and decision quality. These traits and skills have been used to explain decision satisfaction, although their antecedents and other consequences have not yet been the subject of rigorous hypotheses and testing. This paper embeds proactive decision making within a model of three possible consequences. We consider—and empirically test—decision satisfaction, general self-efficacy, and life satisfaction by conducting three studies with 1300 participants. We then apply structural equation modeling to show that proactive decision making helps to account for life satisfaction, an explanation mediated by general self-efficacy and decision satisfaction. Thus proactive decision making fosters greater belief in one&#39;s abilities and increases satisfaction with one&#39;s decisions and with life more generally. These results imply that it is worthwhile to help individuals enhance their decision-making proactivity. Demonstrating the positive effects of proactive decision making at the individual level underscores how important the phase of generating alternatives is, and it also highlights the merit of employing “decision quality” principles and being proactive during that phase. Hence the findings presented here confirm the relevance of OR, and of decision-analytic principles, to the lives of ordinary people.},
  archive      = {J_EJOR},
  author       = {Johannes Ulrich Siebert and Reinhard E. Kunz and Philipp Rolf},
  doi          = {10.1016/j.ejor.2019.08.011},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1171-1187},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Effects of proactive decision making on life satisfaction},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shortest paths with ordinal weights. <em>EJOR</em>,
<em>280</em>(3), 1160–1170. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the single-source-single-destination “shortest” path problem in directed, acyclic graphs with ordinal weighted arc costs. We define the concepts of ordinal dominance and efficiency for paths and their associated ordinal levels, respectively. Further, we show that the number of ordinally non-dominated path vectors from the source node to every other node in the graph is polynomially bounded and we propose a polynomial time labeling algorithm for solving the problem of finding the set of ordinally non-dominated path vectors from source to sink.},
  archive      = {J_EJOR},
  author       = {Luca E. Schäfer and Tobias Dietz and Nicolas Fröhlich and Stefan Ruzika and José R. Figueira},
  doi          = {10.1016/j.ejor.2019.08.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1160-1170},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Shortest paths with ordinal weights},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining guaranteed and spot markets in display
advertising: Selling guaranteed page views with stochastic demand.
<em>EJOR</em>, <em>280</em>(3), 1144–1159. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While page views are often sold instantly through real-time auctions when users visit websites, they can also be sold in advance via guaranteed contracts. In this paper, we present a dynamic programming model to study how an online publisher should optimally allocate and price page views between guaranteed and spot markets. The problem is challenging because the allocation and pricing of guaranteed contracts affect how advertisers split their purchases between the two markets, and the terminal value of the model is endogenously determined by the updated dual force of supply and demand in auctions. We take the advertisers’ purchasing behaviour into consideration, i.e., risk aversion and stochastic demand arrivals, and present a scalable and efficient algorithm for the optimal solution. The model is also empirically validated with a commercial dataset. The experimental results show that selling page views via both channels can increase the publisher’s expected total revenue, and the optimal pricing and allocation strategies are robust to different market and advertiser types.},
  archive      = {J_EJOR},
  author       = {Bowei Chen and Jingmin Huang and Yufei Huang and Stefanos Kollias and Shigang Yue},
  doi          = {10.1016/j.ejor.2019.07.067},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1144-1159},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining guaranteed and spot markets in display advertising: Selling guaranteed page views with stochastic demand},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal consumption and investment strategies with liquidity
risk and lifetime uncertainty for markov regime-switching jump diffusion
models. <em>EJOR</em>, <em>280</em>(3), 1130–1143. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the optimal consumption and investment strategies for households throughout their lifetime. Risks such as the illiquidity of assets, abrupt changes of market states, and lifetime uncertainty are considered. Taking the effects of heritage into account, investors are willing to limit their current consumption in exchange for greater wealth at their death, because they can take advantage of the higher expected returns of illiquid assets. Further, we model the liquidity risks in an illiquid market state by introducing frozen periods with uncertain lengths, during which investors cannot continuously rebalance their portfolios between different types of assets. In liquid market, investors can continuously remix their investment portfolios. In addition, a Markov regime-switching process is introduced to describe the changes in the market’s states. Jumps, classified as either moderate or severe, are jointly investigated with liquidity risks. Explicit forms of the optimal consumption and investment strategies are developed using the dynamic programming principle. Markov chain approximation methods are adopted to obtain the value function. Numerical examples demonstrate that the liquidity of assets and market states have significant effects on optimal consumption and investment strategies in various scenarios.},
  archive      = {J_EJOR},
  author       = {Zhuo Jin and Guo Liu and Hailiang Yang},
  doi          = {10.1016/j.ejor.2019.07.066},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1130-1143},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal consumption and investment strategies with liquidity risk and lifetime uncertainty for markov regime-switching jump diffusion models},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attacking and defending multiple valuable secrets in a big
data world. <em>EJOR</em>, <em>280</em>(3), 1122–1129. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the attack-and-defence game between a web user and a whole set of players over this user’s ‘valuable secrets.’ The number and type of these valuable secrets are the user’s private information. Attempts to tap information as well as privacy protection are costly. The multiplicity of secrets is of strategic value for the holders of these secrets. Users with few secrets keep their secrets private with some probability, even though they do not protect them. Users with many secrets protect their secrets at a cost that is smaller than the value of the secrets protected. The analysis also accounts for multiple redundant information channels with cost asymmetries, relating the analysis to attack-and-defence games with a weakest link.},
  archive      = {J_EJOR},
  author       = {Kai A. Konrad},
  doi          = {10.1016/j.ejor.2019.07.064},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1122-1129},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Attacking and defending multiple valuable secrets in a big data world},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Competing trade mechanisms and monotone mechanism choice.
<em>EJOR</em>, <em>280</em>(3), 1108–1121. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the choice between posted prices and auctions of competing sellers with private valuations. Assuming that buyers face higher hassle costs in auctions, we show the existence of monotone pure strategy equilibria where sellers offer posted prices rather than auctions if and only if they have a sufficiently high reservation value. Posted prices sell with lower probability but yield a larger revenue in case of trade. Using an empirical strategy to compare revenues of posted prices and auctions that takes selling probabilities explicitly into account, we find our theoretical predictions supported by data from eBay auctions on ticket sales for the EURO 2008 European Football Championship.},
  archive      = {J_EJOR},
  author       = {Eberhard Feess and Christian Grund and Markus Walzl and Ansgar Wohlschlegel},
  doi          = {10.1016/j.ejor.2019.08.013},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1108-1121},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Competing trade mechanisms and monotone mechanism choice},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving fairness in ambulance planning by time sharing.
<em>EJOR</em>, <em>280</em>(3), 1095–1107. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most literature on the ambulance location problem aims to maximize coverage, i.e., the fraction of people that can be reached within a certain response time threshold. Such a problem often has one optimum, but several near-optimal solutions may exist. These may have a similar overall performance but provide different coverage for different regions. This raises the question: are we making ‘arbitrary’ choices in terms of who gets coverage and who does not? In this paper we propose to share time between several good ambulance configurations in the interest of fairness. We argue that the Bernoulli–Nash social welfare measure should be used to evaluate the fairness of the system. Therefore, we formulate a nonlinear optimization model that determines the fraction of time spent in each configuration to maximize the Bernoulli–Nash social welfare. We solve this model in a case study for an ambulance provider in the Netherlands, using a combination of simulation and optimization. Furthermore, we analyze how the Bernoulli–Nash optimal solution compares to the maximum-coverage solution by formulating and solving a multi-objective optimization model.},
  archive      = {J_EJOR},
  author       = {C.J. Jagtenberg and A.J. Mason},
  doi          = {10.1016/j.ejor.2019.08.003},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1095-1107},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Improving fairness in ambulance planning by time sharing},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimising cargo loading and ship scheduling in tidal areas.
<em>EJOR</em>, <em>280</em>(3), 1082–1094. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a framework that combines decision theory and stochastic optimisation techniques to address tide routing (i.e. optimisation of cargo loading and ship scheduling decisions in tidal ports and shallow seas). Unlike weather routing, tidal routing has been little investigated so far, especially from the perspective of risk analysis. Considering the journey of a bulk carrier between N ports, a shipping decision model is designed to compute cargo loading and scheduling decisions, given the time series of the sea level point forecasts in these ports. Two procedures based on particle swarm optimisation and Monte Carlo simulations are used to solve the shipping net benefit constrained optimisation problem. The outputs of probabilistic risk minimisation are compared with those of net benefit maximisation, the latter including the possibility of a ‘rule-of-the-thumb’ safety margin. Distributional robustness is discussed as well, with respect to the modelling of sea level residuals. Our technique is assessed on two realistic case studies in British ports. Results show that the decision taking into account the stochastic dimension of sea levels is not only robust in real port and weather conditions, but also closer to optimality than standard practices using a fixed safety margin. Furthermore, it is shown that the proposed technique remains more interesting when sea level variations are artificially increased beyond the extremes of the current residual models.},
  archive      = {J_EJOR},
  author       = {Noémie Le Carrer and Scott Ferson and Peter L. Green},
  doi          = {10.1016/j.ejor.2019.08.002},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1082-1094},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimising cargo loading and ship scheduling in tidal areas},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pattern-based models and a cooperative parallel
metaheuristic for high school timetabling problems. <em>EJOR</em>,
<em>280</em>(3), 1064–1081. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High school timetabling problems consist in building periodic timetables for class-teacher meetings considering compulsory and non-compulsory requirements. This family of problems has been widely studied since the 1950s, mostly via mixed-integer programming and metaheuristic techniques. However, the efficient search of optimal or near-optimal solutions is still a challenge for many problems of practical size. In this paper, we investigate mixed-integer programming formulations and a parallel metaheuristic based algorithm for solving high school timetabling problems with compactness and balancing requirements. We propose two pattern-based formulations and a solution algorithm that simultaneously exploits column generation and a team of metaheuristics to build and improve solutions. Extensive computational experiments conducted with real-world instances demonstrate that our formulations are competitive with the best existing high school timetabling formulations, while our parallel algorithm presents superior performance to alternative methods available in the literature.},
  archive      = {J_EJOR},
  author       = {Landir Saviniec and Maristela O. Santos and Alysson M. Costa and Lana M.R. dos Santos},
  doi          = {10.1016/j.ejor.2019.08.001},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1064-1081},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pattern-based models and a cooperative parallel metaheuristic for high school timetabling problems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-stage solution approach for personalized
multi-department multi-day shift scheduling. <em>EJOR</em>,
<em>280</em>(3), 1051–1063. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address a personalized multi-department multi-day shift scheduling problem with a multi-skill heterogeneous workforce where employees can be transferred between departments under some restrictions. The objective is to construct a schedule that minimizes under-coverage, over-coverage, transfer and labor costs. We propose a novel two-stage approach to solve it: the first stage considers an approximate and smaller problem based on data aggregation and produces approximate transfers. The second stage constructs personalized schedules based on the information deduced from the first stage. An exhaustive experimental study is conducted and proves the efficiency of the proposed approach in terms of solution quality and computing times.},
  archive      = {J_EJOR},
  author       = {Sana Dahmen and Monia Rekik and François Soumis and Guy Desaulniers},
  doi          = {10.1016/j.ejor.2019.07.068},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1051-1063},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A two-stage solution approach for personalized multi-department multi-day shift scheduling},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing drinking water distribution system operations.
<em>EJOR</em>, <em>280</em>(3), 1035–1050. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The operation of Water Distribution Systems (WDS) is often complex, especially when considering the changes in tariffs throughout the day. The cost of energy in these systems can reach 30\% of total operating costs and its careful management can represent increased efficiency. The optimization of WDS scheduling operation appears as an effective method to reduce operating costs while ensuring a good service level to the population. In this paper we propose a new linear relaxation for a non-linear integer programming formulation for WDS in order to optimize its operation costs. This study makes five main contributions. First, our formulation includes new aspects related to the state of the system when the tanks are full, that were not considered before in mathematical programming models. Second, our linearization technique includes a variable number of breakpoints, resulting in significantly fewer binary variables for a given error level. Third, our relaxation reduces the search space of the solutions. Fourth, we have outperformed the best results for three benchmark instances from the literature. Lastly, we also provide a larger new real-life instance with specific conditions of energy tariffs, obtained from the WDS from the city of Florianópolis, southern Brazil, significantly outperforming the current solution employed by the utility provider.},
  archive      = {J_EJOR},
  author       = {Bruno S. Vieira and Sérgio F. Mayerle and Lucila M.S. Campos and Leandro C. Coelho},
  doi          = {10.1016/j.ejor.2019.07.060},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1035-1050},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimizing drinking water distribution system operations},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Automating the planning of container loading for atlas
copco: Coping with real-life stacking and stability constraints.
<em>EJOR</em>, <em>280</em>(3), 1018–1034. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Atlas Copco ☆ distribution center in Allen, TX, supplies spare parts and consumables to mining and construction companies across the world. For some customers, packages are shipped in sea containers. Planning how to load the containers is difficult due to several factors: heterogeneity of the packages with respect to size, weight, stackability, positioning and orientation; the set of packages differs vastly between shipments; it is crucial to avoid cargo damage. Load plan quality is ultimately judged by shipping operators. This container loading problem is thus rich with respect to practical considerations. These are posed by the operators and include cargo and container stability as well as stacking and positioning constraints. To avoid cargo damage, the stacking restrictions are modeled in detail. For solving the problem, we developed a two-level metaheuristic approach and implemented it in a decision support system. The upper level is a genetic algorithm which tunes the objective function for a lower level greedy-type constructive placement heuristic, to optimize the quality of the load plan obtained. The decision support system shows load plans on the forklift laptops and has been used for over two years. Management has recognized benefits including reduction of labour usage, lead time, and cargo damage risk.},
  archive      = {J_EJOR},
  author       = {Jonas Olsson and Torbjörn Larsson and Nils-Hassan Quttineh},
  doi          = {10.1016/j.ejor.2019.07.057},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1018-1034},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Automating the planning of container loading for atlas copco: Coping with real-life stacking and stability constraints},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unsupervised quadratic surface support vector machine with
application to credit risk assessment. <em>EJOR</em>, <em>280</em>(3),
1008–1017. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised classification is a highly important task of machine learning methods. Although achieving great success in supervised classification, support vector machine (SVM) is much less utilized to classify unlabeled data points, which also induces many drawbacks including sensitive to nonlinear kernels and random initializations, high computational cost, unsuitable for imbalanced datasets. In this paper, to utilize the advantages of SVM and overcome the drawbacks of SVM-based clustering methods, we propose a completely new two-stage unsupervised classification method with no initialization: a new unsupervised kernel-free quadratic surface SVM (QSSVM) model is proposed to avoid selecting kernels and related kernel parameters, then a golden-section algorithm is designed to generate the appropriate classifier for balanced and imbalanced data. By studying certain properties of proposed model, a convergent decomposition algorithm is developed to implement this non-covex QSSVM model effectively and efficiently (in terms of computational cost). Numerical tests on artificial and public benchmark data indicate that the proposed unsupervised QSSVM method outperforms well-known clustering methods (including SVM-based and other state-of-the-art methods), particularly in terms of classification accuracy. Moreover, we extend and apply the proposed method to credit risk assessment by incorporating the T-test based feature weights. The promising numerical results on benchmark personal credit data and real-world corporate credit data strongly demonstrate the effectiveness, efficiency and interpretability of proposed method, as well as indicate its significant potential in certain real-world applications.},
  archive      = {J_EJOR},
  author       = {Jian Luo and Xin Yan and Ye Tian},
  doi          = {10.1016/j.ejor.2019.08.010},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {1008-1017},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Unsupervised quadratic surface support vector machine with application to credit risk assessment},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). As simple as possible but not simpler in multiple criteria
decision aiding: The robust-stochastic level dependent choquet integral
approach. <em>EJOR</em>, <em>280</em>(3), 988–1007. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The level dependent Choquet integral has been proposed to handle decision making problems in which the importance and the interaction of criteria may depend on the level of the alternatives’ evaluations. This integral is based on a level dependent capacity, which is a family of single capacities associated to each level of evaluation for the considered criteria. We present two possible formulations of the level dependent capacity where importance and interaction of criteria are constant inside each one of the subintervals in which the interval of evaluations for considered criteria is split or vary with continuity inside the whole interval of evaluations. Since, in general, there is not only one but many level dependent capacities compatible with the preference information provided by the Decision Maker, we propose to take into account all of them by using the Robust Ordinal Regression (ROR) and the Stochastic Multicriteria Acceptability Analysis (SMAA). On one hand, ROR defines a necessary preference relation (if an alternative a is at least as good as an alternative b for all compatible level dependent capacities), and a possible preference relation (if a is at least as good as b for at least one compatible level dependent capacity). On the other hand, considering a random sampling of compatible level dependent capacities, SMAA gives the probability that each alternative reaches a certain ranking position as well as the probability that an alternative is preferred to another. A real-world decision problem on rankings of universities is provided to illustrate the proposed methodology.},
  archive      = {J_EJOR},
  author       = {Sally Giuseppe Arcidiacono and Salvatore Corrente and Salvatore Greco},
  doi          = {10.1016/j.ejor.2019.07.065},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {988-1007},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {As simple as possible but not simpler in multiple criteria decision aiding: The robust-stochastic level dependent choquet integral approach},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing and equity in cross-regional green supply chains.
<em>EJOR</em>, <em>280</em>(3), 970–987. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of the firms operating on cross-border or inter-regional platforms that are subject to the enforcement of each local government&#39;s carbon emissions regulatory policy, thus causing an imbalance in the sharing of the burden of the greening of the total supply chain. We introduce the concept of equity as the incentive mechanism to coordinate this green supply chain which is a function of the carbon emission permits and the revenue generated by the firms. Due to the complexity and imbalance in the original incentive mechanism to this problem, we provide a new equivalent supply chain network equilibrium model under elastic demand based on user equilibrium theory. We state the user equilibrium conditions and provide the equivalent formulation. We show the trade-offs under various carbon emissions regulatory policies. A product with higher price elasticity and carbon emission intensity not only hampers the firm from gaining a higher revenue, but it also reduces the equity of the system under an invariant emission regulatory policy.},
  archive      = {J_EJOR},
  author       = {Chen Daqiang and Joshua Ignatius and Sun Danzhi and Mark Goh and Shalei Zhan},
  doi          = {10.1016/j.ejor.2019.07.059},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {970-987},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Pricing and equity in cross-regional green supply chains},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recovery management for a dial-a-ride system with real-time
disruptions. <em>EJOR</em>, <em>280</em>(3), 953–969. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem considered in this work stems from a non-profit organization in charge of door-to-door passenger transportation for medical appointments. Patients are picked up at home by a driver and are then dropped at their appointment location. They may also be driven back home at the end of their appointment. Some patients have specific requirements, e.g., they may require an accompanying person or a wheelchair. Planning such activities gives rise to a so-called dial-a-ride problem. In the present work, it is assumed that the requests assigned to the drivers have been selected, and the transportation plan has been established for the next day. However, in practice, appointment durations may vary due to unforeseen circumstances, and some transportation requests may be modified, delayed or canceled during the day. The aim of this work is to propose a reactive algorithm which can adapt the initial plan in order to manage the disruptions and to take care of as many patients as possible in real-time. The plan should be modified quickly when a perturbation is observed, without resorting to major changes which may confuse the drivers and the patients. Several recourse procedures are defined for this purpose. They allow the dispatcher to temporarily delete a request, to insert a previously deleted request, or to permanently cancel a request. Simulation techniques are used to test the approach on randomly generated scenarios. Several key performance indicators are introduced in order to measure the impact of the disruptions and the quality of the solutions.},
  archive      = {J_EJOR},
  author       = {Célia Paquay and Yves Crama and Thierry Pironet},
  doi          = {10.1016/j.ejor.2019.08.006},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {953-969},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Recovery management for a dial-a-ride system with real-time disruptions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The parallel stack loading problem minimizing the number of
reshuffles in the retrieval stage. <em>EJOR</em>, <em>280</em>(3),
940–952. (<a href="https://doi.org/10.1016/j.ejor.2019.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the parallel stack loading problem (PSLP) with the objective to minimize the number of reshuffles in the retrieval stage. Since in the PSLP the incoming items have to be stored according to a fixed arrival sequence, some reshuffles cannot be avoided later on. We study two surrogate objective functions (number of unordered stackings, number of badly placed items) to estimate the number of reshuffles and compare them theoretically as well as in a computational study. For this purpose, MIP formulations and a simulated annealing algorithm are proposed.},
  archive      = {J_EJOR},
  author       = {Sven Boge and Sigrid Knust},
  doi          = {10.1016/j.ejor.2019.08.005},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {940-952},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The parallel stack loading problem minimizing the number of reshuffles in the retrieval stage},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The shelf space and pricing strategies for a
retailer-dominated supply chain with consignment based revenue sharing
contracts. <em>EJOR</em>, <em>280</em>(3), 926–939. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a two-echelon supply chain consisting of two manufacturers and a dominant retailer, such as big supermarkets like Walmart. Under a consignment contract with revenue sharing, the two manufacturers sell through the retailer two substitutable products whose demands are dependent on their shelf space and sales prices. The two manufacturers may compete horizontally for shelf space and pricing by three scenarios: Nash game, Stackelberg game, and collusion, and play vertically the retailer-Stackelberg game with the retailer. For each of these horizontal scenarios, we present all participators’ equilibrium strategies and their corresponding profits, based on which the impacts of manufacturers’ cost difference and moving sequence are investigated. Additionally, we discuss whether a horizontal collusion among manufacturers occurs when they choose their scenarios and whether centralization is always beneficial for the entire chain under the considered consignment contract. The study reveals the following results: (i) When the manufacturers compete horizontally, the high-cost manufacturer always sets a high-price and less shelf space strategy, while the low-cost manufacturer always adopts a low-price and more shelf space strategy, which is not affected by their moving sequence. If they collude horizontally, it is just reverse. (ii) When the two manufacturers compete horizontally, all participators’ equilibrium strategies and their corresponding profits are significantly influenced by manufacturers’ moving sequence. (iii) A horizontal collusion between the manufacturers can occur only when their cost difference is relatively small; this finding supplements existing literature. (iv) When the cost difference between manufacturers is relatively big, then centralization may be detrimental to the entire chain, which can explain why several supply chains adopt vertical competition strategies in practice. In addition, we find that these results still hold for the limited shelf space scenario and shelf-space limitation enhances the horizontal and vertical competition intensity by increasing shelf space fee.},
  archive      = {J_EJOR},
  author       = {Ju Zhao and Yong-Wu Zhou and Zong-Hong Cao and Jie Min},
  doi          = {10.1016/j.ejor.2019.07.074},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {926-939},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The shelf space and pricing strategies for a retailer-dominated supply chain with consignment based revenue sharing contracts},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust empty container repositioning considering foldable
containers. <em>EJOR</em>, <em>280</em>(3), 909–925. (<a
href="https://doi.org/10.1016/j.ejor.2019.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the extreme imbalance in intercontinental trade, the repositioning of empty containers creates a significant problem for shipping companies. There are many efforts to reduce the cost of repositioning empty containers, one of which is a foldable container. This paper proposes a robust formulation for the empty container repositioning problem considering foldable containers under demand uncertainty. The robust formulation can be used as a tractable approximation of a multistage stochastic programming formulation which is computationally intractable. Moreover, the robust formulation requires only limited information about the distribution of demand to replicate real-world situations. Computational results show that the proposed formulation performs well in terms of operating costs and there exists a significant cost-saving effect when foldable containers are used in maritime transportation.},
  archive      = {J_EJOR},
  author       = {Sangyoon Lee and Ilkyeong Moon},
  doi          = {10.1016/j.ejor.2019.08.004},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {909-925},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Robust empty container repositioning considering foldable containers},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A supply chain network economic model with time-based
competition. <em>EJOR</em>, <em>280</em>(3), 889–908. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an integrated model for time-cost competition between supply chains with heterogeneous customers. The firms in our model can offer various time options for their production/service to time-sensitive customers. This gives rise of a new concept of time-based supply chain, which we call T-chain, to be the basic element in the competition and extends the inter supply chain competition to a new dimension of time. Assuming the customers are heterogeneous in time-cost bi-criteria decision making, we integrate the discrete choice theory into supply chain network competition and formulate the equilibrium conditions as a multinomial logit based variational inequality problem. Numerical examples are presented for model illustration and managerial insights such as profit maximization for a firm who participates in this supply chain network.},
  archive      = {J_EJOR},
  author       = {Ma Jun and Zhang Ding and Dong June and Tu Yiliu (Paul)},
  doi          = {10.1016/j.ejor.2019.07.063},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {889-908},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A supply chain network economic model with time-based competition},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal hierarchies with autocorrelation for load
forecasting. <em>EJOR</em>, <em>280</em>(3), 876–888. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose four different estimators that take into account the autocorrelation structure when reconciling forecasts in a temporal hierarchy. Combining forecasts from multiple temporal aggregation levels exploits information differences and mitigates model uncertainty, while reconciliation ensures a unified prediction that supports aligned decisions at different horizons. In previous studies, weights assigned to the forecasts were given by the structure of the hierarchy or the forecast error variances without considering potential autocorrelation in the forecast errors. Our first estimator considers the autocovariance matrix within each aggregation level. Since this can be difficult to estimate, we propose a second estimator that blends autocorrelation and variance information, but only requires estimation of the first-order autocorrelation coefficient at each aggregation level. Our third and fourth estimators facilitate information sharing between aggregation levels using robust estimates of the cross-correlation matrix and its inverse. We compare the proposed estimators in a simulation study and demonstrate their usefulness through an application to short-term electricity load forecasting in four price areas in Sweden. We find that by taking account of auto- and cross-covariances when reconciling forecasts, accuracy can be significantly improved uniformly across all frequencies and areas.},
  archive      = {J_EJOR},
  author       = {Peter Nystrup and Erik Lindström and Pierre Pinson and Henrik Madsen},
  doi          = {10.1016/j.ejor.2019.07.061},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {876-888},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Temporal hierarchies with autocorrelation for load forecasting},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling with release dates and preemption to minimize
multiple max-form objective functions. <em>EJOR</em>, <em>280</em>(3),
860–875. (<a href="https://doi.org/10.1016/j.ejor.2019.07.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study multi-agent scheduling with release dates and preemption on a single machine, where the scheduling objective function of each agent to be minimized is regular and of the maximum form (max-form). The multi-agent aspect has three versions, namely ND-agent (multiple agents with non-disjoint job sets), ID-agent (multiple agents with an identical job set), and CO-agent (multiple competing agents with mutually disjoint job sets). We consider three types of problems: The first type (type-1) is the constrained scheduling problem, in which one objective function is to be minimized, subject to the restriction that the values of the other objective functions are upper bounded. The second type (type-2) is the weighted-sum scheduling problem, in which a positive combination of the objective functions is to be minimized. The third type (type-3) is the Pareto scheduling problem, for which we aim to find all the Pareto-optimal points and their corresponding Pareto-optimal schedules. We show that the type-1 problems are polynomially solvable, and the type-2 and type-3 problems are strongly NP -hard even when all jobs’ release dates are zero and processing times are one. When the number of the scheduling criteria is fixed and they are all lateness-like, such as minimizing C max , F max , L max , T max , and WC max , where WC max is the maximum weighted completion time of the jobs, the type-2 and type-3 problems are polynomially solvable. To address the type-3 problems, we develop a new solution technique that guesses the Pareto-optimal points through some elaborately constructed schedule-configurations.},
  archive      = {J_EJOR},
  author       = {Jinjiang Yuan and C.T. Ng and T.C.E. Cheng},
  doi          = {10.1016/j.ejor.2019.07.072},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {860-875},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Scheduling with release dates and preemption to minimize multiple max-form objective functions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decomposed branch-and-price procedure for integrating
demand planning in personnel staffing problems. <em>EJOR</em>,
<em>280</em>(3), 845–859. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The personnel staffing problem calculates the required workforce size and is determined by constructing a baseline personnel roster that assigns personnel members to duties in order to cover certain staffing requirements. In this research, we incorporate the planning of the duty demand in the staff scheduling problem in order to lower the staffing costs. More specifically, the demand originates from a project scheduling problem with discrete time/resource trade-offs, which embodies additional flexibility as activities can be executed in different modes. In order to tackle this integrated problem, we propose a decomposed branch-and-price procedure. A tight lower and upper bound are calculated using a problem formulation that models the project scheduling constraints and the time-related resource scheduling constraints implicitly in the decision variables. Based upon these bounds, the strategic problem is decomposed into multiple tactical subproblems with a fixed workforce size and an optimal solution is searched for each subproblem via branch-and-price. Fixing the workforce size in a subproblem facilitates the definition of resource capacity cuts, which limit the set of eligible project schedules, decreasing the size of the branching tree. In addition, in order to find the optimal integer solution, we propose a specific search strategy based upon the lower bound and dedicated rules to branch upon the workload generated by a project schedule. The computational results show that applying the proposed search space decomposition and the inclusion of resource capacity cuts lead to a well-performing procedure outperforming different other heuristic and exact methodologies.},
  archive      = {J_EJOR},
  author       = {M. Van Den Eeckhout and M. Vanhoucke and B. Maenhout},
  doi          = {10.1016/j.ejor.2019.07.069},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {845-859},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A decomposed branch-and-price procedure for integrating demand planning in personnel staffing problems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic traveling salesman problem with stochastic release
dates. <em>EJOR</em>, <em>280</em>(3), 832–844. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic traveling salesman problem with stochastic release dates (DTSP-srd) is a problem in which a supplier has to deliver parcels to its customers. These parcels are delivered to its depot while the distribution is taking place. The arrival time of a parcel to the depot is called its release date. In the DTSP-srd, release dates are stochastic and dynamically updated as the distribution takes place. The objective of the problem is the minimization of the total time needed to serve all customers, given by the sum of the traveling time and the waiting time at the depot. The problem is represented as a Markov Decision Process and is solved through a reoptimization approach. Two models are proposed for the problem to be solved at each stage. The first model is stochastic and exploits the entire probabilistic information available for the release dates. The second model is deterministic and uses an estimation of the release dates. An instance generation procedure is proposed to simulate the evolution of the information to perform computational tests. The results show that a more frequent reoptimization provides better results across all tested instances and that the stochastic model performs better than the deterministic model. The main drawback of the stochastic model lies in the computational time required to evaluate a solution, which makes an iteration of the heuristic substantially more time-consuming than in the case where the deterministic model is used.},
  archive      = {J_EJOR},
  author       = {C. Archetti and D. Feillet and A. Mor and M.G. Speranza},
  doi          = {10.1016/j.ejor.2019.07.062},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {832-844},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic traveling salesman problem with stochastic release dates},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the maximum small-world subgraph problem. <em>EJOR</em>,
<em>280</em>(3), 818–831. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A clique (or a complete subgraph) is a popular model for an “ideal” cluster in a network. However, in many practical applications this notion turns out to be overly restrictive as it requires the existence of all pairwise links within the cluster. Thus, the researchers and practitioners often rely on various clique relaxation ideas for more flexible models of highly connected clusters. In this paper, we propose a new clique relaxation model referred to as a small-world subgraph , which represents a network cluster with “small-world” properties: low average distance and high clustering coefficient. In particular, we demonstrate that the proposed small-world subgraph model has better “cohesiveness” characteristics than other existing clique relaxation models in some worst-case scenarios. The main focus of the paper is on the problem of finding a small-world subgraph of maximum cardinality in a given graph. We describe a mixed integer programming (MIP) formulation of the problem along with several algorithmic enhancements. For solving large-scale instances of the problem we propose a greedy-type heuristic referred to as the iterative depth-first search (IDF) algorithm. Furthermore, we show that the small-world subgraphs identified by the IDF algorithm have an additional property that may be attractive from the practical perspective, namely, 2-connectivity. Finally, we perform extensive computational experiments on real-world and randomly generated networks to demonstrate the performance of the developed computational approaches that also reveal interesting insights about the proposed clique relaxation model.},
  archive      = {J_EJOR},
  author       = {Jongeun Kim and Alexander Veremyev and Vladimir Boginski and Oleg A. Prokopyev},
  doi          = {10.1016/j.ejor.2019.07.042},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {818-831},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On the maximum small-world subgraph problem},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How much to tell your customer? – a survey of three
perspectives on selling strategies with incompletely specified products.
<em>EJOR</em>, <em>280</em>(3), 793–817. (<a
href="https://doi.org/10.1016/j.ejor.2019.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today&#39;s technology facilitates selling strategies that were unthinkable only a few years ago. One increasingly popular strategy uses incompletely specified products (ICSPs). The seller retains the right to specify some details of the product or service after the sale. The selling strategies’ main advantages are an additional dimension for market segmentation and operational flexibility due to supply-side substitution possibilities. Since the strategy became popular with Priceline and Hotwire in the travel industry about two decades ago, it has increasingly been adopted by other industries with stochastic demand and limited capacity as well. At the same time, it is actively researched from the perspectives of strategic operations management, empirics, and revenue management. This paper first describes the application of ICSPs in practice. Then, we introduce the different research communities that are active in this field and relate the terminology they use. The main part is an exhaustive review of the literature on selling ICSPs from the different perspectives. Here, we complement a tabular overview with an introduction into the community and a detailed description of each paper. Finally, possible directions for future research are outlined. We see that strategic operations management has described advantages of ICSPs over other strategies in a variety of settings, but also identified countervailing effects. Today, empirical research is confined to hotels and airlines and largely disconnected from the other perspectives. Operational papers are ample, but mostly concerned with the availability of ICSPs. Research on operational (dynamic) pricing is surprisingly scarce.},
  archive      = {J_EJOR},
  author       = {Jochen Gönsch},
  doi          = {10.1016/j.ejor.2019.02.008},
  journal      = {European Journal of Operational Research},
  number       = {3},
  pages        = {793-817},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {How much to tell your customer? – a survey of three perspectives on selling strategies with incompletely specified products},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Acknowledgement to referees 2019. <em>EJOR</em>,
<em>280</em>(2), 778–792. (<a
href="https://doi.org/10.1016/j.ejor.2019.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EJOR},
  doi          = {10.1016/j.ejor.2019.09.001},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {778-792},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Acknowledgement to referees 2019},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal dynamic marketing-mix policies for frequently
purchased products and services versus consumer durable goods: A
generalized analytic approach. <em>EJOR</em>, <em>280</em>(2), 764–777.
(<a href="https://doi.org/10.1016/j.ejor.2019.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the qualitative characterization of optimal pricing and advertising policies together with the optimal ratio of the advertising elasticity of demand to its price elasticity over time. The problem is studied for frequently purchased products and services (FPS) as well as consumer durable goods (CDG) in both monopolistic and duopolistic markets. Demand dynamics, cost learning and discounting of future profits are taken into consideration. In addition, both the open-loop and feedback methodologies are pursued to characterize and compare the derived optimal policies. The paper uses an analytical approach to characterize the optimal dynamic policies in a general setting as is mathematically tractable, followed by the analysis of more specific models to gain additional managerial insights while maintaining a certain degree of generality. Optimal FPS marketing-mix policies are shown to be different from their CDG counterparts for both monopolistic and duopolistic markets. While the ratio of advertising elasticity to price elasticity appears to have been governed by similar set of rules for FPS and CDG, the direction of change of such ratio over time looks different from each other. Managerial implications and directions for future research are also discussed.},
  archive      = {J_EJOR},
  author       = {Hani I. Mesak and Abdullahel Bari and T. Selwyn Ellis},
  doi          = {10.1016/j.ejor.2019.07.040},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {764-777},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal dynamic marketing-mix policies for frequently purchased products and services versus consumer durable goods: A generalized analytic approach},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Technical change and the von neumann coefficient of uniform
expansion. <em>EJOR</em>, <em>280</em>(2), 754–763. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study technical change for multi-product technologies to examine its effect on economic growth for 27 OECD (Organization for Economic Cooperation and Development) countries during 1951–2014. We review the Malmquist index and reexamine von Neumann’s model of an expanding economy. We estimate the coefficient of uniform expansion via DEA (Data Envelopment Analysis) and use it to measure technical change via a Solow residual and an alternative von Neumann technical change index which equals the difference between the growth rates of the slowest growing output and the fastest growing input. We also exploit a property of constant returns to scale in order to examine technical change of the average technology. During 2005–2014 the Solow residual shows relatively fast technical change. In contrast, the Malmquist, average technology and alternative von Neumann technical change indexes show negative or stagnant technical change.},
  archive      = {J_EJOR},
  author       = {Rolf Färe and Daniel Primont and William L. Weber},
  doi          = {10.1016/j.ejor.2019.07.033},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {754-763},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Technical change and the von neumann coefficient of uniform expansion},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nested conditional value-at-risk portfolio selection: A
model with temporal dependence driven by market-index volatility.
<em>EJOR</em>, <em>280</em>(2), 741–753. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multistage stochastic programming framework, we develop a new method for finding an approximated portfolio allocation solution to the nested Conditional Value-at-Risk model when asset log returns are stagewise dependent. We describe asset log returns through a single-factor model where the driving factor is the market-index log return modeled by a Generalized Autoregressive Conditional Heteroskedasticity process to take into account the serial dependence usually observed. To solve the nested Conditional Value-at-Risk model, we implement a backward induction scheme coupled with cubic spline interpolation that reduces the computational complexity of the optimal portfolio allocation and allows to treat problems otherwise unmanageable.},
  archive      = {J_EJOR},
  author       = {Alessandro Staino and Emilio Russo},
  doi          = {10.1016/j.ejor.2019.07.032},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {741-753},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Nested conditional value-at-risk portfolio selection: A model with temporal dependence driven by market-index volatility},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recursive lower and dual upper bounds for bermudan-style
options. <em>EJOR</em>, <em>280</em>(2), 730–740. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Bermudan options are routinely priced by simulation and least-squares methods using lower and dual upper bounds, the latter are hardly optimized. In this paper, we optimize recursive upper bounds, which are more tractable than the original/nonrecursive ones, and derive two new results: (1) An upper bound based on (a martingale that depends on) stopping times is independent of the next-stage exercise decision and hence cannot be optimized. Instead, we optimize the recursive lower bound, and use its optimal recursive policy to evaluate the upper bound as well. (2) Less time-intensive upper bounds that are based on a continuation-value function only need this function in the continuation region, where this continuation value is less nonlinear and easier to fit (than in the entire support). In the numerical exercise, both upper bounds improve over state-of-the-art methods (including standard least-squares and pathwise optimization). Specifically, the very small gap between the lower and the upper bounds derived in (1) implies the recursive policy and the associated martingale are near optimal, so that these two specific lower/upper bounds are hard to improve, yet the upper bound is tighter than the lower bound.},
  archive      = {J_EJOR},
  author       = {Alfredo Ibáñez and Carlos Velasco},
  doi          = {10.1016/j.ejor.2019.07.031},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {730-740},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Recursive lower and dual upper bounds for bermudan-style options},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic planning framework for the discovery of
complementary, agricultural systems. <em>EJOR</em>, <em>280</em>(2),
707–729. (<a href="https://doi.org/10.1016/j.ejor.2019.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the greatest 21st century challenges is meeting the need to feed a growing world population which is expected to increase by about 35\% by 2050. To meet this challenge, it is necessary to make major improvements on current food production and distribution systems capabilities, as well as to adapt these systems to expected trends such as climate change. Changing climate patterns may present opportunities for unidentified, geographical regions with adequate climate patterns to produce high-value agricultural products in a profitable and sustainable manner. This paper focuses on the design and planning aspects of a discovery process to unearth agri-food supply chains capable of generating attractive return on investments. A stochastic optimization framework is used to develop planting and harvesting schedules for a set of identified regions with complementary weather characteristics. To address the high-level of variability in the problem context, a two-stage stochastic decomposition method is used to consider a larger number of scenarios. As part of the solution process, a modeling scheme is developed that learns past interactions between entering discretized, weather scenarios and optimal first-stage solutions. In this context, machine learning and dimensionality reduction techniques are used to iteratively estimate each region&#39;s probability of belonging to first-stage solutions based on previous solution-scenario results. The implementation of the stochastic framework is shown through a case study applied to multiple locations within the US southwest states of Arizona and New Mexico.},
  archive      = {J_EJOR},
  author       = {Hector Flores and J. Rene Villalobos},
  doi          = {10.1016/j.ejor.2019.07.053},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {707-729},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A stochastic planning framework for the discovery of complementary, agricultural systems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dependent project evaluation and review technique: A
bayesian network approach. <em>EJOR</em>, <em>280</em>(2), 689–706. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Program Evaluation and Review Technique (PERT) dates back to 1959. This method evaluates the uncertainty distribution of a project’s completion time given the uncertain completion times of the activities/tasks comprised within it. Each activity’s uncertainty was defined originally by a unique two parameter beta PERT distribution satisfying what is known to be the PERT mean and PERT variance. In this paper, a three-parameter PERT family of bounded distributions is introduced satisfying that same mean and variance, generalizing the beta PERT distribution. Their additional flexibility allows for the modeling of statistical dependence in a continuous Bayesian network, generalizing in turn the traditional PERT procedure where statistical independence is assumed among beta PERT activity durations. Through currently available Bayesian network software and the construction of that PERT family herein, the coherent monitoring of remaining project completion time uncertainty given partial completion of a project may become more accessible to PERT analysts. An illustrative example demonstrating the benefit of monitoring of remaining project completion time uncertainty as activities complete in that Bayesian fashion shall be presented, including expressions and algorithms for the specification of the three prior parameters for each activity in the project network to adhere to classical the PERT mean and PERT variance and a degree of statistical dependence between them.},
  archive      = {J_EJOR},
  author       = {Johan René van Dorp},
  doi          = {10.1016/j.ejor.2019.07.051},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {689-706},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A dependent project evaluation and review technique: A bayesian network approach},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multistage stochastic demand-side management for
price-making major consumers of electricity in a co-optimized energy and
reserve market. <em>EJOR</em>, <em>280</em>(2), 671–688. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we take an optimization-driven heuristic approach, motivated by dynamic programming, to solve a class of non-convex multistage stochastic optimization problems. We apply this to the problem of optimizing the timing of energy consumption for a large manufacturer who is a price-making major consumer of electricity. We introduce a mixed-integer program that co-optimizes consumption bids and interruptible load reserve offers, for such a major consumer over a finite time horizon. By utilizing Lagrangian methods, we decompose our model through approximately pricing the constraints that link the stages together. We construct look-up tables in the form of consumption-utility curves, and use these to determine optimal consumption levels. We also present heuristics, in order to tackle the non-convexities within our model, and improve the accuracy of our policies. In the second part of the paper, we present stochastic solution methods for our model in which, we reduce the size of the scenario tree by utilizing a tailor-made scenario clustering method. Furthermore, we report on a case study that implements our models for a major consumer in the (full) New Zealand Electricity Market and present numerical results.},
  archive      = {J_EJOR},
  author       = {Mahbubeh Habibian and Anthony Downward and Golbon Zakeri},
  doi          = {10.1016/j.ejor.2019.07.037},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {671-688},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multistage stochastic demand-side management for price-making major consumers of electricity in a co-optimized energy and reserve market},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Formulation and a two-phase matheuristic for the roaming
salesman problem: Application to election logistics. <em>EJOR</em>,
<em>280</em>(2), 656–670. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate a novel logistical problem. The goal is to determine daily tours for a traveling salesperson who collects rewards from activities in cities during a fixed campaign period. We refer to this problem as the Roaming Salesman Problem (RSP) motivated by real-world applications including election logistics, touristic trip planning and marketing campaigns. RSP can be characterized as a combination of the traditional Periodic TSP and the Prize-Collecting TSP with static arc costs and time-dependent node rewards. Commercial solvers are capable of solving small-size instances of the RSP to near optimality in a reasonable time. To tackle large-size instances we propose a two-phase matheuristic where the first phase deals with city selection while the second phase focuses on route generation. The latter capitalizes on an integer program to construct an optimal route among selected cities on a given day. The proposed matheuristic decomposes the RSP into as many subproblems as the number of campaign days. Computational results show that our approach provides near-optimal solutions in significantly shorter times compared to commercial solvers.},
  archive      = {J_EJOR},
  author       = {Masoud Shahmanzari and Deniz Aksen and Saïd Salhi},
  doi          = {10.1016/j.ejor.2019.07.035},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {656-670},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Formulation and a two-phase matheuristic for the roaming salesman problem: Application to election logistics},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal bidding of a virtual power plant on the spanish
day-ahead and intraday market for electricity. <em>EJOR</em>,
<em>280</em>(2), 639–655. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a multi-stage stochastic programming approach to optimize the bidding strategy of a virtual power plant (VPP) operating on the Spanish spot market for electricity. The VPP markets electricity produced in the wind parks it manages on the day-ahead market and on six staggered auction-based intraday markets. Uncertainty enters the problem via stochastic electricity prices as well as uncertain wind energy production. We set up the problem of bidding for one day of operation as a Markov decision process (MDP) that is solved using a variant of the stochastic dual dynamic programming algorithm. We conduct an extensive out-of-sample comparison demonstrating that the optimal policy obtained by the stochastic program clearly outperforms deterministic planning, a pure day-ahead strategy, a benchmark that only uses the day-ahead market and the first intraday market, as well as a proprietary stochastic programming approach developed in the industry. Furthermore, we study the effect of risk aversion as modeled by the nested Conditional Value-at-Risk as well as the impact of changes in various problem parameters.},
  archive      = {J_EJOR},
  author       = {David Wozabal and Gunther Rameseder},
  doi          = {10.1016/j.ejor.2019.07.022},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {639-655},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal bidding of a virtual power plant on the spanish day-ahead and intraday market for electricity},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed integer formulations for a routing problem with
information collection in wireless networks. <em>EJOR</em>,
<em>280</em>(2), 621–638. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a routing-collecting problem where a system of stations is considered. A vehicle is responsible for collecting information generated continuously in the stations and to deliver it to a base station. The objective is to determine the vehicle route and the collection operations, both physical and wireless, in order to maximize the amount of information collected during a time horizon. Three mixed integer programming models are introduced and a computational study is reported to compare the performance of a solver based on each one of the models.},
  archive      = {J_EJOR},
  author       = {Luis Flores-Luyo and Agostinho Agra and Rosa Figueiredo and Eladio Ocaña},
  doi          = {10.1016/j.ejor.2019.06.054},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {621-638},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Mixed integer formulations for a routing problem with information collection in wireless networks},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Consistency of returns-to-scale characterizations of
production frontiers with respect to model specification. <em>EJOR</em>,
<em>280</em>(2), 609–620. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Returns-to-scale (RTS) characterizations and the underlying notion of scale elasticity are important characteristics of production frontiers, in both parametric and nonparametric methodologies of efficiency and productivity analysis. In practical applications of these methodologies, the model of technology is often experimented with and modified before it is finalized, which involves, for example, a change of the data set, incorporation, exclusion or aggregation of inputs and outputs, or experimentation with the production assumptions, or axioms, on which the model is based. While it is well-known how such modifications of technology affect the efficiency scores, their effect on the RTS characterization of the production frontier has not been sufficiently explored in the literature. In this paper we obtain several general results that clarify this issue.},
  archive      = {J_EJOR},
  author       = {Victor V. Podinovski and Tatiana Bouzdine-Chameeva},
  doi          = {10.1016/j.ejor.2019.07.043},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {609-620},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Consistency of returns-to-scale characterizations of production frontiers with respect to model specification},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic competition over social networks. <em>EJOR</em>,
<em>280</em>(2), 597–608. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an analytical approach to the problem of influence maximization in a social network where two players compete by means of dynamic targeting strategies. We formulate the problem as a two-player zero-sum stochastic game. We prove the existence of the uniform value: if the players are sufficiently patient, both can guarantee the same mean-average opinion without knowing the exact length of the game. Furthermore, we put forward some elements for the characterization of equilibrium strategies. In general, players must implement a trade-off between a forward-looking perspective, according to which they aim to maximize the future spread of their opinion in the network, and a backward-looking perspective, according to which they aim to counteract their opponent’s previous actions. When the influence potential of players is small, we describe an equilibrium through a one-shot game based on eigenvector centrality.},
  archive      = {J_EJOR},
  author       = {Antoine Mandel and Xavier Venel},
  doi          = {10.1016/j.ejor.2019.07.028},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {597-608},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic competition over social networks},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introducing multiobjective complex systems. <em>EJOR</em>,
<em>280</em>(2), 581–596. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article focuses on the optimization of a complex system which is composed of several subsystems. On the one hand, these subsystems are subject to multiple objectives, local constraints as well as local variables, and they are associated with an own, subsystem-dependent decision maker. On the other hand, these subsystems are interconnected to each other by global variables or linking constraints. Due to these interdependencies, it is in general not possible to simply optimize each subsystem individually to improve the performance of the overall system. This article introduces a formal graph-based representation of such complex systems and generalizes the classical notions of feasibility and optimality to match this complex situation. Moreover, several algorithmic approaches are suggested and analyzed.},
  archive      = {J_EJOR},
  author       = {Tobias Dietz and Kathrin Klamroth and Konstantin Kraus and Stefan Ruzika and Luca E. Schäfer and Britta Schulze and Michael Stiglmayr and Margaret M. Wiecek},
  doi          = {10.1016/j.ejor.2019.07.027},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {581-596},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Introducing multiobjective complex systems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). RobinX: A three-field classification and unified data format
for round-robin sports timetabling. <em>EJOR</em>, <em>280</em>(2),
568–580. (<a href="https://doi.org/10.1016/j.ejor.2019.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports timetabling problems are combinatorial optimization problems which consist of creating a timetable that defines against whom, when, and where teams play games. In the literature, sports timetabling problems have been reported featuring a wide variety of constraints and objectives. This variety makes it challenging to identify the relevant set of papers for a given sports timetabling problem. Moreover, the lack of a generally accepted data format makes that problem instances and their solutions are rarely shared. Consequently, it is hard to assess algorithmic performance since solution methods are often tested on just one or two specific instances. To mitigate these issues, this paper presents RobinX, a three-field notation to describe a sports timetabling problem by means of the tournament format, the constraints in use, and the objective. We use this notation to classify sports timetabling problems presented in the operations research literature during the last five decades. Moreover, RobinX contains xml -based file templates to store problem instances and their solutions and presents an online platform that offers three useful tools. First, a query tool assists users to select the relevant set of papers for a given timetabling problem. Second, the online platform provides access to an xml data repository that contains real-life problem instances from different countries and sports. Finally, the website enables users to interact with a free and open-source C++ -library to read and write xml files and to validate and evaluate encoded instances and solutions.},
  archive      = {J_EJOR},
  author       = {David Van Bulck and Dries Goossens and Jörn Schönberger and Mario Guajardo},
  doi          = {10.1016/j.ejor.2019.07.023},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {568-580},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {RobinX: A three-field classification and unified data format for round-robin sports timetabling},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Price optimization with reference price effects: A
generalized benders’ decomposition method and a myopic heuristic
approach. <em>EJOR</em>, <em>280</em>(2), 555–567. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a multi-period revenue maximization and pricing optimization problem in the presence of reference prices. We formulate the problem as a mixed integer nonlinear program and develop a generalized Benders’ decomposition algorithm to solve it. In addition, we propose a myopic heuristic and discuss the conditions under which it produces efficient solutions. We provide analytical results as well as numerical computations to illustrate the efficiency of the solution approaches as well as some managerial pricing insights.},
  archive      = {J_EJOR},
  author       = {Seyed Shervin Shams-Shoaaee and Elkafi Hassini},
  doi          = {10.1016/j.ejor.2019.07.020},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {555-567},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price optimization with reference price effects: A generalized benders’ decomposition method and a myopic heuristic approach},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision support for strategic energy planning: A robust
optimization framework. <em>EJOR</em>, <em>280</em>(2), 539–554. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization models for long-term energy planning often feature many uncertain inputs, which can be handled using robust optimization. However, uncertainty is seldom accounted for in the energy planning practice, and robust optimization applications in this field normally consider only a few uncertain parameters. A reason for this gap between energy practice and stochastic modeling is that large-scale energy models often present features—such as multiplied uncertain parameters in the objective and many uncertainties in the constraints—which make it difficult to develop generalized and tractable robust formulations. In this paper, we address these limiting features to provide a complete robust optimization framework allowing the consideration of all uncertain parameters in energy models. We also introduce an original approach to make use of the obtained robust formulations for decision support and provide a case study of a national energy system for validation.},
  archive      = {J_EJOR},
  author       = {Stefano Moret and Frédéric Babonneau and Michel Bierlaire and François Maréchal},
  doi          = {10.1016/j.ejor.2019.06.015},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {539-554},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision support for strategic energy planning: A robust optimization framework},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Green product development under competition: A study of the
fashion apparel industry. <em>EJOR</em>, <em>280</em>(2), 523–538. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the observed industrial issues, we analytically develop a fashion supply chain consisting of one manufacturer and two competing retailers and investigate how retail competition and consumer returns affect green product development in fashion apparel. In the basic model, that is, the pure “product greenness level” game, we find that the optimal greenness level of the fashion product decreases along with the level of market competition. This finding implies that a more competitive market leads to a lower optimal greenness level. We also identify that when the consumer return rate increases, the optimal product greenness level is substantially reduced. In the extended model with joint decisions on greenness and pricing, we find that the optimal product greenness level for the whole channel is always higher in the scenario when both retailers charge a higher retail price than in the case with a lower retail price. As such, the underdevelopment of green fashion products is a result of fashion industry features, such as an extremely competitive environment for green product development, relatively low retail prices for fashion products, and high consumer return rates. Therefore, fashion companies should join a co-opetition game for the green product market and simultaneously enhance their efficiency in managing consumer returns. To support our analytical findings, we conduct extensive industrial interviews with various representative companies. Based on this multi-methodological approach (MMA), this paper generates practice-relevant managerial insights that not only contribute to the literature, but also act as valuable references for industrialists.},
  archive      = {J_EJOR},
  author       = {Shu Guo and Tsan-Ming Choi and Bin Shen},
  doi          = {10.1016/j.ejor.2019.07.050},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {523-538},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Green product development under competition: A study of the fashion apparel industry},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interactions of competing manufacturers’ leader-follower
relationship and sales format on online platforms. <em>EJOR</em>,
<em>280</em>(2), 508–522. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, manufacturers can sell products on e-tailers’ online platforms through agency sales format or reselling format. However, how to choose the best sales formats has puzzled competing manufacturers in practice. The main purpose of this paper is to answer this problem by considering the combined effects of manufacturers’ leader-follower relationships, the e-tailer’s referral fees, the difference in products’ substitutable degrees and the difference in products’ market bases. Our results show that, if demand functions are linearly price-dependent, when two manufacturers sell substitutable products on the same e-tailer’s online platform, the e-tailer’s best action is always to let both manufacturers adopt reselling format; regardless of one manufacturer’s sales format, the other manufacturer always prefers agency sales format, which are independent of the e-tailer’s referral fees, the difference in two products’ substitutable degrees and the difference in two products’ market bases. Whether demand functions are linear or nonlinear in retail prices, the e-tailer’s best action is to let both manufacturers whose products are symmetric adopt reselling format; no matter what sales format one manufacturer adopts, the other manufacturer always prefers agency sales format, which are independent of the two manufacturers’ leader-follower relationships. Moreover, if two manufacturers adopt same sales format to sell symmetric products, leader role enables a manufacturer to charge higher optimal wholesale/retail price when demand functions are linear in retail prices, but the two products have equal optimal wholesale/retail prices regardless of the two manufacturers’ leader-follower relationships when demand functions are nonlinear in retail prices.},
  archive      = {J_EJOR},
  author       = {Jie Wei and Jinghui Lu and Jing Zhao},
  doi          = {10.1016/j.ejor.2019.07.048},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {508-522},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Interactions of competing manufacturers’ leader-follower relationship and sales format on online platforms},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Order release planning by iterative simulation and linear
programming: Theoretical foundation and analysis of its shortcomings.
<em>EJOR</em>, <em>280</em>(2), 495–507. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning future order releases for complex manufacturing systems with substantial lead times must consider limited capacities and the resulting production smoothing problem as well as the highly nonlinear relationship between capacity utilization, work-in-process and flow times. An important solution approach that has been proposed for this problem is to iterate between an order release model with fixed lead times and a lead time estimation (usually simulation) model that estimates the flow times for given order releases, providing the lead times for the next iteration. However, the convergence of this iterative procedure is highly unpredictable, limiting its practical use. The iterative mechanism is analyzed analytically for simplified formulations of the order release and lead time estimation model. We show that an order release procedure of this type that iterates on the lead times is a dual (price) coordination mechanism whose design does not meet the theoretical requirements, and there is no straightforward way to overcome this. The analysis also provides insights into the results of several numerical studies from the literature and suggests a possible research direction to improve the method. Order release mechanisms of this type are a special case of a broader class of production planning methods that iterate between the production planning and the production scheduling level in order to provide realistic values for lead times and planned capacities. Providing theoretical underpinning for this type of production planning methods is an important research objective, and the paper pursues this direction for the special case of order release.},
  archive      = {J_EJOR},
  author       = {Hubert Missbauer},
  doi          = {10.1016/j.ejor.2019.07.030},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {495-507},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Order release planning by iterative simulation and linear programming: Theoretical foundation and analysis of its shortcomings},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust disaster preparedness model for effective and fair
disaster response. <em>EJOR</em>, <em>280</em>(2), 479–494. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humanitarian network design decisions belonging to the preparedness stage of disaster management life-cycle are of critical importance since they set the frame for all further post-disaster operations. Having an adequate number of strategically located storage and distribution centers for critical supplies is the key that enables effectiveness, efficiency and fairness when responding to a disaster situation. The preparedness model proposed in this study selects locations and inventory levels of these facilities such that the right mix of relief items can be supplied at the right time. Our mixed integer linear model aims to find a robust relief network design that satisfies the demand for all given disaster scenarios, and to help achieve a better response during the response stage when the relief items are distributed. The assumptions and the parameters used in the model are justified by authorities of humanitarian organizations. We propose a logic-based Benders decomposition approach to solve this problem to optimality. Although the problem is NP-hard, our numerical studies demonstrate that it is possible to obtain optimal or very good solutions to problem instances with realistic sizes.},
  archive      = {J_EJOR},
  author       = {Gökalp Erbeyoğlu and Ümit Bilge},
  doi          = {10.1016/j.ejor.2019.07.029},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {479-494},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A robust disaster preparedness model for effective and fair disaster response},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal production-inventory policy for the multi-period
fixed proportions co-production system. <em>EJOR</em>, <em>280</em>(2),
469–478. (<a href="https://doi.org/10.1016/j.ejor.2019.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the multi-period production-inventory problem where a manufacturer purchases and processes a raw material into two products in fixed proportions when facing uncertain demands. In each period, the manufacturer first reviews the on-hand inventories of the products and then decides the purchase/processing quantity of the raw material. After processing the raw material into the end products, the demands of the two products are realized and satisfied by the available inventories. Any leftover inventories are carried to the next period while the unsatisfied demands are backordered. By proving the concavity and submodularity of the expected profit-to-go function, we establish that the one-dimensional produce-up-to policy is optimal. We also study the case where the raw material is seasonal and the manufacturer has only one chance to purchase. Modeling it as a dynamic program, we establish that the one-dimensional produce-down-to policy is optimal. Finally, we conduct numerical studies to examine the impacts of supply-demand balance and price fluctuation on the optimal policy, and derive managerial insights from the analytical findings.},
  archive      = {J_EJOR},
  author       = {Liu Hengyu and Zhang Juliang and Cheng T.C.E. and Ru Yihong},
  doi          = {10.1016/j.ejor.2019.07.025},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {469-478},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal production-inventory policy for the multi-period fixed proportions co-production system},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining lithography and directed self assembly for the
manufacturing of vias: Connections to graph coloring problems, integer
programming formulations, and numerical experiments. <em>EJOR</em>,
<em>280</em>(2), 453–468. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the manufacturing of vias in integrated circuits with a new technology combining lithography and Directed Self Assembly (DSA). Optimizing the production time and costs in this new process entails minimizing the number of lithography steps, which constitutes a generalization of graph coloring. We develop integer programming formulations for several variants of interest in the industry, and then study the computational performance of our formulations on true industrial instances. We show that the best integer programming formulation achieves good computational performance, and indicate potential directions to further speed-up computational time and develop exact approaches feasible for production.},
  archive      = {J_EJOR},
  author       = {Dehia Ait-Ferhat and Vincent Juliard and Gautier Stauffer and Juan Andres Torres},
  doi          = {10.1016/j.ejor.2019.07.021},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {453-468},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Combining lithography and directed self assembly for the manufacturing of vias: Connections to graph coloring problems, integer programming formulations, and numerical experiments},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convexifiability of continuous and discrete nonnegative
quadratic programs for gap-free duality. <em>EJOR</em>, <em>280</em>(2),
441–452. (<a href="https://doi.org/10.1016/j.ejor.2019.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we show that a convexifiability property of nonconvex quadratic programs with nonnegative variables and quadratic constraints guarantees zero duality gap between the quadratic programs and their semi-Lagrangian duals. More importantly, we establish that this convexifiability is hidden in classes of nonnegative homogeneous quadratic programs and discrete quadratic programs, such as mixed integer quadratic programs, revealing zero duality gaps. As an application, we prove that robust counterparts of uncertain mixed integer quadratic programs with objective data uncertainty enjoy zero duality gaps under suitable conditions. Various sufficient conditions for convexifiability are also given.},
  archive      = {J_EJOR},
  author       = {N.H. Chieu and V. Jeyakumar and G. Li},
  doi          = {10.1016/j.ejor.2019.08.009},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {441-452},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Convexifiability of continuous and discrete nonnegative quadratic programs for gap-free duality},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dual control monte-carlo method for tight bounds of value
function under heston stochastic volatility model. <em>EJOR</em>,
<em>280</em>(2), 428–440. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to study the fast computation of the lower and upper bounds on the value function for utility maximization under the Heston stochastic volatility model with general utility functions. It is well known there is a closed form solution to the HJB equation for power utility due to its homothetic property. It is not possible to get closed form solution for general utilities and there is little literature on the numerical scheme to solve the HJB equation for the Heston model. In this paper we propose an efficient dual control Monte-Carlo method for computing tight lower and upper bounds of the value function. We identify a particular form of the dual control which leads to the closed form upper bound for a class of utility functions, including power, non-HARA and Yaari utilities. Finally, we perform some numerical tests to see the efficiency, accuracy, and robustness of the method. The numerical results support strongly our proposed scheme.},
  archive      = {J_EJOR},
  author       = {Jingtang Ma and Wenyuan Li and Harry Zheng},
  doi          = {10.1016/j.ejor.2019.07.041},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {428-440},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dual control monte-carlo method for tight bounds of value function under heston stochastic volatility model},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving policy design problems: Alternating direction method
of multipliers-based methods for structured inverse variational
inequalities. <em>EJOR</em>, <em>280</em>(2), 417–427. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverse variational inequalities have broad applications in various disciplines, and some of them have very appealing structures. There are several algorithms (e.g., proximal point algorithms and projection-type algorithms) for solving the inverse variational inequalities in general settings, while few of them have fully exploited the special structures. In this paper, we consider a class of inverse variational inequalities that has a separable structure and linear constraints, which has its root in spatial economic equilibrium problems. To design an efficient algorithm, we develop an alternating direction method of multipliers (ADMM) based method by utilizing the separable structure. Under some mild assumptions, we prove its global convergence. We propose an improved variant that makes the subproblems much easier and derive the convergence result under the same conditions. Finally, we present the preliminary numerical results to show the capability and efficiency of the proposed methods.},
  archive      = {J_EJOR},
  author       = {Yaning Jiang and Xingju Cai and Deren Han},
  doi          = {10.1016/j.ejor.2019.05.044},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {417-427},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving policy design problems: Alternating direction method of multipliers-based methods for structured inverse variational inequalities},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of hybrid metaheuristics for the
resource-constrained project scheduling problem. <em>EJOR</em>,
<em>280</em>(2), 395–416. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Resource-Constrained Project Scheduling Problem (RCPSP) is a general problem in scheduling that has a wide variety of applications in manufacturing, production planning, project management, and various other areas. The RCPSP has been studied since the 1960s and is an NP-hard problem. As being an NP-hard problem, solution methods are primarily heuristics. Over the last two decades, the increasing interest in operations research for metaheuristics has resulted in a general tendency of moving from pure metaheuristic methods for solving the RCPSP to hybrid methods that rely on different metaheuristic strategies. The purpose of this paper is to survey these hybrid approaches. For the primary hybrid metaheuristics that have been proposed to solve the RCPSP over the last two decades, a description of the basic principles of the hybrid metaheuristics is given, followed by a comparison of the results of the different hybrids on the well-known PSPLIB data instances. The distinguishing features of the best hybrids are also discussed.},
  archive      = {J_EJOR},
  author       = {Robert Pellerin and Nathalie Perrier and François Berthaut},
  doi          = {10.1016/j.ejor.2019.01.063},
  journal      = {European Journal of Operational Research},
  number       = {2},
  pages        = {395-416},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A survey of hybrid metaheuristics for the resource-constrained project scheduling problem},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Price dynamics in the european union emissions trading
system and evaluation of its ability to boost emission-related
investment decisions. <em>EJOR</em>, <em>280</em>(1), 383–394. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The price of permits in the European Union Emissions Trading System (EU ETS) has historically been highly sensitive and prone to jumps. We consider different stochastic processes to model the price of permits, and show that the Variance Gamma (VG) model provides the best fit for the price distribution, among a selection of infinite activity processes. Using this result as a starting point, we assess the effects of the EU ETS in delivering low-carbon investments at the firm level, by modeling a price taker electricity producer subject to the EU ETS jurisdiction. We compute, via Least Squares Monte Carlo, the value of the real option the greenhouse gas emitter has, consisting in the opportunity to switch from its current high-carbon technology to a cleaner one. We use a VG specification for carbon prices, and a mean-reverting (Brennan–Schwartz) process for the price of fuel. Moreover, we further analyze the investment decision problem, in case of a CO 2 price stabilization mechanism in the form of a price floor, by explicitly computing the expected value of the investment project by means of Fourier methods. Our results show that the introduction of the price stabilization mechanism significantly affects the timing of the investment decision, and supports emission-related investments.},
  archive      = {J_EJOR},
  author       = {Maria Flora and Tiziano Vargiolu},
  doi          = {10.1016/j.ejor.2019.07.026},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {383-394},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Price dynamics in the european union emissions trading system and evaluation of its ability to boost emission-related investment decisions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Are solar panels commodities? A bayesian hierarchical
approach to detecting quality differences and asymmetric information.
<em>EJOR</em>, <em>280</em>(1), 365–382. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar panels should not be considered commodities. Considerable quality differences, as measured directly by degradation of production over time, are found between manufacturers. I test two implications from the theory of asymmetric information of quality and find: (1) Solar power systems with high-information third-party owners display higher quality than host-owned systems. (2) Furthermore, with a 85\% probability, the price of solar panels that are owned by high-information owners are more highly correlated to quality. Methodologically, the article demonstrates a novel application of Bayesian hierarchical regression models that are increasingly popular in operations research and the decision sciences.},
  archive      = {J_EJOR},
  author       = {Johannes Mauritzen},
  doi          = {10.1016/j.ejor.2019.07.001},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {365-382},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Are solar panels commodities? a bayesian hierarchical approach to detecting quality differences and asymmetric information},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Direction selection in stochastic directional distance
functions. <em>EJOR</em>, <em>280</em>(1), 351–364. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers rely on the distance function to model multiple product production using multiple inputs. A stochastic directional distance function (SDDF) allows for noise in potentially all input and output variables. Yet, when estimated, the direction selected will affect the functional estimates because deviations from the estimated function are minimized in the specified direction. Specifically, the parameters of the parametric SDDF are point identified when the direction is specified; we show that the parameters of the parametric SDDF are set identified when multiple directions are considered. Further, the set of identified parameters can be narrowed via data-driven approaches to restrict the directions considered. We demonstrate a similar narrowing of the identified parameter set for a shape constrained nonparametric method, where the shape constraints impose standard features of a cost function such as monotonicity and convexity. Our Monte Carlo simulation studies reveal significant improvements, as measured by out of sample radial mean squared error, in functional estimates when we use a directional distance function with an appropriately selected direction and the errors are uncorrelated across variables. We show that these benefits increase as the correlation in error terms across variables increase. This correlation is a type of endogeneity that is common in production settings. From our Monte Carlo simulations we conclude that selecting a direction that is approximately orthogonal to the estimated function in the central region of the data gives significantly better estimates relative to the directions commonly used in the literature. For practitioners, our results imply that selecting a direction vector that has non-zero components for all variables that may have measurement error provides a significant improvement in the estimator’s performance. We illustrate these results using cost and production data from samples of approximately 500 US hospitals per year operating in 2007, 2008, and 2009, respectively, and find that the shape constrained nonparametric methods provide a significant increase in flexibility over second order local approximation parametric methods.},
  archive      = {J_EJOR},
  author       = {Kevin Layer and Andrew L. Johnson and Robin C. Sickles and Gary D. Ferrier},
  doi          = {10.1016/j.ejor.2019.06.046},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {351-364},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Direction selection in stochastic directional distance functions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discovering heterogeneous consumer groups from sales
transaction data. <em>EJOR</em>, <em>280</em>(1), 338–350. (<a
href="https://doi.org/10.1016/j.ejor.2019.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a demand estimation method to discover heterogeneous consumer groups. The estimation requires only historical sales data and product availability. Consumers belonging to different segments possess heterogeneous preferences and, in turn, heterogeneous substitution behaviors. For such consumers, the latent class consumer choice model can better represent their heterogeneous purchasing behaviors. In the latent class choice model, there are multiple consumer segments, and the segment types are not observable to the retailer. The expectation-maximization (EM) method is developed to jointly estimate the arrival rate and the parameters of the choice model. The developed method enables a simple estimation procedure by treating the observed data as incomplete observations of the consumer type along with consumer’s first choice. The first choice is the choice before the substitution effects occur. We test the procedure on simulated data sets. The results show that the procedure effectively detects heterogeneous consumer segments that have significant market presence.},
  archive      = {J_EJOR},
  author       = {Haengju Lee and Yongsoon Eun},
  doi          = {10.1016/j.ejor.2019.05.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {338-350},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discovering heterogeneous consumer groups from sales transaction data},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Profit allocation in investment-based crowdfunding with
investors of dynamic entry times. <em>EJOR</em>, <em>280</em>(1),
323–337. (<a href="https://doi.org/10.1016/j.ejor.2019.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even distribution is a normal profit allocation mechanism for investment-based crowdfunding projects on many platforms. In other words, the investors with the same pledging funds will be paid evenly when the investment ends. The even allocation mechanism works well under the assumption that the investors arrive at the platform simultaneously. However, in practice, the investors are sequential, therefore, the stories are different when considering the dynamic entry times of the investors. In this paper, we study ways to design appropriate profit allocation mechanisms to enhance the success rate of an investment-based crowdfunding project. The basic model focuses on the two-investor case, where only two investors with dynamic entry times are considered. The profit allocation mechanism is shown to have great impacts on the pledging probabilities of investors, as well as the success rate of a project. After that, we shift our focus to the two-cohort case, where dynamic investors are assumed to arrive at the platform as two sequential cohorts. By taking the sizes of each cohort into consideration, we are able to analyze the success rate of a project under various practical situations. Finally, we implement some numerical experiments to generalize our studies to the situations where (i) there are more than two pledging periods for the investors, (ii) the herding effect of the investors is considered, and (iii) the valuations of the investors are assumed to be normally distributed. Our main results still hold under these general situations.},
  archive      = {J_EJOR},
  author       = {Yunshen Yang and Gongbing Bi and Lindong Liu},
  doi          = {10.1016/j.ejor.2019.07.016},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {323-337},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Profit allocation in investment-based crowdfunding with investors of dynamic entry times},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Operational asymptotic stochastic dominance. <em>EJOR</em>,
<em>280</em>(1), 312–322. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Levy (2016) proposes asymptotic first-degree stochastic dominance as a distribution ranking criterion for all non-satiable decision makers with infinite investment horizons. Given Levy’s setting, this paper defines and offers the equivalent distributional conditions for asymptotic second-degree stochastic dominance, as well as operational asymptotic first- and second-degree stochastic dominance. Interestingly, the operational asymptotic stochastic dominance provides a full rank over assets with lognormal returns and different means. Empirical applications show that our conditions can be readily implemented in practice.},
  archive      = {J_EJOR},
  author       = {Rachel J. Huang and Larry Tzeng and Jr-Yan Wang and Lin Zhao},
  doi          = {10.1016/j.ejor.2019.06.052},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {312-322},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Operational asymptotic stochastic dominance},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Project schedule performance under general mode
implementation disruptions. <em>EJOR</em>, <em>280</em>(1), 295–311. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a simulation study for a resource-constrained project scheduling problem with multiple alternatives. We decide on a set of baseline schedules at the project planning phase, resulting in options to switch between execution modes of activities during project execution. We assess the performance of the set of baseline schedules under general mode implementation disruptions. A simple, yet effective algorithm is presented to construct the set of baseline schedules. Moreover, a general disruption system is proposed to model different disruption types, disruption dependencies and disruption sizes.},
  archive      = {J_EJOR},
  author       = {Jeroen Burgelman and Mario Vanhoucke},
  doi          = {10.1016/j.ejor.2019.06.050},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {295-311},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Project schedule performance under general mode implementation disruptions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Filtering for risk assessment of interbank network.
<em>EJOR</em>, <em>280</em>(1), 279–294. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our paper contributes to the recent macroprudential policy addressing the resilience of financial systems in terms of their interconnectedness. We argue that beneath an interbank market, there is a fundamental latent network that affects the liquidity distributions among banks. To investigate the interbank market, we propose a framework that identifies such latent network using a statistical learning procedure. The framework reverse engineers overnight signals observed as banks conduct their reserve management on a daily basis. Our simulation-based results show that possible disruptions in funds supply are highly affected by the interconnectedness of the latent network. Hence, the proposed framework serves as an early warning system for regulators to monitor the overnight market and to detect ex-ante possible disruptions based on the inherent network characteristics.},
  archive      = {J_EJOR},
  author       = {Majeed Simaan and Aparna Gupta and Koushik Kar},
  doi          = {10.1016/j.ejor.2019.06.049},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {279-294},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Filtering for risk assessment of interbank network},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A risk-based modeling approach for radiation therapy
treatment planning under tumor shrinkage uncertainty. <em>EJOR</em>,
<em>280</em>(1), 266–278. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust optimization approaches have been widely used to address uncertainties in radiation therapy treatment planning problems. Because of the unknown probability distribution of uncertainties, robust bounds may not be correctly chosen, and a risk of undesirable effects from worst-case realizations may exist. In this study, we developed a risk-based robust approach, embedded within the conditional value-at-risk representation of the dose-volume constraint, to deal with tumor shrinkage uncertainty during radiation therapy. The objective of our proposed model is to reduce dose variability in the worst-case scenarios as well as the total delivered dose to healthy tissues and target dose deviations from the prescribed dose, especially, in underdosed scenarios. We also took advantage of adaptive radiation therapy in our treatment planning approach. This fractionation technique considers the response of the tumor to treatment up to a particular point in time and reoptimizes the treatment plan using an estimate of tumor shrinkage. The benefits of our model were tested in a clinical lung cancer case. Four plans were generated and compared: static, nominal-adaptive, robust-adaptive, and conventional robust (worst-case) optimization. Our results showed that the robust-adaptive model, which is a risk-based model, achieved less dose variability and more control on the worst-case scenarios while delivering the prescribed dose to the tumor target and sparing organs at risk. This model also outperformed other models in terms of tumor dose homogeneity and plan robustness.},
  archive      = {J_EJOR},
  author       = {Gino J. Lim and Laleh Kardar and Saba Ebrahimi and Wenhua Cao},
  doi          = {10.1016/j.ejor.2019.06.041},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {266-278},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A risk-based modeling approach for radiation therapy treatment planning under tumor shrinkage uncertainty},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic multi-priority, multi-class patient scheduling with
stochastic service times. <em>EJOR</em>, <em>280</em>(1), 254–265. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient patient scheduling has significant operational, clinical and economical benefits on health care systems by not only increasing the timely access of patients to care but also reducing costs. However, patient scheduling is complex due to, among other aspects, the existence of multiple priority levels, the presence of multiple service requirements, and its stochastic nature. Patient appointment (allocation) scheduling refers to the assignment of specific appointment start times to a set of patients scheduled for a particular day while advance patient scheduling refers to the assignment of future appointment days to patients. These two problems have generally been addressed separately despite each being highly dependent on the form of the other. This paper develops a framework that incorporates stochastic service times into the advance scheduling problem as a first step towards bridging these two problems. In this way, we not only take into account the waiting time until the day of service but also the idle time/overtime of medical resources on the day of service. We first extend the current literature by providing theoretical and numerical results for the case with multi-class, multi-priority patients and deterministic service times. We then adapt the model to incorporate stochastic service times and perform a comprehensive numerical analysis on a number of scenarios, including a practical application. Results suggest that the advance scheduling policies based on deterministic service times cannot be easily improved upon by incorporating stochastic service times, a finding that has important implications for practice and future research on the combined problem.},
  archive      = {J_EJOR},
  author       = {Antoine Sauré and Mehmet A. Begen and Jonathan Patrick},
  doi          = {10.1016/j.ejor.2019.06.040},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {254-265},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Dynamic multi-priority, multi-class patient scheduling with stochastic service times},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A conic relaxation model for searching for the global
optimum of network data envelopment analysis. <em>EJOR</em>,
<em>280</em>(1), 242–253. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network data envelopment analysis (DEA) models the internal structures of decision-making units (DMUs). Unlike the standard DEA model, multiplier-based network DEA models are often highly non-linear and cannot be converted into linear programs. As such, obtaining a non-linear network DEA&#39;s global optimal solution is a challenge because it corresponds to a nonconvex optimization problem. In this paper, we introduce a conic relaxation model that searches for the global optimum to the general multiplier-based network DEA model. We reformulate the general network DEA models and relax the new models into second order cone programming (SOCP) problems. In comparison with linear relaxation models, which is potentially applicable to general network DEA structures, the conic relaxation model guarantees applicability in general network DEA, since McCormick envelopes involved are ensured to be finite. Furthermore, the conic relaxation model avoids unnecessary linear relaxations of some nonlinear constraints. It generates, in a more convenient manner, feasible approximations and tighter upper bounds on the global optimal overall efficiency. Compared with a line-parameter search method that has been applied to solve non-linear network DEA models, the conic relaxation model keeps track of the distances between the optimal overall efficiency and its approximations. As a result, it is able to determine whether a qualified approximation has been achieved or not, with the help of a branch and bound algorithm. Hence, our proposed approach can substantially reduce the computations involved.},
  archive      = {J_EJOR},
  author       = {Chen Kun and Wade D. Cook and Zhu Joe},
  doi          = {10.1016/j.ejor.2019.07.012},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {242-253},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A conic relaxation model for searching for the global optimum of network data envelopment analysis},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global sub-increasing and global sub-decreasing returns to
scale in free disposal hull technologies: Definition, characterization
and calculation. <em>EJOR</em>, <em>280</em>(1), 230–241. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global Returns to Scale (GRS) is an important notion in performance analysis under Free Disposal Hull (FDH) technologies. Ray Average Productivity (RAP) function has a crucial role in interpreting the GRS. We define two new notions, called Global Sub-Increasing RTS (G-SIRS) and Global Sub-Decreasing RTS (G-SDRS), invoking the behaviour of the RAP function at its maximizers. These notions are useful from a managerial standpoint, because they help the decision maker to decide about contracting or expanding the operation of the units under consideration. After presenting a motivating example and defining G-SIRS and G-SDRS, some theorems are proved to characterize these new notions. A polynomial-time algorithm is sketched which is able to determine the GRS of the Decision Making Units (DMUs) under evaluation. The second part of the paper is devoted to calculating a stability interval for GRS. It is done through some theorems and a polynomial-time algorithm. The results of the paper are illustrated by numerical examples as well as empirical studies with real-world data. Computational experiments are reported as well.},
  archive      = {J_EJOR},
  author       = {Amin Mostafaee and Majid Soleimani-damaneh},
  doi          = {10.1016/j.ejor.2019.07.005},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {230-241},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Global sub-increasing and global sub-decreasing returns to scale in free disposal hull technologies: Definition, characterization and calculation},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Meta-frontier analysis using cross-efficiency method for
performance evaluation. <em>EJOR</em>, <em>280</em>(1), 219–229. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiency overestimation and technology heterogeneity are important factors that affect the use of data envelopment analysis. This paper introduces a meta-frontier analysis framework into a cross-efficiency method to develop a new efficiency evaluation method. This method can be used to calculate, aggregate, and decompose the cross efficiencies relative to the meta-frontier and group-frontier. Then the technology gap between these frontiers can be measured and more detailed information regarding the inefficiency of decision-making units can be obtained. This enables decision makers to improve efficiency in a targeted manner. Subsequently, the non-uniqueness of the optimal solution is discussed for the new method, and the cross-evaluation strategy is introduced to ensure the stability of the optimal solution. Finally, two examples are presented to illustrate the effectiveness of this method.},
  archive      = {J_EJOR},
  author       = {Lei Chen and Yan Huang and Mei-Juan Li and Ying-Ming Wang},
  doi          = {10.1016/j.ejor.2019.06.053},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {219-229},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Meta-frontier analysis using cross-efficiency method for performance evaluation},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Allocation planning under service-level contracts.
<em>EJOR</em>, <em>280</em>(1), 203–218. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the practical limitations of current demand fulfillment systems, this paper addresses the problem of allocation planning under service-level contracts in a multi-period setting. We provide a formal definition of the allocation planning problem under a type of service-level contract that is particularly relevant to manufacturing industries and formulate a corresponding stochastic dynamic program. Based on a rigorous formal analysis of the dynamic program, we derive the requirements a “good” allocation policy should meet and use them to evaluate the heuristic policies proposed in the literature and to derive new allocation policies that may enhance the performance of allocation planning under service-level contracts. After detailed characterization and discussion of these new policies, we present the results of an extensive numerical study that allow us to quantify and compare allocation policies’ performance and to derive recommendations for decision makers in practice.},
  archive      = {J_EJOR},
  author       = {Konstantin Kloos and Richard Pibernik},
  doi          = {10.1016/j.ejor.2019.07.018},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {203-218},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Allocation planning under service-level contracts},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Estimating value-at-risk and expected shortfall using the
intraday low and range data. <em>EJOR</em>, <em>280</em>(1), 191–202.
(<a href="https://doi.org/10.1016/j.ejor.2019.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Value-at-Risk (VaR) is a popular measure of market risk. To convey information regarding potential exceedances beyond the VaR, Expected Shortfall (ES) has become the risk measure for trading book bank regulation. However, the estimation of VaR and ES is challenging, as it requires the estimation of the tail behaviour of daily returns. In this paper, we take advantage of recent research that develops joint scoring functions for VaR and ES. Using these functions, we present a novel approach to estimating the two risk measures based on intraday data. We focus on the intraday range, which is the difference between the highest and lowest intraday log prices. In contrast to intraday observations, the intraday low and high are widely available for many financial assets. To alleviate the challenge of modelling extreme risk measures, we propose the use of the intraday low series. We draw on a theoretical result for Brownian motion to show that a quantile of the daily returns can be estimated as the product of a constant term and a less extreme quantile of the intraday low returns, which we define as the difference between the lowest log price of the day and the log closing price of the previous day. In view of this, we use estimates of the VaR and ES of the intraday low returns to estimate the VaR and ES of the daily returns. We provide empirical support for the new proposals using data for five stock indices and five individual stocks.},
  archive      = {J_EJOR},
  author       = {Xiaochun Meng and James W. Taylor},
  doi          = {10.1016/j.ejor.2019.07.011},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {191-202},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Estimating value-at-risk and expected shortfall using the intraday low and range data},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predictive modeling of inbound demand at major european
airports with poisson and pre-scheduled random arrivals. <em>EJOR</em>,
<em>280</em>(1), 179–190. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an exhaustive study of the arrivals process at eight major European airports. Using inbound traffic data, we define, compare, and contrast a data-driven in-homogeneous Poisson and Pre-Scheduled Random Arrivals (PSRA) point process with respect to their ability to predict future demand. As part of this analysis, we show the weaknesses and difficulties of using a non-homogeneous Poisson process to model the arrivals stream. On the other hand, our novel and simple data-driven (PSRA) model captures and predicts the main properties of the typical arrivals stream with good accuracy. These results have important implication for the modeling and simulation-based analyses of inbound traffic and can improve the use of available capacity, thus reducing air traffic delays. In a nutshell, the results lead to the conclusion that, in the European context, the (PSRA) model provides more accurate predictions.},
  archive      = {J_EJOR},
  author       = {Carlo Lancia and Guglielmo Lulli},
  doi          = {10.1016/j.ejor.2019.06.056},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {179-190},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Predictive modeling of inbound demand at major european airports with poisson and pre-scheduled random arrivals},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact solution of the soft-clustered vehicle-routing
problem. <em>EJOR</em>, <em>280</em>(1), 164–178. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The soft-clustered vehicle-routing problem (SoftCluVRP) extends the classical capacitated vehicle-routing problem by one additional constraint: The customers are partitioned into clusters and feasible routes must respect the soft-cluster constraint, that is, all customers of the same cluster must be served by the same vehicle. In this article, we design and analyze different branch-and-price algorithms for the exact solution of the SoftCluVRP. The algorithms differ in the way the column-generation subproblem, a variant of the shortest-path problem with resource constraints (SPPRC), is solved. The standard approach for SPPRCs is based on dynamic-programming labeling algorithms. We show that even with all the recent acceleration techniques (e.g., partial pricing, bidirectional labeling, decremental state space relaxation) available for SPPRC labeling algorithms, the solution of the subproblem remains extremely difficult. The main contribution is the modeling and solution of the subproblem using a branch-and-cut algorithm. The conducted computational experiments prove that branch-and-price equipped with this integer programming-based approach outperforms sophisticated labeling-based algorithms by one order of magnitude. The largest SoftCluVRP instances solved to optimality have more than 400 customers or more than 50 clusters.},
  archive      = {J_EJOR},
  author       = {Timo Hintsch and Stefan Irnich},
  doi          = {10.1016/j.ejor.2019.07.019},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {164-178},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact solution of the soft-clustered vehicle-routing problem},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling past-dependent partial repairs for condition-based
maintenance of continuously deteriorating systems. <em>EJOR</em>,
<em>280</em>(1), 152–163. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the stochastic modeling of a condition-based maintained system subject to continuous deterioration and maintenance actions such as inspection, partial repair and replacement. The partial repair is assumed dependent on the past in the sense that it cannot bring the system back into a deterioration state better than the one reached at the last repair. Such a past-dependency can affect ( i ) the selection of a type of maintenance actions, ( ii ) the maintenance duration, ( iii ) the deterioration level after a maintenance, and ( iv ) the restarting system deterioration behavior. In this paper, all these effects are jointly considered in an unifying condition-based maintenance model on the basis of restarting deterioration states randomly sampled from a probability distribution truncated by the deterioration levels just before a current repair and just after the last repair/replacement. Using results from the semi-regenerative theory, the long-run maintenance cost rate is analytically derived. Numerous sensitivity studies illustrate the impacts of past-dependent partial repairs on the economic performance of the considered condition-based maintained system.},
  archive      = {J_EJOR},
  author       = {K.T. Huynh},
  doi          = {10.1016/j.ejor.2019.07.007},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {152-163},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Modeling past-dependent partial repairs for condition-based maintenance of continuously deteriorating systems},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Agency selling or reselling: E-tailer information sharing
with supplier offline entry. <em>EJOR</em>, <em>280</em>(1), 134–151.
(<a href="https://doi.org/10.1016/j.ejor.2019.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, some suppliers are looking for offline expansion in addition to their preexisting online channels relying on e-tailers. This study focuses on the e-tailer’s demand information sharing strategy with the supplier who may build upon brick-and-mortar stores. Both prevailing agreements between the supplier and the e-tailer are investigated: agency selling and reselling. The equilibrium results are quite different under these two agreements. Specifically, when the supplier’s offline entry cost is very small or large, the e-tailer shares information under agency selling while keeps information private under reselling. When the entry cost is intermediate, channel substitution rate is large and information uncertainty is small, the e-tailer withholds the demand information under agency selling while shares information under reselling to deter the supplier from entering an offline channel. Furthermore, two extensions about consumer behavior in multichannel selection are discussed: showrooming and webrooming. With showrooming or webrooming, the e-tailer’s information sharing decisions qualitatively hold, while with showrooming the drive factor behind may change; that is, withholding information under agency selling and sharing information under reselling may also serve as measures to encourage supplier offline entry when the effect of showrooming is strong.},
  archive      = {J_EJOR},
  author       = {Shichen Zhang and Jianxiong Zhang},
  doi          = {10.1016/j.ejor.2019.07.003},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {134-151},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Agency selling or reselling: E-tailer information sharing with supplier offline entry},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maintenance policy for a system with a weighted linear
combination of degradation processes. <em>EJOR</em>, <em>280</em>(1),
124–133. (<a href="https://doi.org/10.1016/j.ejor.2019.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops maintenance policies for a system under condition monitoring. We assume that a number of defects may develop and the degradation process of each defect follows a gamma process. The system is said failed if a linear combination of the degradation processes exceeds a pre-specified threshold. Preventive maintenance is performed. The system is renewed after several preventive maintenance activities have been performed. The main objective of this paper is to optimise the time between preventive maintenance actions and the number of the preventive maintenance. Numerical examples are given to illustrate the results.},
  archive      = {J_EJOR},
  author       = {Shaomin Wu and Inma T. Castro},
  doi          = {10.1016/j.ejor.2019.06.048},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {124-133},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Maintenance policy for a system with a weighted linear combination of degradation processes},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Designing a two-echelon distribution network under demand
uncertainty. <em>EJOR</em>, <em>280</em>(1), 102–123. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a comprehensive methodology for the stochastic multi-period two-echelon distribution network design problem (2E-DDP) where product flows to ship-to-points are directed from an upper layer of primary warehouses to distribution platforms (DPs) before being transported to the ship-to-points. A temporal hierarchy characterizes the design level dealing with DP location and capacity decisions, as well as the operational level involving transportation decisions as origin-destination flows. These design decisions must be calibrated to minimize the expected distribution cost associated with the two-echelon transportation schema on this network under stochastic demand. We consider a multi-period planning horizon where demand varies dynamically from one planning period to the next. Thus, the design of the two-echelon distribution network under uncertain customer demand gives rise to a complex multi-stage decisional problem. Given the strategic structure of the problem, we introduce alternative modeling approaches based on two-stage stochastic programming with recourse. We solve the resulting models using a Benders decomposition approach. The size of the scenario set is tuned using the sample average approximation (SAA) approach. Then, a scenario-based evaluation procedure is introduced to post-evaluate the design solutions obtained. We conduct extensive computational experiments based on several types of instances to validate the proposed models and assess the efficiency of the solution approaches. The evaluation of the quality of the stochastic solution underlines the impact of uncertainty in the two-echelon distribution network design problem (2E-DDP).},
  archive      = {J_EJOR},
  author       = {Imen Ben Mohamed and Walid Klibi and François Vanderbeck},
  doi          = {10.1016/j.ejor.2019.06.047},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {102-123},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Designing a two-echelon distribution network under demand uncertainty},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Controlling distribution inventory systems with shipment
consolidation and compound poisson demand. <em>EJOR</em>,
<em>280</em>(1), 90–101. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a one-warehouse-multiple-retailer inventory system where the retailers face stochastic customer demand, modelled as compound Poisson processes. Deliveries from the central warehouse to groups of retailers are consolidated using a time based shipment consolidation policy. This means that replenishment orders have to wait until a vehicle departures, which increases the lead time for the retailers and therefore also the safety stock. Thus, a trade-off exists between expected shipment costs and holding costs. Our aim is to determine the shipment intervals and the required amount of safety stock for each retailer and the warehouse to minimize total cost, both for backorder costs and fill rate constraints. Previous work has focused on exact solutions which are computationally demanding and not applicable for larger real world problems. The focus of our present work is on the development of computationally attractive heuristics that can be applied in practice. A numerical study shows that the proposed heuristics perform well compared to the exact cost minimizing solutions. We also illustrate that the approaches are appropriate for solving real world problems using data from a large European company.},
  archive      = {J_EJOR},
  author       = {Lina Johansson and Danja R. Sonntag and Johan Marklund and Gudrun P. Kiesmüller},
  doi          = {10.1016/j.ejor.2019.06.045},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {90-101},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Controlling distribution inventory systems with shipment consolidation and compound poisson demand},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On interactive sequencing situations with exponential cost
functions. <em>EJOR</em>, <em>280</em>(1), 78–89. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses interactive one-machine sequencing situations in which the costs of processing a job are given by an exponential function of its completion time. The main difference with the standard linear case is that the gain of switching two neighbors in a queue is time-dependent and depends on their exact position. We illustrate that finding an optimal order is complicated in general and we identify specific subclasses, which are tractable from an optimization perspective. More specifically, we show that in these subclasses, all neighbor switches in any path from the initial order to an optimal order lead to a non-negative gain. Moreover, we derive conditions on the time-dependent neighbor switching gains in a general interactive sequencing situation to guarantee convexity of the corresponding cooperative game. These conditions are satisfied within our specific subclasses of exponential interactive sequencing situations.},
  archive      = {J_EJOR},
  author       = {Alejandro Saavedra-Nieves and Jop Schouten and Peter Borm},
  doi          = {10.1016/j.ejor.2019.06.044},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {78-89},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On interactive sequencing situations with exponential cost functions},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The case for the use of multiple imputation missing data
methods in stochastic frontier analysis with illustration using english
local highway data. <em>EJOR</em>, <em>280</em>(1), 59–77. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple imputation (MI) methods have been widely applied in economic applications as a robust statistical way to incorporate data where some observations have missing values for some variables. However in stochastic frontier analysis (SFA), application of these techniques has been sparse and the case for such models has not received attention in the appropriate academic literature. This paper fills this gap and explores the robust properties of MI within the stochastic frontier context. From a methodological perspective, we depart from the standard MI literature by demonstrating, conceptually and through simulation, that it is not appropriate to use imputations of the dependent variable within the SFA modelling, although they can be useful to predict the values of missing explanatory variables. Fundamentally, this is because efficiency analysis involves decomposing a residual into noise and inefficiency and as a result any imputation of a dependent variable would be imputing efficiency based on some concept of average inefficiency in the sample. A further contribution that we discuss and illustrate for the first time in the SFA literature, is that using auxiliary variables (outside of those contained in the SFA model) can enhance the imputations of missing values. Our empirical example neatly articulates that often the source of missing data is only a sub-set of components comprising a part of a composite (or complex) measure and that the other parts that are observed are very useful in predicting the value.},
  archive      = {J_EJOR},
  author       = {Alexander D. Stead and Phill Wheat},
  doi          = {10.1016/j.ejor.2019.06.042},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {59-77},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The case for the use of multiple imputation missing data methods in stochastic frontier analysis with illustration using english local highway data},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semidefinite programming lower bounds and branch-and-bound
algorithms for the quadratic minimum spanning tree problem.
<em>EJOR</em>, <em>280</em>(1), 46–58. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate Semidefinite Programming (SDP) lower bounds for the Quadratic Minimum Spanning Tree Problem (QMSTP). Two SDP lower bounding approaches are introduced here. Both apply Lagrangian Relaxation to an SDP relaxation for the problem. The first one explicitly dualizes the semidefiniteness constraint, attaching to it a positive semidefinite matrix of Lagrangian multipliers. The second relies on a semi-infinite reformulation for the cone of positive semidefinite matrices and dualizes a dynamically updated finite set of inequalities that approximate the cone. These lower bounding procedures are the core ingredient of two QMSTP Branch-and-bound algorithms. Our computational experiments indicate that the SDP bounds computed here are very strong, being able to close at least 70\% of the gaps of the most competitive formulation in the literature. As a result, their accompanying Branch-and-bound algorithms are competitive with the best previously available QMSTP exact algorithm in the literature. In fact, one of these new Branch-and-bound algorithms stands out as the new best exact solution approach for the problem.},
  archive      = {J_EJOR},
  author       = {Dilson Almeida Guimarães and Alexandre Salles da Cunha and Dilson Lucas Pereira},
  doi          = {10.1016/j.ejor.2019.07.038},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {46-58},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Semidefinite programming lower bounds and branch-and-bound algorithms for the quadratic minimum spanning tree problem},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating hard instances for robust combinatorial
optimization. <em>EJOR</em>, <em>280</em>(1), 34–45. (<a
href="https://doi.org/10.1016/j.ejor.2019.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While research in robust optimization has attracted considerable interest over the last decades, its algorithmic development has been hindered by several factors. One of them is a missing set of benchmark instances that make algorithm performance better comparable, and makes reproducing instances unnecessary. Such a benchmark set should contain hard instances in particular, but so far, the standard approach to produce instances has been to sample values randomly from a uniform distribution. In this paper we introduce a new method to produce hard instances for min-max combinatorial optimization problems, which is based on an optimization model itself. Our approach does not make any assumptions on the problem structure and can thus be applied to any combinatorial problem. Using the Selection and Traveling Salesman problems as examples, we show that it is possible to produce instances which are up to 500 times harder to solve for a mixed-integer programming solver than the current state-of-the-art instances.},
  archive      = {J_EJOR},
  author       = {Marc Goerigk and Stephen J. Maher},
  doi          = {10.1016/j.ejor.2019.07.036},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {34-45},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Generating hard instances for robust combinatorial optimization},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of flow shop scheduling anomalies. <em>EJOR</em>,
<em>280</em>(1), 25–33. (<a
href="https://doi.org/10.1016/j.ejor.2019.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalies in flow shop scheduling are rare; only two anomalies have been reported. We present five new anomalies for the permutation flow shop models with the minimum makespan objective and seven more anomalies for the minimum total flow time objective. These anomalies (including the existing ones) are divided into three types corresponding to an increased processing time of a single operation, the addition of a job and the addition of a machine. We derive two properties which, when satisfied, eliminate the possibility of certain anomalies. We conclude that restrictions such as no-delay schedules, no job waiting or no machine idle time (after it starts processing) often result in anomalies. We also show that anomalies can also occur in non-permutation flow shops (four new anomalies presented).},
  archive      = {J_EJOR},
  author       = {S.S. Panwalkar and Christos Koulamas},
  doi          = {10.1016/j.ejor.2019.06.043},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {25-33},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Analysis of flow shop scheduling anomalies},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decision support models in climate policy. <em>EJOR</em>,
<em>280</em>(1), 1–24. (<a
href="https://doi.org/10.1016/j.ejor.2019.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Climate change is considered among the most critical risks that global society faces in this century. So far, climate policy strategies have been evaluated by means of a variety of climate-economy models, or Integrated Assessment Models (IAMs), in the aim of supporting climate-related decision making. However, their inherent complexity, the number and nature of driving assumptions, and usual exclusion of stakeholders from the modelling process raise the issue of the extent to which they can provide fruitful insights for policy makers. Moreover, as with all modelling frameworks, IAMs inevitably fail to incorporate all relevant types of uncertainty and risk when used as stand-alone tools. This exclusion can have a significant impact on the model outcomes, but can be mitigated if experts’ knowledge is elicited in a structured manner and effectively taken into account, towards identifying such factors or reducing respective knowledge gaps. At the same time, a growing number of research publications have been suggesting decision support frameworks for assessing specific aspects in climate policy, based on “bottom-up” approaches and participatory processes. The objective of this paper is to provide a critical review of such frameworks—namely Portfolio Analysis, Multiple Criteria Decision Making and Fuzzy Cognitive Maps—in order to explore their strengths and weaknesses in this area, and propose a new integrative approach, appropriately exploiting blends of these frameworks, to productively complement IAMs, towards enhancing climate policy support.},
  archive      = {J_EJOR},
  author       = {Haris Doukas and Alexandros Nikas},
  doi          = {10.1016/j.ejor.2019.01.017},
  journal      = {European Journal of Operational Research},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Decision support models in climate policy},
  volume       = {280},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
