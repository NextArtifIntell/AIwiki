<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TCS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tcs---582">TCS - 582</h2>
<ul>
<li><details>
<summary>
(2020). Anti-unification and the theory of semirings. <em>TCS</em>,
<em>848</em>, 133–139. (<a
href="https://doi.org/10.1016/j.tcs.2020.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It was recently shown that anti-unification over an equational theory consisting of only unit equations (more than one) is nullary. Such pure theories are artificial and are of little effect on practical aspects of anti-unification. In this work, we extend these nullarity results to the theory of semirings, a heavily studied theory with many practical applications. Furthermore, our argument holds over semirings with commutative multiplication and/or idempotent addition. We also cover a few open questions discussed in previous work.},
  archive      = {J_TCS},
  author       = {David M. Cerna},
  doi          = {10.1016/j.tcs.2020.10.020},
  journal      = {Theoretical Computer Science},
  pages        = {133-139},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Anti-unification and the theory of semirings},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel rewriting of attributed graphs. <em>TCS</em>,
<em>848</em>, 106–132. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some computations can be elegantly presented as the parallel or simultaneous application of rules. This is the case of cellular automata and of simultaneous assignments in Python. In both cases the expected result cannot be obtained by a sequential application of rules. A general framework of attributed graph transformations is proposed where such computations can be expressed and analyzed. Determinism is achieved by an exhaustive parallel application of rules, as in cellular automata that are shown to have a straightforward representation in this framework. A more concise parallel transformation is also proposed, where some applications of rules can be ignored thanks to their symmetries, while preserving determinism. Parallel transformations are then used to characterize the property of parallel independence.},
  archive      = {J_TCS},
  author       = {Thierry Boy de la Tour and Rachid Echahed},
  doi          = {10.1016/j.tcs.2020.09.025},
  journal      = {Theoretical Computer Science},
  pages        = {106-132},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parallel rewriting of attributed graphs},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stability of termination and sufficient-completeness under
pushouts via amalgamation. <em>TCS</em>, <em>848</em>, 82–105. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, we provide conditions for the existence of pushouts of signature morphisms in constructor-based order-sorted algebra, and then we prove that reducibility and termination of term rewriting systems are closed under pushouts. Under the termination assumption, reducibility is equivalent to sufficient-completeness, which is crucial for proving several important properties in computing for constructor-based logics such as completeness, existence of initial models and interpolation. In logic frameworks that are not based on constructors, sufficient-completeness is essential to establish the soundness of the induction schemes which are based on some methodological constructor operators. We discuss the application of our results to the instantiation of parameterized specifications.},
  archive      = {J_TCS},
  author       = {Daniel Găină and Masaki Nakamura and Kazuhiro Ogata and Kokichi Futatsugi},
  doi          = {10.1016/j.tcs.2020.09.024},
  journal      = {Theoretical Computer Science},
  pages        = {82-105},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Stability of termination and sufficient-completeness under pushouts via amalgamation},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Operator precedence temporal logic and model checking.
<em>TCS</em>, <em>848</em>, 47–81. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decades much research effort has been devoted to extending the success of model checking from the traditional field of finite state machines and various versions of temporal logics to suitable subclasses of context-free languages and appropriate extensions of temporal logics. To the best of our knowledge such attempts only covered structured languages , i.e. languages whose structure is immediately “visible” in their sentences, such as tree-languages or visibly pushdown ones. In this paper we present a new temporal logic suitable to express and automatically verify properties of operator precedence languages . This “historical” language family has been recently proved to enjoy fundamental algebraic and logic properties that make it suitable for model checking applications yet breaking the barrier of visible-structure languages (in fact the original motivation of its inventor Floyd was just to support efficient parsing , i.e. building the “hidden syntax tree” of language sentences). We prove that our logic is at least as expressive as analogous logics defined for visible pushdown languages yet covering a much more powerful family; we design a procedure that, given a formula in our logic builds an automaton recognizing the sentences satisfying the formula, whose size is at most exponential in the length of the formula. Our results cover both finite and infinite string languages.},
  archive      = {J_TCS},
  author       = {Michele Chiari and Dino Mandrioli and Matteo Pradella},
  doi          = {10.1016/j.tcs.2020.08.034},
  journal      = {Theoretical Computer Science},
  pages        = {47-81},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Operator precedence temporal logic and model checking},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity assessments for decidable fragments of set
theory. II: A taxonomy for “small” languages involving membership.
<em>TCS</em>, <em>848</em>, 28–46. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We carry on a long-standing investigation aimed at identifying fragments of set theory that are potentially useful in automated verification with proof-checkers, such as ÆtnaNova , based on the set-theoretic formalism. This note provides a complete taxonomy of the polynomial and the NP -complete fragments consisting of all conjunctions that involve, besides variables intended to range over the von Neumann set-universe, a collection of constructs drawn from the Boolean set operators ∪ , ∩ , ∖ ∪,∩,∖ and the membership relators ∈ and ∉. This is done in sight of combining the aforementioned taxonomy with one recently put together for analogous fragments involving, in place of the relators ∈ and ∉, the Boolean relators ⊆ , = ⊆,= and the predicates ‘ ⋅ = ∅ ⋅=∅ ’ and ‘ Disj ( ⋅ , ⋅ ) Disj(⋅,⋅) ’ (respectively meaning ‘the argument set is empty’ and ‘the arguments are disjoint sets’), along with their opposites ‘ ⊈ , ≠ , ⋅ ≠ ∅ ⊈,≠,⋅≠∅ ’ and ‘ ¬ Disj ( ⋅ , ⋅ ) ¬Disj(⋅,⋅) ’.},
  archive      = {J_TCS},
  author       = {Domenico Cantone and Pietro Maugeri and Eugenio G. Omodeo},
  doi          = {10.1016/j.tcs.2020.08.023},
  journal      = {Theoretical Computer Science},
  pages        = {28-46},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity assessments for decidable fragments of set theory. II: A taxonomy for ‘small’ languages involving membership},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional probability logic, lifted bayesian networks, and
almost sure quantifier elimination. <em>TCS</em>, <em>848</em>, 1–27.
(<a href="https://doi.org/10.1016/j.tcs.2020.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a formal logical language, called conditional probability logic (CPL) , which extends first-order logic and which can express probabilities , conditional probabilities and which can compare conditional probabilities. Intuitively speaking, although formal details are different, CPL can express the same kind of statements as some languages which have been considered in the artificial intelligence community. We also consider a way of making precise the notion of lifted Bayesian network , where this notion is a type of (lifted) probabilistic graphical model used in machine learning , data mining and artificial intelligence. A lifted Bayesian network (in the sense defined here) determines, in a natural way, a probability distribution on the set of all structures (in the sense of first-order logic) with a common finite domain D . Our main result ( Theorem 3.14 ) is that for every “noncritical” CPL-formula φ ( x ¯ ) φ(x¯) there is a quantifier-free formula ⁎ φ ⁎ ( x ¯ ) φ⁎(x¯) which is “almost surely” equivalent to φ ( x ¯ ) φ(x¯) as the cardinality of D tends towards infinity. This is relevant for the problem of making probabilistic inferences on large domains D , because (a) the problem of evaluating, by “brute force”, the probability of φ ( x ¯ ) φ(x¯) being true for some sequence d ¯ d¯ of elements from D has, in general, (highly) exponential time complexity in the cardinality of D , and (b) the corresponding probability for the quantifier-free ⁎ φ ⁎ ( x ¯ ) φ⁎(x¯) depends only on the lifted Bayesian network and not on D . Some conclusions regarding the computational complexity of finding ⁎ φ ⁎ φ⁎ are given in Remark 3.17 . The main result has two corollaries, one of which is a convergence law (and zero-one law) for noncritial CPL-formulas.},
  archive      = {J_TCS},
  author       = {Vera Koponen},
  doi          = {10.1016/j.tcs.2020.08.006},
  journal      = {Theoretical Computer Science},
  pages        = {1-27},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Conditional probability logic, lifted bayesian networks, and almost sure quantifier elimination},
  volume       = {848},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Facility location games with optional preference.
<em>TCS</em>, <em>847</em>, 185–197. (<a
href="https://doi.org/10.1016/j.tcs.2020.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the optional preference model of the facility location game problem with two heterogeneous facilities on a line. The preference of each agent is one of the two facilities or both facilities, and the cost of each agent is a function of the distances to the facilities that the agent prefers. We consider two cost functions: Minimum Distance and Maximum Distance functions. Aiming at minimizing the maximum cost or the social cost of agents, we propose different strategyproof mechanisms without monetary transfers and derive both lower and upper bounds of the approximation ratios with respect to strategyproof mechanisms. In the variant of Minimum Distance, we propose a 2-approximation deterministic strategyproof mechanism for the maximum cost objective, and prove a lower bound of 4/3, while for the social cost objective we propose a ( n / 2 n/2 +1)-approximation deterministic strategyproof mechanism and prove a lower bound of 2, also a lower bound of 3/2 for randomized mechanisms. In the variant of Maximum Distance, we propose an optimal deterministic strategyproof mechanism for the maximum cost objective and a 2-approximation deterministic strategyproof mechanism for the social cost objective.},
  archive      = {J_TCS},
  author       = {Zhihuai Chen and Ken C.K. Fong and Minming Li and Kai Wang and Hongning Yuan and Yong Zhang},
  doi          = {10.1016/j.tcs.2020.10.004},
  journal      = {Theoretical Computer Science},
  pages        = {185-197},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Facility location games with optional preference},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clearing an orthogonal polygon to find the evaders.
<em>TCS</em>, <em>847</em>, 175–184. (<a
href="https://doi.org/10.1016/j.tcs.2020.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a multi-robot system, a number of autonomous robots would sense, communicate, and decide to move within a given domain to achieve a common goal. In the pursuit-evasion problem, a polygonal region is given and a robot called a pursuer tries to find some mobile targets called evaders. The goal of this problem is to design a motion strategy for the pursuer such that it can detect all the evaders. In this paper, we consider a new variant of the pursuit-evasion problem in which the robots (pursuers) each moves back and forth along an orthogonal line segment inside a simple orthogonal polygon P . We assume that P includes unpredictable, moving evaders that have bounded speed. We propose the first motion-planning algorithm for a group of robots, assuming that they move along the pre-located line segments with a constant speed to detect all the evaders with bounded speed. Also, we prove an upper bound for the length of the paths that all pursuers move in the proposed algorithm.},
  archive      = {J_TCS},
  author       = {Salma Sadat Mahdavi and Mohammad Ghodsi},
  doi          = {10.1016/j.tcs.2020.10.003},
  journal      = {Theoretical Computer Science},
  pages        = {175-184},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Clearing an orthogonal polygon to find the evaders},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hierarchical cost-parity games. <em>TCS</em>, <em>847</em>,
147–174. (<a href="https://doi.org/10.1016/j.tcs.2020.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cost-parity games are a fundamental tool in system design for the analysis of reactive and distributed systems that recently have received a lot of attention from the formal methods research community. They allow to reason about the time delay on the requests granted by systems, with a bounded consumption of resources, in their executions. In this paper, we contribute to research on cost-parity games by combining them with hierarchical systems , a successful method for the succinct representation of models. We show that determining the winner of a Hierarchical Cost-parity Game is Pspace -complete, thus matching the complexity of the proper special case of Hierarchical Parity Games . This shows that reasoning about temporal delay can be addressed at a free cost in terms of complexity.},
  archive      = {J_TCS},
  author       = {Laura Bozzelli and Aniello Murano and Giuseppe Perelli and Loredana Sorrentino},
  doi          = {10.1016/j.tcs.2020.10.002},
  journal      = {Theoretical Computer Science},
  pages        = {147-174},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hierarchical cost-parity games},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing branching distances with quantitative games.
<em>TCS</em>, <em>847</em>, 134–146. (<a
href="https://doi.org/10.1016/j.tcs.2020.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We lay out a general method for computing branching distances between labeled transition systems . We translate the quantitative games used for defining these distances to other, path-building games which are amenable to methods from the theory of quantitative games. We then show for all common types of branching distances how the resulting path-building games can be solved. In the end, we achieve a method which can be used to compute all branching distances in the linear-time–branching-time spectrum.},
  archive      = {J_TCS},
  author       = {Uli Fahrenberg and Axel Legay and Karin Quaas},
  doi          = {10.1016/j.tcs.2020.10.001},
  journal      = {Theoretical Computer Science},
  pages        = {134-146},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing branching distances with quantitative games},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tight security for the generic construction of
identity-based signature (in the multi-instance setting). <em>TCS</em>,
<em>847</em>, 122–133. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An identity-based signature (IBS) scheme can be generically constructed from any ordinary signature scheme by appending a chain of signatures. Until now, it has been known that a generic construction cannot lead to a tightly secure IBS scheme, although any tightly secure signature scheme can be used as a building block . In this study, we demonstrate that the generic construction of IBS can achieve tightness if the underlying signature scheme is tightly secure in the multi-user setting with corruption. In addition, we extend the tightness result of IBS to the multi-instance setting, where an adversary can corrupt multiple key generation centers and obtain multiple related master secret keys . As instantiations, we adopt the efficient and tightly secure signature scheme in the multi-user setting with corruption, recently proposed by Gjøsteen and Jager (CRYPTO 2018). As a result, we can obtain the first efficient and tightly secure IBS schemes (in the multi-instance setting) based on the Diffie–Hellman assumptions in the random oracle model .},
  archive      = {J_TCS},
  author       = {Youngkyung Lee and Jong Hwan Park and Kwangsu Lee and Dong Hoon Lee},
  doi          = {10.1016/j.tcs.2020.09.044},
  journal      = {Theoretical Computer Science},
  pages        = {122-133},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tight security for the generic construction of identity-based signature (in the multi-instance setting)},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A linear time combinatorial algorithm to compute the
relative orthogonal convex hull of digital objects. <em>TCS</em>,
<em>847</em>, 103–121. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A linear time combinatorial algorithm to construct the relative orthogonal convex hull of the inner isothetic cover of a digital object (hole-free) with respect to its outer isothetic cover is presented in this paper. The algorithm first constructs the inner and the outer isothetic covers of the digital object which is the input to the algorithm and then constructs the relative orthogonal convex hull from the inner isothetic cover and the outer isothetic cover. The algorithm can also be used to construct the relative orthogonal convex hull of one orthogonal polygon with respect to another orthogonal polygon which encloses the first polygon entirely where the input will be two orthogonal polygons one containing the other instead of the digital object. The proposed algorithm first finds the concavities of the inner polygon and checks for intruded concavities of the outer polygon. A combinatorial technique is used to obtain the relative orthogonal convex hull. The efficiency and the correctness of the algorithm are verified as it is tested on various types of digital objects.},
  archive      = {J_TCS},
  author       = {Md A.A.A. Aman and Apurba Sarkar and Mousumi Dutt and Arindam Biswas},
  doi          = {10.1016/j.tcs.2020.09.043},
  journal      = {Theoretical Computer Science},
  pages        = {103-121},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A linear time combinatorial algorithm to compute the relative orthogonal convex hull of digital objects},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linearly many faults in cayley graphs generated by
transposition triangle free unicyclic graphs. <em>TCS</em>,
<em>847</em>, 95–102. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a kind of Cayley graphs , including the modified bubble-sort graphs M B n MBn , the Cayley graphs generated by lollipop graphs H n , n − 1 Hn,n−1 and the other Cayley graphs generated by unicyclic triangle free graphs . We get that if we delete linearly many vertices in Cayley graphs generated by transposition unicyclic triangle free graphs , then the resulting graphs has a large connected component that comprises of nearly all residual vertices.},
  archive      = {J_TCS},
  author       = {Peiheng Li and Jixiang Meng},
  doi          = {10.1016/j.tcs.2020.09.042},
  journal      = {Theoretical Computer Science},
  pages        = {95-102},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Linearly many faults in cayley graphs generated by transposition triangle free unicyclic graphs},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Further oracles separating conjectures about incompleteness
in the finite domain. <em>TCS</em>, <em>847</em>, 76–94. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pudlák [14] lists several major complexity theoretic conjectures relevant to proof complexity and asks for oracles that separate pairs of corresponding relativized conjectures. Among these conjectures are:},
  archive      = {J_TCS},
  author       = {Titus Dose},
  doi          = {10.1016/j.tcs.2020.09.040},
  journal      = {Theoretical Computer Science},
  pages        = {76-94},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Further oracles separating conjectures about incompleteness in the finite domain},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal facility location problem on polyhedral terrains
using descending paths. <em>TCS</em>, <em>847</em>, 68–75. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the descending facility location (DFL) problem on the surface of a triangulated terrain. A path from a point s to a point t on the surface of a terrain is descending if the heights of the subsequent points along the path from s to t are in a monotonically non-increasing order [1] . We are given a set D = { d 1 , d 2 , ⋯ , d n } D={d1,d2,⋯,dn} of n demand points on the surface of a triangulated terrain W W and our objective is to find a set F (of points), of minimum cardinality, on the surface of the terrain such that for each demand point d ∈ D d∈D there exists a descending path from at least one facility f ∈ F f∈F to d . We present an O ( ( n + m ) log ⁡ m ) O((n+m)log⁡m) time algorithm for solving the DFL problem, where m is the number of vertices in the triangulated terrain. We achieve this by reducing the DFL problem to a graph problem called the directed tree covering ( D T C ) (DTC) problem . In the DTC problem, we have a directed tree B = ( V , E ) B=(V,E) with a set of marked nodes M ⊆ V M⊆V . The objective is to compute a set C ⊆ V C⊆V of minimum cardinality, such that for every node v ∈ M v∈M , either v ∈ C v∈C or there exists a node c ∈ C c∈C such that v is reachable from c . We prove that the DFL problem can be reduced to DTC problem in O ( ( m + n ) log ⁡ m ) O((m+n)log⁡m) time. The DTC problem thereafter can be solved in O ( | V | ) O(|V|) time. We also prove that the general version of the DTC problem, called the directed graph covering ( D G C ) (DGC) problem is NP -hard on directed bipartite graphs and hard to approximate within ( 1 − ϵ ) ln ⁡ | M | (1−ϵ)ln⁡|M| -factor, for every ϵ &gt; 0 ϵ&amp;gt;0 , where | M | |M| is the size of the set of marked nodes. We also prove that for the DGC problem, an O ( log ⁡ | M | ) O(log⁡|M|) factor approximation is possible and this approximation factor is tight.},
  archive      = {J_TCS},
  author       = {Binayak Dutta and Arindam Karmakar and Sasanka Roy},
  doi          = {10.1016/j.tcs.2020.09.037},
  journal      = {Theoretical Computer Science},
  pages        = {68-75},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal facility location problem on polyhedral terrains using descending paths},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Step-by-step community detection in volume-regular graphs.
<em>TCS</em>, <em>847</em>, 49–67. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral techniques have proved amongst the most effective approaches to graph clustering . However, in general they require explicit computation of the main eigenvectors of a suitable matrix (usually the Laplacian matrix of the graph). Recent work (e.g., Becchetti et al., SODA 2017) suggests that observing the temporal evolution of the power method applied to an initial random vector may, at least in some cases, provide enough information on the space spanned by the first two eigenvectors , so as to allow recovery of a hidden partition without explicit eigenvector computations. While the results of Becchetti et al. apply to perfectly balanced partitions and/or graphs that exhibit very strong forms of regularity, we extend their approach to graphs containing a hidden k partition and characterized by a milder form of volume-regularity. We show that the class of k - volume regular graphs is the largest class of undirected (possibly weighted) graphs whose transition matrix admits k “stepwise” eigenvectors (i.e., vectors that have constant entries over the components corresponding to the same set of the hidden partition). To obtain this result, we highlight a connection between volume regularity and lumpability of Markov chains . Moreover, we prove that if the stepwise eigenvectors are those associated to the first k largest eigenvalues of the transition matrix of a random walk on the graph and the gap between the k -th and the ( k + 1 k+1 )-th eigenvalues is sufficiently large, the Averaging dynamics of Becchetti et al. recovers the underlying community structure of the graph in logarithmic time, with high probability .},
  archive      = {J_TCS},
  author       = {Luca Becchetti and Emilio Cruciani and Francesco Pasquale and Sara Rizzo},
  doi          = {10.1016/j.tcs.2020.09.036},
  journal      = {Theoretical Computer Science},
  pages        = {49-67},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Step-by-step community detection in volume-regular graphs},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge-fault-tolerant strong menger edge connectivity on
regular graphs. <em>TCS</em>, <em>847</em>, 39–48. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The connectivity of a graph is an important issue in graph theory and is also one of the most important factors in evaluating the reliability and fault tolerance of a network. A graph G is called m -edge-fault-tolerant strongly Menger ( m -EFTSM for short) edge connected if there are min ⁡ { deg G − F ⁡ ( x ) , deg G − F ⁡ ( y ) } min⁡{degG−F⁡(x),degG−F⁡(y)} edge-disjoint paths between any two different vertices x and y in G − F G−F for any F ⊆ E ( G ) F⊆E(G) with | F | ≤ m |F|≤m . In this paper, we give a necessary and sufficient condition of EFTSM edge connectivity on regular graphs . And we obtain several optimal results about EFTSM edge connectivity on (1, 2)-matching composition networks, each of which is constructed by connecting two graphs via one or two perfect matchings . As applications, we show that the class of n -dimensional hypercube-like networks (included hypercube , crossed cube et al.) are ( n − 2 ) (n−2) -EFTSM edge connected; show that the n -dimensional folded hypercube is ( n − 1 ) (n−1) -EFTSM edge connected, and show that the n -dimensional augmented cube is ( 2 n − 3 ) (2n−3) -EFTSM edge connected. The bounds ( n − 2 ) , ( n − 1 ) (n−2),(n−1) and ( 2 n − 3 ) (2n−3) are sharp.},
  archive      = {J_TCS},
  author       = {Min Xu and Pingshan Li},
  doi          = {10.1016/j.tcs.2020.09.035},
  journal      = {Theoretical Computer Science},
  pages        = {39-48},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Edge-fault-tolerant strong menger edge connectivity on regular graphs},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revisiting the parameterized complexity of maximum-duo
preservation string mapping. <em>TCS</em>, <em>847</em>, 27–38. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Maximum-Duo Preservation String Mapping ( Max-Duo PSM ) problem, the input consists of two related strings A and B of length n and a nonnegative integer k . The objective is to determine whether there exists a mapping m from the set of positions of A to the set of positions of B that maps only to positions with the same character and preserves at least k duos , which are pairs of adjacent positions. We develop a randomized algorithm that solves Max-Duo PSM in 4 k ⋅ n O ( 1 ) 4k⋅nO(1) time, and a deterministic algorithm that solves this problem in 6.855 k ⋅ n O ( 1 ) 6.855k⋅nO(1) time. The previous best known (deterministic) algorithm for this problem has ( 8 e ) 2 k + o ( k ) ⋅ n O ( 1 ) (8e)2k+o(k)⋅nO(1) running time [Beretta et al. (2016) [1] , [2] ]. We also show that Max-Duo PSM admits a problem kernel of size O ( k 3 ) O(k3) , improving upon the previous best known problem kernel of size O ( k 6 ) O(k6) .},
  archive      = {J_TCS},
  author       = {Christian Komusiewicz and Mateus de Oliveira Oliveira and Meirav Zehavi},
  doi          = {10.1016/j.tcs.2020.09.034},
  journal      = {Theoretical Computer Science},
  pages        = {27-38},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Revisiting the parameterized complexity of maximum-duo preservation string mapping},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The one-cop-moves game on graphs with some special
structures. <em>TCS</em>, <em>847</em>, 17–26. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the one-cop-moves game played on a graph. In this game, a set of cops and a robber occupy the vertices of the graph and move alternately along the graph&#39;s edges with perfect information about each other&#39;s positions. The goal of the cops is to capture the robber. At cops&#39; turns, exactly one cop is allowed to move from his location to an adjacent vertex; at robber&#39;s turns, she is allowed to move from her location to an adjacent vertex or to stay still. We want to find the minimum number of cops to capture the robber. This number is known as the cop number. In this paper, we investigate the cop number of several classes of graphs, including graphs with treewidth at most 2, Halin graphs, and Cartesian product graphs. We also give a characterization of k -winnable graphs in the one-cop-moves game.},
  archive      = {J_TCS},
  author       = {Lusheng Wang and Boting Yang},
  doi          = {10.1016/j.tcs.2020.09.033},
  journal      = {Theoretical Computer Science},
  pages        = {17-26},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The one-cop-moves game on graphs with some special structures},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constant-size CCA-secure multi-hop unidirectional proxy
re-encryption from indistinguishability obfuscation. <em>TCS</em>,
<em>847</em>, 1–16. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In ACM CCS 2007, Canetti and Hohenberger left an open problem of how to construct a multi-hop unidirectional proxy re-encryption scheme secure against chosen-ciphertext attacks (CCA). To resolve this problem, we utilize the recent advances in indistinguishability obfuscation, overcome several obstacles and propose a multi-hop unidirectional proxy re-encryption scheme. The proposed scheme is proved to be CCA-secure in the standard model (i.e., without using the random oracle heuristic), and its ciphertext remains constant-size regardless of how many times it has been transformed. It is worth noting that, our techniques proposed in this paper can also be used to construct an identity-based multi-hop unidirectional PRE scheme with constant-size ciphertexts and CCA-security in the standard model.},
  archive      = {J_TCS},
  author       = {Junzuo Lai and Zhengan Huang and Man Ho Au and Xianping Mao},
  doi          = {10.1016/j.tcs.2020.09.031},
  journal      = {Theoretical Computer Science},
  pages        = {1-16},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Constant-size CCA-secure multi-hop unidirectional proxy re-encryption from indistinguishability obfuscation},
  volume       = {847},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Prior-free multi-unit auctions with ordered bidders.
<em>TCS</em>, <em>846</em>, 160–171. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior-free auctions are robust auctions that assume no distribution over bidders&#39; valuations and provide worst-case (input-by-input) approximation guarantees. In contrast to previous work on this topic, we pursue good prior-free auctions with non-identical bidders. Prior-free auctions can approximate meaningful benchmarks for non-identical bidders only when sufficient qualitative information about the bidder asymmetry is publicly known. We consider digital goods auctions where there is a total ordering of the bidders that is known to the seller, where earlier bidders are in some sense thought to have higher valuations. We use the framework of Hartline and Roughgarden (STOC&#39;08) to define an appropriate revenue benchmark: the maximum revenue that can be obtained from a bid vector using prices that are nonincreasing in the bidder ordering and bounded above by the second-highest bid. This monotone-price benchmark is always as large as the well-known fixed-price benchmark F ( 2 ) F(2) , so designing prior-free auctions with good approximation guarantees is only harder. By design, an auction that approximates the monotone-price benchmark satisfies a very strong guarantee: it is, in particular, simultaneously near-optimal for essentially every Bayesian environment in which bidders&#39; valuation distributions have nonincreasing monopoly prices, or in which the distribution of each bidder stochastically dominates that of the next. Even when there is no distribution over bidders&#39; valuations, such an auction still provides a quantifiable input-by-input performance guarantee. In this paper, we design a simple O ( 1 ) O(1) -competitive prior-free auction for digital goods with ordered bidders. We also extend the monotone-price benchmark and our O ( 1 ) O(1) -competitive prior-free auction to multi-unit settings with limited supply.},
  archive      = {J_TCS},
  author       = {Sayan Bhattacharya and Elias Koutsoupias and Janardhan Kulkarni and Stefano Leonardi and Tim Roughgarden and Xiaoming Xu},
  doi          = {10.1016/j.tcs.2020.09.030},
  journal      = {Theoretical Computer Science},
  pages        = {160-171},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Prior-free multi-unit auctions with ordered bidders},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The untyped computational λ-calculus and its intersection
type discipline. <em>TCS</em>, <em>846</em>, 141–159. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a Curry style type assignment system for untyped λ -calculi with effects, based on Moggi&#39;s monadic approach. Moving from the abstract definition of monads, we introduce a version of the call-by-value computational λ -calculus based on Wadler&#39;s variant, without let , and with unit and bind operators. We define a notion of reduction for the calculus and prove it confluent. We then introduce an intersection type system inspired by Barendregt, Coppo and Dezani system for ordinary untyped λ -calculus, establishing type invariance under conversion. Finally, we introduce a notion of convergence, which is precisely related to reduction, and characterize convergent terms via their types.},
  archive      = {J_TCS},
  author       = {Ugo de&#39;Liguoro and Riccardo Treglia},
  doi          = {10.1016/j.tcs.2020.09.029},
  journal      = {Theoretical Computer Science},
  pages        = {141-159},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The untyped computational λ-calculus and its intersection type discipline},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the curve complexity of 3-colored point-set embeddings.
<em>TCS</em>, <em>846</em>, 114–140. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish new results on the curve complexity of k -colored point-set embeddings when k = 3 k=3 . We show that there exist 3-colored caterpillars with only three independent edges whose 3-colored point-set embeddings may require Ω ( n 1 3 ) Ω(n13) bends on Ω ( n 2 3 ) Ω(n23) edges. This settles an open problem by Badent et al. [5] about the curve complexity of point set embeddings of k -colored trees and it extends a lower bound by Pach and Wenger [35] to the case that the graph only has O ( 1 ) O(1) independent edges. Concerning upper bounds, we prove that any 3-colored path admits a 3-colored point-set embedding with curve complexity at most 4. In addition, we introduce a variant of the k -colored simultaneous embeddability problem and study its relationship with the k -colored point-set embeddability problem.},
  archive      = {J_TCS},
  author       = {Emilio Di Giacomo and Leszek Gąsieniec and Giuseppe Liotta and Alfredo Navarra},
  doi          = {10.1016/j.tcs.2020.09.027},
  journal      = {Theoretical Computer Science},
  pages        = {114-140},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the curve complexity of 3-colored point-set embeddings},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterized algorithms and kernels for almost induced
matching. <em>TCS</em>, <em>846</em>, 103–113. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Almost Induced Matching problem asks whether we can delete at most k vertices from the input graph such that each vertex in the remaining graph has a degree exactly one. This paper studies parameterized algorithms for this problem by taking the size k of the deletion set as the parameter. We give a 7 k -vertex kernel and an ⁎ O ⁎ ( 1.7485 k ) O⁎(1.7485k) -time and polynomial-space algorithm, both of which are the best-known results. The linear-vertex kernel is obtained by using an extended crown decomposition and careful analysis, and the parameterized algorithm is based on a branch-and-search paradigm.},
  archive      = {J_TCS},
  author       = {Mingyu Xiao and Shaowei Kou},
  doi          = {10.1016/j.tcs.2020.09.026},
  journal      = {Theoretical Computer Science},
  pages        = {103-113},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameterized algorithms and kernels for almost induced matching},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Priority evacuation from a disk: The case of n ≥ 4.
<em>TCS</em>, <em>846</em>, 91–102. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a new search-type problem with ( n + 1 n+1 )-robots on a disk. The searchers (robots) all start from the center of the disk, have unit speed, and can communicate wirelessly. The goal is for a distinguished robot (the queen) to reach and evacuate from an exit that is hidden on the perimeter of the disk in as little time as possible. The remaining n robots (servants) are there to facilitate the queen&#39;s objective and are not required to reach the hidden exit. We provide upper and lower bounds for the time required to evacuate the queen from a unit disk. Namely, we propose an algorithm specifying the trajectories of the robots which guarantees evacuation of the queen in time always better than 2 + 4 ( 2 − 1 ) π n 2+4(2−1)πn for n ≥ 4 n≥4 servants. We also demonstrate that for n ≥ 4 n≥4 servants the queen cannot be evacuated in time less than 2 + π n + 2 n 2 2+πn+2n2 .},
  archive      = {J_TCS},
  author       = {J. Czyzowicz and K. Georgiou and R. Killick and E. Kranakis and D. Krizanc and L. Narayanan and J. Opatrny and S. Shende},
  doi          = {10.1016/j.tcs.2020.09.023},
  journal      = {Theoretical Computer Science},
  pages        = {91-102},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Priority evacuation from a disk: The case of n ≥ 4},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On caterpillar factors in graphs. <em>TCS</em>,
<em>846</em>, 82–90. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A caterpillar is either a K 2 K2 or a tree on at least 3 vertices such that deleting its leaves we obtain a path of order at least 1. Given a simple undirected graph G = ( V , E ) G=(V,E) , a caterpillar factor of G is a set of caterpillar subgraphs of G such that each vertex v ∈ V v∈V belongs to exactly one of them. A caterpillar factor F is internally even if every vertex of degree deg F ( v ) ≥ 2 degF(v)≥2 has an even degree; F is odd if deg F ( v ) degF(v) is odd for every v ∈ V ( G ) v∈V(G) . We present a linear-time algorithm that decides whether a tree admits an internally even caterpillar factor and, on the other hand, we prove that the decision problem is NP-complete on the class of planar bipartite graphs . For the odd caterpillar factor problem, we obtain similar results. It can be decided in linear time over the class of trees, but the problem is NP-complete on the class of bipartite graphs.},
  archive      = {J_TCS},
  author       = {Csilla Bujtás and Stanislav Jendroľ and Zsolt Tuza},
  doi          = {10.1016/j.tcs.2020.09.022},
  journal      = {Theoretical Computer Science},
  pages        = {82-90},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On caterpillar factors in graphs},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fractional matching preclusion of product networks.
<em>TCS</em>, <em>846</em>, 75–81. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The matching preclusion number of a graph, introduced in [2] as a fault analysis, is the minimum number of edges whose deletion leaves a resulting graph that has neither perfect matchings nor almost perfect matchings . As a generalization, Liu and Liu [14] recently introduced the concept of fractional matching preclusion number. The fractional matching preclusion number of graph is the minimum number of edges whose deletion results in a graph that has no fractional perfect matching. If the sets of edges of the graph attaining the minimum are precisely those incident to a single vertex of minimum degree, we say such graph is fractional super matched . In this paper, the upper and lower bounds for the fractional matching preclusion number for Cartesian product , direct product, strong product, and lexicographic product are obtained, and we give sufficient conditions for such graphs to be fractional super matched.},
  archive      = {J_TCS},
  author       = {Jinling Wang},
  doi          = {10.1016/j.tcs.2020.09.021},
  journal      = {Theoretical Computer Science},
  pages        = {75-81},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fractional matching preclusion of product networks},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A distributed algorithm for finding hamiltonian cycles in
random graphs in o(log⁡n) time. <em>TCS</em>, <em>846</em>, 61–74. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known for some time that a random graph G ( n , p ) G(n,p) contains w.h.p. a Hamiltonian cycle if p is larger than the critical value p c r i t = ( log ⁡ n + log ⁡ log ⁡ n + ω n ) / n pcrit=(log⁡n+log⁡log⁡n+ωn)/n . The determination of a concrete Hamiltonian cycle for G ( n , p ) G(n,p) is a nontrivial task, even when p is much larger than p c r i t pcrit . In this paper we consider random graphs G ( n , p ) G(n,p) with p in Ω ˜ ( 1 / n ) Ω˜(1/n) , where Ω ˜ Ω˜ hides poly-logarithmic factors in n . For this range of p we present a distributed algorithm A HC AHC that finds w.h.p. a Hamiltonian cycle in O ( log ⁡ n ) O(log⁡n) rounds. The algorithm works in the synchronous model and uses messages of size O ( log ⁡ n ) O(log⁡n) and O ( log ⁡ n ) O(log⁡n) memory per node.},
  archive      = {J_TCS},
  author       = {Volker Turau},
  doi          = {10.1016/j.tcs.2020.09.020},
  journal      = {Theoretical Computer Science},
  pages        = {61-74},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A distributed algorithm for finding hamiltonian cycles in random graphs in o(log⁡n) time},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast two-robot disk evacuation with wireless communication.
<em>TCS</em>, <em>846</em>, 38–60. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the fast evacuation problem, we study the path planning problem for two robots who want to minimize the worst-case evacuation time on the unit disk, that is, the time till both of them evacuate. The robots are initially placed at the center of the disk. In order to evacuate, they need to reach an unknown point, the exit, on the boundary of the disk. Once one of the robots finds the exit, it will instantaneously, i.e., using wireless communication , notify the other agent who will then follow a straight line to it. The problem has been studied for robots with the same speed [13] . We study a more general case where one robot has speed 1 and the other has speed s ≥ 1 s≥1 . We provide optimal evacuation strategies in the case that s ≥ 2.75 s≥2.75 by showing matching upper and lower bounds on the worst-case evacuation time. For 1 ≤ s 1≤s&amp;lt;2.75 , we show (non-matching) upper and lower bounds on the evacuation time with a ratio less than 1.22. Moreover, we demonstrate that a different-speeds generalization of the two-robot search strategy from [13] is outperformed by our proposed strategies for any s ≥ 1.71 s≥1.71 .},
  archive      = {J_TCS},
  author       = {Ioannis Lamprou and Russell Martin and Sven Schewe},
  doi          = {10.1016/j.tcs.2020.09.019},
  journal      = {Theoretical Computer Science},
  pages        = {38-60},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fast two-robot disk evacuation with wireless communication},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple and local independent set approximation.
<em>TCS</em>, <em>846</em>, 27–37. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the worst-case behavior of Turán-like bounds for unweighted and weighted independent sets in bounded-degree graphs. In particular, we revisit a randomized approach of Boppana that forms a simple 1-round distributed algorithm, as well as a streaming algorithm and a preemptive online algorithm . We show that it gives a tight ( Δ + 1 ) / 2 (Δ+1)/2 -approximation in unweighted graphs of maximum degree Δ, which is best possible for 1-round distributed algorithms. For weighted graphs , it gives only a ( Δ + 1 ) (Δ+1) -approximation, but a simple modification results in an asymptotic expected 0.529 ( Δ + 1 ) 0.529(Δ+1) -approximation.},
  archive      = {J_TCS},
  author       = {Ravi B. Boppana and Magnús M. Halldórsson and Dror Rawitz},
  doi          = {10.1016/j.tcs.2020.09.018},
  journal      = {Theoretical Computer Science},
  pages        = {27-37},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Simple and local independent set approximation},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum independent sets in subcubic graphs: New results.
<em>TCS</em>, <em>846</em>, 14–26. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum independent set problem is known to be NP-hard in the class of subcubic graphs, i.e. graphs of vertex degree at most 3. We study complexity of the problem on hereditary subclasses of subcubic graphs. Each such subclass can be described by means of forbidden induced subgraphs . In case of finitely many forbidden induced subgraphs a necessary condition for polynomial-time solvability of the problem in subcubic graphs (unless P = N P P=NP ) is the exclusion of the graph S i , j , k Si,j,k , which is a tree with three leaves of distance i , j , k i,j,k from the only vertex of degree 3. Whether this condition is also sufficient is an open question, which was previously answered only for S 1 , k , k S1,k,k -free subcubic graphs and S 2 , 2 , 2 S2,2,2 -free subcubic graphs. Combining various algorithmic techniques, in the present paper we generalize both results and show that the problem can be solved in polynomial time for S 2 , k , k S2,k,k -free subcubic graphs, for any fixed value of k .},
  archive      = {J_TCS},
  author       = {A. Harutyunyan and M. Lampis and V. Lozin and J. Monnot},
  doi          = {10.1016/j.tcs.2020.09.010},
  journal      = {Theoretical Computer Science},
  pages        = {14-26},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Maximum independent sets in subcubic graphs: New results},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed-parameter tractable algorithms for tracking shortest
paths. <em>TCS</em>, <em>846</em>, 1–13. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the parameterized complexity of the problem of tracking shortest s - t paths in graphs, motivated by applications in security and wireless networks. Given an undirected and unweighted graph with a source s and a destination t , Tracking Shortest Paths asks if there exists a k -sized subset of vertices (referred to as tracking set ) that intersects each shortest s - t path in a distinct set of vertices. We first generalize this problem for set systems, namely Tracking Set System , where given a family of subsets of a universe, we are required to find a subset of elements from the universe that has a unique intersection with each set in the family. Tracking Set System is shown to be fixed-parameter tractable due to its relation with a known problem, Test Cover . By a reduction to the well-studied d -hitting set problem, we give a polynomial (with respect to k ) kernel for the case when the set sizes are bounded by d . This also helps in solving Tracking Shortest Paths when the input graph diameter is bounded by d . While the results for Tracking Set System show that Tracking Shortest Paths is fixed-parameter tractable, we also give an independent algorithm by using some preprocessing rules, resulting in an improved running time.},
  archive      = {J_TCS},
  author       = {Aritra Banik and Pratibha Choudhary and Venkatesh Raman and Saket Saurabh},
  doi          = {10.1016/j.tcs.2020.09.006},
  journal      = {Theoretical Computer Science},
  pages        = {1-13},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fixed-parameter tractable algorithms for tracking shortest paths},
  volume       = {846},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Space-efficient algorithms for computing minimal/shortest
unique substrings. <em>TCS</em>, <em>845</em>, 230–242. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a string T of length n , a substring u = T [ i . . j ] u=T[i..j] of T is called a shortest unique substring (SUS) for an interval [ s , t ] [s,t] if (a) u occurs exactly once in T , (b) u contains the interval [ s , t ] [s,t] (i.e. i ≤ s ≤ t ≤ j i≤s≤t≤j ), and (c) every substring v of T with | v | |v|&amp;lt;|u| containing [ s , t ] [s,t] occurs at least twice in T . Given a query interval [ s , t ] ⊂ [ 1 , n ] [s,t]⊂[1,n] , the interval SUS problem is to output all the SUSs for the interval [ s , t ] [s,t] . In this article, we propose a 4 n + o ( n ) 4n+o(n) bits data structure answering an interval SUS query in output-sensitive O ( o c c ) O(occ) time, where occ is the number of returned SUSs. Additionally, we focus on the point SUS problem , which is the interval SUS problem for s = t s=t . Here, we propose a ⌈ ( log 2 ⁡ 3 + 1 ) n ⌉ + o ( n ) ⌈(log2⁡3+1)n⌉+o(n) bits data structure answering a point SUS query in the same output-sensitive time. We also propose space-efficient algorithms for computing the minimal unique substrings of T .},
  archive      = {J_TCS},
  author       = {Takuya Mieno and Dominik Köppl and Yuto Nakashima and Shunsuke Inenaga and Hideo Bannai and Masayuki Takeda},
  doi          = {10.1016/j.tcs.2020.09.017},
  journal      = {Theoretical Computer Science},
  pages        = {230-242},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Space-efficient algorithms for computing minimal/shortest unique substrings},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online parameterized dictionary matching with one gap.
<em>TCS</em>, <em>845</em>, 208–229. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the online Parameterized Dictionary Matching with One Gap problem (PDMOG) which is the following. Preprocess a dictionary D of d patterns, where each pattern contains a special gap symbol that can match any string, so that given a text T arriving online, a character at a time, we can report all the patterns from D that parameterized match to suffixes of the text that has arrived so far, before the next character arrives. Two equal-length strings are a parameterized match if there exists a bijection on the alphabets, such that one string matches the other under the bijection . The gap symbols are associated with bounds determining the possible lengths of matching strings. Online Dictionary Matching with One Gap (DMOG) captures the difficulty in a bottleneck procedure for cyber-security, as many digital signatures of viruses manifest themselves as patterns with a single gap. Parameterized match captures possible encryption of the patterns. We also define the strict PDMOG problem, in which subpatterns of the same dictionary pattern should be parameterized matched via the same bijection. This captures situations where subpatterns of a dictionary pattern are encoded simultaneously. We study this problem for special case called alphabet-saturated dictionairy , where every subpattern contains all characters of the dictionary alphabet Σ. We use the following parameters to describe our results: D D is the total size of the dictionary (not including the gaps), plsc is the longest parameterized suffix chain of subpatterns in D , op is the number of parameterized patterns occurrences in T , ⁎ α ⁎ α⁎ and ⁎ β ⁎ β⁎ are the minimum left and maximum right gap borders in the non-uniformly bounded dictionary case, δ ( G D ) δ(GD) is the degeneracy of the graph G D GD representing dictionary D . This graph is classified as sparse or dense according the value of the δ ( G D ) δ(GD) and plsc parameters. We obtain: These results are parallel to the ones obtained for the Dictionary with One Gap (DMOG) problem almost matching the lower bounds achieved for this problem [7] . While the parameter δ ( G D ) δ(GD) can be as large as d d and much lager if the dictionary has non-uniform gap boundaries, and the parameter plsc could theoretically be as large as d , in many practical situations these parameters are actually small. The strength of our work is in achieving results that explore and exploit small values for these parameters, thus supplying algorithms that are suitable for some practical cyber security needs.},
  archive      = {J_TCS},
  author       = {Avivit Levy and B. Riva Shalom},
  doi          = {10.1016/j.tcs.2020.09.016},
  journal      = {Theoretical Computer Science},
  pages        = {208-229},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online parameterized dictionary matching with one gap},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure fault tolerance of balanced hypercubes.
<em>TCS</em>, <em>845</em>, 198–207. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The S -structure connectivity κ ( G ; S ) and S -substructure connectivity κ s ( G ; S ) of graph G with structure graph S , which are newly proposed in recent years, can better measure fault tolerance of networks. In this paper, we study κ ( B H n ; S ) and κ s ( B H n ; S ) of n -dimensional balanced hypercube B H n , which is a relatively popular network topology proposed recently, for S ∈ { P k , C 6 α , K 1 , r } where 4 ≤ k ≤ n , 6 ≤ 6 α ≤ n and 4 ≤ r ≤ 5 .},
  archive      = {J_TCS},
  author       = {Heqin Liu and Dongqin Cheng},
  doi          = {10.1016/j.tcs.2020.09.015},
  journal      = {Theoretical Computer Science},
  pages        = {198-207},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Structure fault tolerance of balanced hypercubes},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding patterns and periods in cartesian tree matching.
<em>TCS</em>, <em>845</em>, 181–197. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new metric of match, called Cartesian tree matching , which means that two strings match if they have the same Cartesian trees. Based on Cartesian tree matching, we define single pattern matching , multiple pattern matching , and indexing problems. We propose a linear time algorithm for single pattern matching, and randomized linear time algorithms for multiple pattern matching and indexing. We also define three types of periods, called full period, initial period, and general period. We propose O ( n ) O(n) time, O ( n log ⁡ log ⁡ n ) O(nlog⁡log⁡n) time, and O ( n log ⁡ n ) O(nlog⁡n) time algorithms for finding all the full periods, initial periods, and general periods of a string of length n , respectively. Our efficient algorithms use a representation of the Cartesian tree, called parent-distance representation .},
  archive      = {J_TCS},
  author       = {Sung Gwan Park and Magsarjav Bataa and Amihood Amir and Gad M. Landau and Kunsoo Park},
  doi          = {10.1016/j.tcs.2020.09.014},
  journal      = {Theoretical Computer Science},
  pages        = {181-197},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Finding patterns and periods in cartesian tree matching},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Absolutely no free lunches! <em>TCS</em>, <em>845</em>,
159–180. (<a href="https://doi.org/10.1016/j.tcs.2020.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with learners who aim to learn patterns in infinite binary sequences : shown longer and longer initial segments of a binary sequence, they either attempt to predict whether the next bit will be a 0 or will be a 1 or they issue forecast probabilities for these events. Several variants of this problem are considered. In each case, a no-free-lunch result of the following form is established: the problem of learning is a formidably difficult one, in that no matter what method is pursued, failure is incomparably more common that success; and difficult choices must be faced in choosing a method of learning, since no approach dominates all others in its range of success. In the simplest case, the comparison of the set of situations in which a method fails and the set of situations in which it succeeds is a matter of cardinality (countable vs. uncountable); in other cases, it is a topological matter (meagre vs. co-meagre) or a hybrid computational-topological matter (effectively meagre vs. effectively co-meagre).},
  archive      = {J_TCS},
  author       = {Gordon Belot},
  doi          = {10.1016/j.tcs.2020.09.013},
  journal      = {Theoretical Computer Science},
  pages        = {159-180},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Absolutely no free lunches!},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On positionality of trigger strategies nash equilibria in
SCAR. <em>TCS</em>, <em>845</em>, 144–158. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study here the positionality of trigger strategies Nash equilibria σ ‾ σ‾ for the N -player SCAR games Γ N ( G | s 0 , γ , ε ) ΓN(G|s0,γ,ε) (with N ≥ 3 N≥3 ). Our study is exhaustive with respect to types of graphs G , initial states s 0 s0 and values of N , γ , ε N,γ,ε . We conclude that in the majority of cases, profiles σ ‾ σ‾ are nonpositional. Whenever σ ‾ σ‾ are positional a key role is played by paths and the ε , γ values (especially whether ε &gt; 0 ε&amp;gt;0 or not). A crucial concept in our analysis is the state cop number , which is first introduced in the current paper.},
  archive      = {J_TCS},
  author       = {G. Konstantinidis and Ath. Kehagias},
  doi          = {10.1016/j.tcs.2020.09.011},
  journal      = {Theoretical Computer Science},
  pages        = {144-158},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On positionality of trigger strategies nash equilibria in SCAR},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation of set multi-cover via hypergraph matching.
<em>TCS</em>, <em>845</em>, 136–143. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a given b ∈ N n b∈Nn and a hypergraph H = ( V , E ) H=(V,E) with maximum degree Δ, the b -set multicover problem which we are concerned with in this paper may be stated as follows: find a minimum cardinality subset C ⊆ E C⊆E such that no vertex v i ∈ V vi∈V is contained in less than b i bi hyperedges of C C . Peleg, Schechtman, and Wool (1997) conjectured that for any fixed Δ and b = min i ⁡ b i b=mini⁡bi , the problem cannot be approximated with a ratio strictly smaller than δ : = Δ − b + 1 δ:=Δ−b+1 , unless P = NP P=NP . In this paper, we show that the conjecture of Peleg et al. is not true on ℓ -uniform hypergraphs by presenting a polynomial-time approximation algorithm based on a matching/covering duality for hypergraphs due to Ray-Chaudhuri (1960), which we convert into an approximative form. The given algorithm yields a ratio smaller than ( 1 − b ( ℓ + 1 ) Δ ) Δ b (1−b(ℓ+1)Δ)Δb . Moreover, we prove that the lower bound conjectured by Peleg et al. holds for regular hypergraphs under the unique games conjecture.},
  archive      = {J_TCS},
  author       = {Abbass Gorgi and Mourad El Ouali and Anand Srivastav and Mohamed Hachimi},
  doi          = {10.1016/j.tcs.2020.09.009},
  journal      = {Theoretical Computer Science},
  pages        = {136-143},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation of set multi-cover via hypergraph matching},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Card-based protocols for secure ranking computations.
<em>TCS</em>, <em>845</em>, 122–135. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a group of people who want to know the “rich list” among them, namely the ranking in terms of their total assets, without revealing any information about the actual value of their assets. This can be achieved by a “secure ranking computation,” which was first considered by Jiang and Gong (2006) [2] ; they constructed a secure ranking computation protocol based on a public-key cryptosystem. In this paper, instead of using a public-key cryptosystem, we use a deck of physical cards to provide secure ranking computation protocols. Therefore, our card-based protocols do not rely on computers, and they are simple and easy for humans to implement. Specifically, we design four protocols considering tradeoffs between the number of cards and the number of shuffles required to execute the protocols. We also present a guide to choose an appropriate protocol according to the number of people participating in the protocol and the size of the input range. To be precise, whereas our protocols make all players know the rich list, the Jiang–Gong scheme makes each player know his/her rank only; to achieve the same task (as the Jiang–Gong scheme) using a deck of cards is an intriguing open problem.},
  archive      = {J_TCS},
  author       = {Ken Takashima and Yuta Abe and Tatsuya Sasaki and Daiki Miyahara and Kazumasa Shinagawa and Takaaki Mizuki and Hideaki Sone},
  doi          = {10.1016/j.tcs.2020.09.008},
  journal      = {Theoretical Computer Science},
  pages        = {122-135},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Card-based protocols for secure ranking computations},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards a theory of mixing graphs: A characterization of
perfect mixability. <em>TCS</em>, <em>845</em>, 98–121. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some microfluidic lab-on-chip devices contain modules whose function is to mix two fluids, called reactant and buffer, in desired proportions. In one of the technologies for fluid mixing the process can be represented by a directed acyclic graph whose nodes represent micro-mixers and edges represent micro-channels. A micro-mixer has two input channels and two output channels; it receives two fluid droplets, one from each input, mixes them perfectly, and produces two droplets of the mixed fluid on its output channels. Such a mixing graph converts a set I of input droplets into a set T of output droplets, where the droplets are specified by their reactant concentrations. The most fundamental algorithmic question related to mixing graphs is to determine, given an input set I and a target set T , whether there is a mixing graph that converts I into T . We refer to this decision problem as mix-reachability . While the complexity of this problem remains open, we provide a solution to its natural sub-problem, called perfect mixability , in which we ask whether, given a collection C of droplets, there is a mixing graph that mixes C perfectly, producing only droplets whose concentration is the average concentration of C . We provide a complete characterization of such perfectly mixable sets and an efficient algorithm for testing perfect mixability. Further, we prove that any perfectly mixable set has a perfect-mixing graph of polynomial size, and that this graph can be computed in polynomial time .},
  archive      = {J_TCS},
  author       = {Miguel Coviello Gonzalez and Marek Chrobak},
  doi          = {10.1016/j.tcs.2020.09.007},
  journal      = {Theoretical Computer Science},
  pages        = {98-121},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Towards a theory of mixing graphs: A characterization of perfect mixability},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sorting an array using the topological sort of a
corresponding comparison graph. <em>TCS</em>, <em>845</em>, 76–97. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quest for efficient sorting is ongoing, and we will explore a graph-based stable sorting strategy, in particular employing comparison graphs. We use the topological sort to map the comparison graph to a linear domain, and we can manipulate our graph such that the resulting topological sort is the sorted array. By taking advantage of the many relations between Hamiltonian paths and topological sorts in comparison graphs, we design a Divide-and-Conquer algorithm that runs in the optimal O ( n log ⁡ n ) O(nlog⁡n) time. In the process, we construct a new merge process for graphs with relevant invariant properties for our use. Furthermore, this method is more space-efficient than the famous MergeSort since we modify our fixed graph only.},
  archive      = {J_TCS},
  author       = {Balaram D. Behera},
  doi          = {10.1016/j.tcs.2020.09.004},
  journal      = {Theoretical Computer Science},
  pages        = {76-97},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Sorting an array using the topological sort of a corresponding comparison graph},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New bounds for energy complexity of boolean functions.
<em>TCS</em>, <em>845</em>, 59–75. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a Boolean function f : { 0 , 1 } n → { 0 , 1 } f:{0,1}n→{0,1} computed by a Boolean circuit C over a finite basis B B , the energy complexity of C (denoted by EC B ( C ) ECB(C) ) is the maximum over all inputs { 0 , 1 } n {0,1}n of the number gates of the circuit C (excluding the inputs) that output a one. Energy Complexity of a Boolean function over a finite basis B B denoted by EC B ( f ) = def min C ⁡ EC B ( C ) ECB(f)=defminC⁡ECB(C) where C is a Boolean circuit over B B computing f . We study the case when B = { ∧ 2 , ∨ 2 , ¬ } B={∧2,∨2,¬} , the standard Boolean basis. It is known that any Boolean function can be computed by a circuit (with potentially large size) with an energy of at most 3 n ( 1 + ϵ ( n ) ) 3n(1+ϵ(n)) for a small ϵ ( n ) ϵ(n) (which we observe is improvable to 3 n − 1 3n−1 ). We show several new results and connections between energy complexity and other well-studied parameters of Boolean functions.},
  archive      = {J_TCS},
  author       = {Krishnamoorthy Dinesh and Samir Otiv and Jayalal Sarma},
  doi          = {10.1016/j.tcs.2020.09.003},
  journal      = {Theoretical Computer Science},
  pages        = {59-75},
  shortjournal = {Theor. Comput. Sci.},
  title        = {New bounds for energy complexity of boolean functions},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterized complexity of determinant and permanent.
<em>TCS</em>, <em>845</em>, 50–58. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Every square matrix A = ( a u v ) ∈ C n × n A=(auv)∈Cn×n can be represented as a digraph having n vertices. In the digraph , a block (or 2-connected component) is a maximally connected subdigraph that has no cut-vertex. The determinant and the permanent of a matrix can be calculated in terms of the determinant and the permanent of some specific induced subdigraphs of the blocks in the digraph. Interestingly, these induced subdigraphs are vertex-disjoint and they partition the digraph. Such partitions of the digraph are called the B B -partitions. In this paper, first, we develop an algorithm to find the B B -partitions. Next, we analyze the parameterized complexity of matrix determinant and permanent, where, the parameters are the sizes of blocks and the number of cut-vertices of the digraph. We give a class of combinations of cut-vertices and block sizes for which the parametrized complexities beat the state of art complexities of the determinant and the permanent.},
  archive      = {J_TCS},
  author       = {Ranveer Singh},
  doi          = {10.1016/j.tcs.2020.08.031},
  journal      = {Theoretical Computer Science},
  pages        = {50-58},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameterized complexity of determinant and permanent},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Liar’s domination in unit disk graphs. <em>TCS</em>,
<em>845</em>, 38–49. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study a variant of the minimum dominating set problem known as the minimum liar&#39;s dominating set (MLDS) problem. We prove that the MLDS problem is NP-hard in unit disk graphs. We point out that the approximation guarantee of 11 2 112 for the approximation algorithm for unit disk graphs proposed by Banerjee and Bhore (2019) [11] is not correct and we propose a simple O ( n + m ) O(n+m) time 7.31-factor approximation algorithm , where n and m are the number of vertices and edges, respectively, in the given unit disk graph. Finally, we prove that the MLDS problem admits a polynomial-time approximation scheme.},
  archive      = {J_TCS},
  author       = {Ramesh K. Jallu and Sangram K. Jena and Gautam K. Das},
  doi          = {10.1016/j.tcs.2020.08.029},
  journal      = {Theoretical Computer Science},
  pages        = {38-49},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Liar&#39;s domination in unit disk graphs},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vertex deletion on split graphs: Beyond 4-hitting set.
<em>TCS</em>, <em>845</em>, 21–37. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertex deletion problems on graphs involve finding a set of minimum number of vertices whose deletion results in a graph with some specific property. In a recent study on vertex deletion problems on split graphs, it was shown that transforming a split graph to a block graph or a threshold graph using minimum number of vertex deletions is NP -hard. We call the decision version of these problems as Split to Block Vertex Deletion ( SBVD ) and Split to Threshold Vertex Deletion ( STVD ), respectively. In this paper, we study the parameterized complexity of these problems with the number of vertex deletions, k , as a parameter. These problems are implicit 4- Hitting Set and thus admit an algorithm with running time O ⋆ ( 3.0755 k ) O⋆(3.0755k) , a kernel with O ( k 3 ) O(k3) vertices, and a 4-approximation algorithm. In this paper, we exploit the structural properties of the concerned graph classes and obtain a kernel for SBVD with O ( k 2 ) O(k2) vertices and FPT algorithms for SBVD and STVD with running times O ⋆ ( 2.3028 k ) O⋆(2.3028k) and O ⋆ ( 2.7913 k ) O⋆(2.7913k) , respectively. We further give improved approximation algorithms for SBVD and STVD .},
  archive      = {J_TCS},
  author       = {Pratibha Choudhary and Pallavi Jain and R. Krithika and Vibha Sahlot},
  doi          = {10.1016/j.tcs.2020.08.028},
  journal      = {Theoretical Computer Science},
  pages        = {21-37},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Vertex deletion on split graphs: Beyond 4-hitting set},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NextPriorityConcept: A new and generic algorithm computing
concepts from complex and heterogeneous data. <em>TCS</em>,
<em>845</em>, 1–20. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we present a new data type agnostic algorithm calculating a concept lattice from heterogeneous and complex data. Our NextPriorityConcept algorithm is first introduced and proved in the binary case as an extension of Bordat&#39;s algorithm with the notion of strategies to select only some predecessors of each concept, avoiding the generation of unreasonably large lattices. The algorithm is then extended to any type of data in a generic way. It is inspired by the pattern structure theory, where data are locally described by predicates independent of their types, allowing the management of heterogeneous data .},
  archive      = {J_TCS},
  author       = {Christophe Demko and Karell Bertet and Cyril Faucher and Jean-François Viaud and Sergei O. Kuznetsov},
  doi          = {10.1016/j.tcs.2020.08.026},
  journal      = {Theoretical Computer Science},
  pages        = {1-20},
  shortjournal = {Theor. Comput. Sci.},
  title        = {NextPriorityConcept: A new and generic algorithm computing concepts from complex and heterogeneous data},
  volume       = {845},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing the hull number in δ-convexity. <em>TCS</em>,
<em>844</em>, 217–226. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph G , a set S ⊆ V ( G ) S⊆V(G) is Δ-convex if there is no vertex u ∈ V ( G ) ∖ S u∈V(G)∖S forming a triangle with two vertices of S . The Δ-convex hull of S is the minimum Δ-convex set containing S . The Δ-hull number of a graph G is the cardinality of a minimum set such that its Δ-convex hull is V ( G ) V(G) . We show that the problem of deciding whether the Δ-hull number of a general graph is at most k is an NP -complete problem and present polynomial-time algorithms for computing the Δ-hull number of some graph classes including chordal graphs , dually chordal graphs , and cographs.},
  archive      = {J_TCS},
  author       = {Bijo S. Anand and Arun Anil and Manoj Changat and Mitre C. Dourado and Sabeer S. Ramla},
  doi          = {10.1016/j.tcs.2020.08.024},
  journal      = {Theoretical Computer Science},
  pages        = {217-226},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing the hull number in Δ-convexity},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online presentations of finitely generated structures.
<em>TCS</em>, <em>844</em>, 195–216. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We systematically investigate into the online content of finitely generated structures. The online content of a potentially infinite algebraic or combinatorial structure is perhaps best reflected by its PR-degrees (to be defined). We confirm a natural conjecture by showing that the PR-degrees of a finitely generated structure must be dense. Remarkably, we show that PR-degrees of an f.g. structure do not have to be upwards dense. As an application of our techniques, we refute a natural conjecture about honestly generated structures (to be stated).},
  archive      = {J_TCS},
  author       = {Nikolay Bazhenov and Iskander Kalimullin and Alexander Melnikov and Keng Meng Ng},
  doi          = {10.1016/j.tcs.2020.08.021},
  journal      = {Theoretical Computer Science},
  pages        = {195-216},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online presentations of finitely generated structures},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving hard stable matching problems involving groups of
similar agents. <em>TCS</em>, <em>844</em>, 171–194. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many important stable matching problems are known to be NP -hard, even when strong restrictions are placed on the input. In this paper we seek to identify structural properties of instances of stable matching problems which will allow us to design efficient algorithms using elementary techniques. We focus on the setting in which all agents involved in some matching problem can be partitioned into k different types , where the type of an agent determines his or her preferences, and agents have preferences over types (which may be refined by more detailed preferences within a single type). This situation would arise in practice if agents form preferences solely based on some small collection of agents&#39; attributes. We also consider a generalisation in which each agent may consider some small collection of other agents to be exceptional, and rank these in a way that is not consistent with their types; this could happen in practice if agents have prior contact with a small number of candidates. We show that (for the case without exceptions), several well-studied NP -hard stable matching problems including Max SMTI (that of finding the maximum cardinality stable matching in an instance of stable marriage with ties and incomplete lists) belong to the parameterised complexity class FPT when parameterised by the number of different types of agents needed to describe the instance. For Max SMTI this tractability result can be extended to the setting in which each agent promotes at most one “exceptional” candidate to the top of his/her list (when preferences within types are not refined), but the problem remains NP -hard if preference lists can contain two or more exceptions and the exceptional candidates can be placed anywhere in the preference lists, even if the number of types is bounded by a constant.},
  archive      = {J_TCS},
  author       = {Kitty Meeks and Baharak Rastegari},
  doi          = {10.1016/j.tcs.2020.08.017},
  journal      = {Theoretical Computer Science},
  pages        = {171-194},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Solving hard stable matching problems involving groups of similar agents},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural parameters for scheduling with assignment
restrictions. <em>TCS</em>, <em>844</em>, 154–170. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider scheduling on identical and unrelated parallel machines with job assignment restrictions. These problems are NP-hard and they do not admit polynomial time approximation algorithms with approximation ratios smaller than 1.5 unless P=NP. However, if we impose limitations on the set of machines that can process a job, the problem sometimes becomes easier in the sense that algorithms with approximation ratios better than 1.5 exist. We introduce a graph framework based on the assignment restrictions and study the computational complexity of the scheduling problem with respect to structural properties of the resulting graphs, in particular, their tree- and cliquewidth. We identify cases that admit polynomial time approximation schemes or FPT algorithms generalizing and extending previous results in this area.},
  archive      = {J_TCS},
  author       = {Klaus Jansen and Marten Maack and Roberto Solis-Oba},
  doi          = {10.1016/j.tcs.2020.08.015},
  journal      = {Theoretical Computer Science},
  pages        = {154-170},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Structural parameters for scheduling with assignment restrictions},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analyzing fractional horn constraint systems. <em>TCS</em>,
<em>844</em>, 142–153. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study linear constraint systems in which each constraint is a fractional Horn constraint . A constraint is fractional Horn, if it can be written in the form: ∑ i = 1 n a i ⋅ x i ≥ c ∑i=1nai⋅xi≥c , where each a i ai is integral, c is integral, at most one of the a i ai s is positive, and all negative a i ai s are equal to −1. A conjunction of fractional Horn constraints is called a Fractional Horn Constraint Systems (FHS). FHSs generalize a number of specialized constraint systems such as Difference Constraint Systems (DCS) and Horn Constraint Systems (HCS). We know that the problem of checking lattice point feasibility in DCSs and HCSs is in P . In contrast, we show that the problem of checking lattice point feasibility in FHSs is NP-complete . We then study a sub-class of fractional Horn constraint systems called Binary Fractional Horn Constraint Systems (BFHS). In a BFHS, each constraint has at most two non-zero coefficients. In this case, we show that the problem of checking integer feasibility is in P . Furthermore, we establish several properties of the least integer point and the least linear point of a BFHS, if they exist.},
  archive      = {J_TCS},
  author       = {Piotr Wojciechowski and R. Chandrasekaran and K. Subramani},
  doi          = {10.1016/j.tcs.2020.08.012},
  journal      = {Theoretical Computer Science},
  pages        = {142-153},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Analyzing fractional horn constraint systems},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational aspects of the inverse single facility
location problem on trees under lk-norm. <em>TCS</em>, <em>844</em>,
133–141. (<a href="https://doi.org/10.1016/j.tcs.2020.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider in this paper the inverse versions of the two popular problems in location theory, say the 1-median and the 1-center problems on trees. The cost for modifying vertex weights is measured under l k lk -norm for a positive integer k and hence the cost function is nonlinear. For the inverse 1-median problem, we develop a linear time algorithm based on the optimal solution of the induced unconstrained problem. For the inverse 1-center problem, we prove that the problem can be decomposed into linearly many subproblems and the objective function in each subproblem is piecewise-convex. Furthermore, we also discuss an O ( n log ⁡ n ) O(nlog⁡n) time algorithm for the inverse 1-center problem under l 2 l2 -norm based on the convexity of the cost function of each subproblem.},
  archive      = {J_TCS},
  author       = {Le Huynh My Van and Kien Trung Nguyen and Nguyen Thanh Hung},
  doi          = {10.1016/j.tcs.2020.08.010},
  journal      = {Theoretical Computer Science},
  pages        = {133-141},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computational aspects of the inverse single facility location problem on trees under lk-norm},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extensions of dynamic programming for multi-stage
combinatorial optimization. <em>TCS</em>, <em>844</em>, 106–132. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a dynamic programming framework for an exact multi-stage (lexicographic) combinatorial optimization . Unlike conventional algorithms of dynamic programming that return one optimal solution, two dynamic programming algorithms proposed in this paper are coping with the whole set of optimal solutions or with its essential part. We describe the set of elements for optimization by a labeled directed acyclic graph, which in some sense, is similar to the structure of subproblems of the considered problem. For a given cost function (objective), the first algorithm constructs a subgraph of this graph that describes the whole set of optimal elements or its essential part. This algorithm can be used for multi-stage optimization of elements relative to a sequence of cost functions. The second algorithm counts elements before the optimization and after each optimization step. The considered labeled directed acyclic graph is a kind of circuit. This circuit builds the set of elements for optimization from one-element sets attached to input nodes. It uses the operation of union of sets attached to unifying nodes and functional operations attached to functional nodes. The algorithms for optimization and counting elements are defined for an arbitrary circuit without repetitions in which each element is generated exactly one time. For a considered problem with a known conventional dynamic programming solution algorithm, usually, it is easy to construct a corresponding circuit without repetitions. Once the circuit and cost functions are defined, our framework provides the correctness proofs and detailed time complexity analysis for the proposed algorithms. To make this approach more intuitive, we consider an illustrative example related to the maximum subarray problem. We tested our approach on the following nine combinatorial optimization problems : matrix chain multiplication, global sequence alignment , optimal paths in directed graphs , binary search trees , optimal bitonic tour, segmented least squares , convex polygon triangulation, one-dimensional clustering, and line breaking (text justification). We consider the last three problems in detail: construct a circuit without repetitions, describe at least two cost functions, evaluate a number of operations and time required by the algorithms, discuss an example, and consider the results of computer experiments with randomly generated instances of the problem.},
  archive      = {J_TCS},
  author       = {Michal Mankowski and Mikhail Moshkov},
  doi          = {10.1016/j.tcs.2020.08.009},
  journal      = {Theoretical Computer Science},
  pages        = {106-132},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Extensions of dynamic programming for multi-stage combinatorial optimization},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the parameterized complexity of 2-partitions.
<em>TCS</em>, <em>844</em>, 97–105. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give an FPT algorithm for deciding whether the vertex set of a digraph D can be partitioned into two disjoint sets V1,V2 such that the digraph D[V1] induced by V1 has a vertex that can reach all other vertices by directed paths, the digraph D[V2] has no vertex of in-degree zero and |Vi|≥ki , where k1,k2 are part of the input. This settles an open problem from [1] , [4] .},
  archive      = {J_TCS},
  author       = {J.B. Andersen and J. Bang-Jensen and A. Yeo},
  doi          = {10.1016/j.tcs.2020.08.008},
  journal      = {Theoretical Computer Science},
  pages        = {97-105},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the parameterized complexity of 2-partitions},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust digital signature revisited. <em>TCS</em>,
<em>844</em>, 87–96. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In CT-RSA 2019, Geraud, Naccache and Rosie introduced the notion of robustness (ROB) for digital signature schemes to guarantee that the same signature and message pair cannot be valid under two different public keys . Their definition of complete ROB (CROB) can even support the ROB when the keys are malignantly generated. Motivated by the fact that the signature and the key could be illegally produced in some circumstances, we extended the ROB security one step further to guarantee that one valid signature cannot be modified to another valid signature under a different public key, which we call extreme robustness (EXROB). After analysing the relations between the EXROB security and existing ROB related definitions, we describe generic constructions to convert any digital signature scheme that is unforgeable into an EXROB secure one. Our hash-then-sign construction is very efficient, which only adds one hash calculation to the underlying digital signature scheme and does not increase the size of the signature generated by the underlying digital signature scheme.},
  archive      = {J_TCS},
  author       = {Hui Cui and Baodong Qin and Willy Susilo and Surya Nepal},
  doi          = {10.1016/j.tcs.2020.08.005},
  journal      = {Theoretical Computer Science},
  pages        = {87-96},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Robust digital signature revisited},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The 4-set tree connectivity of (n,k)-star networks.
<em>TCS</em>, <em>844</em>, 81–86. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tree connectivity, as a generalization of the traditional connectivity, can serve to measure the capability of connection for vertices in a network. The ( n , k ) (n,k) -star graph S n , k Sn,k can be used to model the topological structure of a large-scale parallel processing system . We show in this article that the 4-set tree connectivity of S n , k Sn,k is n − 2 n−2 , that is, there exist ( n − 2 ) (n−2) internally disjoint trees connecting x , y , z x,y,z and w in S n , k Sn,k for four arbitrary vertices x , y , z x,y,z and w of S n , k Sn,k . Two known results about the 3-set tree connectivity of star graphs and ( n , k ) (n,k) -star graphs are immediate consequences of our result.},
  archive      = {J_TCS},
  author       = {Chunfang Li and Shangwei Lin and Shengjia Li},
  doi          = {10.1016/j.tcs.2020.08.004},
  journal      = {Theoretical Computer Science},
  pages        = {81-86},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The 4-set tree connectivity of (n,k)-star networks},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint string complexity for markov sources: Small data
matters. <em>TCS</em>, <em>844</em>, 46–80. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {String complexity is defined as the cardinality of a set of all distinct words (factors) of a given string. For two strings, we introduce the joint string complexity as the cardinality of a set of words that are common to both strings. String complexity finds a number of applications from capturing the richness of a language to finding similarities between two genome sequences. In this paper we analyze the joint string complexity when both strings are generated by Markov sources. We prove that the joint string complexity grows linearly (in terms of the string lengths) when both sources are statistically indistinguishable and sublinearly when sources are statistically distinguishable. Precise analysis of the joint string complexity requires subtle singularity analysis and saddle point method over infinity many saddle points leading to novel oscillatory phenomena with single and double periodicities. To overcome these challenges, we apply analytic techniques such as multivariate generating functions, multivariate depoissonization and Mellin transform , spectral matrix analysis, and complex asymptotic methods .},
  archive      = {J_TCS},
  author       = {Philippe Jacquet and Dimitris Milioris and Wojciech Szpankowski},
  doi          = {10.1016/j.tcs.2020.08.002},
  journal      = {Theoretical Computer Science},
  pages        = {46-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Joint string complexity for markov sources: Small data matters},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equitable improper choosability of graphs. <em>TCS</em>,
<em>844</em>, 34–45. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let R R be an arbitrary class of graphs and let L be a list assignment for a graph G . A colouring of G such that every vertex receives a colour from its list and the subgraph induced by vertices coloured with one colour belongs to R R is called the ( L , R ) (L,R) -colouring of G . For k ∈ N k∈N and a k -uniform list assignment L , a graph G is equitably ( L , R ) (L,R) -colourable if there is an ( L , R ) (L,R) -colouring of G such that the size of any colour class does not exceed ⌈ | V ( G ) | / k ⌉ ⌈|V(G)|/k⌉ . An equitable ( L , R ) (L,R) -colouring is a generalization of an equitable list colouring, that was introduced by Kostochka at al. This notion also generalizes an equitable list arboricity that was presented by Zhang for the first time. Let D d Dd denote the class of d -degenerated graphs. We give a polynomial-time algorithm that for a given ( k , d ) (k,d) -partition of G with a t -uniform list assignment L , t ≥ k t≥k , returns its equitable ( L , D d − 1 ) (L,Dd−1) -colouring. In addition, we show the application of the main theorem to induced hereditary classes of graphs, as well as we show that 3-dimensional grids are equitable ( L , D 1 ) (L,D1) -colourable for any k -uniform list assignment L where k ≥ 3 k≥3 .},
  archive      = {J_TCS},
  author       = {Ewa Drgas-Burchardt and Hanna Furmańczyk and Elżbieta Sidorowicz},
  doi          = {10.1016/j.tcs.2020.08.001},
  journal      = {Theoretical Computer Science},
  pages        = {34-45},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Equitable improper choosability of graphs},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximation algorithm for the k-prize-collecting
multicut on a tree problem. <em>TCS</em>, <em>844</em>, 26–33. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the k -prize-collecting multicut on a tree ( k -PCM( T )) problem. In this problem, we are given an undirected tree T = ( V , E ) T=(V,E) , a set of m distinct pairs of vertices P = { ( s 1 , t 1 ) , … , ( s m , t m ) } P={(s1,t1),…,(sm,tm)} and a parameter k with k ≤ m k≤m . Every edge in E has a nonnegative cost c e ce . Every pair ( s i , t i ) (si,ti) in P has a nonnegative penalty cost π i πi . Our goal is to find a multicut M that separates at least k pairs in P such that the total cost, including the edge cost of the multicut M and the penalty cost of the pairs not separated by M , is minimized. This problem generalizes the well-known multicut on a tree problem . Our main work is to present a ( 4 + ε ) (4+ε) -approximation algorithm for the k -PCM( T ) problem via the methods of primal-dual and Lagrangean relaxation, where ε is any fixed positive number.},
  archive      = {J_TCS},
  author       = {Xin Hou and Wen Liu and Bo Hou},
  doi          = {10.1016/j.tcs.2020.07.014},
  journal      = {Theoretical Computer Science},
  pages        = {26-33},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An approximation algorithm for the k-prize-collecting multicut on a tree problem},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Graph orientation with splits. <em>TCS</em>, <em>844</em>,
16–25. (<a href="https://doi.org/10.1016/j.tcs.2020.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Minimum Maximum Outdegree Problem (MMO) is to assign a direction to every edge in an input undirected, edge-weighted graph so that the maximum weighted outdegree taken over all vertices becomes as small as possible. In this paper, we introduce a new variant of MMO called the p-Split Minimum Maximum Outdegree Problem ( p -Split-MMO) in which one is allowed to perform a sequence of p split operations on the vertices before orienting the edges, for some specified non-negative integer p , and study its computational complexity .},
  archive      = {J_TCS},
  author       = {Yuichi Asahiro and Jesper Jansson and Eiji Miyano and Hesam Nikpey and Hirotaka Ono},
  doi          = {10.1016/j.tcs.2020.07.013},
  journal      = {Theoretical Computer Science},
  pages        = {16-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Graph orientation with splits},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tracking routes in communication networks. <em>TCS</em>,
<em>844</em>, 1–15. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum tracking set problem is an optimization problem that deals with monitoring communication paths that can be used for exchanging point-to-point messages using as few tracking devices as possible. More precisely, a tracking set of a given graph G and a set of source-destination pairs of vertices is a subset T of vertices of G such that the vertices in T traversed by any source-destination shortest path P uniquely identify P . The minimum tracking set problem has been introduced in Banik et al., CIAC (2017) [1] for the case of a single source-destination pair. There, the authors show that the problem is APX-hard and that it can be 2-approximated for the class of planar graphs , even though no hardness result is known for this case. In this paper we focus on the case of multiple source-destination pairs and we present the first O ˜ ( n ) O˜(n) -approximation algorithm for general graphs. Moreover, we prove that the problem remains NP-hard even for cubic planar graphs and all pairs S × D S×D , where S and D are the sets of sources and destinations, respectively. Finally, for the case of a single source-destination pair, we design an (exact) FPT algorithm w.r.t. the maximum number of vertices at the same distance from the source.},
  archive      = {J_TCS},
  author       = {Davide Bilò and Luciano Gualà and Stefano Leucci and Guido Proietti},
  doi          = {10.1016/j.tcs.2020.07.012},
  journal      = {Theoretical Computer Science},
  pages        = {1-15},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tracking routes in communication networks},
  volume       = {844},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Editorial. <em>TCS</em>, <em>843</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(20)30576-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(20)30576-4},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Universal insertion grammars of size two. <em>TCS</em>,
<em>843</em>, 153–163. (<a
href="https://doi.org/10.1016/j.tcs.2020.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show that pure insertion grammars of size 2 ( i.e. , inserting two symbols in a left and right context, each consisting of two symbols) can characterize all recursively enumerable languages . This is achieved by either applying an inverse morphism and a weak coding, or a left (right) quotient with a regular L O C ( 2 ) LOC(2) language, or an intersection with a L O C ( 2 ) LOC(2) language and a weak coding. The obtained results improve the descriptional complexity of insertion grammars and complete the picture of known results on insertion-deletion systems that are motivated from the DNA computing area.},
  archive      = {J_TCS},
  author       = {Sergey Verlan and Henning Fernau and Lakshmanan Kuppusamy},
  doi          = {10.1016/j.tcs.2020.09.002},
  journal      = {Theoretical Computer Science},
  pages        = {153-163},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Universal insertion grammars of size two},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quaternion-valued recurrent projection neural networks on
unit quaternions. <em>TCS</em>, <em>843</em>, 136–152. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypercomplex-valued neural networks , including quaternion-valued neural networks , can treat multi-dimensional data as a single entity. In this paper, we present the quaternion-valued recurrent projection neural networks (QRPNNs). Briefly, the QRPNNs are obtained by combining the non-local projection learning with the quaternion-valued recurrent correlation neural network (QRCNNs). We show that the QRPNNs overcome the cross-talk problem of the QRCNNs. Thus, they are appropriate to implement associative memories . Furthermore, computational experiments reveal that the QRPNNs exhibit greater storage capacity and noise tolerance than their corresponding QRCNNs.},
  archive      = {J_TCS},
  author       = {Marcos Eduardo Valle and Rodolfo Anibal Lobo},
  doi          = {10.1016/j.tcs.2020.08.033},
  journal      = {Theoretical Computer Science},
  pages        = {136-152},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Quaternion-valued recurrent projection neural networks on unit quaternions},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Synthesis of quantifier-free DNF sentences from
inconsistent samples of strings with EF games and SAT. <em>TCS</em>,
<em>843</em>, 115–135. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a method to extract knowledge in terms of quantifier-free sentences in disjunctive normal form from noisy samples of classified strings. We show that the problem to find such a sentence is NP-complete, and our approach for solving it is based on a reduction to the Boolean satisfiability problem . Moreover, our method bounds the number of disjuncts and the maximum number of literals per clause since sentences with few clauses and few literals per clause are easier to interpret. As the logic we are considering defines exactly the class of locally threshold testable (LTT) languages, our results can be useful in grammatical inference when the goal is to find a model of an LTT language from a sample of strings. We also use results of the Ehrenfeucht–Fraïssé game over strings in order to handle consistent and inconsistent samples of strings.},
  archive      = {J_TCS},
  author       = {Thiago Alves Rocha and Ana Teresa Martins and Francicleber Martins Ferreira},
  doi          = {10.1016/j.tcs.2020.08.032},
  journal      = {Theoretical Computer Science},
  pages        = {115-135},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Synthesis of quantifier-free DNF sentences from inconsistent samples of strings with EF games and SAT},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Verifying polymer reaction networks using bisimulation.
<em>TCS</em>, <em>843</em>, 84–114. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Chemical Reaction Network model has been proposed as a programming language for molecular programming. Methods to implement arbitrary CRNs using DNA strand displacement circuits have been investigated, as have methods to prove the correctness of those or other implementations. However, the stochastic Chemical Reaction Network model is provably not deterministically Turing-universal, that is, it is impossible to create a stochastic CRN where a given output molecule is produced if and only if an arbitrary Turing machine accepts. A DNA stack machine that can simulate arbitrary Turing machines with minimal slowdown deterministically has been proposed, but it uses unbounded polymers that cannot be modeled as a Chemical Reaction Network. We propose an extended version of a Chemical Reaction Network that models unbounded linear polymers made from a finite number of monomers. This Polymer Reaction Network model covers the DNA stack machine, as well as copy-tolerant Turing machines and some examples from biochemistry. We adapt the bisimulation method of verifying DNA implementations of Chemical Reaction Networks to our model, and use it to prove the correctness of the DNA stack machine implementation. We define a subclass of single-locus Polymer Reaction Networks and show that any member of that class can be bisimulated by a network using only four primitives, suggesting a method of DNA implementation. Finally, we prove that deciding whether an implementation is a bisimulation is Π 2 0 Π20 -complete, and thus undecidable in the general case, although it is tractable in many special cases of interest. We hope that the ability to model and verify implementations of Polymer Reaction Networks will aid in the rational design of molecular systems .},
  archive      = {J_TCS},
  author       = {Robert F. Johnson and Erik Winfree},
  doi          = {10.1016/j.tcs.2020.08.007},
  journal      = {Theoretical Computer Science},
  pages        = {84-114},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Verifying polymer reaction networks using bisimulation},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-free cell-like p systems with multiple
promoters/inhibitors. <em>TCS</em>, <em>843</em>, 73–83. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell-like P systems with promoters/inhibitors (PIC-P systems) are a class of distributed and parallel computing models inspired by the function of regulating biochemical reactions by enzymes in biological cells. In PIC-P systems, each evolution rule (rule for short) can be associated with one promoter/inhibitor which helps control the evolution process of objects. In this work, we propose a novel variant of PIC-P systems, called time-free cell-like P systems with multi-promoters/inhibitors (time-free MPIC-P systems for short). In such systems, each rule can be associated with multiple promoters/inhibitors, and the execution time of each rule is extended from one time unit to a random number of time units. These two characters make the time-free MPIC-P systems closer to biological cells. We also investigate the computational power of time-free MPIC-P systems. As results, it is achieved by simulating the matrix grammar that such systems can generate the set of lengths of recursively enumerable languages , that is, Turing universality can be achieved. This indicates that the time-free working mode will not reduce the computational power of PIC-P systems, by using multiple promoters/inhibitors.},
  archive      = {J_TCS},
  author       = {Yuzhen Zhao and Xiyu Liu and Minghe Sun and Jianhua Qu and Yuanjie Zheng},
  doi          = {10.1016/j.tcs.2020.07.018},
  journal      = {Theoretical Computer Science},
  pages        = {73-83},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Time-free cell-like p systems with multiple promoters/inhibitors},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Running time analysis of the (1+1)-EA for robust linear
optimization. <em>TCS</em>, <em>843</em>, 57–72. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) have found many successful real-world applications, where the optimization problems are often subject to a wide range of uncertainties. To understand the practical behaviors of EAs theoretically, there are a series of efforts devoted to analyzing the running time of EAs for optimization under uncertainties. Existing studies mainly focus on noisy and dynamic optimization , while another common type of uncertain optimization, i.e., robust optimization , has been rarely touched. In this paper, we analyze the expected running time of the (1+1)-EA solving robust linear optimization problems (i.e., linear problems under robust scenarios) with a cardinality constraint k . Two common robust scenarios, i.e., deletion-robust and worst-case, are considered. Particularly, we derive tight ranges of the robust parameter d or budget k allowing the (1+1)-EA to find an optimal solution in polynomial running time, which disclose the potential of EAs for robust optimization .},
  archive      = {J_TCS},
  author       = {Chao Bian and Chao Qian and Ke Tang and Yang Yu},
  doi          = {10.1016/j.tcs.2020.07.001},
  journal      = {Theoretical Computer Science},
  pages        = {57-72},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Running time analysis of the (1+1)-EA for robust linear optimization},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamical behavior of additive cellular automata over finite
abelian groups. <em>TCS</em>, <em>843</em>, 45–56. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the dynamical behavior of additive D -dimensional ( D ≥ 1 ) D≥1) cellular automata where the alphabet is any finite abelian group . This class of discrete time dynamical systems is a generalization of the systems extensively studied by many authors among which one may list [38] , [44] , [41] . Among our major contributions, there is the proof that topologically transitive additive D -dimensional cellular automata over a finite abelian group are ergodic. This result represents a solid bridge between the world of measure theory and that of topology and greatly extends previous results obtained in [12] , [44] for linear CA over Z / m Z Z/mZ , i.e., additive CA in which the alphabet is the cyclic group Z / m Z Z/mZ and the local rules are linear combinations with coefficients in Z / m Z Z/mZ . In our scenario, the alphabet is any finite abelian group and the global rule is any additive map. This class of CA strictly contains the class of linear CA over ( Z / m Z ) n (Z/mZ)n , i.e., with the local rule defined by n × n n×n matrices with elements in Z / m Z Z/mZ which, in turn, strictly contains the class of linear CA over Z / m Z Z/mZ . In order to further emphasize that finite abelian groups are more expressive than Z / m Z Z/mZ we prove that, contrary to what happens in Z / m Z Z/mZ , there exist additive CA over suitable finite abelian groups which are roots (with arbitrarily large indices) of the shift map. As a relevant consequence of our results, we have that, for additive D -dimensional CA over a finite abelian group, ergodic mixing, weak ergodic mixing, ergodicity , topological mixing, weak topological mixing, topological total transitivity and topological transitivity are all equivalent properties. As a corollary, we see that invertible transitive additive CA are isomorphic to Bernoulli shifts . Furthermore, we prove that surjectivity implies openness for additive D -dimensional CA over a finite abelian group. Hence, we get that topological transitivity is equivalent to the well-known Devaney notion of chaos when D = 1 D=1 . Moreover, we provide a first characterization of strong transitivity for additive CA which we suspect to be true also for the general case.},
  archive      = {J_TCS},
  author       = {Alberto Dennunzio and Enrico Formenti and Darij Grinberg and Luciano Margara},
  doi          = {10.1016/j.tcs.2020.06.021},
  journal      = {Theoretical Computer Science},
  pages        = {45-56},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dynamical behavior of additive cellular automata over finite abelian groups},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Expansive automata networks. <em>TCS</em>, <em>843</em>,
25–44. (<a href="https://doi.org/10.1016/j.tcs.2020.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Automata Network is a map f : Q n → Q n f:Qn→Qn where Q is a finite alphabet. It can be viewed as a network of n entities, each holding a state from Q , and evolving according to a deterministic synchronous update rule in such a way that each entity only depends on its neighbors in the network&#39;s graph, called interaction graph. In this work we introduce the following property called expansivity: the observation of the sequence of states at any given node is sufficient to determine the initial configuration of the whole network. A major trend in automata network theory is to understand how the interaction graph affects dynamical properties of f . Our first result is a characterization of interaction graphs that allow expansivity. Moreover, we show that this property is generic among linear automata networks over such graphs with large enough alphabet. We show however that the situation is more complex when the alphabet is fixed independently of the size of the interaction graph: no alphabet is sufficient to obtain expansivity on all admissible graphs, and only non-linear solutions exist in some cases. Besides, we show striking differences between the linear and the general non-linear case, in particular we prove that deciding expansivity is PSPACE-complete in the general case, while it can be done in polynomial time in the linear case. Finally, we consider a stronger version of expansivity where we ask to determine the initial configuration from any large enough observation of the system. We show that it can be achieved for any number of nodes and naturally gives rise to maximum distance separable codes.},
  archive      = {J_TCS},
  author       = {Florian Bridoux and Maximilien Gadouleau and Guillaume Theyssier},
  doi          = {10.1016/j.tcs.2020.06.019},
  journal      = {Theoretical Computer Science},
  pages        = {25-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Expansive automata networks},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the emergence of regularities on one-dimensional
decreasing sandpiles. <em>TCS</em>, <em>843</em>, 1–24. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decreasing sandpiles model the dynamics of configurations where each position i ∈ N i∈N contains a finite number of stacked grains h i hi , such that h i ≥ h i + 1 hi≥hi+1 (decrease property). Grains move according to a decreasing local rule R = ( r 1 , r 2 , … , r p ) R=(r1,r2,…,rp) such that r j ≥ r j + 1 rj≥rj+1 , meaning that r j rj grains move from columns i to i + j i+j for all 1 ≤ j ≤ p 1≤j≤p , if it does not contradict the decrease property. We are interested in the fixed point reached starting from a finite number of grains on a unique column. In [21] , we proved the emergence of wave patterns periodically covering fixed points, for rules of the form ( 1 , … , 1 ) (1,…,1) (Kadanoff sandpile models). The present work is a significative extension: for large classes of decreasing sandpile model instances, we prove the emergence of patterns of various shapes periodically covering fixed points. We introduce new automata to analyze their asymptotic structure, and use the least action principle. The difficulty of understanding the behavior of sandpile models, despite the simplicity of the rules, is what makes the problem challenging.},
  archive      = {J_TCS},
  author       = {Kévin Perrot and Éric Rémila},
  doi          = {10.1016/j.tcs.2020.06.018},
  journal      = {Theoretical Computer Science},
  pages        = {1-24},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the emergence of regularities on one-dimensional decreasing sandpiles},
  volume       = {843},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “the orthogonal colouring game” [theor.
Comput. Sci. 795 (2019) 312–325]. <em>TCS</em>, <em>842</em>, 133–135.
(<a href="https://doi.org/10.1016/j.tcs.2019.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lower bound for the number of isomorphism classes of graphs admitting a strictly matched involution given in Theorem 15 of our paper on the orthogonal colouring game [1] is incorrect. Here, we prove a weaker lower bound.},
  archive      = {J_TCS},
  author       = {Stephan Dominique Andres and Melissa Huggan and Fionn Mc Inerney and Richard J. Nowakowski},
  doi          = {10.1016/j.tcs.2019.12.007},
  journal      = {Theoretical Computer Science},
  pages        = {133-135},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Corrigendum to “The orthogonal colouring game” [Theor. comput. sci. 795 (2019) 312–325]},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>842</em>, 132. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  doi          = {10.1016/j.tcs.2020.07.017},
  journal      = {Theoretical Computer Science},
  pages        = {132},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). FUN editorial. <em>TCS</em>, <em>842</em>, 131. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Hiro Ito and Stefano Leonardi and Linda Pagli and Giuseppe Prencipe},
  doi          = {10.1016/j.tcs.2020.06.026},
  journal      = {Theoretical Computer Science},
  pages        = {131},
  shortjournal = {Theor. Comput. Sci.},
  title        = {FUN editorial},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>842</em>, 130. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Faith Ellen and Luís Rodrigues},
  doi          = {10.1016/j.tcs.2020.03.019},
  journal      = {Theoretical Computer Science},
  pages        = {130},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general method for decomposing self-intersecting polygon
to normal based on self-intersection points. <em>TCS</em>, <em>842</em>,
118–129. (<a href="https://doi.org/10.1016/j.tcs.2020.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Checking whether polygons are self-intersecting or not is an important step for GIS projects before they are published to the web. Automatically converting self-intersection polygons into normal ones is practically useful, especially there are numerous polygons need to be processed. Based on the relationships of self-intersection points, this paper presents an algorithm to convert a complex self-intersection polygon to a normal one which has no self-intersection part. Furthermore, using the relationships of the repeat points (original self-intersection points) of the decomposed polygon, the result of the only simple polygon can be split into independent sub-polygons bounded by those points. The algorithm is easy to understand and with high efficiency because we consider only the self-intersection point relationships of the polygon, and we do not pay attention to the edges and their directions. A point structure in which the relationships of the self-intersection points are defined is used in the algorithm.},
  archive      = {J_TCS},
  author       = {Yong Cui and Qian Liu and Guo Chen and Hujun Zhang},
  doi          = {10.1016/j.tcs.2020.07.040},
  journal      = {Theoretical Computer Science},
  pages        = {118-129},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A general method for decomposing self-intersecting polygon to normal based on self-intersection points},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quantum algorithm for the multicollision problem.
<em>TCS</em>, <em>842</em>, 100–117. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current paper presents a new quantum algorithm for finding multicollisions, often denoted by ℓ -collisions, where an ℓ -collision for a function is a set of ℓ distinct inputs that are mapped by the function to the same value. In cryptology , it is important to study how many queries are required to find an ℓ -collision for a random function of which domain is larger than its range. However, the problem of finding ℓ -collisions for random functions has not received much attention in the quantum setting. The tight bound of quantum query complexity for finding a 2-collisions of a random function has been revealed to be Θ ( N 1 / 3 ) Θ(N1/3) , where N is the size of the range of the function, but neither the lower nor upper bounds are known for general ℓ -collisions. The paper first integrates the results from existing research to derive several new observations, e.g., ℓ -collisions can be generated only with O ( N 1 / 2 ) O(N1/2) quantum queries for any integer constant ℓ . It then provides a quantum algorithm that finds an ℓ -collision for a random function with the average quantum query complexity of O ( N ( 2 ℓ − 1 − 1 ) / ( 2 ℓ − 1 ) ) O(N(2ℓ−1−1)/(2ℓ−1)) , which matches the tight bound of Θ ( N 1 / 3 ) Θ(N1/3) for ℓ = 2 ℓ=2 and improves upon the known bounds, including the above simple bound of O ( N 1 / 2 ) O(N1/2) . More generally, the algorithm achieves the average quantum query complexity of O ( c N ⋅ N ( 2 ℓ − 1 − 1 ) / ( 2 ℓ − 1 ) ) O(cN⋅N(2ℓ−1−1)/(2ℓ−1)) , and runs over O ˜ ( c N ⋅ N ( 2 ℓ − 1 − 1 ) / ( 2 ℓ − 1 ) ) O˜(cN⋅N(2ℓ−1−1)/(2ℓ−1)) qubits in O ˜ ( c N ⋅ N ( 2 ℓ − 1 − 1 ) / ( 2 ℓ − 1 ) ) O˜(cN⋅N(2ℓ−1−1)/(2ℓ−1)) expected time for a random function F : X → Y F:X→Y such that | X | ≥ ℓ ⋅ | Y | / c N |X|≥ℓ⋅|Y|/cN for any 1 ≤ c N ∈ o ( N 1 / ( 2 ℓ − 1 ) ) 1≤cN∈o(N1/(2ℓ−1)) , where it is assumed that QRAM is available. With the same query complexity, it is actually able to find a multiclaw for random functions, which is harder to find than a multicollision.},
  archive      = {J_TCS},
  author       = {Akinori Hosoyamada and Yu Sasaki and Seiichiro Tani and Keita Xagawa},
  doi          = {10.1016/j.tcs.2020.07.039},
  journal      = {Theoretical Computer Science},
  pages        = {100-117},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Quantum algorithm for the multicollision problem},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating a gray code for prefix normal words in amortized
polylogarithmic time per word. <em>TCS</em>, <em>842</em>, 86–99. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A prefix normal word is a binary word with the property that no substring has more 1s than the prefix of the same length. By proving that the set of prefix normal words is a bubble language, we can exhaustively list all prefix normal words of length n as a combinatorial Gray code, where successive strings differ by at most two swaps or bit flips. This Gray code can be generated in O ( log 2 ⁡ n ) O(log2⁡n) amortized time per word, while the best generation algorithm hitherto has O ( n ) O(n) running time per word. We also present a membership tester for prefix normal words, as well as a novel characterization of bubble languages.},
  archive      = {J_TCS},
  author       = {Péter Burcsi and Gabriele Fici and Zsuzsanna Lipták and Rajeev Raman and Joe Sawada},
  doi          = {10.1016/j.tcs.2020.07.035},
  journal      = {Theoretical Computer Science},
  pages        = {86-99},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Generating a gray code for prefix normal words in amortized polylogarithmic time per word},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A 2O(k)n algorithm for k-cycle in minor-closed graph
families. <em>TCS</em>, <em>842</em>, 74–85. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let C C be a proper minor-closed family of graphs. We present a randomized algorithm that given a graph G ∈ C G∈C with n vertices, finds a simple cycle of size k in G (if exists) in 2 O ( k ) n 2O(k)n time. The algorithm applies to both directed and undirected graphs. In previous linear time algorithms for this problem, the runtime dependence on k is super-exponential. The algorithm can be derandomized yielding a 2 O ( k ) n log ⁡ n 2O(k)nlog⁡n time algorithm.},
  archive      = {J_TCS},
  author       = {Raphael Yuster},
  doi          = {10.1016/j.tcs.2020.07.034},
  journal      = {Theoretical Computer Science},
  pages        = {74-85},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A 2O(k)n algorithm for k-cycle in minor-closed graph families},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). String factorisations with maximum or minimum dimension.
<em>TCS</em>, <em>842</em>, 65–73. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider two problems concerning string factorisation . Specifically given a string w and an integer k find a factorisation of w where each factor has length bounded by k and has the minimum (the F-Min-D problem) or the maximum (the F-Max-D problem) number of different factors. The F-Min-D has been proved to be NP-hard even if k = 2 k=2 in [9] and for this case we provide a 3/2-approximation algorithm. The F-Max-D problem, up to our knowledge has not been considered in the literature. We show that this problem is NP-hard for any k ≥ 3 k≥3 . In view of this we propose a 2-approximation algorithm (for any k ) and an FPT algorithm w.r.t. parameter max ⁡ { k , | Σ | } max⁡{k,|Σ|} .},
  archive      = {J_TCS},
  author       = {A. Monti and B. Sinaimeri},
  doi          = {10.1016/j.tcs.2020.07.029},
  journal      = {Theoretical Computer Science},
  pages        = {65-73},
  shortjournal = {Theor. Comput. Sci.},
  title        = {String factorisations with maximum or minimum dimension},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deterministic normal position transformation and its
applications. <em>TCS</em>, <em>842</em>, 50–64. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of transforming an ideal into normal position. We present a deterministic algorithm (based on linear algebra techniques) that finds a suitable linear change of variables to transform a given zero-dimensional (not necessarily radical) ideal into normal position. The main idea of this algorithm is to achieve this position via a sequence of elementary linear changes; i.e. each change involves only two variables. Furthermore we give complete complexity analysis of all the algorithms described in this paper based on a sharp upper bound for the maximal number of required elementary linear changes in the special case of the bi-variate polynomial ideal. As an application of this investigation, we conclude the paper by giving a sharper complexity bound for computing a primary decomposition for a zero-dimensional ideal.},
  archive      = {J_TCS},
  author       = {Benyamin M.-Alizadeh and Amir Hashemi},
  doi          = {10.1016/j.tcs.2020.07.025},
  journal      = {Theoretical Computer Science},
  pages        = {50-64},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Deterministic normal position transformation and its applications},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Population monotonic allocation schemes for vertex cover
games. <em>TCS</em>, <em>842</em>, 41–49. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For vertex cover games (introduced by Deng et al. (1999) [2] ), we investigate population monotonic allocation schemes (introduced by Sprumont (1990) [11] ). We show that the existence of a population monotonic allocation scheme (PMAS for short) for vertex cover games can be determined efficiently and that a PMAS, if exists, can be constructed accordingly. We also show that integral PMAS-es for vertex cover games can be characterized with stable matchings and be enumerated by employing Gale-Shapley algorithm (introduced by Gale and Shapley (1962) [4] ).},
  archive      = {J_TCS},
  author       = {Han Xiao and Qizhi Fang and Ding-Zhu Du},
  doi          = {10.1016/j.tcs.2020.07.023},
  journal      = {Theoretical Computer Science},
  pages        = {41-49},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Population monotonic allocation schemes for vertex cover games},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Faster balanced clusterings in high dimension. <em>TCS</em>,
<em>842</em>, 28–40. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of constrained clustering has attracted significant attention in the past decades. In this paper, we study the balanced k -center, k -median, and k -means clustering problems where the size of each cluster is constrained by the given lower and upper bounds . The problems are motivated by the applications in processing large-scale data in high dimension . Existing methods often need to compute complicated matchings (or min cost flows) to satisfy the balance constraint, and thus suffer from high complexities especially in high dimension . We develop an effective framework for the three balanced clustering problems to address this issue, and our method is based on a novel spatial partition idea in geometry. For the balanced k -center clustering, we provide a 4-approximation algorithm that improves the existing approximation factors ; for the balanced k -median and k -means clusterings, our algorithms yield constant and ( 1 + ϵ ) (1+ϵ) -approximation factors with any ϵ &gt; 0 ϵ&amp;gt;0 . More importantly, our algorithms achieve linear or nearly linear running times when k is a constant, and significantly improve the existing ones. Our results can be easily extended to metric balanced clusterings and the running times are sub-linear in terms of the complexity of n -point metric.},
  archive      = {J_TCS},
  author       = {Hu Ding},
  doi          = {10.1016/j.tcs.2020.07.022},
  journal      = {Theoretical Computer Science},
  pages        = {28-40},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Faster balanced clusterings in high dimension},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity of the multi-service center problem.
<em>TCS</em>, <em>842</em>, 18–27. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-service center problem is a variant of facility location problems. In the problem, we consider locating p facilities on a graph, each of which provides distinct service required by all vertices. Each vertex incurs the cost determined by the sum of the weighted distances to the p facilities. The aim of the problem is to minimize the maximum cost among all vertices. This problem is known to be NP-hard for general graphs, while it is solvable in polynomial time when p is a fixed constant. In this paper, we give sharp analyses for the complexity of the problem from the viewpoint of graph classes and weights on vertices. We first propose a polynomial-time algorithm for trees when p is a part of input. In contrast, we prove that the problem becomes strongly NP-hard even for cycles. We also show that when vertices are allowed to have negative weights, the problem becomes NP-hard for paths of only three vertices and strongly NP-hard for stars.},
  archive      = {J_TCS},
  author       = {Takehiro Ito and Naonori Kakimura and Yusuke Kobayashi},
  doi          = {10.1016/j.tcs.2020.07.021},
  journal      = {Theoretical Computer Science},
  pages        = {18-27},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity of the multi-service center problem},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple combinatorial auctions with budget constraints.
<em>TCS</em>, <em>842</em>, 6–17. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the efficiency of simple combinatorial auctions for the allocation of a set of items to a set of agents, with private subadditive valuation functions and budget constraints. The class we consider includes all auctions that allocate each item independently to the agent that submits the highest bid for it, and requests a payment that depends on the bids of all agents only for this item. Two well-known examples of this class are the simultaneous first and second price auctions. We focus on the pure equilibria of the induced strategic games, and using the liquid welfare as our efficiency benchmark, we show an upper bound of 2 on the price of anarchy for any auction in this class, as well as a tight corresponding lower bound on the price of stability for all auctions whose payment rules are convex combinations of the bids. This implies a tight bound of 2 on the price of stability of the well-known simultaneous first and second price auctions, which are members of the class. Additionally, we show lower bounds for the whole class, for more complex auctions (like VCG), and for settings where the budgets are assumed to be common knowledge rather than private information.},
  archive      = {J_TCS},
  author       = {Alexandros A. Voudouris},
  doi          = {10.1016/j.tcs.2020.07.019},
  journal      = {Theoretical Computer Science},
  pages        = {6-17},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Simple combinatorial auctions with budget constraints},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Connectivity and super connectivity of the divide-and-swap
cube. <em>TCS</em>, <em>842</em>, 1–5. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The divide-and-swap cube network is a new hypercube variant network proposed recently. Compared to hypercube , it keeps the same number of vertices and the same asymptotic performances for fundamental algorithms while reducing the network cost. Connectivity and super connectivity are important indices to measure the reliability of networks. In this work, we get the connectivity and super connectivity of divide-and-swap cube network.},
  archive      = {J_TCS},
  author       = {Wantao Ning},
  doi          = {10.1016/j.tcs.2020.06.017},
  journal      = {Theoretical Computer Science},
  pages        = {1-5},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Connectivity and super connectivity of the divide-and-swap cube},
  volume       = {842},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pattern-avoiding inversion sequences and open partition
diagrams. <em>TCS</em>, <em>841</em>, 186–197. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using the generating tree technique and the obstinate kernel method , Kim and Lin confirmed a conjecture due to Martinez and Savage which asserts that inversion sequences e = ( e 1 , e 2 , … , e n ) e=(e1,e2,…,en) containing no three indices i i&amp;lt;j&amp;lt;k such that e i ≥ e j ei≥ej , e j ≥ e k ej≥ek and e i &gt; e k ei&amp;gt;ek are counted by Baxter numbers. In this paper, we provide a bijective proof of this conjecture via an intermediate structure of open partition diagrams, in answer to a problem posed by Beaton-Bouvel-Guerrini-Rinaldi. Moreover, we show that two new classes of pattern-avoiding inversion sequences are also counted by Baxter numbers.},
  archive      = {J_TCS},
  author       = {Sherry H.F. Yan and Yao Yu},
  doi          = {10.1016/j.tcs.2020.07.011},
  journal      = {Theoretical Computer Science},
  pages        = {186-197},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Pattern-avoiding inversion sequences and open partition diagrams},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian generalized network design. <em>TCS</em>,
<em>841</em>, 167–185. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study network coordination problems, as captured by the setting of generalized network design (Emek et al., STOC 2018 [18] ), in the face of uncertainty resulting from partial information that the network users hold regarding the actions of their peers. This uncertainty is formalized using Alon et al.&#39;s Bayesian ignorance framework (TCS 2012 [1] ). While the approach of Alon et al. is purely combinatorial, the current paper takes into account computational considerations: Our main technical contribution is the development of (strongly) polynomial time algorithms for local decision making in the face of Bayesian uncertainty.},
  archive      = {J_TCS},
  author       = {Yuval Emek and Shay Kutten and Ron Lavi and Yangguang Shi},
  doi          = {10.1016/j.tcs.2020.07.010},
  journal      = {Theoretical Computer Science},
  pages        = {167-185},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bayesian generalized network design},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial kernels for hitting forbidden minors under
structural parameterizations. <em>TCS</em>, <em>841</em>, 124–166. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate polynomial-time preprocessing for the problem of hitting forbidden minors in a graph, using the framework of kernelization. For a fixed finite set of connected graphs F F , the F F -Deletion problem is the following: given a graph G and integer k , is it possible to delete k vertices from G to ensure the resulting graph does not contain any graph from F F as a minor? Earlier work by Fomin, Lokshtanov, Misra, and Saurabh [FOCS&#39;12] showed that when F F contains a planar graph , an instance ( G , k ) (G,k) can be reduced in polynomial time to an equivalent one of size k O ( 1 ) kO(1) . In this work we focus on structural measures of the complexity of an instance, with the aim of giving nontrivial preprocessing guarantees for instances whose solutions are large. Motivated by several impossibility results, we parameterize the F F -Deletion problem by the size of a vertex modulator whose removal results in a graph of constant treedepth η . We prove that for each set F F of connected graphs and constant η , the F F -Deletion problem parameterized by the size of a treedepth- η modulator has a polynomial kernel. Our kernelization is fully explicit and does not depend on protrusion reduction or well-quasi-ordering, which are sources of algorithmic non-constructivity in earlier works on F F -Deletion . Our main technical contribution is to analyze how models of a forbidden minor in a graph G with modulator X , interact with the various connected components of G − X G−X . Using the language of labeled minors, we analyze the fragments of potential forbidden minor models that can remain after removing an optimal F F -Deletion solution from a single connected component of G − X G−X . By bounding the number of different types of behavior that can occur by a polynomial in | X | |X| , we obtain a polynomial kernel using a recursive preprocessing strategy. Our results extend earlier work for specific instances of F F -Deletion such as Vertex Cover and Feedback Vertex Set . It also generalizes earlier preprocessing results for F F -Deletion parameterized by a vertex cover, which is a treedepth-one modulator.},
  archive      = {J_TCS},
  author       = {Bart M.P. Jansen and Astrid Pieterse},
  doi          = {10.1016/j.tcs.2020.07.009},
  journal      = {Theoretical Computer Science},
  pages        = {124-166},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Polynomial kernels for hitting forbidden minors under structural parameterizations},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Almost envy-freeness in group resource allocation.
<em>TCS</em>, <em>841</em>, 110–123. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fairly allocating indivisible goods between groups of agents using the recently introduced relaxations of envy-freeness. We consider the existence of fair allocations under different assumptions on the valuations of the agents. In particular, our results cover cases of arbitrary monotonic, responsive, and additive valuations, while for the case of binary valuations we fully characterize the cardinalities of two groups of agents for which a fair allocation can be guaranteed with respect to both envy-freeness up to one good (EF1) and envy-freeness up to any good (EFX). Moreover, we introduce a new model where the agents are not partitioned into groups in advance, but instead the partition can be chosen in conjunction with the allocation of the goods. In this model, we show that for agents with arbitrary monotonic valuations, there is always a partition of the agents into two groups of any given sizes along with an EF1 allocation of the goods. We also provide an extension of this result to any number of groups.},
  archive      = {J_TCS},
  author       = {Maria Kyropoulou and Warut Suksompong and Alexandros A. Voudouris},
  doi          = {10.1016/j.tcs.2020.07.008},
  journal      = {Theoretical Computer Science},
  pages        = {110-123},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Almost envy-freeness in group resource allocation},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiple birds with one stone: Beating 1/2 for EFX and GMMS
via envy cycle elimination. <em>TCS</em>, <em>841</em>, 94–109. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several relaxations of envy-freeness, tailored to fair division in settings with indivisible goods, have been introduced within the last decade. Due to the lack of general existence results for most of these concepts, great attention has been paid to establishing approximation guarantees. In this work, we propose a simple algorithm that is universally fair in the sense that it returns allocations that have good approximation guarantees with respect to four such fairness notions at once. In particular, this is the first algorithm achieving a ( ϕ − 1 ) (ϕ−1) -approximation of envy-freeness up to any good ( ) and a 2 ϕ + 2 2ϕ+2 -approximation of groupwise maximin share fairness ( ), where ϕ is the golden ratio ( ϕ ≈ 1.618 ϕ≈1.618 ). The best known approximation factor , in polynomial time , for either one of these fairness notions prior to this work was 1/2. Moreover, the returned allocation achieves envy-freeness up to one good ( ) and a 2/3-approximation of pairwise maximin share fairness ( ). While is our primary focus, we also exhibit how to fine-tune our algorithm and further improve the guarantees for or . Finally, we show that —and thus and —allocations always exist when the number of goods does not exceed the number of agents by more than two.},
  archive      = {J_TCS},
  author       = {Georgios Amanatidis and Evangelos Markakis and Apostolos Ntokos},
  doi          = {10.1016/j.tcs.2020.07.006},
  journal      = {Theoretical Computer Science},
  pages        = {94-109},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Multiple birds with one stone: Beating 1/2 for EFX and GMMS via envy cycle elimination},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the behavioral implications of differential privacy.
<em>TCS</em>, <em>841</em>, 84–93. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy is commonly used in the computer science literature as a mathematical definition of privacy for the purpose of quantifying and bounding privacy loss. It induces a preference order over the set of privacy-jeopardizing mechanisms which, in turn, adhere to some properties of this order. We show that a set of five such properties uniquely captures the ordinal implications of prioritizing the alternatives in agreement with differential privacy. The model can also be applied to evaluate the appropriateness of differential privacy in different settings.},
  archive      = {J_TCS},
  author       = {Gail Gilboa-Freedman and Rann Smorodinsky},
  doi          = {10.1016/j.tcs.2020.07.005},
  journal      = {Theoretical Computer Science},
  pages        = {84-93},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the behavioral implications of differential privacy},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Extended partial key exposure attacks on RSA: Improvement up
to full size decryption exponents. <em>TCS</em>, <em>841</em>, 62–83.
(<a href="https://doi.org/10.1016/j.tcs.2020.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial key exposure attacks on RSA have been intensively studied by using lattice-based Coppersmith&#39;s methods. Ernst et al. (Eurocrypt&#39;05) studied the problem by considering three attack scenarios; (1) the most significant bits (MSBs) of a secret exponent d known, (2) the least significant bits (LSBs) of d known, (3) both the MSBs and the LSBs of d known. The proposed attacks were valuable since they were the first results to handle full size exponents e . Takayasu and Kunihiro (SAC&#39;14, Theoretical Computer Science&#39;19) proposed improved attacks for (1) and (2) when d is sufficiently small, i.e., d d&amp;lt;N0.5625 for (1) and d d&amp;lt;N0.368 for (2), by utilizing a linearization technique. In this paper, we extend Takayasu-Kunihiro&#39;s attacks and improve Ernst et al.&#39;s attack for (3). In particular, our attack contains Takayasu-Kunihiro&#39;s attacks for (1) and (2) as special cases when the amount of given LSBs and MSBs are zero, respectively. Furthermore, as opposed to Takayasu-Kunihiro&#39;s attacks, our improvement against Ernst et al.&#39;s attack is not limited to small secret exponents such as d d&amp;lt;N0.5625 . Indeed, we are able to improve Ernst et al.&#39;s attack almost up to full size decryption exponents, i.e., even when d is close to N . Technically, the extension is not straightforward. We first modify Takayasu-Kunihiro&#39;s lattice basis matrix for (2), so that it is compatible to embed the given MSBs. The modification is crucial for embedding both the MSBs and the LSBs simultaneously to the matrix.},
  archive      = {J_TCS},
  author       = {Kaichi Suzuki and Atsushi Takayasu and Noboru Kunihiro},
  doi          = {10.1016/j.tcs.2020.07.004},
  journal      = {Theoretical Computer Science},
  pages        = {62-83},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Extended partial key exposure attacks on RSA: Improvement up to full size decryption exponents},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploration of carrier-based time-varying networks: The
power of waiting. <em>TCS</em>, <em>841</em>, 50–61. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of exploration by a mobile entity (agent) of a class of highly dynamic networks, namely the carrier graphs (the C-graphs, modeling public transportation systems, among others). These are defined by a set of carriers following infinitely their prescribed route along the stations of the network. Flocchini, Mans, and Santoro [9] studied this problem in the case when the agent must always travel on the carriers and thus cannot wait on a station. They described the necessary and sufficient conditions for the problem to be solvable and proved that the optimal worst-case number of time units (and thus of moves) to explore a n -node C-graph of k carriers and maximal period p is in Θ ( k p 2 ) Θ(kp2) in the general case. In this paper, we study the impact of the ability to wait at the stations. We exhibit the necessary and sufficient conditions for the problem to be solvable in this context, and we prove that waiting at the stations allows the agent to reduce the optimal worst-case number of moves by a multiplicative factor of at least Θ ( p ) Θ(p) , while the worst-case time complexity is reduced to Θ ( n p ) Θ(np) . (In any connected carrier graph, we have n ≤ k p n≤kp .) We also show some complementary optimal results in specific cases (same period for all carriers, highly connected C-graphs). Finally this new ability allows the agent to completely map the C-graph, in addition to just exploring it.},
  archive      = {J_TCS},
  author       = {David Ilcinkas and Ahmed M. Wade},
  doi          = {10.1016/j.tcs.2020.07.003},
  journal      = {Theoretical Computer Science},
  pages        = {50-61},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Exploration of carrier-based time-varying networks: The power of waiting},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On fan-crossing graphs. <em>TCS</em>, <em>841</em>, 39–49.
(<a href="https://doi.org/10.1016/j.tcs.2020.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fan is a set of edges with a single common endpoint. A drawing of a graph in the plane is fan-crossing if each edge can only be crossed by edges of a fan. It is fan-planar if, in addition, the common endpoint is on the same side of the crossed edge. A drawing is adjacency-crossing if any two edges are adjacent if they cross the same edge. Then multiple independent crossings are excluded, in which an edge is crossed by at least two edges with no common endpoint. In adjacency-crossing drawings it is allowed that an edge crosses the edges of a triangle, which is excluded for fan-crossing drawings. A graph is fan-crossing (fan-planar, adjacency-crossing) if it admits a respective drawing. We show that every adjacency-crossing graph is fan-crossing and that there are fan-crossing graphs that are not fan-planar. Moreover, for every fan-crossing graph there is a fan-planar graph on the same set of vertices and with the same number of edges. Hence, fan-crossing and fan-planar graphs are different, but they do not differ in the density with at most 5 n − 10 5n−10 edges for graphs of order n .},
  archive      = {J_TCS},
  author       = {Franz J. Brandenburg},
  doi          = {10.1016/j.tcs.2020.07.002},
  journal      = {Theoretical Computer Science},
  pages        = {39-49},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On fan-crossing graphs},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hardness results for three kinds of colored connections of
graphs. <em>TCS</em>, <em>841</em>, 27–38. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of rainbow connection number of a graph was introduced by Chartrand et al. in 2008. Inspired by this concept, other concepts on colored version of connectivity in graphs were introduced, such as the monochromatic connection number by Caro and Yuster in 2011, the proper connection number by Borozan et al. in 2012, and the conflict-free connection number by Czap et al. in 2018, as well as some other variants of connection numbers later on. Chakraborty et al. proved that to compute the rainbow connection number of a graph is NP-hard. For a long time, it has been tried to fix the computational complexity for the monochromatic connection number, the proper connection number and the conflict-free connection number of a graph. However, it has not been solved yet. Only the complexity results for the strong version, i.e., the strong proper connection number and the strong conflict-free connection number, of these connection numbers were determined to be NP-hard. In this paper, we prove that to compute each of the monochromatic connection number, the proper connection number and the conflict free connection number for a graph is NP-hard. This solves a long standing problem in this field, asked in many talks of workshops and papers.},
  archive      = {J_TCS},
  author       = {Zhong Huang and Xueliang Li},
  doi          = {10.1016/j.tcs.2020.06.030},
  journal      = {Theoretical Computer Science},
  pages        = {27-38},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hardness results for three kinds of colored connections of graphs},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully persistent b-trees. <em>TCS</em>, <em>841</em>, 10–26.
(<a href="https://doi.org/10.1016/j.tcs.2020.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present efficient fully persistent B-trees in the I/O model with block size B that support range searches on t reported elements at any accessed version of size n in O ( log B ⁡ n + t / B ) O(logB⁡n+t/B) I/Os and updates at any accessed version in O ( log B ⁡ n + log 2 ⁡ B ) O(logB⁡n+log2⁡B) amortized I/Os, using O ( m / B ) O(m/B) disk blocks after m updates. This improves both the query and update I/O-efficiency of the previous fully persistent B-trees of Lanka and Mays (ACM SIGMOD ICMD 1991). To achieve the result, we introduce an implementation for ephemeral B-trees that supports searches and updates in O ( log B ⁡ n ) O(logB⁡n) I/Os, using O ( n / B ) O(n/B) blocks, where moreover every update makes a worst-case constant number of modifications to the structure. We make these B-trees fully persistent using an I/O-efficient method for full persistence, inspired by the node-splitting method of Driscoll et al. (JCSS 1989). Interesting in its own right, the method is generic enough to be applied to any external memory pointer-based data structure with maximum in-degree d i n din and out-degree O ( B ) O(B) , where every node occupies a constant number of blocks on disk. For a user-specified parameter π = Ω ( d i n ) π=Ω(din) , we achieve O ( π B + log 2 ⁡ π ) O(πB+log2⁡π) I/O-overhead per access to a field of an ephemeral block and amortized O ( π B + log 2 ⁡ π + d i n π log 2 ⁡ B ) O(πB+log2⁡π+dinπlog2⁡B) I/O-overhead and O ( 1 / B ) O(1/B) block space-overhead per modification to the ephemeral structure.},
  archive      = {J_TCS},
  author       = {Gerth Stølting Brodal and Spyros Sioutas and Konstantinos Tsakalidis and Kostas Tsichlas},
  doi          = {10.1016/j.tcs.2020.06.027},
  journal      = {Theoretical Computer Science},
  pages        = {10-26},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fully persistent B-trees},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling jobs with sizes and delivery times on identical
parallel batch machines. <em>TCS</em>, <em>841</em>, 1–9. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of scheduling jobs with sizes, release times and delivery times on identical parallel batch machines. All machines have the same capacity. Each machine can simultaneously process several jobs as a batch as long as the total size of these jobs does not exceed the capacity. The release time, processing time and delivery time of a batch are defined to be the latest release time, longest processing time and largest delivery time of all the jobs in the batch, respectively. The objective is to minimize the maximum delivery completion time, i.e., the time by which all jobs are delivered. For this strongly NP-hard problem, there does not exist any polynomial time algorithm with approximation ratio better than 2 unless P=NP, even if all jobs have equal processing times and all release times and delivery times are zero. We present an algorithm with approximation ratio arbitrarily close to 2.},
  archive      = {J_TCS},
  author       = {Yijie Li and Shuguang Li},
  doi          = {10.1016/j.tcs.2020.06.023},
  journal      = {Theoretical Computer Science},
  pages        = {1-9},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Scheduling jobs with sizes and delivery times on identical parallel batch machines},
  volume       = {841},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Community-based rumor blocking maximization in social
networks: Algorithms and analysis. <em>TCS</em>, <em>840</em>, 257–269.
(<a href="https://doi.org/10.1016/j.tcs.2020.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks provide us a convenient platform to communicate and share information or ideas with each other, but it also causes many negative effects at the same time, such as, the spread of misinformation or rumor in social networks may cause public panic and even serious economic or political crisis. In this paper, we propose a Community-based Rumor Blocking Problem (CRBMP), i.e., selecting a set of seed users from all communities as protectors with the constraint of budget b such that the expected number of users eventually not being influenced by rumor sources is maximized. We consider the community structure in social networks and solve our problem in two stages, in the first stage, we allocate budget b for all the communities, this sub-problem whose objective function is proved to be monotone and DR-submodular, so we can use the method of submodular function maximization on an integer lattice , which is different from most of the existing work with the submodular function over a set function. Then a greedy community budget allocation algorithm is devised to get an 1 − 1 / e 1−1/e approximation ratio; we also propose a speed-up greedy algorithm which greatly reduces the time complexity for the community budget allocation and can get an 1 − 1 / e − ϵ 1−1/e−ϵ approximation guarantee meanwhile. Next we solve the Protector Seed Selection (PSS) problem in the second stage after we obtained the budget allocation vector for communities, we greedily choose protectors for each community with the budget constraints to achieve the maximization of the influence of protectors. The greedy algorithm for PSS problem can achieve a 1/2 approximation guarantee. We also consider a special case where the rumor just originates from one community and does not spread out of its own community before the protectors are selected, the proposed algorithm can reduce the computational cost than the general greedy algorithm since we remove the uninfected communities. Finally, we conduct extensive experiments on three real world data sets, the results demonstrate the effectiveness of the proposed algorithm and its superiority over other methods.},
  archive      = {J_TCS},
  author       = {Qiufen Ni and Jianxiong Guo and Chuanhe Huang and Weili Wu},
  doi          = {10.1016/j.tcs.2020.08.030},
  journal      = {Theoretical Computer Science},
  pages        = {257-269},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Community-based rumor blocking maximization in social networks: Algorithms and analysis},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved learning of k-parities. <em>TCS</em>, <em>840</em>,
249–256. (<a href="https://doi.org/10.1016/j.tcs.2020.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of learning k -parities in the online mistake-bound model: given a hidden vector x ∈ { 0 , 1 } n x∈{0,1}n where the hamming weight of x is k and a sequence of “questions” a 1 , a 2 , … ∈ { 0 , 1 } n a1,a2,…∈{0,1}n , where the algorithm must reply to each question with 〈 a i , x 〉 ( mod 2 ) 〈ai,x〉(mod2) , what is the best trade-off between the number of mistakes made by the algorithm and its time complexity? We improve the previous best result of Buhrman et al. [3] by an exp ⁡ ( k ) exp⁡(k) factor in the time complexity. Next, we consider the problem of learning k -parities in the PAC model in the presence of random classification noise of rate η ∈ ( 0 , 1 2 ) η∈(0,12) . Here, we observe that even in the presence of classification noise of non-trivial rate, it is possible to learn k -parities in time better than ( n k / 2 ) (nk/2) , whereas the current best algorithm for learning noisy k -parities, due to Grigorescu et al. [9] , inherently requires time ( n k / 2 ) (nk/2) even when the noise rate is polynomially small.},
  archive      = {J_TCS},
  author       = {Arnab Bhattacharyya and Ameet Gadekar and Ninad Rajgopal},
  doi          = {10.1016/j.tcs.2020.08.025},
  journal      = {Theoretical Computer Science},
  pages        = {249-256},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved learning of k-parities},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the semantic equivalence of language syntax formalisms.
<em>TCS</em>, <em>840</em>, 234–248. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several formalisms for language syntax specification exist in literature. In this paper, we prove that longstanding syntactical transformations between context-free grammars and algebraic signatures are adjoint functors and/or adjoint equivalences that preserve the abstract syntax of the generated terms. The main result is a categorical equivalence between the categories of algebras ( i.e. , all the possible semantics) over the objects in these formalisms up to the provided syntactical transformations, namely that all these language specification frameworks are essentially the same from a semantic perspective.},
  archive      = {J_TCS},
  author       = {Samuele Buro and Isabella Mastroeni},
  doi          = {10.1016/j.tcs.2020.08.022},
  journal      = {Theoretical Computer Science},
  pages        = {234-248},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the semantic equivalence of language syntax formalisms},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient scheduling of a mobile charger in large-scale
sensor networks. <em>TCS</em>, <em>840</em>, 219–233. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schedule a mobile charger to replenish energy to sensor nodes for the wireless sensor networks has attracted great attention recently, due to its efficiency and flexibility. Some existing works study the mobile charger scheduling problem by considering that only the depot can recharge or replace the battery for the mobile charger. However, for large-scale wireless sensor networks, the mobile charger is energy inefficient or even may run out of energy during the travel for charging. In this paper, we consider the scenario that there are some service stations in the network area which can be used to replace the battery for the mobile charger, and we study the problem of minimizing the number of used batteries for a mobile charger to charge a wireless sensor network (MBA). We first consider a special case of the MBA problem, in which the depot is the only service station, and we present an approximation algorithm to address it. Then we propose an approximation algorithm for the MBA problem with the assumption that the distance of any two service stations is limited. And finally, we consider the general MBA problem and propose an approximation algorithm. We validate the performance of our algorithms by extensive simulations, and the results show that our proposed algorithms are promising.},
  archive      = {J_TCS},
  author       = {Xingjian Ding and Wenping Chen and Yongcai Wang and Deying Li and Yi Hong},
  doi          = {10.1016/j.tcs.2020.08.020},
  journal      = {Theoretical Computer Science},
  pages        = {219-233},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient scheduling of a mobile charger in large-scale sensor networks},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complete bipartite graphs deleted in ramsey graphs.
<em>TCS</em>, <em>840</em>, 212–218. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For graphs F , G and H , let F → ( G , H ) F→(G,H) signify that any red/blue edge coloring of F contains either a red G or a blue H . The Ramsey number R ( G , H ) R(G,H) is defined as min ⁡ { r | K r → ( G , H ) } min⁡{r|Kr→(G,H)} . In this note, we consider an optimization problem to bound the complete bipartite-critical Ramsey number R Λ ( G , H ) RΛ(G,H) defined as max ⁡ { t | K r ∖ K t , t → ( G , H ) } max⁡{t|Kr∖Kt,t→(G,H)} where r = R ( G , H ) r=R(G,H) and Λ is a set of K t , t Kt,t , and determine R Λ ( G , H ) RΛ(G,H) for some pairs ( G , H ) (G,H) .},
  archive      = {J_TCS},
  author       = {Yan Li and Yusheng Li and Ye Wang},
  doi          = {10.1016/j.tcs.2020.08.019},
  journal      = {Theoretical Computer Science},
  pages        = {212-218},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complete bipartite graphs deleted in ramsey graphs},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). The parameterized complexity and kernelization of
resilience for database queries. <em>TCS</em>, <em>840</em>, 199–211.
(<a href="https://doi.org/10.1016/j.tcs.2020.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a database instance and a query on it whose result is initially non-empty, the resilience decision problem is to decide if there exist a small enough number of facts in the database instance such that the deletion of these facts empties the result of the given query. In this paper, we revisit the resilience decision problem. We investigate the parameterized complexity for various classes of database queries. We consider the factors including the query size and the number of variables, and present several intractable cases even from the perspective of parameterized complexity. Meanwhile, we refine the characteristics of resilience for self-join-free conjunctive queries containing triads, and show that it is still NP-hard even if the structure of the input database instance is simple. This result implies the hardness essentially comes from the parity of triangle sequence instead of the complicate (non-planar) intersections of cycles. On the other hand, we also obtain some positive results showing that the resilience decision problem is still fixed parameter tractable for an important case through kernelization. Our work demonstrates a new insight for employing resilience computation in database operations.},
  archive      = {J_TCS},
  author       = {Dongjing Miao and Jianzhong Li and Zhipeng Cai},
  doi          = {10.1016/j.tcs.2020.08.018},
  journal      = {Theoretical Computer Science},
  pages        = {199-211},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The parameterized complexity and kernelization of resilience for database queries},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Maximum reachability preserved graph cut. <em>TCS</em>,
<em>840</em>, 187–198. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of reachability reduction problems were raised in the area of computer network security and software engineering. This paper studies such a reachability reduction problem on a vertex labeled graph . The reachability reduction here is modeled as maximum reachability preserved cut which is a variant of minimum multiway cut with a new objective function. Finding a maximum reachability preserved cut is to disconnect some labels specified in advance by edge deletion while preserving other reachable labels. It gives a way to model a large family of network problems based on graph model . We provide a comprehensive complexity analysis of this problem under different input settings. A landscape of the hardness hierarchy of this problem is shown in this paper, in which polynomial tractable and intractable cases are identified.},
  archive      = {J_TCS},
  author       = {Dongjing Miao and Jianzhong Li and Zhipeng Cai},
  doi          = {10.1016/j.tcs.2020.08.016},
  journal      = {Theoretical Computer Science},
  pages        = {187-198},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Maximum reachability preserved graph cut},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast algorithm for maximizing a non-monotone DR-submodular
integer lattice function. <em>TCS</em>, <em>840</em>, 177–186. (<a
href="https://doi.org/10.1016/j.tcs.2020.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of maximizing a non-monotone and non-negative DR-submodular function on a bounded integer lattice [ B → ] = { ( x 1 , … , x n ) ∈ Z + n : 0 ≤ x k ≤ B k , ∀ 1 ≤ k ≤ n } [B→]={(x1,…,xn)∈Z+n:0≤xk≤Bk,∀1≤k≤n} without any constraint, where B → = ( B 1 , … , B n ) ∈ Z + n B→=(B1,…,Bn)∈Z+n . We design an algorithm for the problem and measure its performance by its approximation ratio and the number of value oracle queries it needs, where the latter one is the dominating term in the running time of an algorithm. It has been showed that, for the problem considered, any algorithm achieving an approximation ratio greater than 1 2 12 requires an exponential number of value oracle queries. In the literature there are two algorithms that reach 1 2 12 approximation guarantee. The first algorithm needs O ( n | | B | | ∞ ) O(n||B||∞) oracle queries. The second one reduces its number of oracle queries to O ( n max ⁡ { 1 , log ⁡ | | B → | | ∞ } ) O(nmax⁡{1,log⁡||B→||∞}) but it needs large storage. In this paper we present a randomized approximation algorithm that has an approximation guarantee of 1 2 12 , calls O ( n max ⁡ { 1 , log ⁡ | | B → | | ∞ } ) O(nmax⁡{1,log⁡||B→||∞}) oracle queries and does not need large storage, improving the results of the literature.},
  archive      = {J_TCS},
  author       = {Qingqin Nong and Jiazhu Fang and Suning Gong and Yan Feng and Xiaoying Qu},
  doi          = {10.1016/j.tcs.2020.08.011},
  journal      = {Theoretical Computer Science},
  pages        = {177-186},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A fast algorithm for maximizing a non-monotone DR-submodular integer lattice function},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering and packing of rectilinear subdivision.
<em>TCS</em>, <em>840</em>, 166–176. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of geometric covering and packing problems for bounded closed regions on the plane. We are given a set of axis-parallel line segments that induce a planar subdivision with bounded (rectilinear) faces. We are interested in the following problems.},
  archive      = {J_TCS},
  author       = {Satyabrata Jana and Supantha Pandit},
  doi          = {10.1016/j.tcs.2020.07.038},
  journal      = {Theoretical Computer Science},
  pages        = {166-176},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Covering and packing of rectilinear subdivision},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Limitations of current wireless link scheduling algorithms.
<em>TCS</em>, <em>840</em>, 154–165. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the following basic scheduling problem in wireless networks: partition a given set of unit demand communication links into the minimum number of feasible subsets. A subset is feasible if all communications can be done simultaneously, subject to mutual interference. We use the so-called physical model to formulate feasibility. We consider the two families of approximation algorithms that are known to guarantee O ( log ⁡ n ) O(log⁡n) approximation for the scheduling problem, where n is the number of links. We present network constructions showing that the approximation ratios of those algorithms are no better than logarithmic, both in n and in Δ, where Δ is a geometric parameter – the ratio of the maximum and minimum link lengths.},
  archive      = {J_TCS},
  author       = {Magnús M. Halldórsson and Christian Konrad and Tigran Tonoyan},
  doi          = {10.1016/j.tcs.2020.07.033},
  journal      = {Theoretical Computer Science},
  pages        = {154-165},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Limitations of current wireless link scheduling algorithms},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Radio aggregation scheduling. <em>TCS</em>, <em>840</em>,
143–153. (<a href="https://doi.org/10.1016/j.tcs.2020.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the aggregation problem in radio networks: find a spanning tree in a given graph and a conflict-free schedule of the edges so as to minimize the latency of the computation. While a large body of literature exists on this and related problems, we give the first approximation results in graphs that are not induced by unit ranges in the plane. We give a polynomial-time O ˜ ( d n ) O˜(dn) -approximation algorithm, where d is the average degree and n the number of vertices in the graph, and show that the problem is Ω ( n 1 − ϵ ) Ω(n1−ϵ) -hard (and Ω ( ( d n ) 1 / 2 − ϵ ) Ω((dn)1/2−ϵ) -hard) to approximate even on bipartite graphs , for any ϵ &gt; 0 ϵ&amp;gt;0 , rendering our algorithm essentially optimal. We also obtain a O ( log ⁡ n ) O(log⁡n) -approximation in interval graphs .},
  archive      = {J_TCS},
  author       = {Rajiv Gandhi and Magnús M. Halldórsson and Christian Konrad and Guy Kortsarz and Hoon Oh},
  doi          = {10.1016/j.tcs.2020.07.032},
  journal      = {Theoretical Computer Science},
  pages        = {143-153},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Radio aggregation scheduling},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). LTL to self-loop alternating automata with generic
acceptance and back. <em>TCS</em>, <em>840</em>, 122–142. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-loop alternating automata (SLAA) with Büchi or co-Büchi acceptance are popular formalisms also known as very weak alternating automata (VWAA). They are often used as an intermediate results in translations of LTL to deterministic or nondeterministic automata. This paper considers SLAA with generic transition-based Emerson-Lei acceptance and presents translations of LTL to these automata and back. Importantly, the translation of LTL to SLAA with generic acceptance produces considerably smaller automata than previous translations of LTL to Büchi or co-Büchi SLAA. Our translation is already implemented in the tool ltl3tela, where it helps to produce small deterministic or nondeterministic transition-based Emerson-Lei automata for given LTL formulae.},
  archive      = {J_TCS},
  author       = {František Blahoudek and Juraj Major and Jan Strejček},
  doi          = {10.1016/j.tcs.2020.07.015},
  journal      = {Theoretical Computer Science},
  pages        = {122-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {LTL to self-loop alternating automata with generic acceptance and back},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The amortized analysis of a non-blocking chromatic tree.
<em>TCS</em>, <em>840</em>, 59–121. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A non-blocking chromatic tree is a type of balanced binary search tree where multiple processes can concurrently perform search and update operations. We prove that a certain implementation has amortized cost O ( c ˙ + log ⁡ n ) O(c˙+log⁡n) for each operation, where c ˙ c˙ is the maximum number of concurrent operations during the execution and n is the maximum number of keys in the tree during the operation. This amortized analysis presents new challenges compared to existing analyses of other non-blocking data structures .},
  archive      = {J_TCS},
  author       = {Jeremy Ko},
  doi          = {10.1016/j.tcs.2020.07.007},
  journal      = {Theoretical Computer Science},
  pages        = {59-121},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The amortized analysis of a non-blocking chromatic tree},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A local characterization for perfect plane
near-triangulations. <em>TCS</em>, <em>840</em>, 45–58. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a local criterion for a plane near-triangulated graph to be perfect. It is shown that a plane near-triangulated graph is perfect if and only if it does not contain either a vertex, an edge or a triangle, the neighbourhood of which has an odd hole as its boundary. The characterization leads to an O ( n 2 ) O(n2) algorithm for checking perfectness of plane near-triangulations.},
  archive      = {J_TCS},
  author       = {Sameera M. Salam and Jasine Babu and K. Murali Krishnan},
  doi          = {10.1016/j.tcs.2020.06.031},
  journal      = {Theoretical Computer Science},
  pages        = {45-58},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A local characterization for perfect plane near-triangulations},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The sparsest additive spanner via multiple weighted BFS
trees. <em>TCS</em>, <em>840</em>, 33–44. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spanners are fundamental graph structures that sparsify graphs at the cost of small stretch. In particular, in recent years, many sequential algorithms constructing additive all-pairs spanners were designed, providing very sparse small-stretch subgraphs. Remarkably, it was then shown that the known ( + 6 ) (+6) -spanner constructions are essentially the sparsest possible, that is, larger additive stretch cannot guarantee a sparser spanner, which brought the stretch-sparsity trade-off to its limit. Distributed constructions of spanners are also abundant. However, for additive spanners, while there were algorithms constructing ( + 2 ) (+2) and ( + 4 ) (+4) -all-pairs spanners, the sparsest case of ( + 6 ) (+6) -spanners remained elusive. We remedy this by designing a new sequential algorithm for constructing a ( + 6 ) (+6) -spanner with the essentially-optimal sparsity of O ˜ ( n 4 / 3 ) O˜(n4/3) edges. We then show a distributed implementation of our algorithm, answering an open problem in [12] . A main ingredient in our distributed algorithm is an efficient construction of multiple weighted BFS trees. A weighted BFS tree is a BFS tree in a weighted graph , that consists of the lightest among all shortest paths from the root to each node. We present a distributed algorithm in the CONGEST model, that constructs multiple weighted BFS trees in | S | + D − 1 |S|+D−1 rounds, where S is the set of sources and D is the diameter of the network graph.},
  archive      = {J_TCS},
  author       = {Keren Censor-Hillel and Ami Paz and Noam Ravid},
  doi          = {10.1016/j.tcs.2020.05.035},
  journal      = {Theoretical Computer Science},
  pages        = {33-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The sparsest additive spanner via multiple weighted BFS trees},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithm and hardness results on neighborhood total
domination in graphs. <em>TCS</em>, <em>840</em>, 16–32. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set D ⊆ V D⊆V of a graph G = ( V , E ) G=(V,E) is called a neighborhood total dominating set of G if D is a dominating set and the subgraph of G induced by the open neighborhood of D has no isolated vertex. Given a graph G , Min-NTDS is the problem of finding a neighborhood total dominating set of G of minimum cardinality. The decision version of Min-NTDS is known to be NP -complete for bipartite graphs and chordal graphs. In this paper, we extend this NP -completeness result to undirected path graphs, chordal bipartite graphs, and planar graphs . We also present a linear time algorithm for computing a minimum neighborhood total dominating set in proper interval graphs . We show that for a given graph G = ( V , E ) G=(V,E) , Min-NTDS cannot be approximated within a factor of ( 1 − ε ) log ⁡ | V | (1−ε)log⁡|V| , unless NP ⊆ DTIME ( | V | O ( log ⁡ log ⁡ | V | ) |V|O(log⁡log⁡|V|) ) and can be approximated within a factor of O ( log ⁡ Δ ) O(log⁡Δ) , where Δ is the maximum degree of the graph G . Finally, we show that Min-NTDS is APX -complete for graphs of degree at most 3.},
  archive      = {J_TCS},
  author       = {Anupriya Jha and D. Pradhan and S. Banerjee},
  doi          = {10.1016/j.tcs.2020.05.002},
  journal      = {Theoretical Computer Science},
  pages        = {16-32},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algorithm and hardness results on neighborhood total domination in graphs},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A 2-approximation algorithm and beyond for the minimum
diameter k-steiner forest problem. <em>TCS</em>, <em>840</em>, 1–15. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an edge-weighted undirected graph G = ( V , E , w ) G=(V,E,w) and a subset T ⊆ V T⊆V of p terminals, a k-Steiner forest spanning all the terminals in T T includes k branches, where every branch is a Steiner tree . The diameter of a k -Steiner forest is referred to as the maximum distance between two terminals of a branch. This paper studies the minimum diameter k-Steiner forest problem (MD k SFP) and establishes the relationship between MD k SFP and the absolute k-Steiner center problem (A k SCP). We first obtain a 2-factor dual approximation algorithm for A k SCP, and then achieve a 2-approximation algorithm for MD k SFP based on the 2-approximation to A k SCP. Furthermore, we develop an improved 2 ρ -approximation algorithm for MD k SFP, where ρ ρ&amp;lt;1 in general, by perturbing the sites of facilities and re-clustering the terminals.},
  archive      = {J_TCS},
  author       = {Wei Ding and Ke Qiu},
  doi          = {10.1016/j.tcs.2019.12.012},
  journal      = {Theoretical Computer Science},
  pages        = {1-15},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A 2-approximation algorithm and beyond for the minimum diameter k-steiner forest problem},
  volume       = {840},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simple strategies versus optimal schedules in multi-agent
patrolling. <em>TCS</em>, <em>839</em>, 195–206. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose that a set of mobile agents , each with a predefined maximum speed, want to patrol a fence together so as to minimize the longest time interval during which a point on the fence is left unvisited. In 2011, Czyzowicz, Gąsieniec, Kosowski and Kranakis studied this problem for the settings where the fence is an interval (a line segment) and a circle, and conjectured that the following simple strategies are always optimal: for Interval Patrolling, the simple strategy partitions the fence into subintervals , one for each agent, and lets each agent move back and forth in the assigned subinterval with its maximum speed; for Circle Patrolling, the simple strategy is to choose a number r , place the r fastest agents equidistantly around the circle, and move them at the speed of the r th agent. Surprisingly, these conjectures were then proved false: schedules were found (for some settings of maximum speeds) that slightly outperform the simple strategies. In this paper, we are interested in the ratio between the performances of optimal schedules and simple strategies. For the two problems, we construct schedules that are 4/3 times (for Interval Patrolling) and 21/20 times (for Circle Patrolling) as good, respectively, as the simple strategies. We also propose a new variant, in which we want to patrol a single point under the constraint that each agent can only visit the point some predefined time after its previous visit. We obtain some similar ratio bounds and NP NP -hardness results related to this problem.},
  archive      = {J_TCS},
  author       = {Akitoshi Kawamura and Makoto Soejima},
  doi          = {10.1016/j.tcs.2020.07.037},
  journal      = {Theoretical Computer Science},
  pages        = {195-206},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Simple strategies versus optimal schedules in multi-agent patrolling},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cops and robbers on graphs with a set of forbidden induced
subgraphs. <em>TCS</em>, <em>839</em>, 186–194. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the class of all graphs not containing a graph H as an induced subgraph is cop-bounded if and only if H is a forest whose every component is a path [4] . In this paper, we characterize all sets H H of graphs with bounded diameter, such that H H -free graphs are cop-bounded. This, in particular, gives a characterization of cop-bounded classes of graphs defined by a finite set of connected graphs as forbidden induced subgraphs. Furthermore, we extend our characterization to the case of cop-bounded classes of graphs defined by a set H H of forbidden graphs such that the components of members of H H have bounded diameter.},
  archive      = {J_TCS},
  author       = {Masood Masjoody and Ladislav Stacho},
  doi          = {10.1016/j.tcs.2020.06.032},
  journal      = {Theoretical Computer Science},
  pages        = {186-194},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cops and robbers on graphs with a set of forbidden induced subgraphs},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online graph exploration on a restricted graph class:
Optimal solutions for tadpole graphs. <em>TCS</em>, <em>839</em>,
176–185. (<a href="https://doi.org/10.1016/j.tcs.2020.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of online graph exploration on undirected graphs , where a searcher has to visit every vertex and return to the origin. Once a new vertex is visited, the searcher learns of all neighboring vertices and the connecting edge weights. The goal of such an exploration is to minimize its total cost, where each edge traversal incurs a cost of the corresponding edge weight. We investigate the problem on tadpole graphs (also known as dragons, kites), which consist of a cycle with an attached path. The construction by Miyazaki et al. (The online graph exploration problem on restricted graphs, IEICE Transactions 92-D (9), 2009) can be extended to show that every online algorithm on these graphs must have a competitive ratio of 2 − ε 2−ε , but the authors did not investigate non-unit edge weights. We show via amortized analysis that a greedy approach yields a matching competitive ratio of 2 on tadpole graphs, for arbitrary non-negative edge weights. Moreover, we also briefly discuss the topic of advice complexity on cycle and tadpole graphs.},
  archive      = {J_TCS},
  author       = {Sebastian Brandt and Klaus-Tycho Foerster and Jonathan Maurer and Roger Wattenhofer},
  doi          = {10.1016/j.tcs.2020.06.007},
  journal      = {Theoretical Computer Science},
  pages        = {176-185},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online graph exploration on a restricted graph class: Optimal solutions for tadpole graphs},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Edge degeneracy: Algorithmic and structural results.
<em>TCS</em>, <em>839</em>, 164–175. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a cops and robber game where the cops are blocking edges of a graph , while the robber occupies its vertices. At each round of the game, the cops choose some set of edges to block and right after the robber is obliged to move to another vertex traversing at most s unblocked edges ( s can be seen as the speed of the robber). Both parts have complete knowledge of the opponent&#39;s moves and the cops win when they occupy all edges incident to the robbers position. We introduce the capture cost on G against a robber of speed s . This defines a hierarchy of invariants , namely δ e 1 , δ e 2 , … , δ e ∞ δe1,δe2,…,δe∞ , where δ e ∞ δe∞ is an edge-analogue of the admissibility graph invariant , namely the edge-admissibility of a graph. We prove that the problem asking whether δ e s ( G ) ≤ k δes(G)≤k , is polynomially solvable when s ∈ { 1 , 2 , 3 , ∞ } s∈{1,2,3,∞} while, otherwise, it is NP -complete. Our main result is a structural theorem for graphs of bounded edge-admissibility. We prove that every graph of edge-admissibility at most k can be constructed using ( ≤ k ) (≤k) -edge-sums, starting from graphs whose all vertices, except possibly from one, have degree at most k . Our structural result is approximately tight in the sense that graphs generated by this construction always have edge-admissibility at most 2 k − 1 2k−1 . Our proofs are based on a precise structural characterization of the graphs that do not contain θ r θr as an immersion, where θ r θr is the graph on two vertices and r parallel edges.},
  archive      = {J_TCS},
  author       = {Stratis Limnios and Christophe Paul and Joanny Perret and Dimitrios M. Thilikos},
  doi          = {10.1016/j.tcs.2020.06.006},
  journal      = {Theoretical Computer Science},
  pages        = {164-175},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Edge degeneracy: Algorithmic and structural results},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tight lower bound for the capture time of the cops and
robbers game. <em>TCS</em>, <em>839</em>, 143–163. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the game of Cops and Robbers , it is known that in 1-cop-win graphs, the cop can capture the robber in O ( n ) time, and that there exist graphs in which this capture time is tight. When k ≥ 2 , a simple counting argument shows that in k -cop-win graphs, the capture time is at most O ( n k + 1 ) , however, no non-trivial lower bounds were previously known; indeed, in their 2011 book, Bonato and Nowakowski ask whether this upper bound can be improved. In this paper, the question of Bonato and Nowakowski is answered on the negative, proving that the O ( n k + 1 ) bound is asymptotically tight for any constant k ≥ 2 . This yields a surprising gap in the capture time complexities between the 1-cop and the 2-cop cases.},
  archive      = {J_TCS},
  author       = {Sebastian Brandt and Yuval Emek and Jara Uitto and Roger Wattenhofer},
  doi          = {10.1016/j.tcs.2020.06.004},
  journal      = {Theoretical Computer Science},
  pages        = {143-163},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A tight lower bound for the capture time of the cops and robbers game},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient card-based zero-knowledge proof for sudoku.
<em>TCS</em>, <em>839</em>, 135–142. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2009, Gradwohl, Naor, Pinkas, and Rothblum proposed physical zero-knowledge proof protocols for Sudoku. That is, for a puzzle instance of Sudoku, their excellent protocols allow a prover to convince a verifier that there is a solution to the Sudoku puzzle and the prover knows it, without revealing any information about the solution. The possible drawback is that the existing protocols have an extractability error with a non-zero probability , or need special cards (such as scratch-off cards). Thus, in this study, we propose new protocols to perform zero-knowledge proof of knowledge for Sudoku using a normal deck of playing cards with no extractability error. Our protocols can be easily implemented by humans with a reasonable number of playing cards.},
  archive      = {J_TCS},
  author       = {Tatsuya Sasaki and Daiki Miyahara and Takaaki Mizuki and Hideaki Sone},
  doi          = {10.1016/j.tcs.2020.05.036},
  journal      = {Theoretical Computer Science},
  pages        = {135-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient card-based zero-knowledge proof for sudoku},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A faster cryptographer’s conspiracy santa. <em>TCS</em>,
<em>839</em>, 122–134. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Conspiracy Santa, a variant of Secret Santa, a group of people offer each other Christmas gifts, where each member of the group receives a gift from the other members of the group. To that end, the members of the group form conspiracies, to decide on appropriate gifts, and usually divide the cost of each gift among all participants of that conspiracy. This requires to settle the shared expenses per conspiracy, so Conspiracy Santa can actually be seen as an aggregation of several shared expenses problems. First, we show that the problem of finding a minimal number of transaction when settling shared expenses is NP-complete. Still, there exist good greedy approximations . Second, we present a greedy distributed secure solution to Conspiracy Santa. This solution allows a group of n people to share the expenses for the gifts in such a way that no participant learns the price of his gift, but at the same time notably reduces the number of transactions to 2 ⋅ n + 1 2⋅n+1 with respect to a naïve aggregation of n ⋅ ( n − 2 ) n⋅(n−2) . Furthermore, our solution does not require a trusted third party, and can either be implemented physically (the participants are in the same room and exchange money using envelopes) or, over Internet, using a cryptocurrency .},
  archive      = {J_TCS},
  author       = {Xavier Bultel and Jannik Dreier and Jean-Guillaume Dumas and Pascal Lafourcade},
  doi          = {10.1016/j.tcs.2020.05.034},
  journal      = {Theoretical Computer Science},
  pages        = {122-134},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A faster cryptographer&#39;s conspiracy santa},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Uniform distribution for pachinko. <em>TCS</em>,
<em>839</em>, 103–121. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pachinko is a Japanese mechanical gambling game similar to pinball. Recently, several mathematical models of Pachinko have been proposed. A number of pins are spiked in a field. A ball drops from the top of the playfield and the ball falls down. In the 50-50 model, if the ball hits a pin, it moves to the left or right passage of the pin with an equal probability . An arrangement of pins generates a distribution of the drop probability for all of the columns. This problem was considered by generating uniform distributions. Previous studies have demonstrated that the ( 1 / 2 a ) (1/2a) -uniform distribution is possible for a ∈ { 0 , 1 , 2 , 3 , 4 } a∈{0,1,2,3,4} and is conjectured so that it is possible for any positive integer a . This study describes the constructive proof for this conjecture. This study also formalizes a natural decision problem yielded by this model while investigating its computational complexity . More precisely, given any drop-probability distribution A and any partial drop-probability distribution B , this study uses non-deterministic polynomial-time (NP) hardness to determine if there exists a pin arrangement that transforms A into B .},
  archive      = {J_TCS},
  author       = {Naoki Kitamura and Yuya Kawabata and Taisuke Izumi},
  doi          = {10.1016/j.tcs.2020.05.032},
  journal      = {Theoretical Computer Science},
  pages        = {103-121},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Uniform distribution for pachinko},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Who witnesses the witness? Finding witnesses in the witness
is hard and sometimes impossible. <em>TCS</em>, <em>839</em>, 41–102.
(<a href="https://doi.org/10.1016/j.tcs.2020.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the computational complexity of the many types of pencil-and-paper-style puzzles featured in the 2016 puzzle video game The Witness . In all puzzles, the goal is to draw a simple path in a rectangular grid graph from a start vertex to a destination vertex . The different puzzle types place different constraints on the path: preventing some edges from being visited (broken edges); forcing some edges or vertices to be visited (hexagons); forcing some cells to have certain numbers of incident path edges (triangles); or forcing the regions formed by the path to be partially monochromatic (squares), have exactly two special cells (stars), or be singly covered by given shapes (polyominoes) and/or negatively counting shapes (antipolyominoes). We show that any one of these clue types (except the first) is enough to make path finding NP-complete (“witnesses exist but are hard to find”), even for rectangular boards. Furthermore, we show that a final clue type (antibody), which necessarily “cancels” the effect of another clue in the same region, makes path finding Σ 2 Σ2 -complete (“witnesses do not exist”), even with a single antibody (combined with many anti/polyominoes), and the problem gets no harder with many antibodies. On the positive side, we give a polynomial-time algorithm for monomino clues, by reducing to hexagon clues on the boundary of the puzzle, even in the presence of broken edges, and solving “subset Hamiltonian path” for terminals on the boundary of an embedded planar graph in polynomial time .},
  archive      = {J_TCS},
  author       = {Zachary Abel and Jeffrey Bosboom and Michael Coulombe and Erik D. Demaine and Linus Hamilton and Adam Hesterberg and Justin Kopinsky and Jayson Lynch and Mikhail Rudoy and Clemens Thielen},
  doi          = {10.1016/j.tcs.2020.05.031},
  journal      = {Theoretical Computer Science},
  pages        = {41-102},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Who witnesses the witness? finding witnesses in the witness is hard and sometimes impossible},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cooperating in video games? Impossible! Undecidability of
team multiplayer games. <em>TCS</em>, <em>839</em>, 30–40. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show the undecidability of whether a team has a forced win in a number of well known video games including: Team Fortress 2, Super Smash Brothers: Brawl, and Mario Kart. To do so, we give a simplification of the Team Computation Game from Hearn and Demaine&#39;s “Games, Puzzles, and Computation” [7] , and use that to give an undecidable abstract game on graphs. This graph game framework better captures the geometry and common constraints in many games and is thus a powerful tool for showing their computational complexity .},
  archive      = {J_TCS},
  author       = {Michael J. Coulombe and Jayson Lynch},
  doi          = {10.1016/j.tcs.2020.05.028},
  journal      = {Theoretical Computer Science},
  pages        = {30-40},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cooperating in video games? impossible! undecidability of team multiplayer games},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tracks from hell — when finding a proof may be easier than
checking it. <em>TCS</em>, <em>839</em>, 21–29. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the popular smartphone game Trainyard: a puzzle game that requires the player to lay down tracks in order to route colored trains from departure stations to suitable arrival stations. While it is already known [Almanza et al., FUN 2016] that the problem of finding a solution to a given Trainyard instance (i.e., game level) is NP-hard, determining the computational complexity of checking whether a candidate solution (i.e., a track layout) solves the level was left as an open problem. In this paper we prove that this verification problem is PSPACE-complete, thus implying that Trainyard players might not only have a hard time finding solutions to a given level, but they might even be unable to efficiently recognize them.},
  archive      = {J_TCS},
  author       = {Matteo Almanza and Stefano Leucci and Alessandro Panconesi},
  doi          = {10.1016/j.tcs.2020.05.027},
  journal      = {Theoretical Computer Science},
  pages        = {21-29},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tracks from hell — when finding a proof may be easier than checking it},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the exact complexity of polyomino packing. <em>TCS</em>,
<em>839</em>, 13–20. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the problem of deciding whether a collection of polyominoes, each fitting in a 2 × O ( log ⁡ n ) 2×O(log⁡n) rectangle, can be packed into a 3 × n 3×n box does not admit a 2 o ( n / log ⁡ n ) 2o(n/log⁡n) -time algorithm, unless the Exponential Time Hypothesis fails. We also give an algorithm that attains this lower bound, solving any instance of polyomino packing with total area n in 2 O ( n / log ⁡ n ) 2O(n/log⁡n) time. This establishes a tight bound on the complexity of Polyomino Packing , even in a very restricted case. In contrast, for a 2 × n 2×n box, we show that the problem can be solved in strongly subexponential time.},
  archive      = {J_TCS},
  author       = {Hans L. Bodlaender and Tom C. van der Zanden},
  doi          = {10.1016/j.tcs.2020.05.025},
  journal      = {Theoretical Computer Science},
  pages        = {13-20},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the exact complexity of polyomino packing},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The power of one evil secret agent. <em>TCS</em>,
<em>839</em>, 1–12. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I am a job. In job-scheduling applications, my friends and I are assigned to machines that can process us. In the last decade, thanks to our strong labor union, and the rise of algorithmic game theory, we are getting more and more freedom regarding our assignment. Each of us acts to minimize his own cost, rather than to optimize a global objective. My goal is different. I am a secret agent operated by the system. I do my best to lead my fellow jobs to an outcome with a high social cost. My naive friends keep doing the best they can, each of them performs his best-response move whenever he gets the opportunity to do so. Luckily, I am a charismatic guy. I can determine the order according to which the naive jobs perform their best-response moves. In this paper, I analyze my power, formalized as the Price of a Traitor (PoT), in cost-sharing scheduling games – in which we need to cover the cost of the machines that process us. Starting from an initial Nash Equilibrium (NE) profile, I join the instance and hurt its stability. A sequence of best-response moves is performed until I vanish, leaving the naive jobs in a new NE. For an initial NE assignment, S 0 S0 , the PoT measures the ratio between the social cost of a worst NE I can lead the jobs to, starting from S 0 S0 , and the social cost of S 0 S0 . The PoT of a game is the maximal such ratio among all game instances and initial NE assignments. My analysis distinguishes between instances with unit- and arbitrary-cost machines, and instances with unit- and arbitrary-length jobs. I give exact bounds on the PoT for each setting, in general and in symmetric games. While it turns out that in most settings my power is really impressive, my task is computationally hard (and also hard to approximate).},
  archive      = {J_TCS},
  author       = {Tami Tamir},
  doi          = {10.1016/j.tcs.2020.05.021},
  journal      = {Theoretical Computer Science},
  pages        = {1-12},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The power of one evil secret agent},
  volume       = {839},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact algorithms for the repetition-bounded longest common
subsequence problem. <em>TCS</em>, <em>838</em>, 238–249. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study exact, exponential-time algorithms for a variant of the classic Longest Common Subsequence problem called the Repetition-Bounded Longest Common Subsequence problem (or RBLCS , for short): Let an alphabet S be a finite set of symbols and an occurrence constraint C o c c Cocc be a function C o c c : S → N Cocc:S→N , assigning an upper bound on the number of occurrences of each symbol in S . Given two sequences X and Y over the alphabet S and an occurrence constraint C o c c Cocc , the goal of RBLCS is to find a longest common subsequence of X and Y such that each symbol s ∈ S s∈S appears at most C o c c ( s ) Cocc(s) times in the obtained subsequence. The special case where C o c c ( s ) = 1 Cocc(s)=1 for every symbol s ∈ S s∈S is known as the Repetition-Free Longest Common Subsequence problem ( RFLCS ) and has been studied previously; e.g., in [1] , Adi et al. presented a simple (exponential-time) exact algorithm for RFLCS . However, they did not analyze its time complexity in detail, and to the best of our knowledge, there are no previous results on the running times of any exact algorithms for this problem. Without loss of generality, we will assume that | X | ≤ | Y | |X|≤|Y| and | X | = n |X|=n . In this paper, we first propose a simpler algorithm for RFLCS based on the strategy used in [1] and show explicitly that its running time is O ( 1.44225 n ) O(1.44225n) . Next, we provide a dynamic programming (DP) based algorithm for RBLCS and prove that its running time is O ( 1.44225 n ) O(1.44225n) for any occurrence constraint C o c c Cocc , and even less in certain special cases. In particular, for RFLCS , our DP-based algorithm runs in O ( 1.41422 n ) O(1.41422n) time, which is faster than the previous one. Furthermore, we prove NP-hardness and APX-hardness results for RBLCS on restricted instances.},
  archive      = {J_TCS},
  author       = {Yuichi Asahiro and Jesper Jansson and Guohui Lin and Eiji Miyano and Hirotaka Ono and Tadatoshi Utashima},
  doi          = {10.1016/j.tcs.2020.07.042},
  journal      = {Theoretical Computer Science},
  pages        = {238-249},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Exact algorithms for the repetition-bounded longest common subsequence problem},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for the partial assignment problem.
<em>TCS</em>, <em>838</em>, 231–237. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the partial assignment problem, a seller has an item set M = { i 1 , i 2 , … , i m } M={i1,i2,…,im} , the amount of each item is exactly one. There are n buyers N = { b 1 , b 2 , . . . , b n } N={b1,b2,...,bn} , each buyer b p bp has a preferred bundle B p ⊆ M Bp⊆M and a value function f p ( ⋅ ) fp(⋅) . Assume that each item should be sold integrally and thus can be only assigned to at most one buyer. In previous works, buyers are often considered to be single-minded, i.e., a buyer can be either assigned the whole preferred bundle, or nothing. In this paper, we consider a more generalized and realistic model where the buyer can be partially satisfied, i.e., buyer b p bp can have some positive value if the seller assigns a subset of b p bp &#39;s preferred bundle. However, there might be exponential number of subsets, to tackle this situation, a value oracle is implemented. We can get the value f p ( S p ) fp(Sp) for buyer b p bp and S p ⊆ B p Sp⊆Bp by querying the value oracle. The objective is to assign items to buyers such that the total values are maximized, i.e., max ⁡ ∑ p = 1 n f p ( S p ) max⁡∑p=1nfp(Sp) . We first show that in this model, maximizing the total values is NP-hard. We then propose provably efficient approximation algorithms for general and submodular value functions respectively. If the value function satisfies non-negative, monotone and normalized, an 1 / m 1/m -approximation algorithm can be achieved. If the value function is submodular, the total values can be approximated within a factor of ( 1 − 1 / e ) (1−1/e) .},
  archive      = {J_TCS},
  author       = {Guichen Gao and Li Ning and Hing-Fung Ting and Yicheng Xu and Yong Zhang and Yifei Zou},
  doi          = {10.1016/j.tcs.2020.07.041},
  journal      = {Theoretical Computer Science},
  pages        = {231-237},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithms for the partial assignment problem},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Improved bounds for two query adaptive bitprobe schemes
storing five elements. <em>TCS</em>, <em>838</em>, 208–230. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study two-bitprobe adaptive schemes storing five elements. For this class of schemes, the best known lower bound is Ω ( m 1 / 2 ) Ω(m1/2) due to Alon and Feige [1] . Recently, it was proved by Kesh [2] that two-bitprobe adaptive schemes storing three elements will take at least Ω ( m 2 / 3 ) Ω(m2/3) space, which also puts a lower bound on schemes storing five elements. In this work, we have improved the lower bound to Ω ( m 3 / 4 ) Ω(m3/4) . We also present a scheme for the same that takes O ( m 5 / 6 ) O(m5/6) space. This improves upon the O ( m 18 / 19 ) O(m18/19) -scheme due to Garg [3] and the O ( m 10 / 11 ) O(m10/11) -scheme due to Baig et al. [4] .},
  archive      = {J_TCS},
  author       = {Mirza Galib Anwarul Husain Baig and Deepanjan Kesh},
  doi          = {10.1016/j.tcs.2020.07.036},
  journal      = {Theoretical Computer Science},
  pages        = {208-230},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved bounds for two query adaptive bitprobe schemes storing five elements},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recognizing the tractability in big data computing.
<em>TCS</em>, <em>838</em>, 195–207. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the limitation on computational power of existing computers, the polynomial time does not work for identifying the tractable problems in big data computing. This paper adopts the sublinear time as the new standard to recognize the tractability in big data computing and study tractable problems in terms of computational complexity theory. The random-access Turing machine is used as the computational model to characterize the problems that are tractable on big data. First, pure tractable class PT is proposed and two important classes within it, PPL and PDP , are studied. The structures of this two pure tractable classes are deeply investigated and they are proved PPL i ⊊ PPL i + 1 PPLi⊊PPLi+1 , PPL ⊊ PT PPL⊊PT and PDP k + 1 ⊊ PDP k ⊊ PT PDPk+1⊊PDPk⊊PT . Then, pseudo-tractable class PsT is proposed and is partitioned into two classes, PsTR and PsTE , according to preprocessing techniques. The relations among pseudo-tractable classes and other complexity classes are investigated and they are proved that PsT ⊆ P PsT⊆P and . Finally, we show that PPL is closed under DLOGTIME reduction.},
  archive      = {J_TCS},
  author       = {Xiangyu Gao and Jianzhong Li and Dongjing Miao and Xianmin Liu},
  doi          = {10.1016/j.tcs.2020.07.026},
  journal      = {Theoretical Computer Science},
  pages        = {195-207},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Recognizing the tractability in big data computing},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The efficiency of nash equilibria in the load balancing game
with a randomizing scheduler. <em>TCS</em>, <em>838</em>, 180–194. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the efficiency of Nash equilibria for the load balancing game with a randomizing scheduler. In the game, we are given a set of facilities and a set of players along with a scheduler, where each facility is associated with a linear cost function, and the players are randomly ordered by the scheduler. Each player chooses exactly one of these facilities to fulfill his task, which incurs to him a cost depending on not only the cost function of the facility he chooses and the players who choose the same facility (as in a usual load balancing game), but also his uncertain position in the uniform random ordering. From an individual perspective, each player tries to choose a facility for optimizing his own objective that is determined by a certain decision-making principle. From a system perspective, it is desirable to minimize the maximum cost among all players, which is a commonly used criterion for load balancing. We estimate the price of anarchy and price of stability for this class of load balancing games under uncertainty, provided all players follow one of the four decision-making principles, namely the bottom-out, win-or-go-home, minimum-expected-cost, and minimax-regret principles. Our results show that the efficiency loss of Nash equilibria in these decentralized environments heavily rely on player&#39;s attitude toward the uncertainty.},
  archive      = {J_TCS},
  author       = {Xujin Chen and Xiaodong Hu and Chenhao Wang and Xiaoying Wu},
  doi          = {10.1016/j.tcs.2020.07.024},
  journal      = {Theoretical Computer Science},
  pages        = {180-194},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The efficiency of nash equilibria in the load balancing game with a randomizing scheduler},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hardness and efficiency on minimizing maximum distances in
spanning trees. <em>TCS</em>, <em>838</em>, 168–179. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The t -admissibility problem aims to decide whether a graph G has a spanning tree T in which the distance between any two adjacent vertices of G is at most t . Regarding its optimization version, the smallest t for which G is t -admissible is the stretch index of G , denoted by σ T ( G ) σT(G) . The problem of deciding whether σ T ( G ) ≤ t σT(G)≤t , t ≥ 4 t≥4 is NP NP -complete and polynomial-time solvable for t = 2 t=2 . However, deciding if t = 3 t=3 is an open problem. We determine 3-admissible graph classes by studying graphs with few P 4 P4 &#39;s, and we partially classify the P P vs NP NP -complete dichotomy of the t -admissibility problem for ( k , ℓ ) (k,ℓ) -graphs. These graph classes generalize some others in which the computational complexity of the t -admissibility problem was already determined. Moreover, we determine the stretch index for cycle-power graphs and for ( 2 , 1 ) (2,1) -chordal graphs, which are subclasses of ( k , ℓ ) (k,ℓ) -graphs and the t -admissibility problem is NP NP -complete.},
  archive      = {J_TCS},
  author       = {Fernanda Couto and Luís Felipe I. Cunha},
  doi          = {10.1016/j.tcs.2020.06.012},
  journal      = {Theoretical Computer Science},
  pages        = {168-179},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hardness and efficiency on minimizing maximum distances in spanning trees},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Approximation algorithm for minimum weight
connected-k-subgraph cover. <em>TCS</em>, <em>838</em>, 160–167. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a given graph G , the minimum weight connected- k -subgraph cover problem (MinWC k SC) is to find a minimum weight vertex subset C of G such that each connected subgraph of G on k vertices contains at least one vertex of C . Previously, Zhang et al. [37] presented a ( k − 1 ) (k−1) -approximation algorithm for MinWC k SC under the assumption that the girth of G , which is the length of a shortest cycle of G , is at least k . In this paper, we improve this result by showing that ( k − 1 ) (k−1) -approximation can be achieved when the girth requirement is relaxed from k to 2 k / 3 2k/3 .},
  archive      = {J_TCS},
  author       = {Pengcheng Liu and Zhao Zhang and Xiaohui Huang},
  doi          = {10.1016/j.tcs.2020.05.043},
  journal      = {Theoretical Computer Science},
  pages        = {160-167},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithm for minimum weight connected-k-subgraph cover},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The one-round multi-player discrete voronoi game on grids
and trees. <em>TCS</em>, <em>838</em>, 143–159. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basing on the two-player Voronoi game introduced by Ahn et al. [1] and the multi-player diffusion game introduced by Alon et al. [2] , we investigate the following one-round multi-player discrete Voronoi game on grids and trees. There are n players playing this game on a graph G=(V,E) . Each player chooses an initial vertex from the vertex set of the graph and tries to maximize the size of the nearest vertex set. As the main result, we give sufficient conditions for the existence/non-existence of a pure-strategy Nash equilibrium in 4-player games on grids and only a constant gap leaves unknown. We further consider this game with more than 4 players and construct a family of strategy profiles, which are pure-strategy Nash equilibria on sufficiently narrow graphs. Besides, we investigate the game with 3 players on trees and design a linear time/space algorithm to decide the existence of a pure-strategy Nash equilibrium .},
  archive      = {J_TCS},
  author       = {Xiaoming Sun and Yuan Sun and Zhiyu Xia and Jialin Zhang},
  doi          = {10.1016/j.tcs.2020.06.028},
  journal      = {Theoretical Computer Science},
  pages        = {143-159},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The one-round multi-player discrete voronoi game on grids and trees},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic data structures for interval coloring. <em>TCS</em>,
<em>838</em>, 126–142. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the dynamic graph coloring problem restricted to the class of interval graphs in the incremental and fully dynamic setting. The input consists of a sequence of intervals that are to be either colored, or deleted, if previously colored. For the incremental setting, we consider the well studied optimal online algorithm (KT-algorithm) for interval coloring due to Kierstead and Trotter [1] . We present the following results on the dynamic interval coloring problem.},
  archive      = {J_TCS},
  author       = {Girish Raguvir J. and Manas Jyoti Kashyop and N.S. Narayanaswamy},
  doi          = {10.1016/j.tcs.2020.06.024},
  journal      = {Theoretical Computer Science},
  pages        = {126-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dynamic data structures for interval coloring},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Target users’ activation probability maximization with
different seed set constraints in social networks. <em>TCS</em>,
<em>838</em>, 111–125. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization (IM) over the online social networks have been widely explored in recent years, which selects a seed set from nodes in the network using a limited budget such that the expected number of nodes influenced by the seed set is maximized. However, how to activate a considered set of targeting users T T , e.g., selling a product to a specific target group, is a more practical problem. To address this problem, we respectively propose the Target Users&#39; Activation Probability Maximization with Constraint (TUAPM-WC) problem and the Target Users&#39; Activation Probability Maximization without Constraint (TUAPM-WOC) problem, i.e., to select a seed set S with/without size constraints such that the activation probabilities of the target users in T T are maximized. Considering that the influence will decay during information propagation, we propose a novel and practical Influence Decay Model (IDM) as the information diffusion model . Based on the IDM, we show that the TUAPM-WC and the TUAPM-WOC problems are NP-hard. We also prove that the objective functions of TUAPM-WC and TUAPM-WOC problems are monotone non-decreasing and submodular. On one hand, we employ a Double Greedy Algorithm (DGA) to guarantee a (1/3)-approximation ratio for TUAPM-WOC problem when | S | |S| is unconstrained. On the other hand, we propose a series of algorithms to solve the TUAPM-WC when | S | ≤ b |S|≤b , where b is a positive integer. More specifically, we provide a ( 1 − 1 / e 1−1/e )-approximation Basic Greedy Algorithm (BGA). Furthermore, a speed-up Scalable Algorithm (SA) is proposed for online large social networks. Finally, we run our algorithms by simulations on synthetic and real-life social networks to evaluate the effectiveness and efficiency of the proposed algorithms. Experimental results validate our algorithms&#39; superior to the comparison algorithms.},
  archive      = {J_TCS},
  author       = {Ruidong Yan and Hongwei Du and Yi Li and Wenping Chen and Yongcai Wang and Yuqing Zhu and Deying Li},
  doi          = {10.1016/j.tcs.2020.06.008},
  journal      = {Theoretical Computer Science},
  pages        = {111-125},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Target users&#39; activation probability maximization with different seed set constraints in social networks},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lower bounds for the happy coloring problems. <em>TCS</em>,
<em>838</em>, 94–110. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the Maximum Happy Vertices and the Maximum Happy Edges problems (MHV and MHE for short). Very recently, the problems attracted a lot of attention and were studied in Agrawal &#39;18, Aravind et al. &#39;16, Choudhari and Reddy &#39;18, Misra and Reddy &#39;18. Main focus of our work is lower bounds on the computational complexity of these problems. Established lower bounds can be divided into the following groups: NP-hardness of the above guarantee parameterization, kernelization lower bounds (answering questions of Misra and Reddy &#39;18), exponential lower bounds under the Set Cover Conjecture and the Exponential Time Hypothesis , and inapproximability results. Moreover, we present an ⁎ O ⁎ ( ℓ k ) O⁎(ℓk) randomized algorithm for MHV and an ⁎ O ⁎ ( 2 k ) O⁎(2k) algorithm for MHE, where ℓ is the number of colors used and k is the number of required happy vertices or edges. These algorithms cannot be improved to subexponential taking proved lower bounds into account.},
  archive      = {J_TCS},
  author       = {Ivan Bliznets and Danil Sagunov},
  doi          = {10.1016/j.tcs.2020.06.005},
  journal      = {Theoretical Computer Science},
  pages        = {94-110},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lower bounds for the happy coloring problems},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On 1-factorizations of bipartite kneser graphs.
<em>TCS</em>, <em>838</em>, 81–93. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a challenging open problem to construct an explicit 1-factorization of the bipartite Kneser graph H(v,t) , which contains as vertices all t -element and (v−t) -element subsets of [v]:={1,…,v} (where v&amp;gt;2t ) and an edge between any two vertices when one is a subset of the other. In this paper, for the special case where t=2 and v is an odd prime power, we construct such 1-factorizations using perpendicular arrays. We also revisit two known 1-factorizations of H(2t+1,t) – the lexical factorization and modular factorization . Among other results, we give interesting alternative definitions of these 1-factorizations and design an optimal algorithm for computing the lexical factorization.},
  archive      = {J_TCS},
  author       = {Kai Jin},
  doi          = {10.1016/j.tcs.2020.06.003},
  journal      = {Theoretical Computer Science},
  pages        = {81-93},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On 1-factorizations of bipartite kneser graphs},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sensitivity, affine transforms and quantum communication
complexity. <em>TCS</em>, <em>838</em>, 68–80. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the Boolean function parameters sensitivity ( s s ), block sensitivity ( bs bs ), and alternation ( alt alt ) under specially designed affine transforms and show several applications. For a function f : F 2 n → { − 1 , 1 } f:F2n→{−1,1} , and A = M x + b A=Mx+b for M ∈ F 2 n × n M∈F2n×n and b ∈ F 2 n b∈F2n , the result of the transformation g is defined as ∀ x ∈ F 2 n , g ( x ) = f ( M x + b ) ∀x∈F2n,g(x)=f(Mx+b) . As a warm up, we study alternation under linear shifts (when M is restricted to be the identity matrix) called the shift invariant alternation (the smallest alternation that can be achieved for the Boolean function f by shifts, denoted by salt ( f ) salt(f) ). By a result of Lin and Zhang (2017) [7] , it follows that bs ( f ) ≤ O ( salt ( f ) 2 s ( f ) ) bs(f)≤O(salt(f)2s(f)) . Thus, to settle the Sensitivity Conjecture ( ∀ f , bs ( f ) ≤ poly ( s ( f ) ) ∀f,bs(f)≤poly(s(f)) ), it suffices to argue that ∀ f , salt ( f ) ≤ poly ( s ( f ) ) ∀f,salt(f)≤poly(s(f)) . However, we exhibit an explicit family of Boolean functions for which salt ( f ) salt(f) is 2 Ω ( s ( f ) ) 2Ω(s(f)) . Going further, we use an affine transform A , such that the corresponding function g satisfies bs ( f , 0 n ) ≤ s ( g ) bs(f,0n)≤s(g) . We apply this in the setting of quantum communication complexity to prove that for F ( x , y ) = def f ( x ∧ y ) F(x,y)=deff(x∧y) , the bounded error quantum communication complexity of F with prior entanglement, ⁎ Q 1 / 3 ⁎ ( F ) Q1/3⁎(F) is Ω ( bs ( f , 0 n ) ) Ω(bs(f,0n)) . Our proof builds on ideas from Sherstov (2010) [17] where we use specific properties of the above affine transformation. Using this, we show the following.},
  archive      = {J_TCS},
  author       = {Krishnamoorthy Dinesh and Jayalal Sarma},
  doi          = {10.1016/j.tcs.2020.05.048},
  journal      = {Theoretical Computer Science},
  pages        = {68-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Sensitivity, affine transforms and quantum communication complexity},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MpUFLP: Universal facility location problem in the p-th
power of metric space. <em>TCS</em>, <em>838</em>, 58–67. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and study the M p UFLP (universal facility location problem in the p -th power of metric space) in this paper, where the universal facility location problem (UFLP) extends several classical facility location problems like the uncapacitated facility location, hard-capacitated facility location, soft-capacitated facility location, incremental-cost facility location, concave-cost facility location, etc. In UFLP, a set of facilities, a set of clients, as well as the distances between them are given. Each facility has its specific cost function w.r.t. the amount of clients assigned to that facility. The goal is to assign the clients to facilities such that the sum of facility cost and service cost is minimized. In traditional facility location problems, the unit service cost is proportional to the distance between the client and its assigned facility and thus metric. However, in our work, this assumption is removed and a generalized version of universal facility location problem is proposed, which is the so-called M n UFLP. When p = 2 p=2 , it is also known as l 2 2 l22 measure considered by Jain and Vazirani [J. ACM&#39;01] and Fernandes et al. [Math. Program.&#39;15]. Particularly in this case, we extend their work to include the aforementioned variants of facility location and a local search based ( 11.18 + ε ) (11.18+ε) -approximation algorithm is proposed. Furthermore, the reanalysis of the proposed algorithm gives a p -related performance guarantee for general p .},
  archive      = {J_TCS},
  author       = {Yicheng Xu and Dachuan Xu and Yong Zhang and Juan Zou},
  doi          = {10.1016/j.tcs.2020.05.038},
  journal      = {Theoretical Computer Science},
  pages        = {58-67},
  shortjournal = {Theor. Comput. Sci.},
  title        = {MpUFLP: Universal facility location problem in the p-th power of metric space},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Diameter of colorings under kempe changes. <em>TCS</em>,
<em>838</em>, 45–57. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a k -coloring of a graph G , a Kempe-change for two colors a and b produces another k -coloring of G , as follows: first choose a connected component in the subgraph of G induced by the two color classes of a and b , and then swap the colors a and b in the component. Two k -colorings are called Kempe-equivalent if one can be transformed into the other by a sequence of Kempe-changes. We consider two problems, defined as follows: First, given two k -colorings of a graph G , Kempe Reachability asks whether they are Kempe-equivalent; and second, given a graph G and a positive integer k , Kempe Connectivity asks whether any two k -colorings of G are Kempe-equivalent. We analyze the complexity of these problems from the viewpoint of graph classes. We prove that Kempe Reachability is PSPACE PSPACE -complete for any fixed k ≥ 3 k≥3 , and that it remains PSPACE PSPACE -complete even when restricted to three colors and planar graphs of maximum degree six. Furthermore, we show that both problems admit polynomial-time algorithms on chordal graphs , bipartite graphs , and cographs. For each of these graph classes, we give a non-trivial upper bound on the number of Kempe-changes needed in order to certify that two k -colorings are Kempe-equivalent.},
  archive      = {J_TCS},
  author       = {Marthe Bonamy and Marc Heinrich and Takehiro Ito and Yusuke Kobayashi and Haruka Mizuta and Moritz Mühlenthaler and Akira Suzuki and Kunihiro Wasa},
  doi          = {10.1016/j.tcs.2020.05.033},
  journal      = {Theoretical Computer Science},
  pages        = {45-57},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Diameter of colorings under kempe changes},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A sound and complete proof system for a unified temporal
logic. <em>TCS</em>, <em>838</em>, 25–44. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theorem proving is one of the most widely used approaches to the verification of computer systems, and its theoretical basis is generally a proof system for formal derivation of logic formulas. In this paper, we propose a sound and complete proof system for Propositional Projection Temporal Logic (PPTL) with indexed expressions, which is a unified temporal logic that subsumes the well used Linear Temporal Logic (LTL). First, the syntax, semantics and logic laws of PPTL that allows indexed expressions are introduced, and the representation of LTL constructs by PPTL formulas is illustrated. Then, the proof system for the logic is presented which consists of axioms and inference rules for the derivation of both basic constructs and indexed expressions. To show the capability of the proof system, several examples of formal proofs are provided. Finally, the soundness and completeness of the proof system are demonstrated.},
  archive      = {J_TCS},
  author       = {Liang Zhao and Xiaobing Wang and Xinfeng Shu and Nan Zhang},
  doi          = {10.1016/j.tcs.2020.05.015},
  journal      = {Theoretical Computer Science},
  pages        = {25-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A sound and complete proof system for a unified temporal logic},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local search is a PTAS for feedback vertex set in minor-free
graphs. <em>TCS</em>, <em>838</em>, 17–24. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that an extremely simple local search gives a PTAS for the Feedback Vertex Set (FVS) problem in minor-free graphs. It keeps exchanging a constant number of vertices to improve the current solution until a local optimum is reached. The previous PTAS by Fomin, Lokshtanov, Raman and Saurabh [1] , despite theoretical efficiency, is much more complicated in the sense that it combines many advanced algorithmic tools such as contraction decomposition framework by Demaine and Hajiaghayi [2] , Courcelle&#39;s theorem [3] and the Robertson and Seymour decomposition [4] . Our main technical contribution is to show that the local optimum only differs the global optimum by a ( 1 + ϵ ) factor. We do so by introducing Steiner points, those who are not in the local and optimal solutions, to the standard analysis of local search. We believe that our technique is of independent interest.},
  archive      = {J_TCS},
  author       = {Hung Le and Baigong Zheng},
  doi          = {10.1016/j.tcs.2020.05.010},
  journal      = {Theoretical Computer Science},
  pages        = {17-24},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Local search is a PTAS for feedback vertex set in minor-free graphs},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient decision procedure for propositional projection
temporal logic. <em>TCS</em>, <em>838</em>, 1–16. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decision problem for Propositional Projection Temporal Logic (PPTL) has been solved successfully, however time complexity of the procedure is increased exponentially to the length of the formula. To solve the problem, a labeled unified complete normal form is introduced as the intermediate form to rewrite a PPTL formula into its equivalent labeled normal form, based on which the labeled normal form graph is constructed, and an efficient decision procedure for PPTL is formalized with the time complexity linear to the length of the formula and the size of the power set of the atomic propositions in the formula. Besides, an example is given to show how the improved decision procedure works.},
  archive      = {J_TCS},
  author       = {Xinfeng Shu and Nan Zhang and Xiaobing Wang and Liang Zhao},
  doi          = {10.1016/j.tcs.2020.05.009},
  journal      = {Theoretical Computer Science},
  pages        = {1-16},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient decision procedure for propositional projection temporal logic},
  volume       = {838},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the axiomatisability of priority III: Priority strikes
again. <em>TCS</em>, <em>837</em>, 223–246. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aceto et al., proved that, over the process algebra BCCSP with the priority operator of Baeten, Bergstra and Klop, the equational theory of order-insensitive bisimilarity is not finitely based. However, it was noticed that by substituting the action prefixing operator of BCCSP with BPA&#39;s sequential composition , the infinite family of equations used to show that non-finite axiomatisability result could be proved by a finite collection of sound equations. That observation left as an open question the existence of a finite axiomatisation for order-insensitive bisimilarity over BPA with the priority operator. In this paper we provide a negative answer to this question. We prove that, in the presence of at least two actions, order-insensitive bisimilarity is not finitely based over BPA with priority.},
  archive      = {J_TCS},
  author       = {Luca Aceto and Elli Anastasiadi and Valentina Castiglioni and Anna Ingólfsdóttir and Bas Luttik and Mathias Ruggaard Pedersen},
  doi          = {10.1016/j.tcs.2020.07.044},
  journal      = {Theoretical Computer Science},
  pages        = {223-246},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the axiomatisability of priority III: Priority strikes again},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). First-order interpolation derived from propositional
interpolation. <em>TCS</em>, <em>837</em>, 209–222. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a general methodology to connect propositional and first-order interpolation. In fact, the existence of suitable skolemizations and of Herbrand expansions together with a propositional interpolant suffice to construct a first-order interpolant. This methodology is realized for lattice-based finitely-valued logics, the top element representing true. It is shown that interpolation is decidable for these logics.},
  archive      = {J_TCS},
  author       = {Matthias Baaz and Anela Lolic},
  doi          = {10.1016/j.tcs.2020.07.043},
  journal      = {Theoretical Computer Science},
  pages        = {209-222},
  shortjournal = {Theor. Comput. Sci.},
  title        = {First-order interpolation derived from propositional interpolation},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on “posets having continuous interval.” <em>TCS</em>,
<em>837</em>, 207–208. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note we present a counterexample for a result in [2] , where the concept of continuous interval posets (CI-posets for short) was introduced. A CI-poset is a poset in which every nonempty interval [ x , y ] [x,y] is a continuous poset (in the restricted order) and the above mentioned result is about continuous functions spaces [ X ⟶ P ] [X⟶P] , where X is a core compact topological space and P is a CI-poset (with its Scott topology).},
  archive      = {J_TCS},
  author       = {Jarafe Abdala and Fagner Santana},
  doi          = {10.1016/j.tcs.2020.06.025},
  journal      = {Theoretical Computer Science},
  pages        = {207-208},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A note on “Posets having continuous interval”},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized abstraction-refinement for game-based CTL lifted
model checking. <em>TCS</em>, <em>837</em>, 181–206. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System families (Software Product Lines) are becoming omnipresent in application areas ranging from embedded system domains to system-level software and communication protocols. Software Product Line methods and architectures allow effective building many custom variants of a software system in these domains. In many of the applications, their rigorous verification and quality assurance are of paramount importance. Lifted model checking for system families is capable of verifying all their variants simultaneously in a single run by exploiting the similarities between the variants. The computational cost of lifted model checking still greatly depends on the number of variants (the size of configuration space), which is often huge. Variability abstractions have successfully addressed this configuration space explosion problem, giving rise to smaller abstract variability models with fewer abstract configurations. Abstract variability models are given as modal transition systems, which contain may (over-approximating) and must (under-approximating) transitions. Thus, they preserve both universal and existential CTL properties. In this work, we bring two main contributions. First, we define a novel game-based approach for variability-specific abstraction and refinement for lifted model checking of the full CTL, interpreted over 3-valued semantics. We propose a direct algorithm for solving a 3-valued (abstract) lifted model checking game. In case the result of model checking an abstract variability model is indefinite, we suggest a new notion of refinement, which eliminates indefinite results. This provides an iterative incremental variability-specific abstraction and refinement framework, where refinement is applied only where indefinite results exist and definite results from previous iterations are reused. Second, we propose a new generalized definition of abstract variability models, given as so-called generalized modal transition systems, by introducing the notion of (must) hyper-transitions. This results in more precise abstract models in which more CTL formulae can be proved or disproved. We integrate the newly defined generalized abstract variability models in the existing abstraction-refinement framework for game-based lifted model checking of CTL. Finally, we evaluate the practicality of this approach on several system families.},
  archive      = {J_TCS},
  author       = {Aleksandar S. Dimovski and Axel Legay and Andrzej Wasowski},
  doi          = {10.1016/j.tcs.2020.06.011},
  journal      = {Theoretical Computer Science},
  pages        = {181-206},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Generalized abstraction-refinement for game-based CTL lifted model checking},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Causality analysis and fault ascription in component-based
systems. <em>TCS</em>, <em>837</em>, 158–180. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a general framework for fault ascription , which consists in identifying, within a multi-component system, the components whose faulty behavior has caused the failure of said system. Our framework uses configuration structures as a general semantical model to handle truly concurrent executions, partial and distributed observations in a uniform way. As a first contribution, and in contrast with most of the current literature on counterfactual analysis which relies heavily on a set of toy examples, we first define a set of expected formal properties for counterfactual builders , i.e. operators that build counterfactual executions. We then show that causality analyses that satisfy our requirements meet a set of elementary soundness and completeness properties. Finally we present a concrete causality analysis meeting all our requirements, and we show that it behaves well under refinement. We present several examples illustrating various phenomena such as causal over-determination or observational determinism, and we discuss the relationship of our approach with Halpern and Pearl&#39;s actual causality analysis.},
  archive      = {J_TCS},
  author       = {Gregor Gössler and Jean-Bernard Stefani},
  doi          = {10.1016/j.tcs.2020.06.010},
  journal      = {Theoretical Computer Science},
  pages        = {158-180},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Causality analysis and fault ascription in component-based systems},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Counting and enumerating preferred database repairs.
<em>TCS</em>, <em>837</em>, 115–157. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In its traditional definition, a repair of an inconsistent database is a consistent database that differs from the inconsistent one in a “minimal way.” Often, repairs are not equally legitimate, as it is desired to prefer one over another; for example, one fact is regarded more reliable than another, or a more recent fact should be preferred to an earlier one. Motivated by these considerations, researchers have introduced and investigated the framework of preferred repairs, in the context of denial constraints and subset repairs. There, a priority relation between facts is lifted towards a priority relation between consistent databases, and repairs are restricted to the ones that are optimal in the lifted sense. Three notions of lifting (and preferred repairs) have been proposed: Pareto, global, and completion. In this article, we investigate the complexity of three problems on preferred repairs. The first is the problem of deciding whether the priority relation contains enough information to clean the database unambiguously, or in other words, whether there is exactly one preferred repair. We show that the different lifting semantics entail highly different complexities for this problem. Then, we study the ability to quantify ambiguity, by investigating two classes of problems. The first is that of counting the preferred repairs. We establish a dichotomy in data complexity for the entire space of (sets of) functional dependencies for all three notions. The second class of problems is that of enumerating (i.e., generating) the preferred repairs. We devise enumeration algorithms with efficiency guarantees on the delay between generated repairs, even for constraints represented as general conflict graphs or hypergraphs .},
  archive      = {J_TCS},
  author       = {Benny Kimelfeld and Ester Livshits and Liat Peterfreund},
  doi          = {10.1016/j.tcs.2020.05.016},
  journal      = {Theoretical Computer Science},
  pages        = {115-157},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Counting and enumerating preferred database repairs},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general theory of concept lattice with tractable
implication exploration. <em>TCS</em>, <em>837</em>, 84–114. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work develops the general concept lattice for the problem concerning categorisation of objects according to their properties. Unlike the conventional approaches, such as the formal concept lattice and the rough set lattice, the general concept lattice is designed to adhere to the general principle that the information content should be invariant regardless how the variables/parameters are presented. Here, one will explicitly demonstrate the existence of such a construction by a sequence of fulfilments compatible with the conventional lattice structure. The general concept lattice promises to be a comprehensive categorisation for all the distinctive object classes according to whatever properties they are equipped with. It will be shown that one can always regain the formal concept lattice and rough set lattice from the general concept lattice. One also speaks of the tractability of the general concept lattice for both its lattice structure and logical content . The general concept lattice permits a feasible construction that can be completed in a single scan of the formal context, though the conventional formal-concept lattice and rough-set lattice can be regained from the general concept lattice. The logic implication deducible from the general concept lattice takes the form of μ 1 → μ 2 μ1→μ2 where μ 1 , μ 2 ∈ M ⁎ ⁎ μ1,μ2∈M⁎ are composite attributes out of the concerned formal attributes M . Remarkable is that with a single formula based on the contextual truth 1 η 1η one can deduce all the implication relations extractable from the formal context. For concreteness, it can be shown that any implication A → B A→B ( A , B A,B being subsets of the formal attributes M ) discussed in the formal-concept lattice corresponds to a special case of μ 1 → μ 2 μ1→μ2 by means of μ 1 = ∏ A μ1=∏A and μ 2 = ∏ B μ2=∏B . Thus, one may elude the intractability due to searching for the Guigues-Duquenne basis appropriate for the implication relations deducible from the formal-concept lattice. Likewise, one may identify those μ 1 → μ 2 μ1→μ2 where μ 1 = ∑ A μ1=∑A and μ 2 = ∑ B μ2=∑B with the implications that can be acquired from the rough-set lattice. (Here, the product ∏ stands for the conjunction and the summation ∑ the disjunction.)},
  archive      = {J_TCS},
  author       = {Tsong-Ming Liaw and Simon C. Lin},
  doi          = {10.1016/j.tcs.2020.05.014},
  journal      = {Theoretical Computer Science},
  pages        = {84-114},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A general theory of concept lattice with tractable implication exploration},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Expressiveness of concurrent intensionality. <em>TCS</em>,
<em>837</em>, 54–83. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expressiveness of communication primitives has been explored in a common framework based on the π -calculus by considering four features: synchronism (asynchronous vs synchronous), arity (monadic vs polyadic data), communication medium (shared dataspaces vs channel-based), and pattern-matching (binding to a name vs testing name equality). Here pattern-matching is generalised to account for terms with internal structure such as in recent calculi like Spi calculi, Concurrent Pattern Calculus and Psi calculi. This paper explores intensionality , a feature that extends pattern-matching to allow communication primitives to interact by also matching on the structure of terms. By means of possibility/impossibility of encodings, this paper shows that intensionality alone can encode synchronism, arity, communication-medium, and pattern-matching, yet no combination of these without intensionality can encode any intensional language. Further, some languages may also be non-linear, where two inputs must be equal to allow interaction. This paper also explores all the relations between linear and non-linear variations of the above languages.},
  archive      = {J_TCS},
  author       = {Ioana Cristescu and Thomas Given-Wilson and Axel Legay},
  doi          = {10.1016/j.tcs.2020.05.007},
  journal      = {Theoretical Computer Science},
  pages        = {54-83},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Expressiveness of concurrent intensionality},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A type-assignment of linear erasure and duplication.
<em>TCS</em>, <em>837</em>, 26–53. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce LEM LEM , a type-assignment system for the linear λ -calculus that extends second-order IMLL 2 IMLL2 , i.e., intuitionistic multiplicative Linear Logic, by means of logical rules that weaken and contract assumptions, but in a purely linear setting. LEM LEM enjoys both a mildly weakened cut-elimination, whose computational cost is cubic, and Subject reduction. A translation of LEM LEM into IMLL 2 IMLL2 exists such that the derivations of the former can exponentially compress the dimension of the derivations in the latter. LEM LEM allows for a modular and compact representation of boolean circuits , directly encoding the fan-out nodes, by means of contraction, and disposing garbage, by means of weakening. It can also represent natural numbers with terms very close to standard Church numerals which, moreover, apply to Hereditarily Finite Permutations , i.e. a group structure that exists inside the linear λ -calculus.},
  archive      = {J_TCS},
  author       = {Gianluca Curzi and Luca Roversi},
  doi          = {10.1016/j.tcs.2020.05.001},
  journal      = {Theoretical Computer Science},
  pages        = {26-53},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A type-assignment of linear erasure and duplication},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the complexity of linear temporal logic with team
semantics. <em>TCS</em>, <em>837</em>, 1–25. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A specification given as a formula in linear temporal logic (LTL) defines a system by its set of traces. However, certain features such as information flow security constraints are rather modeled as so-called hyperproperties, which are sets of sets of traces. One logical approach to this is team logic, which is a logical framework for the specification of dependence and independence of information. LTL with team semantics has recently been discovered as a logic for hyperproperties. We study the complexity theoretic aspects of LTL with so-called synchronous team semantics and Boolean negation, and prove that both its model checking and satisfiability problems are highly undecidable, and equivalent to the decision problem of third-order arithmetic. Furthermore, we prove that this complexity already appears at small temporal depth and with only the “future” modality F F . Finally, we also introduce a team-semantical generalization of stutter-invariance.},
  archive      = {J_TCS},
  author       = {Martin Lück},
  doi          = {10.1016/j.tcs.2020.04.019},
  journal      = {Theoretical Computer Science},
  pages        = {1-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the complexity of linear temporal logic with team semantics},
  volume       = {837},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leader-based de-anonymization of an anonymous read/write
memory. <em>TCS</em>, <em>836</em>, 110–123. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new notion of anonymity was recently introduced at PODC 2017, namely, anonymity on the names of the registers that define the shared memory. As an example, a shared register named A by a process p and a shared register named B by another process q may correspond to the very same shared register X , while the same name C may correspond to different shared registers for p and q . Considering an asynchronous n -process anonymous shared memory system , this paper is concerned with the de-anonymization of the memory, i.e., at the end of the execution of a de-anonymization algorithm, the processes must agree on the same name for each shared register, and different shared registers must have different names. To this end, the paper first addresses leader election in an anonymous memory system. Let n be the number of processes and m the size of the anonymous memory (total number of anonymous registers). It is first shown that there is no election algorithm when the number of anonymous registers is a multiple of n . Then, assuming m = α n + β m=αn+β , where α is a positive integer, three election algorithms are presented, which consider the cases β = 1 β=1 , β = n − 1 β=n−1 , and β ∈ M ( n ) β∈M(n) , where the set M ( n ) M(n) characterizes the values for which mutual exclusion can be solved despite memory anonymity. Once election is solved, a general (and simple) de-anonymization algorithm is presented, which takes as a subroutine any memory anonymous leader election algorithm . Hence, any instance of this algorithm works for the values of m required by the selected underlying election algorithm. As the underlying election algorithms, the de-anonymization algorithm is symmetric in the sense that process identities can only be compared for equality.},
  archive      = {J_TCS},
  author       = {Emmanuel Godard and Damien Imbs and Michel Raynal and Gadi Taubenfeld},
  doi          = {10.1016/j.tcs.2020.07.027},
  journal      = {Theoretical Computer Science},
  pages        = {110-123},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Leader-based de-anonymization of an anonymous read/write memory},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gathering in the plane of location-aware robots in the
presence of spies. <em>TCS</em>, <em>836</em>, 94–109. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set of mobile robots (represented as points) is distributed in the Cartesian plane . The collection contains an unknown subset of byzantine robots which are indistinguishable from the reliable ones. The reliable robots need to gather, i.e., arrive to a configuration in which at the same time, all of them occupy the same point on the plane. The robots are equipped with GPS devices and at the beginning of the gathering process they communicate the Cartesian coordinates of their respective positions to a central authority. On the basis of this information, and without the knowledge of which robots are faulty, the central authority designs a trajectory for every robot. The central authority aims to provide the trajectories which result in the shortest possible gathering time of the reliable robots. The efficiency of a gathering strategy is measured by its competitive ratio , i.e., the maximal ratio between the time required for gathering achieved by the given trajectories and the optimal time required for gathering in the offline case, i.e., when the faulty robots are known to the central authority in advance. The role of the byzantine robots, controlled by the adversary, is to act so that the gathering is delayed and the resulting competitive ratio is maximized. The objective of our paper is to propose efficient algorithms when the central authority is aware of an upper bound on the number of byzantine robots. We give optimal algorithms for collections of robots known to contain at most one faulty robot. When the proportion of byzantine robots is known to be less than one half or one third, we provide algorithms with small constant competitive ratios. We also propose algorithms with bounded competitive ratio in the case where the proportion of faulty robots is arbitrary.},
  archive      = {J_TCS},
  author       = {Jurek Czyzowicz and Ryan Killick and Evangelos Kranakis and Danny Krizanc and Oscar Morales-Ponce},
  doi          = {10.1016/j.tcs.2020.06.034},
  journal      = {Theoretical Computer Science},
  pages        = {94-109},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Gathering in the plane of location-aware robots in the presence of spies},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed fault tolerance in server assignment: Combining
reinforcement and backup. <em>TCS</em>, <em>836</em>, 76–93. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the mixed approach to fault tolerance in the general context of server assignment in networks. The approach is based on mixing two different existing strategies, namely, reinforcement and backup . The former strategy protects clients by reinforcing the servers assigned to them and making them fault-resistant, possibly at a high cost, while the latter protects clients by assigning to them alternate low price backup servers that can replace their primary servers in case those fail. Applying the mixed approach to fault tolerance gives rise to new fault tolerant variations of known server assignment problems. We introduce several NP-hard problems of this type, including the mixed fault-tolerant dominating set problem, the mixed fault-tolerant centers problem, and the mixed fault-tolerant facility location problem, and present polynomial time approximation algorithms for them, demonstrating the viability of the mixed strategy for server assignment problems.},
  archive      = {J_TCS},
  author       = {Tal Navon and David Peleg},
  doi          = {10.1016/j.tcs.2020.06.033},
  journal      = {Theoretical Computer Science},
  pages        = {76-93},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Mixed fault tolerance in server assignment: Combining reinforcement and backup},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A semantic relatedness preserved subset extraction method
for language corpora based on pseudo-boolean optimization. <em>TCS</em>,
<em>836</em>, 65–75. (<a
href="https://doi.org/10.1016/j.tcs.2020.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As language corpora have been playing an increasingly important role in the field of Artificial Intelligence ( AI ) research, lots of extremely large corpora are created. However, a larger corpora size not only increases power and accuracy but also brings redundancy. Therefore, researchers began to emphasize the study of appropriate subset extraction methods. Due to the trade-off between data sufficiency and redundancy, a group of interesting and challenging problems are emerged that are studied in this paper: (1) How to make the resulting subset include as much data as possible under some necessary constraints? (2) How to preserve the potential useful semantic relatedness included in the original corpora while reducing the size of the corpora? For these two problems, existing work mainly focuses on the methods to construct particular subsets for special usage. These methods are limited in their focus. In this paper, we try to address the problems listed above. First, considering the cubic and binary semantic relatedness among tokens, we construct a general system model and formulate the mix problem as a cubic pseudo-Boolean optimization problem . Then, by analyzing the characteristics of the objective function, we transfer the problem into the maximum flow problem of a corresponding graph. Third, we propose a new algorithm by introducing discrete Lagrangian iteration method . We prove that the objective function is supermodular, which allows us to use fast minimum cut algorithms in each iteration step to propose another fast algorithm. Finally, we experimentally validate our new algorithms on several randomly created corpora.},
  archive      = {J_TCS},
  author       = {Luobing Dong and Qiumin Guo and Weili Wu and Meghana N. Satpute},
  doi          = {10.1016/j.tcs.2020.07.020},
  journal      = {Theoretical Computer Science},
  pages        = {65-75},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A semantic relatedness preserved subset extraction method for language corpora based on pseudo-boolean optimization},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Approximation algorithm for (connected) bounded-degree
deletion problem on unit disk graphs. <em>TCS</em>, <em>836</em>, 59–64.
(<a href="https://doi.org/10.1016/j.tcs.2020.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the minimum (connected) k -bounded-degree node deletion problem (Min(C) k BDND). For a connected graph G , a constant k and a weight function w : V → R + w:V→R+ , a vertex set C ⊆ V ( G ) C⊆V(G) is a k BDND-set if the maximum degree of graph G − C G−C is at most k . If furthermore, the subgraph of G induced by C is connected, then C is a C k BDND-set. The goal of MinW k BDND (resp. MinWC k BDND) is to find a k BDND-set (resp. C k BDND-set) with the minimum weight. In this paper, we focus on their cardinality versions with w ( v ) ≡ 1 , v ∈ V w(v)≡1,v∈V , which are denoted as Min k BDND and MinC k BDND. This paper presents a ( 1 + ε ) (1+ε) and a 3.76-approximation algorithm for Min k BDND and MinC k BDND on unit disk graphs, respectively, where 0 0&amp;lt;ε&amp;lt;1 is an arbitrary constant.},
  archive      = {J_TCS},
  author       = {Pengcheng Liu and Zhao Zhang and Xiaohui Huang},
  doi          = {10.1016/j.tcs.2020.06.020},
  journal      = {Theoretical Computer Science},
  pages        = {59-64},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithm for (connected) bounded-degree deletion problem on unit disk graphs},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note of vertex arboricity of planar graphs without
4-cycles intersecting with 6-cycles. <em>TCS</em>, <em>836</em>, 53–58.
(<a href="https://doi.org/10.1016/j.tcs.2020.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vertex arboricity v a ( G ) va(G) of G is the smallest integer k which the acyclic partition of V ( G ) V(G) make the vertex set V ( G ) V(G) be partitioned into k subsets which each subset induces an acyclic graph. In this paper, we mainly study vertex arboricity of planar graphs , and we prove that if there is without 4-cycles intersecting with 6-cycles, then v a ( G ) ⩽ 2 va(G)⩽2 .},
  archive      = {J_TCS},
  author       = {Xuyang Cui and Wenshun Teng and Xing Liu and Huijuan Wang},
  doi          = {10.1016/j.tcs.2020.06.009},
  journal      = {Theoretical Computer Science},
  pages        = {53-58},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A note of vertex arboricity of planar graphs without 4-cycles intersecting with 6-cycles},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Delivery route optimization with automated vehicle in smart
urban environment. <em>TCS</em>, <em>836</em>, 42–52. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a part of the smart urban construction, automated driving is introduced to improve the utilization efficiency of cars and roads, which not only reduces the incidence of traffic accidents, but also improves the environment quality. With the development of the smart urban, it is predictable that, in the city of the future, the service of package pickup and delivery or takeout will be supported mainly by automated vehicles. However, the existing works mainly focus on the variants of the Vehicle Routing Problem (VRP), in which they either take no account of service time of automated vehicle for customers when the automated vehicle arrives at the locations of customers or ignore the impact of rewards gained from customers on path planning of the automated vehicles. In this paper, we also extend a variant of VRP where an automated vehicle is used to package delivery or distribution of food in the smart urban environment, which is called the Delivery Reward Maximization (DRM) problem. The problem aims at designing a route of the automated vehicle while considering the service time for customers before their deadlines and the impact of rewards of the automated vehicle on path planning . We first prove that the DRM problem is NP-hard. Then we study two special cases of the DRM problem, which are called Linear DRM (LDRM) problem and Two-dimensional DRM (TDRM) problem, respectively. In the LDRM and TDRM problems, all customers have the same visiting deadlines and are deployed on the one-dimensional line and two-dimensional plane, respectively. Then we prove that the LDRM and TDRM problems are also NP-hard and propose a constant approximation algorithm for each of them. Afterward, we propose a greedy algorithm to solve the DRM problem, and give the analysis by counterexample .},
  archive      = {J_TCS},
  author       = {Chuanwen Luo and Deying Li and Xingjian Ding and Weili Wu},
  doi          = {10.1016/j.tcs.2020.05.050},
  journal      = {Theoretical Computer Science},
  pages        = {42-52},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Delivery route optimization with automated vehicle in smart urban environment},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Maximum star deleted from ramsey graphs of book and tree.
<em>TCS</em>, <em>836</em>, 37–41. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For graphs F , G and H , let F → ( G , H ) F→(G,H) signify that any red/blue edge coloring of F contains a red G or a blue H . Define the Ramsey number R ( G , H ) R(G,H) to be the smallest r such that K r → ( G , H ) Kr→(G,H) . In this note, we consider an optimization problem to find the star-critical Ramsey number R S ( G , H ) RS(G,H) defined as max ⁡ { n | K r ∖ K 1 , n → ( G , H ) } max⁡{n|Kr∖K1,n→(G,H)} by showing that for n ≥ 3 m n≥3m , R S ( B m , T n ) = n − 2 RS(Bm,Tn)=n−2 , where r = R ( G , H ) r=R(G,H) .},
  archive      = {J_TCS},
  author       = {Ye Wang and Yusheng Li and Yan Li},
  doi          = {10.1016/j.tcs.2020.05.030},
  journal      = {Theoretical Computer Science},
  pages        = {37-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Maximum star deleted from ramsey graphs of book and tree},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A game theoretic approach for minimal connected dominating
set. <em>TCS</em>, <em>836</em>, 29–36. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connected dominating set (CDS) is a subset of vertices in a graph which dominates all vertices and induces a connected subgraph . This paper proposes a game theoretic approach to find a CDS, and proves that starting from a non-trivial initial state, every non-trivial Nash equilibrium is a minimal CDS and reaching a non-trivial Nash equilibrium needs O ( n ) O(n) rounds in the worst case.},
  archive      = {J_TCS},
  author       = {Xiuyang Chen and Zhao Zhang},
  doi          = {10.1016/j.tcs.2020.05.020},
  journal      = {Theoretical Computer Science},
  pages        = {29-36},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A game theoretic approach for minimal connected dominating set},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional diagnosability of component-composition graphs
under the PMC model. <em>TCS</em>, <em>836</em>, 16–28. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosability is an important metric for measuring the reliability of multiprocessor systems . The conditional diagnosability, which is more general than the classical diagnosability, is to measure the diagnosability of a multiprocessor system under the assumption that all of the neighbors of any node in the system cannot fail at the same time. This paper adopts the PMC model and outlines the common properties of a wide class of interconnection networks , called component-composition graphs (CCGs), to determine their conditional diagnosability by using the derived properties. As applications, the diagnosability of hypercube-like networks (including hypercubes, crossed cubes, Möbius cubes, twisted cubes, locally twisted cubes, generalized twisted cubes, and recursive circulants), and bubble-sort graphs, all of which belong to CCGs can be readily obtained.},
  archive      = {J_TCS},
  author       = {Chia-Wei Lee},
  doi          = {10.1016/j.tcs.2020.05.013},
  journal      = {Theoretical Computer Science},
  pages        = {16-28},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Conditional diagnosability of component-composition graphs under the PMC model},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Group sweep coverage with guaranteed approximation ratio.
<em>TCS</em>, <em>836</em>, 1–15. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless Sensor Networks (WSNs) are often deployed to monitor a region of interest. With sweep coverage, mobile sensor nodes are scheduled to move along a planned route (i.e. sweep route) in order to collect the data from a series of Point of Interests (POIs) sequentially. In this paper, we generalize the sweep coverage problem by proposing a new coverage paradigm, group sweep coverage. With group sweep coverage, the POIs are divided into several groups. A group is said to be covered when one of the POIs in the group is covered. The goal in group sweep coverage is to construct a sweep route that mobile sensor nodes should follow in order to cover all groups during each predefined period. In our research, we devised two algorithms for group sweep coverage: AGSC and DSRM. AGSC is a centralized scheme whose approximation ratio is 5Δ. Namely, the length of the sweep route generated by AGSC is at most 5Δ times that of the optimal sweep route. DSRM is a distributed scheme for large-scale networks with dynamic POIs. Compared with AGSC, DSRM leads to the same approximation ratio and better scalability. Our experimental results indicate that both AGSC and DSRM outperform the state-of-the-art schemes in terms of average and maximal sweep route length.},
  archive      = {J_TCS},
  author       = {Chuang Liu and Hongwei Du and Qiang Ye and Wen Xu},
  doi          = {10.1016/j.tcs.2020.05.012},
  journal      = {Theoretical Computer Science},
  pages        = {1-15},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Group sweep coverage with guaranteed approximation ratio},
  volume       = {836},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterization of rational translational surfaces.
<em>TCS</em>, <em>835</em>, 156–167. (<a
href="https://doi.org/10.1016/j.tcs.2017.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rational translational surface is a typical modeling surface used in computer-aided design and the architecture industry. In this study, we determine whether a given algebraic surface implicitly defined as V V is a rational translational surface or not. This problem is reduced to finding the rational parameterizations of two space curves. More important, our discussions are constructive, and thus if V V is translational, we provide a parametric representation of V V of the form P ( t 1 , t 2 ) = P 1 ( t 1 ) + P 2 ( t 2 ) P(t1,t2)=P1(t1)+P2(t2) .},
  archive      = {J_TCS},
  author       = {Sonia Pérez-Díaz and Li-Yong Shen},
  doi          = {10.1016/j.tcs.2017.08.005},
  journal      = {Theoretical Computer Science},
  pages        = {156-167},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameterization of rational translational surfaces},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomized approximation scheme for steiner multi cycle in
the euclidean plane. <em>TCS</em>, <em>835</em>, 134–155. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a randomized approximation scheme for the Euclidean Steiner Multi Cycle problem which runs in quasilinear time. In this problem, we are given a set of n pairs of points (terminals) T = { { t i , t i ′ } } i = 1 n T={{ti,ti′}}i=1n in the Euclidean plane , and the objective is to find a collection of cycles of minimum cost such that t i ti and t i ′ ti′ belong to a same cycle, for each i ∈ { 1 , … , n } i∈{1,…,n} . This problem extends the Steiner Cycle problem in the same way the Steiner Forest extends the Steiner Tree problem . Additionally, it has applications on routing problems with pickup and delivery locations.},
  archive      = {J_TCS},
  author       = {Carla N. Lintzmayer and Flávio K. Miyazawa and Phablo F.S. Moura and Eduardo C. Xavier},
  doi          = {10.1016/j.tcs.2020.06.022},
  journal      = {Theoretical Computer Science},
  pages        = {134-155},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Randomized approximation scheme for steiner multi cycle in the euclidean plane},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hardness of minimum barrier shrinkage and minimum
installation path. <em>TCS</em>, <em>835</em>, 120–133. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Minimum Installation Path problem, we are given a graph G with edge weights w ( ⋅ ) w(⋅) and two vertices s , t s,t of G . We want to assign a non-negative power p : V → R ≥ 0 p:V→R≥0 to the vertices of G , so that the activated edges { u v ∈ E ( G ) | p ( u ) + p ( v ) ≥ w ( u v ) } {uv∈E(G)|p(u)+p(v)≥w(uv)} contain some s - t -path, and minimize the sum of assigned powers. In the Minimum Barrier Shrinkage problem, we are given, in the plane, a family of disks and two points x and y . The task is to shrink the disks, each one possibly by a different amount, so that we can draw an x - y curve that is disjoint from the interior of the shrunken disks, and the sum of the decreases in the radii is minimized. We show that the Minimum Installation Path and the Minimum Barrier Shrinkage problems (or, more precisely, the natural decision problems associated with them) are weakly NP-hard.},
  archive      = {J_TCS},
  author       = {Sergio Cabello and Éric Colin de Verdière},
  doi          = {10.1016/j.tcs.2020.06.016},
  journal      = {Theoretical Computer Science},
  pages        = {120-133},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hardness of minimum barrier shrinkage and minimum installation path},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The component (edge) connectivity of shuffle-cubes.
<em>TCS</em>, <em>835</em>, 108–119. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Component (edge) connectivity is a generalization of traditional (edge) connectivity. Let F be a vertex set (resp., an edge set), if G − F G−F has at least g components, F is a g -component (edge) cut. The g -component (edge) connectivity of graph G is the minimum size of the g -component (edge) cut. In this paper, we study the g -component (edge) connectivity of shuffle-cubes for small g .},
  archive      = {J_TCS},
  author       = {Tongtong Ding and Pingshan Li and Min Xu},
  doi          = {10.1016/j.tcs.2020.06.015},
  journal      = {Theoretical Computer Science},
  pages        = {108-119},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The component (edge) connectivity of shuffle-cubes},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On compatible triangulations with a minimum number of
steiner points. <em>TCS</em>, <em>835</em>, 97–107. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two vertex-labelled polygons are compatible if they have the same clockwise cyclic ordering of vertices. The definition extends to polygonal regions (polygons with holes) and to triangulations—for every face, the clockwise cyclic order of vertices on the boundary must be the same. It is known that every pair of compatible n -vertex polygonal regions can be extended to compatible triangulations by adding O ( n 2 ) O(n2) Steiner points. Furthermore, Ω ( n 2 ) Ω(n2) Steiner points are sometimes necessary, even for a pair of polygons. Compatible triangulations provide piecewise linear homeomorphisms and are also a crucial first step in morphing planar graph drawings, aka “2D shape animation.” An intriguing open question, first posed by Aronov, Seidel, and Souvaine in 1993, is to decide if two compatible polygons have compatible triangulations with at most k Steiner points. In this paper we prove the problem to be NP-hard for polygons with holes . The question remains open for simple polygons .},
  archive      = {J_TCS},
  author       = {Anna Lubiw and Debajyoti Mondal},
  doi          = {10.1016/j.tcs.2020.06.014},
  journal      = {Theoretical Computer Science},
  pages        = {97-107},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On compatible triangulations with a minimum number of steiner points},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A post-quantum hybrid encryption based on QC-LDPC codes in
the multi-user setting. <em>TCS</em>, <em>835</em>, 82–96. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The encryption schemes based on coding theory are one of the most accredited choices in post-quantum scenario, where QC-LDPC codes are usually employed to construct concrete schemes due to the well security and good efficiency. In this work, we introduce a new IND-CCA secure multi-instance framework for code-based hybrid encryption primitive in the random oracle model, which is derived from our new multi-instance KEM and DEM building modules. We note that previous multi-instance KEM and DEM are usually derived from single-instance KEM and DEM, and hence suffers from large parameter sizes and security loss. Nevertheless, our multi-instance KEM is a direct construction based on a key generation function and a one-way trapdoor function, and our multi-instance DEM is constructed from a standard DEM and MAC with a tag in the input to achieve a tighter security loss. Finally, we present a IND-CCA secure multi-instance hybrid encryption scheme based on QC-LDPC codes in the random oracle model, where the scheme achieves small private key size and only consumes addition and multiplication operations over F 2 [ x ] F2[x] .},
  archive      = {J_TCS},
  author       = {Luping Wang and Jie Chen and Kai Zhang and Haifeng Qian},
  doi          = {10.1016/j.tcs.2020.06.013},
  journal      = {Theoretical Computer Science},
  pages        = {82-96},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A post-quantum hybrid encryption based on QC-LDPC codes in the multi-user setting},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterized complexity of happy coloring problems.
<em>TCS</em>, <em>835</em>, 58–81. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a vertex-colored graph, an edge is happy if its endpoints have the same color. Similarly, a vertex is happy if all its incident edges are happy. Motivated by the computation of homophily in social networks, we consider the algorithmic aspects of the following Maximum Happy Edges ( k -MHE ) problem: given a partially k -colored graph G and an integer ℓ , find an extended full k -coloring of G making at least ℓ edges happy. When we want to make ℓ vertices happy on the same input, the problem is known as Maximum Happy Vertices ( k -MHV ). We perform an extensive study into the complexity of the problems, particularly from a parameterized viewpoint. For every k ≥ 3 k≥3 , we prove both problems can be solved in time 2 n n O ( 1 ) 2nnO(1) . Moreover, by combining this result with a linear vertex kernel of size ( k + ℓ ) (k+ℓ) for k -MHE , we show that the edge-variant can be solved in time 2 ℓ n O ( 1 ) 2ℓnO(1) . In contrast, we prove that the vertex-variant remains W[1] -hard for the natural parameter ℓ . However, the problem does admit a kernel with O ( k 2 ℓ 2 ) O(k2ℓ2) vertices for the combined parameter k + ℓ k+ℓ . From a structural perspective, we show both problems are fixed-parameter tractable for treewidth and neighborhood diversity, which can both be seen as sparsity and density measures of a graph. Finally, we extend the known -completeness results of the problems by showing they remain hard on bipartite graphs and split graphs. On the positive side, we show the vertex-variant can be solved optimally in polynomial-time for cographs.},
  archive      = {J_TCS},
  author       = {Akanksha Agrawal and N.R. Aravind and Subrahmanyam Kalyanasundaram and Anjeneya Swami Kare and Juho Lauri and Neeldhara Misra and I. Vinod Reddy},
  doi          = {10.1016/j.tcs.2020.06.002},
  journal      = {Theoretical Computer Science},
  pages        = {58-81},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameterized complexity of happy coloring problems},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault tolerance of hypercube like networks: Spanning
laceability under edge faults. <em>TCS</em>, <em>835</em>, 44–57. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given two vertices u and v in a connected undirected graph G , a w ⁎-container C ( u , v ) C(u,v) is a set of w internally vertex disjoint paths between u and v spanning all the vertices in G . A bipartite graph G is ⁎ w ⁎ w⁎ -laceable if there exists a ⁎ w ⁎ w⁎ -container between any two vertices belonging to different partitions of G . In [8] , [33] a class B n ′ Bn′ of bipartite graphs called hypercube-like bipartite networks was defined. In [22] , Lin et al. showed that every graph in B n ′ Bn′ is ⁎ w ⁎ w⁎ -laceable for every 1 ≤ w ≤ n 1≤w≤n . We define a graph is f -edge fault tolerant ⁎ w ⁎ w⁎ -laceable if G − F G−F is ⁎ w ⁎ w⁎ -laceable for any arbitrary subset F of edges of G with | F | ≤ f |F|≤f . In this paper we show that every graph in B n ′ Bn′ is f -edge-fault tolerant ⁎ w ⁎ w⁎ -laceable for every 0 ≤ f ≤ n − 2 0≤f≤n−2 and 1 ≤ w ≤ n − f 1≤w≤n−f which generalize Lin&#39;s result. We also give generalization of two other results in [22] , [27] .},
  archive      = {J_TCS},
  author       = {Min Xu and Kshirasagar Naik and Krishnaiyan Thulasiraman},
  doi          = {10.1016/j.tcs.2020.05.049},
  journal      = {Theoretical Computer Science},
  pages        = {44-57},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fault tolerance of hypercube like networks: Spanning laceability under edge faults},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithms for visualizing phylogenetic networks.
<em>TCS</em>, <em>835</em>, 31–43. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of visualizing phylogenetic networks, which are extensions of the Tree of Life in biology. We use a space filling visualization method , called DAGmaps, in order to obtain clear visualizations using limited space. In this paper, we first show that the general problem of drawing galled networks as DAGmaps is NP-complete. Next, we restrict our attention to galled trees and planar galled networks and present linear time algorithms for visualizing them as DAGmaps. Finally, we explore whether these graphs can be visualized using One-Dimensional DAGmaps.},
  archive      = {J_TCS},
  author       = {Ioannis G. Tollis and Konstantinos G. Kakoulis},
  doi          = {10.1016/j.tcs.2020.05.047},
  journal      = {Theoretical Computer Science},
  pages        = {31-43},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algorithms for visualizing phylogenetic networks},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A code-based signature scheme from the lyubashevsky
framework. <em>TCS</em>, <em>835</em>, 15–30. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new method to construct code-based signature scheme following the Lyubashevsky&#39;s lattice-based framework. Our technique ensures that the Hamming weight of each row of the private key matrix is below the GV bound instead of fixed weight. Our scheme can generate signatures whose maximum Hamming weight is below the GV bound of random linear codes with the public key matrix as parity-check matrix. We argue that our scheme can resist existing attacks on code-based signatures. We provide a detailed security analysis and prove that our scheme is existentially unforgeable under adaptive chosen-message attacks (EUF-CMA) in the random oracle model through exploiting and expanding code-based complex problems. Our scheme enjoys the shorter signature size than the Durandal signature scheme (EUROCRYPT 2019) and the Wave signature scheme (ASIACRYPT 2019) for security level of 128 bits. We also show that there is a generic method to construct Weight Restricted Hash (WRH) functions which can produce hash value with a given Hamming weight.},
  archive      = {J_TCS},
  author       = {Yongcheng Song and Xinyi Huang and Yi Mu and Wei Wu and Huaxiong Wang},
  doi          = {10.1016/j.tcs.2020.05.011},
  journal      = {Theoretical Computer Science},
  pages        = {15-30},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A code-based signature scheme from the lyubashevsky framework},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The reliability analysis of k-ary n-cube networks.
<em>TCS</em>, <em>835</em>, 1–14. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of scalability and application of multiprocessor system , the components of the system possibly become faulty. It is desirable to know the reliability of the system. However, the exact reliability of a complicated network system is usually difficult to determine. A typical approach is to decompose the system into smaller ones based on a graph-theory model in which nodes are assumed to fail independently with known probabilities to measure the subsystem-based reliability, which is defined as the probability that a fault-free subsystem of a specific size is still available when the system has faults. In this paper, we use the probability fault model to establish upper and lower bounds on the subsystem-based reliability of k -ary n -cube networks, by taking into account the intersection of no more than five or four subgraphs. In addition, some numerical simulations of the subsystem-based reliability of k -ary n -cube networks are conducted.},
  archive      = {J_TCS},
  author       = {Mengjie Lv and Jianxi Fan and Guo Chen and Baolei Cheng and Jingya Zhou and Jia Yu},
  doi          = {10.1016/j.tcs.2020.05.003},
  journal      = {Theoretical Computer Science},
  pages        = {1-14},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The reliability analysis of k-ary n-cube networks},
  volume       = {835},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Reprint of: Palindromization and construction of markoff
triples. <em>TCS</em>, <em>834</em>, 75–83. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Markoff equation is the Diophantine equation x 2 + y 2 + z 2 = 3 x y z x2+y2+z2=3xyz . A solution is called a Markoff triple. We give a bijection between the free monoid on two letters and the set of Markoff triples, using the palindromization map of Aldo de Luca. In our construction, special Christoffel words appear, whose lengths are Markoff numbers; we study their standard and palindromic factorizations , and show that they are self-dual.},
  archive      = {J_TCS},
  author       = {Antoine Abram and Mélodie Lapointe and Christophe Reutenauer},
  doi          = {10.1016/j.tcs.2020.05.042},
  journal      = {Theoretical Computer Science},
  pages        = {75-83},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reprint of: Palindromization and construction of markoff triples},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Reprint of: Generalized lyndon factorizations of infinite
words. <em>TCS</em>, <em>834</em>, 66–74. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalized lexicographic order on words is a lexicographic order where the total order of the (possibly infinite) alphabet depends on the position of the comparison. A generalized Lyndon word is a finite word which is strictly smallest among its class of rotations with respect to a generalized lexicographic order. This notion can be extended to infinite words: an infinite generalized Lyndon word is an infinite word which is strictly smallest among its class of suffixes. We positively answer a question of Dolce, Restivo, and Reutenauer by proving that every infinite word has a unique nonincreasing factorization into finite and infinite generalized Lyndon words. When this factorization has finitely many terms, we characterize the last term of the factorization. Our methods also show that the infinite generalized Lyndon words are precisely the words with infinitely many generalized Lyndon prefixes.},
  archive      = {J_TCS},
  author       = {Amanda Burcroff and Eric Winsor},
  doi          = {10.1016/j.tcs.2020.05.040},
  journal      = {Theoretical Computer Science},
  pages        = {66-74},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reprint of: Generalized lyndon factorizations of infinite words},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Reprint of: Ω-lyndon words. <em>TCS</em>, <em>834</em>,
60–65. (<a href="https://doi.org/10.1016/j.tcs.2020.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let A A be a finite non-empty set and ⪯ a total order on A N AN verifying the following lexicographic like condition: For each n ∈ N n∈N and u , v ∈ A n u,v∈An , if u ω ≺ v ω uω≺vω then u x ≺ v y ux≺vy for all x , y ∈ A N x,y∈AN . A word x ∈ A N x∈AN is called ω -Lyndon if x ≺ y x≺y for each proper suffix y of x . A finite word w ∈ A + w∈A+ is called ω -Lyndon if w ω ≺ v ω wω≺vω for each proper suffix v of w . In this note we prove that every infinite word may be written uniquely as a non-increasing product of ω -Lyndon words.},
  archive      = {J_TCS},
  author       = {Mickaël Postic and Luca Q. Zamboni},
  doi          = {10.1016/j.tcs.2020.05.037},
  journal      = {Theoretical Computer Science},
  pages        = {60-65},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reprint of: ω-lyndon words},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deque automata, languages, and planar graph representations.
<em>TCS</em>, <em>834</em>, 43–59. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deque automaton is a finite-state machine equipped with a deque memory tape. Such memory being more general than a queue or two stacks, we restrict consideration to quasi-real-time deque machines, for which we present useful normal forms. The closure properties of deque languages qualify them as an abstract family of languages but not a full one. The newly defined characteristic deque language CDL combines Dyck and AntiDyck (or FIFO) languages, and homomorphically characterizes the deque languages. The notion of deque graph from the graph drawing theory, well represents deque computations by means of a planar graph developed on a cylinder surface, with edges visualizing how deque symbols are inserted and removed. The drawing of deque computations on a cylinder is remindful of 3D models used in theoretical (bio)chemistry. We prove that a CDL can be defined in different ways: by a simple deque automaton , by labeled deque graphs, by cancellation rules, and by means of the shuffle and intersection of simpler languages. The labeled deque graph represents the syntax structure of a word.},
  archive      = {J_TCS},
  author       = {Stefano Crespi Reghizzi and Pierluigi San Pietro},
  doi          = {10.1016/j.tcs.2020.02.029},
  journal      = {Theoretical Computer Science},
  pages        = {43-59},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Deque automata, languages, and planar graph representations},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Plug-in context providers for reaction systems.
<em>TCS</em>, <em>834</em>, 26–42. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reaction systems originated as models of interactions between biochemical reactions in the living cell. Since then they were also successfully developed as models of interactive computation. Here, the interaction between a (reaction) system and its environment is modelled through context sequences provided by the environment – they influence the processes in the system. In this paper we introduce and investigate a ‘plug-in’ methodology for providing context sequences, where we view interactive processes from the perspective of the environment. The environment is modelled by a plug-in device, where a reaction system can be plugged in. When a reaction system is plugged in, then it receives context sequences from the plug-in device. Several sorts of such devices are investigated and compared (as influencers of behaviours of reaction systems).},
  archive      = {J_TCS},
  author       = {Jetty Kleijn and Maciej Koutny and Grzegorz Rozenberg},
  doi          = {10.1016/j.tcs.2020.01.033},
  journal      = {Theoretical Computer Science},
  pages        = {26-42},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Plug-in context providers for reaction systems},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coding by minimal linear grammars. <em>TCS</em>,
<em>834</em>, 14–25. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the structure and the properties of a special class of combinatorial systems called minimal linear grammars. The role of unambiguous minimal linear grammars is investigated in the framework of the information transmission and coding problem and some related issues.},
  archive      = {J_TCS},
  author       = {Arturo Carpi and Flavio D&#39;Alessandro},
  doi          = {10.1016/j.tcs.2020.01.032},
  journal      = {Theoretical Computer Science},
  pages        = {14-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Coding by minimal linear grammars},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A compactness property of the k-abelian monoids.
<em>TCS</em>, <em>834</em>, 3–13. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -abelian equivalence of words, counting the numbers of occurrences of factors of length at most k , has been analyzed in recent years from several different directions. We continue this analysis. The k -abelian equivalence classes are known to constitute a monoid . Hence, equations over these monoids are well defined. We show that these monoids satisfy a compactness property: each system of equations with a finite number of unknowns is equivalent to some of its finite subsystems. We give two proofs for this compactness result. One is based the fact that the monoid can be embedded into the (multiplicative) monoid of matrices, and the other directly on linear algebra . The former method allows the application of Hilbert&#39;s basis theorem . The latter one, in turn, allows to conclude an upper bound for the size of the finite subsystem.},
  archive      = {J_TCS},
  author       = {Juhani Karhumäki and Markus A. Whiteland},
  doi          = {10.1016/j.tcs.2020.01.023},
  journal      = {Theoretical Computer Science},
  pages        = {3-13},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A compactness property of the k-abelian monoids},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Aldo de luca (1941-2018). <em>TCS</em>, <em>834</em>, 1–2.
(<a href="https://doi.org/10.1016/j.tcs.2020.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Clelia De Felice and Dominique Perrin and Antonio Restivo},
  doi          = {10.1016/j.tcs.2020.05.041},
  journal      = {Theoretical Computer Science},
  pages        = {1-2},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Aldo de luca (1941-2018)},
  volume       = {834},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quadratic vertex kernel for split vertex deletion.
<em>TCS</em>, <em>833</em>, 164–172. (<a
href="https://doi.org/10.1016/j.tcs.2020.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph is called a split graph if its vertex set can be partitioned into a clique and an independent set. Split graphs have rich mathematical structure and interesting algorithmic properties making it one of the most well-studied special graph classes. In the Split Vertex Deletion problem, given a graph and a positive integer k , the objective is to test whether there exists a subset of at most k vertices whose deletion results in a split graph. In this paper, we design a kernel for this problem with O ( k 2 ) O(k2) vertices, improving upon the previous cubic bound known. Also, by giving a simple reduction from the Vertex Cover problem, we establish that Split Vertex Deletion does not admit a kernel with O ( k 2 − ϵ ) O(k2−ϵ) edges, for any ϵ &gt; 0 ϵ&amp;gt;0 , unless NP ⊆ coNP/poly NP⊆coNP/poly .},
  archive      = {J_TCS},
  author       = {Akanksha Agrawal and Sushmita Gupta and Pallavi Jain and R. Krithika},
  doi          = {10.1016/j.tcs.2020.06.001},
  journal      = {Theoretical Computer Science},
  pages        = {164-172},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Quadratic vertex kernel for split vertex deletion},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An infinite class of unsaturated rooted trees corresponding
to designable RNA secondary structures. <em>TCS</em>, <em>833</em>,
147–163. (<a href="https://doi.org/10.1016/j.tcs.2020.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An RNA secondary structure is designable if there is an RNA sequence which can attain its maximum number of base pairs only by adopting that structure. The combinatorial RNA design problem, introduced by Haleš et al. in 2016, is to determine whether or not a given RNA secondary structure is designable. Haleš et al. identified certain classes of designable and non-designable secondary structures by reference to their corresponding rooted trees. We introduce an infinite class of rooted trees containing unpaired nucleotides at the greatest depth, and prove constructively that their corresponding secondary structures are designable. This complements previous results for the combinatorial RNA design problem.},
  archive      = {J_TCS},
  author       = {Jonathan Jedwab and Tara Petrie and Samuel Simon},
  doi          = {10.1016/j.tcs.2020.05.046},
  journal      = {Theoretical Computer Science},
  pages        = {147-163},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An infinite class of unsaturated rooted trees corresponding to designable RNA secondary structures},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimum-width double-strip and parallelogram annulus.
<em>TCS</em>, <em>833</em>, 133–146. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of computing a minimum-width double-strip or parallelogram annulus that encloses a given set of n points in the plane. A double-strip is a closed region in the plane whose boundary consists of four parallel lines and a parallelogram annulus is a closed region between two edge-parallel parallelograms. We present several first algorithms for these problems. Among them are O ( n 2 ) O(n2) and O ( n 3 log ⁡ n ) O(n3log⁡n) -time algorithms that compute a minimum-width double-strip and parallelogram annulus, respectively, when their orientations can be freely chosen.},
  archive      = {J_TCS},
  author       = {Sang Won Bae},
  doi          = {10.1016/j.tcs.2020.05.045},
  journal      = {Theoretical Computer Science},
  pages        = {133-146},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Minimum-width double-strip and parallelogram annulus},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial algorithm for equivalence problem of
deterministic multitape finite automata. <em>TCS</em>, <em>833</em>,
120–132. (<a href="https://doi.org/10.1016/j.tcs.2020.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient algorithm for determining the equivalence of two deterministic multitape finite automata is suggested. It is based on an already published proof of solvability for this problem. It is shown that the suggested algorithm has polynomial complexity . The asymptotic running time of the algorithm is bounded by k ⁎ s n + 1 k⁎sn+1 , where k is some constant, n is the number of tapes and s is the sum of the number of states for the considered automata .},
  archive      = {J_TCS},
  author       = {Hayk A. Grigoryan and Samvel K. Shoukourian},
  doi          = {10.1016/j.tcs.2020.05.044},
  journal      = {Theoretical Computer Science},
  pages        = {120-132},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Polynomial algorithm for equivalence problem of deterministic multitape finite automata},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tree path majority data structures. <em>TCS</em>,
<em>833</em>, 107–119. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the first solution to finding τ -majorities on tree paths. Given a tree of n nodes, each with a label from [ 1 . . σ ] [1..σ] , and a fixed threshold 0 0&amp;lt;τ&amp;lt;1 , such a query gives two nodes u and v and asks for all the labels that appear more than τ ⋅ | P u v | τ⋅|Puv| times in the path P u v Puv from u to v , where | P u v | |Puv| denotes the number of nodes in P u v Puv . Note that the answer to any query is of size up to 1 / τ 1/τ . On a w -bit RAM, we obtain a linear-space data structure with O ( ( 1 / τ ) lg ⁡ lg w ⁡ σ ) O((1/τ)lg⁡lgw⁡σ) query time, which is worst-case optimal for polylogarithmic-sized alphabets. We also describe two succinct-space solutions with query time ⁎ O ( ( 1 / τ ) lg ⁎ ⁡ n lg ⁡ lg w ⁡ σ ) O((1/τ)lg⁎⁡nlg⁡lgw⁡σ) . One uses 2 n H + 4 n + o ( n ) ( H + 1 ) 2nH+4n+o(n)(H+1) bits, where H ≤ lg ⁡ σ H≤lg⁡σ is the entropy of the label distribution; the other uses n H + O ( n ) + o ( n H ) nH+O(n)+o(nH) bits. By using just o ( n lg ⁡ σ ) o(nlg⁡σ) extra bits, our succinct structures allow τ to be specified at query time. We obtain analogous results to find a τ -minority, that is, an element that appears between 1 and τ ⋅ | P u v | τ⋅|Puv| times in P u v Puv .},
  archive      = {J_TCS},
  author       = {Travis Gagie and Meng He and Gonzalo Navarro and Carlos Ochoa},
  doi          = {10.1016/j.tcs.2020.05.039},
  journal      = {Theoretical Computer Science},
  pages        = {107-119},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tree path majority data structures},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An FPTAS for the volume of some v-polytopes — it is hard to
compute the volume of the intersection of two cross-polytopes.
<em>TCS</em>, <em>833</em>, 87–106. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an n -dimensional convex body by a membership oracle in general, it is known that any polynomial-time deterministic algorithm cannot approximate its volume within ratio ( n / log ⁡ n ) n (n/log⁡n)n . There is a substantial progress on randomized approximation such as Markov chain Monte Carlo for a high-dimensional volume, and for many #P-hard problems, while only a few #P-hard problems are known to yield deterministic approximation. Motivated by the problem of deterministically approximating the volume of a V V -polytope, that is a polytope with a small number of vertices and (possibly) exponentially many facets, this paper investigates the problem of computing the volume of a “knapsack dual polytope,” which is known to be #P-hard due to Khachiyan (1989) [16] . We reduce an approximate volume of a knapsack dual polytope to that of the intersection of two cross-polytopes in a short distance, and give FPTASs for those volume computations. Interestingly, computing the volume of the intersection of two cross-polytopes (i.e., L 1 L1 -balls) is #P-hard, unlike the cases of L ∞ L∞ -balls or L 2 L2 -balls.},
  archive      = {J_TCS},
  author       = {Ei Ando and Shuji Kijima},
  doi          = {10.1016/j.tcs.2020.05.029},
  journal      = {Theoretical Computer Science},
  pages        = {87-106},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An FPTAS for the volume of some V-polytopes — it is hard to compute the volume of the intersection of two cross-polytopes},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tightly secure inner product functional encryption:
Multi-input and function-hiding constructions. <em>TCS</em>,
<em>833</em>, 56–86. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tightly secure cryptographic schemes have been extensively studied in the fields of chosen-ciphertext secure public-key encryption (CCA-secure PKE), identity-based encryption (IBE), signatures and more. We extend tightly secure cryptography to inner product functional encryption (IPFE) and present the first tightly secure schemes related to IPFE. We first construct a new IPFE schemes that are tightly secure in the multi-user and multi-challenge setting. In other words, the security of our schemes do not degrade even if an adversary obtains many ciphertexts generated by many users. Our schemes are constructible on a pairing-free group and secure under the matrix decisional Diffie-Hellman (MDDH) assumption, which is the generalization of the decisional Diffie-Hellman (DDH) assumption. Applying the known conversions by Lin (CRYPTO 2017) and Abdalla et al. (CRYPTO 2018) to our schemes, we can obtain the first tightly secure function-hiding IPFE schemes and multi-input IPFE (MIPFE) schemes respectively. Our second main contribution is the proposal of a new generic conversion from function-hiding IPFE to function-hiding MIPFE, which was left as an open problem by Abdalla et al. (CRYPTO 2018). We can obtain the first tightly secure function-hiding MIPFE schemes by applying our conversion to the tightly secure function-hiding IPFE schemes described above.},
  archive      = {J_TCS},
  author       = {Junichi Tomida},
  doi          = {10.1016/j.tcs.2020.05.008},
  journal      = {Theoretical Computer Science},
  pages        = {56-86},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tightly secure inner product functional encryption: Multi-input and function-hiding constructions},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relationship between extra edge connectivity and component
edge connectivity for regular graphs. <em>TCS</em>, <em>833</em>, 41–55.
(<a href="https://doi.org/10.1016/j.tcs.2020.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A conditional connectivity is the generalization of the traditional connectivity and can provide more accurate measures regarding the reliability of a large-scale multiprocessor system. The extra edge connectivity and component edge connectivity are two parameters for the reliability evaluation. Although these two measures have attracted considerable attention and been determined for many classes of graphs in recent years, they are established independently. In this paper, we determine the relationship between extra edge connectivities and component edge connectivities of regular networks. Using this relationship, the extra edge connectivity and component edge connectivity are explored for some well-known graphs, including BC graphs, data center networks, augmented k -ary n -cubes, hierarchical star networks, burnt pancake graphs, ( n , k ) (n,k) -star graphs, etc.},
  archive      = {J_TCS},
  author       = {Rong-Xia Hao and Mei-Mei Gu and Jou-Ming Chang},
  doi          = {10.1016/j.tcs.2020.05.006},
  journal      = {Theoretical Computer Science},
  pages        = {41-55},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Relationship between extra edge connectivity and component edge connectivity for regular graphs},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Eccentricity function in distance-hereditary graphs.
<em>TCS</em>, <em>833</em>, 26–40. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph G = ( V , E ) G=(V,E) is distance hereditary if every induced path of G is a shortest path. In this paper, we show that the eccentricity function e ( v ) = max ⁡ { d ( v , u ) : u ∈ V } e(v)=max⁡{d(v,u):u∈V} in any distance-hereditary graph G is almost unimodal, that is, every vertex v with e ( v ) &gt; r a d ( G ) + 1 e(v)&amp;gt;rad(G)+1 has a neighbor with smaller eccentricity. Here, r a d ( G ) = min ⁡ { e ( v ) : v ∈ V } rad(G)=min⁡{e(v):v∈V} is the radius of graph G . Moreover, we use this result to fully characterize the centers of distance-hereditary graphs. Several bounds on the eccentricity of a vertex with respect to its distance to the center of G or to the ends of a diametral path are established. Finally, we propose a new linear time algorithm to compute all eccentricities in a distance-hereditary graph.},
  archive      = {J_TCS},
  author       = {Feodor F. Dragan and Heather M. Guarnera},
  doi          = {10.1016/j.tcs.2020.05.004},
  journal      = {Theoretical Computer Science},
  pages        = {26-40},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Eccentricity function in distance-hereditary graphs},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-colored spanning graphs. <em>TCS</em>, <em>833</em>,
11–25. (<a href="https://doi.org/10.1016/j.tcs.2020.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a problem motivated by sparse set visualization. Given n points in the plane, each labeled with one or more primary colors , a colored spanning graph (for short, CSG) is a graph in which the vertices of each primary color induce a connected subgraph . The Min-CSG problem asks for the minimum sum of edge lengths in a colored spanning graph. We show that the problem is NP-hard for k primary colors when k ≥ 3 k≥3 and provide a ( 2 − 1 3 + 2 ϱ ) (2−13+2ϱ) -approximation algorithm for k = 3 k=3 that runs in polynomial time , where ϱ is the Steiner ratio. Further, we give an O ( n ) O(n) time algorithm in the special case that the given points are collinear and k is constant.},
  archive      = {J_TCS},
  author       = {Hugo A. Akitaya and Maarten Löffler and Csaba D. Tóth},
  doi          = {10.1016/j.tcs.2020.04.022},
  journal      = {Theoretical Computer Science},
  pages        = {11-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Multi-colored spanning graphs},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Note on matching preclusion number of random graphs.
<em>TCS</em>, <em>833</em>, 1–10. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A perfect matching in a graph is a set of edges such that every vertex is incident with exactly one edge in this set. The matching preclusion number of an even graph G , denoted by m p ( G ) mp(G) , is the minimum number of edges whose deletion leaves the resulting graph without a perfect matching . In this paper, we study the matching preclusion number of random graphs, and prove that if n is even and p &gt; { log ⁡ n + log ⁡ log ⁡ n } / n p&amp;gt;{log⁡n+log⁡log⁡n}/n , then asymptotically almost surely, m p ( G ( n , p ) ) = δ ( G ( n , p ) ) mp(G(n,p))=δ(G(n,p)) .},
  archive      = {J_TCS},
  author       = {Ran Gu and Yaping Mao and Guoju Ye},
  doi          = {10.1016/j.tcs.2019.12.011},
  journal      = {Theoretical Computer Science},
  pages        = {1-10},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Note on matching preclusion number of random graphs},
  volume       = {833},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Editorial. <em>TCS</em>, <em>832</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(20)30309-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(20)30309-1},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When hypermutations and ageing enable artificial immune
systems to outperform evolutionary algorithms. <em>TCS</em>,
<em>832</em>, 166–185. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a time complexity analysis of the Opt-IA artificial immune system (AIS). We first highlight the power and limitations of its distinguishing operators (i.e., hypermutations with mutation potential and ageing) by analysing them in isolation. Recent work has shown that ageing combined with local mutations can help escape local optima on a dynamic optimisation benchmark function . We generalise this result by rigorously proving that, compared to evolutionary algorithms (EAs), ageing leads to impressive speed-ups on the standard benchmark function both when using local and global mutations. Unless the stop at first constructive mutation (FCM) mechanism is applied, we show that hypermutations require exponential expected runtime to optimise any function with a polynomial number of optima. If instead FCM is used, the expected runtime is at most a linear factor larger than the upper bound achieved for any random local search algorithm using the artificial fitness levels method. Nevertheless, we prove that algorithms using hypermutations can be considerably faster than EAs at escaping local optima. An analysis of the complete Opt-IA reveals that it is efficient on the previously considered functions and highlights problems where the use of the full algorithm is crucial. We complete the picture by presenting a class of functions for which Opt-IA fails with overwhelming probability while standard EAs are efficient.},
  archive      = {J_TCS},
  author       = {Dogan Corus and Pietro S. Oliveto and Donya Yazdani},
  doi          = {10.1016/j.tcs.2019.03.002},
  journal      = {Theoretical Computer Science},
  pages        = {166-185},
  shortjournal = {Theor. Comput. Sci.},
  title        = {When hypermutations and ageing enable artificial immune systems to outperform evolutionary algorithms},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lower bounds on the run time of the univariate marginal
distribution algorithm on OneMax. <em>TCS</em>, <em>832</em>, 143–165.
(<a href="https://doi.org/10.1016/j.tcs.2018.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Univariate Marginal Distribution Algorithm (UMDA) – a popular estimation-of-distribution algorithm – is studied from a run time perspective. On the classical OneMax benchmark function on bit strings of length n , a lower bound of Ω ( λ + μ n + n log ⁡ n ) Ω(λ+μn+nlog⁡n) , where μ and λ are algorithm-specific parameters, on its expected run time is proved. This is the first direct lower bound on the run time of UMDA. It is stronger than the bounds that follow from general black-box complexity theory and is matched by the run time of many evolutionary algorithms . The results are obtained through advanced analyses of the stochastic change of the frequencies of bit values maintained by the algorithm, including carefully designed potential functions. These techniques may prove useful in advancing the field of run time analysis for estimation-of-distribution algorithms in general.},
  archive      = {J_TCS},
  author       = {Martin S. Krejca and Carsten Witt},
  doi          = {10.1016/j.tcs.2018.06.004},
  journal      = {Theoretical Computer Science},
  pages        = {143-165},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lower bounds on the run time of the univariate marginal distribution algorithm on OneMax},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design and analysis of diversity-based parent selection
schemes for speeding up evolutionary multi-objective optimisation.
<em>TCS</em>, <em>832</em>, 123–142. (<a
href="https://doi.org/10.1016/j.tcs.2018.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parent selection in evolutionary algorithms for multi-objective optimisation is usually performed by dominance mechanisms or indicator functions that prefer non-dominated points. We propose to refine the parent selection on evolutionary multi-objective optimisation with diversity-based metrics. The aim is to focus on individuals with a high diversity contribution located in poorly explored areas of the search space, so the chances of creating new non-dominated individuals are better than in highly populated areas. We show by means of rigorous runtime analysis that the use of diversity-based parent selection mechanisms in the Simple Evolutionary Multi-objective Optimiser (SEMO) and Global SEMO for the well known bi-objective functions OneMinMax and LOTZ can significantly improve their performance. Our theoretical results are accompanied by experimental studies that show a correspondence between theory and empirical results and motivate further theoretical investigations in terms of stagnation. We show that stagnation might occur when favouring individuals with a high diversity contribution in the parent selection step and provide a discussion on which scheme to use for more complex problems based on our theoretical and experimental results.},
  archive      = {J_TCS},
  author       = {Edgar Covantes Osuna and Wanru Gao and Frank Neumann and Dirk Sudholt},
  doi          = {10.1016/j.tcs.2018.06.009},
  journal      = {Theoretical Computer Science},
  pages        = {123-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Design and analysis of diversity-based parent selection schemes for speeding up evolutionary multi-objective optimisation},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the steady state analysis of covariance matrix
self-adaptation evolution strategies on the noisy ellipsoid model.
<em>TCS</em>, <em>832</em>, 98–122. (<a
href="https://doi.org/10.1016/j.tcs.2018.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the analysis of covariance matrix self-adaptive Evolution Strategies (CMSA-ES) on a subclass of quadratic functions subject to additive Gaussian noise : the noisy ellipsoid model. To this end, it is demonstrated that the dynamical systems approach from the context of isotropic mutations can be transferred to ES that also control the covariance matrix . Theoretical findings such as the component-wise quadratic progress rate or the self-adaptation response function can thus be reused for the CMSA-ES analysis. By deriving the steady state quantities approached on the noisy ellipsoid model for constant population size, a detailed description of the asymptotic CMSA-ES behavior is obtained. By providing self-adaptive ES with a population control mechanism, despite noise disturbances, the algorithm is able to realize continuing progress towards the optimum. Regarding the population control CMSA-ES (pcCMSA-ES), the analytical findings allow to specify its asymptotic long-term behavior and to identify influencing parameters. The finally obtained convergence rate matches the theoretical lower bound of all comparison-based direct search algorithms.},
  archive      = {J_TCS},
  author       = {Michael Hellwig and Hans-Georg Beyer},
  doi          = {10.1016/j.tcs.2018.05.016},
  journal      = {Theoretical Computer Science},
  pages        = {98-122},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the steady state analysis of covariance matrix self-adaptation evolution strategies on the noisy ellipsoid model},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On invariance and linear convergence of evolution strategies
with augmented lagrangian constraint handling. <em>TCS</em>,
<em>832</em>, 68–97. (<a
href="https://doi.org/10.1016/j.tcs.2018.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of numerical constrained optimization , we investigate stochastic algorithms , in particular evolution strategies, handling constraints via augmented Lagrangian approaches. In those approaches, the original constrained problem is turned into an unconstrained one and the function optimized is an augmented Lagrangian whose parameters are adapted during the optimization. The use of an augmented Lagrangian however breaks a central invariance property of evolution strategies, namely invariance to strictly increasing transformations of the objective function. We formalize nevertheless that an evolution strategy with augmented Lagrangian constraint handling should preserve invariance to strictly increasing affine transformations of the objective function and the scaling of the constraints—a subclass of strictly increasing transformations. We show that this invariance property is important for the linear convergence of these algorithms and show how both properties are connected.},
  archive      = {J_TCS},
  author       = {Asma Atamna and Anne Auger and Nikolaus Hansen},
  doi          = {10.1016/j.tcs.2018.10.006},
  journal      = {Theoretical Computer Science},
  pages        = {68-97},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On invariance and linear convergence of evolution strategies with augmented lagrangian constraint handling},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quality gain analysis of the weighted recombination
evolution strategy on general convex quadratic functions. <em>TCS</em>,
<em>832</em>, 42–67. (<a
href="https://doi.org/10.1016/j.tcs.2018.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality gain is the expected relative improvement of the function value in a single step of a search algorithm. Quality gain analysis reveals the dependencies of the quality gain on the parameters of a search algorithm, based on which one can derive the optimal values for the parameters. In this paper, we investigate evolution strategies with weighted recombination on general convex quadratic functions . We derive a bound for the quality gain and two limit expressions of the quality gain. From the limit expressions, we derive the optimal recombination weights and the optimal step-size, and find that the optimal recombination weights are independent of the Hessian of the objective function. Moreover, the dependencies of the optimal parameters on the dimension and the population size are revealed. Differently from previous works where the population size is implicitly assumed to be smaller than the dimension, our results cover the population size proportional to or greater than the dimension. Numerical simulation shows that the asymptotically optimal step-size well approximates the empirically optimal step-size for a finite dimensional convex quadratic function.},
  archive      = {J_TCS},
  author       = {Youhei Akimoto and Anne Auger and Nikolaus Hansen},
  doi          = {10.1016/j.tcs.2018.05.015},
  journal      = {Theoretical Computer Science},
  pages        = {42-67},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Quality gain analysis of the weighted recombination evolution strategy on general convex quadratic functions},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Runtime analysis of RLS and (1 + 1) EA for the dynamic
weighted vertex cover problem. <em>TCS</em>, <em>832</em>, 20–41. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we perform theoretical analyses on the behaviour of an evolutionary algorithm and a randomised search algorithm for the dynamic vertex cover problem based on its dual formulation . The dynamic vertex cover problem has already been theoretically investigated to some extent and it has been shown that using its dual formulation to represent possible solutions can lead to a better approximation behaviour. We improve some of the existing results, i.e. we find a linear expected re-optimization time for a ( 1 + 1 1+1 ) EA to re-discover a 2-approximation when edges are dynamically deleted from the graph. Furthermore, we investigate a different setting for applying the dynamism to the problem, in which a dynamic change happens at each step with a probability P D PD . We also expand these analyses to the weighted vertex cover problem, in which weights are assigned to vertices and the goal is to find a cover set with minimum total weight. Similar to the classical case, the dynamic changes that we consider on the weighted vertex cover problem are adding and removing edges to and from the graph. We aim at finding a maximal solution for the dual problem, which gives a 2-approximate solution for the vertex cover problem. This is equivalent to the maximal matching problem for the classical vertex cover problem.},
  archive      = {J_TCS},
  author       = {Mojgan Pourhassan and Vahid Roostapour and Frank Neumann},
  doi          = {10.1016/j.tcs.2019.03.003},
  journal      = {Theoretical Computer Science},
  pages        = {20-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Runtime analysis of RLS and (1 + 1) EA for the dynamic weighted vertex cover problem},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of the (1 + 1) EA on subclasses of linear functions
under uniform and linear constraints. <em>TCS</em>, <em>832</em>, 3–19.
(<a href="https://doi.org/10.1016/j.tcs.2018.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear functions have gained great attention in the run time analysis of evolutionary computation methods. The corresponding investigations have provided many effective tools for analyzing more complex problems. So far, the runtime analysis of evolutionary algorithms has mainly focused on unconstrained problems, but problems occurring in applications frequently involve constraints. Therefore, there is a strong need to extend the current analyses and used methods for analyzing unconstrained problems to a setting involving constraints. In this paper, we consider the behavior of the classical ( 1 + 1 ) (1+1) Evolutionary Algorithm on linear functions under linear constraint . We show tight bounds in the case where the constraint is given by the OneMax function and the objective function is given by either the OneMax or the BinVal function. For the general case we present upper and lower bounds .},
  archive      = {J_TCS},
  author       = {Tobias Friedrich and Timo Kötzing and J.A. Gregor Lagodzinski and Frank Neumann and Martin Schirneck},
  doi          = {10.1016/j.tcs.2018.04.051},
  journal      = {Theoretical Computer Science},
  pages        = {3-19},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Analysis of the (1 + 1) EA on subclasses of linear functions under uniform and linear constraints},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Theory of evolutionary computation – special issue
editorial. <em>TCS</em>, <em>832</em>, 1–2. (<a
href="https://doi.org/10.1016/j.tcs.2020.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Pietro S. Oliveto and Andrew M. Sutton},
  doi          = {10.1016/j.tcs.2020.05.026},
  journal      = {Theoretical Computer Science},
  pages        = {1-2},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Theory of evolutionary computation – special issue editorial},
  volume       = {832},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On modification of boyer-moore-horspool’s algorithm for tree
pattern matching in linearised trees. <em>TCS</em>, <em>830-831</em>,
60–90. (<a href="https://doi.org/10.1016/j.tcs.2020.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree pattern matching on ordered trees is an important problem in Computer Science. Ordered trees can be represented as strings with additional properties via various linearisations. We present a backward tree pattern matching algorithm for ordered trees for various linear representations of trees and tree patterns. The algorithm adaptations find all occurrences of a single given tree pattern which match an input tree regardless of the chosen linearisation. The algorithms preserve the properties and advantages of standard backward string pattern matching using Boyer-Moore-Horspool&#39;s bad character shift heuristics. The number of symbol comparisons in the backward tree pattern matching can be sublinear in the size of the input tree. As in the case of the string version of Boyer-Moore-Horspool&#39;s matching algorithm , the size of the bad character shift table used by the algorithm is linear in the size of the alphabet. We compare the algorithm adaptations with the algorithm using originally chosen linear representation and with the best performing previously existing algorithms based on (non-linearised) tree pattern matching using finite tree automata or stringpath matchers. We show that the presented backward tree pattern matching algorithms outperform the non-linearising ones for single pattern matching and they perform among themselves comparably.},
  archive      = {J_TCS},
  author       = {Jan Trávníček and Jan Janoušek and Bořivoj Melichar and Loek Cleophas},
  doi          = {10.1016/j.tcs.2020.04.027},
  journal      = {Theoretical Computer Science},
  pages        = {60-90},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On modification of boyer-moore-horspool&#39;s algorithm for tree pattern matching in linearised trees},
  volume       = {830-831},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pushing lines helps: Efficient universal centralised
transformations for programmable matter. <em>TCS</em>, <em>830-831</em>,
43–59. (<a href="https://doi.org/10.1016/j.tcs.2020.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study a discrete system of entities residing on a two-dimensional square grid. Each entity is modelled as a node occupying a distinct cell of the grid. The set of all n nodes forms initially a connected shape A . Entities are equipped with a linear-strength pushing mechanism that can push a whole line of entities in parallel in a single time-step on one position in a given (one of the four possible) direction of a grid. A target connected shape B is also provided and the goal is to transform A into B via a sequence of line moves. Existing models based on local movement of individual nodes, such as rotating or sliding a single node, can be shown to be special cases of the present model, therefore their (inefficient, Θ ( n 2 ) Θ(n2) -time) universal transformations carry over. Our main goal is to investigate whether the parallelism inherent in this new type of movement can be exploited for efficient, i.e., sub-quadratic worst-case, transformations. This paper provides several solutions for specific and universal centralised transformations in the context of the new model. In particular we first design O ( n log ⁡ n ) O(nlog⁡n) -time universal transformation without preserving the connectivity of original shape. Then we focus on transformations which preserve the connectivity of the shape throughout its course and develop an O ( n n ) O(nn) -time transformation for the apparently hard instance of transforming a diagonal A into a straight line B .},
  archive      = {J_TCS},
  author       = {Abdullah Almethen and Othon Michail and Igor Potapov},
  doi          = {10.1016/j.tcs.2020.04.026},
  journal      = {Theoretical Computer Science},
  pages        = {43-59},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Pushing lines helps: Efficient universal centralised transformations for programmable matter},
  volume       = {830-831},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Inferring sequences produced by elliptic curve generators
using coppersmith’s methods. <em>TCS</em>, <em>830-831</em>, 20–42. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze the security of two number-theoretic pseudo-random generators based on elliptic curves : the elliptic curve linear congruential generator and the elliptic curve power generator . We show that these recursive generators are insecure if sufficiently many bits are output at each iteration (improving notably the prior cryptanalysis of Gutierrez and Ibeas from 2007). We present several theoretical attacks based on Coppersmith&#39;s techniques for finding small roots on polynomial equations . Our results confirm that these generators are not appropriate for cryptographic purposes.},
  archive      = {J_TCS},
  author       = {Thierry Mefenza and Damien Vergnaud},
  doi          = {10.1016/j.tcs.2020.04.025},
  journal      = {Theoretical Computer Science},
  pages        = {20-42},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Inferring sequences produced by elliptic curve generators using coppersmith&#39;s methods},
  volume       = {830-831},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast rebalanced RSA signature scheme with typical prime
generation. <em>TCS</em>, <em>830-831</em>, 1–19. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In RSA, private exponent is usually obtained from the preselected public exponent by extended Euclid algorithm and is roughly the same bit size as a modulus number. If the private exponent is preselected as in rebalanced RSA, then the public exponent obtained by extended Euclid algorithm is roughly the same bit size as a modulus number. Hence, it is not easy to reduce both public exponent and private exponent (or CRT private exponents) in RSA key generation. In order to reduce both public exponent and CRT private exponents, the methods to search the modulus number after selecting proper public exponent and private exponent have been proposed in recent researches. However, these methods all have complicated key generation because prime generation module developed for RSA cannot be used. In this paper, we present a method to reduce both public exponent and CRT private exponents after selecting the prime numbers and propose a fast rebalanced RSA signature scheme with small public exponent. Our scheme is advantageous than other schemes in the aspect of using typical prime generation. That is, key generation is not complicated in our scheme.},
  archive      = {J_TCS},
  author       = {Kim Gyu-Chol and Li Su-Chol and Hwang Hak-Chol},
  doi          = {10.1016/j.tcs.2020.04.024},
  journal      = {Theoretical Computer Science},
  pages        = {1-19},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fast rebalanced RSA signature scheme with typical prime generation},
  volume       = {830-831},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new proof for exact relationship between extra
connectivity and extra diagnosability of regular connected graphs under
MM* model. <em>TCS</em>, <em>828-829</em>, 70–80. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extra connectivity and extra diagnosability are two important measures for network reliability. Under MM* model, two possible relationships between extra connectivity and extra diagnosability were proposed in Reference [24] . However, there are some shortcomings in it: (1) the conclusion of Theorem 3.9 is wrong; (2) the corresponding proof of Theorem 3.9 is flawed; (3) the exact relationship is still not clear. In this paper, we impose reasonable constraints, and give a new and correct proof for measuring the exact relationship between h -extra connectivity κ h ( G ) κh(G) and h -extra diagnosability t h m ˜ ( G ) thm˜(G) of the regular connected graph G under MM* model, which is t h m ˜ ( G ) = κ h ( G ) + h thm˜(G)=κh(G)+h . As an application, we directly obtain the h -extra diagnosability of star graph S n Sn , alternating group graph network A N n ANn and ( n , k ) (n,k) -star graph S n , k Sn,k by our proposed new result.},
  archive      = {J_TCS},
  author       = {Yanze Huang and Limei Lin and Li Xu},
  doi          = {10.1016/j.tcs.2020.04.023},
  journal      = {Theoretical Computer Science},
  pages        = {70-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A new proof for exact relationship between extra connectivity and extra diagnosability of regular connected graphs under MM* model},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On ultrametric 1-median selection. <em>TCS</em>,
<em>828-829</em>, 65–69. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of finding a point in a finite ultrametric space with the minimum average distance to all points. We give this problem a Monte Carlo O ( ( log 2 ⁡ ( 1 / ϵ ) ) / ϵ 3 ) O((log2⁡(1/ϵ))/ϵ3) -time ( 1 + ϵ ) (1+ϵ) -approximation algorithm with success probability 1 − O ( ϵ ) 1−O(ϵ) , for all ϵ &gt; 0 ϵ&amp;gt;0 .},
  archive      = {J_TCS},
  author       = {Ching-Lueh Chang},
  doi          = {10.1016/j.tcs.2020.04.021},
  journal      = {Theoretical Computer Science},
  pages        = {65-69},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On ultrametric 1-median selection},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing the cost of batch calibrations. <em>TCS</em>,
<em>828-829</em>, 55–64. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the scheduling problem with calibrations. We are given a set of n jobs that need to be scheduled on a set of m machines. However, a machine can schedule jobs only if a calibration has been performed beforehand and the machine is considered as valid during a fixed time period of T , after which it must be recalibrated before running more jobs. In this paper, we investigate the batch calibrations; calibrations occur in batch and at the same moment. It is then not possible to perform any calibrations during a period of T . We consider different cost function depending on the number of machines we calibrate at a given time, i.e., the cost function is denoted as f ( x ) f(x) where x is the number of calibrations in the batch. Moreover, jobs have release time, deadline, and unit processing time. The objective is to schedule all jobs with the minimum cost of calibrations. We give a dynamic program to solve the case with an arbitrary cost function. Then, we propose several faster approximation algorithms for different cost functions: an optimal algorithm when f ( x ) = b f(x)=b , a 3-approximation algorithm when f ( x ) = x f(x)=x and a ( m + b ) / ( b + 1 ) (m+b)/(b+1) -approximation algorithm when f ( x ) = x + b f(x)=x+b . The running time of these algorithms are O ( n 2 ) O(n2) .},
  archive      = {J_TCS},
  author       = {Vincent Chau and Minming Li and Elaine Yinling Wang and Ruilong Zhang and Yingchao Zhao},
  doi          = {10.1016/j.tcs.2020.04.020},
  journal      = {Theoretical Computer Science},
  pages        = {55-64},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Minimizing the cost of batch calibrations},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On RAC drawings of graphs with one bend per edge.
<em>TCS</em>, <em>828-829</em>, 42–54. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k-bend right-angle-crossing drawing (or k-bend RAC drawing , for short) of a graph is a polyline drawing where each edge has at most k bends and the angles formed at the crossing points of the edges are 90 ∘ 90∘ . Accordingly, a graph that admits a k -bend RAC drawing is referred to as k-bend right-angle-crossing graph (or k-bend RAC , for short); a 0-bend RAC graph is also called a straight-line RAC graph . In this paper, we close the gap between the upper bound and the lower bound on the maximum edge-density of 1-bend RAC graphs. We show that an n -vertex 1-bend RAC graph cannot have more than 5.5 n − O ( 1 ) 5.5n−O(1) edges. This bound is asymptotically tight, as we show that there exist infinitely many n -vertex 1-bend RAC graphs whose density matches the upper bound up to a constant. Our results improve both the previously known best upper bound of 6.5 n − O ( 1 ) 6.5n−O(1) edges and the corresponding lower bound of 4.5 n − O ( n ) 4.5n−O(n) edges by Arikushi et al. (2012) [9] . Finally, we consider simple 1-bend RAC drawings, that is, drawings in which each pair of edges shares at most one point (crossing or endpoint). In this setting, we provide an upper bound of 5.4 n − O ( 1 ) 5.4n−O(1) and a lower bound of 5 n − O ( 1 ) 5n−O(1) edges for n -vertex graphs that admit simple 1-bend RAC drawings, which shows that requiring simplicity is indeed a restriction.},
  archive      = {J_TCS},
  author       = {Patrizio Angelini and Michael A. Bekos and Henry Förster and Michael Kaufmann},
  doi          = {10.1016/j.tcs.2020.04.018},
  journal      = {Theoretical Computer Science},
  pages        = {42-54},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On RAC drawings of graphs with one bend per edge},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Information coverage maximization for multiple products in
social networks. <em>TCS</em>, <em>828-829</em>, 32–41. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from most existing work which is focus on maximizing the influence of a single product in viral marketing, we study the k kinds of products information coverage maximization problem ( k -PICMP). Since a company usually produces different products for different people and the active node set cannot completely represent the coverage of the products information propagation due to the neglect for informed users, our problem has its practical significance. The target of the k -PICMP is to choose M users to maximize the information coverage of k kinds of products. To give a high-quality solution for the proposed problem under the IC model, we formulate the k -PICMP as two different problems: k -PICMTP with total size constraint and k -PICMIP with individual size constraint. Then we prove that the objective function we want to solve is a k -submodular function, it aims at maximizing the value of the function by selecting k disjoint seed sets with cardinality constraint. Next, we present greedy algorithms under the total size constraint and individual size constraint to solve the k -PICMTP and k -PICMIP, respectively. Extensive experiments on three real-world datasets verify the performance of our proposed algorithms.},
  archive      = {J_TCS},
  author       = {Qiufen Ni and Jianxiong Guo and Chuanhe Huang and Weili Wu},
  doi          = {10.1016/j.tcs.2020.04.017},
  journal      = {Theoretical Computer Science},
  pages        = {32-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Information coverage maximization for multiple products in social networks},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). GHS algorithm on a graph with random weights. <em>TCS</em>,
<em>828-829</em>, 19–31. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {GHS algorithm is the classical distributed algorithm constructing a minimum spanning tree in a graph with weights assigned to its edges. We are interested in the average performance of GHS algorithm, i.e. time complexity of GHS algorithm on a random input. As a random input we choose a complete graph with randomly assigned weights. In the analysis we study some properties of the classical random graph process and a minimum degree graph process related to it.},
  archive      = {J_TCS},
  author       = {Katarzyna Rybarczyk},
  doi          = {10.1016/j.tcs.2020.04.013},
  journal      = {Theoretical Computer Science},
  pages        = {19-31},
  shortjournal = {Theor. Comput. Sci.},
  title        = {GHS algorithm on a graph with random weights},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Faster compression of patterns to rectangle rule lists.
<em>TCS</em>, <em>828-829</em>, 1–18. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Access Control Lists (ACLs) are an essential security component in network routers. ACLs can be geometrically modeled as a two-dimensional black and white grid; our interest is in the most efficient way to represent such a grid. The more general problem is that of Rectangle Rule Lists (RRLs) minimization, which is finding the least number of rectangles needed to generate a given pattern. The scope of this paper focuses on a restricted version of RRLs minimization in which only rectangles that span the length or width of the grid are considered. Applegate et al.&#39;s paper “Compressing Rectilinear Pictures and Minimizing Access Control Lists” gives an algorithm for finding an optimal solution for strip-rule RRLs minimization in O ( n 3 ) O(n3) time, where n is the total number of rows and columns in the grid. Following the structure of Applegate et al.&#39;s algorithm, we simplify the solution, remove redundancies in data structures , and exploit overlapping sub-problems in order to achieve an optimal solution for strip-rule RRLs minimization in O ( n 2 O(n2 log n ) time.},
  archive      = {J_TCS},
  author       = {Ian Albuquerque Raymundo Da Silva and Gruia Calinescu and Nathan De Graaf},
  doi          = {10.1016/j.tcs.2020.03.014},
  journal      = {Theoretical Computer Science},
  pages        = {1-18},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Faster compression of patterns to rectangle rule lists},
  volume       = {828-829},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Step-optimal implementations of large single-writer
registers. <em>TCS</em>, <em>826-827</em>, 40–50. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present two wait-free algorithms for simulating an ℓ -bit single-writer register from k -bit single-writer registers, for any k ≥ 1 k≥1 . Our first algorithm has Θ ( ℓ / k ) Θ(ℓ/k) step complexity for both and and uses Θ ( 4 ℓ − k ) Θ(4ℓ−k) registers. Our second algorithm has Θ ( ℓ / k + ( log ⁡ n ) / k ) Θ(ℓ/k+(log⁡n)/k) step complexity for both and , where n is the number of readers, but uses only Θ ( n ℓ / k ) Θ(nℓ/k) registers. By using the first algorithm when ℓ ≤ ( log ⁡ n ) / 2 ℓ≤(log⁡n)/2 and the second algorithm when ℓ &gt; ( log ⁡ n ) / 2 ℓ&amp;gt;(log⁡n)/2 , we get a combined implementation with Θ ( ℓ / k ) Θ(ℓ/k) step complexity using Θ ( n ℓ / k ) Θ(nℓ/k) registers which works for any 1 ≤ k 1≤k&amp;lt;ℓ . We also prove that any implementation with O ( ℓ / k ) O(ℓ/k) step complexity for requires Ω ( ℓ / k ) Ω(ℓ/k) step complexity for . Reading ℓ bits requires at least ⌈ ℓ / k ⌉ ⌈ℓ/k⌉ reads of k -bit registers, so our lower bound shows that our combined implementation is step-optimal.},
  archive      = {J_TCS},
  author       = {Tian Ze Chen and Yuanhao Wei},
  doi          = {10.1016/j.tcs.2020.04.008},
  journal      = {Theoretical Computer Science},
  pages        = {40-50},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Step-optimal implementations of large single-writer registers},
  volume       = {826-827},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Kleinberg’s grid unchained. <em>TCS</em>, <em>826-827</em>,
25–39. (<a href="https://doi.org/10.1016/j.tcs.2018.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the key features of small-world networks is the ability to route messages in a few hops, using a decentralized algorithm in which each node has a limited knowledge of the topology. In 2000, Kleinberg proposed a model based on an augmented grid that asymptotically exhibits such a property. In this paper, we revisit the original model with the help of numerical simulations. Our approach is fueled by a new algorithm that can sample augmenting links in an almost constant time. The speed gain allows us to perform detailed numerical evaluations. We first observe that, in practice, the augmented scheme proposed by Kleinberg is more robust than what is predicted by the asymptotic behavior , even in very large finite grids. We also propose tighter bounds on the asymptotic performance of Kleinberg&#39;s greedy routing algorithm . We finally show that, if the model is fed with realistic parameters, the results are in line with real-life experiments.},
  archive      = {J_TCS},
  author       = {Céline Comte and Fabien Mathieu},
  doi          = {10.1016/j.tcs.2018.09.025},
  journal      = {Theoretical Computer Science},
  pages        = {25-39},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Kleinberg&#39;s grid unchained},
  volume       = {826-827},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bounded disagreement. <em>TCS</em>, <em>826-827</em>, 12–24.
(<a href="https://doi.org/10.1016/j.tcs.2018.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A well-known generalization of the consensus problem, namely, set agreement (SA) , limits the number of distinct decision values that processes decide. In some settings, it may be more important to limit the number of “disagreers”. Thus, we introduce another natural generalization of the consensus problem, namely, bounded disagreement (BD) , which limits the number of processes that decide differently from the plurality. More precisely, in a system with n processes, the ( n , ℓ ) -BD (n,ℓ)-BD task has the following requirement: there is a value v such that at most ℓ processes (the disagreers) decide a value other than v . Despite their apparent similarities, the results described below show that bounded disagreement, consensus, and set agreement are in fact fundamentally different problems. We investigate the relationship between bounded disagreement, consensus, and set agreement. In particular, we determine the consensus number [15] for every instance of the BD task. We also determine values of n , ℓ , m , and k such that the ( n , ℓ ) -BD (n,ℓ)-BD task can solve the ( m , k ) -SA (m,k)-SA task (where m processes can decide at most k distinct values). Using our results and a previously-known impossibility result for set agreement [7] , we prove that for all n ≥ 2 n≥2 , there is a BD task (and a corresponding BD object) that has consensus number n but cannot be solved using n -consensus and registers. Prior to our paper, the only objects known to have this unusual characteristic for n ≥ 2 n≥2 (which shows that the consensus number of an object is not sufficient to fully capture its power) were artificial objects crafted solely for the purpose of exhibiting this behavior [1] , [17] .},
  archive      = {J_TCS},
  author       = {David Yu Cheng Chan and Vassos Hadzilacos and Sam Toueg},
  doi          = {10.1016/j.tcs.2018.09.026},
  journal      = {Theoretical Computer Science},
  pages        = {12-24},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bounded disagreement},
  volume       = {826-827},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the viability of the deterministic consensus hierarchy.
<em>TCS</em>, <em>826-827</em>, 2–11. (<a
href="https://doi.org/10.1016/j.tcs.2018.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent paper by Afek, Ellen, and Gafni introduced a family of deterministic objects O m , k Om,k , for m , k ≥ 2 m,k≥2 , with consensus numbers m such that, for each k ≥ 2 k≥2 , O m , k Om,k is computationally less powerful than O m , k + 1 Om,k+1 in systems with at least m k + m + k mk+m+k processes. This paper gives a wait-free implementation of O m , k Om,k from ( m + 1 ) (m+1) -consensus objects and registers in systems with finitely many processes. In order to do so, it introduces a new family of objects which helps us to understand the power of m -consensus in a system with more than m processes.},
  archive      = {J_TCS},
  author       = {Ammar Qadri},
  doi          = {10.1016/j.tcs.2018.02.004},
  journal      = {Theoretical Computer Science},
  pages        = {2-11},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the viability of the deterministic consensus hierarchy},
  volume       = {826-827},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>826-827</em>, 1. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Panagiota Fatourou ( Guest Editor ) and Fernando Pedone ( Guest Editor )},
  doi          = {10.1016/j.tcs.2020.04.006},
  journal      = {Theoretical Computer Science},
  pages        = {1},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {826-827},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A graph-theoretical basis of stochastic-cascading network
influence: Characterizations of influence-based centrality.
<em>TCS</em>, <em>824-825</em>, 92–111. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ker-I Ko (葛可一, 1950-2018) made multiple pioneering and milestone contributions to structural complexity theory and real-number computation. His sharp perception of both discrete and continuous structures had led him to study fundamental concepts from one-way functions [29] , to polynomial-time hierarchy [21] , from integral equations [24] , to real functions [28] , from fractals [27] to fixed-points [25] , from optimization [20] to relativization [22] , from instance complexity [36] to real complexity [28] , from NP-completeness [31] to exponential-time completeness [23] . In his final two years, he turned his focus to game-theoretical designs for dynamic processes over social networks [12] , [33] . For this honorary special issue in memory of Professor Ker-I Ko , we are pleased to be able to contribute a paper with scope intersecting the areas that drew his last attention, and with results connecting discrete and continuous formulations of network dynamics. We prove that the complex stochastic network-influence processes have a simple graph-theoretical basis: Every stochastic-cascading influence profile can be written as a linear combination of breadth-first-search-based broadcast-propagations over layered-graphs. This graph-theoretical basis of stochastic network influence provides us with a systematic framework for studying the following fundamental question in network analysis: Our framework systematically extends a family of classical graph-theoretical centrality formulations — including degree centrality , harmonic centrality, and various notions of “sphere-of-influence” — to influence-based network centralities. Given that group cooperation is essential in social influences, we further extend natural group centralities from graph models to influence models, enabling us to assess individuals&#39; centralities in group influence settings by applying the fundamental concept of Shapley value from cooperative game theory . Mathematically, using the property that these centrality formulations are Bayesian , 3 we prove an axiomatic characterization theorem: Every influence-based centrality formulation in this family is the unique Bayesian centrality that conforms with its corresponding graph-theoretical centrality. Moreover, the uniqueness is fully determined by the centrality formulation on the class of layered graphs, which is derived from a beautiful algebraic structure of influence instances modeled by cascading sequences. We further provide an algorithmic framework for efficient approximation of these influence-based centrality measures . Our study provides us with a systematic road map for comparative analyses of different influence-based centrality formulations. The fact that layered graphs form a basis for the space of influence-cascading-sequence profiles could also be useful in other studies of network influences.},
  archive      = {J_TCS},
  author       = {Wei Chen and Shang-Hua Teng and Hanrui Zhang},
  doi          = {10.1016/j.tcs.2020.04.016},
  journal      = {Theoretical Computer Science},
  pages        = {92-111},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A graph-theoretical basis of stochastic-cascading network influence: Characterizations of influence-based centrality},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Restricted connectivity and good-neighbor diagnosability of
split-star networks. <em>TCS</em>, <em>824-825</em>, 81–91. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The restricted connectivity and the g -good-neighbor diagnosability are two important indicators of the robustness for a multi-processor system in presence of failing processors. The g -good-neighbor diagnosability of a graph guarantees that the number of fault-free neighbors of every fault-free vertex is greater or equal to g in the graph. We first establish the 3-restricted connectivity of an n -dimensional split-star network S n 2 Sn2 . Then we propose the upper bound of the { 1 , 2 , 3 } {1,2,3} -good-neighbor diagnosability of S n 2 Sn2 under the MM* model. Moreover, we show that when deleting two indistinguishable good-neighbor faulty vertex-sets from S n 2 Sn2 , the remaining connected subgraph has no isolated vertex. Furthermore, we give a complete proof for the lower bound of the { 1 , 2 , 3 } {1,2,3} -good-neighbor diagnosability of S n 2 Sn2 , and prove that the lower and upper bounds of the { 1 , 2 , 3 } {1,2,3} -good-neighbor diagnosability of S n 2 Sn2 are accurate.},
  archive      = {J_TCS},
  author       = {Limei Lin and Yanze Huang and Xiaoding Wang and Li Xu},
  doi          = {10.1016/j.tcs.2020.04.015},
  journal      = {Theoretical Computer Science},
  pages        = {81-91},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Restricted connectivity and good-neighbor diagnosability of split-star networks},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structure connectivity and substructure connectivity of the
crossed cube. <em>TCS</em>, <em>824-825</em>, 67–80. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interconnection network is usually represented by a simple graph G . The structure connectivity κ ( G ; H ) κ(G;H) and substructure connectivity κ s ( G ; H ) κs(G;H) are the new proposed indicators to measure network fault tolerance and reliability when the network fails with different structures. As a variant of the popular network hypercube , the crossed cube is also a famous interconnection network in parallel and distributed systems . In this paper, we establish the H -structure connectivity of the n -dimensional crossed cube when H ∈ { K 1 , 1 , K 1 , 3 , P k , C 4 } H∈{K1,1,K1,3,Pk,C4} and 3 ≤ k ≤ n 3≤k≤n and H -substructure connectivity of the n -dimensional crossed cube when H ∈ { K 1 , 1 , K 1 , 3 , P k , C m } H∈{K1,1,K1,3,Pk,Cm} , 3 ≤ k ≤ n 3≤k≤n and 4 ≤ m ≤ n 4≤m≤n .},
  archive      = {J_TCS},
  author       = {Zhuowen Pan and Dongqin Cheng},
  doi          = {10.1016/j.tcs.2020.04.014},
  journal      = {Theoretical Computer Science},
  pages        = {67-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Structure connectivity and substructure connectivity of the crossed cube},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The largest component of faulty star graphs. <em>TCS</em>,
<em>824-825</em>, 57–66. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum size of the largest component of a network with faults is a useful parameter to make a full evaluation of this network and it is helpful for estimating some other parameters in graph theory. In this paper, we focus on discussing the minimum size of the largest component of star graph S n Sn which contains faulty edges. Specifically, we show that there exists at most one, two, three, four, five vertices beyond the largest component of S n − F Sn−F with F ⊆ E ( S n ) F⊆E(Sn) and | F | ≤ 2 n − 5 , 3 n − 8 , 4 n − 11 , 5 n − 15 , 6 n − 19 |F|≤2n−5,3n−8,4n−11,5n−15,6n−19 respectively. As applications, we study the g -extra edge connectivity of S n Sn for 1 ≤ g ≤ 5 1≤g≤5 , and study the strong Menger edge connectivity of S n − F Sn−F with F ∈ E ( S n ) F∈E(Sn) .},
  archive      = {J_TCS},
  author       = {Pingshan Li and Min Xu},
  doi          = {10.1016/j.tcs.2020.04.012},
  journal      = {Theoretical Computer Science},
  pages        = {57-66},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The largest component of faulty star graphs},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Diagnosability for two families of composition networks.
<em>TCS</em>, <em>824-825</em>, 46–56. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosability is an important parameter to assess the reliability of multiprocessor systems . A multiprocessor system is called t -diagnosable if all faulty processors can be identified without replacement as long as the number of faulty processors does not exceed t . The diagnosability is the maximum value of t such that multiprocessors system is t -diagnosable. Matching composition networks (MCNs) and cycle composition networks (CCNs) are two typical network structures to construct multiprocessor systems . Let G G be a MCN which is obtained by adding a perfect matching between two graph G 0 G0 and G 1 G1 , and let H H be a CCN obtained by adding a perfect matching between G i Gi and G i + 1 ( mod m ) Gi+1(modm) for each i ∈ { 0 , 1 , … , m − 1 } i∈{0,1,…,m−1} with m ≥ 3 m≥3 . In this paper, we show that the diagnosability of G G under the PMC ( δ ( G ) ≥ 2 δ(G)≥2 ) model and MM ⁎ model ( δ ( G ) ≥ 5 δ(G)≥5 ) is n − 1 n−1 if G 0 ≅ G 1 ≅ K n G0≅G1≅Kn ; otherwise, δ ( G ) δ(G) . Furthermore, we show that the diagnosability of H H under the PMC model ( δ ( H ) ≥ 4 δ(H)≥4 ) and MM ⁎ model ( δ ( H ) ≥ 5 δ(H)≥5 ) is δ ( H ) δ(H) .},
  archive      = {J_TCS},
  author       = {Yihong Wang and Cheng-Kuan Lin and Xiaoyan Li and Shuming Zhou},
  doi          = {10.1016/j.tcs.2020.04.011},
  journal      = {Theoretical Computer Science},
  pages        = {46-56},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Diagnosability for two families of composition networks},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). PSPACE-completeness of two graph coloring games.
<em>TCS</em>, <em>824-825</em>, 36–45. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we answer a long-standing open question proposed by Bodlaender in 1991: the game chromatic number is PSPACE-hard. We also prove that the game Grundy number is PSPACE-hard. In fact, we prove that both problems (the graph coloring game and the greedy coloring game) are PSPACE-Complete even if the number of colors is the chromatic number . Despite this, we prove that the game Grundy number is equal to the chromatic number for split graphs and several superclasses of cographs, extending a result of Havet and Zhu in 2013.},
  archive      = {J_TCS},
  author       = {Eurinardo Costa and Victor Lage Pessoa and Rudini Sampaio and Ronan Soares},
  doi          = {10.1016/j.tcs.2020.03.022},
  journal      = {Theoretical Computer Science},
  pages        = {36-45},
  shortjournal = {Theor. Comput. Sci.},
  title        = {PSPACE-completeness of two graph coloring games},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Emptiness problems for integer circuits. <em>TCS</em>,
<em>824-825</em>, 11–35. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the computational complexity of emptiness problems for circuits over sets of natural numbers with the operations union, intersection, complement, addition, and multiplication. For most settings of allowed operations we precisely characterize the complexity in terms of completeness for classes like NL, NP, and PSPACE. The case where intersection, addition, and multiplication is allowed turns out to be equivalent to the complement of polynomial identity testing (PIT). Our results imply the following improvements and insights on problems studied in earlier papers. We improve the bounds for the membership problem MC ( ∪ , ∩ , x ‾ , + , × ) MC(∪,∩,x‾,+,×) studied by McKenzie and Wagner 2007 and for the equivalence problem EQ ( ∪ , ∩ , x ‾ , + , × ) EQ(∪,∩,x‾,+,×) studied by Glaßer et al. 2010. Moreover, it turns out that the following problems are equivalent to PIT, which shows that the challenge to improve their bounds is just a reformulation of a well-studied, major open problem in algebraic computing complexity:},
  archive      = {J_TCS},
  author       = {Dominik Barth and Moritz Beck and Titus Dose and Christian Glaßer and Larissa Michler and Marc Technau},
  doi          = {10.1016/j.tcs.2020.03.023},
  journal      = {Theoretical Computer Science},
  pages        = {11-35},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Emptiness problems for integer circuits},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Paid exchanges are worth the price. <em>TCS</em>,
<em>824-825</em>, 1–10. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the list update problem as defined in the seminal work on competitive analysis by Sleator and Tarjan [13] . An instance of the problem consists of a sequence of requests to access items in a linked list. After an item is accessed, that item can be moved to any position forward in the list at no cost (a move called free exchange), and, at any time, any two adjacent items can be swapped at a cost of 1 (a move called paid exchange). The cost to access an item is equal to its current position in the list. The goal is to dynamically rearrange the list so as to minimize the total cost (accrued from accesses and exchanges) over the request sequence. We show a lower bound of 12/11 on the worst-case ratio between the performance of an (offline) optimal algorithm that can only perform free exchanges and that of an (offline) optimal algorithm that can perform both paid and free exchanges. This answers the question of the asymptotic relative power of the two models which has been open since Reingold and Westbrook [11] showed in 1996 that Sleator and Tarjan erred in [13] when they claimed that the two models are equivalent.},
  archive      = {J_TCS},
  author       = {Alejandro López-Ortiz and Marc P. Renault and Adi Rosén},
  doi          = {10.1016/j.tcs.2020.01.031},
  journal      = {Theoretical Computer Science},
  pages        = {1-10},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Paid exchanges are worth the price},
  volume       = {824-825},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Backward type inference for XML queries. <em>TCS</em>,
<em>823</em>, 69–99. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although XQuery is a statically typed, functional query language for XML data, some of its features such as upward and horizontal XPath axes are typed imprecisely. The main reason is that while the XQuery data model allows us to navigate upwards and between siblings from a given XML node, the type model, e.g. , regular tree types, can describe only the subtree structure of the given node. To alleviate this limitation, precise forward type inference systems for XQuery were recently proposed using an extended regular type language that can describe not only a given XML node but also its context . In this paper, as a different approach, we propose a novel backward type inference system for XQuery, based on a type language extended with logical formulas. Our backward type inference system provides an exact typing result for XPath axes and a sound typing result for XQuery expressions .},
  archive      = {J_TCS},
  author       = {Hyeonseung Im and Pierre Genevès and Nils Gesbert and Nabil Layaïda},
  doi          = {10.1016/j.tcs.2020.03.020},
  journal      = {Theoretical Computer Science},
  pages        = {69-99},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Backward type inference for XML queries},
  volume       = {823},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Presenting de groot duality of stably compact spaces.
<em>TCS</em>, <em>823</em>, 44–68. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a constructive account of the de Groot duality of stably compact spaces in the setting of strong proximity lattice , a point-free representation of a stably compact space. To this end, we introduce a notion of strong continuous entailment relation , which can be thought of as a presentation of a strong proximity lattice by generators and relations. The new notion allows us to identify de Groot duals of stably compact spaces by analysing the duals of their presentations. We carry out a number of constructions on strong proximity lattices using strong continuous entailment relations and study their de Groot duals. The examples include various powerlocales, patch topology, and the space of valuations. These examples illustrate the simplicity of our approach by which we can reason about the de Groot duality of stably compact spaces.},
  archive      = {J_TCS},
  author       = {Tatsuji Kawai},
  doi          = {10.1016/j.tcs.2020.03.002},
  journal      = {Theoretical Computer Science},
  pages        = {44-68},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Presenting de groot duality of stably compact spaces},
  volume       = {823},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bisimulation invariant monadic-second order logic in the
finite. <em>TCS</em>, <em>823</em>, 26–43. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider bisimulation-invariant monadic second-order logic over various classes of finite transition systems. We present several combinatorial characterisations of when the expressive power of this fragment coincides with that of the modal μ -calculus. Using these characterisations we prove for some simple classes of transition systems that this is indeed the case. In particular, we show that, over the class of all finite transition systems with Cantor–Bendixson rank at most k , bisimulation-invariant coincides with L μ Lμ .},
  archive      = {J_TCS},
  author       = {Achim Blumensath and Felix Wolf},
  doi          = {10.1016/j.tcs.2020.03.001},
  journal      = {Theoretical Computer Science},
  pages        = {26-43},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bisimulation invariant monadic-second order logic in the finite},
  volume       = {823},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On collecting semantics for program analysis. <em>TCS</em>,
<em>823</em>, 1–25. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning on a complex system in the abstract interpretation theory starts with a formal description of the system behavior specified by a collecting semantics. We take the common point of view that a collecting semantics is a very precise semantics from which other abstractions may be derived. We elaborate on both the concepts of precision and derivability, and introduce a notion of adequacy which tell us when a collecting semantics is a good choice for a given family of abstractions. We instantiate this approach to the case of first-order functional programs by considering three common collecting semantics and some abstract properties of functions. We study their relative precision and give a constructive characterization of the classes of abstractions which are adequate for the collecting semantics.},
  archive      = {J_TCS},
  author       = {Gianluca Amato and Maria Chiara Meo and Francesca Scozzari},
  doi          = {10.1016/j.tcs.2020.02.021},
  journal      = {Theoretical Computer Science},
  pages        = {1-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On collecting semantics for program analysis},
  volume       = {823},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Move-optimal partial gathering of mobile agents without
identifiers or global knowledge in asynchronous unidirectional rings.
<em>TCS</em>, <em>822</em>, 92–109. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the partial gathering problem of mobile agents in asynchronous unidirectional ring networks. The partial gathering problem is a generalization of the (well-investigated) total gathering problem, which requires that all the k agents distributed in the network terminate at a single node. The partial gathering problem requires, for a given positive integer g ( g(&amp;lt;k) , that all the agents terminate in a configuration such that either at least g agents or no agent exists at each node. The requirement for the partial gathering problem is strictly weaker than that for the total gathering problem, and thus it is interesting to clarify the difference on the move complexity between them. In this paper, we aim to solve the partial gathering problem for agents without identifiers or any global knowledge such as the number k of agents or the number n of nodes. We consider deterministic and randomized cases. First, in the deterministic case , we show that the set of unsolvable initial configurations is the same as that for the case of agents with knowledge of k . In addition, we propose an algorithm that solves the problem from any solvable initial configuration in a total number of O ( g n ) O(gn) moves. Next, in the randomized case, we propose an algorithm that solves the problem in a total number of O ( g n ) O(gn) moves in expectation from any initial configuration. Note that g g&amp;lt;k holds and agents require a total number of Ω ( g n ) Ω(gn) (resp., Ω ( k n ) Ω(kn) ) moves to solve the partial (resp., total) gathering problem. Thus, our algorithms can solve the partial gathering problem in asymptotically optimal total number of moves without identifiers or global knowledge, and the total number of O ( g n ) O(gn) moves is strictly smaller than that for the total gathering problem.},
  archive      = {J_TCS},
  author       = {Masahiro Shibata and Norikazu Kawata and Yuichi Sudo and Fukuhito Ooshita and Hirotsugu Kakugawa and Toshimitsu Masuzawa},
  doi          = {10.1016/j.tcs.2020.04.002},
  journal      = {Theoretical Computer Science},
  pages        = {92-109},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Move-optimal partial gathering of mobile agents without identifiers or global knowledge in asynchronous unidirectional rings},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Placing quantified variants of 3-SAT and not-all-equal 3-SAT
in the polynomial hierarchy. <em>TCS</em>, <em>822</em>, 72–91. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity of variants of 3 -SAT and Not-All-Equal 3 -SAT is well studied. However, in contrast, very little is known about the complexity of the problems&#39; quantified counterparts. In the first part of this paper, we show that ∀∃ 3 -SAT is Π 2 P Π2P -complete even if (1) each variable appears exactly twice unnegated and exactly twice negated, (2) each clause is a disjunction of exactly three distinct variables, and (3) the number of universal variables is equal to the number of existential variables. Furthermore, we show that the problem remains Π 2 P Π2P -complete if (1a) each universal variable appears exactly once unnegated and exactly once negated, (1b) each existential variable appears exactly twice unnegated and exactly twice negated, and (2) and (3) remain unchanged. On the other hand, the problem becomes NP-complete for certain variants in which each universal variable appears exactly once. In the second part of the paper, we establish Π 2 P Π2P -completeness for ∀∃ Not-All-Equal 3 -SAT even if (1′) the Boolean formula is linear and monotone, (2′) each universal variable appears exactly once and each existential variable appears exactly three times, and (3′) each clause is a disjunction of exactly three distinct variables that contains at most one universal variable. On the positive side, we uncover variants of ∀∃ Not-All-Equal 3 -SAT that are co-NP-complete or solvable in polynomial time .},
  archive      = {J_TCS},
  author       = {Janosch Döcker and Britta Dorn and Simone Linz and Charles Semple},
  doi          = {10.1016/j.tcs.2020.04.003},
  journal      = {Theoretical Computer Science},
  pages        = {72-91},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Placing quantified variants of 3-SAT and not-all-equal 3-SAT in the polynomial hierarchy},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equilibria in doodle polls under three tie-breaking rules.
<em>TCS</em>, <em>822</em>, 61–71. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doodle polls allow people to schedule meetings or events based on time preferences of participants. Each participant indicates on a web-based poll form which time slots they find acceptable and a time slot with the most votes is chosen. This is a social choice mechanism known as approval voting , in which a standard assumption is that all voters vote sincerely —no one votes “no” on a time slot they prefer to a time slot they have voted “yes” on. We take a game-theoretic approach to understanding what happens in approval voting assuming participants vote sincerely. While our instances are framed in the context of the Doodle poll application, the results apply more broadly to approval voting. First we characterize Doodle poll instances where sincere pure Nash Equilibria (NE) exist, under lexicographic tie-breaking, random candidate, and random voter tie-breaking. We then study the quality of such NE voting profiles in Doodle polls, showing the price of anarchy and price of stability are both unbounded, even when a time slot that many participants vote yes for is selected. Finally, we find some reasonable conditions under which the quality of the NE (and strong NE) is good.},
  archive      = {J_TCS},
  author       = {Barbara M. Anthony and Christine Chung},
  doi          = {10.1016/j.tcs.2020.03.024},
  journal      = {Theoretical Computer Science},
  pages        = {61-71},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Equilibria in doodle polls under three tie-breaking rules},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Coreness of cooperative games with truncated submodular
profit functions. <em>TCS</em>, <em>822</em>, 49–60. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coreness represents solution concepts related to core in cooperative games, which captures the stability of players. Motivated by the scale effect in social networks, economics and other scenario, we study the coreness of cooperative game with truncated submodular profit functions. Specifically, the profit function f ( ⋅ ) f(⋅) is defined by a truncation of a submodular function σ ( ⋅ ) σ(⋅) : f ( ⋅ ) = σ ( ⋅ ) f(⋅)=σ(⋅) if σ ( ⋅ ) ≥ η σ(⋅)≥η and f ( ⋅ ) = 0 f(⋅)=0 otherwise, where η is a given threshold. In this paper, we study the core and three core-related concepts of truncated submodular profit cooperative game. We first prove that whether core is empty can be decided in polynomial time and an allocation in core also can be found in polynomial time when core is not empty. When core is empty, we show hardness results and approximation algorithms for computing other core-related concepts including relative least-core value, absolute least-core value and least average dissatisfaction value.},
  archive      = {J_TCS},
  author       = {Wei Chen and Xiaohan Shan and Xiaoming Sun and Jialin Zhang},
  doi          = {10.1016/j.tcs.2020.04.004},
  journal      = {Theoretical Computer Science},
  pages        = {49-60},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Coreness of cooperative games with truncated submodular profit functions},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Weak mitoticity of bounded disjunctive and conjunctive
truth-table autoreducible sets. <em>TCS</em>, <em>822</em>, 36–48. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaßer et al. (SIAMJCOMP 2008 and TCS 2009) 2 proved existence of two sparse sets A and B in EXP, where A is 3-tt (truth-table) polynomial-time autoreducible but not weakly polynomial-time Turing mitotic and B is polynomial-time 2-tt autoreducible but not weakly polynomial-time 2-tt mitotic. We unify and strengthen both of those results by showing that there is a sparse set in EXP that is polynomial-time 2-tt autoreducible but not even weakly polynomial-time Turing mitotic. All these results indicate that polynomial-time autoreducibilities in general do not imply polynomial-time mitoticity at all with the only exceptions of the many-one and 1-tt reductions. On the other hand, however, we proved that every autoreducible set for the polynomial-time bounded disjunctive or conjunctive tt reductions is weakly mitotic for the polynomial-time tt reduction that makes logarithmically many queries only. This shows that autoreducible sets for reductions making more than one query could still be mitotic in some way if they possess certain special properties.},
  archive      = {J_TCS},
  author       = {Liyu Zhang and Mahmoud Quweider and Hansheng Lei and Fitra Khan},
  doi          = {10.1016/j.tcs.2020.04.005},
  journal      = {Theoretical Computer Science},
  pages        = {36-48},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Weak mitoticity of bounded disjunctive and conjunctive truth-table autoreducible sets},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NP-completeness of the game KingdominoTM. <em>TCS</em>,
<em>822</em>, 23–35. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kingdomino TM TM is a board game designed by Bruno Cathala and edited by Blue Orange since 2016. The goal is to place 2 × 1 2×1 dominoes on a grid layout, and get a better score than other players. Each 1 × 1 1×1 domino cell has a color that must match at least one adjacent cell, and an integer number of crowns (possibly none) used to compute the score. We prove that even with full knowledge of the future of the game, it is NP NP -complete to decide whether a given score is achievable at Kingdomino TM TM .},
  archive      = {J_TCS},
  author       = {Viet-Ha Nguyen and Kévin Perrot and Mathieu Vallet},
  doi          = {10.1016/j.tcs.2020.04.007},
  journal      = {Theoretical Computer Science},
  pages        = {23-35},
  shortjournal = {Theor. Comput. Sci.},
  title        = {NP-completeness of the game KingdominoTM},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A linear-space data structure for range-LCP queries in
poly-logarithmic time. <em>TCS</em>, <em>822</em>, 15–22. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let T [ 1 , n ] T[1,n] be a text of length n and T [ i , n ] T[i,n] be the suffix starting at position i . Also, for any two strings X and Y , let LCP ( X , Y ) LCP(X,Y) denote their longest common prefix. The range-LCP of T T w.r.t. a range [ α , β ] [α,β] , where 1 ≤ α 1≤α&amp;lt;β≤n is rlcp ( α , β ) = max ⁡ { | LCP ( T [ i , n ] , T [ j , n ] ) | | i ≠ j a n d i , j ∈ [ α , β ] } rlcp(α,β)=max⁡{|LCP(T[i,n],T[j,n])||i≠jandi,j∈[α,β]} Amir et al. [2] introduced the indexing version of this problem, where the task is to build a data structure over T T , so that rlcp ( α , β ) rlcp(α,β) for any query range [ α , β ] [α,β] can be reported efficiently. They proposed an O ( n log 1 + ϵ ⁡ n ) O(nlog1+ϵ⁡n) space structure with query time O ( log ⁡ log ⁡ n ) O(log⁡log⁡n) , and a linear space (i.e., O ( n ) O(n) words) structure with query time O ( δ log ⁡ log ⁡ n ) O(δlog⁡log⁡n) , where δ = β − α + 1 δ=β−α+1 is the length of the input range and ϵ &gt; 0 ϵ&amp;gt;0 is an arbitrarily small constant. Later, Patil et al. [5] proposed another linear space structure with an improved query time of O ( δ log ϵ ⁡ δ ) O(δlogϵ⁡δ) . This poses an interesting question, whether it is possible to answer rlcp ( ⋅ , ⋅ ) rlcp(⋅,⋅) queries in poly-logarithmic time using a linear space data structure . In this paper, we settle this question by presenting an O ( n ) O(n) space data structure with query time O ( log 1 + ϵ ⁡ n ) O(log1+ϵ⁡n) and construction time O ( n log ⁡ n ) O(nlog⁡n) .},
  archive      = {J_TCS},
  author       = {Paniz Abedin and Arnab Ganguly and Wing-Kai Hon and Kotaro Matsuda and Yakov Nekrich and Kunihiko Sadakane and Rahul Shah and Sharma V. Thankachan},
  doi          = {10.1016/j.tcs.2020.04.009},
  journal      = {Theoretical Computer Science},
  pages        = {15-22},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A linear-space data structure for range-LCP queries in poly-logarithmic time},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fully dynamic arboricity maintenance. <em>TCS</em>,
<em>822</em>, 1–14. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected graph , its arboricity is the minimum number of edge disjoint forests that its edge set can be partitioned into. We develop the first fully dynamic algorithms to determine the arboricity of a graph under edge insertions and deletions. While our insertion algorithm is based on known static algorithms to determine the arboricity, our deletion algorithm is, to the best of our knowledge, new. Our algorithms take O(mlog⁡n) time to insert or delete an edge where m is the number of edges in the graph while the best static algorithm to compute arboricity takes O(m3/2log⁡(n2/m)) time [9] . We complement our upper bound with a lower bound of amortized Ω(log⁡n) time for an update for an algorithm that maintains a forest decomposition of size arboricity of the graph under edge insertions and deletions.},
  archive      = {J_TCS},
  author       = {Niranka Banerjee and Venkatesh Raman and Saket Saurabh},
  doi          = {10.1016/j.tcs.2020.04.010},
  journal      = {Theoretical Computer Science},
  pages        = {1-14},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fully dynamic arboricity maintenance},
  volume       = {822},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Skew circuits of small width. <em>TCS</em>, <em>821</em>,
111–123. (<a href="https://doi.org/10.1016/j.tcs.2017.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A celebrated result of Barrington (1985) proved that polynomial size, width-5 branching programs (BP) are equivalent in power to a restricted form of branching programs – polynomial sized width-5 permutation branching programs (PBP), which in turn capture all of NC 1 . On the other hand it is known that width-3 PBPs require exponential size to compute the AND function. No such lower bound is known for width-4 PBPs, however it is widely conjectured that width-4 PBPs will not capture all of NC 1 . In this work, we study the power of bounded width branching programs by comparing them with bounded width skew circuits. It is well known that branching programs of bounded width have the same power as skew circuit of bounded width. The naive approach converts a BP of width w to a skew circuit of width w 2 w2 . We improve this bound and show that BP of width w ≥ 5 w≥5 can be converted to a skew circuit of width 7. This also implies that skew circuits of bounded width are equal in power to skew circuits of width 7. For the other way, we prove that for any w ≥ 2 w≥2 , a skew circuit of width w can be converted into an equivalent branching program of width w . We prove that width-2 skew circuits are not universal while width-3 skew circuits are universal and that any polynomial sized CNF or DNF is computable by width 3 skew circuits of polynomial size. It is known that Parity does not have small CNFs or DNFs. It is easy to see that Parity has width-4 skew circuits. We prove that a width-3 skew circuit computing Parity requires exponential size. This gives an exponential separation between the power of width-3 skew circuits and width-4 skew circuits.},
  archive      = {J_TCS},
  author       = {Nikhil Balaji and Andreas Krebs and Nutan Limaye},
  doi          = {10.1016/j.tcs.2017.03.013},
  journal      = {Theoretical Computer Science},
  pages        = {111-123},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Skew circuits of small width},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). List-coloring – parameterizing from triviality.
<em>TCS</em>, <em>821</em>, 102–110. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical graph coloring problem is given an undirected graph and the goal is to color the vertices of the graph with the minimum number of colors so that endpoints of each edge gets different colors. In list-coloring, each vertex is given a list of allowed colors with which it can be colored. Most versions of the problems are hard in several paradigms including approximation and parameterized complexity. We consider a few versions of the problems that are polynomial time solvable and try to extend the notion of feasible algorithms by parameterizing suitably in the paradigm of parameterized complexity. In particular, we provide extensions of these polynomial time solvable coloring problems that belong to the extreme ends of the parameterized complexity hierarchy including fixed-parameter tractable (FPT) class or the complexity class XP or W [ 1 ] W[1] -hard or para -NP -hard (i.e. NP -hard even for constant values of the parameter). Specifically, we consider generalizations of odd cycle transversal and edge bipartization in the context of list-coloring and show them fixed-parameter tractable. We also look at list coloring where each list has n − k n−k colors and the goal is to color the vertices respecting the list. We show that the problem is in the parameterized complexity class XP, when parameterized by k .},
  archive      = {J_TCS},
  author       = {Pranav Arora and Aritra Banik and Vijay Kumar Paliwal and Venkatesh Raman},
  doi          = {10.1016/j.tcs.2020.02.022},
  journal      = {Theoretical Computer Science},
  pages        = {102-110},
  shortjournal = {Theor. Comput. Sci.},
  title        = {List-coloring – parameterizing from triviality},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic growth rate of square grids dominating sets: A
symbolic dynamics approach. <em>TCS</em>, <em>821</em>, 87–101. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this text, we prove the existence of an asymptotic growth rate of the number of dominating sets (and variants) on finite rectangular grids, when the dimensions of the grid grow to infinity. Moreover, we provide, for each of the variants, an algorithm which computes the growth rate. We also give bounds on these rates provided by a computer program.},
  archive      = {J_TCS},
  author       = {Silvère Gangloff and Alexandre Talon},
  doi          = {10.1016/j.tcs.2020.03.006},
  journal      = {Theoretical Computer Science},
  pages        = {87-101},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Asymptotic growth rate of square grids dominating sets: A symbolic dynamics approach},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterization of interval graphs that are unpaired
2-disjoint path coverable. <em>TCS</em>, <em>821</em>, 71–86. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given disjoint source and sink sets, S={s1,…,sk} and T={t1,…,tk} , in a graph G , an unpaired k-disjoint path cover joining S and T is a set of pairwise vertex-disjoint paths {P1,…,Pk} that altogether cover every vertex of the graph, in which Pi is a path from source si to some sink tj . In terms of a generalized scattering number, named an r-scattering number , we characterize interval graphs that have an unpaired 2-disjoint path cover joining S and T for any possible configurations of source and sink sets S and T of size 2 each. Also, it is shown that the r -scattering number of an interval graph can be computed in polynomial time .},
  archive      = {J_TCS},
  author       = {Jung-Heum Park and Hyeong-Seok Lim},
  doi          = {10.1016/j.tcs.2020.03.010},
  journal      = {Theoretical Computer Science},
  pages        = {71-86},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Characterization of interval graphs that are unpaired 2-disjoint path coverable},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A search game on a hypergraph with booby traps.
<em>TCS</em>, <em>821</em>, 57–70. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set of n boxes, located on the vertices of a hypergraph G , contain known but different rewards. A Searcher opens all the boxes in some hyperedge of G with the objective of collecting the maximum possible total reward. Some of the boxes, however, are booby trapped. If the Searcher opens a booby trapped box, the search ends and she loses all her collected rewards. We assume the number k of booby traps is known, and we model the problem as a zero-sum game between the maximizing Searcher and a minimizing Hider , where the Hider chooses k boxes to booby trap and the Searcher opens all the boxes in some hyperedge . The payoff is the total reward collected by the Searcher. This model could reflect a military operation in which a drone gathers intelligence from guarded locations, and a booby trapped box being opened corresponds to the drone being destroyed or incapacitated. It could also model a machine scheduling problem , in which rewards are obtained from successfully processing jobs but the machine may crash. We solve the game when G is a 1-uniform hypergraph (the hyperedges are all singletons), so the Searcher can open just 1 box. When G is the complete hypergraph (containing all possible hyperedges), we solve the game in a few cases: (1) same reward in each box, (2) k = 1 k=1 , and (3) n = 4 n=4 and k = 2 k=2 . The solutions to these few cases indicate that a general simple, closed form solution to the game appears unlikely.},
  archive      = {J_TCS},
  author       = {Thomas Lidbetter and Kyle Y. Lin},
  doi          = {10.1016/j.tcs.2020.03.011},
  journal      = {Theoretical Computer Science},
  pages        = {57-70},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A search game on a hypergraph with booby traps},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new algorithm design technique for hard problems.
<em>TCS</em>, <em>821</em>, 45–56. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heuristic algorithms have been used for a long time to tackle problems that are known or conjectured intractable. A heuristic algorithm is one that provides a correct decision for most inputs, but may fail on some. We focus on the case when failure means that the algorithm does not return any answer, rather than returning a wrong result. These algorithms are called errorless heuristics. A reasonable quality measure for heuristics is the failure rate over the set of n -bit instances. When no efficient exact algorithm is available for a problem, then, ideally, we would like one with vanishing failure rate. We show, however, that this is hard to achieve: unless a complexity theoretic hypothesis fails, some NP -complete problems cannot have a polynomial-time errorless heuristic algorithm with any vanishing failure rate. On the other hand, we prove that vanishing, even exponentially small, failure rate is achievable, if we use a somewhat different accounting scheme to count the failures. This is based on special sets, that we call α -spheres, which are the images of the n -bit strings under a bijective, polynomial-time computable and polynomial-time invertible encoding function α . Our main result is that polynomial-time errorless heuristic algorithms exist, with exponentially low failure rates on the α -spheres, for a large class of decision problems. This class includes, surprisingly, all known intuitively natural NP -complete problems. We also explore some connections to the theory of average case complexity.},
  archive      = {J_TCS},
  author       = {András Faragó and Rupei Xu},
  doi          = {10.1016/j.tcs.2020.03.012},
  journal      = {Theoretical Computer Science},
  pages        = {45-56},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A new algorithm design technique for hard problems},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Makespan minimization on unrelated parallel machines with a
few bags. <em>TCS</em>, <em>821</em>, 34–44. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let there be a set M of m parallel machines and a set J of n jobs, where each job j takes p i , j pi,j time units on machine M i Mi . In makespan minimization the goal is to schedule each job non-preemptively on a machine such that the length of the schedule, the makespan, is minimum. We investigate a generalization of makespan minimization on unrelated parallel machines ( R | | C m a x R||Cmax ) where J is partitioned into b bags B = ( B 1 , … , B b ) B=(B1,…,Bb) , and no two jobs belonging to the same bag can be scheduled on the same machine. First we present a simple b -approximation algorithm for R | | C m a x R||Cmax with bags ( R | b a g | C m a x R|bag|Cmax ). We also give a polynomial-time approximation scheme (PTAS) for R | b a g | C m a x R|bag|Cmax with machine types where both the number of machine types and bags are constant; two machines M i Mi and M i ′ Mi′ have the same machine type if p i , j = p i ′ , j pi,j=pi′,j for all j ∈ J j∈J . This result infers the existence of a PTAS for uniform parallel machines ( Q | b a g | C m a x Q|bag|Cmax ) when the number of machine speeds and number of bags are both constant. Then, we present a b / 2 b/2 -approximation algorithm for the graph balancing problem with b ≥ 2 b≥2 bags; the approximation ratio is tight for b = 3 b=3 , unless P = NP P=NP , and this algorithm solves the graph balancing problem with b = 2 b=2 bags in polynomial time . In addition, we present a polynomial-time algorithm for the restricted assignment problem on uniform parallel machines with bags when all the jobs have unit length. To complement our algorithmic results, we show that when the jobs have lengths 1 or 2 it is NP NP -hard to approximate the optimum makespan within a factor smaller than 3/2 for both the restricted assignment and graph balancing problems with b = 2 b=2 bags and b = 3 b=3 bags, respectively. We also prove that Q | b a g | C m a x Q|bag|Cmax with b = 2 b=2 bags is strongly NP NP -hard.},
  archive      = {J_TCS},
  author       = {Daniel R. Page and Roberto Solis-Oba},
  doi          = {10.1016/j.tcs.2020.03.013},
  journal      = {Theoretical Computer Science},
  pages        = {34-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Makespan minimization on unrelated parallel machines with a few bags},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Interaction-aware influence maximization and iterated
sandwich method. <em>TCS</em>, <em>821</em>, 23–33. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization problem has been studied extensively with the development of online social networks . Most of the existing works focus on the maximization of influence spread under the assumption that the number of influenced users determines the success of a product promotion. However, the profit of some products such as online game depends on the interactions among users besides the number of users. In this paper, we take both the number of active users and the user-to-user interactions into account and propose the interaction-aware influence maximization problem. To address this practical issue, we analyze its complexity and modularity, propose the sandwich theory which is based on decomposing the non-submodular objective function into the difference of two submodular functions and design two iterated sandwich algorithms which are guaranteed to get data dependent approximation solution. Through real data sets , we verify the effectiveness of our proposed algorithms.},
  archive      = {J_TCS},
  author       = {Chuangen Gao and Shuyang Gu and Ruiqi Yang and Jiguo Yu and Weili Wu and Dachuan Xu},
  doi          = {10.1016/j.tcs.2020.03.016},
  journal      = {Theoretical Computer Science},
  pages        = {23-33},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Interaction-aware influence maximization and iterated sandwich method},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Offline and online algorithms for single-minded selling
problem. <em>TCS</em>, <em>821</em>, 15–22. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a seller with k types of items and n single-minded buyers, i.e., each buyer is only interested in a particular bundle of items, to maximize the revenue, the seller must assign some amount of bundles to each buyer with respect to the buyer&#39;s accepted price. Each buyer b i bi is associated with a value function v i ( ⋅ ) vi(⋅) such that v i ( x ) vi(x) is the accepted unit bundle price b i bi is willing to pay for x bundles. In this paper, we assume that bundles can be sold fractionally. The single-minded item selling problem is proved to be NP-hard. Moreover, we give an O ( k ) O(k) -approximation algorithm. For the online version, i.e., buyers come one by one and the decision must be made immediately on the arrival of each buyer, an O ( k ⋅ ( log ⁡ h + log ⁡ k ) ) O(k⋅(log⁡h+log⁡k)) -competitive algorithm is given, where h is the highest unit item price among all buyers.},
  archive      = {J_TCS},
  author       = {Yong Zhang and Francis Y.L. Chin and Sheung-Hung Poon and Hing-Fung Ting and Dachuan Xu and Dongxiao Yu},
  doi          = {10.1016/j.tcs.2020.03.017},
  journal      = {Theoretical Computer Science},
  pages        = {15-22},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Offline and online algorithms for single-minded selling problem},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calibration scheduling with time slot cost. <em>TCS</em>,
<em>821</em>, 1–14. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the scheduling problem with calibrations and time slot costs. In this problem, the machine has to be calibrated to run a job and such a calibration only remains valid for a fixed time period of length T , after which it must be recalibrated in order to execute jobs. On the other hand, a certain cost will be incurred when the machine executes a job and such a cost is determined by the time slot that is occupied by the job in the schedule. We consider jobs with release times, deadlines and identical processing times. The objective is to schedule the jobs on a single machine and minimize the total cost while calibrating the machine at most K times. We investigate the structure of the optimal schedule and based on that we propose dynamic programs for different scenarios of the problem. At last, for another variant of the problem without the consideration of machine calibration, a greedy algorithm is proposed, which is based on matroid theory.},
  archive      = {J_TCS},
  author       = {Kai Wang},
  doi          = {10.1016/j.tcs.2020.03.018},
  journal      = {Theoretical Computer Science},
  pages        = {1-14},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Calibration scheduling with time slot cost},
  volume       = {821},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subversion-resilient signatures: Definitions, constructions
and applications. <em>TCS</em>, <em>820</em>, 91–122. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a formal treatment of security of digital signatures against subversion attacks (SAs). Our model of subversion generalizes previous work in several directions, and is inspired by the proliferation of software attacks (e.g., malware and buffer overflow attacks), and by the recent revelations of Edward Snowden about intelligence agencies trying to surreptitiously sabotage cryptographic algorithms . The main security requirement we put forward demands that a signature scheme should remain unforgeable even in the presence of an attacker applying SAs (within a certain class of allowed attacks) in a fully-adaptive and continuous fashion. Previous notions—e.g., the notion of security against algorithm-substitution attacks introduced by Bellare et al. (CRYPTO ‘14) for symmetric encryption—were non-adaptive and non-continuous. In this vein, we show both positive and negative results for the goal of constructing subversion-resilient signature schemes.},
  archive      = {J_TCS},
  author       = {Giuseppe Ateniese and Bernardo Magri and Daniele Venturi},
  doi          = {10.1016/j.tcs.2020.03.021},
  journal      = {Theoretical Computer Science},
  pages        = {91-122},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Subversion-resilient signatures: Definitions, constructions and applications},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault-free cycles embedding in folded hypercubes with f4.
<em>TCS</em>, <em>820</em>, 85–90. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The n -dimensional folded hypercube F Q n FQn interconnection network has been shown that it is bipartite for every odd n ≥ 3 n≥3 , and which is non-bipartite for every even n ≥ 2 n≥2 . Let F 4 = { f 1 , f 2 , f 3 , f 4 } F4={f1,f2,f3,f4} denote the faulty set of extreme vertices from any four cycle in F Q n FQn . Then, we show that the fault-free cycles can be embedded in F Q n − F 4 FQn−F4 as follows: The results are optimal with respect to the length type of embedded cycles in F Q n − F 4 FQn−F4 .},
  archive      = {J_TCS},
  author       = {Che-Nan Kuo and Yu-Huei Cheng},
  doi          = {10.1016/j.tcs.2020.03.015},
  journal      = {Theoretical Computer Science},
  pages        = {85-90},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fault-free cycles embedding in folded hypercubes with f4},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generic hardness of inversion on ring and its relation to
self-bilinear map. <em>TCS</em>, <em>820</em>, 60–84. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the generic hardness of the inversion problem on a ring, which is a problem to compute the inverse of a given prime c by just using additions, subtractions and multiplications on the ring. If the characteristic of an underlying ring is public and coprime to c , then it is easy to compute the inverse of c by using the extended Euclidean algorithm . On the other hand, if the characteristic is hidden, it seems difficult to compute it. For discussing the generic hardness of the inversion problem, we first extend existing generic ring models to capture a ring of an unknown characteristic. Then we prove that there is no generic algorithm to solve the inversion problem in our model when the underlying ring is isomorphic to Z p Zp for a randomly chosen prime p assuming the hardness of factorization of an unbalanced modulus. We also study a relation between the inversion problem on a ring and a self-bilinear map. Namely, we give a construction of a self-bilinear map based on a ring on which the inversion problem is hard, and prove that natural complexity assumptions including the multilinear computational Diffie-Hellman (MCDH) assumption hold w.r.t. the resulting sef-bilinear map.},
  archive      = {J_TCS},
  author       = {Takashi Yamakawa and Shota Yamada and Goichiro Hanaoka and Noboru Kunihiro},
  doi          = {10.1016/j.tcs.2020.03.009},
  journal      = {Theoretical Computer Science},
  pages        = {60-84},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Generic hardness of inversion on ring and its relation to self-bilinear map},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local approximation of the maximum cut in regular graphs.
<em>TCS</em>, <em>820</em>, 45–59. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the distributed complexity of finding an approximation of the maximum cut ( MaxCut ) in graphs. A classical algorithm consists in letting each vertex choose its side of the cut uniformly at random. This does not require any communication and achieves an approximation ratio of at least 1 2 12 in expectation. When the graph is d -regular and triangle-free, a slightly better approximation ratio can be achieved with a randomized algorithm running in a single round. Here, we investigate the round complexity of deterministic distributed algorithms for MaxCut in regular graphs . We first prove that if G is d -regular, with d even and fixed, no deterministic algorithm running in a constant number of rounds can achieve a constant approximation ratio. We then give a simple one-round deterministic algorithm achieving an approximation ratio of 1 d 1d for d -regular graphs when d is odd. We show that this is best possible in several ways, and in particular no deterministic algorithm with approximation ratio 1 d + ϵ 1d+ϵ (with ϵ &gt; 0 ϵ&amp;gt;0 ) can run in a constant number of rounds. We also prove results of a similar flavor for the MaxDiCut problem in regular oriented graphs , where we want to maximize the number of arcs oriented from the left part to the right part of the cut.},
  archive      = {J_TCS},
  author       = {Étienne Bamas and Louis Esperet},
  doi          = {10.1016/j.tcs.2020.03.008},
  journal      = {Theoretical Computer Science},
  pages        = {45-59},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Local approximation of the maximum cut in regular graphs},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Markov chain analysis of evolutionary algorithms on OneMax
function – from coupon collector’s problem to (1 + 1) EA. <em>TCS</em>,
<em>820</em>, 26–44. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theoretical investigation of Evolutionary Algorithms (EAs) has increased our understanding of the computational mechanism of algorithms. OneMax is a test function most frequently and deeply studied in the field of EAs. In this work, a method is presented for describing the runtime properties of ( 1 + 1 ) (1+1) EA on OneMax. This method is motivated by the work of Erdös and Rényi treating the coupon collector&#39;s problem. They showed that the success probability of the coupon collector&#39;s problem is given by a function of double exponential form, and that the number of uncollected coupons follows the Poisson distribution . Today, the double exponential function is called Gumbel function, which is one of three fundamental functions in extreme value statistics. We introduce an algorithm that is a variant of the ( 1 + 1 ) (1+1) EA, First Order Evolutionary Algorithm (FO-EA). FO-EA takes into account only the effect of single-bit mutations in the ( 1 + 1 ) (1+1) EA, which in general includes multiple-bit mutations. We modified the method of Erdös and Rényi to apply FO-EA. We apply the Gumbel distribution for calculating the success probability of the ( 1 + 1 ) (1+1) EA on OneMax. This method turns out to give a sufficiently reliable estimation for success probabilities, even in the tail region.},
  archive      = {J_TCS},
  author       = {Yu-an Zhang and Xiaofeng Qin and Qinglian Ma and Minghao Zhao and Satoru Hiwa and Tomoyuki Hiroyasu and Hiroshi Furutani},
  doi          = {10.1016/j.tcs.2020.03.007},
  journal      = {Theoretical Computer Science},
  pages        = {26-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Markov chain analysis of evolutionary algorithms on OneMax function – from coupon collector&#39;s problem to (1 + 1) EA},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Small normalized circuits for semi-disjoint bilinear forms
require logarithmic and-depth. <em>TCS</em>, <em>820</em>, 17–25. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider normalized Boolean circuits that use binary operations of disjunction and conjunction, and unary negation, with the restriction that negation can be only applied to input variables. We derive a lower bound trade-off between the size of normalized Boolean circuits computing Boolean semi-disjoint bilinear forms and their conjunction-depth (i.e., the maximum number of and-gates on a directed path to an output gate). In particular, we show that any normalized Boolean circuit of at most ϵ log ⁡ n ϵlog⁡n conjunction-depth computing the n -dimensional Boolean vector convolution has Ω ( n 2 − 4 ϵ ) Ω(n2−4ϵ) and-gates. For Boolean matrix product , we derive even a stronger lower-bound trade-off. Instead of conjunction-depth we use the negation-dependent conjunction-depth, where one counts only and-gates whose each direct predecessor has a (not necessarily direct) predecessor representing a negated input variable. We show that if a normalized Boolean circuit of at most ϵ log ⁡ n ϵlog⁡n negation-dependent conjunction-depth computes the n × n n×n Boolean matrix product then the circuit has Ω ( n 3 − 2 ϵ ) Ω(n3−2ϵ) and-gates. We complete our lower-bound trade-offs for the Boolean convolution and matrix product with upper-bound trade-offs of similar form yielded by the known fast algebraic algorithms.},
  archive      = {J_TCS},
  author       = {Andrzej Lingas},
  doi          = {10.1016/j.tcs.2020.03.005},
  journal      = {Theoretical Computer Science},
  pages        = {17-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Small normalized circuits for semi-disjoint bilinear forms require logarithmic and-depth},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lift &amp; project systems performing on the
partial-vertex-cover polytope. <em>TCS</em>, <em>820</em>, 1–16. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study integrality gap (IG) lower bounds on strong LP and SDP relaxations derived by the Sherali-Adams ( SA ), Lovász-Schrijver -SDP ( LS + ), Sherali-Adams -SDP ( SA + ), and Lasserre -SDP ( La ) lift-and-project (L&amp;P) systems for the t -Partial-Vertex-Cover ( t -PVC ) problem, a variation of the classic Vertex-Cover problem in which only t edges need to be covered. t -PVC admits a 2-approximation using various algorithmic techniques, all relying on a natural LP relaxation. With starting point this LP relaxation, our main results assert that for every ϵ &gt; 0 ϵ&amp;gt;0 , level- Θ ( n ) Θ(n) LPs or SDPs derived by all known L&amp;P systems that have been used for positive algorithmic results (but the Lasserre hierarchy) have IGs at least ( 1 − ϵ ) n / t (1−ϵ)n/t , where n is the number of vertices of the input graph. Our lower bounds are nearly tight, in that level- n relaxations, even of the weakest systems, have integrality gap 1. Additionally, we give a O ( n ) O(n) integrality gap for the Level-1 Lasserre system and a superconstant general integrality gap for all Level- Θ ( n ) Θ(n) Lasserre derived SDPs. As lift-and-project systems have given the best algorithms known for numerous combinatorial optimization problems , our results show that restricted yet powerful models of computation derived by many L&amp;P systems fail to witness c -approximate solutions to t -PVC for any constant c , and for t = O ( n ) t=O(n) . As further motivation for our results, we show that the SDP that has given the best algorithm known for t -PVC has integrality gap n / t n/t on instances that can be solved by the level-1 LP relaxation derived by the LS system. This constitutes another rare phenomenon where (even in specific instances) a static LP outperforms an SDP that has been used for the best approximation guarantee for the problem at hand. Finally, we believe our results are of independent interest as they are among the very few known integrality gap lower bounds for LP and SDP 0-1 relaxations in which not all variables possess the same semantics in the underlying combinatorial optimization problem. To achieve our results, we utilize a common methodology of constructing solutions to LP relaxations that almost trivially satisfy constraints derived by all SDP L&amp;P systems known to be useful for algorithmic positive results (except the La system). The latter sheds some light as to why La tightenings seem strictly stronger than LS + or SA + tightenings.},
  archive      = {J_TCS},
  author       = {Konstantinos Georgiou and Andy (Jia) Jiang and Edward Lee and Astrid A. Olave and Ian Seong and Twesh Upadhyaya},
  doi          = {10.1016/j.tcs.2020.03.004},
  journal      = {Theoretical Computer Science},
  pages        = {1-16},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lift &amp; project systems performing on the partial-vertex-cover polytope},
  volume       = {820},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A decision procedure and complete axiomatization for
projection temporal logic. <em>TCS</em>, <em>819</em>, 50–84. (<a
href="https://doi.org/10.1016/j.tcs.2017.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To specify and verify the concurrent and reactive systems with the theorem proving approach, a complete axiomatization is formalized for first order projection temporal logic (PTL) with both finite and infinite time. To this end, PTL is restricted to a finite domain, and the syntax, semantics as well as the axiomatization of PTL are presented. Further, the techniques of labeled normal form and labeled normal form graph of PTL formulas are introduced respectively, with which a decision procedure for quantifier free PTL (QFPTL) formulas is given. Moreover, a generalized labeled normal form graph is defined and employed to transform a quantified PTL formula into its equivalent QFPTL formula. Finally, a decision procedure for PTL is formalized and the completeness of the axiomatic system is proved based on the decidability of PTL formulas.},
  archive      = {J_TCS},
  author       = {Xinfeng Shu and Zhenhua Duan and Hongwei Du},
  doi          = {10.1016/j.tcs.2017.09.026},
  journal      = {Theoretical Computer Science},
  pages        = {50-84},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A decision procedure and complete axiomatization for projection temporal logic},
  volume       = {819},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Verify heaps via unified model checking. <em>TCS</em>,
<em>819</em>, 35–49. (<a
href="https://doi.org/10.1016/j.tcs.2017.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of verifying heap evolution properties of pointer programs. To this end, a new unified model checking approach with MSVL (Modeling, Simulation and Verification Language) and PPTL SL is presented. The former is an executable subset of PTL (Projection Temporal Logic) while the latter is an extension of PPTL (Propositional Projection Temporal Logic) with separation logic. MSVL is used to model pointer programs, and PPTL SL to specify heap evolution properties. Technically, on one hand, models of MSVL programs are characterized by Normal Form Graphs (NFGs). On the other hand, PPTL SL is equisatisfiably reduced to its subset which can reuse the decision procedure of PPTL. Our technique is able to deal with a variety of pointer structures such as linked lists and composite structures. In addition, we implement a prototype tool by using an SMT solver as the verification engine in order to demonstrate our approach.},
  archive      = {J_TCS},
  author       = {Xu Lu and Zhenhua Duan and Cong Tian and Hongwei Du},
  doi          = {10.1016/j.tcs.2017.09.025},
  journal      = {Theoretical Computer Science},
  pages        = {35-49},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Verify heaps via unified model checking},
  volume       = {819},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Flow shop for dual CPUs in dynamic voltage scaling.
<em>TCS</em>, <em>819</em>, 24–34. (<a
href="https://doi.org/10.1016/j.tcs.2017.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the following flow shop scheduling problem on two processors. We are given n jobs with a common deadline D , where each job j has workload p i , j pi,j on processor i and a set of processors which can vary their speed dynamically. Job j can be executed on the second processor if the execution of job j is completed on the first processor. Our objective is to find a feasible schedule such that all jobs are completed by the common deadline D with minimized energy consumption. For this model, we present a linear program for the discrete speed case, where the processor can only run at specific speeds in S = { s 1 , s 2 , ⋯ , s q } S={s1,s2,⋯,sq} and the job execution order is fixed. We also provide a m α − 1 mα−1 -approximation algorithm for the arbitrary order case and for continuous speed model where m is the number of processors and α is a parameter of the processor. We then introduce a new variant of flow shop scheduling problem called sense-and-aggregate model motivated by data aggregation in wireless sensor networks where the base station needs to receive data from sensors and then compute a single aggregate result. In this model, the first processor will receive unit size data from sensors and the second processor is responsible for calculating the aggregate result. The second processor can decide when to aggregate and the workload that needs to be done to aggregate x data will be f ( x ) f(x) and another unit size data will be generated as the result of the partial aggregation which will then be used in the next round aggregation. Our objective is to find a schedule such that all data are received and aggregated by the deadline with minimum energy consumption. We present an O ( n 5 ) O(n5) dynamic programming algorithm when f ( x ) = x f(x)=x and a greedy algorithm when f ( x ) = x − 1 f(x)=x−1 . Finally, we investigate the performance of the flowshop problem when the order of jobs is fixed by comparing it to the approximation algorithm with an arbitrary order. We show experimentally that the approximation ratio is close to 1 when there are few machines and when there are more jobs.},
  archive      = {J_TCS},
  author       = {Vincent Chau and Xin Chen and Ken C.K. Fong and Minming Li and Kai Wang},
  doi          = {10.1016/j.tcs.2017.09.014},
  journal      = {Theoretical Computer Science},
  pages        = {24-34},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Flow shop for dual CPUs in dynamic voltage scaling},
  volume       = {819},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial-time algorithm for isomorphism of graphs with
clique-width at most three. <em>TCS</em>, <em>819</em>, 9–23. (<a
href="https://doi.org/10.1016/j.tcs.2017.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clique-width is a measure of complexity of decomposing graphs into certain tree-like structures. The class of graphs with bounded clique-width contains bounded tree-width graphs. We give a polynomial time graph isomorphism algorithm for graphs with clique-width at most three. Our work is independent of the work by Grohe et al. [1] showing that the isomorphism problem for graphs of bounded clique-width is polynomial time .},
  archive      = {J_TCS},
  author       = {Bireswar Das and Murali Krishna Enduri and I. Vinod Reddy},
  doi          = {10.1016/j.tcs.2017.09.013},
  journal      = {Theoretical Computer Science},
  pages        = {9-23},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Polynomial-time algorithm for isomorphism of graphs with clique-width at most three},
  volume       = {819},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Functional dependency restricted insertion propagation.
<em>TCS</em>, <em>819</em>, 1–8. (<a
href="https://doi.org/10.1016/j.tcs.2017.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a rise of research on data provenance and quality, insertion propagation problem has been an important role in data lineage . As an variated version of classic view update problem in relational databases , it is defined on a given database D , a monotonic relational algebraic query Q and its materialized view V on D , insertion propagation aims to find a set ΔD of tuples whose insertion into D guarantees that the result of Q is exactly the view V union with a intended insertion ΔV , i.e, ΔD will not produce side-effect on view. This paper considers functional dependency restricted version insertion propagation problem ‘ FD-vsef-IP ’ which generalizes the computational issues involved in data lineage , it is to find the ΔD not only view side-effect free but also without introducing inconsistency with respect to the predefined functional dependencies. Both data and combined complexity of FD-vsef-IP are studied under both single and group insertion. Plenty of analysis are provided on this problem with respect to queries in different classes on either complexity aspect. Contrary to its counterpart fd -restricted deletion propagation, this paper shows the fd -restricted version is harder to get the optimal solution.},
  archive      = {J_TCS},
  author       = {Dongjing Miao and Zhipeng Cai and Xianmin Liu and Jianzhong Li},
  doi          = {10.1016/j.tcs.2017.03.043},
  journal      = {Theoretical Computer Science},
  pages        = {1-8},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Functional dependency restricted insertion propagation},
  volume       = {819},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The existence of universally agreed fairest semi-matchings
in any given bipartite graph. <em>TCS</em>, <em>818</em>, 83–91. (<a
href="https://doi.org/10.1016/j.tcs.2018.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a bipartite graph G = ( U ∪ V , E ) G=(U∪V,E) where E ⊆ U × V E⊆U×V , a semi-matching is defined as a set of edges M ⊆ E M⊆E , such that each vertex in U is incident with exactly one edge in M . Many previous works focus on the problem of finding the fairest semi-matchings: ones that assign U -vertices with V -vertices as fairly as possible. In these works, fairness is usually measured according to a specific index. In fact, there exist various fairness measures, and they often disagree on the fairness comparison of some semi-matching pairs. In this paper, we prove that there always exists one (or a set of equally fair) semi-matching(s), universally agreed by all the existing fairness measures, to be the fairest among all the semi-matchings of a given bipartite graph . In other words, given that fairness measures disagree on many comparisons between semi-matchings, they nonetheless are all in agreement on the (set of) fairest semi-matching(s) for a given bipartite graph. To prove this, we propose a partially ordered relationship (named Transfer-based Comparison) among the semi-matchings, showing that the greatest elements always exist in such a partially ordered set . We then show that such greatest elements can guarantee to be the fairest ones under the fairness measure of Majorization [1] . This further indicates that such fairest semi-matchings are agreed by all the fairness measures which are compatible with Majorization . To the best knowledge of us, this is true for all existing fairness measures.},
  archive      = {J_TCS},
  author       = {Jian Xu and Soumya Banerjee and Wenjing Rao},
  doi          = {10.1016/j.tcs.2018.03.020},
  journal      = {Theoretical Computer Science},
  pages        = {83-91},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The existence of universally agreed fairest semi-matchings in any given bipartite graph},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). On scheduling multiple two-stage flowshops. <em>TCS</em>,
<em>818</em>, 74–82. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of scheduling n two-stage jobs on m multiple two-stage flowshops, with the objective of minimizing the makespan. The problem is NP-hard even when m is a fixed constant, and becomes strongly NP-hard when m is part of the input. A 2.6-approximation algorithm along with its analysis is presented for an arbitrary m ≥ 2 m≥2 . This is the first approximation algorithm for multiple flowshops when the number m of flowshops is part of the input. The fact that m is part of the input and the time complexity O ( n log ⁡ n ) O(nlog⁡n) of the algorithm demonstrate that the problem, which plays an important role in the current research in cloud computing and data centers , can be solved efficiently with a reasonable level of satisfaction.},
  archive      = {J_TCS},
  author       = {Guangwei Wu and Jianer Chen and Jianxin Wang},
  doi          = {10.1016/j.tcs.2018.04.017},
  journal      = {Theoretical Computer Science},
  pages        = {74-82},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On scheduling multiple two-stage flowshops},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity and algorithms for finding a subset of vectors
with the longest sum. <em>TCS</em>, <em>818</em>, 60–73. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem is, given a set of n vectors in a d -dimensional normed space , find a subset with the largest length of the sum vector. We prove that, in the case of the ℓ p ℓp norm, the problem is APX-complete for any p ∈ [ 1 , 2 ] p∈[1,2] and is not in APX if p ∈ ( 2 , ∞ ) p∈(2,∞) . In the case of an arbitrary norm, we propose an algorithm which finds an optimal solution in time O ( n d − 1 ( d + log ⁡ n ) ) O(nd−1(d+log⁡n)) , improving previously known algorithms. In particular, the two-dimensional problem can be solved in nearly linear time. We also present an improved algorithm for the cardinality-constrained version of the problem with running time O ( d n d + 1 ) O(dnd+1) . In the two-dimensional case, this version is shown to be solvable in nearly quadratic time .},
  archive      = {J_TCS},
  author       = {Vladimir Shenmaier},
  doi          = {10.1016/j.tcs.2018.04.018},
  journal      = {Theoretical Computer Science},
  pages        = {60-73},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity and algorithms for finding a subset of vectors with the longest sum},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linear representation of transversal matroids and gammoids
parameterized by rank. <em>TCS</em>, <em>818</em>, 51–59. (<a
href="https://doi.org/10.1016/j.tcs.2018.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a bipartite graph G = ( U ⊎ V , E ) G=(U⊎V,E) , a linear representation of the transversal matroid associated with G on the ground set U , can be constructed in randomized polynomial time . In fact one can get a linear representation deterministically in time 2 O ( m 2 n ) 2O(m2n) , where m = | U | m=|U| and n = | V | n=|V| , by looping through all the choices made in the randomized algorithm . Other important matroids for which one can obtain linear representation deterministically in time similar to the one for transversal matroids include gammoids and strict gammoids. Strict gammoids are duals of transversal matroids and gammoids are restrictions of strict gammoids. We give faster deterministic algorithms to construct linear representations of transversal matroids, gammoids and strict gammoids. All our algorithms run in time ( m r ) m O ( 1 ) (mr)mO(1) , where m is the cardinality of the ground set and r is the rank of the matroid. In the language of parameterized complexity, we give an XP XP algorithm for finding linear representations of transversal matroids, gammoids and strict gammoids parameterized by the rank of the given matroid.},
  archive      = {J_TCS},
  author       = {Pranabendu Misra and Fahad Panolan and M.S. Ramanujan and Saket Saurabh},
  doi          = {10.1016/j.tcs.2018.02.029},
  journal      = {Theoretical Computer Science},
  pages        = {51-59},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Linear representation of transversal matroids and gammoids parameterized by rank},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An incentive compatible, efficient market for air traffic
flow management. <em>TCS</em>, <em>818</em>, 41–50. (<a
href="https://doi.org/10.1016/j.tcs.2018.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a market-based approach to the Air Traffic Flow Management (ATFM) problem. The goods in our market are delays and buyers are airline companies; the latter pay money to the Federal Aviation Administration (FAA) to buy away the desired amount of delay on a per flight basis. We give a notion of equilibrium for this market and an LP whose every optimal solution gives an equilibrium allocation of flights to landing slots as well as equilibrium prices for the landing slots. Via a reduction to matching, we show that this equilibrium can be computed combinatorially in strongly polynomial time . Moreover, there is a special set of equilibrium prices , which can be computed easily, that is identical to the VCG solution, and therefore the market is incentive compatible (truthful) in dominant strategy .},
  archive      = {J_TCS},
  author       = {Ruta Mehta and Vijay V. Vazirani},
  doi          = {10.1016/j.tcs.2018.09.006},
  journal      = {Theoretical Computer Science},
  pages        = {41-50},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An incentive compatible, efficient market for air traffic flow management},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the modulo degree complexity of boolean functions.
<em>TCS</em>, <em>818</em>, 32–40. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For each integer m ≥ 2 m≥2 , every Boolean function f can be expressed as a unique multilinear polynomial modulo m , and the degree of this multilinear polynomial is called its modulo m degree . In this paper we investigate the modulo degree complexity of total Boolean functions initiated by Parikshit Gopalan et al. [9] , in which they asked the following question: whether the degree complexity of a Boolean function is polynomially related with its modulo m degree. For m be a power of primes, it is already known that the module m degree can be arbitrarily smaller compare to the degree complexity (see Section 2 for details). When m has at least two distinct prime factors, the question remains open. Towards this question, our results include: (1) we obtain some nontrivial equivalent forms of this question; (2) we affirm this question for some special classes of functions; (3) we prove a no-go theorem, explaining why this problem is difficult to attack from the computational complexity point of view; (4) we show a super-linear separation between the degree complexity and the modulo m degree.},
  archive      = {J_TCS},
  author       = {Qian Li and Xiaoming Sun},
  doi          = {10.1016/j.tcs.2018.04.049},
  journal      = {Theoretical Computer Science},
  pages        = {32-40},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the modulo degree complexity of boolean functions},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). NP-completeness results for partitioning a graph into total
dominating sets. <em>TCS</em>, <em>818</em>, 22–31. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A total domatic k-partition of a graph is a partition of its vertex set into k subsets such that each intersects the open neighborhood of each vertex. The maximum k for which a total domatic k -partition exists is known as the total domatic number of a graph G , denoted by d t ( G ) dt(G) . We extend considerably the known hardness results by showing it is -complete to decide whether d t ( G ) ≥ 3 dt(G)≥3 where G is a bipartite planar graph of bounded maximum degree . Similarly, for every k ≥ 3 k≥3 , it is -complete to decide whether d t ( G ) ≥ k dt(G)≥k , where G is split or k -regular. In particular, these results complement recent combinatorial results regarding d t ( G ) dt(G) on some of these graph classes by showing that the known results are, in a sense, best possible. Finally, for general n -vertex graphs, we show the problem is solvable in 2 n n O ( 1 ) 2nnO(1) time, and derive even faster algorithms for special graph classes.},
  archive      = {J_TCS},
  author       = {Mikko Koivisto and Petteri Laakkonen and Juho Lauri},
  doi          = {10.1016/j.tcs.2018.04.006},
  journal      = {Theoretical Computer Science},
  pages        = {22-31},
  shortjournal = {Theor. Comput. Sci.},
  title        = {NP-completeness results for partitioning a graph into total dominating sets},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved kernel for max-bisection above tight lower
bound. <em>TCS</em>, <em>818</em>, 12–21. (<a
href="https://doi.org/10.1016/j.tcs.2018.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study kernelizations for Max-Bisection above Tight Lower Bound , which is to decide if a given graph G = ( V , E ) G=(V,E) admits a bisection with at least ⌈ | E | / 2 ⌉ + k ⌈|E|/2⌉+k crossing edges. The best known kernel for this problem has 16 k vertices. Based on the Gallai–Edmonds decomposition, we divide the vertices of G into several categories and study the roles of vertices in each category for obtaining a larger number of crossing edges. By making use of the properties of maximum matchings in G , graph G is partitioned into a set of blocks, and each block in G is closely related to the number of crossing edges of a bisection of G . By analyzing the number of crossing edges in blocks, an improved kernel of 8 k vertices is presented.},
  archive      = {J_TCS},
  author       = {Qilong Feng and Senmin Zhu and Jianxin Wang},
  doi          = {10.1016/j.tcs.2018.06.027},
  journal      = {Theoretical Computer Science},
  pages        = {12-21},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An improved kernel for max-bisection above tight lower bound},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient enumeration of maximal k-degenerate induced
subgraphs of a chordal graph. <em>TCS</em>, <em>818</em>, 2–11. (<a
href="https://doi.org/10.1016/j.tcs.2018.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider the problem of listing the maximal k -degenerate induced subgraphs of a chordal graph , and propose an output-sensitive algorithm using delay O ( m ⋅ ω ( G ) ) O(m⋅ω(G)) for any n -vertex chordal graph with m edges, where ω ( G ) ≤ n ω(G)≤n is the maximum size of a clique in G . Degeneracy is a well known sparsity measure, and k -degenerate subgraphs are a notion of sparse subgraphs, which generalizes other problems such as independent sets (0-degenerate subgraphs) and forests (1-degenerate subgraphs). Many efficient enumeration algorithms are designed by solving the so-called Extension problem , which asks whether there exists a maximal solution containing a given set of nodes, but no node from a forbidden set. We show that solving this problem is np -complete for maximal k -degenerate induced subgraphs , motivating the need for additional techniques.},
  archive      = {J_TCS},
  author       = {Alessio Conte and Mamadou Moustapha Kanté and Yota Otachi and Takeaki Uno and Kunihiro Wasa},
  doi          = {10.1016/j.tcs.2018.08.009},
  journal      = {Theoretical Computer Science},
  pages        = {2-11},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient enumeration of maximal k-degenerate induced subgraphs of a chordal graph},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface to the special issue on computing and combinatorics.
<em>TCS</em>, <em>818</em>, 1. (<a
href="https://doi.org/10.1016/j.tcs.2020.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Yixin Cao},
  doi          = {10.1016/j.tcs.2020.04.001},
  journal      = {Theoretical Computer Science},
  pages        = {1},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface to the special issue on computing and combinatorics},
  volume       = {818},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020c). Editorial. <em>TCS</em>, <em>817</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(20)30176-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(20)30176-6},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “inductive-data-type systems” [theoret.
Comput. Sci. 272 (1–2) (2002) 41–68]. <em>TCS</em>, <em>817</em>, 81–82.
(<a href="https://doi.org/10.1016/j.tcs.2018.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a previous work (Abstract data type systems, Theoret. Comput. Sci. 173 (2) (1997)), the last two authors presented a combined language made of a (strongly normalizing) algebraic rewrite system and a typed lambda-calculus enriched by pattern-matching definitions following a certain format, called the “General Schema”, which generalizes the usual recursor definitions for natural numbers and similar “basic inductive types”. This combined language was shown to be strongly normalizing. The purpose of this paper is to reformulate and extend the General Schema in order to make it easily extensible, to capture a more general class of inductive types, called “strictly positive”, and to ease the strong normalization proof of the resulting system. This result provides a computation model for the combination of an algebraic specification language based on abstract data types and of a strongly typed functional language with strictly positive inductive types.},
  archive      = {J_TCS},
  author       = {Frédéric Blanqui and Jean-Pierre Jouannaud and Mitsuhiro Okada},
  doi          = {10.1016/j.tcs.2018.01.010},
  journal      = {Theoretical Computer Science},
  pages        = {81-82},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Corrigendum to “Inductive-data-type systems” [Theoret. comput. sci. 272 (1–2) (2002) 41–68]},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Erratum/correction to “on the complexity of an expanded
tarski’s fixed point problem under the componentwise ordering” [theor.
Comput. Sci. 732 (2018) 26–45]. <em>TCS</em>, <em>817</em>, 80. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Chuangyin Dang and Yinyu Ye},
  doi          = {10.1016/j.tcs.2019.03.014},
  journal      = {Theoretical Computer Science},
  pages        = {80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Erratum/Correction to “On the complexity of an expanded tarski&#39;s fixed point problem under the componentwise ordering” [Theor. comput. sci. 732 (2018) 26–45]},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fault-tolerant metric dimension of circulant graphs
cn(1,2,3). <em>TCS</em>, <em>817</em>, 66–79. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a connected graph G = ( V , E ) G=(V,E) , an ordered set R = { r 1 , r 2 , … , r k } ⊂ V ( G ) R={r1,r2,…,rk}⊂V(G) is said to be a resolving set if c ( u | R ) ≠ c ( v | R ) c(u|R)≠c(v|R) for every distinct pair of vertices u , v u,v of G , where c ( w | R ) = ( d ( w , r 1 ) , d ( w , r 2 ) , … , d ( w , r k ) ) c(w|R)=(d(w,r1),d(w,r2),…,d(w,rk)) for w ∈ V ( G ) w∈V(G) and d ( x , y ) d(x,y) denotes the distance between two vertices x and y . A resolving set F for the graph G is fault-tolerant if for each v ∈ F v∈F , F ∖ { v } F∖{v} is also a resolving set for G and the fault-tolerant metric dimension of G is the minimum cardinality of a fault-tolerant resolving set. In this article, we determine the exact value of the fault tolerant metric dimension for the circulant graphs C n ( 1 , 2 , 3 ) Cn(1,2,3) for all finite values of n .},
  archive      = {J_TCS},
  author       = {Mithun Basak and Laxman Saha and Gour Kanta Das and Kalishankar Tiwary},
  doi          = {10.1016/j.tcs.2019.01.011},
  journal      = {Theoretical Computer Science},
  pages        = {66-79},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fault-tolerant metric dimension of circulant graphs cn(1,2,3)},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). KNN-p: A kNN classifier optimized by p systems.
<em>TCS</em>, <em>817</em>, 55–65. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a k -nearest neighbors (kNN) classifier optimized by P systems , called kNN-P, which can improve the performance of the original kNN classifier. A P system consisting of multiple cells is considered as its computational framework. Under the control of both evolution rules and communication rules, each cell determines the optimal set of k -nearest neighbors for a test sample. The proposed algorithm is evaluated on eighteen benchmark datasets and compared with classical kNN algorithm and eight recently developed improved algorithms. Experimental results demonstrate the availability and effectiveness of the proposed algorithm.},
  archive      = {J_TCS},
  author       = {Juan Hu and Hong Peng and Jun Wang and Wenping Yu},
  doi          = {10.1016/j.tcs.2020.01.001},
  journal      = {Theoretical Computer Science},
  pages        = {55-65},
  shortjournal = {Theor. Comput. Sci.},
  title        = {KNN-P: A kNN classifier optimized by p systems},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). From mathematical equivalence such as ma equivalence to
generalized zhang equivalency including gradient equivalency.
<em>TCS</em>, <em>817</em>, 44–54. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The authors carried out time-varying problems solving (TVPS) including robot problems solving in 2001, and began to figure out the reasons for the problems solving via diverse layers. After eight years&#39; thinking, i.e., in 2009, the authors began to manifest, put forward and carry out the thought of “physical equivalency”. By another eight years&#39; practicing and experimenting, i.e., in 2017, the authors basically finished establishing the framework of Zhang equivalency. Now, it is the time to establish the complete theory in a brief manner. Therefore, concepts about mathematical equivalence simply termed equivalence are presented firstly including Ma equivalence (especially for robotics), and then concepts about physical equivalency simply termed equivalency are proposed. Meanwhile, concepts about Zhang equivalency as a kind of equivalency are further proposed, and concepts about gradient-dynamics equivalency simply termed gradient equivalency as a kind of equivalency are proposed as well. Furthermore, two specific applications are considered and investigated, which substantiate the efficacy of Zhang equivalency.},
  archive      = {J_TCS},
  author       = {Yunong Zhang and Min Yang and Binbin Qiu and Jian Li and Mingjie Zhu},
  doi          = {10.1016/j.tcs.2019.07.027},
  journal      = {Theoretical Computer Science},
  pages        = {44-54},
  shortjournal = {Theor. Comput. Sci.},
  title        = {From mathematical equivalence such as ma equivalence to generalized zhang equivalency including gradient equivalency},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discrete-time formulation, control, solution and
verification of pendulum systems with zeroing neural dynamics.
<em>TCS</em>, <em>817</em>, 33–43. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a typical kind of nonlinear system , pendulum systems have drawn attention of numerous researchers for a very long time. This paper focuses mainly on dealing with the discrete-time tracking control problem of both the simple pendulum system and inverted-pendulum-on-a-cart (IPOAC) system. Based on zeroing neural dynamics (ZND), controllers of z2 type are designed respectively for the effective tracking control of the above two pendulum systems. Then, with the aim of possible digital hardware implementation, a 4-node discretization (4ND) formula, which is of square precision in terms of truncation error , is employed to discretize the continuous-time pendulum systems with high precision (i.e., with discretization error being proportional to the cube of the sampling gap). By comparing with Euler-type discretization, simulative results further substantiate the feasibility, accuracy and superiority of the discrete-time control of both the simple pendulum system and IPOAC system with the 4ND formula.},
  archive      = {J_TCS},
  author       = {Yunong Zhang and Huanchang Huang and Min Yang and Jian Li},
  doi          = {10.1016/j.tcs.2019.06.027},
  journal      = {Theoretical Computer Science},
  pages        = {33-43},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Discrete-time formulation, control, solution and verification of pendulum systems with zeroing neural dynamics},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic maintenance case base using knowledge discovery
techniques for case based reasoning systems. <em>TCS</em>, <em>817</em>,
24–32. (<a href="https://doi.org/10.1016/j.tcs.2019.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The achievement of a Case Based Reasoning (CBR) system is strongly related to the quality of case data and the rapidity of the retrieval process that depends on the quantity of the cases. This quality can diminish especially when the number of cases gets outsized. To guarantee this quality, maintenance the case base becomes essentially. Much existing maintenance CBR approaches focus on the performance of the CBR or the study of the case base (CB) competence. Even though the two points are directly related, there is a few research on using strategies at both points at the same time. Furthermore, the proposed methods are not dynamic, they are not suitable for the frequently change in learning process. In this paper, we propose maintenance CBR method based on well-organized machine learning techniques , in the process of improving the competence and the performance of the CB and can handle incremental cases which evolve over time. We support our approach with empirical evaluation using different benchmark data sets to show the effectiveness of our method.},
  archive      = {J_TCS},
  author       = {Abir Smiti and Zied Elouedi},
  doi          = {10.1016/j.tcs.2019.06.026},
  journal      = {Theoretical Computer Science},
  pages        = {24-32},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dynamic maintenance case base using knowledge discovery techniques for case based reasoning systems},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved adaptive genetic algorithm for the vehicle
insurance fraud identification model based on a BP neural network.
<em>TCS</em>, <em>817</em>, 12–23. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the insurance industry, insurance fraud is increasing rapidly. The existence of insurance fraud considerably hinders the development of the insurance industry. Fraud identification has become the most important part of insurance fraud research. In this paper, an improved adaptive genetic algorithm (NAGA) combined with a BP neural network (BP neural network) is proposed to optimize the initial weight of BP neural networks to overcome their shortcomings, such as ease of falling into local minima, slow convergence rates and sample dependence. Finally, the historical automobile insurance claim data of an insurance company are taken as a sample. The NAGA-BP neural network model was used for simulation and prediction. The empirical results show that the improved genetic algorithm is more advanced than the traditional genetic algorithm in terms of convergence speed and prediction accuracy.},
  archive      = {J_TCS},
  author       = {Chun Yan and Meixuan Li and Wei Liu and Man Qi},
  doi          = {10.1016/j.tcs.2019.06.025},
  journal      = {Theoretical Computer Science},
  pages        = {12-23},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved adaptive genetic algorithm for the vehicle insurance fraud identification model based on a BP neural network},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). List r-dynamic coloring of sparse graphs. <em>TCS</em>,
<em>817</em>, 1–11. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The r -dynamic coloring is a generalization of the L ( 1 , 1 ) L(1,1) -labeling. An r -dynamic k -coloring of a graph G is a proper k -coloring such that every vertex v in V ( G ) V(G) has neighbors in at least min ⁡ { d ( v ) , r } min⁡{d(v),r} different classes. The r -dynamic chromatic number of G , written χ r ( G ) χr(G) , is the minimum k such that G has such a coloring. The list r -dynamic chromatic number of G is denoted c h r ( G ) chr(G) . In this paper, we show that c h r ( G ) ≤ r + 5 chr(G)≤r+5 for planar graphs G with g ( G ) ≥ 5 g(G)≥5 and r ≥ 15 r≥15 , c h r ( G ) ≤ r + 10 chr(G)≤r+10 for graphs G with m a d ( G ) mad(G)&amp;lt;103 and c h r ( G ) ≤ r + 1 chr(G)≤r+1 for graphs G with m a d ( G ) mad(G)&amp;lt;83 and r ≥ 14 r≥14 .},
  archive      = {J_TCS},
  author       = {Junlei Zhu and Yuehua Bu},
  doi          = {10.1016/j.tcs.2019.05.032},
  journal      = {Theoretical Computer Science},
  pages        = {1-11},
  shortjournal = {Theor. Comput. Sci.},
  title        = {List r-dynamic coloring of sparse graphs},
  volume       = {817},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020d). Editorial. <em>TCS</em>, <em>816</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(20)30153-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(20)30153-5},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence of the non-uniform physarum dynamics.
<em>TCS</em>, <em>816</em>, 260–269. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Physarum computing model is an analog computing model motivated by the network dynamics of the slime mold Physarum Polycephalum. In previous works, it was shown that it can solve a class of linear programs . We extend these results to a more general dynamics motivated by situations where the slime mold operates in a non-uniform environment. Let c ∈ Z &gt; 0 m c∈Z&amp;gt;0m , A ∈ Z n × m A∈Zn×m , and b ∈ Z n b∈Zn . We show under fairly general conditions that the non-uniform Physarum dynamics x ˙ e = a e ( x , t ) ( | q e | − x e ) x˙e=ae(x,t)(|qe|−xe) converges to the optimum solution ⁎ x ⁎ x⁎ of the weighted basis pursuit problem minimize c T x cTx subject to A f = b Af=b and | f | ≤ x |f|≤x . Here, f and x are m -dimensional vectors of real variables, q minimizes the energy ∑ e ( c e / x e ) q e 2 ∑e(ce/xe)qe2 subject to the constraints A q = b Aq=b and supp ( q ) ⊆ supp ( x ) supp(q)⊆supp(x) , and a e ( x , t ) &gt; 0 ae(x,t)&amp;gt;0 is the reactivity of edge e to the difference | q e | − x e |qe|−xe at time t and in state x . Previously convergence was only shown for the uniform case a e ( x , t ) = 1 ae(x,t)=1 for all e , x , and t . We also show convergence for the dynamics x ˙ e = x e ( g e ( | q e | x e ) − 1 ) , x˙e=xe(ge(|qe|xe)−1), where each g e ge is an increasing differentiable function with g e ( 1 ) = 1 ge(1)=1 (satisfying some mild conditions). Previously, convergence was only shown for the special case of the shortest path problem on a graph consisting of two nodes connected by parallel edges.},
  archive      = {J_TCS},
  author       = {Andreas Karrenbauer and Pavel Kolev and Kurt Mehlhorn},
  doi          = {10.1016/j.tcs.2020.02.032},
  journal      = {Theoretical Computer Science},
  pages        = {260-269},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Convergence of the non-uniform physarum dynamics},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliability analysis of subsystem in dual cubes.
<em>TCS</em>, <em>816</em>, 249–259. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The probability of failing processors in the multiprocessor system increases as the cardinality of system grows. The subsystem reliability in a system, defined as the probability that a subsystem of a specified cardinality is operational with the emergence of failed nodes. In this paper, we derive an approximation and an upper bound on the probability of a subgraph D n − 1 Dn−1 being fault-free under the probabilistic fault model. Numerical simulations indicate that these two analytical results we get are in good consistency, especially when the node reliability is at a low level.},
  archive      = {J_TCS},
  author       = {Qifan Zhang and Liqiong Xu and Shuming Zhou and Weihua Yang},
  doi          = {10.1016/j.tcs.2020.02.028},
  journal      = {Theoretical Computer Science},
  pages        = {249-259},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reliability analysis of subsystem in dual cubes},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fluid approximation of broadcasting systems. <em>TCS</em>,
<em>816</em>, 221–248. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nature-inspired paradigms have been proposed to design and forecast behaviour of open distributed systems, such as sensor networks and the internet of things . In these paradigms system behaviour emerges from (complex) interactions among a large number of agents. Modelling these interactions in terms of classical point-to-point communication is often not practical. This is due to the large scale and the open nature of the systems, which means that partners for point-to-point communication may not be available at any given time. Nevertheless the need for efficient formal verification of qualitative and quantitative properties of these systems is of utmost importance , especially given their proposed pervasive and transparent nature. Carma is a recently proposed formal modelling language for open distributed systems, which is equipped with a broadcast communication in order to meet the communication challenges of such systems. The inclusion of quantitative information about the timing and probability of actions gives rise to models suitable for analysing questions such as the probability that information will achieve total coverage within a system, or the expected market share that might be gained by competing service providers relying on viral advertising. The ability to express models is not the only challenge, because the scale of the systems we are interested in often defies discrete state-based analysis techniques such as stochastic simulation . This is the problem that we address in this paper as we consider how to provide an efficient fluid approximation , supporting efficient and accurate quantitative analysis of large scale systems , for a language that incorporates broadcast communication.},
  archive      = {J_TCS},
  author       = {Luca Bortolussi and Jane Hillston and Michele Loreti},
  doi          = {10.1016/j.tcs.2020.02.020},
  journal      = {Theoretical Computer Science},
  pages        = {221-248},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fluid approximation of broadcasting systems},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bounded privacy-utility monotonicity indicating bounded
tradeoff of differential privacy mechanisms. <em>TCS</em>, <em>816</em>,
195–220. (<a href="https://doi.org/10.1016/j.tcs.2020.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy can achieve the tradeoff between privacy and utility by using privacy metric and utility metric. However, since privacy metric and utility metric may not be bounded, differential privacy can not provide the bounded tradeoff. Moreover, there is no unified method to indicate the bounded tradeoff of differential privacy in the current work. To this end, we proposed the bounded privacy-utility monotonicity indicating the bounded tradeoff of differential privacy. First, we gave the definition of the bounded tradeoff of differential privacy, and we presented the bounded privacy-utility monotonicity of differential privacy based on computational indistinguishability . Second, we theoretically proved the bounded privacy-utility monotonicity of several differential privacy mechanisms based on the bounded metrics of modulus of characteristic function and normalized entropy, including the Laplace mechanism, discrete Laplace mechanism, Gaussian mechanism, exponential mechanism, optimal mechanism, and quaternary mechanism. We also showed that these mechanisms had the bounded privacy-utility monotonicity in the multivariate case . Third, our numerical results further demonstrated that these several differential privacy mechanisms obtained the bounded privacy-utility monotonicity. Finally, we gave an instance of achieving the bounded tradeoff of differential privacy mechanisms based on the bounded privacy-utility monotonicity under semi-honest model, and we discussed the goal of optimization of the bounded tradeoff of differential privacy based on the bounded privacy-utility monotonicity under semi-honest model. Therefore, the bounded privacy-utility monotonicity can be used to indicate the bounded tradeoff of differential privacy under semi-honest model. Furthermore, the bounded privacy-utility monotonicity plays an important role of optimizing the bounded tradeoff of differential privacy under semi-honest model.},
  archive      = {J_TCS},
  author       = {Hai Liu and Zhenqiang Wu and Changgen Peng and Feng Tian and Laifeng Lu},
  doi          = {10.1016/j.tcs.2020.02.004},
  journal      = {Theoretical Computer Science},
  pages        = {195-220},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bounded privacy-utility monotonicity indicating bounded tradeoff of differential privacy mechanisms},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Convergence of the non-uniform directed physarum model.
<em>TCS</em>, <em>816</em>, 184–194. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The directed Physarum dynamics is known to solve positive linear programs : minimize c T x subject to A x = b and x ≥ 0 for a positive cost vector c . The directed Physarum dynamics evolves a positive vector x according to the dynamics x ˙ = q ( x ) − x . Here q ( x ) is the solution to A f = b that minimizes the “energy” ∑ i c i f i 2 / x i . In this paper, we study the non-uniform directed dynamics x ˙ = D ( q ( x ) − x ) , where D is a positive diagonal matrix . The non-uniform dynamics is more complex than the uniform dynamics (with D being the identity matrix), as it allows each component of x to react with different speed to the differences between q ( x ) and x . Our contribution is to show that the non-uniform directed dynamics solves positive linear programs.},
  archive      = {J_TCS},
  author       = {Enrico Facca and Andreas Karrenbauer and Pavel Kolev and Kurt Mehlhorn},
  doi          = {10.1016/j.tcs.2020.01.034},
  journal      = {Theoretical Computer Science},
  pages        = {184-194},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Convergence of the non-uniform directed physarum model},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Theory versus practice in annealing-based quantum computing.
<em>TCS</em>, <em>816</em>, 169–183. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces basic concepts of annealing-based quantum computing , also known as adiabatic quantum computing (AQC) and quantum annealing (QA), and surveys what is known about this novel computing paradigm . Extensive empirical research on physical quantum annealing processers built by D-Wave Systems has exposed many interesting features and properties. However, because of longstanding differences between abstract and empirical approaches to the study of computational performance, much of this work may not be considered relevant to questions of interest to complexity theory; by the same token, several theoretical results in quantum computing may be considered irrelevant to practical experience. To address this communication gap, this paper proposes models of computation and of algorithms that lie on a scale of instantiation between pencil-and-paper abstraction and physical device. Models at intermediate points on these scales can provide a common language, allowing researchers from both ends to communicate and share their results. The paper also gives several examples of common terms that have different technical meanings in different regions of this highly multidisciplinary field, which can create barriers to effective communication across disciplines.},
  archive      = {J_TCS},
  author       = {Catherine C. McGeoch},
  doi          = {10.1016/j.tcs.2020.01.024},
  journal      = {Theoretical Computer Science},
  pages        = {169-183},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Theory versus practice in annealing-based quantum computing},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The impact of lexicographic parsimony pressure for
ORDER/MAJORITY on the run time. <em>TCS</em>, <em>816</em>, 144–168. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While many optimization problems work with a fixed number of decision variables and thus a fixed-length representation of possible solutions, genetic programming (GP) works on variable-length representations. A naturally occurring problem is that of bloat, that is, the unnecessary growth of solution lengths, which may slow down the optimization process. So far, the mathematical runtime analysis could not deal well with bloat and required explicit assumptions limiting bloat. In this paper, we provide the first mathematical runtime analysis of a GP algorithm that does not require any assumptions on the bloat. Previous performance guarantees were only proven conditionally for runs in which no strong bloat occurs. Together with improved analyses for the case with bloat restrictions our results show that such assumptions on the bloat are not necessary and that the algorithm is efficient without explicit bloat control mechanism. More specifically, we analyzed the performance of the ( 1 + 1 ) (1+1) GP on the two benchmark functions Order and Majority . When using lexicographic parsimony pressure as bloat control, we show a tight runtime estimate of O ( T init + n log ⁡ n ) O(Tinit+nlog⁡n) iterations both for Order and Majority . For the case without bloat control, the bounds O ( T init log ⁡ T init + n ( log ⁡ n ) 3 ) O(Tinitlog⁡Tinit+n(log⁡n)3) and Ω ( T init + n log ⁡ n ) Ω(Tinit+nlog⁡n) (and Ω ( T init log ⁡ T init ) Ω(Tinitlog⁡Tinit) for n = 1 n=1 ) hold for Majority . 1},
  archive      = {J_TCS},
  author       = {Benjamin Doerr and Timo Kötzing and J.A. Gregor Lagodzinski and Johannes Lengler},
  doi          = {10.1016/j.tcs.2020.01.011},
  journal      = {Theoretical Computer Science},
  pages        = {144-168},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The impact of lexicographic parsimony pressure for ORDER/MAJORITY on the run time},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust biomolecular finite automata. <em>TCS</em>,
<em>816</em>, 114–143. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a uniform method for translating an arbitrary nondeterministic finite automaton (NFA) into a deterministic mass action input/output chemical reaction network ( I/O CRN ) that simulates it. The I/O CRN receives its input as a continuous time signal consisting of concentrations of chemical species that vary to represent the NFA&#39;s input string in a natural way. The I/O CRN exploits the inherent parallelism of chemical kinetics to simulate the NFA in real time with a number of chemical species that is linear in the size of the NFA. We prove that the simulation is correct and that it is robust with respect to perturbations of the input signal, the initial concentrations of species, the output (decision), and the rate constants of the reactions of the I/O CRN.},
  archive      = {J_TCS},
  author       = {Titus H. Klinge and James I. Lathrop and Jack H. Lutz},
  doi          = {10.1016/j.tcs.2020.01.008},
  journal      = {Theoretical Computer Science},
  pages        = {114-143},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Robust biomolecular finite automata},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Destructiveness of lexicographic parsimony pressure and
alleviation by a concatenation crossover in genetic programming.
<em>TCS</em>, <em>816</em>, 96–113. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For theoretical analyses there are two specifics distinguishing GP from many other areas of evolutionary computation: the variable size representations, in particular yielding a possible bloat (i.e. the growth of individuals with redundant parts); and also the role and the realization of crossover, which is particularly central in GP due to the tree-based representation. Whereas some theoretical work on GP has studied the effects of bloat, crossover had surprisingly little share in this work. We analyze a simple crossover operator in combination with randomized local search, where a preference for small solutions minimizes bloat (lexicographic parsimony pressure); we denote the resulting algorithm Concatenation Crossover GP. We consider three variants of the well-studied Majority test function, adding large plateaus in different ways to the fitness landscape and thus giving a test bed for analyzing the interplay of variation operators and bloat control mechanisms in a setting with local optima. We show that the Concatenation Crossover GP can efficiently optimize these test functions, while local search cannot be efficient for all three variants independent of employing bloat control.},
  archive      = {J_TCS},
  author       = {Timo Kötzing and J.A. Gregor Lagodzinski and Johannes Lengler and Anna Melnichenko},
  doi          = {10.1016/j.tcs.2019.11.036},
  journal      = {Theoretical Computer Science},
  pages        = {96-113},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Destructiveness of lexicographic parsimony pressure and alleviation by a concatenation crossover in genetic programming},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Multicarrier continuous-variable quantum key distribution.
<em>TCS</em>, <em>816</em>, 67–95. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multicarrier continuous-variable quantum key distribution (CVQKD) protocol is defined. In a CVQKD protocol, the information is conveyed by coherent quantum states . The quantum continuous variables are sent through a noisy quantum channel . For a quantum channel with additive-multiplicative noise both additive and multiplicative disturbances are present in the transmission. The multiplicative disturbance is an inherent attribute of diverse physical environments. Physical links with additive and multiplicative disturbances can represent a more general approach than purely additive noise links in several practical scenarios. In a standard CVQKD setting, the noise is modeled as an additive white Gaussian noise caused by an eavesdropper (Gaussian quantum link). As a corollary, standard CVQKD protocols are not optimal for arbitrary Gaussian quantum channels if multiplicative disturbances are also present in the physical link. Here, we define the adaptive multicarrier quadrature division (AMQD) modulation technique for CVQKD. The AMQD method is optimal for arbitrary Gaussian quantum channels with arbitrary multiplicative disturbances. The protocol granulates the Gaussian random input into Gaussian subcarrier continuous variables in the encoding phase, which are then decoded by a continuous unitary transformation . The subcarrier coherent variables formulate sub-channels from the physical link which leads to improved transmission efficiency, higher tolerable loss, and excess noise in comparison to standard CVQKD protocols. We also derive the security proof of multicarrier CVQKD at optimal Gaussian attacks in the finite-size and asymptotic regimes.},
  archive      = {J_TCS},
  author       = {Laszlo Gyongyosi},
  doi          = {10.1016/j.tcs.2019.11.026},
  journal      = {Theoretical Computer Science},
  pages        = {67-95},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Multicarrier continuous-variable quantum key distribution},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pre-expansivity in cellular automata. <em>TCS</em>,
<em>816</em>, 37–66. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the notion of pre-expansivity for cellular automata (CA): it is the property of being positively expansive on asymptotic pairs of configurations (i.e. configurations that differ in only finitely many positions). Pre-expansivity therefore lies between positive expansivity and pre-injectivity, two important notions of CA theory. We show that there exist one-dimensional pre-expansive CAs which are not positively expansive and they can be chosen reversible (while positive expansivity is impossible for reversible CAs). We provide both linear and non-linear examples. In the one-dimensional setting, we also show that pre-expansivity implies sensitivity to initial conditions in any direction. We show however that no two-dimensional Abelian CA can be pre-expansive. We also consider the finer notion of k -expansivity (positive expansivity over pairs of configurations with exactly k differences) and show examples of linear CA in dimension 2 and on the free group that are k -expansive depending on the value of k , whereas no (positively) expansive CA exists in this setting.},
  archive      = {J_TCS},
  author       = {A. Gajardo and V. Nesme and G. Theyssier},
  doi          = {10.1016/j.tcs.2019.10.034},
  journal      = {Theoretical Computer Science},
  pages        = {37-66},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Pre-expansivity in cellular automata},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Derivation languages and descriptional complexity measures
of restricted flat splicing systems. <em>TCS</em>, <em>816</em>, 19–36.
(<a href="https://doi.org/10.1016/j.tcs.2019.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we associate the idea of derivation languages with a restricted variant of flat splicing systems where at each step splicing is done with an element from the initial set of words present in the system. We call these flat splicing systems as restricted flat splicing systems. We show that the families of Szilard languages of labeled restricted flat finite splicing systems of type ( m , n ) (m,n) and REG , CF and CS are incomparable. Also, any non-empty regular, non-empty context-free and recursively enumerable language can be obtained as homomorphic image of the Szilard language of the labeled restricted flat finite splicing systems of type ( 1 , 2 ) , ( 2 , 2 ) (1,2),(2,2) and ( 5 , 2 ) (5,2) respectively. We also introduce the idea of control languages for restricted labeled flat finite splicing systems and show that any non-empty regular and context-free language can be obtained as a control language of labeled restricted flat finite splicing systems of type ( 1 , 2 ) (1,2) and ( 2 , 2 ) (2,2) respectively. At the end, we show that any recursively enumerable language can be obtained as a control language of labeled restricted flat finite splicing systems of type ( 5 , 2 ) (5,2) when λ -labeled rules are allowed.},
  archive      = {J_TCS},
  author       = {Prithwineel Paul and Kumar Sankar Ray},
  doi          = {10.1016/j.tcs.2019.10.003},
  journal      = {Theoretical Computer Science},
  pages        = {19-36},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Derivation languages and descriptional complexity measures of restricted flat splicing systems},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cell-like p systems with polarizations and minimal rules.
<em>TCS</em>, <em>816</em>, 1–18. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {P systems with active membranes are a class of computation models in the area of membrane computing, which are inspired from the mechanism by which chemicals interact and cross cell membranes. In this work, we consider a normal form of P systems with active membranes, called cell-like P systems with polarizations and minimal rules, where rules are minimal in the sense that an object evolves to exactly one object with the application of an evolution rule or a communication rule, or an object evolves to two objects that are assigned to the two new generated membranes by applying a division rule. The present work investigates the computational power of P systems with polarizations and minimal rules. Specifically, results about Turing universality and non-universality are obtained with the combination of the number of membranes, the number of polarizations, and the types of rules. We also show that polarizationless P systems with minimal rules are equivalent to Turing machines working in a polynomial space , that is, the class of problems that can be solved in polynomial time by polarizationless P systems with minimal rules is equal to the class PSPACE .},
  archive      = {J_TCS},
  author       = {Linqiang Pan and David Orellana-Martín and Bosheng Song and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.tcs.2019.10.001},
  journal      = {Theoretical Computer Science},
  pages        = {1-18},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cell-like p systems with polarizations and minimal rules},
  volume       = {816},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The italian conference on theoretical computer science.
<em>TCS</em>, <em>815</em>, 310. (<a
href="https://doi.org/10.1016/j.tcs.2020.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Alessandro Aldini and Marco Bernardo},
  doi          = {10.1016/j.tcs.2020.03.003},
  journal      = {Theoretical Computer Science},
  pages        = {310},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The italian conference on theoretical computer science},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gathering anonymous, oblivious robots on a grid.
<em>TCS</em>, <em>815</em>, 289–309. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a swarm of n autonomous mobile robots distributed on a 2-dimensional grid. A basic task for such a swarm is to perform the gathering process: All robots have to gather at one not predefined place. On the grid there are configurations which, due to symmetry, cannot be gathered at a single point. Such configurations are 2 × 2 2×2 squares. Therefore, we say that the swarm is gathered if all robots are located inside of a 2 × 2 2×2 square. We assume the fully synchronous FSYNC FSYNC time model and the following very simple so-called Basic&amp;Plain robot model: The robots are oblivious, only have a constant viewing radius, are autonomous and indistinguishable, do not have a common compass, and cannot communicate. This implies that a robot&#39;s decision about its next action can only be based on the current relative positions of the robots in its viewing range. We consider connected swarms. We say two robots are connected if they are located in horizontally or vertically neighboring grid cells. We present the first gathering algorithm on the grid for this simple robot model and show that it gathers in time O ( n 2 ) O(n2) . Known algorithms for gathering on the grid need much stronger robot models: Either they have a common compass, or they have a finite memory and can communicate (via lights or flags) with robots in their viewing range. Finally, we extend our algorithm to the case where one of the robots is stationary, i.e. does not move.},
  archive      = {J_TCS},
  author       = {Jannik Castenow and Matthias Fischer and Jonas Harbig and Daniel Jung and Friedhelm Meyer auf der Heide},
  doi          = {10.1016/j.tcs.2020.02.018},
  journal      = {Theoretical Computer Science},
  pages        = {289-309},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Gathering anonymous, oblivious robots on a grid},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing coverage kernels under restricted settings.
<em>TCS</em>, <em>815</em>, 270–288. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set B B of d -dimensional boxes (i.e., axis-aligned hyperrectangles), a minimum coverage kernel is a subset of B B of minimum size covering the same region as B B . Computing it is NP NP -hard, but as for many similar NP NP -hard problems (e.g., Box Cover , and Orthogonal Polygon Covering ), the problem becomes solvable in polynomial time under restrictions on B B . We show that computing minimum coverage kernels remains NP NP -hard even when restricting the graph induced by the input to a highly constrained class of graphs. Alternatively, we present two polynomial-time approximation algorithms for this problem: one deterministic with an approximation ratio within O ( log ⁡ n ) O(log⁡n) , and one randomized with an improved approximation ratio within O ( lg ⁡ OPT ) O(lg⁡OPT) (with high probability).},
  archive      = {J_TCS},
  author       = {Jérémy Barbay and Pablo Pérez-Lantero and Javiel Rojas-Ledesma},
  doi          = {10.1016/j.tcs.2020.01.021},
  journal      = {Theoretical Computer Science},
  pages        = {270-288},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing coverage kernels under restricted settings},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On timeline-based games and their complexity. <em>TCS</em>,
<em>815</em>, 247–269. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In timeline-based planning, domains are described as sets of independent, but interacting, components, whose behaviour over time (the set of timelines) is governed by a set of temporal constraints . A distinguishing feature of timeline-based planning systems is the ability to integrate planning with execution by synthesising control strategies for flexible plans . However, flexible plans can only represent temporal uncertainty , while more complex forms of nondeterminism are needed to deal with a wider range of real-world domains. In this paper, we propose a novel game-theoretic approach to timeline-based planning problems, generalising the state of the art while uniformly handling temporal uncertainty and nondeterminism . We define a general concept of timeline-based game and we show that the notion of winning strategy for these games is strictly more general than that of control strategy for dynamically controllable flexible plans. Moreover, we show that the problem of establishing the existence of such winning strategies is 2EXPTIME -complete.},
  archive      = {J_TCS},
  author       = {Nicola Gigante and Angelo Montanari and Andrea Orlandini and Marta Cialdea Mayer and Mark Reynolds},
  doi          = {10.1016/j.tcs.2020.02.011},
  journal      = {Theoretical Computer Science},
  pages        = {247-269},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On timeline-based games and their complexity},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>815</em>, 246. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Aniello Murano ( The Guest Editor ) and Sasha Rubin (The Guest Editor)},
  doi          = {10.1016/j.tcs.2019.12.022},
  journal      = {Theoretical Computer Science},
  pages        = {246},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Visualizing co-phylogenetic reconciliations. <em>TCS</em>,
<em>815</em>, 228–245. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a hybrid metaphor for the visualization of the reconciliations of co-phylogenetic trees, that are mappings among the nodes of two trees with constraints on the leaves. The typical application is the visualization of the co-evolution of hosts and parasites in biology. Our strategy combines a space-filling and a node-link approach. Differently from traditional methods, it guarantees an unambiguous and downward representation whenever the reconciliation is time-consistent (i.e., biologically-feasible). We address the problem of the minimization of the number of crossings in the representation, by giving a characterization of planar instances and by establishing the complexity of the problem. Finally, we propose heuristics for computing representations with few crossings.},
  archive      = {J_TCS},
  author       = {Tiziana Calamoneri and Valentino Di Donato and Diego Mariottini and Maurizio Patrignani},
  doi          = {10.1016/j.tcs.2019.12.024},
  journal      = {Theoretical Computer Science},
  pages        = {228-245},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Visualizing co-phylogenetic reconciliations},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Arbitrary pattern formation on infinite grid by asynchronous
oblivious robots. <em>TCS</em>, <em>815</em>, 213–227. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Arbitrary Pattern Formation problem asks to design a distributed algorithm that allows a set of autonomous mobile robots to form any specific but arbitrary geometric pattern given as input. The problem has been extensively studied in the literature in continuous domains. This paper investigates a discrete version of the problem where the robots are operating on a two dimensional infinite grid. The robots are assumed to be autonomous, identical, anonymous and oblivious. They operate in Look-Compute-Move cycles under a fully asynchronous scheduler. The robots do not have access to any common global coordinate system. However, the grid allows the robots to have a partial agreement on coordinate system as they can align the axes of their local coordinate systems along the grid lines. In this setting, we have shown that a set of robots can form any pattern, if their starting configuration is asymmetric.},
  archive      = {J_TCS},
  author       = {Kaustav Bose and Ranendu Adhikary and Manash Kumar Kundu and Buddhadeb Sau},
  doi          = {10.1016/j.tcs.2020.02.016},
  journal      = {Theoretical Computer Science},
  pages        = {213-227},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Arbitrary pattern formation on infinite grid by asynchronous oblivious robots},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hard and easy instances of l-tromino tilings. <em>TCS</em>,
<em>815</em>, 197–212. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study tilings of regions in the square lattice with L-shaped trominoes. Deciding the existence of a tiling with L-trominoes for an arbitrary region in general is NP-complete, nonetheless, we identify restrictions to the problem where it either remains NP-complete or has a polynomial time algorithm. First, we characterize the possibility of when an Aztec rectangle and an Aztec diamond has an L-tromino tiling. Then, we study tilings of arbitrary regions where only 180 ∘ 180∘ rotations of L-trominoes are available. For this particular case we show that deciding the existence of a tiling remains NP-complete; yet, if a region does not contain certain so-called “forbidden polyominoes” as sub-regions, then there exists a polynomial time algorithm for deciding a tiling.},
  archive      = {J_TCS},
  author       = {Javier T. Akagi and Carlos F. Gaona and Fabricio Mendoza and Manjil P. Saikia and Marcos Villagra},
  doi          = {10.1016/j.tcs.2020.02.025},
  journal      = {Theoretical Computer Science},
  pages        = {197-212},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hard and easy instances of L-tromino tilings},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A complexity dichotomy for critical values of the
b-chromatic number of graphs. <em>TCS</em>, <em>815</em>, 182–196. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A b-coloring of a graph G is a proper coloring of its vertices such that each color class contains a vertex that has at least one neighbor in all the other color classes. The b - Coloring problem asks whether a graph G has a b -coloring with k colors. The b-chromatic number of a graph G , denoted by χb(G) , is the maximum number k such that G admits a b -coloring with k colors. We consider the complexity of the b - Coloring problem, whenever the value of k is close to one of two upper bounds on χb(G) : The maximum degree Δ(G) plus one, and the m -degree, denoted by m(G) , which is defined as the maximum number i such that G has i vertices of degree at least i−1 . We obtain a dichotomy result for all fixed k∈N when k is close to one of the two above mentioned upper bounds. Concretely, we show that if k∈{Δ(G)+1−p,m(G)−p} , the problem is polynomial-time solvable whenever p∈{0,1} and, even when k=3 , it is NP -complete whenever p≥2 . We furthermore consider parameterizations of the b - Coloring problem that involve the maximum degree Δ(G) of the input graph G and give two FPT -algorithms. First, we show that deciding whether a graph G has a b -coloring with m(G) colors is FPT parameterized by Δ(G) . Second, we show that b - Coloring is FPT parameterized by Δ(G)+ℓk(G) , where ℓk(G) denotes the number of vertices of degree at least k .},
  archive      = {J_TCS},
  author       = {Lars Jaffke and Paloma T. Lima},
  doi          = {10.1016/j.tcs.2020.02.007},
  journal      = {Theoretical Computer Science},
  pages        = {182-196},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A complexity dichotomy for critical values of the b-chromatic number of graphs},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Covering orthogonal polygons with sliding k-transmitters.
<em>TCS</em>, <em>815</em>, 163–181. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a new variant of covering in an orthogonal art gallery problem where each guard is a sliding k -transmitter. Such a guard can travel back and forth along an orthogonal line segment, say s , inside the polygon. A point p is covered by this guard if there exists a point q ∈ s q∈s such that p q ‾ pq‾ is a line segment normal to s , and has at most k intersections with the boundary walls of the polygon. The objective is to minimize the sum of the lengths of the sliding k -transmitters to cover the entire polygon. In other words, the goal is to find the minimum total length of trajectories on which the guards can travel to cover the entire polygon. We prove that this problem is NP-hard when k = 2 k=2 , and present a 2-approximation algorithm for any fixed k ≥ 2 k≥2 . The proposed algorithm also works well for an orthogonal polygon where the edges have thickness.},
  archive      = {J_TCS},
  author       = {Salma Sadat Mahdavi and Saeed Seddighin and Mohammad Ghodsi},
  doi          = {10.1016/j.tcs.2020.02.008},
  journal      = {Theoretical Computer Science},
  pages        = {163-181},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Covering orthogonal polygons with sliding k-transmitters},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The cover time of deterministic random walks for general
transition probabilities. <em>TCS</em>, <em>815</em>, 153–162. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A deterministic random walk is a deterministic process analogous to a random walk. While there are some results on the cover time of the rotor-router model, which is a deterministic random walk corresponding to a simple random walk , nothing is known about the cover time of deterministic random walks emulating general transition probabilities . This paper is concerned with the shortest remaining time (SRT)-router model with multiple tokens, which is a deterministic process coping with general transition probabilities possibly containing irrational numbers. For the model, we give an upper bound of the cover time, which is the first result on the cover time of deterministic random walks for general transition probabilities. Our upper bound also improves the existing bounds for the rotor-router model in some cases.},
  archive      = {J_TCS},
  author       = {Takeharu Shiraga},
  doi          = {10.1016/j.tcs.2020.02.009},
  journal      = {Theoretical Computer Science},
  pages        = {153-162},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The cover time of deterministic random walks for general transition probabilities},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On a simple hard variant of not-all-equal 3-sat.
<em>TCS</em>, <em>815</em>, 147–152. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a simplified version of Not-All-Equal 3- Sat , a variation of the famous Satisfiability problem, where each clause is made up of exactly three distinct literals and the question is whether there exists a truth assignment such that for each clause at least one literal is set to true and at least one is set to false. We show that Not-All-Equal 3- Sat remains NP-complete if (1) each variable appears exactly four times, (2) there are no negations in the formula, and (3) the formula is linear, i.e., each pair of distinct clauses shares at most one variable. Therewith, we improve upon two results in the literature.},
  archive      = {J_TCS},
  author       = {Andreas Darmann and Janosch Döcker},
  doi          = {10.1016/j.tcs.2020.02.010},
  journal      = {Theoretical Computer Science},
  pages        = {147-152},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On a simple hard variant of not-all-equal 3-sat},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recognizing hyperelliptic graphs in polynomial time.
<em>TCS</em>, <em>815</em>, 121–146. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on analogies between algebraic curves and graphs, Baker and Norine introduced divisorial gonality , a graph parameter for multigraphs related to treewidth, multigraph algorithms and number theory . Various equivalent definitions of the gonality of an algebraic curve translate to different notions of gonality for graphs, called stable gonality and stable divisorial gonality . We consider so-called hyperelliptic graphs (multigraphs of gonality 2, in any meaning of graph gonality) and provide a safe and complete set of reduction rules for such multigraphs. This results in an algorithm to recognize hyperelliptic graphs in time O ( m + n log ⁡ n ) O(m+nlog⁡n) , where n is the number of vertices and m the number of edges of the multigraph. A corollary is that we can decide with the same runtime whether a two-edge-connected graph G admits an involution σ such that the quotient G / 〈 σ 〉 G/〈σ〉 is a tree.},
  archive      = {J_TCS},
  author       = {Jelco M. Bodewes and Hans L. Bodlaender and Gunther Cornelissen and Marieke van der Wegen},
  doi          = {10.1016/j.tcs.2020.02.013},
  journal      = {Theoretical Computer Science},
  pages        = {121-146},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Recognizing hyperelliptic graphs in polynomial time},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved parameterized algorithms and kernels for mixed
domination. <em>TCS</em>, <em>815</em>, 109–120. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mixed domination of a graph G = ( V , E ) G=(V,E) is a mixed set D of vertices and edges such that for every edge or vertex, if it is not in D , then it is adjacent or incident to at least one vertex or edge in D . The Mixed Domination problem is to check whether there is a mixed domination of size at most k in a graph. Mixed domination is a mixture concept of vertex domination and edge domination, and the mixed domination problem has been studied from the view of approximation algorithms , parameterized algorithms, and so on. In this paper, we give a branch-and-search algorithm with running time bound of ⁎ O ⁎ ( 4.172 k ) O⁎(4.172k) , which improves the previous bound of ⁎ O ⁎ ( 7.465 k ) O⁎(7.465k) . For kernelization, it is known that the problem parameterized by k in general graphs is unlikely to have a polynomial kernel. We show the problem in planar graphs allows linear kernel by giving a kernel of 11 k − 16 11k−16 vertices.},
  archive      = {J_TCS},
  author       = {Mingyu Xiao and Zimo Sheng},
  doi          = {10.1016/j.tcs.2020.02.014},
  journal      = {Theoretical Computer Science},
  pages        = {109-120},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved parameterized algorithms and kernels for mixed domination},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Practical regular expression constrained sequence alignment.
<em>TCS</em>, <em>815</em>, 95–108. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The regular expression constrained sequence alignment problem is that of producing an optimal score alignment of two sequences which, at the same time, has aligned portions that are both described by a regular expression. In this article we introduce a series of improvements over existing algorithms to solve the problem when the regular expression has no Kleene closures. This is the case of biological patterns, such as those described by PROSITE and other databases. Such improvements include the construction of more compact ϵ -free NFAs for patterns and a significant reduction on automata transitions tracking during the alignment. The time complexity of our solution is O ( n m k 2 ) O(nmk2) , improving on the best known solution O ( n m k 3 | Σ | 3 / log ⁡ ( k | Σ | ) ) O(nmk3|Σ|3/log⁡(k|Σ|)) , where n and m are sequence lengths, k is the number of single elements in a PROSITE pattern and Σ is the alphabet. Our experiments have shown that practical running time is significantly smaller than the theoretical worst case mentioned above, and that the solution may be used efficiently in practice for solving the regular expression constrained alignment problem for biological sequences.},
  archive      = {J_TCS},
  author       = {Lise Rommel Romero Navarrete and Guilherme P. Telles},
  doi          = {10.1016/j.tcs.2020.02.017},
  journal      = {Theoretical Computer Science},
  pages        = {95-108},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Practical regular expression constrained sequence alignment},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On solving the 7,7,5-game and the 8,8,5-game. <em>TCS</em>,
<em>815</em>, 79–94. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An mnk -game is a kind of k -in-a-row game played on an m × n m×n board, where two players alternatively mark empty squares with their own colors and the first player who gets k -consecutive marks (horizontally, vertically, or diagonally) wins. In this paper, we present an AND/OR search tree algorithm specifically for proving mnk -games. We first propose three novel methods to reduce the branching factor of AND/OR search trees. We also propose a new method to find pairing strategies, which further accelerate the proof of mnk -games. The combined methods drastically speed up the proof for the 7,7,5-game, which is solved in 2.5 seconds. Moreover, this paper is the first to solve the 8,8,5-game, which is proven as a draw within 17.4 hours.},
  archive      = {J_TCS},
  author       = {Wei-Yuan Hsu and Chu-Ling Ko and Jr-Chang Chen and Ting-Han Wei and Chu-Hsuan Hsueh and I-Chen Wu},
  doi          = {10.1016/j.tcs.2020.02.023},
  journal      = {Theoretical Computer Science},
  pages        = {79-94},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On solving the 7,7,5-game and the 8,8,5-game},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A diagonal-based algorithm for the longest common increasing
subsequence problem. <em>TCS</em>, <em>815</em>, 69–78. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The longest common increasing subsequences (LCIS) problem is to find out a common increasing subsequence with the maximal length of two given sequences A and B . In this paper, we propose an algorithm for solving the LCIS problem with O ( ( n + L ( m − L ) ) log ⁡ log ⁡ | Σ | ) O((n+L(m−L))log⁡log⁡|Σ|) time and O( n ) space, where m and n denote the lengths of A and B , respectively, m ≤ n m≤n , L denotes the LCIS length, and Σ denotes the alphabet set. The main idea of our algorithm is to extend the answer from some previously feasible solutions, in which the domination function is invoked. To accomplish the extension and domination functions, the data structure of the van Emde Boas tree is utilized. From the time complexity, it is obvious that our algorithm is extremely efficient when L is very small or L is close to m . Some experiments are performed to demonstrate the efficiency of our algorithm.},
  archive      = {J_TCS},
  author       = {Shou-Fu Lo and Kuo-Tsung Tseng and Chang-Biau Yang and Kuo-Si Huang},
  doi          = {10.1016/j.tcs.2020.02.024},
  journal      = {Theoretical Computer Science},
  pages        = {69-78},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A diagonal-based algorithm for the longest common increasing subsequence problem},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Error-tolerant nonadaptive interval group testing with
density-based tests. <em>TCS</em>, <em>815</em>, 60–68. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In interval group testing , all items in the search space are linearly ordered and each of them is either positive or negative. The goal is to identify all positive ones by interval group tests, each asking a query of the type “does a group of consecutive items contain any positive one?” Xu et al. (1998) formulated the splice sites identification problem as an interval group testing problem. Nonadaptive and multistage algorithms have been studied (Cicalese et al. 2005, 2007). Motivated by a situation that a large group with a small number of positives may be too sparse so that positives can not be recognized there, we use density-based group tests to deal with interval group testing. Each density-based group test tells whether the proportion of positive items in a group exceeds a given ratio. We provide bounds on the number of density-based tests in an nonadaptive algorithm with error-tolerance.},
  archive      = {J_TCS},
  author       = {Huilan Chang and Han-Min Chu},
  doi          = {10.1016/j.tcs.2020.02.026},
  journal      = {Theoretical Computer Science},
  pages        = {60-68},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Error-tolerant nonadaptive interval group testing with density-based tests},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Tight lower bound of sparse covariance matrix estimation in
the local differential privacy model. <em>TCS</em>, <em>815</em>, 47–59.
(<a href="https://doi.org/10.1016/j.tcs.2020.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the sparse covariance matrix estimation problem in the local differential privacy model, and give a lower bound of Ω ( s 2 log ⁡ p n ϵ 2 ) Ω(s2log⁡pnϵ2) on the ϵ non-interactive private minimax risk in the metric of squared spectral norm, where s is the row sparsity of the underlying covariance matrix , n is the sample size, and p is the dimensionality of the data. We show that the lower bound is actually tight, as it matches a previous upper bound. Our main technique for achieving this lower bound is a general framework, called General Private Assouad Lemma , which is a considerable generalization of the previous private Assouad lemma and can be used as a general method for bounding the private minimax risk of matrix-related estimation problems.},
  archive      = {J_TCS},
  author       = {Di Wang and Jinhui Xu},
  doi          = {10.1016/j.tcs.2020.02.027},
  journal      = {Theoretical Computer Science},
  pages        = {47-59},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tight lower bound of sparse covariance matrix estimation in the local differential privacy model},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fully distributed hierarchical attribute-based encryption
scheme. <em>TCS</em>, <em>815</em>, 25–46. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of cloud computing, many enterprises have been interested in outsourcing their data to cloud servers to decrease IT costs and rise capabilities of provided services. To afford confidentiality and fine-grained data access control, attribute-based encryption (ABE) was proposed and used in several cloud storage systems. However, scalability and flexibility in key delegation and user revocation mechanisms are primary issues in ABE systems. In this paper, we introduce the concept of a fully distributed revocable ciphertext-policy hierarchical ABE (FDR-CP-HABE) and design the first FDR-CP-HABE scheme. Our scheme offers a high level of flexibility and scalability in the key delegation and user revocation phases. Moreover, our scheme is efficient and provides lightweight computation in the decryption phase. Indeed, by exploiting a computation outsourcing technique, most of the operations are executed by the powerful cloud server, and very few computations are left to the users. Also, the storage cost on the user side is significantly decreased as compared to similar schemes. Furthermore, using the hardness assumption of DBDH problem, we prove that our scheme is adaptively secure in the standard model. Our security analyses and implementation results indicate that our scheme is efficient, secure, and scalable.},
  archive      = {J_TCS},
  author       = {Mohammad Ali and Javad Mohajeri and Mohammad-Reza Sadeghi and Ximeng Liu},
  doi          = {10.1016/j.tcs.2020.02.030},
  journal      = {Theoretical Computer Science},
  pages        = {25-46},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A fully distributed hierarchical attribute-based encryption scheme},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Revocable identity-based encryption with server-aided
ciphertext evolution. <em>TCS</em>, <em>815</em>, 11–24. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utmost important problem in identity-based cryptosystems is the issue of user revocation . One of the existing solutions in the literature is to issue extra time keys periodically for every non-revoked user over public channels. Unfortunately, this solution is inefficient and very impractical when applying to the cloud. Because the scheme requires different time keys to allow data decryption for different time periods, and therefore the user has to keep a long list of time keys, which grows linearly with time. Furthermore, it is worth noting that ciphertexts produced prior to the revocation will remain available to the revoked users, which is undesirable for most application scenarios. To the best of our knowledge, there is no existing work that can solve both the aforementioned problems simultaneously in a practical manner . In this paper, we present an efficient solution called ciphertext evolution . The ciphertexts evolve to new ones with cloud&#39;s aid and the old ones are deleted. At any time, the data user has to utilize its current decryption key to decrypt ciphertexts in the cloud. So, all the past time keys become invalid and the user only needs to keep the current one. If the user is revoked, it cannot decrypt any ciphertext in the cloud because it does not have the current time key. We present generic and concrete constructions of revocable identity-based encryption with ciphertext evolution (RIBE-CE), which are proven based on the IND-CPA security model. Subsequently, we also extend RIBE-CE to the broadcast setting by giving generic and concrete constructions of revocable identity-based broadcast encryption with ciphertext evolution , which are secure under the IND-sID-CPA security model. Our schemes can be applied to the (group) data sharing, which is very practical and applicable to the cloud setting.},
  archive      = {J_TCS},
  author       = {Yinxia Sun and Yi Mu and Willy Susilo and Futai Zhang and Anmin Fu},
  doi          = {10.1016/j.tcs.2020.02.031},
  journal      = {Theoretical Computer Science},
  pages        = {11-24},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Revocable identity-based encryption with server-aided ciphertext evolution},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Resolution based algorithms for the transversal hypergraph
generation problem. <em>TCS</em>, <em>815</em>, 1–10. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem, given a hypergraph H H , how to generate its transversal (or dual) hypergraph G G , using tools from Boolean resolution. We show how to compute the residual dual of H H given a subset E E of its minimal transversals. This is the hypergraph whose minimal transversals are exactly those missing from E E to become the dual of H H . We give a novel algorithm for the problem based on the notion of subtransversal. Though its complexity is superpolynomial, it gives new insight to the problem of hypergraph duality. Another variant of the algorithm seems also promising to efficiently test hypergraph duality in practice.},
  archive      = {J_TCS},
  author       = {Stavros Cosmadakis and Dimitris Kavvadias and Lina Panagopoulou},
  doi          = {10.1016/j.tcs.2020.02.033},
  journal      = {Theoretical Computer Science},
  pages        = {1-10},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Resolution based algorithms for the transversal hypergraph generation problem},
  volume       = {815},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fully polynomial time approximation scheme for the
smallest diameter of imprecise points. <em>TCS</em>, <em>814</em>,
259–270. (<a href="https://doi.org/10.1016/j.tcs.2020.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set D = { d 1 , … , d n } D={d1,…,dn} of imprecise points modeled as disks, the minimum diameter problem is to locate a set P = { p 1 , … , p n } P={p1,…,pn} of fixed points, where p i ∈ d i pi∈di , such that the furthest distance between any pair of points in P is as small as possible. This introduces a tight lower bound on the size of the diameter of any instance P . In this paper, we present a fully polynomial time approximation scheme (FPTAS) for computing the minimum diameter of a set of disjoint disks that runs in O ( n 2 ϵ − 1 ) O(n2ϵ−1) time. Then we relax the disjointness assumption and we show that adjusting the presented FPTAS will cost O ( n 2 ϵ − 2 ) O(n2ϵ−2) time. We also show that our results can be generalized in R d Rd when the dimension d is an arbitrary fixed constant.},
  archive      = {J_TCS},
  author       = {Vahideh Keikha and Maarten Löffler and Ali Mohades},
  doi          = {10.1016/j.tcs.2020.02.006},
  journal      = {Theoretical Computer Science},
  pages        = {259-270},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A fully polynomial time approximation scheme for the smallest diameter of imprecise points},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Popularity of patterns over d-equivalence classes of words
and permutations. <em>TCS</em>, <em>814</em>, 249–258. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two same length words are d -equivalent if they have same descent set and same underlying alphabet. In particular, two same length permutations are d -equivalent if they have same descent set. The popularity of a pattern in a set of words is the overall number of copies of the pattern within the words of the set. We show the far-from-trivial fact that two patterns are d -equivalent if and only if they are equipopular over any d -equivalence class, and this equipopularity does not follow obviously from a trivial equidistribution .},
  archive      = {J_TCS},
  author       = {Jean-Luc Baril and Vincent Vajnovszki},
  doi          = {10.1016/j.tcs.2020.02.005},
  journal      = {Theoretical Computer Science},
  pages        = {249-258},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Popularity of patterns over d-equivalence classes of words and permutations},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Paraunitary matrices, entropy, algebraic condition number
and fourier computation. <em>TCS</em>, <em>814</em>, 234–248. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fourier Transform is one of the most important linear transformations used in science and engineering. Cooley and Tukey&#39;s Fast Fourier Transform (FFT) from 1964 is a method for computing this transformation in time O ( n log ⁡ n ) O(nlog⁡n) . From a lower bound perspective, relatively little is known. Ailon shows in 2013 an Ω ( n log ⁡ n ) Ω(nlog⁡n) bound for computing the normalized Fourier Transform assuming only unitary operations on two coordinates are allowed at each step, and no extra memory is allowed. In 2014, Ailon then improved the result to show that, in a κ -well conditioned computation, Fourier computation can be sped up by no more than O ( κ ) O(κ) . The main conjecture is that Ailon&#39;s result can be exponentially improved, in the sense that κ -well condition cannot admit ω ( log ⁡ κ ) ω(log⁡κ) speedup. The main result here is that ‘algebraic’ κ -well condition cannot admit ω ( κ ) ω(κ) speedup. One equivalent definition of algebraic condition number is related to the degree of polynomials naturally arising as the computation evolves. Using the maximum modulus theorem from complex analysis, we show that algebraic condition number upper bounds standard condition number, and equals it in certain cases. Algebraic condition number is an interesting measure of numerical computation stability in its own right, and provides a novel computational lens. Moreover, based on evidence from other recent related work, we believe that the approach of algebraic condition number has a good chance of establishing an algebraic version of the main conjecture.},
  archive      = {J_TCS},
  author       = {Nir Ailon},
  doi          = {10.1016/j.tcs.2020.02.002},
  journal      = {Theoretical Computer Science},
  pages        = {234-248},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Paraunitary matrices, entropy, algebraic condition number and fourier computation},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leakage-resilient biometric-based remote user authentication
with fuzzy extractors. <em>TCS</em>, <em>814</em>, 223–233. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy extractors convert biometrics and other noisy data into a cryptographic key for security applications such as remote user authentication . Leakage attacks, such as side channel attacks , have been extensively modelled and studied in the literature. However, to the best of our knowledge, leakage attacks to biometric-based remote user authentication with fuzzy extractors have never been studied rigorously. In this paper, we propose a generic framework of leakage-resilient and privacy-preserving biometric-based remote user authentication that allows an authorized user to securely authenticate herself to a remote authentication server using her biometrics . In particular, the authorized user relies only on her secret biometrics to perform a valid authentication — which is suitable for user authentications in a cross-platform setting.},
  archive      = {J_TCS},
  author       = {Yangguang Tian and Yingjiu Li and Binanda Sengupta and Nan Li and Chunhua Su},
  doi          = {10.1016/j.tcs.2020.02.001},
  journal      = {Theoretical Computer Science},
  pages        = {223-233},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Leakage-resilient biometric-based remote user authentication with fuzzy extractors},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient meta-data structure in top-k queries of
combinations and multi-item procurement auctions. <em>TCS</em>,
<em>814</em>, 210–222. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Top- k query processing is an important building block for ranked retrieval, with various applications. In this paper, we consider two interesting top- k retrieval problems. In the first problem, we consider the r -combinations of a set S of n real numbers. Precisely, on any input set S , any positive integers k and r , our target is to generate the k best size- r subsets of S efficiently, whose sum of elements is maximized. Our method defines a novel metadata structure G for n and r , even before S and k are known, so that we can later use G to report the top- k r -combinations efficiently when S is available. In the second problem, we consider the top- k procurement decision problem in a multi-item auction, where the input consists of (i) a set of items, where each item is partitioned into equal number of shares, (ii) a set of suppliers, and (iii) for each supplier, her prices of selling different shares of each item; our target is to find k procurements with the least total costs. Our solution extends the novel metadata structure G of the first problem to speed up the reporting steps. For both of the above problems, we further show that the metadata structure can be generated on the fly, thereby saving a considerable amount of storage space.},
  archive      = {J_TCS},
  author       = {Biswajit Sanyal and Subhashis Majumder and Wing-Kai Hon and Prosenjit Gupta},
  doi          = {10.1016/j.tcs.2020.01.036},
  journal      = {Theoretical Computer Science},
  pages        = {210-222},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient meta-data structure in top-k queries of combinations and multi-item procurement auctions},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A computational complexity analysis of tunable type
inference for generic universe types. <em>TCS</em>, <em>814</em>,
189–209. (<a href="https://doi.org/10.1016/j.tcs.2020.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address questions related to the computational complexity of inferring types for a particular type system, Generic Universe Types (GUT) [1] , [2] , for Java programs. GUT is useful for many applications, such as program verification [3] , thread synchronization, and memory management . However, requiring the programmer to explicitly provide type information is onerous, which motivates the problem of automatically inferring types. In contrast to classical type systems, ownership type systems such as GUT may have multiple typings that satisfy the type system&#39;s rules. It is therefore appropriate for the inference to be tunable — that is, the programmer can indicate preferences for certain typings via breakable constraints and/or by partial annotations. A question then is whether efficient algorithms exist for the type inference problem. In this work we establish the following results for the type inference problem for GUT [2] . (1) The tunable type inference problem that allows breakable constraints is NP -hard, (2) an encoding of the problem as boolean satisfiability (SAT), as in prior work, is indeed a polynomial-time reduction, (3) P ≠ NP implies that the problem is not approximable in polynomial time within an approximation ratio of n 1 − ϵ n1−ϵ for any ϵ &gt; 0 ϵ&amp;gt;0 , and (4) while some restricted versions of the problem of practical interest, such as when breakable constraints are forbidden, are in P , others remain NP -hard. Our results justify the prior approach to the problem that is based on reduction to SAT. Apart from these results, given the observation in prior work that instances of the problem that arise in practice appear to be easy, we address the natural question as to what hard instances may look like, and whether they may arise in practice. We identify a class of hard instances of the problem by devising a method to generate such instances starting at instances of the Vertex Cover problem, which is known to be NP -hard. We then analyze the structural properties of such instances as compared to easy instances of similar size. We find that for the classes of instances we consider, certain SAT structural parameters may be predictive of empirical hardness.},
  archive      = {J_TCS},
  author       = {Nahid Juma and Werner Dietl and Mahesh Tripunitara},
  doi          = {10.1016/j.tcs.2020.01.035},
  journal      = {Theoretical Computer Science},
  pages        = {189-209},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A computational complexity analysis of tunable type inference for generic universe types},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subset feedback vertex set on graphs of bounded independent
set size. <em>TCS</em>, <em>814</em>, 177–188. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ( Weighted ) Subset Feedback Vertex Set problem is a generalization of the classical Feedback Vertex Set problem and asks for a vertex set of minimum (weight) size that intersects all cycles containing a vertex of a predescribed set of vertices. Although Subset Feedback Vertex Set and Feedback Vertex Set exhibit different computational complexity on split graphs, no similar characterization is known on other classes of graphs. Towards the understanding of the complexity difference between the two problems, it is natural to study the importance of structural graph parameters. Here we consider graphs of bounded independent set number for which it is known that Weighted Feedback Vertex Set can be solved in polynomial time . We provide a dichotomy result with respect to the size α of a maximum independent set. In particular we show that Weighted Subset Feedback Vertex Set can be solved in polynomial time for graphs with α ≤ 3 α≤3 , whereas we prove that the problem remains NP-hard for graphs with α ≥ 4 α≥4 . Moreover, we show that the (unweighted) Subset Feedback Vertex Set problem can be solved in polynomial time on graphs of bounded independent set number by giving an algorithm with running time n O ( α ) nO(α) . To complement our results, we demonstrate how our ideas can be extended to other terminal set problems on graphs of bounded independent set size. Node Multiway Cut is a terminal set problem that asks for a vertex set of minimum size that intersects all paths connecting any two terminals. Based on our findings for Subset Feedback Vertex Set , we settle the complexity of Node Multiway Cut as well as its variants where nodes are weighted and/or the terminals are deletable, for every value of the given independent set number.},
  archive      = {J_TCS},
  author       = {Charis Papadopoulos and Spyridon Tzimas},
  doi          = {10.1016/j.tcs.2020.01.029},
  journal      = {Theoretical Computer Science},
  pages        = {177-188},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Subset feedback vertex set on graphs of bounded independent set size},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dualization in lattices given by implicational bases.
<em>TCS</em>, <em>814</em>, 169–176. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It was recently proved that the dualization in lattices given by implicational bases is impossible in output-polynomial time unless P = NP . In this paper, we show that this result holds even when the premises in the implicational base are of size at most two. Then we show using hypergraph dualization that the problem can be solved in output quasi-polynomial time whenever the implicational base has bounded independent-width, defined as the size of a maximum set of implications having independent conclusions. Lattices that share this property include distributive lattices coded by the ideals of an interval order , when both the independent-width and the size of the premises equal one.},
  archive      = {J_TCS},
  author       = {Oscar Defrain and Lhouari Nourine},
  doi          = {10.1016/j.tcs.2020.01.028},
  journal      = {Theoretical Computer Science},
  pages        = {169-176},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dualization in lattices given by implicational bases},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computational aspects of optimal strategic network
diffusion. <em>TCS</em>, <em>814</em>, 153–168. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion on complex networks is often modeled as a stochastic process . Yet, recent work on strategic diffusion emphasizes the decision power of agents [1] and treats diffusion as a strategic problem. Here we study the computational aspects of strategic diffusion, i.e. , finding the optimal sequence of nodes to activate a network in the minimum time. We prove that finding an optimal solution to this problem is NP-complete in a general case. To overcome this computational difficulty, we present an algorithm to compute an optimal solution based on a dynamic programming technique. We also show that the problem is fixed parameter-tractable when parametrized by the product of the treewidth and maximum degree . We analyze the possibility of developing an efficient approximation algorithm and show that two heuristic algorithms proposed so far cannot have better than a logarithmic approximation guarantee. Finally, we prove that the problem does not admit better than a logarithmic approximation, unless P=NP.},
  archive      = {J_TCS},
  author       = {Marcin Waniek and Khaled Elbassioni and Flávio L. Pinheiro and César A. Hidalgo and Aamena Alshamsi},
  doi          = {10.1016/j.tcs.2020.01.027},
  journal      = {Theoretical Computer Science},
  pages        = {153-168},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computational aspects of optimal strategic network diffusion},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hitting minors on bounded treewidth graphs. II.
Single-exponential algorithms. <em>TCS</em>, <em>814</em>, 135–152. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a finite collection of graphs F , the F -M-Deletion (resp. F -TM-Deletion ) problem consists in, given a graph G and an integer k , decide whether there exists S ⊆ V ( G ) with | S | ≤ k such that G ∖ S does not contain any of the graphs in F as a minor (resp. topological minor). We are interested in the parameterized complexity of both problems when the parameter is the treewidth of G , denoted by tw , and specifically in the cases where F contains a single connected planar graph H . We present algorithms running in time 2 O ( tw ) ⋅ n O ( 1 ) , called single-exponential , when H is either P 3 , P 4 , C 4 , the paw , the chair , and the banner for both { H } -M-Deletion and { H } -TM-Deletion , and when H = K 1 , i , with i ≥ 1 , for { H } -TM-Deletion . Some of these algorithms use the rank-based approach introduced by Bodlaender et al. (2015) [7] . This is the second of a series of articles on this topic, and the results given here together with other ones allow us, in particular, to provide a tight dichotomy on the complexity of { H } -M-Deletion in terms of H .},
  archive      = {J_TCS},
  author       = {Julien Baste and Ignasi Sau and Dimitrios M. Thilikos},
  doi          = {10.1016/j.tcs.2020.01.026},
  journal      = {Theoretical Computer Science},
  pages        = {135-152},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hitting minors on bounded treewidth graphs. II. single-exponential algorithms},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Binary-decision-diagram-based decomposition of boolean
functions into reversible logic elements. <em>TCS</em>, <em>814</em>,
120–134. (<a href="https://doi.org/10.1016/j.tcs.2020.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A binary decision diagram (BDDs) is a compact data structure used to represent a Boolean function , which facilitates scalable constructions of Boolean functions using reversible logic gates. Motivated by the scalable synthesis approach, this paper proposes an effective scheme for transforming the BDD representation of a Boolean function into a reversible circuit composed by reversible logic elements. Unlike a logic gate, a reversible logic element carries a memory to record a finite number of states. Especially, logic circuits composed by reversible elements can operate in asynchronous mode , thereby no need of a clock signal to drive all elements operating simultaneously.},
  archive      = {J_TCS},
  author       = {Jia Lee and Ya-Hui Ye and Xin Huang and Rui-Long Yang},
  doi          = {10.1016/j.tcs.2020.01.019},
  journal      = {Theoretical Computer Science},
  pages        = {120-134},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Binary-decision-diagram-based decomposition of boolean functions into reversible logic elements},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The number of rearrangements for clos networks – new
results. <em>TCS</em>, <em>814</em>, 106–119. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rearrangeable Clos networks have been studied for a long time due to their many applications, as well as their theoretical interest. In a rearrangeable Clos network, a newly requested connection may be blocked by existing connections. However, this blocking is eliminated by adequately rearranging some other existing connections. In this operation, an interesting topic is the sufficient number of rearrangements required to eliminate the blocking. Despite previous studies, the sufficient number of rearrangements has only been found for limited cases and has not been completely determined for generic parameter values. This paper analyses the number of rearrangements using the connection chain concept, which clearly and efficiently represents a sequence of connections to be rearranged. The analysis assumes the employment of a rearrangement algorithm, which eliminates the blocking using the shortest connection chain. The usage of the shortest connection chain results in the minimum number of rearrangements. As a result, this paper determines a new bound on the number of rearrangements for a parameter range that has not been considered in any previous studies. In addition, this paper examines the condition for which the system is unblocked via one rearrangement.},
  archive      = {J_TCS},
  author       = {Satoru Ohta},
  doi          = {10.1016/j.tcs.2020.01.018},
  journal      = {Theoretical Computer Science},
  pages        = {106-119},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The number of rearrangements for clos networks – new results},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed integer programming with convex/concave constraints:
Fixed-parameter tractability and applications to multicovering and
voting. <em>TCS</em>, <em>814</em>, 86–105. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classic result of Lenstra [Math. Oper. Res. 1983] says that an integer linear program can be solved in fixed-parameter tractable ( FPT FPT ) time for the parameterization by the number of variables. We extend this result by incorporating piecewise linear convex or concave functions to our (mixed) integer programs . This general technique allows us to analyze the parameterized complexity of a number of classic NP NP -hard computational problems. In particular, we prove that Weighted Set Multicover is in FPT FPT when parameterized by the number of elements to cover, and that there exists an FPT FPT -time approximation scheme for Multiset Multicover for the same parameter—this is our most technical result. Further, we use our general technique to prove that a number of problems from computational social choice (e.g., problems related to bribery and control in elections) are in FPT FPT when parameterized by the number of candidates. For bribery, this resolves a nearly 10-year old family of open problems, and for weighted electoral control of Approval voting, this improves some previously known XP XP -memberships to FPT FPT -memberships.},
  archive      = {J_TCS},
  author       = {Robert Bredereck and Piotr Faliszewski and Rolf Niedermeier and Piotr Skowron and Nimrod Talmon},
  doi          = {10.1016/j.tcs.2020.01.017},
  journal      = {Theoretical Computer Science},
  pages        = {86-105},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Mixed integer programming with convex/concave constraints: Fixed-parameter tractability and applications to multicovering and voting},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for connected maximum cut and
related problems. <em>TCS</em>, <em>814</em>, 74–85. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An instance of the Connected Maximum Cut problem consists of an undirected graph G = ( V , E ) G=(V,E) and the goal is to find a subset of vertices S ⊆ V S⊆V that maximizes the number of edges in the cut δ ( S ) δ(S) such that the induced graph G [ S ] G[S] is connected. We present the first non-trivial Ω ( 1 log ⁡ n ) Ω(1log⁡n) approximation algorithm for the Connected Maximum Cut problem in general graphs using novel techniques. We then extend our algorithm to edge weighted case and obtain a poly-logarithmic approximation algorithm . Interestingly, in contrast to the classical Max-Cut problem that can be solved in polynomial time on planar graphs , we show that the Connected Maximum Cut problem remains NP-hard on unweighted, planar graphs . On the positive side, we obtain a polynomial time approximation scheme for the Connected Maximum Cut problem on planar graphs and more generally on bounded genus graphs.},
  archive      = {J_TCS},
  author       = {MohammadTaghi Hajiaghayi and Guy Kortsarz and Robert MacDavid and Manish Purohit and Kanthi Sarpatwar},
  doi          = {10.1016/j.tcs.2020.01.016},
  journal      = {Theoretical Computer Science},
  pages        = {74-85},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithms for connected maximum cut and related problems},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The directed 2-linkage problem with length constraints.
<em>TCS</em>, <em>814</em>, 69–73. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weak 2-linkage problem for digraphs asks for a given digraph and vertices s 1 , s 2 , t 1 , t 2 whether D contains a pair of arc-disjoint paths P 1 , P 2 such that P i is an ( s i , t i ) -path. This problem is NP-complete for general digraphs but polynomially solvable for acyclic digraphs [8] . Recently it was shown [3] that if D is equipped with a weight function w on the arcs which satisfies that all edges have positive weight, then there is a polynomial algorithm for the variant of the weak-2-linkage problem when both paths have to be shortest paths in D . In this paper we consider the unit weight case and prove that for every pair of constants k 1 , k 2 , there is a polynomial algorithm which decides whether the input digraph D has a pair of arc-disjoint paths P 1 , P 2 such that P i is an ( s i , t i ) -path of length no more than d ( s i , t i ) + k i , for i = 1 , 2 , where d ( s i , t i ) denotes the length of the shortest ( s i , t i ) -path. We prove that, unless the exponential time hypothesis (ETH) fails, there is no polynomial algorithm for deciding the existence of a solution P 1 , P 2 to the weak 2-linkage problem where each path P i has length at most d ( s i , t i ) + c log 1 + ϵ ⁡ n for some constant c .},
  archive      = {J_TCS},
  author       = {J. Bang-Jensen and T. Bellitto and W. Lochet and A. Yeo},
  doi          = {10.1016/j.tcs.2020.01.012},
  journal      = {Theoretical Computer Science},
  pages        = {69-73},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The directed 2-linkage problem with length constraints},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Refined analysis to the extended tower number field sieve.
<em>TCS</em>, <em>814</em>, 49–68. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hardness of discrete logarithm problem over finite fields is the security foundation of many cryptographic protocols . When the characteristic of the finite field is medium or large, the state-of-art algorithms for solving the corresponding problem are the number field sieve and its variants. In 2016, Kim and Barbulescu presented the extended tower number field sieve, which achieves a new complexity in the medium prime case and imposes a new estimation of the security of concrete parameters in certain cryptosystems such as pairing-based cryptosystems. In this paper, a refined analysis to this algorithm is given as follows.},
  archive      = {J_TCS},
  author       = {Yuqing Zhu and Jiejing Wen and Jincheng Zhuang and Chang Lv and Dongdai Lin},
  doi          = {10.1016/j.tcs.2020.01.010},
  journal      = {Theoretical Computer Science},
  pages        = {49-68},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Refined analysis to the extended tower number field sieve},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semitotal domination: New hardness results and a
polynomial-time algorithm for graphs of bounded mim-width. <em>TCS</em>,
<em>814</em>, 28–48. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A semitotal dominating set of a graph G with no isolated vertex is a dominating set D of G such that every vertex in D is within distance two of another vertex in D . The minimum size γ t 2 ( G ) γt2(G) of a semitotal dominating set of G is squeezed between the domination number γ ( G ) γ(G) and the total domination number γ t ( G ) γt(G) . Semitotal Dominating Set is the problem of finding, given a graph G , a semitotal dominating set of G of size γ t 2 ( G ) γt2(G) . In this paper, we continue the systematic study on the computational complexity of this problem when restricted to special graph classes. In particular, we show that it is solvable in polynomial time for the class of graphs of bounded mim-width by a reduction to Total Dominating Set and we provide several approximation lower bounds for subclasses of subcubic graphs. Moreover, we obtain complexity dichotomies in monogenic classes for the decision versions of Semitotal Dominating Set and Total Dominating Set . Finally, we show that it is NP NP -complete to recognise the graphs such that γ t 2 ( G ) = γ t ( G ) γt2(G)=γt(G) and those such that γ ( G ) = γ t 2 ( G ) γ(G)=γt2(G) , even if restricted to be planar and with maximum degree at most 4, and we provide forbidden induced subgraph characterisations for the graphs hereditarily satisfying either of these two equalities.},
  archive      = {J_TCS},
  author       = {Esther Galby and Andrea Munaro and Bernard Ries},
  doi          = {10.1016/j.tcs.2020.01.007},
  journal      = {Theoretical Computer Science},
  pages        = {28-48},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Semitotal domination: New hardness results and a polynomial-time algorithm for graphs of bounded mim-width},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rg conditional diagnosability: A novel generalized measure
of system-level diagnosis. <em>TCS</em>, <em>814</em>, 19–27. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System-level diagnosis has become an important diagnosis method for multiprocessor systems . Among all system-level diagnosis measures, diagnosability is relatively small. The conditional diagnosability constraint that each vertex has at least one good neighbor is relatively conservative when the dimension is far greater than 1, and g-good-neighbor conditional diagnosability does not consider this restriction on faulty vertices. Therefore, a thorough study of diagnosability under the condition that each vertex has at least g good neighbors is an appealing subject. Motivated by R g Rg vertex connectivity, in this paper, we introduce a novel generalized system-level diagnosis measure named R g Rg conditional diagnosability, which assumes that every processor has at least g good neighbors. The popular conditional diagnosability is a special case of R g Rg conditional diagnosability when g = 1 g=1 . Then, we determine that the R g Rg conditional diagnosability of n -dimensional hypercube Q n Qn under the Preparata Metze Chien (PMC) model is 2 2 g ( n − 2 g ) + 2 2 g − 1 − 1 22g(n−2g)+22g−1−1 .},
  archive      = {J_TCS},
  author       = {Chen Guo and Zhifang Xiao and Zhihong Liu and Shuo Peng},
  doi          = {10.1016/j.tcs.2020.01.006},
  journal      = {Theoretical Computer Science},
  pages        = {19-27},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Rg conditional diagnosability: A novel generalized measure of system-level diagnosis},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pseudo-solutions of word equations. <em>TCS</em>,
<em>814</em>, 13–18. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a framework which allows a uniform approach to the recently introduced concept of pseudo-repetitions on words in the morphic case. This framework is at the same time more general and simpler. We introduce the concept of a pseudo-solution and a pseudo-rank of an equation. In particular, this allows to prove that if a classical equation forces periodicity then it also forces pseudo-periodicity. Consequently, there is no need to investigate generalizations of important equations one by one.},
  archive      = {J_TCS},
  author       = {Štěpán Holub},
  doi          = {10.1016/j.tcs.2019.12.035},
  journal      = {Theoretical Computer Science},
  pages        = {13-18},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Pseudo-solutions of word equations},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Counter based suffix tree for DNA pattern repeats.
<em>TCS</em>, <em>814</em>, 1–12. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the string datasets have increased exponentially, so is the need to process them. Most of these datasets have been deeply rooted in the field of bioinformatics since the entire characteristics of any living organism is encoded in their genes. Genes consist of nucleic bases which will, therefore, makeup the entire genome. A genome is made of a concatenation of different types of nucleic bases. To efficiently extract the information encrypted in these sequences there is a need to use algorithms to decrypt it. Most available methods use the data structure commonly referred to as the suffix tree. They have tremendously evolved over the years, and the on-line construction of the suffix tree is deemed as the best data structure, however, it is not optimal when it comes to finding repeated sequences because of many traversals algorithm will have to do when identifying repeats. To improve the speed and of finding repeats we developed a counter based suffix tree algorithm. Our work presents a novel algorithm of constructing a counter based suffix tree without losing its properties. The counter based suffix tree time complexity is θ ( n ) θ(n) where n represents the length of a string. Which is the same as the fastest suffix tree implementation. We have shown that the counter based suffix tree will reduce the search time when identifying repeats. We have proved that a counter based suffix tree can be developed during construction.},
  archive      = {J_TCS},
  author       = {Tshepo Kitso Gobonamang and Dimane Mpoeleng},
  doi          = {10.1016/j.tcs.2019.12.014},
  journal      = {Theoretical Computer Science},
  pages        = {1-12},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Counter based suffix tree for DNA pattern repeats},
  volume       = {814},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branching-time logic ECTL# and its tree-style one-pass
tableau: Extending fairness expressibility of ECTL+. <em>TCS</em>,
<em>813</em>, 428–451. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal logic has become essential for various areas in computer science, most notably for the specification and verification of hardware and software systems. For the specification purposes rich temporal languages are required that, in particular, can express fairness constraints . For linear-time logics which deal with fairness in the linear-time setting, one-pass and two-pass tableau methods have been developed. In the repository of the CTL-type branching-time setting, the well-known logics ECTL ECTL and ECT L + ECTL+ were developed to explicitly deal with fairness. However, due to the syntactical restrictions, these logics can only express restricted versions of fairness. The logic CT L ⋆ CTL⋆ , often considered as ‘the full branching-time logic’ overcomes these restrictions on expressing fairness. However, CT L ⋆ CTL⋆ is extremely challenging for the application of verification techniques, and the tableau technique, in particular. For example, there is no one-pass tableau construction for CT L ⋆ CTL⋆ , while one-pass tableau has an additional benefit enabling the formulation of dual sequent calculi that are often treated as more ‘natural’ being more friendly for human understanding. These two considerations lead to the following problem - are there logics that have richer expressiveness than ECT L + ECTL+ , allowing the formulation of a new range of fairness constraints with ‘until’ operator, yet ‘simpler’ than CT L ⋆ CTL⋆ , and for which a one-pass tableau can be developed? Here we give a positive answer to this question, introducing a sub-logic of CT L ⋆ CTL⋆ called ECT L # ECTL# , its tree-style one-pass tableau, and an algorithm for obtaining a systematic tableau, for any given admissible branching-time formulae. We prove the termination, soundness and completeness of the method. As tree-shaped one-pass tableaux are well suited for the automation and are amenable for the implementation and for the formulation of sequent calculi . Our results also open a prospect of relevant developments of the automation and implementation of the tableau method for ECT L # ECTL# , and of a dual sequent calculi.},
  archive      = {J_TCS},
  author       = {Alexander Bolotov and Montserrat Hermo and Paqui Lucio},
  doi          = {10.1016/j.tcs.2020.02.015},
  journal      = {Theoretical Computer Science},
  pages        = {428-451},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Branching-time logic ECTL# and its tree-style one-pass tableau: Extending fairness expressibility of ECTL+},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A logic for lawson compact algebraic l-domains.
<em>TCS</em>, <em>813</em>, 410–427. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we build a logic which is named N-sequent calculus. Based on this logic, we provide two kinds of logical representations of Lawson compact algebraic L-domains: one in terms of logical algebras and the other in terms of logical syntax. The first representation takes the corresponding logical algebras as research objects. The use of prime filters achieves the connection between our logic and Lawson compact algebraic L-domains. This approach is inspired by Abramsky&#39;s SFP domain logic and the disjunctive propositional logic on algebraic L-domains introduced by Yixiang Chen and Achim Jung. However, there are essential differences between them at the morphisms part. For the second representation, we directly adopt N-sequent calculi themselves as objects instead of the logical algebras. Then we establish the category of N-sequent calculi with consequence relations equivalent to that of Lawson compact algebraic L-domains with Scott continuous maps. This demonstrates the capability of the syntax of the logic in representing domains.},
  archive      = {J_TCS},
  author       = {Longchun Wang and Qingguo Li},
  doi          = {10.1016/j.tcs.2020.01.025},
  journal      = {Theoretical Computer Science},
  pages        = {410-427},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A logic for lawson compact algebraic L-domains},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the concurrent computational content of intermediate
logics. <em>TCS</em>, <em>813</em>, 375–409. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a proofs-as-concurrent-programs interpretation for a large class of intermediate logics that can be formalized by cut-free hypersequent calculi. Obtained by adding classical disjunctive tautologies to intuitionistic logic , these logics are used to type concurrent λ -calculi by Curry–Howard correspondence; each of the calculi features a specific communication mechanism, enhanced expressive power when compared to the λ -calculus, and implements forms of code mobility. We thus confirm Avron&#39;s 1991 thesis that intermediate logics formalizable by hypersequent calculi can serve as basis for concurrent λ -calculi.},
  archive      = {J_TCS},
  author       = {Federico Aschieri and Agata Ciabattoni and Francesco A. Genco},
  doi          = {10.1016/j.tcs.2020.01.022},
  journal      = {Theoretical Computer Science},
  pages        = {375-409},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the concurrent computational content of intermediate logics},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the expressive power of hybrid branching-time logics.
<em>TCS</em>, <em>813</em>, 362–374. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid branching-time logics are a powerful extension of branching-time logics like CTL, CTL ⁎ or even the modal μ -calculus through the addition of binders, jumps and variable tests. Their expressiveness is not restricted by bisimulation-invariance anymore. Hence, they do not retain the tree model property, and the finite model property is equally lost. Their satisfiability problems are typically undecidable, their model checking problems (on finite models) are decidable with complexities ranging from polynomial to non-elementary time. In this paper we study the expressive power of such hybrid branching-time logics. We extend the hierarchy of branching-time logics CTL, CTL + , CTL ⁎ and the modal μ -calculus to their hybrid extensions. We show that most separation results can be transferred to the hybrid world, even though the required techniques become more involved. We also present collapse results for linear, tree-shaped and finite models.},
  archive      = {J_TCS},
  author       = {Daniel Kernberger and Martin Lange},
  doi          = {10.1016/j.tcs.2020.01.014},
  journal      = {Theoretical Computer Science},
  pages        = {362-374},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the expressive power of hybrid branching-time logics},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the efficiency of normal form systems for representing
boolean functions. <em>TCS</em>, <em>813</em>, 341–361. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A normal form system (NFS) for representing Boolean functions is thought of as a set of stratified terms over a fixed set of connectives. For a fixed NFS A , the complexity of a Boolean function f with respect to A is the minimum of the sizes of terms in A that represent f . This induces a preordering of NFSs: an NFS A is polynomially as efficient as an NFS B if there is a polynomial P with nonnegative integer coefficients such that the complexity of any Boolean function f with respect to A is at most the value of P in the complexity of f with respect to B . In this paper we study monotonic NFSs, i.e., NFSs whose connectives are increasing or decreasing in each argument. We describe the monotonic NFSs that are optimal, i.e., that are minimal with respect to the latter preorder. We show that these minimal monotonic NFSs are all equivalent. Moreover, we address some natural questions, e.g.: does optimality depend on the arity of connectives? Does it depend on the number of connectives used? We show that optimal monotonic NFSs are exactly those that use a single connective or one connective and the negation. Finally, we show that optimality does not depend on the arity of the connectives.},
  archive      = {J_TCS},
  author       = {Miguel Couceiro and Erkko Lehtonen and Pierre Mercuriali and Romain Péchoux},
  doi          = {10.1016/j.tcs.2020.01.009},
  journal      = {Theoretical Computer Science},
  pages        = {341-361},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the efficiency of normal form systems for representing boolean functions},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A formal system of reduction paths for parallel reduction.
<em>TCS</em>, <em>813</em>, 327–340. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a formal system of reduction paths as a category-like structure induced from a digraph . Our motivation behind this work comes from a quantitative analysis of reduction systems based on the perspective of computational cost and computational orbit. From the perspective, we define a formal system of reduction paths for parallel reduction, wherein reduction paths are generated from a quiver by means of three path-operators. Next, we introduce an equational theory and reduction rules for the reduction paths, and show that the rules on paths are terminating and confluent so that normal paths are obtained. Following the notion of normal paths, a graphical representation of reduction paths is provided. Then we show that the reduction graph is a plane graph , and unique path and universal common-reduct properties are established. Finally, a set of transformation rules from a conversion sequence to a reduction path leading to the universal common-reduct is given under a certain strategy.},
  archive      = {J_TCS},
  author       = {Ken-etsu Fujita},
  doi          = {10.1016/j.tcs.2020.01.002},
  journal      = {Theoretical Computer Science},
  pages        = {327-340},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A formal system of reduction paths for parallel reduction},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Timeline-based planning over dense temporal domains.
<em>TCS</em>, <em>813</em>, 305–326. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning is one of the most studied problems in computer science. In this paper, we focus on the timeline-based approach, where the domain is modeled by a set of independent, but interacting, components, each one represented by a number of state variables, whose behavior over time (timelines) is governed by a set of temporal constraints (transition functions and synchronization rules). Whereas the time domain is usually assumed to be discrete, here we address decidability and complexity issues for timeline-based planning (TP) over dense time. We first prove that dense TP is undecidable in the general case; then, we show that decidability can be recovered by restricting to synchronization rules with a suitable future semantics. More “tractable” settings can be obtained by additionally constraining the form of intervals used in rules: EXPSPACE -completeness is obtained by avoiding singular intervals, and PSPACE -completeness by admitting only intervals of the forms [ 0 , a ] [0,a] and [ b , + ∞ [ [b,+∞[ . Finally, NP -completeness can be proved for dense TP with purely existential rules only.},
  archive      = {J_TCS},
  author       = {Laura Bozzelli and Alberto Molinari and Angelo Montanari and Adriano Peron and Gerhard Woeginger},
  doi          = {10.1016/j.tcs.2019.12.030},
  journal      = {Theoretical Computer Science},
  pages        = {305-326},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Timeline-based planning over dense temporal domains},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beyond ω-regular languages: ωT-regular expressions and their
automata and logic counterparts. <em>TCS</em>, <em>813</em>, 270–304.
(<a href="https://doi.org/10.1016/j.tcs.2019.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years, some extensions of ω -regular languages, namely, ωB -regular ( ω -regular languages extended with boundedness), ωS -regular ( ω -regular languages extended with strong unboundedness), and ωBS -regular languages (the combination of ωB - and ωS -regular ones), have been proposed in the literature. While the first two classes satisfy a generalized closure property, which states that the complement of an ωB -regular (resp., ωS -regular) language is an ωS -regular (resp., ωB -regular) one, the last class is not closed under complementation. The existence of non- ωBS -regular languages that are the complements of some ωBS -regular ones and express fairly natural asymptotic behaviors motivates the search for other significant classes of extended ω -regular languages. In this paper, we present the class of ωT -regular languages, which includes meaningful languages that are not ωBS -regular. We define this new class of languages in terms of ωT -regular expressions. Then, we introduce a new class of automata (counter-check automata) and we prove that (i) their emptiness problem is decidable in PTIME, and (ii) they are expressive enough to capture ωT -regular languages. We also provide an encoding of ωT -regular expressions into S1S + U . Finally, we investigate a stronger variant of ωT -regular languages ( ω T s ωTs -regular languages). We characterize the resulting class of languages in terms of ω T s ωTs -regular expressions, and we show how to map it into a suitable class of automata, called counter-queue automata. We conclude the paper with a comparison of the expressiveness of ωT - and ω T s ωTs -regular languages and of the corresponding automata.},
  archive      = {J_TCS},
  author       = {David Barozzini and David de Frutos-Escrig and Dario Della Monica and Angelo Montanari and Pietro Sala},
  doi          = {10.1016/j.tcs.2019.12.029},
  journal      = {Theoretical Computer Science},
  pages        = {270-304},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Beyond ω-regular languages: ωT-regular expressions and their automata and logic counterparts},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameterized model checking of networks of timed automata
with boolean guards. <em>TCS</em>, <em>813</em>, 248–269. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized model checking is a formal verification technique for verifying that some specifications hold in systems consisting of many similar cooperating but indistinguishable processes. The problem is known to be undecidable in general, even when restricted to reachability properties. To overcome this limitation, several techniques have been explored to address specific system families, logical formulas or topologies of process networks. Some use the notion of cutoff , i.e. if a certain property is verified for systems up to a certain size (the cutoff) then it is verified for systems of any size. Here we analyze the case of networks consisting of an arbitrary number of timed automata that can synchronize by looking at which state the neighbors are currently. We show that cutoffs exist independently from the checked formula, with or without a distinguished process acting as controller. We show how, exploiting the cutoffs, we can obtain upper bounds on complexity of the parameterized model-checking problem. Finally, we show how to use the theoretical results in order to model and verify a distributed algorithm for clock synchronization based on gossip techniques.},
  archive      = {J_TCS},
  author       = {Luca Spalazzi and Francesco Spegni},
  doi          = {10.1016/j.tcs.2019.12.026},
  journal      = {Theoretical Computer Science},
  pages        = {248-269},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameterized model checking of networks of timed automata with boolean guards},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effectful applicative similarity for call-by-name lambda
calculi. <em>TCS</em>, <em>813</em>, 234–247. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a notion of applicative similarity in which not terms but monadic values arising from the evaluation of effectful terms, can be compared. We prove this notion to be fully abstract whenever terms are evaluated in call-by-name order. This is the first full-abstraction result for such a generic, coinductive methodology for program equivalence.},
  archive      = {J_TCS},
  author       = {Ugo Dal Lago and Francesco Gavazzo and Ryo Tanaka},
  doi          = {10.1016/j.tcs.2019.12.025},
  journal      = {Theoretical Computer Science},
  pages        = {234-247},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Effectful applicative similarity for call-by-name lambda calculi},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A class of recursive permutations which is primitive
recursive complete. <em>TCS</em>, <em>813</em>, 218–233. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on total functions in the theory of reversible computational models . We define a class of recursive permutations , dubbed Reversible Primitive Permutations ( RPP RPP ) which are computable invertible total endo-functions on integers, so a subset of total reversible computations. RPP RPP is generated from five basic functions (identity, sign-change, successor, predecessor, swap), two notions of composition (sequential and parallel), one functional iteration and one functional selection. RPP RPP is closed by inversion and it is expressive enough to encode Cantor pairing and the whole class of Primitive Recursive Functions.},
  archive      = {J_TCS},
  author       = {Luca Paolini and Mauro Piccolo and Luca Roversi},
  doi          = {10.1016/j.tcs.2019.11.029},
  journal      = {Theoretical Computer Science},
  pages        = {218-233},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A class of recursive permutations which is primitive recursive complete},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Alternating-time temporal logics with linear past.
<em>TCS</em>, <em>813</em>, 199–217. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the succinctness gap between two known equally-expressive and different linear-past extensions of standard ⁎ ATL ⁎ ATL⁎ . We establish by formal non-trivial arguments that the ‘memoryful’ linear-past extension (the history leading to the current state is taken into account) can be exponentially more succinct than the standard ‘local’ linear-past extension (the history leading to the current state is forgotten). As a second contribution, we consider the ATL -like fragment, denoted ATL l p lp , of the known ‘memoryful’ linear-past extension of ⁎ ATL ⁎ ATL⁎ . We show that ATL l p ATLlp is strictly more expressive than ATL ATL , and interestingly, it can be exponentially more succinct than the more expressive logic ATL ⁎ . Moreover, we prove that both satisfiability and model-checking for the logic ATL l p lp are Exptime -complete.},
  archive      = {J_TCS},
  author       = {Laura Bozzelli and Aniello Murano and Loredana Sorrentino},
  doi          = {10.1016/j.tcs.2019.11.028},
  journal      = {Theoretical Computer Science},
  pages        = {199-217},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Alternating-time temporal logics with linear past},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the initialization of clocks in timed formalisms.
<em>TCS</em>, <em>813</em>, 175–198. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constraint LTL over clocks (CLTLoc) is an extension of LTL allowing for atomic formulae of the form x x&amp;lt;c or x = c x=c , which constrain the time delay measured by clock x with respect to constant value c . In a previous work, we showed that CLTLoc is equivalent to Timed Automata . The result was proven by considering a clock semantics that conforms to the original definition by Alur and Dill, i.e., when clocks are reset (i.e., equal to 0) in the origin, both CLTLoc and Timed Automata define the class of Timed ω -Regular languages. In this paper, we show that if we allow the clocks to have any value in the origin, the power of the formalism to express timed languages does not change, as long as non-Zeno languages are considered. If Zeno languages are allowed, then CLTLoc is strictly more powerful than TA. As a consequence of these results, we also show that non-Zeno Timed ω -Regular languages are closed with respect to the left quotient operation with timed regular languages over finite words.},
  archive      = {J_TCS},
  author       = {Marcello M. Bersani and Matteo Rossi and Pierluigi San Pietro},
  doi          = {10.1016/j.tcs.2019.11.023},
  journal      = {Theoretical Computer Science},
  pages        = {175-198},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the initialization of clocks in timed formalisms},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Adding the power-set to description logics. <em>TCS</em>,
<em>813</em>, 155–174. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the relationships between Description Logics and Set Theory. The study is carried on using, on the set-theoretic side, a very rudimentary axiomatic set theory Ω, consisting of only four axioms characterizing binary union, set difference, inclusion, and the power-set. An extension of ALC ALC , dubbed ALC Ω ALCΩ , is defined in which concepts are naturally interpreted as sets living in Ω-models. In ALC Ω ALCΩ not only membership between concepts is allowed—even admitting membership circularity—but also the power-set construct is exploited to add metamodelling capabilities. We investigate translations of ALC Ω ALCΩ into standard description logics as well as a set-theoretic translation. A polynomial encoding of ALC Ω ALCΩ in ALCOI ALCOI proves the validity of the finite model property as well as an ExpTime upper bound on the complexity of concept satisfiability . We develop a set-theoretic translation of ALC Ω ALCΩ in the theory Ω, exploiting a technique proposed for translating normal modal and polymodal logics into Ω. Finally, we show that the fragment LC Ω LCΩ of ALC Ω ALCΩ not admitting roles and individual names, is as expressive as ALC Ω ALCΩ .},
  archive      = {J_TCS},
  author       = {Laura Giordano and Alberto Policriti},
  doi          = {10.1016/j.tcs.2019.10.049},
  journal      = {Theoretical Computer Science},
  pages        = {155-174},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Adding the power-set to description logics},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The fixed point problem of a simple reversible language.
<em>TCS</em>, <em>813</em>, 143–154. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SRL is a total programming language with distinctive features: (i) every program that mentions n registers defines a bijection Z n → Z n Zn→Zn , and (ii) the generation of the SRL -program that computes the inverse of that bijection can be automatic. Containing SRL a very essential set of commands, it is suitable for studying strengths and weaknesses of reversible computations. We deal with the fixed points of SRL -programs. Given any SRL -program P P , we are interested in the problem of deciding if a tuple of initial register values of P P exists which remains unaltered after its execution. We show that the existence of fixed points in SRL is undecidable and complete in Σ 1 0 Σ10 . We show that such problem remains undecidable even when the number of registers mentioned by P P is limited to 12. Moreover, if we restrict to the linear programs of SRL , i.e. to those programs where different registers control nested loops, then the problem is already undecidable for the class of SRL -programs that mention no more than 3712 registers. Last, we show that, except for trivial cases , finding if the number of fixed points has a given cardinality is also undecidable.},
  archive      = {J_TCS},
  author       = {Armando B. Matos and Luca Paolini and Luca Roversi},
  doi          = {10.1016/j.tcs.2019.10.005},
  journal      = {Theoretical Computer Science},
  pages        = {143-154},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The fixed point problem of a simple reversible language},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial time in untyped elementary linear logic.
<em>TCS</em>, <em>813</em>, 117–142. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to represent polynomial time computation in an untyped version of proof-nets for elementary linear logic . This follows previous work by P. Baillot but which was developed in a typed and affine setting. We describe how these two properties can be adapted.},
  archive      = {J_TCS},
  author       = {Olivier Laurent},
  doi          = {10.1016/j.tcs.2019.10.002},
  journal      = {Theoretical Computer Science},
  pages        = {117-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Polynomial time in untyped elementary linear logic},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On randomised strategies in the λ-calculus. <em>TCS</em>,
<em>813</em>, 100–116. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we study randomised reduction strategies—a notion already known in the context of abstract reduction systems—for the λ -calculus. We develop a simple framework that allows us to prove a randomised strategy to be positive almost-surely normalising. Then we propose a simple example of randomised strategy for the λ -calculus that has such a property and we show why it is non-trivial with respect to classical deterministic strategies such as leftmost-outermost or rightmost-innermost. We conclude studying this strategy for two sub- λ -calculi, namely those where duplication and erasure are syntactically forbidden, showing some non-trivial properties.},
  archive      = {J_TCS},
  author       = {Ugo Dal Lago and Gabriele Vanoni},
  doi          = {10.1016/j.tcs.2019.09.033},
  journal      = {Theoretical Computer Science},
  pages        = {100-116},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On randomised strategies in the λ-calculus},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Combining linear logic and size types for implicit
complexity. <em>TCS</em>, <em>813</em>, 70–99. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several type systems have been proposed to statically control the time complexity of lambda-calculus programs and characterize complexity classes such as FPTIME or FEXPTIME. A first line of research stems from linear logic and restricted versions of its !-modality controlling duplication. An instance of this is light linear logic for polynomial time computation [5] . A second approach relies on the idea of tracking the size increase between input and output, and together with a restricted recursion scheme, to deduce time complexity bounds. This second approach is illustrated for instance by non-size-increasing types [8] . However, both approaches suffer from limitations. The first one, that of linear logic, has a limited intensional expressivity, that is to say some natural polynomial time programs are not typable. As to the second approach it is essentially linear, more precisely it does not allow for a non-linear use of functional arguments. In the present work we incorporate both approaches into a common type system, in order to overcome their respective constraints. The source language we consider is a lambda-calculus with data-types and iteration, that is to say a variant of Gödel&#39;s system T. Our goal is to design a system for this language allowing both to handle non-linear functional arguments and to keep a good intensional expressivity. We illustrate our methodology by choosing the system of elementary linear logic (ELL) and combining it with a system of linear size types. We discuss the expressivity of this new type system, called sEAL, and prove that it gives a characterization of the complexity classes FPTIME and 2k-FEXPTIME, for k ≥ 0 k≥0 .},
  archive      = {J_TCS},
  author       = {Patrick Baillot and Alexis Ghyselen},
  doi          = {10.1016/j.tcs.2019.09.032},
  journal      = {Theoretical Computer Science},
  pages        = {70-99},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Combining linear logic and size types for implicit complexity},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The metric linear-time branching-time spectrum on
nondeterministic probabilistic processes. <em>TCS</em>, <em>813</em>,
20–69. (<a href="https://doi.org/10.1016/j.tcs.2019.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavioral equivalences were introduced as a simple and elegant proof methodology for establishing whether the behavior of two processes cannot be distinguished by an external observer. The knowledge of observers usually depends on the observations that they can make on process behavior. Furthermore, the combination of nondeterminism and probability in concurrent systems leads to several interpretations of process behavior. Clearly, different kinds of observations as well as different interpretations lead to different kinds of behavioral relations, such as (bi)simulations, traces and testing. If we restrict our attention to linear properties only, we can identify three main approaches to trace and testing semantics: the trace distributions , the trace-by-trace and the extremal probabilities approaches. In this paper, we propose novel notions of behavioral metrics that are based on the three classic approaches above, and that can be used to measure the disparities in the linear behavior of processes with respect to trace and testing semantics. We study the properties of these metrics, like compositionality (expressed in terms of the non-expansiveness property), and we compare their expressive powers . More precisely, we compare them also to (bi)simulation metrics, thus obtaining the first metric linear time – branching time spectrum .},
  archive      = {J_TCS},
  author       = {Valentina Castiglioni and Michele Loreti and Simone Tini},
  doi          = {10.1016/j.tcs.2019.09.019},
  journal      = {Theoretical Computer Science},
  pages        = {20-69},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The metric linear-time branching-time spectrum on nondeterministic probabilistic processes},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Type-two polynomial-time and restricted lookahead.
<em>TCS</em>, <em>813</em>, 1–19. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides an alternate characterization of type-two polynomial-time computability, with the goal of making second-order complexity theory more approachable. We rely on the usual oracle machines to model programs with subroutine calls . In contrast to previous results, the use of higher-order objects as running times is avoided, either explicitly or implicitly. Instead, regular polynomials are used. This is achieved by refining the notion of oracle-polynomial-time introduced by Cook. We impose a further restriction on the oracle interactions to force feasibility. Both the restriction as well as its purpose are very simple: it is well-known that Cook&#39;s model allows polynomial depth iteration of functional inputs with no restrictions on size, and thus does not guarantee that polynomial-time computability is preserved. To mend this we restrict the number of lookahead revisions, that is the number of times a query can be asked that is bigger than any of the previous queries. We prove that this leads to a class of feasible functionals and that all feasible problems can be solved within this class if one is allowed to separate a task into efficiently solvable subtasks. Formally put: the closure of our class under lambda-abstraction and application includes all feasible operations. We also revisit the very similar class of strongly polynomial-time computable operators previously introduced by Kawamura and Steinberg. We prove it to be strictly included in our class and, somewhat surprisingly, to have the same closure property. This can be attributed to properties of the limited recursion operator: It is not strongly polynomial-time computable but decomposes into two such operations and lies in our class.},
  archive      = {J_TCS},
  author       = {Bruce M. Kapron and Florian Steinberg},
  doi          = {10.1016/j.tcs.2019.07.003},
  journal      = {Theoretical Computer Science},
  pages        = {1-19},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Type-two polynomial-time and restricted lookahead},
  volume       = {813},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Longest property-preserved common factor: A new
string-processing framework. <em>TCS</em>, <em>812</em>, 244–251. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new family of string processing problems. Given two or more strings, we are asked to compute a factor common to all strings that preserves a specific property and has maximal length. We consider three fundamental string properties: square-free factors, periodic factors, and palindromic factors under three different settings, one per property. In the first setting, we are given a string x and we are asked to construct a data structure over x answering the following type of online queries: given a string y , find a longest square-free factor common to x and y . In the second setting, we are given k strings and an integer 1 1&amp;lt;k′≤k and we are asked to find a longest periodic factor common to at least k ′ k′ strings. In the third one, we are given two strings and we are asked to find a longest palindromic factor common to the two strings. We present linear-time solutions for all settings. This is a full and extended version of a paper from SPIRE 2018.},
  archive      = {J_TCS},
  author       = {Lorraine A.K. Ayad and Giulia Bernardini and Roberto Grossi and Costas S. Iliopoulos and Nadia Pisanti and Solon P. Pissis and Giovanna Rosone},
  doi          = {10.1016/j.tcs.2020.02.012},
  journal      = {Theoretical Computer Science},
  pages        = {244-251},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Longest property-preserved common factor: A new string-processing framework},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The alternating BWT: An algorithmic perspective.
<em>TCS</em>, <em>812</em>, 230–243. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Burrows-Wheeler Transform (BWT) is a word transformation introduced in 1994 for Data Compression . It has become a fundamental tool for designing self-indexing data structures, with important applications in several areas in science and engineering. The Alternating Burrows-Wheeler Transform (ABWT) is another transformation recently introduced in Gessel et al. (2012) [21] and studied in the field of Combinatorics on Words. It is analogous to the BWT, except that it uses an alternating lexicographical order instead of the usual one. Building on results in Giancarlo et al. (2018) [23] , where we have shown that BWT and ABWT are part of a larger class of reversible transformations, here we provide a combinatorial and algorithmic study of the novel transform ABWT. We establish a deep analogy between BWT and ABWT by proving they are the only ones in the above mentioned class to be rank-invertible, a novel notion guaranteeing efficient invertibility . In addition, we show that the backward-search procedure can be efficiently generalized to the ABWT; this result implies that also the ABWT can be used as a basis for efficient compressed full text indices. Finally, we prove that the ABWT can be efficiently computed by using a combination of the Difference Cover suffix sorting algorithm (Kärkkäinen et al., 2006 [28] ) with a linear time algorithm for finding the minimal cyclic rotation of a word with respect to the alternating lexicographical order .},
  archive      = {J_TCS},
  author       = {Raffaele Giancarlo and Giovanni Manzini and Antonio Restivo and Giovanna Rosone and Marinella Sciortino},
  doi          = {10.1016/j.tcs.2019.11.002},
  journal      = {Theoretical Computer Science},
  pages        = {230-243},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The alternating BWT: An algorithmic perspective},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lightweight merging of compressed indices based on BWT
variants. <em>TCS</em>, <em>812</em>, 214–229. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a flexible and lightweight technique for merging compressed indices based on variants of Burrows-Wheeler transform (BWT), thus addressing the need for algorithms that compute compressed indices over large collections using a limited amount of working memory. Merge procedures make it possible to use an incremental strategy for building large indices based on merging indices for progressively larger subcollections. Starting with a known lightweight algorithm for merging BWTs Holt and McMillan (2014) [22] , we show how to modify it in order to merge, or compute from scratch, also the Longest Common Prefix (LCP) array. We then expand our technique for merging compressed tries and circular/permuterm compressed indices, two compressed data structures for which there were hitherto no known merging algorithms.},
  archive      = {J_TCS},
  author       = {Lavinia Egidi and Giovanni Manzini},
  doi          = {10.1016/j.tcs.2019.11.001},
  journal      = {Theoretical Computer Science},
  pages        = {214-229},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lightweight merging of compressed indices based on BWT variants},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accelerated proximal incremental algorithm schemes for
non-strongly convex functions. <em>TCS</em>, <em>812</em>, 203–213. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There have been a number of recent advances in accelerated gradient and proximal schemes for optimization of convex finite sum problems. Defazio introduced a simple accelerated scheme for incremental stochastic proximal algorithms inspired by gradient based methods like SAGA. He was able to prove O ( 1 / k ) O(1/k) convergence for non-smooth function but only under the assumption of strong convexity of component terms. We introduce a slight modification of his scheme, called MP-SAGA for which we can prove O ( 1 / k ) O(1/k) convergence without strong convexity, but for smooth functions. Numerical results show that our method has better or comparable convergence to Defazio&#39;s scheme, even for non-strongly convex functions . As important special cases, we also derive an accelerated schemes for a multi–class formulation of SVM as well as clustering based on the SON regularization . Finally, we introduce a simplification of Point–SAGA, called SP–SAGA for problems such as SON with large number of variables and sparse relation between variables and objective terms.},
  archive      = {J_TCS},
  author       = {Ashkan Panahi and Morteza Haghir Chehreghani and Devdatt Dubhashi},
  doi          = {10.1016/j.tcs.2019.10.030},
  journal      = {Theoretical Computer Science},
  pages        = {203-213},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Accelerated proximal incremental algorithm schemes for non-strongly convex functions},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Linear-time online algorithm for inferring the shortest path
graph from a walk label. <em>TCS</em>, <em>812</em>, 187–202. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of inferring an edge-labeled graph from the sequence of edge labels seen in a walk on that graph. It has been known that this problem is solvable in O ( n log ⁡ n ) O(nlog⁡n) time when the targets are path or cycle graphs. This paper presents an online algorithm for the problem of this restricted case that runs in O ( n ) O(n) time, based on Manacher&#39;s algorithm for computing all the maximal palindromes in a string.},
  archive      = {J_TCS},
  author       = {Shintaro Narisada and Diptarama Hendrian and Ryo Yoshinaka and Ayumi Shinohara},
  doi          = {10.1016/j.tcs.2019.10.029},
  journal      = {Theoretical Computer Science},
  pages        = {187-202},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Linear-time online algorithm for inferring the shortest path graph from a walk label},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Universal reconstruction of a string. <em>TCS</em>,
<em>812</em>, 174–186. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many properties of a string can be viewed as sets of dependencies between substrings of the string expressed in terms of substring equality. We design a linear-time algorithm which finds a solution to an arbitrary system of such constraints: a generic string satisfying a system of substring equations. This provides a general tool for reconstructing a string from different kinds of repetitions or symmetries present in the string, in particular, from runs or from maximal palindromes. The recursive structure of our algorithm in some aspects resembles the suffix array construction by Kärkkäinen et al. (2006) [23] . This is a full version of a paper presented at WADS 2015 [18] .},
  archive      = {J_TCS},
  author       = {Paweł Gawrychowski and Tomasz Kociumaka and Jakub Radoszewski and Wojciech Rytter and Tomasz Waleń},
  doi          = {10.1016/j.tcs.2019.10.027},
  journal      = {Theoretical Computer Science},
  pages        = {174-186},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Universal reconstruction of a string},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient computation of longest single-arm-gapped
palindromes in a string. <em>TCS</em>, <em>812</em>, 160–173. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce new types of approximate palindromes called single-arm-gapped palindromes (shortly SAGPs ). A SAGP contains a gap in either its left or right arm, which is in the form of either w g u c u R w R wgucuRwR or w u c u R g w R wucuRgwR , where w and u are non-empty strings, w R wR and u R uR are respectively the reversed strings of w and u , g is a string called a gap, and c is either a single character or the empty string. Here we call wu and u R w R uRwR the arm of the SAGP, and | u v | |uv| the length of the arm. We classify SAGPs into two groups: those which have u c u R ucuR as a maximal palindrome (type-1), and the others (type-2). We propose several algorithms to compute type-1 SAGPs with longest arms occurring in a given string, based on suffix arrays. Then, we propose a linear-time algorithm to compute all type-1 SAGPs with longest arms, based on suffix trees. Also, we show how to compute type-2 SAGPs with longest arms in linear time. We also perform some preliminary experiments to show practical performances of the proposed methods.},
  archive      = {J_TCS},
  author       = {Shintaro Narisada and Diptarama Hendrian and Kazuyuki Narisawa and Shunsuke Inenaga and Ayumi Shinohara},
  doi          = {10.1016/j.tcs.2019.10.025},
  journal      = {Theoretical Computer Science},
  pages        = {160-173},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient computation of longest single-arm-gapped palindromes in a string},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ranked document selection. <em>TCS</em>, <em>812</em>,
149–159. (<a href="https://doi.org/10.1016/j.tcs.2019.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let D D be a collection of string documents of n characters in total. The top-k document retrieval problem is to preprocess D D into a data structure that, given a query ( P , k ) (P,k) , can return the k documents of D D most relevant to pattern P . The relevance of a document d for a pattern P is given by a predefined ranking function w ( P , d ) w(P,d) . Linear space and optimal query time solutions already exist for this problem. In this paper we consider a novel problem, document selection , in which a query ( P , k ) (P,k) aims to report the k th document most relevant to P (instead of reporting all top- k documents). We present a data structure using O ( n log ϵ ⁡ n ) O(nlogϵ⁡n) space, for any constant ϵ &gt; 0 ϵ&amp;gt;0 , answering selection queries in time O ( log ⁡ k / log ⁡ log ⁡ n ) O(log⁡k/log⁡log⁡n) , and a linear-space data structure answering queries in time O ( log ⁡ k ) O(log⁡k) , given the locus node of P in a (generalized) suffix tree of D D . We also prove that it is unlikely that a succinct-space solution for this problem exists with poly-logarithmic query time, and that O ( log ⁡ k / log ⁡ log ⁡ n ) O(log⁡k/log⁡log⁡n) is indeed optimal within O ( n polylog n ) O(npolylogn) space for most text families. Finally, we present some additional space-time trade-offs exploring the extremes of those lower bounds.},
  archive      = {J_TCS},
  author       = {J. Ian Munro and Gonzalo Navarro and Rahul Shah and Sharma V. Thankachan},
  doi          = {10.1016/j.tcs.2019.10.008},
  journal      = {Theoretical Computer Science},
  pages        = {149-159},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Ranked document selection},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast string matching for DNA sequences. <em>TCS</em>,
<em>812</em>, 137–148. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose the Maximal Average Shift (MAS) algorithm that finds a pattern scan order that maximizes the average shift length. We also present two extensions of MAS: one improves the scan speed of MAS by using the scan result of the previous window, and the other improves the running time of MAS by using q -grams. These algorithms show better average performances in scan speed than previous string matching algorithms for DNA sequences.},
  archive      = {J_TCS},
  author       = {Cheol Ryu and Thierry Lecroq and Kunsoo Park},
  doi          = {10.1016/j.tcs.2019.09.031},
  journal      = {Theoretical Computer Science},
  pages        = {137-148},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fast string matching for DNA sequences},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parallel computation of the burrows wheeler transform in
compact space. <em>TCS</em>, <em>812</em>, 123–136. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Burrows-Wheeler Transform (BWT) has become since its introduction a key tool for representing large text collections in compressed space while supporting indexed searching: on a text of length n over an alphabet of size σ , it requires O ( n lg ⁡ σ ) O(nlg⁡σ) bits of space, instead of the O ( n lg ⁡ n ) O(nlg⁡n) bits required by classical indexes. A challenge for its adoption is to build it within O ( n lg ⁡ σ ) O(nlg⁡σ) bits as well. There are some sequential algorithms building it within this space, but no such a parallel algorithm . In this paper we present a PRAM CREW algorithm to build the BWT using O ( n lg ⁡ n ) O(nlg⁡n) work, O ( lg 3 ⁡ n / lg ⁡ σ ) O(lg3⁡n/lg⁡σ) depth, and O ( n lg ⁡ σ ) O(nlg⁡σ) bits.},
  archive      = {J_TCS},
  author       = {José Fuentes-Sepúlveda and Gonzalo Navarro and Yakov Nekrich},
  doi          = {10.1016/j.tcs.2019.09.030},
  journal      = {Theoretical Computer Science},
  pages        = {123-136},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parallel computation of the burrows wheeler transform in compact space},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate pattern matching on elastic-degenerate text.
<em>TCS</em>, <em>812</em>, 109–122. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An elastic-degenerate string is a sequence of n sets of strings of total length N . It has been introduced to represent a multiple alignment of several closely-related sequences ( e.g., pan-genome) compactly. In this representation, substrings of these sequences that match exactly are collapsed, while in positions where the sequences differ, all possible variants observed at that location are listed. The natural problem that arises is finding all matches of a deterministic pattern of length m in an elastic-degenerate text. There exists a non-combinatorial O ( n m 1.381 + N ) O(nm1.381+N) -time algorithm to solve this problem on-line [1] . In this paper, we study the same problem under the edit distance model and present an O ( k 2 m G + k N ) O(k2mG+kN) -time and O ( m ) O(m) -space algorithm, where G is the total number of strings in the elastic-degenerate text and k is the maximum edit distance allowed. We also present a simple O ( k m G + k N ) O(kmG+kN) -time and O ( m ) O(m) -space algorithm for solving the problem under Hamming distance .},
  archive      = {J_TCS},
  author       = {Giulia Bernardini and Nadia Pisanti and Solon P. Pissis and Giovanna Rosone},
  doi          = {10.1016/j.tcs.2019.08.012},
  journal      = {Theoretical Computer Science},
  pages        = {109-122},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximate pattern matching on elastic-degenerate text},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Refining the r-index. <em>TCS</em>, <em>812</em>, 96–108.
(<a href="https://doi.org/10.1016/j.tcs.2019.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gagie, Navarro and Prezza&#39;s r -index (SODA, 2018) promises to speed up DNA alignment and variation calling by allowing us to index entire genomic databases, provided certain obstacles can be overcome. In this paper we first strengthen and simplify Policriti and Prezza&#39;s Toehold Lemma (DCC &#39;16; Algorithmica , 2017), which inspired the r -index and plays an important role in its implementation. We then show how to update the r -index efficiently after adding a new genome to the database, which is likely to be vital in practice. As a by-product of this result, we obtain an online version of Policriti and Prezza&#39;s algorithm for constructing the LZ77 parse from a run-length compressed Burrows-Wheeler Transform. Our experiments demonstrate the practicality of all three of these results. Finally, we show how to augment the r -index such that, given a new genome and fast random access to the database, we can quickly compute the matching statistics and maximal exact matches of the new genome with respect to the database.},
  archive      = {J_TCS},
  author       = {Hideo Bannai and Travis Gagie and Tomohiro I},
  doi          = {10.1016/j.tcs.2019.08.005},
  journal      = {Theoretical Computer Science},
  pages        = {96-108},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Refining the r-index},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The combinatorics of hidden diversity. <em>TCS</em>,
<em>812</em>, 80–95. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the following “balls in buckets” problem. Suppose there is a sequence B 1 , B 2 , … , B n B1,B2,…,Bn of buckets having integer sizes s 1 , s 2 , … , s n s1,s2,…,sn , respectively. For a given target fraction α , 0 0&amp;lt;α&amp;lt;1 , our goal is to sequentially place balls in buckets until at least ⌈ α n ⌉ ⌈αn⌉ buckets are full, so as to minimize the number of balls used, which we shall denote by O P T α ( I ) OPTα(I) for a given instance I . If we knew the size of each bucket, we could obtain an optimal assignment , simply by filling the buckets in order of increasing size until the desired number had been filled. Here we consider the case where, although we know n and α , we do not know the specific bucket sizes s i si , and when we place a ball in bucket B j Bj , we only learn whether or not the bucket B j Bj is now full. We study what can be done under four variants of incomplete information: The game above showcases the rich variety of interesting combinatorial and algorithmic questions that this setup gives rise to, and in addition has applications in an area of cryptography known as secure multi-party computation , where taking over (“corrupting”) a party by an adversary has a cost, and where a hidden diversity —corresponding to lack of information on the amount of computational resources the adversary should invest to corrupt a participant—translates into robustness and efficiency benefits.},
  archive      = {J_TCS},
  author       = {Juan Garay and David Johnson and Aggelos Kiayias and Moti Yung},
  doi          = {10.1016/j.tcs.2019.07.016},
  journal      = {Theoretical Computer Science},
  pages        = {80-95},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The combinatorics of hidden diversity},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast and frugal targeting with incentives. <em>TCS</em>,
<em>812</em>, 62–79. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A widely studied model of influence diffusion in social networks represents the network as a graph G = ( V , E ) G=(V,E) , with an integer influence threshold t ( v ) t(v) for each node, and the diffusion process as follows: Initially the members of a chosen set S ⊆ V S⊆V are influenced and, during each subsequent round, the set of influenced nodes is augmented by including every new node v that has at least t ( v ) t(v) previously influenced neighbours. The general problem is to find a small initial set that influences the whole network. In this paper we extend this model by using incentives to reduce the thresholds of some nodes. The goal is to minimize the total amount of the incentive required to ensure that the information diffusion process terminates within a given number of rounds λ . The problem is hard to approximate in general networks. We present optimal polynomial-time algorithms for paths, cycles, trees, and complete networks for any λ . For the special case λ = 1 λ=1 , we present a polynomial-time algorithm with a logarithmic approximation guarantee for any network.},
  archive      = {J_TCS},
  author       = {Gennaro Cordasco and Luisa Gargano and Joseph G. Peters and Adele A. Rescigno and Ugo Vaccaro},
  doi          = {10.1016/j.tcs.2019.07.007},
  journal      = {Theoretical Computer Science},
  pages        = {62-79},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fast and frugal targeting with incentives},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-dimensional maximal repetitions. <em>TCS</em>,
<em>812</em>, 49–61. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximal repetitions or runs in strings have a wide array of applications and thus have been extensively studied. In this paper, we extend this notion to 2-dimensions, precisely defining a maximal 2D repetition . We provide initial bounds on the number of maximal 2D repetitions that can occur in an n × n n×n array. The main contribution of this paper is the presentation of the first algorithm for locating all maximal 2D repetitions. The algorithm is efficient and straightforward, with runtime O ( n 2 log ⁡ n + ρ ) O(n2log⁡n+ρ) , where n 2 n2 is the size of the input array and ρ is the number of maximal 2D repetitions in the output.},
  archive      = {J_TCS},
  author       = {Amihood Amir and Gad M. Landau and Shoshana Marcus and Dina Sokol},
  doi          = {10.1016/j.tcs.2019.07.006},
  journal      = {Theoretical Computer Science},
  pages        = {49-61},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Two-dimensional maximal repetitions},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compressed range minimum queries. <em>TCS</em>,
<em>812</em>, 39–48. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a string S of n integers in [ 0 , σ ) [0,σ) , a range minimum query RMQ ( i , j ) RMQ(i,j) asks for the index of the smallest integer in S [ i … j ] S[i…j] . It is well known that the problem can be solved with a succinct data structure of size 2 n + o ( n ) 2n+o(n) and constant query-time. In this paper we show how to preprocess S into a compressed representation that allows fast range minimum queries. This allows for sublinear size data structures with logarithmic query time. The most natural approach is to use string compression and construct a data structure for answering range minimum queries directly on the compressed string. We investigate this approach in the context of grammar compression. We then consider an alternative approach. Instead of compressing S using string compression, we compress the Cartesian tree of S using tree compression. We show that this approach can be exponentially better than the former, is never worse by more than an O ( σ ) O(σ) factor (i.e. for constant alphabets it is never asymptotically worse), and can in fact be worse by an Ω ( σ ) Ω(σ) factor.},
  archive      = {J_TCS},
  author       = {Paweł Gawrychowski and Seungbum Jo and Shay Mozes and Oren Weimann},
  doi          = {10.1016/j.tcs.2019.07.002},
  journal      = {Theoretical Computer Science},
  pages        = {39-48},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Compressed range minimum queries},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simultaneous consecutive ones submatrix and editing
problems: Classical complexity and fixed-parameter tractable results.
<em>TCS</em>, <em>812</em>, 13–38. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A binary matrix M has the consecutive ones property (C1P) for rows (resp. columns) if there exists a permutation of its columns (resp. rows) that arranges the ones consecutively in all the rows (resp. columns). If M has the C1P for rows and the C1P for columns, then M is said to have the simultaneous consecutive ones property (SC1P). In this article, we consider the classical complexity and fixed-parameter tractability of a few variants of decision problems related to the SC1P. Given a binary matrix M and a positive integer d , we focus on problems that decide whether there exists a set of rows, columns, and rows as well as columns, respectively, of size at most d in M , whose deletion results in a matrix with the SC1P. We also consider problems that decide whether there exists a set of 0-entries, 1-entries and 0-entries as well as 1-entries, respectively, of size at most d in M , whose flipping results in a matrix with the SC1P. In this paper, we show that all the above mentioned problems are NP-complete. We could also prove that all these problems are fixed-parameter tractable with respect to solution size as the parameter, except for two variants (flipping 1-entries and flipping 0/1-entries). We also give improved FPT algorithms for certain problems on restricted binary matrices.},
  archive      = {J_TCS},
  author       = {Rani M. R and Subashini R and Mohith Jagalmohanan},
  doi          = {10.1016/j.tcs.2019.05.043},
  journal      = {Theoretical Computer Science},
  pages        = {13-38},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Simultaneous consecutive ones submatrix and editing problems: Classical complexity and fixed-parameter tractable results},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Faster algorithms for 1-mappability of a sequence.
<em>TCS</em>, <em>812</em>, 2–12. (<a
href="https://doi.org/10.1016/j.tcs.2019.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the k -mappability problem, we are given a string x of length n and integers m and k , and we are asked to count, for each length- m factor y of x , the number of other factors of length m of x that are at Hamming distance at most k from y . We focus here on the version of the problem where k = 1 k=1 . There exists an algorithm to solve this problem for k = 1 k=1 requiring time O ( m n log ⁡ n / log ⁡ log ⁡ n ) O(mnlog⁡n/log⁡log⁡n) using space O ( n ) O(n) . Here we present two new algorithms that require worst-case time O ( m n ) O(mn) and O ( n log ⁡ n log ⁡ log ⁡ n ) O(nlog⁡nlog⁡log⁡n) , respectively, and space O ( n ) O(n) , thus greatly improving the previous result. Moreover, we present another algorithm that requires average-case time and space O ( n ) O(n) for integer alphabets of size σ if m = Ω ( log σ ⁡ n ) m=Ω(logσ⁡n) . Notably, we show that this algorithm is generalizable for arbitrary k , requiring average-case time O ( k n ) O(kn) and space O ( n ) O(n) if m = Ω ( k log σ ⁡ n ) m=Ω(klogσ⁡n) , assuming that the letters are independent and uniformly distributed random variables. Finally, we provide an experimental evaluation of our average-case algorithm demonstrating its competitiveness to the state-of-the-art implementation.},
  archive      = {J_TCS},
  author       = {Mai Alzamel and Panagiotis Charalampopoulos and Costas S. Iliopoulos and Solon P. Pissis and Jakub Radoszewski and Wing-Kin Sung},
  doi          = {10.1016/j.tcs.2019.04.026},
  journal      = {Theoretical Computer Science},
  pages        = {2-12},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Faster algorithms for 1-mappability of a sequence},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>812</em>, 1. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Gabriele Fici and Giuseppe F. Italiano},
  doi          = {10.1016/j.tcs.2020.02.019},
  journal      = {Theoretical Computer Science},
  pages        = {1},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {812},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate proof-labeling schemes. <em>TCS</em>,
<em>811</em>, 112–124. (<a
href="https://doi.org/10.1016/j.tcs.2018.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new model of verification of boolean predicates over distributed networks. Given a network configuration , the proof-labeling scheme (PLS) model defines a distributed proof in the form of a label that is given to each node, and all nodes locally verify that the network configuration satisfies the desired boolean predicate by exchanging labels with their neighbors. The proof size of the scheme is defined to be the maximum size of a label. In this work, we extend this model by defining the approximate proof-labeling scheme (APLS) model. In this new model, the predicates for verification are of the form ψ ≤ φ ψ≤φ , where ψ , φ : F → N ψ,φ:F→N for a family of configurations F F . Informally, the predicates considered in this model are a comparison between two values of the configuration. As in the PLS model, nodes exchange labels in order to locally verify the predicate, and all must accept if the network satisfies the predicate. The soundness condition is relaxed with an approximation ration α , so that only if ψ &gt; α φ ψ&amp;gt;αφ some node must reject. We focus on two verification problems: upper and lower bounds on the diameter of the graph, and the maximality of a given matching. For these problems, we present the first results that apply to all graph structures. In our new APLS model, we show that the proof size can be much smaller than the proof size of the same predicate in the PLS model. Moreover, we prove that there is a tradeoff between the approximation ratio and the proof size. Finally, we present the first general result for maximum cardinality matching in the PLS model.},
  archive      = {J_TCS},
  author       = {Keren Censor-Hillel and Ami Paz and Mor Perry},
  doi          = {10.1016/j.tcs.2018.08.020},
  journal      = {Theoretical Computer Science},
  pages        = {112-124},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximate proof-labeling schemes},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to choose friends strategically. <em>TCS</em>,
<em>811</em>, 99–111. (<a
href="https://doi.org/10.1016/j.tcs.2018.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alice wants to join a new social network, and influence its members to adopt a new product or idea. Each person v in the network has a certain threshold t ( v ) t(v) for activation , i.e. adoption of the product or idea. If v has at least t ( v ) t(v) activated neighbors, then v will also become activated. If Alice wants to make k new friends in the network, and thereby activate the most number of people, how should she choose these friends? We study the problem of choosing the k people in the network to befriend, who will in turn activate the maximum number of people. This Maximum Influence with Links Problem has applications in viral marketing and the study of epidemics. We show that the solution can be quite different from the related and widely studied influence maximization problem where the objective is to choose a seed or target set with maximum influence. We prove that the Maximum Influence with Links problem is NP-complete even for bipartite graphs in which all nodes have threshold 1 or 2. In contrast, we give polynomial time algorithms that find optimal solutions for the problem for trees, paths, cycles, and cliques .},
  archive      = {J_TCS},
  author       = {Lata Narayanan and Kangkang Wu},
  doi          = {10.1016/j.tcs.2018.07.013},
  journal      = {Theoretical Computer Science},
  pages        = {99-111},
  shortjournal = {Theor. Comput. Sci.},
  title        = {How to choose friends strategically},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Gathering in dynamic rings. <em>TCS</em>, <em>811</em>,
79–98. (<a href="https://doi.org/10.1016/j.tcs.2018.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The gathering (or multi-agent rendezvous ) problem requires a set of mobile agents , arbitrarily positioned at different nodes of a network to group within finite time at the same location, not fixed in advanced. The extensive existing literature on this problem shares the same fundamental assumption: the topological structure does not change during the rendezvous or the gathering; this is true also for those investigations that consider faulty nodes. In other words, they only consider static graphs . In this paper we start the investigation of gathering in dynamic graphs , that is networks where the topology changes continuously and at unpredictable locations. We study the feasibility of gathering mobile agents , identical and without explicit communication capabilities, in a dynamic ring of anonymous nodes; the class of dynamics we consider is the classic 1-interval-connectivity ; i.e., dynamic graphs that are however connected at any point in time. We focus on the impact that factors such as chirality (i.e., a common sense of orientation) and cross detection (i.e., the ability to detect, when traversing an edge, whether some agent is traversing it in the other direction), have on the solvability of the problem; and we establish several results. We provide a complete characterization of the classes of initial configurations from which the gathering problem is solvable in presence and in absence of cross detection and of chirality. The feasibility results of the characterization are all constructive: we provide distributed algorithms that allow the agents to gather within low polynomial time . In particular, the algorithms for gathering with cross detection are time optimal. We also show that cross detection is a powerful computational element. Indeed, we prove that, without chirality, knowledge of the ring size n is strictly more powerful than knowledge of the number k of agents; on the other hand, with chirality, knowledge of n can be substituted by knowledge of k , yielding the same classes of feasible initial configurations . From our investigation it follows that, for the gathering problem, the computational obstacles created by the dynamic nature of the ring can be overcome by the presence of chirality or of cross-detection.},
  archive      = {J_TCS},
  author       = {Giuseppe Antonio Di Luna and Paola Flocchini and Linda Pagli and Giuseppe Prencipe and Nicola Santoro and Giovanni Viglietta},
  doi          = {10.1016/j.tcs.2018.10.018},
  journal      = {Theoretical Computer Science},
  pages        = {79-98},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Gathering in dynamic rings},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A general lower bound for collaborative tree exploration.
<em>TCS</em>, <em>811</em>, 70–78. (<a
href="https://doi.org/10.1016/j.tcs.2018.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider collaborative graph exploration with a set of k agents. All agents start at a common vertex of an initially unknown graph with n vertices and need to collectively visit all other vertices. We assume agents are deterministic, moves are simultaneous, and we allow agents to communicate globally. For this setting, we give the first non-trivial lower bounds that bridge the gap between small ( k ≤ n k≤n ) and large ( k ≥ n k≥n ) teams of agents. Remarkably, our bounds tightly connect to existing results in both domains. First, we significantly extend a lower bound of Ω ( log ⁡ k / log ⁡ log ⁡ k ) Ω(log⁡k/log⁡log⁡k) by Dynia et al. on the competitive ratio of a collaborative tree exploration strategy to the range k ≤ n log c ⁡ n k≤nlogc⁡n for any c ∈ N c∈N . Second, we provide a tight lower bound on the number of agents needed for any competitive exploration algorithm. In particular, we show that any collaborative tree exploration algorithm with k = D n 1 + o ( 1 ) k=Dn1+o(1) agents has a competitive ratio of ω ( 1 ) ω(1) , while Dereniowski et al. gave an algorithm with k = D n 1 + ε k=Dn1+ε agents and competitive ratio O ( 1 ) O(1) , for any ε &gt; 0 ε&amp;gt;0 and with D denoting the diameter of the graph. Lastly, we show that, for any exploration algorithm using k = n k=n agents, there exist trees of arbitrarily large height D that require Ω ( D 2 ) Ω(D2) rounds, and we provide a simple algorithm that matches this bound for all trees.},
  archive      = {J_TCS},
  author       = {Yann Disser and Frank Mousset and Andreas Noever and Nemanja Škorić and Angelika Steger},
  doi          = {10.1016/j.tcs.2018.03.006},
  journal      = {Theoretical Computer Science},
  pages        = {70-78},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A general lower bound for collaborative tree exploration},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Wireless evacuation on m rays with k searchers.
<em>TCS</em>, <em>811</em>, 56–69. (<a
href="https://doi.org/10.1016/j.tcs.2018.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the online problem of evacuating k robots on m concurrent rays to a single unknown exit. All k robots start on the same point s , not necessarily on the junction j of the m rays, move at unit speed, and can communicate wirelessly. The goal is to minimize the competitive ratio , i.e., the ratio between the time it takes to evacuate all robots to the exit and the time it would take if the location of the exit was known in advance, in the worst-case instance. When k = m k=m , we show that a simple waiting strategy yields a competitive ratio of 4 and present a lower bound of 2 + 7 / 3 ≈ 3.52753 2+7/3≈3.52753 for all k = m ≥ 3 k=m≥3 . For k = 3 k=3 robots on m = 3 m=3 rays, we give a class of parametrized algorithms with a nearly matching competitive ratio of 2 + 3 ≈ 3.73205 2+3≈3.73205 . We also present an algorithm for 1 1&amp;lt;k&amp;lt;m , achieving a competitive ratio of 1 + 2 ⋅ m − 1 k ⋅ ( 1 + k m − 1 ) 1 + m − 1 k 1+2⋅m−1k⋅(1+km−1)1+m−1k , obtained by parameter optimization on a geometric search strategy. Interestingly, the robots can be initially oblivious to the value of m &gt; 2 m&amp;gt;2 . Lastly, by using a simple but fundamental argument, we show that for k k&amp;lt;m robots, no algorithm can reach a competitive ratio better than 3 + 2 ⌊ ( m − 1 ) / k ⌋ 3+2⌊(m−1)/k⌋ , for every k , m k,m with k k&amp;lt;m .},
  archive      = {J_TCS},
  author       = {Sebastian Brandt and Klaus-Tycho Foerster and Benjamin Richner and Roger Wattenhofer},
  doi          = {10.1016/j.tcs.2018.10.032},
  journal      = {Theoretical Computer Science},
  pages        = {56-69},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Wireless evacuation on m rays with k searchers},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How long it takes for an ordinary node with an ordinary id
to output? <em>TCS</em>, <em>811</em>, 42–55. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of distributed synchronous computing, processors perform in rounds, and the time complexity of a distributed algorithm is classically defined as the number of rounds before all computing nodes have output. Hence, this complexity measure captures the running time of the slowest node(s). In this paper, we are interested in the running time of the ordinary nodes, to be compared with the running time of the slowest nodes. The node-averaged time complexity of a distributed algorithm on a given instance is defined as the average, taken over every node of the instance, of the number of rounds before that node outputs. We compare the node-averaged time complexity with the classic one in the standard LOCAL LOCAL model for distributed network computing. We show that there can be an exponential gap between the former and the later, as witnessed by, e.g., leader election. Our first main result is a positive one, stating that, in fact, the two time complexities behave the same for a large class of problems on very sparse graphs . In particular, we show that, for the classic class of problems named LCL LCL , restricted to cycles, the node-averaged time complexity is of the same order of magnitude as the “slowest node” time complexity. In addition, in the LOCAL LOCAL model, the time complexity is computed as a worst case over all possible identity assignments to the nodes of the network. In this paper, we also investigate the ID-averaged time complexity, when the number of rounds is averaged over all possible identity assignments of O ( log ⁡ n ) O(log⁡n) -size identifiers, where n is the size of the network. Our second main result is that the ID-averaged time complexity is essentially the same as the expected time complexity of randomized algorithms (where the expectation is taken over all possible random bits used by the nodes, and the number of rounds is measured for the worst-case identity assignment). Finally, we study the node-averaged ID-averaged time complexity. We show that 3-colouring the n -node ring requires ⁎ Θ ( log ⁎ ⁡ n ) Θ(log⁎⁡n) rounds if the number of rounds is averaged over the nodes, or if the number of rounds is averaged over the identity assignments. In contrast, we show that 3-colouring the ring requires only O ( 1 ) O(1) rounds if the number of rounds is averaged over both the nodes and the identity assignments.},
  archive      = {J_TCS},
  author       = {Laurent Feuilloley},
  doi          = {10.1016/j.tcs.2019.01.023},
  journal      = {Theoretical Computer Science},
  pages        = {42-55},
  shortjournal = {Theor. Comput. Sci.},
  title        = {How long it takes for an ordinary node with an ordinary id to output?},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved distributed algorithms for coloring interval graphs
with application to multicoloring trees. <em>TCS</em>, <em>811</em>,
29–41. (<a href="https://doi.org/10.1016/j.tcs.2018.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a distributed ( 1 + ϵ ) (1+ϵ) -approximation algorithm for the minimum vertex coloring problem on interval graphs , which runs in the LOCAL LOCAL model and operates in ⁎ O ( 1 ϵ log ⁎ ⁡ n ) O(1ϵlog⁎⁡n) rounds. If nodes are aware of their interval representations, then the algorithm can be adapted to the CONGEST CONGEST model using the same number of rounds. Prior to this work, only constant factor approximations using ⁎ O ( log ⁎ ⁡ n ) O(log⁎⁡n) rounds were known [1] . Linial&#39;s ring coloring lower bound implies that the dependency on ⁎ log ⁎ ⁡ n log⁎⁡n cannot be improved. We further prove that the dependency on 1 ϵ 1ϵ is also optimal. To obtain our CONGEST CONGEST model algorithm, we develop a color rotation technique that may be of independent interest. We demonstrate that color rotations can also be applied to obtain a ( 1 + ϵ ) (1+ϵ) -approximate multicoloring of directed trees in ⁎ O ( 1 ϵ log ⁎ ⁡ n ) O(1ϵlog⁎⁡n) rounds.},
  archive      = {J_TCS},
  author       = {Magnús M. Halldórsson and Christian Konrad},
  doi          = {10.1016/j.tcs.2018.11.028},
  journal      = {Theoretical Computer Science},
  pages        = {29-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved distributed algorithms for coloring interval graphs with application to multicoloring trees},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Leader election in SINR model with arbitrary power control.
<em>TCS</em>, <em>811</em>, 21–28. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Leader Election Problem in the Signal-to-Interference-plus-Noise-Ratio (SINR) model where nodes can adjust their transmission power. We show that in this setting it is possible to elect a leader in two communication rounds, with high probability . Previously, it was known that Θ ( log ⁡ n ) Θ(log⁡n) rounds were sufficient and necessary when using uniform power, where n is the number of nodes in the network. We then examine how much power control is needed to achieve fast leader election. We show that every 2-round leader election algorithm in the SINR model running correctly w.h.p. requires a power range 2 Ω ( n ) 2Ω(n) , even when n is known. We complement this with an algorithm that uses power range 2 O ˜ ( n ) 2O˜(n) 1 , when n is known, and 2 O ˜ ( n 1.5 ) 2O˜(n1.5) , when n is not known. We also explore tradeoffs between time and power used, and show that to elect a leader in t rounds, a range of possible power levels of size e x p ( n 1 / Θ ( t ) ) exp(n1/Θ(t)) is sufficient and necessary.},
  archive      = {J_TCS},
  author       = {Magnús M. Halldórsson and Stephan Holzer and Evangelia Anna Markatou and Nancy Lynch},
  doi          = {10.1016/j.tcs.2019.01.024},
  journal      = {Theoretical Computer Science},
  pages        = {21-28},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Leader election in SINR model with arbitrary power control},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Token traversal in ad hoc wireless networks via implicit
carrier sensing. <em>TCS</em>, <em>811</em>, 3–20. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication problems in ad hoc wireless networks have been already widely studied under the SINR model, but a vast majority of results concern networks with constraints on connectivity, so called strongly-connected networks . In such networks, connectivity is defined based on highly reliable links, that is, where both ends are located far closer from their transmission boundaries. What happens if the network is not strongly-connected, e.g., it contains some long but still viable “shortcut links” connecting transmission boundaries? It is known that even a single broadcast in such ad hoc weakly-connected networks with uniform transmission powers requires Ω ( n ) Ω(n) communication rounds, where n is the number of nodes in the network. The best up-to-date (randomized) distributed algorithm, designed by Daum et al. [1] , accomplishes broadcast task in O ( n log 2 ⁡ n ) O(nlog2⁡n) communication rounds with high probability . In this work, inspired by the work on broadcasting, we show a novel deterministic distributed implementation of token traversal — a fundamental tool in distributed systems — in the SINR model with uniform transmission powers and no restriction on connectivity. We show that it is efficient even in a very harsh model of weakly-connected networks without GPS, carrier sensing and other helping features. We apply this method to span a traversal tree and accomplish broadcast in O ( n log ⁡ N ) O(nlog⁡N) communication rounds, deterministically, provided nodes are equipped with unique IDs in the range [ 1 , N ] [1,N] for some integer N ≥ n N≥n . This result implies an O ( n log ⁡ n ) O(nlog⁡n) -round randomized solution that does not require IDs, which improves the result from [1] . The lower bound Ω ( n log ⁡ N ) Ω(nlog⁡N) for deterministic algorithms proved in our work shows that our result is tight without randomization. Our implementation of token traversal routine, efficient in terms of time and memory, is based on a novel implicit algorithmic carrier sensing method and a new type of selectors, which might be of independent interest and applicable to other communication tasks in distributed ad hoc setting.},
  archive      = {J_TCS},
  author       = {Tomasz Jurdzinski and Dariusz R. Kowalski and Michal Rozanski and Grzegorz Stachowiak},
  doi          = {10.1016/j.tcs.2019.09.016},
  journal      = {Theoretical Computer Science},
  pages        = {3-20},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Token traversal in ad hoc wireless networks via implicit carrier sensing},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on structural information and communication
complexity. <em>TCS</em>, <em>811</em>, 1–2. (<a
href="https://doi.org/10.1016/j.tcs.2020.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Shantanu Das ( Guest Editor ) and Sebastien Tixeuil ( Guest Editor )},
  doi          = {10.1016/j.tcs.2020.02.003},
  journal      = {Theoretical Computer Science},
  pages        = {1-2},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Special issue on structural information and communication complexity},
  volume       = {811},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Message lower bounds via efficient network synchronization.
<em>TCS</em>, <em>810</em>, 82–95. (<a
href="https://doi.org/10.1016/j.tcs.2018.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a uniform approach to derive message-time tradeoffs and message lower bounds for synchronous distributed computations using results from communication complexity theory. Since the models used in the classical theory of communication complexity are inherently asynchronous, lower bounds do not directly apply in a synchronous setting. To address this issue, we show a general result called Synchronous Simulation Theorem (SST) which allows to obtain message lower bounds for synchronous distributed computations by leveraging lower bounds on communication complexity. The SST is a by-product of a new efficient synchronizer for complete networks, called σ , which has simulation overheads that are only logarithmic in the number of synchronous rounds with respect to both time and message complexity, even in networks with limited bandwidth. Synchronizer σ is particularly efficient in simulating synchronous algorithms which employ silence , a situation that occurs when in some round no processor sends any message. In particular, a curious property of this synchronizer , which sets it apart from its predecessors, is that it is time-compressing , and hence in some cases it may result in a simulation that is faster than the original execution. While the SST gives near-optimal message lower bounds up to large values of the number of allowed synchronous rounds r (usually polynomial in the size of the input), it fails to provide meaningful bounds when the synchronous algorithm to be simulated may comprise a very large number of rounds. To complement the bounds provided by the SST, we then derive message lower bounds for the synchronous message-passing model that are unconditional , that is, independent of r , by establishing novel lower bounds for multi-party synchronous communication complexity. We apply our approach to show (almost) tight message-time tradeoffs and message lower bounds for several fundamental problems in the synchronous message-passing model of distributed computation. These include sorting, matrix multiplication, and several graph problems. All these lower bounds hold for any distributed algorithms, including randomized Monte Carlo algorithms .},
  archive      = {J_TCS},
  author       = {Gopal Pandurangan and David Peleg and Michele Scquizzato},
  doi          = {10.1016/j.tcs.2018.11.017},
  journal      = {Theoretical Computer Science},
  pages        = {82-95},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Message lower bounds via efficient network synchronization},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Public vs. Private randomness in simultaneous multi-party
communication complexity. <em>TCS</em>, <em>810</em>, 72–81. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In simultaneous number-in-hand multi-party communication protocols, we have k players, who each receive a private input, and wish to compute a joint function of their inputs. The players simultaneously each send a single message to a referee, who then outputs the value of the function. The cost of the protocol is the total number of bits sent to the referee. For two players, it is known that giving the players a public (shared) random string is much more useful than private randomness: public-coin protocols can be unboundedly better than deterministic protocols, while private-coin protocols can only give a quadratic improvement on deterministic protocols. We extend the two-player gap to multiple players, and show that the private-coin communication complexity of a k -player function f is at least Ω ( D ( f ) ) Ω(D(f)) for any k ≥ 2 k≥2 . Perhaps surprisingly, this bound is tight: although one might expect the gap between private-coin and deterministic protocols to grow with the number of players, we show that the All-Equality function, where each player receives n bits of input and the players must determine if their inputs are all the same, can be solved by a private-coin protocol with O ˜ ( n k + k ) O˜(nk+k) bits. Since All-Equality has deterministic complexity Θ ( n k ) Θ(nk) , this shows that sometimes the gap scales only as the square root of the number of players, and consequently the number of bits each player needs to send actually decreases as the number of players increases. We also consider the Exists-Equality function, where we ask whether there is a pair of players that received the same input, and prove a nearly-tight bound of Θ ˜ ( k n ) Θ˜(kn) for it.},
  archive      = {J_TCS},
  author       = {Orr Fischer and Rotem Oshman and Uri Zwick},
  doi          = {10.1016/j.tcs.2018.04.032},
  journal      = {Theoretical Computer Science},
  pages        = {72-81},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Public vs. private randomness in simultaneous multi-party communication complexity},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic networks of finite state machines. <em>TCS</em>,
<em>810</em>, 58–71. (<a
href="https://doi.org/10.1016/j.tcs.2017.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like distributed systems, biological multicellular processes are subject to dynamic changes and a biological system will not pass the survival-of-the-fittest test unless it exhibits certain features that enable fast recovery from these changes. In most cases, the types of dynamic changes a biological process may experience and its desired recovery features differ from those traditionally studied in the distributed computing literature. In particular, a question seldomly asked in the context of distributed digital systems, and that is crucial in the context of biological cellular networks , is whether the system can keep the changing components confined so that only nodes in their vicinity may be affected by the changes, but nodes sufficiently far away from any changing component remain unaffected. Based on this notion of confinement, we propose a new metric for measuring the dynamic changes recovery performance in distributed network algorithms operating under the Stone Age model (Emek and Wattenhofer, 2013) [1] , where the class of dynamic topology changes we consider includes inserting/deleting an edge, deleting a node together with its incident edges, and inserting a new isolated node. Our main technical contribution is a distributed algorithm for maximal independent set (MIS) in synchronous networks subject to these topology changes that performs well in terms of the aforementioned new metric. Specifically, our algorithm guarantees that nodes which do not experience a topology change in their immediate vicinity are not affected and that all surviving nodes (including the affected ones) perform O ( ( C + 1 ) log 2 ⁡ n ) O((C+1)log2⁡n) computationally-meaningful steps, where C is the number of topology changes; in other words, each surviving node performs O ( log 2 ⁡ n ) O(log2⁡n) steps when amortized over the number of topology changes. This is accompanied by a simple example demonstrating that the linear dependency on C cannot be avoided.},
  archive      = {J_TCS},
  author       = {Yuval Emek and Jara Uitto},
  doi          = {10.1016/j.tcs.2017.05.025},
  journal      = {Theoretical Computer Science},
  pages        = {58-71},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dynamic networks of finite state machines},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rumor spreading with bounded in-degree. <em>TCS</em>,
<em>810</em>, 43–57. (<a
href="https://doi.org/10.1016/j.tcs.2018.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the gossip-based model of communication for disseminating information in a network, in each time unit, every node u can contact a single random neighbor v but can possibly be contacted by many nodes. In the present paper, we consider a restricted model where at each node only one incoming call can be answered in one time unit. We study the implied weaker version of the well-studied pull protocol, which we call restricted pull . We prove an exponential separation of the rumor spreading time between two variants of the protocol (the answered call among a set of calls is chosen adversarially or uniformly at random). Further, we show that if the answered call is chosen randomly, the slowdown of restricted pull versus the classic pull protocol can w.h.p. be upper bounded by O ( ψ ( G ) ⋅ log ⁡ n ) , where ψ ( G ) = max { u , v } ∈ E ⁡ d ( u ) / d ( v ) ≤ Δ δ with Δ and δ being the largest and smallest degree of the network G = ( V , E ) and d ( u ) being the degree of u .},
  archive      = {J_TCS},
  author       = {Sebastian Daum and Fabian Kuhn and Yannic Maus},
  doi          = {10.1016/j.tcs.2018.05.041},
  journal      = {Theoretical Computer Science},
  pages        = {43-57},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Rumor spreading with bounded in-degree},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Whom to befriend to influence people. <em>TCS</em>,
<em>810</em>, 26–42. (<a
href="https://doi.org/10.1016/j.tcs.2018.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alice wants to join a new social network, and influence its members to adopt a new product or idea. Each person v in the network has a certain threshold t ( v ) t(v) for activation , i.e. adoption of the product or idea. If v has at least t ( v ) t(v) activated neighbors, then v will also become activated. If Alice wants to activate the entire social network, whom should she befriend? More generally, we study the problem of finding the minimum number of links that a set of external influencers should form to people in the network, in order to activate the entire social network. This Minimum Links Problem has applications in viral marketing and the study of epidemics. Its solution can be quite different from the related and widely studied Target Set Selection problem. We prove that the Minimum Links problem cannot be approximated to within a ratio of O ( 2 log 1 − ϵ ⁡ n ) O(2log1−ϵ⁡n) , for any fixed ϵ &gt; 0 ϵ&amp;gt;0 , unless N P ⊆ D T I M E ( n p o l y l o g ( n ) ) NP⊆DTIME(npolylog(n)) , where n is the number of nodes in the network. On the positive side, we give linear time algorithms to solve the problem for trees, cycles, and cliques , for any given set of external influencers, and give precise bounds on the number of links needed. For general graphs, we design a polynomial time algorithm to compute size-efficient link sets that can activate the entire graph.},
  archive      = {J_TCS},
  author       = {Gennaro Cordasco and Luisa Gargano and Manuel Lafond and Lata Narayanan and Adele A. Rescigno and Ugo Vaccaro and Kangkang Wu},
  doi          = {10.1016/j.tcs.2018.05.030},
  journal      = {Theoretical Computer Science},
  pages        = {26-42},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Whom to befriend to influence people},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fast size approximation of a radio network in beeping model.
<em>TCS</em>, <em>810</em>, 15–25. (<a
href="https://doi.org/10.1016/j.tcs.2017.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a single-hop radio network, nodes can communicate with each other by broadcasting to a shared wireless channel. In each time slot, all nodes receive feedback from the channel depending on the number of transmitters. In the Beeping Model, each node learns whether zero or at least one node have transmitted. In such a model, a procedure estimating the size of the network can be used for efficiently solving the problems of leader election or conflict resolution. We introduce a time-efficient uniform algorithm for size estimation of single-hop networks. With probability at least 1 − 1 / f 1−1/f our solution returns ( 1 + ε ) (1+ε) -approximation of the network size n within O ( log ⁡ log ⁡ n + log ⁡ f / ε 2 ) O(log⁡log⁡n+log⁡f/ε2) time slots. We prove that the algorithm is asymptotically time-optimal in a class of uniform algorithms.},
  archive      = {J_TCS},
  author       = {Philipp Brandes and Marcin Kardas and Marek Klonowski and Dominik Pająk and Roger Wattenhofer},
  doi          = {10.1016/j.tcs.2017.05.022},
  journal      = {Theoretical Computer Science},
  pages        = {15-25},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fast size approximation of a radio network in beeping model},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Collaborative delivery with energy-constrained mobile
robots. <em>TCS</em>, <em>810</em>, 2–14. (<a
href="https://doi.org/10.1016/j.tcs.2017.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of collectively delivering some package from a specified source to a designated target location in a graph, using multiple mobile agents . Each agent has limited energy which constrains the distance it can move. Hence multiple agents need to collaborate to move the package, each agent handing over the package to the next agent to carry it forward. Given the positions of the agents in the graph and their respective budgets, the problem of finding a feasible movement schedule for the agents can be challenging. We consider two variants of the problem: in non-returning delivery, the agents can stop anywhere; whereas in returning delivery, each agent needs to return to its starting location, a variant which has not been studied before. We first provide a polynomial-time algorithm for returning delivery on trees, which is in contrast to the known (weak) NP-hardness of the non-returning version. In addition, we give resource-augmented algorithms for returning delivery in general graphs. Finally, we give tight lower bounds on the required resource augmentation for both variants of the problem. In this sense, our results close the gap left by previous research.},
  archive      = {J_TCS},
  author       = {Andreas Bärtschi and Jérémie Chalopin and Shantanu Das and Yann Disser and Barbara Geissmann and Daniel Graf and Arnaud Labourel and Matúš Mihalák},
  doi          = {10.1016/j.tcs.2017.04.018},
  journal      = {Theoretical Computer Science},
  pages        = {2-14},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Collaborative delivery with energy-constrained mobile robots},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Structural information and communication complexity.
<em>TCS</em>, <em>810</em>, 1. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Jukka Suomela ( SIROCCO 2016 program committee chair )},
  doi          = {10.1016/j.tcs.2020.01.030},
  journal      = {Theoretical Computer Science},
  pages        = {1},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Structural information and communication complexity},
  volume       = {810},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for the connected sensor cover
problem. <em>TCS</em>, <em>809</em>, 563–574. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the minimum connected sensor cover problem ( MIN MIN - CSC CSC ) and the budgeted connected sensor cover ( Budgeted Budgeted - CSC CSC ) problem, both motivated by important applications (e.g., reduce the communication cost among sensors) in wireless sensor networks . In both problems, we are given a set of sensors and a set of target points in the Euclidean plane . In MIN MIN - CSC CSC , our goal is to find a set of sensors of minimum cardinality, such that all target points are covered, and all sensors can communicate with each other (i.e., the communication graph is connected). We obtain a constant factor approximation algorithm, assuming that the ratio between the sensor radius and communication radius is bounded. In Budgeted Budgeted - CSC CSC problem, our goal is to choose a set of B sensors, such that the number of targets covered by the chosen sensors is maximized and the communication graph is connected. We also obtain a constant approximation under the same assumption.},
  archive      = {J_TCS},
  author       = {Lingxiao Huang and Jian Li and Qicai Shi},
  doi          = {10.1016/j.tcs.2020.01.020},
  journal      = {Theoretical Computer Science},
  pages        = {563-574},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithms for the connected sensor cover problem},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic and rational languages of scattered and countable
series-parallel posets. <em>TCS</em>, <em>809</em>, 538–562. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let A be an alphabet and S P ⋄ ( A ) denote the class of all countable N-free partially ordered sets labeled by A , in which chains are scattered linear orderings and antichains are finite. We characterize the rational languages of S P ⋄ ( A ) by means of logic. We define an extension of monadic second-order logic by Presburger arithmetic, named P-MSO, such that a language L of S P ⋄ ( A ) is rational if and only if L is the language of a sentence of P-MSO, with effective constructions from one formalism to the other. As a corollary, the P-MSO theory of S P ⋄ ( A ) is decidable.},
  archive      = {J_TCS},
  author       = {Amazigh Amrane and Nicolas Bedon},
  doi          = {10.1016/j.tcs.2020.01.015},
  journal      = {Theoretical Computer Science},
  pages        = {538-562},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Logic and rational languages of scattered and countable series-parallel posets},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Descriptive complexity of computable sequences revisited.
<em>TCS</em>, <em>809</em>, 531–537. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to answer two questions left open in Durand et al. (2001) [2] . Namely, we consider the following two complexities of an infinite computable 0-1-sequence α : C 0 ′ ( α ) C0′(α) , defined as the minimal length of a program with oracle 0′ that prints α , and M ∞ ( α ) M∞(α) , defined as lim sup C ( α 1 : n | n ) limsupC(α1:n|n) , where α 1 : n α1:n denotes the length- n prefix of α and C ( x | y ) C(x|y) stands for conditional Kolmogorov complexity . We show that C 0 ′ ( α ) ⩽ M ∞ ( α ) + O ( 1 ) C0′(α)⩽M∞(α)+O(1) and M ∞ ( α ) M∞(α) is not bounded by any computable function of C 0 ′ ( α ) C0′(α) , even on the domain of computable sequences.},
  archive      = {J_TCS},
  author       = {Nikolay Vereshchagin},
  doi          = {10.1016/j.tcs.2020.01.013},
  journal      = {Theoretical Computer Science},
  pages        = {531-537},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Descriptive complexity of computable sequences revisited},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel approach to verifying context free properties of
programs. <em>TCS</em>, <em>809</em>, 519–530. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an approach to verifying context free properties of programs. In this approach, the system to be verified is modeled as a program m in Modeling, Simulation and Verification Language (MSVL), and the desired property is also specified by an MSVL program m ′ m′ . Then program m and formula ¬ m ′ ¬m′ are interpreted by means of executing programs m and m ′ m′ . If an acceptable execution path is generated, a counterexample is found, otherwise the property is valid. To show how the proposed approach works, an example is given.},
  archive      = {J_TCS},
  author       = {Nan Zhang and Zhenhua Duan and Cong Tian and Hongwei Du},
  doi          = {10.1016/j.tcs.2020.01.005},
  journal      = {Theoretical Computer Science},
  pages        = {519-530},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A novel approach to verifying context free properties of programs},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithms for optimal replica placement under correlated
failure in hierarchical failure domains. <em>TCS</em>, <em>809</em>,
482–518. (<a href="https://doi.org/10.1016/j.tcs.2020.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In data centers , data replication is the primary method used to ensure availability of customer data. To avoid correlated failure, cloud storage infrastructure providers model hierarchical failure domains using a tree, and avoid placing a large number of data replicas within the same failure domain (i.e. on the same branch of the tree). Typical best practices ensure that replicas are distributed across failure domains, but relatively little is known concerning optimization algorithms for distributing data replicas. Using a hierarchical model, we answer how to distribute replicas across failure domains optimally. We formulate a novel optimization problem for replica placement in data centers . As part of our problem, we formalize and present a new criterion for optimizing a replica placement. Our overall goal is to choose placements in which correlated failures disable as few replicas as possible. In this work, we provide two optimization algorithms for dependency models represented by trees. We first present an O ( n + ρ log ⁡ ρ ) O(n+ρlog⁡ρ) time dynamic programming algorithm for optimally placing ρ replicas of a single block on the leaves (representing servers) of a tree with n vertices. We next consider the problem of optimally placing replicas of multiple blocks of data, where every block may have a different replication factor. For this problem, we give a dynamic programming algorithm that runs in O ( n ρ max 3 δ 2 m poly ( δ ) ) O(nρmax3δ2mpoly(δ)) , where m denotes the number of blocks, ρ max ρmax denotes the maximum replication factor of a block, and δ denotes the maximum difference in the replication factors of any two blocks. The running time of the algorithm is polynomial when the δ , which we refer to as the skew , is a constant.},
  archive      = {J_TCS},
  author       = {K. Alex Mills and R. Chandrasekaran and Neeraj Mittal},
  doi          = {10.1016/j.tcs.2020.01.004},
  journal      = {Theoretical Computer Science},
  pages        = {482-518},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algorithms for optimal replica placement under correlated failure in hierarchical failure domains},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). An oracle separating conjectures about incompleteness in
the finite domain. <em>TCS</em>, <em>809</em>, 466–481. (<a
href="https://doi.org/10.1016/j.tcs.2020.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pudlák [19] lists several major complexity theoretic conjectures relevant to proof complexity and asks for oracles that separate pairs of corresponding relativized conjectures. Among these conjectures are: As one answer to this question, we construct an oracle relative to which (among others) DisjNP DisjNP , ¬ SAT ¬SAT , UP UP , and NP ∩ coNP NP∩coNP hold. Hence, there is no relativizable proof for the implication DisjNP ∧ UP ∧ NP ∩ coNP ⇒ SAT DisjNP∧UP∧NP∩coNP⇒SAT . In particular, regarding the conjectures by Pudlák this extends a result by Khaniki [11] .},
  archive      = {J_TCS},
  author       = {Titus Dose},
  doi          = {10.1016/j.tcs.2020.01.003},
  journal      = {Theoretical Computer Science},
  pages        = {466-481},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An oracle separating conjectures about incompleteness in the finite domain},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Translating xd-c programs to MSVL programs. <em>TCS</em>,
<em>809</em>, 430–465. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {C language is one of the most popular languages for software systems. In order to verify safety, reliability and security properties of such systems written in C, a tool UMC4M for runtime verification at code level based on Modeling, Simulation and Verification Language (MSVL) and its compiler MC is employed. To do so, a C program P has to be translated to an MSVL program M and the negation of a desired property Q is also translated to an MSVL program M&#39; , then “ M and M&#39; ” is compiled and executed armed with MC. Whether P violates Q is checked by evaluating whether there exists an acceptable execution of new MSVL program “ M and M&#39; ”. Therefore, how to translate a C program to an MSVL program is a critical issue. However, in general, C is of complicated structures with goto statement. In this paper, we confine the syntax of C in a suitable subset called Xd-C without loss of expressiveness. Further, we present a translation algorithm from an Xd-C program to an MSVL program based on translation algorithms for expressions and statements. Moreover, the equivalences between expressions and statements involved in Xd-C and MSVL programs are inductively proved. Subsequently, the equivalence between the original Xd-C program and the translated MSVL program is also proved. In addition, the proposed approach has been implemented by a tool called C 2 M C2M . A benchmark of experiments including 13 real-world Xd-C programs is conducted. The results show that C 2 M C2M works effectively.},
  archive      = {J_TCS},
  author       = {Meng Wang and Cong Tian and Nan Zhang and Zhenhua Duan and Chenguang Yao},
  doi          = {10.1016/j.tcs.2019.12.038},
  journal      = {Theoretical Computer Science},
  pages        = {430-465},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Translating xd-C programs to MSVL programs},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Orbit expandability of automaton semigroups and groups.
<em>TCS</em>, <em>809</em>, 418–429. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the notion of expandability in the context of automaton semigroups and groups: a word is k-expandable if one can append a suffix to it such that the size of the orbit under the action of the automaton increases by at least k . This definition is motivated by the question which ω -words admit infinite orbits: for such a word, every prefix is expandable. In this paper, we show that, given a word u , an automaton T T and a number k as input, it is decidable to check whether u is k -expandable with respect to the action of T T . In fact, this can be done in exponential nondeterministic space. From this nondeterministic algorithm, we obtain a bound on the length of a potential orbit-increasing suffix x . Moreover, we investigate the situation if the automaton is invertible and generates a group. In this case, we give an algebraic characterization for the expandability of a word based on its shifted stabilizer . We also give a more efficient algorithm to decide the expandability of a word in the case of automaton groups, which allows us to improve the upper bound on the maximal orbit-increasing suffix length. Then, we investigate the situation for reversible (and complete) automata and obtain that every word is expandable with respect to such automata. Finally, we give a lower bound example for the length of an orbit-increasing suffix.},
  archive      = {J_TCS},
  author       = {Daniele D&#39;Angeli and Emanuele Rodaro and Jan Philipp Wächter},
  doi          = {10.1016/j.tcs.2019.12.037},
  journal      = {Theoretical Computer Science},
  pages        = {418-429},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Orbit expandability of automaton semigroups and groups},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Morphic words, beatty sequences and integer images of the
fibonacci language. <em>TCS</em>, <em>809</em>, 407–417. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphic words are letter-to-letter images of fixed points x of morphisms on finite alphabets. There are situations where these letter-to-letter maps do not occur naturally, but have to be replaced by a morphism. We call this a decoration of x . Theoretically, decorations of morphic words are again morphic words, but in several problems the idea of decorating the fixed point of a morphism is useful. We present two of such problems. The first considers the so called AA sequences, where α is a quadratic irrational, A is the Beatty sequence defined by A ( n ) = ⌊ α n ⌋ A(n)=⌊αn⌋ , and AA is the sequence ( A ( A ( n ) ) ) (A(A(n))) . The second example considers homomorphic embeddings of the Fibonacci language into the integers, which turns out to lead to generalized Beatty sequences with terms of the form V ( n ) = p ⌊ α n ⌋ + q n + r V(n)=p⌊αn⌋+qn+r , where p , q p,q and r are integers.},
  archive      = {J_TCS},
  author       = {Michel Dekking},
  doi          = {10.1016/j.tcs.2019.12.036},
  journal      = {Theoretical Computer Science},
  pages        = {407-417},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Morphic words, beatty sequences and integer images of the fibonacci language},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing the nearest polynomial to multiple given
polynomials with a given zero via l2,q-norm minimization. <em>TCS</em>,
<em>809</em>, 394–406. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given multiple univariate or multivariate real polynomials f 1 , f 2 , … , f m f1,f2,…,fm and a desired real zero z , we study the problem of computing a real polynomial f ˜ f˜ such that f ˜ ( z ) = 0 f˜(z)=0 and the distance between f ˜ f˜ and f 1 , f 2 , … , f m f1,f2,…,fm is minimal, where the distance is measured by a pair of norms ( ‖ ⋅ ‖ p , ‖ ⋅ ‖ q ) (‖⋅‖p,‖⋅‖q) . As the difficulty of finding solutions to this problem relies on selection of the norm pair ( p , q ) (p,q) , previous works just discussed some special cases, e.g., ( p , q ) = ( 2 , 2 ) , ( 2 , ∞ ) (p,q)=(2,2),(2,∞) and ( ∞ , ∞ ) (∞,∞) , where the corresponding problems were translated in geometric views. In this paper, we revisit this problem from an optimization view for all the cases of ( 2 , q ) (2,q) with q ∈ ( 0 , 2 ] q∈(0,2] . That is, instead of directly finding the nearest polynomial, we first transform the problem into solving a constrained minimization problem based on l 2 , q l2,q -norm minimization. For all q in ( 0 , 2 ] (0,2] , then a unified iterative algorithm is proposed to solve the constrained optimization problem and also the convergence is uniformly demonstrated. Finally, a simple example is presented to validate the effectiveness of the proposed algorithm.},
  archive      = {J_TCS},
  author       = {Wenyu Hu and Shenghao Li and Jinhong Huang and Tinghua Wang and Gaohang Yu},
  doi          = {10.1016/j.tcs.2019.12.034},
  journal      = {Theoretical Computer Science},
  pages        = {394-406},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing the nearest polynomial to multiple given polynomials with a given zero via l2,q-norm minimization},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity of modification problems for reciprocal best
match graphs. <em>TCS</em>, <em>809</em>, 384–393. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reciprocal best match graphs (RBMGs) are vertex colored graphs whose vertices represent genes and the colors the species where the genes reside. Edges identify pairs of genes that are most closely related with respect to an underlying evolutionary tree. In practical applications this tree is unknown and the edges of the RBMGs are inferred by quantifying sequence similarity. Due to noise in the data, these empirically determined graphs in general violate the condition of being a “biologically feasible” RBMG. Therefore, it is of practical interest in computational biology to correct the initial estimate. Here we consider deletion (remove at most k edges) and editing (add or delete at most k edges) problems. We show that the decision version of the deletion and editing problem to obtain RBMGs from vertex colored graphs is NP-hard. Using known results for the so-called bicluster editing, we show that the RBMG editing problem for 2-colored graphs is fixed-parameter tractable. A restricted class of RBMGs appears in the context of orthology detection. These are cographs with a specific type of vertex coloring known as hierarchical coloring. We show that the decision problem of modifying a vertex-colored graph (either by edge-deletion or editing) into an RBMG with cograph structure or, equivalently, to an hierarchically colored cograph is NP-complete.},
  archive      = {J_TCS},
  author       = {Marc Hellmuth and Manuela Geiß and Peter F. Stadler},
  doi          = {10.1016/j.tcs.2019.12.033},
  journal      = {Theoretical Computer Science},
  pages        = {384-393},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity of modification problems for reciprocal best match graphs},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new encryption scheme for multivariate quadratic systems.
<em>TCS</em>, <em>809</em>, 372–383. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is regarded as a difficult task to design a secure MPKC fundamental schemes such as an encryption scheme . In this paper we introduce a new central trapdoor for multivariate quadratic (MQ) public-key cryptosystems that allows for encryption, in contrast to time-tested MQ primitives such as Unbalanced Oil and Vinegar or Rainbow which only allow for signatures. The same as UOV or Rainbow, our construction is single field scheme where the central polynomial system is chosen to have a particular structure that enables efficient inversion. After applying this transformation, the plaintext can be recovered by solving a linear system. Our new central trapdoor can use to replace the broken extension field calculation trapdoor and simple matrix encryption trapdoor, thereafter, we use the minus and plus modifiers to inoculate our scheme against known attacks. It is highlight that our encryption scheme is a good explore in the area of multivariate cryptography. Finally, a straightforward Magma implementation confirms the efficient operation of the public key algorithms .},
  archive      = {J_TCS},
  author       = {Jiahui Chen and Jianting Ning and Jie Ling and Terry Shue Chien Lau and Yacheng Wang},
  doi          = {10.1016/j.tcs.2019.12.032},
  journal      = {Theoretical Computer Science},
  pages        = {372-383},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A new encryption scheme for multivariate quadratic systems},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Space-efficient uniform deployment of mobile agents in
asynchronous unidirectional rings. <em>TCS</em>, <em>809</em>, 357–371.
(<a href="https://doi.org/10.1016/j.tcs.2019.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the uniform deployment problem of mobile agents in asynchronous unidirectional ring networks. This problem requires agents to spread uniformly in the network. In this paper, we focus on the memory space per agent required to solve the problem. We consider two problem settings. The first setting assumes that agents have no multiplicity detection, that is, agents cannot detect whether another agent is staying at the same node or not. In this case, we show that each agent requires Ω ( log ⁡ n ) Ω(log⁡n) memory space to solve the problem, where n is the number of nodes. In addition, we propose an algorithm to solve the problem with O ( k + log ⁡ n ) O(k+log⁡n) memory space per agent, where k is the number of agents. The second setting assumes that each agent is equipped with the weak multiplicity detection, that is, agents can detect whether another agent is staying at the same node or not, but cannot get any other information about the number of the agents. Then, we show that the memory space per agent can be reduced to O ( log ⁡ k + log ⁡ log ⁡ n ) O(log⁡k+log⁡log⁡n) . To the best of our knowledge, this is the first research considering the effect of the multiplicity detection on memory space required to solve problems.},
  archive      = {J_TCS},
  author       = {Masahiro Shibata and Hirotsugu Kakugawa and Toshimitsu Masuzawa},
  doi          = {10.1016/j.tcs.2019.12.031},
  journal      = {Theoretical Computer Science},
  pages        = {357-371},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Space-efficient uniform deployment of mobile agents in asynchronous unidirectional rings},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the multi-interval ulam-rényi game: For 3 lies 4
intervals suffice. <em>TCS</em>, <em>809</em>, 339–356. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of identifying an initially unknown m -bit number by using yes-no questions when up to a fixed number e of the answers can be erroneous. In the variant we consider here questions are restricted to be the union of up to a fixed number of intervals. For any e ≥ 1 e≥1 let k e ke be the minimum k such that for all sufficiently large m , there exists a strategy matching the information theoretic lower bound and only using k -interval questions. It is known that k e = O ( e 2 ) ke=O(e2) and it has been conjectured that the k e = Θ ( e ) ke=Θ(e) . This linearity conjecture is supported by the known results for small values of e as for e ≤ 2 e≤2 we have k e = e ke=e . We focus on the case e = 3 e=3 and show k 3 ≤ 4 k3≤4 improving upon the previously known bound k 3 ≤ 10 k3≤10 .},
  archive      = {J_TCS},
  author       = {Ferdinando Cicalese and Massimiliano Rossi},
  doi          = {10.1016/j.tcs.2019.12.028},
  journal      = {Theoretical Computer Science},
  pages        = {339-356},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the multi-interval ulam-rényi game: For 3 lies 4 intervals suffice},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed approximation algorithms for k-dominating set in
graphs of bounded genus and linklessly embeddable graphs. <em>TCS</em>,
<em>809</em>, 327–338. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k -dominating set in a graph G = ( V , E ) G=(V,E) is a set U ⊆ V U⊆V such that every vertex of G is either in U or has at least k neighbors in U . In this paper we give simple distributed approximation algorithms in the standard Local model of computations for the minimum k -dominating set problem for k ≥ 2 k≥2 in graphs with no K 3 , h K3,h -minor for some h ∈ Z + h∈Z+ and graphs with no K 4 , 4 K4,4 -minor. In particular, this gives fast distributed approximations for graphs of bounded genus and linklessly embeddable graphs. The algorithms give a constant approximation ratio and run in a constant number of rounds. In addition, we will give a ( 1 + ϵ ) (1+ϵ) -approximation for an arbitrary fixed ϵ &gt; 0 ϵ&amp;gt;0 which runs in ⁎ O ( log ⁎ ⁡ n ) O(log⁎⁡n) rounds where n is the order of a graph.},
  archive      = {J_TCS},
  author       = {Andrzej Czygrinow and Michał Hanćkowiak and Wojciech Wawrzyniak and Marcin Witkowski},
  doi          = {10.1016/j.tcs.2019.12.027},
  journal      = {Theoretical Computer Science},
  pages        = {327-338},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Distributed approximation algorithms for k-dominating set in graphs of bounded genus and linklessly embeddable graphs},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed balanced color assignment on arbitrary networks.
<em>TCS</em>, <em>809</em>, 313–326. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider a scenario in which a set of n agents hold items, where each item can be of one out of m possible types (colors). The agents are connected by an arbitrary network and have to distributively find a repartition of the colors such that the amount of colors for each agent is as balanced as possible: in the particular case where m is a multiple of n , each agent must have exactly m / n m/n colors. More formally, the goal is to let the agents agree on an assignment of colors to agents such that the following two conditions hold: This kind of questions, usually modeled as generalized bipartite matching problems , have been studied in the distributed setting only on clusters of commodity nodes with the aim of copying with real-world massive instances, which may involve millions of agents and colors. Here we propose the first distributed algorithm designed to run on an arbitrary network with the agents as nodes. Our algorithm turns out to be efficient in terms of both time and message complexity for a large class of graphs. Our results can be outlined as follows. We prove a lower bound Ω ( m / n ⋅ D 2 ) Ω(m/n⋅D2) on message complexity, where D is the diameter of the graph, that holds for any approximation algorithm whose solution has cost at most 2 ( α − 2 ) / α 2(α−2)/α times the cost of any optimal solution, for every constant α &gt; 2 α&amp;gt;2 . We give a distributed deterministic algorithm with time complexity O ( max ⁡ { n 2 , D log ⁡ q } ) O(max⁡{n2,Dlog⁡q}) and message complexity O ( n log ⁡ n ⋅ ( log ⁡ q + m log ⁡ m ) ) O(nlog⁡n⋅(log⁡q+mlog⁡m)) , where q is the maximum number of items of a given color held by any agent. We show that the cost of our solution for arbitrary graphs is at most ( 2 + δ ) (2+δ) times the optimal cost, for any δ &gt; 0 δ&amp;gt;0 . We finally observe that, for large diameter graphs ( i.e. , D = Ω ( n ϵ ) D=Ω(nϵ) , ϵ &gt; 0 ϵ&amp;gt;0 ), we get matching lower and upper bounds on message complexity for the vast majority of instances of potential interest, that is, instances with polynomial number of colors and (up to) super-exponential number of items.},
  archive      = {J_TCS},
  author       = {Gianluca De Marco and Mauro Leoncini and Manuela Montangero},
  doi          = {10.1016/j.tcs.2019.12.023},
  journal      = {Theoretical Computer Science},
  pages        = {313-326},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Distributed balanced color assignment on arbitrary networks},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Principal component analysis in the local differential
privacy model. <em>TCS</em>, <em>809</em>, 296–312. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the Principal Component Analysis (PCA) problem under the (distributed) non-interactive local differential privacy model. For the low dimensional case ( i.e., p ≪ n p≪n ), we show the optimal rate of Θ ( k p n ϵ 2 ) Θ(kpnϵ2) (omitting the eigenvalue terms) for the private minimax risk of the k -dimensional PCA using the squared subspace distance as the measurement, where n is the sample size and ϵ is the privacy parameter. For the high dimensional ( i.e., p ≫ n p≫n ) row sparse case, we first give a lower bound of Ω ( k s log ⁡ p n ϵ 2 ) Ω(kslog⁡pnϵ2) on the private minimax risk, where s is the underlying sparsity parameter. Then we provide an efficient algorithm to achieve the upper bound of O ( s 2 log ⁡ p n ϵ 2 ) O(s2log⁡pnϵ2) . Experiments on both synthetic and real world datasets confirm our theoretical guarantees.},
  archive      = {J_TCS},
  author       = {Di Wang and Jinhui Xu},
  doi          = {10.1016/j.tcs.2019.12.019},
  journal      = {Theoretical Computer Science},
  pages        = {296-312},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Principal component analysis in the local differential privacy model},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identity-based encryption with leakage-amplified
chosen-ciphertext attacks security. <em>TCS</em>, <em>809</em>, 277–295.
(<a href="https://doi.org/10.1016/j.tcs.2019.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alwen et al. (EUROCRYPT 2010) proposed the formal definition of identity-based hash proof system (IB-HPS). As an independent interest, they showed that a leakage-resilient identity-based encryption (LR-IBE) scheme can be created based on an IB-HPS. That is, a generic construction of LR-IBE scheme with the chosen-plaintext attacks (CPA) security be designed from the IB-HPS. However, in order to further improve the practicability of identity-based encryption (IBE) system, an IBE scheme must have the chosen-ciphertext attacks (CCA) security. Hence, in this paper, a generic construction of LR-IBE scheme with the CCA security is proposed from the IB-HPS. In additional, to design an LR-IBE schemes with an arbitrarily length leakage parameter, we design a novel generic construction of leakage amplified IBE scheme with CCA security, where we only increase the size of private key proportionally, while do not change all other parameters, and the upper bound of permitted leakage can be flexibly controlled by changing the leakage-size parameter. In other words, the length of allowed leakage of our generic construction is determined by the leakage requirements of actual applications.},
  archive      = {J_TCS},
  author       = {Yanwei Zhou and Bo Yang and Zhe Xia and Mingwu Zhang and Yi Mu},
  doi          = {10.1016/j.tcs.2019.12.018},
  journal      = {Theoretical Computer Science},
  pages        = {277-295},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Identity-based encryption with leakage-amplified chosen-ciphertext attacks security},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Popular matchings with two-sided preference lists and
matroid constraints. <em>TCS</em>, <em>809</em>, 265–276. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the popular matching problem with two-sided preference lists and matroid constraints, which is based on the variants of the popular matching problem proposed by Brandl and Kavitha, and Nasre and Rawat. We prove that there always exists a popular matching in our model, and a popular matching can be found in polynomial time . Furthermore, we prove that if every matroid is weakly base orderable, then we can find a maximum-size popular matching in polynomial time .},
  archive      = {J_TCS},
  author       = {Naoyuki Kamiyama},
  doi          = {10.1016/j.tcs.2019.12.017},
  journal      = {Theoretical Computer Science},
  pages        = {265-276},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Popular matchings with two-sided preference lists and matroid constraints},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polyline drawings with topological constraints.
<em>TCS</em>, <em>809</em>, 250–264. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of representing topological graphs as polyline drawings with few bends per edge and such that the topology of the graph is either fully or partially preserved. More formally, let G be a simple topological graph and let Γ be a polyline drawing of G . Drawing Γ partially preserves the topology of G if it has the same external boundary, the same circular order of the edges around each vertex, and the same set of crossings as G , while it fully preserves the topology of G if the planarization of G and the planarization of Γ have the same planar embedding. We prove that if the set of crossing-free edges of G forms a biconnected (connected) spanning subgraph, then G admits a polyline drawing that partially preserves its topology and that has curve complexity at most one (three), i.e., with at most one (three) bend(s) per edge. If, however, the set of crossing-free edges of G is not a connected spanning subgraph, the curve complexity may be Ω ( n ) Ω(n) , while it is O ( 1 ) O(1) if the number of connected components is O ( 1 ) O(1) . Concerning drawings that fully preserve the topology, we show that if G is k -skew (i.e., it becomes planar after removing k suitably chosen edges), it admits one such drawing with curve complexity at most 2 k ; for 1-skew graphs, the curve complexity can be reduced to one, which is a tight bound. We also consider optimal 2-plane graphs (i.e., with at most two crossings per edge and maximum edge density), for which we discuss trade-offs between curve complexity and crossing angle resolution of drawings that fully preserve the topology.},
  archive      = {J_TCS},
  author       = {Emilio Di Giacomo and Peter Eades and Giuseppe Liotta and Henk Meijer and Fabrizio Montecchiani},
  doi          = {10.1016/j.tcs.2019.12.016},
  journal      = {Theoretical Computer Science},
  pages        = {250-264},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Polyline drawings with topological constraints},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Complexity of the multicut problem, in its vanilla, partial
and generalized versions, in graphs of bounded treewidth. <em>TCS</em>,
<em>809</em>, 239–249. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Multicut problem, the input consists of a graph and a set of pairs of terminal vertices that have to be disconnected by the removal of a set of edges with minimum total weight. The Partial Multicut problem generalizes Multicut by only requiring a given number of pairs of terminals to be disconnected by the removal of edges. It has been shown that Multicut remains APX -hard if the treewidth t w ( G ) tw(G) of its input graph G is bounded, but that it is FPT w.r.t. t w ( G + H ) tw(G+H) , where H is the demand graph, whose vertices are the terminals and whose edges are the pairs of terminals. We prove that this also holds for Partial Multicut . Furthermore, it has been proved that Multicut also becomes polynomial-time solvable if t w ( G ) tw(G) is bounded and H is complete (this is the Multiterminal Cut problem). We extend this result in two directions, by proving that Multicut remains polynomial-time solvable if t w ( G + H ¯ ) tw(G+H¯) is bounded, and that this remains true for Partial Multicut . Finally, we show that if we further generalize the problem to allow non-unitary profits for pairs of terminals, then the problem is weakly NP -hard and has an FPTAS if t w ( G + H ) tw(G+H) is bounded, and becomes APX -hard if t w ( G + H ¯ ) tw(G+H¯) is bounded.},
  archive      = {J_TCS},
  author       = {Cédric Bentz and Pierre Le Bodic},
  doi          = {10.1016/j.tcs.2019.12.015},
  journal      = {Theoretical Computer Science},
  pages        = {239-249},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Complexity of the multicut problem, in its vanilla, partial and generalized versions, in graphs of bounded treewidth},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The k-power domination problem in weighted trees.
<em>TCS</em>, <em>809</em>, 231–238. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The power domination problem of the graph comes from how to choose the node location of the least phase measurement units in the electric power system. In the actual electric power system, because of the difference in the cost of phase measurement units at different nodes, it is more practical to study the power domination problem with the weighted graph . In this paper, we present a dynamic programming style linear-time algorithm for k -power domination problem in weighted trees.},
  archive      = {J_TCS},
  author       = {Changjie Cheng and Changhong Lu and Yu Zhou},
  doi          = {10.1016/j.tcs.2019.12.013},
  journal      = {Theoretical Computer Science},
  pages        = {231-238},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The k-power domination problem in weighted trees},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online unit covering in euclidean space. <em>TCS</em>,
<em>809</em>, 218–230. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We revisit the online Unit Covering problem in higher dimensions : Given a set of n points in R d Rd , that arrive one by one, cover the points by balls of unit radius, so as to minimize the number of balls used. In this paper, we work in R d Rd using the Euclidean distance . (I) We give an online deterministic algorithm with competitive ratio O ( 1.321 d ) O(1.321d) , thereby improving on the previous record, O ( 2 d d log ⁡ d ) O(2ddlog⁡d) , due to Charikar et al. (2004), by an exponential factor. In particular, the competitive ratios are 5 in the plane and 12 in 3-space (the previous ratios were 7 and 21, respectively). For d = 3 d=3 , the ratio of our online algorithm matches the ratio of the current best offline algorithm for the same problem due to Biniaz et al. (2017), which is remarkable (and rather unusual). (II) We show that the competitive ratio of every deterministic online algorithm for Unit Covering in R d Rd under the L 2 L2 norm is at least d + 1 d+1 for every d ≥ 1 d≥1 . This greatly improves upon the previous best lower bound, Ω ( log ⁡ d / log ⁡ log ⁡ log ⁡ d ) Ω(log⁡d/log⁡log⁡log⁡d) , due to Charikar et al. (2004). (III) We generalize the above result to Unit Covering in R d Rd under the L C LC norm, where C is a centrally symmetric convex body , via the illumination number. (IV) We obtain lower bounds of 4 and 5 for the competitive ratio of any deterministic algorithm for online Unit Covering in R 2 R2 and R 3 R3 , respectively; the previous best lower bounds were 3 for both cases. (V) When the input points are from the square or hexagonal lattice in R 2 R2 , we give deterministic online algorithms for Unit Covering with an optimal competitive ratio of 3. For the cubic lattice in R 3 R3 , we give a deterministic online algorithm with a competitive ratio of 5.},
  archive      = {J_TCS},
  author       = {Adrian Dumitrescu and Anirban Ghosh and Csaba D. Tóth},
  doi          = {10.1016/j.tcs.2019.12.010},
  journal      = {Theoretical Computer Science},
  pages        = {218-230},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online unit covering in euclidean space},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Makespan minimization on unrelated parallel machines with
simple job-intersection structure and bounded job assignments.
<em>TCS</em>, <em>809</em>, 204–217. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let there be a set J of n jobs and a set M of m parallel machines, where each job J j Jj takes p i , j ∈ Z + pi,j∈Z+ time units on machine M i Mi and assume p i , j = ∞ pi,j=∞ implies job J j Jj cannot be scheduled on machine M i Mi . In makespan minimization on unrelated parallel machines ( R | | C m a x R||Cmax ), the goal is to schedule each job non-preemptively on a machine so as to minimize the makespan. A job-intersection graph G J = ( J , E J ) GJ=(J,EJ) is an unweighted undirected graph where there is an edge { J j , J j ′ } ∈ E J {Jj,Jj′}∈EJ if there is a machine M i Mi such that both p i , j ≠ ∞ pi,j≠∞ and p i , j ′ ≠ ∞ pi,j′≠∞ . In this paper we consider two variants of R | | C m a x R||Cmax where there are a small number of eligible jobs per machine. First, we prove that there are no approximation algorithms with approximation ratios less than 3/2 for R | | C m a x R||Cmax when restricted to instances with job-intersection graphs belonging to some graph classes such as diamondless graphs and planar graphs , unless P = NP P=NP . Second, we match this lower bound by presenting a 3/2-approximation algorithm for R | | C m a x R||Cmax restricted to instances with diamondless job-intersection graphs, and furthermore show that when G J GJ is triangle free R | | C m a x R||Cmax is solvable in polynomial time . For R | | C m a x R||Cmax restricted to instances when every machine can process at most ℓ jobs, we give an approximation algorithm with approximation ratios 3/2 and 5/3 for ℓ = 3 ℓ=3 and ℓ = 4 ℓ=4 respectively, a polynomial-time algorithm when ℓ = 2 ℓ=2 , and prove that it is NP NP -hard to approximate the optimum solution within a factor less than 3/2 when ℓ ≥ 3 ℓ≥3 . In the special case where every p i , j ∈ { p j , ∞ } pi,j∈{pj,∞} , called the restricted assignment problem, and there are only two job lengths p j ∈ { α , β } pj∈{α,β} we present a ( 2 − 1 / ( ℓ − 1 ) ) (2−1/(ℓ−1)) -approximation algorithm when ℓ ≥ 3 ℓ≥3 . In addition, we give a 2-approximation algorithm for the so-called unrelated graph balancing problem for ℓ = 3 ℓ=3 in the case where J is partitioned into b sets called bags, and no two jobs from the same bag can be scheduled on the same machine.},
  archive      = {J_TCS},
  author       = {Daniel R. Page and Roberto Solis-Oba and Marten Maack},
  doi          = {10.1016/j.tcs.2019.12.009},
  journal      = {Theoretical Computer Science},
  pages        = {204-217},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Makespan minimization on unrelated parallel machines with simple job-intersection structure and bounded job assignments},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reliability analysis of data center networks based on
precise and imprecise diagnosis strategies. <em>TCS</em>, <em>809</em>,
189–203. (<a href="https://doi.org/10.1016/j.tcs.2019.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault tolerance and reliability are the crucial issues for data center networks (DCNs). Both the g -extra conditional diagnosis ( g -ECD) precise strategy and the t / k t/k -diagnosis imprecise strategy play essential role in the reliability of networks. For the data center network based on DCell structure D m , n Dm,n , we prove that: 1) the g -ECD of D m , n Dm,n under the MM ⁎ model is ( g + 1 ) m + n − 1 (g+1)m+n−1 with n ≥ 4 n≥4 , m ≥ 3 m≥3 , and 1 ≤ g ≤ min ⁡ { n 4 , m − 2 } 1≤g≤min⁡{n4,m−2} ; 2) D m , n Dm,n is [ ( k + 1 ) ( m − 1 ) + n ] / k [(k+1)(m−1)+n]/k -diagnosable under the MM ⁎ model with n ≥ 2 n≥2 , m ≥ 2 m≥2 , and 0 ≤ k ≤ n − 1 0≤k≤n−1 . Furthermore, for N -server DCN, we propose the first t / k t/k -diagnosis algorithm on D m , n Dm,n under the MM ⁎ model, namely t / k t/k - D m , n Dm,n -DIAG with O ( N log N ) O(NlogN) time complexity. Comparing with the traditional t -diagnosable algorithm by Ziwich and Duarte (2016) [11] , on D m , n Dm,n , the t / k t/k - D m , n Dm,n -DIAG can identify the number of faulty vertices is almost k times larger than the t -diagnosable algorithm, where the time complexity of t -diagnosable algorithm is about O ( N ( log N ) 3 ) O(N(logN)3) . These results provide a quantitative analysis for the reliability and availability evaluation of a large-scale DCN.},
  archive      = {J_TCS},
  author       = {Xiaoyan Li and Xiaohua Jia and Jianxi Fan and Cheng-Kuan Lin},
  doi          = {10.1016/j.tcs.2019.12.006},
  journal      = {Theoretical Computer Science},
  pages        = {189-203},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reliability analysis of data center networks based on precise and imprecise diagnosis strategies},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the computation of the möbius transform. <em>TCS</em>,
<em>809</em>, 171–188. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Möbius transform is a crucial transformation into the Boolean world; it allows to change the Boolean representation between the True Table and Algebraic Normal Form . In this work, we introduce a new algebraic point of view of this transformation based on the polynomial form of Boolean functions . It appears that we can perform a new notion: the Möbius computation variable by variable and new computation properties. As a consequence, we propose new algorithms which can produce a huge speed up of the Möbius computation for sub-families of Boolean function. Furthermore we compute directly the Möbius transformation of some particular Boolean functions . Finally, we show that for some of them the Hamming weight is directly related to the algebraic degree of specific factors.},
  archive      = {J_TCS},
  author       = {Morgan Barbier and Hayat Cheballah and Jean-Marie Le Bars},
  doi          = {10.1016/j.tcs.2019.12.005},
  journal      = {Theoretical Computer Science},
  pages        = {171-188},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the computation of the möbius transform},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constrained pseudorandom functions from functional
encryption. <em>TCS</em>, <em>809</em>, 137–170. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates how to design constrained pseudorandom functions ( CPRF ) and their various extensions from any public key functional encryption ( FE ) with standard polynomial security against arbitrary collusions. More precisely, we start by presenting a CPRF construction that supports constraint predicates realizable by arbitrary polynomial-size circuits , based on polynomially-hard public key FE and one way functions. Next, we augment our CPRF construction with the verifiability feature, relying only on a minimal additional assumption, namely, the existence of standard public key encryption ( PKE ). Finally, we show how to achieve privacy for the issued keys in the context of programable pseudorandom functions ( PPRF ), which is an enhanced variant of CPRF supporting puncturing constraints, employing polynomially-hard FE and one way functions. All prior works addressing the above problems either work for very restricted settings or rely on highly powerful yet little-understood cryptographic objects such as multilinear maps or indistinguishability obfuscation ( IO ). Although, there are known transformations from FE to IO , the reductions suffer from an exponential security loss and hence cannot be directly employed to replace IO with FE in cryptographic constructions at the expense of only a polynomial loss. Thus, our results open up a new pathway towards realizing numerous variants of CPRF , which are interesting cryptographic primitives in their own right and, moreover, have already been shown instrumental in a staggering range of applications, both in classical as well as in cutting edge cryptography, based on progressively weaker and well-studied cryptographic building blocks. Our work can also be interpreted as yet another stepping stone towards establishing FE as a substitute for IO in cryptographic applications. In order to achieve our results we build upon the prefix puncturing technique developed by Garg et al. [CRYPTO 2016, EUROCRYPT 2017] [42] , [43] .},
  archive      = {J_TCS},
  author       = {Pratish Datta},
  doi          = {10.1016/j.tcs.2019.12.004},
  journal      = {Theoretical Computer Science},
  pages        = {137-170},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Constrained pseudorandom functions from functional encryption},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lattice-based revocable (hierarchical) IBE with decryption
key exposure resistance. <em>TCS</em>, <em>809</em>, 103–136. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Revocable identity-based encryption (RIBE) is an extension of IBE that supports a key revocation mechanism, which is an indispensable feature for practical cryptographic schemes. Due to this extra feature, RIBE is often required to satisfy a strong security notion unique to the revocation setting called decryption key exposure resistance (DKER). Additionally, hierarchal IBE (HIBE) is another orthogonal extension of IBE that supports key delegation functionalities allowing for scalable deployments of cryptographic schemes. So far, R(H)IBE constructions with DKER are only known from bilinear maps , where all constructions rely heavily on the so-called key re-randomization property to achieve the DKER and/or hierarchal feature. Since lattice-based schemes seem to be inherently ill-fit with the key re-randomization property, no construction of lattice-based R(H)IBE schemes with DKER are known. In this paper, we propose the first lattice-based RHIBE scheme with DKER without relying on the key re-randomization property, departing from all the previously known methods. We start our work by providing a generic construction of RIBE schemes with DKER, which uses as building blocks any two-level standard HIBE scheme and (weak) RIBE scheme without DKER. Based on previous lattice-based RIBE constructions without DKER, our result implies the first lattice-based RIBE scheme with DKER. Then, building on top of our generic construction, we construct the first lattice-based RHIBE scheme with DKER, by further exploiting the algebraic structure of lattices. To this end, we prepare a new tool called the level conversion keys , which enables us to achieve the hierarchal feature without relying on the key re-randomization property. In this full version, we give the formal proofs of our proposed schemes.},
  archive      = {J_TCS},
  author       = {Shuichi Katsumata and Takahiro Matsuda and Atsushi Takayasu},
  doi          = {10.1016/j.tcs.2019.12.003},
  journal      = {Theoretical Computer Science},
  pages        = {103-136},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lattice-based revocable (hierarchical) IBE with decryption key exposure resistance},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The extra connectivity and extra diagnosability of regular
interconnection networks. <em>TCS</em>, <em>809</em>, 88–102. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability assessment of interconnection networks is critical to the design of multiprocessor systems . Extra connectivity and extra diagnosability are two important metric parameters for the reliability evaluation of interconnection networks . In this paper, we first establish that the i -extra connectivities of regular networks with some conditions G n Gn are ( i + 1 ) n − 2 i (i+1)n−2i for i = 1 , 2 i=1,2 , where n ≥4, and then determine that the i -extra diagnosabilities of the networks under the PMC model and the MM* model are ( i + 1 ) n − i (i+1)n−i for i = 1 , 2 i=1,2 , where n ≥4. Furthermore, two polynomial time diagnostic algorithms of regular interconnection networks under the PMC and MM* model are described. Finally, the corresponding extra connectivities and extra diagnosabilities of some networks, including the star networks, the pancake networks and the burnt pancake networks, can be derived by our results.},
  archive      = {J_TCS},
  author       = {Mengjie Lv and Jianxi Fan and Jingya Zhou and Baolei Cheng and Xiaohua Jia},
  doi          = {10.1016/j.tcs.2019.12.001},
  journal      = {Theoretical Computer Science},
  pages        = {88-102},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The extra connectivity and extra diagnosability of regular interconnection networks},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Accountable authority identity-based broadcast encryption
with constant-size private keys and ciphertexts. <em>TCS</em>,
<em>809</em>, 73–87. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identity-based broadcast encryption (IBBE) enables a sender to broadcast a message to multiple identities efficiently. Nevertheless, since IBBE is based on identity-based cryptography (IBC), it suffers from the inherent key escrow problem. As a consequence, not only the user knows its private key, but also the private key generator (PKG). This property leads to that the creator of a given pirated private key, named a private key from an unknown source, is untraceable since both the PKG and suspected user can generate such a pirated private key for this identity. To mitigate this problem, accountable authority IBBE (A-IBBE) was proposed to provide accountability for IBBE, where white-box A-IBBE can distinguish the creator of a given pirated private key between the PKG and suspected user and black-box A-IBBE can further trace the creator of a decoder box. However, all prior constructions of black-box A-IBBE do not capture constant-size private keys and ciphertexts simultaneously. In this paper, to fill this gap, we propose a weak black-box A-IBBE scheme with constant-size private keys and ciphertexts . Our construction supports public traceability such that tracing can be performed with the public tracing key of suspected user instead of its secret key. We first define the weak black-box A-IBBE with public traceability. Then, we give our construction where the private key and ciphertext consist of two and five group elements respectively. Furthermore, the proposed scheme is proven to be secure with random oracles.},
  archive      = {J_TCS},
  author       = {Zhen Zhao and Fuchun Guo and Jianchang Lai and Willy Susilo and Baocang Wang and Yupu Hu},
  doi          = {10.1016/j.tcs.2019.11.035},
  journal      = {Theoretical Computer Science},
  pages        = {73-87},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Accountable authority identity-based broadcast encryption with constant-size private keys and ciphertexts},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Metric dimension of cayley digraphs of split metacyclic
groups. <em>TCS</em>, <em>809</em>, 61–72. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A directed Cayley graph C a y ( Γ , X ) Cay(Γ,X) is specified by a group Γ and an identity-free generating set X for this group. Vertices of C a y ( Γ , X ) Cay(Γ,X) are elements of Γ and there is a directed edge from a vertex u to a vertex v in C a y ( Γ , X ) Cay(Γ,X) if and only if there is a generator x ∈ X x∈X such that u x = v ux=v . We study the metric dimension for the directed Cayley graphs C a y ( Γ s , { a , b } ) Cay(Γs,{a,b}) of general split metacyclic groups, and present the exact values of the metric dimension for the special split metacyclic groups Γ s = 〈 a , b | a n = b 2 s = 1 , b a = a − 1 b 〉 Γs=〈a,b|an=b2s=1,ba=a−1b〉 .},
  archive      = {J_TCS},
  author       = {Marcel Abas and Tomáš Vetrík},
  doi          = {10.1016/j.tcs.2019.11.025},
  journal      = {Theoretical Computer Science},
  pages        = {61-72},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Metric dimension of cayley digraphs of split metacyclic groups},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sparse matrix multiplication and triangle listing in the
congested clique model. <em>TCS</em>, <em>809</em>, 45–60. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show how to multiply two n × n n×n matrices S and T over semirings in the Congested Clique model, where n nodes communicate in a fully connected synchronous network using O ( log ⁡ n ) O(log⁡n) -bit messages, within O ( n z ( S ) 1 / 3 n z ( T ) 1 / 3 / n + 1 ) O(nz(S)1/3nz(T)1/3/n+1) rounds of communication, where n z ( S ) nz(S) and n z ( T ) nz(T) denote the number of non-zero elements in S and T , respectively. By leveraging the sparsity of the input matrices, our algorithm greatly reduces communication costs compared with general multiplication algorithms [Censor-Hillel et al. (2015) [9] ], and thus improves upon the state-of-the-art for matrices with o ( n 2 ) o(n2) non-zero elements. Moreover, our algorithm exhibits the additional strength of surpassing previous solutions also in the case where only one of the two matrices is such. Particularly, this allows to efficiently raise a sparse matrix to a power greater than 2. As applications, we show how to speed up the computation on non-dense graphs of 4-cycle counting and all-pairs-shortest-paths. Our algorithmic contribution is a new deterministic method of restructuring the input matrices in a sparsity-aware manner, which assigns each node with element-wise multiplication tasks that are not necessarily consecutive but guarantee a balanced element distribution, providing for communication-efficient multiplication. Moreover, this new deterministic method for restructuring matrices may be used to restructure the adjacency matrix of input graphs, enabling faster deterministic solutions for graph related problems. As an example, we present a new sparsity aware, deterministic algorithm which solves the triangle listing problem in O ( m / n 5 / 3 + 1 ) O(m/n5/3+1) rounds, a complexity that was previously obtained by a randomized algorithm [Pandurangan et al. (2018) [26] ], and that matches the known lower bound of Ω ˜ ( n 1 / 3 ) Ω˜(n1/3) when m = n 2 m=n2 of [Izumi and Le Gall (2017) [19] , Pandurangan et al. (2018) [26] ]. Naturally, our triangle listing algorithm also implies triangle counting within the same complexity of O ( m / n 5 / 3 + 1 ) O(m/n5/3+1) rounds, which is (possibly more than) a cubic improvement over the previously known deterministic O ( m 2 / n 3 ) O(m2/n3) -round algorithm [Dolev et al. (2012) [12] ].},
  archive      = {J_TCS},
  author       = {Keren Censor-Hillel and Dean Leitersdorf and Elia Turner},
  doi          = {10.1016/j.tcs.2019.11.006},
  journal      = {Theoretical Computer Science},
  pages        = {45-60},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Sparse matrix multiplication and triangle listing in the congested clique model},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Ω-lyndon words. <em>TCS</em>, <em>809</em>, 39–44. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let A A be a finite non-empty set and ⪯ a total order on A N AN verifying the following lexicographic like condition: For each n ∈ N n∈N and u , v ∈ A n u,v∈An , if u ω ≺ v ω uω≺vω then u x ≺ v y ux≺vy for all x , y ∈ A N x,y∈AN . A word x ∈ A N x∈AN is called ω -Lyndon if x ≺ y x≺y for each proper suffix y of x . A finite word w ∈ A + w∈A+ is called ω -Lyndon if w ω ≺ v ω wω≺vω for each proper suffix v of w . In this note we prove that every infinite word may be written uniquely as a non-increasing product of ω -Lyndon words.},
  archive      = {J_TCS},
  author       = {Mickaël Postic and Luca Q. Zamboni},
  doi          = {10.1016/j.tcs.2019.11.004},
  journal      = {Theoretical Computer Science},
  pages        = {39-44},
  shortjournal = {Theor. Comput. Sci.},
  title        = {ω-lyndon words},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Generalized lyndon factorizations of infinite words.
<em>TCS</em>, <em>809</em>, 30–38. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalized lexicographic order on words is a lexicographic order where the total order of the (possibly infinite) alphabet depends on the position of the comparison. A generalized Lyndon word is a finite word which is strictly smallest among its class of rotations with respect to a generalized lexicographic order. This notion can be extended to infinite words: an infinite generalized Lyndon word is an infinite word which is strictly smallest among its class of suffixes. We positively answer a question of Dolce, Restivo, and Reutenauer by proving that every infinite word has a unique nonincreasing factorization into finite and infinite generalized Lyndon words. When this factorization has finitely many terms, we characterize the last term of the factorization. Our methods also show that the infinite generalized Lyndon words are precisely the words with infinitely many generalized Lyndon prefixes.},
  archive      = {J_TCS},
  author       = {Amanda Burcroff and Eric Winsor},
  doi          = {10.1016/j.tcs.2019.11.003},
  journal      = {Theoretical Computer Science},
  pages        = {30-38},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Generalized lyndon factorizations of infinite words},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Palindromization and construction of markoff triples.
<em>TCS</em>, <em>809</em>, 21–29. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Markoff equation is the Diophantine equation x 2 + y 2 + z 2 = 3 x y z x2+y2+z2=3xyz . A solution is called a Markoff triple. We give a bijection between the free monoid on two letters and the set of Markoff triples, using the palindromization map of Aldo de Luca. In our construction, special Christoffel words appear, whose lengths are Markoff numbers; we study their standard and palindromic factorizations , and show that they are self-dual.},
  archive      = {J_TCS},
  author       = {Antoine Abram and Mélodie Lapointe and Christophe Reutenauer},
  doi          = {10.1016/j.tcs.2019.10.048},
  journal      = {Theoretical Computer Science},
  pages        = {21-29},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Palindromization and construction of markoff triples},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lower bounds for special cases of syntactic multilinear
ABPs. <em>TCS</em>, <em>809</em>, 1–20. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algebraic Branching Programs (ABPs) are standard models for computing polynomials. Syntactic multilinear ABPs (smABPs) are restrictions of ABPs where every variable is allowed to occur at most once in every path from the source to the sink node. Proving super-polynomial lower bounds for syntactic multilinear ABPs remains a challenging open question in Algebraic Complexity Theory. The current best lower bound for smABPs is only quadratic in the number of variables [1] . In this article, we develop a new approach for proving syntactic multilinear branching program lower bounds: Convert the smABP into an equivalent multilinear formula with a super-polynomial blow-up in size and then exploit the structural limitations of the resulting formula to obtain an upper bound on the rank of partial derivative matrix of the polynomial computed by the smABP. Using this approach, we prove exponential lower bounds for special cases of smABPs namely sum of Read-Once Oblivious smABPs, multilinear r -pass ABPs and α -set-multilinear ABPs. En route, we also prove an exponential lower bound for a special class of syntactic multilinear arithmetic circuits using a similar approach.},
  archive      = {J_TCS},
  author       = {C. Ramya and B.V. Raghavendra Rao},
  doi          = {10.1016/j.tcs.2019.10.047},
  journal      = {Theoretical Computer Science},
  pages        = {1-20},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lower bounds for special cases of syntactic multilinear ABPs},
  volume       = {809},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New bounds on the price of bandit feedback for
mistake-bounded online multiclass learning. <em>TCS</em>, <em>808</em>,
159–163. (<a href="https://doi.org/10.1016/j.tcs.2019.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is about two generalizations of the mistake bound model to online multiclass classification . In the standard model , the learner receives the correct classification at the end of each round, and in the bandit model , the learner only finds out whether its prediction was correct or not. For a set F of multiclass classifiers , let opt std ( F ) optstd(F) and opt bandit ( F ) optbandit(F) be the optimal bounds for learning F according to these two models. We show that an opt bandit ( F ) ≤ ( 1 + o ( 1 ) ) ( | Y | ln ⁡ | Y | ) opt std ( F ) optbandit(F)≤(1+o(1))(|Y|ln⁡|Y|)optstd(F) bound is the best possible up to the leading constant, closing a Θ ( log ⁡ | Y | ) Θ(log⁡|Y|) factor gap.},
  archive      = {J_TCS},
  author       = {Philip M. Long},
  doi          = {10.1016/j.tcs.2019.11.017},
  journal      = {Theoretical Computer Science},
  pages        = {159-163},
  shortjournal = {Theor. Comput. Sci.},
  title        = {New bounds on the price of bandit feedback for mistake-bounded online multiclass learning},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scale-invariant unconstrained online learning. <em>TCS</em>,
<em>808</em>, 139–158. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an online supervised learning problem, in which both the instances (input vectors) and the comparator (weight vector) are unconstrained. We exploit a natural scale invariance symmetry in our unconstrained setting: the predictions of the optimal comparator are invariant under any linear transformation of the instances. Our goal is to design online algorithms which also enjoy this property, i.e. are scale-invariant. We start with the case of coordinate-wise invariance, in which the individual coordinates (features) can be arbitrarily rescaled. We give an algorithm, which achieves essentially optimal regret bound in this setup, expressed by means of a coordinate-wise scale-invariant norm of the comparator. We then study general invariance with respect to arbitrary linear transformations. We first give a negative result, showing that no algorithm can achieve a meaningful bound in terms of scale-invariant norm of the comparator in the worst case. Next, we compliment this result with a positive one, providing an algorithm which “almost” achieves the desired bound, incurring only a logarithmic overhead in terms of the relative size of the instances.},
  archive      = {J_TCS},
  author       = {Wojciech Kotłowski},
  doi          = {10.1016/j.tcs.2019.11.016},
  journal      = {Theoretical Computer Science},
  pages        = {139-158},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Scale-invariant unconstrained online learning},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A modular analysis of adaptive (non-)convex optimization:
Optimism, composite objectives, variance reduction, and variational
bounds. <em>TCS</em>, <em>808</em>, 108–138. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, much work has been done on extending the scope of online learning and incremental stochastic optimization algorithms. In this paper we contribute to this effort in two ways: First, based on a generalization of Bregman divergences and a generic regret decomposition, we provide a self-contained, modular analysis of the two workhorses of online learning: (general) adaptive versions of Mirror Descent (MD) and the Follow-the-Regularized-Leader (FTRL) algorithms. The analysis is done with extra care so as not to introduce assumptions not needed in the proofs and allows to combine, in a straightforward way, different algorithmic ideas (e.g., adaptivity, optimism, implicit updates, variance reduction) and learning settings (e.g., strongly convex or composite objectives). This way we are able to reprove, extend and refine a large body of the literature, while keeping the proofs concise. The second contribution is a by-product of this careful analysis: We present algorithms with improved variational bounds for smooth, composite objectives, including a new family of optimistic MD algorithms with only one projection step per round. Furthermore, we provide a simple extension of adaptive regret bounds to a class of practically relevant non-convex problem settings (namely, star-convex loss functions and their extensions) with essentially no extra effort.},
  archive      = {J_TCS},
  author       = {Pooria Joulani and András György and Csaba Szepesvári},
  doi          = {10.1016/j.tcs.2019.11.015},
  journal      = {Theoretical Computer Science},
  pages        = {108-138},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A modular analysis of adaptive (non-)convex optimization: Optimism, composite objectives, variance reduction, and variational bounds},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parameter identification in markov chain choice models.
<em>TCS</em>, <em>808</em>, 99–107. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies the parameter identification problem for the Markov chain choice model of Blanchet, Gallego, and Goyal used in assortment planning. In this model, the product selected by a customer is determined by a Markov chain over the products, where the products in the offered assortment are absorbing states. The underlying parameters of the model were previously shown to be identifiable from the choice probabilities for the all-products assortment, together with choice probabilities for assortments of all-but-one products. Obtaining and estimating choice probabilities for such large assortments is not desirable in many settings. The main result of this work is that the parameters may be identified from assortments of sizes two and three, regardless of the total number of products. The result is obtained via a simple and efficient parameter recovery algorithm .},
  archive      = {J_TCS},
  author       = {Arushi Gupta and Daniel Hsu},
  doi          = {10.1016/j.tcs.2019.11.014},
  journal      = {Theoretical Computer Science},
  pages        = {99-107},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parameter identification in markov chain choice models},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tight bounds on ℓ1 approximation and learning of
self-bounding functions. <em>TCS</em>, <em>808</em>, 86–98. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the complexity of learning and approximation of self-bounding functions over the uniform distribution on the Boolean hypercube { 0 , 1 } n {0,1}n . Informally, a function f : { 0 , 1 } n → R f:{0,1}n→R is self-bounding if for every x ∈ { 0 , 1 } n x∈{0,1}n , f ( x ) f(x) upper bounds the sum of all the n marginal decreases in the value of the function at x . Self-bounding functions include such well-known classes of functions as submodular and fractionally-subadditive (XOS) functions. They were introduced by Boucheron et al. (2010) in the context of concentration of measure inequalities. Our main result is a nearly tight ℓ 1 ℓ1 -approximation of self-bounding functions by low-degree juntas. Specifically, all self-bounding functions can be ϵ -approximated in ℓ 1 ℓ1 by a polynomial of degree O ˜ ( 1 / ϵ ) O˜(1/ϵ) over 2 O ˜ ( 1 / ϵ ) 2O˜(1/ϵ) variables. We show that both the degree and junta-size are optimal up to logarithmic terms . Previous techniques considered stronger ℓ 2 ℓ2 approximation and proved nearly tight bounds of Θ ( 1 / ϵ 2 ) Θ(1/ϵ2) on the degree and 2 Θ ( 1 / ϵ 2 ) 2Θ(1/ϵ2) on the number of variables. Our bounds rely on the analysis of noise stability of self-bounding functions together with a stronger connection between noise stability and ℓ 1 ℓ1 approximation by low-degree polynomials. This technique can also be used to get tighter bounds on ℓ 1 ℓ1 approximation by low-degree polynomials and a faster learning algorithm for halfspaces. These results lead to improved and in several cases almost tight bounds for PAC and agnostic learning of self-bounding functions relative to the uniform distribution. In particular, assuming hardness of learning juntas, we show that PAC and agnostic learning of self-bounding functions have complexity of n Θ ˜ ( 1 / ϵ ) nΘ˜(1/ϵ) .},
  archive      = {J_TCS},
  author       = {Vitaly Feldman and Pravesh Kothari and Jan Vondrák},
  doi          = {10.1016/j.tcs.2019.11.013},
  journal      = {Theoretical Computer Science},
  pages        = {86-98},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Tight bounds on ℓ1 approximation and learning of self-bounding functions},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The complexity of explaining neural networks through (group)
invariants. <em>TCS</em>, <em>808</em>, 74–85. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ever since the work of Minsky and Papert, it has been thought that neural networks derive their effectiveness by finding representations of the data that are invariant with respect to the task. In other words, the representations eliminate components of the data that vary in a way that is irrelevant. These invariants are naturally expressed with respect to group operations, and thus an understanding of these groups is key to explaining the effectiveness of the neural network. Moreover, a line of work in deep learning has shown that explicit knowledge of group invariants can lead to more effective training results. In this paper, we investigate the difficulty of discovering anything about these implicit invariants. Unfortunately, our main results are negative: we show that a variety of questions around investigating invariant representations are NP-hard, even in approximate settings. Moreover, these results do not depend on the kind of architecture used: in fact, our results follow as soon as the network architecture is powerful enough to be universal. The key idea behind our results is that if we can find the symmetries of a problem then we can solve it.},
  archive      = {J_TCS},
  author       = {Danielle Ensign and Scott Neville and Arnab Paul and Suresh Venkatasubramanian},
  doi          = {10.1016/j.tcs.2019.11.012},
  journal      = {Theoretical Computer Science},
  pages        = {74-85},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The complexity of explaining neural networks through (group) invariants},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finitely distinguishable erasing pattern languages.
<em>TCS</em>, <em>808</em>, 38–73. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern languages have been an object of study in various subfields of computer science for decades. This paper introduces and studies a decision problem on patterns called the finite distinguishability problem: given a pattern π , are there finite sets T + T+ and T − T− of strings such that the only pattern language containing all strings in T + T+ and none of the strings in T − T− is the language generated by π ? This problem is related to the complexity of teacher-directed learning, as studied in computational learning theory , as well as to the long-standing open question whether the equivalence of two patterns is decidable. We show that finite distinguishability is decidable if the underlying alphabet is of size other than 2 or 3, and provide a number of related results, such as (i) partial solutions for alphabet sizes 2 and 3, and (ii) decidability proofs for variants of the problem for special subclasses of patterns, namely, regular, 1-variable, and non-cross patterns. For the same subclasses , we further determine the values of two complexity parameters in teacher-directed learning, namely the teaching dimension and the recursive teaching dimension .},
  archive      = {J_TCS},
  author       = {Fahimeh Bayeh and Ziyuan Gao and Sandra Zilles},
  doi          = {10.1016/j.tcs.2019.11.011},
  journal      = {Theoretical Computer Science},
  pages        = {38-73},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Finitely distinguishable erasing pattern languages},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lifelong learning in costly feature spaces. <em>TCS</em>,
<em>808</em>, 14–37. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important long-term goal in machine learning systems is to build learning agents that, like humans, can learn many tasks over their lifetime, and moreover use information from these tasks to improve their ability to do so efficiently. In this work, our goal is to provide new theoretical insights into the potential of this paradigm. In particular, we propose a lifelong learning framework that adheres to a novel notion of resource efficiency that is critical in many real-world domains where feature evaluations are costly. That is, our learner aims to reuse information from previously learned related tasks to learn future tasks in a feature-efficient manner. Furthermore, we consider novel combinatorial ways in which learning tasks can relate. Specifically, we design lifelong learning algorithms for two structurally different and widely used families of target functions: decision trees/lists and monomials/polynomials. We also provide strong feature-efficiency guarantees for these algorithms; in fact, we show that in order to learn future targets, we need only slightly more feature evaluations per training example than what is needed to predict on an arbitrary example using those targets. We also provide algorithms with guarantees in an agnostic model where not all the targets are related to each other. Finally, we also provide lower bounds on the performance of a lifelong learner in these models, which are in fact tight under some conditions.},
  archive      = {J_TCS},
  author       = {Maria-Florina Balcan and Avrim Blum and Vaishnavh Nagarajan},
  doi          = {10.1016/j.tcs.2019.11.010},
  journal      = {Theoretical Computer Science},
  pages        = {14-37},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Lifelong learning in costly feature spaces},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The power of random counterexamples. <em>TCS</em>,
<em>808</em>, 2–13. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a target concept from a finite n × m n×m concept space requires Ω ( n ) Ω(n) proper equivalence queries in the worst case. We propose a variation of the usual equivalence query in which the teacher is constrained to choose counterexamples randomly from a known probability distribution on examples. We present and analyze the Max-Min learning algorithm, which identifies an arbitrary target concept in an arbitrary finite n × m n×m concept space using at most an expected log 2 ⁡ n log2⁡n proper equivalence queries with random counterexamples .},
  archive      = {J_TCS},
  author       = {Dana Angluin and Tyler Dohrn},
  doi          = {10.1016/j.tcs.2019.11.009},
  journal      = {Theoretical Computer Science},
  pages        = {2-13},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The power of random counterexamples},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Special issue on ALT 2017: Guest editors’ introduction.
<em>TCS</em>, <em>808</em>, 1. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Steve Hanneke and Lev Reyzin},
  doi          = {10.1016/j.tcs.2019.11.008},
  journal      = {Theoretical Computer Science},
  pages        = {1},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Special issue on ALT 2017: Guest editors&#39; introduction},
  volume       = {808},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Security improvements of several basic quantum private query
protocols with o(log n) communication complexity. <em>TCS</em>,
<em>807</em>, 330–340. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New quantum private database (with N elements) query protocols are presented and analyzed. Protocols preserve O ( log ⁡ N ) O(log⁡N) communication complexity of known protocols for the same task, but achieve several significant improvements in security, especially concerning user privacy. For example, the randomized form of our protocol has a cheat-sensitive property – it allows the user to detect a dishonest database with a nonzero probability , while the phase-encoded private query protocols [6] , [7] for the same task do not have such a property. Moreover, when the database performs the computational basis measurement, a particular projective measurement which can cause a significant loss of user privacy in the previous private query protocols with O ( log ⁡ N ) O(log⁡N) communication complexity, at most half of the user privacy could leak to such a database in our protocol, while in the QPQ protocol [5] , the entire user privacy could leak out. In addition, it is proved here that for large N , the user could detect a cheating via the computational basis measurement, with a probability close to 1 2 12 using O ( N ) O(N) special queries. Finally, it is shown here, for both forms of our protocol, basic and randomized, how a dishonest database has to act in case it could not learn user&#39;s queries.},
  archive      = {J_TCS},
  author       = {Fang Yu and Daowen Qiu and Xiaoming Wang and Qin Li and Lvzhou Li and Jozef Gruska},
  doi          = {10.1016/j.tcs.2019.12.008},
  journal      = {Theoretical Computer Science},
  pages        = {330-340},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Security improvements of several basic quantum private query protocols with o(log n) communication complexity},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A game-based approximate verification of deep neural
networks with provable guarantees. <em>TCS</em>, <em>807</em>, 298–329.
(<a href="https://doi.org/10.1016/j.tcs.2019.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the improved accuracy of deep neural networks , the discovery of adversarial examples has raised serious safety concerns. In this paper, we study two variants of pointwise robustness, the maximum safe radius problem, which for a given input sample computes the minimum distance to an adversarial example, and the feature robustness problem, which aims to quantify the robustness of individual features to adversarial perturbations. We demonstrate that, under the assumption of Lipschitz continuity , both problems can be approximated using finite optimisation by discretising the input space, and the approximation has provable guarantees, i.e., the error is bounded. We then show that the resulting optimisation problems can be reduced to the solution of two-player turn-based games, where the first player selects features and the second perturbs the image within the feature. While the second player aims to minimise the distance to an adversarial example, depending on the optimisation objective the first player can be cooperative or competitive. We employ an anytime approach to solve the games, in the sense of approximating the value of a game by monotonically improving its upper and lower bounds . The Monte Carlo tree search algorithm is applied to compute upper bounds for both games, and the Admissible A ⁎ and the Alpha-Beta Pruning algorithms are, respectively, used to compute lower bounds for the maximum safety radius and feature robustness games. When working on the upper bound of the maximum safe radius problem, our tool demonstrates competitive performance against existing adversarial example crafting algorithms. Furthermore, we show how our framework can be deployed to evaluate pointwise robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.},
  archive      = {J_TCS},
  author       = {Min Wu and Matthew Wicker and Wenjie Ruan and Xiaowei Huang and Marta Kwiatkowska},
  doi          = {10.1016/j.tcs.2019.05.046},
  journal      = {Theoretical Computer Science},
  pages        = {298-329},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A game-based approximate verification of deep neural networks with provable guarantees},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Domains and stochastic processes. <em>TCS</em>,
<em>807</em>, 284–297. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain theory has a long history of applications in theoretical computer science and mathematics. In this article, we explore the relation of domain theory to probability theory and stochastic processes . The goal is to establish a theory in which Polish spaces are replaced by domains, and measurable maps are replaced by Scott-continuous functions. We illustrate the approach by recasting one of the fundamental results of stochastic process theory – Skorohod&#39;s Representation Theorem – in domain-theoretic terms. We anticipate the domain-theoretic version of results like Skorohod&#39;s Theorem will improve our understanding of probabilistic choice in computational models , and help devise models of probabilistic programming, with its focus on programming languages that support sampling from distributions where the results are applied to Bayesian reasoning .},
  archive      = {J_TCS},
  author       = {Michael Mislove},
  doi          = {10.1016/j.tcs.2019.05.002},
  journal      = {Theoretical Computer Science},
  pages        = {284-297},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Domains and stochastic processes},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Conditional value-at-risk: Structure and complexity of
equilibria. <em>TCS</em>, <em>807</em>, 266–283. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Value-at-Risk, denoted as CVaR α CVaRα , is becoming the prevailing measure of risk over two paramount economic domains: the insurance domain and the financial domain; α ∈ ( 0 , 1 ) α∈(0,1) is the confidence level . In this work, we study the strategic equilibria for an economic system modeled as a game, where risk-averse players seek to minimize the Conditional Value-at-Risk of their costs. Concretely, in a CVaR α CVaRα -equilibrium, the mixed strategy of each player is a best-response . We establish two significant properties of CVaR α CVaRα at equilibrium: (1) The Optimal-Value property: For any best-response of a player, each mixed strategy in the support gives the same cost to the player. This follows directly from the concavity of CVaR α CVaRα in the involved probabilities , which we establish. (2) The Crawford property: For every α , there is a 2-player game with no CVaR α CVaRα -equilibrium. The property is established using the Optimal-Value property and a new functional property of CVaR α CVaRα , called Weak-Equilibrium-for- VaR α VaRα , we establish. On top of these properties, we show, as one of our two main results, that deciding the existence of a CVaR α CVaRα -equilibrium is strongly NP NP -hard even for 2-player games. As our other main result, we show the strong NP NP -hardness of deciding the existence of a V V -equilibrium, over 2-player minimization games, for any valuation V V with the Optimal-Value and the Crawford properties. This result has a rich potential since we prove that the very significant and broad class of strictly quasiconcave valuations has the Optimal-Value property.},
  archive      = {J_TCS},
  author       = {Marios Mavronicolas and Burkhard Monien},
  doi          = {10.1016/j.tcs.2019.09.015},
  journal      = {Theoretical Computer Science},
  pages        = {266-283},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Conditional value-at-risk: Structure and complexity of equilibria},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The riemann hypothesis in computer science. <em>TCS</em>,
<em>807</em>, 257–265. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Riemann Hypothesis is reformulated as the statement that particular explicitly presented register machine with 29 registers and 130 instructions never halts.},
  archive      = {J_TCS},
  author       = {Yu. Matiyasevich},
  doi          = {10.1016/j.tcs.2019.07.028},
  journal      = {Theoretical Computer Science},
  pages        = {257-265},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The riemann hypothesis in computer science},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the least number of palindromes in two-dimensional words.
<em>TCS</em>, <em>807</em>, 245–256. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the least number of distinct palindromic sub-arrays in two-dimensional words over a finite alphabet Σ = { a 1 , a 2 ⋯ , a q } Σ={a1,a2⋯,aq} for a given alphabet size q . We discuss the case for both periodic as well as aperiodic words.},
  archive      = {J_TCS},
  author       = {Kalpana Mahalingam and Palak Pandoh and Kamala Krithivasan},
  doi          = {10.1016/j.tcs.2019.06.030},
  journal      = {Theoretical Computer Science},
  pages        = {245-256},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the least number of palindromes in two-dimensional words},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Every schnyder drawing is a greedy embedding. <em>TCS</em>,
<em>807</em>, 234–244. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show that every Schnyder drawing is a greedy embedding. Schnyder drawings are used to represent planar (maximal) graphs. It is a way of getting coordinates in R 2 R2 given a graph G = ( V , E ) G=(V,E) such that the representation is planar. The Schnyder technique leads to a family of representations and previous results show that a particular representation may be chosen such that the drawing has additional properties like being greedy or monotone . In this article, we relax the definition of greediness to a definition that does not rely on the geometry and the Euclidean distance in R 2 R2 , but rather on the combinatorial graph G . The construction of greedy paths valid for all Schnyder representations shows that, provided the relaxed definition, every Schnyder drawing is a greedy embedding.},
  archive      = {J_TCS},
  author       = {Pierre Leone and Kasun Samarasinghe and José D.P. Rolim},
  doi          = {10.1016/j.tcs.2019.07.021},
  journal      = {Theoretical Computer Science},
  pages        = {234-244},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Every schnyder drawing is a greedy embedding},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Left-handed completeness. <em>TCS</em>, <em>807</em>,
220–233. (<a href="https://doi.org/10.1016/j.tcs.2019.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give a new proof of the completeness of the left-handed star rule of Kleene algebra. The proof is significantly shorter than previous proofs and exposes the rich interaction of algebra and coalgebra in the theory of Kleene algebra.},
  archive      = {J_TCS},
  author       = {Dexter Kozen and Alexandra Silva},
  doi          = {10.1016/j.tcs.2019.10.040},
  journal      = {Theoretical Computer Science},
  pages        = {220-233},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Left-handed completeness},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved average complexity for comparison-based sorting.
<em>TCS</em>, <em>807</em>, 201–219. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the average complexity on the number of comparisons for sorting algorithms. Its information-theoretic lower bound is n lg ⁡ n − 1.4427 n + O ( log ⁡ n ) nlg⁡n−1.4427n+O(log⁡n) . For many efficient algorithms, the first n lg ⁡ n nlg⁡n term is easy to achieve and our focus is on the (negative) constant factor of the linear term. The current best value is −1.3999 for the MergeInsertion sort. Our new value is −1.4106, narrowing the gap by some 25\%. An important building block of our algorithm is “two-element insertion,” which inserts two elements A and B , A A&amp;lt;B , into a sorted sequence T . This insertion algorithm is still sufficiently simple for rigorous mathematical analysis and works well for a certain range of the length of T for which the simple binary insertion does not, thus allowing us to take a complementary approach together with the binary insertion.},
  archive      = {J_TCS},
  author       = {Kazuo Iwama and Junichi Teruyama},
  doi          = {10.1016/j.tcs.2019.06.032},
  journal      = {Theoretical Computer Science},
  pages        = {201-219},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved average complexity for comparison-based sorting},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximating the smallest 2-vertex connected spanning
subgraph of a directed graph. <em>TCS</em>, <em>807</em>, 185–200. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of approximating the smallest 2-vertex connected spanning subgraph ( 2VCSS ) of a 2-vertex connected directed graph , and provide new efficient algorithms. We provide two linear-time algorithms, the first based on a linear-time test for 2-vertex connectivity and divergent spanning trees, and the second based on low-high orders, that correspondingly give 3- and 2-approximations. Then we show that these linear-time algorithms can be combined with an algorithm of Cheriyan and Thurimella that achieves a 3/2-approximation. The combined algorithms preserve the 3/2 approximation guarantee of the Cheriyan-Thurimella algorithm and improve its running time from O ( m 2 ) O(m2) to O ( m n + n 2 ) O(mn+n2) , for a digraph with n vertices and m edges. Finally, we present an experimental evaluation of the above algorithms for a variety of input data. The experimental results show that our linear-time algorithms perform very well in practice. Furthermore, the experiments show that the combined algorithms not only improve the running time of the Cheriyan-Thurimella algorithm, but it may also compute a better solution.},
  archive      = {J_TCS},
  author       = {Loukas Georgiadis and Giuseppe F. Italiano and Aikaterini Karanasiou},
  doi          = {10.1016/j.tcs.2019.09.040},
  journal      = {Theoretical Computer Science},
  pages        = {185-200},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximating the smallest 2-vertex connected spanning subgraph of a directed graph},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A calculus of branching processes. <em>TCS</em>,
<em>807</em>, 169–184. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {CCS-like calculi can be viewed as an extension of classical automata with communication primitives. We are interested here to follow this principle, applied to tree-automata. It naturally yields a calculus of branching processes (CBP), where the continuations of communications are allowed to branch according to the arity of the communication channel. After introducing the calculus with a reduction semantics we show that CBP can be “implemented” by a fully compositional LTS semantics. We argue that CBP offers an interesting tradeoff between calculi with a fixed communication topology à la CCS and calculi with dynamic connectivity such as the π -calculus.},
  archive      = {J_TCS},
  author       = {Thomas Ehrhard and Jean Krivine and Ying Jiang},
  doi          = {10.1016/j.tcs.2019.06.028},
  journal      = {Theoretical Computer Science},
  pages        = {169-184},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A calculus of branching processes},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Towards “up to context” reasoning about higher-order
processes. <em>TCS</em>, <em>807</em>, 154–168. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proving behavioural equivalences in higher-order languages is a difficult task, because interactions involve complex values, namely terms of the language. In coinductive (i.e., bisimulation-like) techniques for these languages, a useful enhancement is the ‘up-to context’ reasoning, whereby common pieces of context in related terms are factorised out and erased. In higher-order process languages, however, such techniques are rare, as their soundness is usually delicate and difficult to establish. In this paper we adapt the technique of unique solution of equations, that implicitly captures ‘up-to context’ reasoning, to the setting of the Higher-order π -calculus. Equations are written and solved with respect to normal bisimilarity, chosen both because of its efficiency — its clauses do not require universal quantifications on terms supplied by the external observer — and because of the challenges it poses on the ‘up-to context’ reasoning and that already show up when proving its congruence properties .},
  archive      = {J_TCS},
  author       = {Adrien Durier and Daniel Hirschkoff and Davide Sangiorgi},
  doi          = {10.1016/j.tcs.2019.09.036},
  journal      = {Theoretical Computer Science},
  pages        = {154-168},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Towards ‘up to context’ reasoning about higher-order processes},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global types with internal delegation. <em>TCS</em>,
<em>807</em>, 128–153. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new form of delegation for multiparty session calculi. Usually, delegation allows a session participant to appoint a participant in another session to act on her behalf. This means that delegation is inherently an inter-session mechanism, which requires session interleaving. Hence delegation falls outside the descriptive power of global types, which specify single sessions. As a consequence, properties such as deadlock-freedom or lock-freedom are difficult to ensure in the presence of delegation. Here we adopt a different view of delegation, by allowing participants to delegate tasks to each other within the same multiparty session. This way, delegation occurs within a single session (internal delegation) and may be captured by its global type. To increase flexibility in the use of delegation, our calculus uses connecting communications, which allow optional participants in the branches of choices. By these means, we are able to express conditional delegation. We present a session type system based on global types with internal delegation, and show that it ensures the usual safety properties of multiparty sessions, together with a progress property.},
  archive      = {J_TCS},
  author       = {Ilaria Castellani and Mariangiola Dezani-Ciancaglini and Paola Giannini and Ross Horne},
  doi          = {10.1016/j.tcs.2019.09.027},
  journal      = {Theoretical Computer Science},
  pages        = {128-153},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Global types with internal delegation},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Searching for shortest and least programs. <em>TCS</em>,
<em>807</em>, 114–127. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kolmogorov complexity of a string x is defined as the length of a shortest program p of x for some appropriate universal machine U , that is, U ( p ) = x U(p)=x and p is a shortest string with this property. Neither the plain nor the prefix-free version of Kolmogorov complexity are recursive but for both versions it is well-known that there are recursive exact Solovay functions, that is, recursive upper bounds for Kolmogorov complexity that are infinitely often tight. Let a coding function for a machine M be a function f such that f ( x ) f(x) is always a program of x for M . From the existence of exact Solovay functions it follows easily that for every universal machine there is a recursive coding function that maps infinitely many strings to a shortest program. Extending a recent line of research, in what follows it is investigated in which situations there is a coding function for some universal machine that maps infinitely many strings to the length-lexicographically least program. The main results which hold in the plain as well as in the prefix-free setting are the following. For every universal machine there is a recursive coding function that maps infinitely many strings to their least programs. There is a partial recursive coding function (defined in the natural way) for some universal machine that for every set maps infinitely many prefixes of the set to their least programs. Exactly for every set that is Bennett shallow (not deep), there is a recursive coding function for some universal machine that maps all prefixes of the set to their least programs. Differences between the plain and the prefix-free frameworks are obtained by considering effective sequences I 1 , I 2 , … I1,I2,… of mutually disjoint finite sets and asking for a recursive coding function for some universal machine that maps at least one string in each set I n In to its least code. Such coding functions do not exist in the prefix-free setting but exist in the plain setting in case the sets I n In are not too small.},
  archive      = {J_TCS},
  author       = {Cristian S. Calude and Sanjay Jain and Wolfgang Merkle and Frank Stephan},
  doi          = {10.1016/j.tcs.2019.10.011},
  journal      = {Theoretical Computer Science},
  pages        = {114-127},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Searching for shortest and least programs},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bayesian network semantics for petri nets. <em>TCS</em>,
<em>807</em>, 95–113. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work by the authors equips Petri occurrence nets (PN) with probability distributions which fully replace nondeterminism . To avoid the so-called confusion problem, the construction imposes additional causal dependencies which restrict choices within certain subnets called structural branching cells (s-cells). Bayesian nets (BN) are usually structured as partial orders where nodes define conditional probability distributions. In the paper, we unify the two structures in terms of Symmetric Monoidal Categories (SMC), so that we can apply to PN ordinary analysis techniques developed for BN. Interestingly, it turns out that PN which cannot be SMC-decomposed are exactly s-cells. This result confirms the importance for Petri nets of both SMC and s-cells.},
  archive      = {J_TCS},
  author       = {Roberto Bruni and Hernán Melgratti and Ugo Montanari},
  doi          = {10.1016/j.tcs.2019.07.034},
  journal      = {Theoretical Computer Science},
  pages        = {95-113},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bayesian network semantics for petri nets},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Braided distributivity. <em>TCS</em>, <em>807</em>, 73–94.
(<a href="https://doi.org/10.1016/j.tcs.2019.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In category-theoretic models for the anyon systems proposed for topological quantum computing , the essential ingredients are two monoidal structures, ⊕ and ⊗. The former is symmetric but the latter is only braided, and ⊗ is required to distribute over ⊕. What are the appropriate coherence conditions for the distributivity isomorphisms? We came to this question working on a simplification of the category-theoretical foundation of topological quantum computing , which is the intended application of the research reported here. This question was answered by Laplaza when both monoidal structures are symmetric, but topological quantum computation depends crucially on ⊗ being only braided, not symmetric. We propose coherence conditions for distributivity in this situation, and we prove that our conditions are},
  archive      = {J_TCS},
  author       = {Andreas Blass and Yuri Gurevich},
  doi          = {10.1016/j.tcs.2019.11.027},
  journal      = {Theoretical Computer Science},
  pages        = {73-94},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Braided distributivity},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Vertex-weighted realizations of graphs. <em>TCS</em>,
<em>807</em>, 56–72. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a degree sequence d ¯ d¯ of length n , the degree realization problem is to decide if d ¯ d¯ has a realization , namely, an n -vertex graph whose degree sequence is d ¯ d¯ , and if so, to construct one such realization. The problem was well researched over the recent decades and plays an important role in the field of Social Networks. In this paper, we consider the following natural generalization of the problem: Let G = ( V , E ) G=(V,E) be a simple undirected graph on V = { 1 , 2 , … , n } V={1,2,…,n} . Let f ¯ ∈ R + n f¯∈R+n be a vector of requirements of the vertices, and let w ¯ ∈ R + n w¯∈R+n be a vector of provided services at the vertices. The provided services vector w ¯ w¯ satisfies the requirements vector f ¯ f¯ on G if the constraints ∑ j ∈ Γ ( i ) w j = f i ∑j∈Γ(i)wj=fi are satisfied for all i ∈ V i∈V , where Γ ( i ) Γ(i) denotes the neighborhood of i . We study the following weighted graph realization problem. Given a requirements vector f ¯ f¯ , the goal is to find a suitable graph G and a vector w ¯ w¯ of provided services that satisfy f ¯ f¯ on G . In the original degree realization problem, all the provided services must be equal to one. For even n , we show that every requirement vector is realizable. For odd n , the picture is more complicated, as certain requirement vectors are non-realizable. We provide a complete characterization for n = 3 n=3 and n = 5 n=5 , and give (non-matching but close) necessary and sufficient conditions for realizability for odd n ≥ 7 n≥7 . We provide a complete characterization for the variant in which the constraints that should be satisfied are: max j ∈ Γ ( i ) ⁡ w j = f i maxj∈Γ(i)⁡wj=fi , for all i ∈ V i∈V . As before, we show that every requirement vector can be realized if n is even. For odd n , we show that a vector is realizable if and only if not all requirements are distinct.},
  archive      = {J_TCS},
  author       = {Amotz Bar-Noy and David Peleg and Dror Rawitz},
  doi          = {10.1016/j.tcs.2019.12.020},
  journal      = {Theoretical Computer Science},
  pages        = {56-72},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Vertex-weighted realizations of graphs},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic resource allocation games. <em>TCS</em>,
<em>807</em>, 42–55. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In resource allocation games , selfish players share resources that are needed in order to fulfill their objectives. The cost of using a resource depends on the load on it. In the traditional setting, the players make their choices concurrently and in one-shot. That is, a strategy for a player is a subset of the resources. We introduce and study dynamic resource allocation games. In this setting, the game proceeds in phases. In each phase each player chooses one resource. A scheduler dictates the order in which the players proceed in a phase, possibly scheduling several players to proceed concurrently. The game ends when each player has collected a set of resources that fulfills his objective. The cost for each player then depends on this set as well as on the load on the resources in it – we consider both congestion and cost-sharing games. We argue that the dynamic setting is the suitable setting for many applications in practice. We study the stability of dynamic resource allocation games, where the appropriate notion of stability is that of subgame perfect equilibrium, study the inefficiency incurred due to selfish behavior, and also study problems that are particular to the dynamic setting, like constraints on the order in which resources can be chosen or the problem of finding a scheduler that achieves stability.},
  archive      = {J_TCS},
  author       = {Guy Avni and Thomas A. Henzinger and Orna Kupferman},
  doi          = {10.1016/j.tcs.2019.06.031},
  journal      = {Theoretical Computer Science},
  pages        = {42-55},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Dynamic resource allocation games},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Streamable regular transductions. <em>TCS</em>,
<em>807</em>, 15–41. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by real-time monitoring and data processing applications , we develop a formal theory of quantitative queries for streaming data that can be evaluated efficiently. We consider the model of unambiguous Cost Register Automata (CRAs), which are machines that combine finite-state control (for identifying regular patterns) with a finite set of data registers (for computing numerical aggregates). The definition of CRAs is parameterized by the collection of numerical operations that can be applied to the registers. These machines give rise to the class of streamable regular transductions ( SR SR ), and to the class of streamable linear regular transductions ( SLR SLR ) when the register updates are copyless , i.e. every register appears at most once in the right-hand-side expressions of the updates. We give a logical characterization of the class SR SR (resp., SLR SLR ) using MSO-definable transformations from strings to DAGs (resp., trees) without backward edges. Additionally, we establish that the two classes SR SR and SLR SLR are closed under operations that are relevant for designing query languages . Finally, we study the relationship with weighted automata (WA), and show that CRAs over a suitably chosen set of operations correspond to WA, thus establishing that WA are a special case of CRAs.},
  archive      = {J_TCS},
  author       = {Rajeev Alur and Dana Fisman and Konstantinos Mamouras and Mukund Raghothaman and Caleb Stanford},
  doi          = {10.1016/j.tcs.2019.11.018},
  journal      = {Theoretical Computer Science},
  pages        = {15-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Streamable regular transductions},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Whither semantics? <em>TCS</em>, <em>807</em>, 3–14. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss how mathematical semantics has evolved, and suggest some new directions for future work. As an example, we discuss some recent work on encapsulating model comparison games as comonads, in the context of finite model theory.},
  archive      = {J_TCS},
  author       = {Samson Abramsky},
  doi          = {10.1016/j.tcs.2019.06.029},
  journal      = {Theoretical Computer Science},
  pages        = {3-14},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Whither semantics?},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Preface. <em>TCS</em>, <em>807</em>, 1–2. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Giorgio Ausiello ( Former and current Editors-in-Chief ) and Lila Kari and Grzegorz Rozenberg and Donald Sannella and Paul Spirakis and Pierre-Louis Curien (Guest Editor)},
  doi          = {10.1016/j.tcs.2019.12.021},
  journal      = {Theoretical Computer Science},
  pages        = {1-2},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Preface},
  volume       = {807},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to “on the edge-length ratio of outerplanar
graphs” [theoret. Comput. Sci. 770 (2019) 88–94]. <em>TCS</em>,
<em>806</em>, 689. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to an editorial oversight, a flaw in the proof (not the result) of Lemma 5 remained in the TCS published version of the following paper “On the edge-length ratio of outerplanar graphs”, published in Theoretical Computer Science, vol. 770, pp. 88–94, 2019. Please refer to the electronic version on HAL ( https://hal.inria.fr/hal-01886947 ) for the correct version.},
  archive      = {J_TCS},
  author       = {Sylvain Lazard and William J. Lenhart and Giuseppe Liotta},
  doi          = {10.1016/j.tcs.2019.11.019},
  journal      = {Theoretical Computer Science},
  pages        = {689},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Corrigendum to “On the edge-length ratio of outerplanar graphs” [Theoret. comput. sci. 770 (2019) 88–94]},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online interval scheduling to maximize total satisfaction.
<em>TCS</em>, <em>806</em>, 673–688. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval scheduling problem is one variant of the scheduling problem. In this paper, we propose a novel variant of the interval scheduling problem, whose definition is as follows: given jobs are specified by their release times , deadlines and profits . An algorithm must start a job at its release time on one of m identical machines, and continue processing until its deadline on the machine to complete the job. All the jobs must be completed and the algorithm can obtain the profit of a completed job as a user&#39;s satisfaction. It is possible to process more than one job at a time on one machine. The profit of a job is distributed uniformly between its release time and deadline, that is its interval, and the profit gained from a subinterval of a job decreases in reverse proportion to the number of jobs whose intervals intersect with the subinterval on the same machine. The objective of our variant is to maximize the total profit of completed jobs. This formulation is naturally motivated by best-effort requests and responses to them, which appear in many situations. In best-effort requests and responses, the total amount of available resources for users is always invariant and the resources are equally shared with every user. We study online algorithms for this problem. Specifically, we show that for the case where the profits of jobs are arbitrary, there does not exist an algorithm whose competitive ratio is bounded. Then, we consider the case in which the profit of each job is equal to its length, that is, the time interval between its release time and deadline. For this case, we prove that for m = 2 m=2 and m ≥ 3 m≥3 , the competitive ratios of a greedy algorithm are at most 4/3 and at most 3, respectively. Also, for each m ≥ 2 m≥2 , we show a lower bound on the competitive ratio of any deterministic algorithm.},
  archive      = {J_TCS},
  author       = {Koji M. Kobayashi},
  doi          = {10.1016/j.tcs.2019.10.046},
  journal      = {Theoretical Computer Science},
  pages        = {673-688},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online interval scheduling to maximize total satisfaction},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Low-weight superimposed codes and related combinatorial
structures: Bounds and applications. <em>TCS</em>, <em>806</em>,
655–672. (<a href="https://doi.org/10.1016/j.tcs.2019.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ( k , n ) (k,n) -superimposed code is a well known and widely used combinatorial structure that can be represented by a t × n t×n binary matrix such that for any k columns of the matrix and for any column c chosen among these k columns, there exists a row in correspondence of which column c has an entry equal to 1 and the remaining k − 1 k−1 columns have entries equal to 0. Due to the many situations in which superimposed codes find applications, there is an abundant literature that studies the problem of constructing ( k , n ) (k,n) -superimposed codes with a small number t of rows. Motivated by applications to conflict-free communication in multiple-access networks, group testing , and data security, we study the problem of constructing superimposed codes that have the additional constraints that the number of 1&#39;s in each column of the matrix is constant, and equal to an input parameter w . Our results improve on the known literature in the area. We also extend our findings to other important combinatorial structures, like selectors, generalized superimposed codes, and z -error correcting superimposed codes.},
  archive      = {J_TCS},
  author       = {Luisa Gargano and Adele Anna Rescigno and Ugo Vaccaro},
  doi          = {10.1016/j.tcs.2019.10.032},
  journal      = {Theoretical Computer Science},
  pages        = {655-672},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Low-weight superimposed codes and related combinatorial structures: Bounds and applications},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The price of anarchy of affine congestion games with similar
strategies. <em>TCS</em>, <em>806</em>, 641–654. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affine congestion games are a well-studied model for selfish behavior in distributed systems, such as transportation and communication networks. Seminal influential papers in Algorithmic Game Theory have bounded the worst-case inefficiency of Nash equilibria , termed as price of anarchy, in several variants of these games. In this work, we investigate to what extent these bounds depend on the similarities among the players&#39; strategies. Our notion of similarity is modeled by assuming that, given a parameter θ ≥ 1 θ≥1 , the costs of any two strategies available to a same player, when evaluated in absence of congestion, are within a factor θ one from the other. It turns out that, for the non-atomic case, better bounds can always be obtained for any finite value of θ . For the atomic case, instead, θ θ&amp;lt;3/2 and θ θ&amp;lt;2 are necessary and sufficient conditions to obtain better bounds in games played on general graph topologies and on parallel link graphs, respectively. It is worth noticing that small values of θ model the behavioral attitude of players who are partially oblivious to congestion and are not willing to significantly deviate from what is their best strategy in absence of congestion.},
  archive      = {J_TCS},
  author       = {Vittorio Bilò and Cosimo Vinci},
  doi          = {10.1016/j.tcs.2019.10.012},
  journal      = {Theoretical Computer Science},
  pages        = {641-654},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The price of anarchy of affine congestion games with similar strategies},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Corrigendum to: “Linear time algorithm to cover and hit a
set of line segments optimally by two axis-parallel squares” [theor.
Comput. Sci. 769 (2019) 63–74]. <em>TCS</em>, <em>806</em>, 632–640. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper “Linear time algorithm to cover and hit a set of line segments optimally by two axis-parallel squares”, Theor. Comput. Sci. 769 (2019) 63–74, the LHIT problem is proposed as follows:},
  archive      = {J_TCS},
  author       = {Sanjib Sadhu and Xiaozhou He and Sasanka Roy and Subhas C. Nandy and Suchismita Roy},
  doi          = {10.1016/j.tcs.2019.09.044},
  journal      = {Theoretical Computer Science},
  pages        = {632-640},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Corrigendum to: “Linear time algorithm to cover and hit a set of line segments optimally by two axis-parallel squares” [Theor. comput. sci. 769 (2019) 63–74]},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Loosely-stabilizing leader election with polylogarithmic
convergence time. <em>TCS</em>, <em>806</em>, 617–631. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A loosely-stabilizing leader election protocol with polylogarithmic convergence time in the population protocol model is presented in this paper. In the population protocol model, which is a common abstract model of mobile sensor networks , it is known to be impossible to design a self-stabilizing leader election protocol unless the exact number of agents is known a priori . Thus, in our prior work, we introduced concept of loose-stabilization, which is weaker than self-stabilization but has similar advantage in practice. Following this work, several loosely-stabilizing leader election protocols have been given. Loosely-stabilizing leader election guarantees that, starting from an arbitrary configuration, the system reaches a safe configuration with a single leader within a short time, and keeps the unique leader for a long time thereafter. The convergence times of all existing loosely-stabilizing protocols, i.e. , the expected times to reach a safe configuration, are polynomial in n where n is the number of nodes, while their holding times, i.e. , the expected times to keep the unique leader after reaching a safe configuration, are exponential in n . In this paper, a loosely-stabilizing protocol with polylogarithmic convergence time is presented. Its holding time is not exponential, rather an arbitrarily large polynomial function of n .},
  archive      = {J_TCS},
  author       = {Yuichi Sudo and Fukuhito Ooshita and Hirotsugu Kakugawa and Toshimitsu Masuzawa and Ajoy K. Datta and Lawrence L. Larmore},
  doi          = {10.1016/j.tcs.2019.09.034},
  journal      = {Theoretical Computer Science},
  pages        = {617-631},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Loosely-stabilizing leader election with polylogarithmic convergence time},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Priority evacuation from a disk: The case of n = 1,2,3.
<em>TCS</em>, <em>806</em>, 595–616. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An exit (or target) is at an unknown location on the perimeter of a unit disk. A group of n + 1 n+1 robots (in our case, n = 1 , 2 , 3 n=1,2,3 ), initially located at the centre of the disk, are tasked with finding the exit. The robots have unique identities, share the same coordinate system, move at maximum speed 1 and are able to communicate wirelessly the position of the exit once found. Among them there is a distinguished robot called the queen and the remainder of the robots are referred to as servants . It is known that with two robots searching, the room can be evacuated (i.e., with both robots reaching the exit) in 1 + 2 π 3 + 3 ≈ 4.8264 1+2π3+3≈4.8264 time units and this is optimal [11] . Somewhat surprisingly, in this paper we show that if the goal is to have the queen reach the exit, not caring if her servants make it, there is a slightly better strategy for the case of one servant. We prove that this “priority” version of evacuation can be solved in time at most 4.81854. Furthermore, we show that any strategy for saving the queen with one servant requires time at least 3 + π / 6 + 3 / 2 ≈ 4.3896 3+π/6+3/2≈4.3896 in the worst case. If more servants are available, we show that the time bounds can be improved to 3.8327 for two servants, and 3.3738 for three servants which are better than the known lower bound for the corresponding problems of evacuating three or four robots. Finally, we show lower bounds for these cases of 3.6307 (two servants) and 3.2017 (three servants). The case of more than three servants uses substantially different techniques and is discussed in a separate paper [13] .},
  archive      = {J_TCS},
  author       = {Jurek Czyzowicz and Konstantinos Georgiou and Ryan Killick and Evangelos Kranakis and Danny Krizanc and Lata Narayanan and Jaroslav Opatrny and Sunil Shende},
  doi          = {10.1016/j.tcs.2019.09.026},
  journal      = {Theoretical Computer Science},
  pages        = {595-616},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Priority evacuation from a disk: The case of n = 1,2,3},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New kernels for several problems on planar graphs.
<em>TCS</em>, <em>806</em>, 587–594. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the kernelization of the Induced Matching problem on planar graphs , the Parameterized Planar 4-Cycle Transversal problem and the Parameterized Planar Edge-Disjoint 4-Cycle Packing problem . For the Induced Matching problem on planar graphs , based on the Gallai-Edmonds decomposition structure, a kernel of size 26 k is presented, which improves the previous best result 28 k . For the Parameterized Planar 4-Cycle Transversal problem, by partitioning the vertices in a given instance into several parts and analyzing the size of each part independently, a kernel with at most 51 k − 22 51k−22 vertices is obtained, which improves the previous best result 74 k . Based on the kernelization process of the Parameterized Planar 4-Cycle Transversal problem, a kernel of size 51 k − 22 51k−22 can also be obtained for the Parameterized Planar Edge-Disjoint 4-Cycle Packing problem , which improves the previous best result 96 k .},
  archive      = {J_TCS},
  author       = {Guanlan Tan and Qilong Feng and Beilin Zhuo and Neng Huang and Jianxin Wang},
  doi          = {10.1016/j.tcs.2019.09.024},
  journal      = {Theoretical Computer Science},
  pages        = {587-594},
  shortjournal = {Theor. Comput. Sci.},
  title        = {New kernels for several problems on planar graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Model-checking graded computation-tree logic with finite
path semantics. <em>TCS</em>, <em>806</em>, 577–586. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Graded Computation Tree Logic with finite path semantics (GCTL ⁎ f ⁎ f⁎ , for short), a variant of Computation Tree Logic CTL ⁎ , in which path quantifiers are interpreted over finite paths and can count the number of such paths. State formulas of GCTL ⁎ f ⁎ f⁎ are interpreted over Kripke structures . The syntax of GCTL ⁎ f ⁎ f⁎ has path quantifiers of the form E ≥ g ψ E≥gψ which express that there are at least g many distinct finite paths that satisfy ψ . After defining and justifying the logic GCTL ⁎ f ⁎ f⁎ , we solve its model checking problem and establish that its computational complexity is PSPACE-complete. Moreover, we investigate GCTL ⁎ f ⁎ f⁎ under the imperfect information setting. Precisely, we introduce GCTLK ⁎ f ⁎ f⁎ , an epistemic extension of GCTL ⁎ f ⁎ f⁎ and prove that the model checking problem also in this case is PSPACE-complete.},
  archive      = {J_TCS},
  author       = {Aniello Murano and Mimmo Parente and Sasha Rubin and Loredana Sorrentino},
  doi          = {10.1016/j.tcs.2019.09.021},
  journal      = {Theoretical Computer Science},
  pages        = {577-586},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Model-checking graded computation-tree logic with finite path semantics},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Global synchronization and consensus using beeps in a
fault-prone multiple access channel. <em>TCS</em>, <em>806</em>,
567–576. (<a href="https://doi.org/10.1016/j.tcs.2019.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global synchronization is an important prerequisite to many distributed tasks. Communication between processors proceeds in synchronous rounds. Processors are woken up in possibly different rounds. The clock of each processor starts in its wakeup round showing local round 0, and ticks once per round, incrementing the value of the local clock by one. The global round 0, unknown to processors, is the wakeup round of the earliest processor. Global synchronization (or establishing a global clock) means that each processor chooses a local clock round such that their chosen rounds all correspond to the same global round t . We study the task of global synchronization in a Multiple Access Channel (MAC) prone to faults, under a very weak communication model called the beeping model . Some processors wake up spontaneously, in possibly different rounds decided by an adversary. In each round, an awake processor can either listen, i.e., stay silent, or beep, i.e., emit a signal. In each round, a fault can occur in the channel independently with constant probability 0 0&amp;lt;p&amp;lt;1 . In a fault-free round, an awake processor hears a beep if it listens in this round and if one or more other processors beep in this round. A processor still dormant in a fault-free round in which some other processor beeps is woken up by this beep and hears it. In a faulty round nothing is heard, regardless of the behaviour of the processors. An algorithm working with error probability at most ϵ , for a given ϵ &gt; 0 ϵ&amp;gt;0 , is called ϵ - safe . Our main result is the design and analysis, for any ϵ &gt; 0 ϵ&amp;gt;0 , of a deterministic ϵ -safe global synchronization algorithm that works in O ( log p 2 ⁡ ϵ ) O(logp2⁡ϵ) time in any fault-prone MAC using beeps. As an application, we solve the consensus problem in a fault-prone MAC using beeps. Processors have input values from some set V and they have to decide the same value from this set. If all processors have the same input value, then they must all decide this value. Using global synchronization, we give a deterministic ϵ -safe consensus algorithm that works in time O ( ( log ⁡ w ) ( log p ⁡ ϵ ) ) O((log⁡w)(logp⁡ϵ)) in a fault-prone MAC, where w is the smallest input value of all participating processors. We show that this time cannot be significantly improved, even when the MAC is fault-free.},
  archive      = {J_TCS},
  author       = {Kokouvi Hounkanli and Avery Miller and Andrzej Pelc},
  doi          = {10.1016/j.tcs.2019.09.020},
  journal      = {Theoretical Computer Science},
  pages        = {567-576},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Global synchronization and consensus using beeps in a fault-prone multiple access channel},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconfiguring spanning and induced subgraphs. <em>TCS</em>,
<em>806</em>, 553–566. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph reconfiguration is a family of problems focusing on the reachability of the solution space in which feasible solutions are subgraphs, represented either as sets of vertices or sets of edges, satisfying a prescribed graph structure property. Although there has been previous work that can be categorized as subgraph reconfiguration , most of the related results appear under the name of the property under consideration; for example, independent set, clique , and matching. In this paper, we systematically clarify the complexity status of subgraph reconfiguration with respect to graph structure properties.},
  archive      = {J_TCS},
  author       = {Tesshu Hanaka and Takehiro Ito and Haruka Mizuta and Benjamin Moore and Naomi Nishimura and Vijay Subramanya and Akira Suzuki and Krishna Vaidyanathan},
  doi          = {10.1016/j.tcs.2019.09.018},
  journal      = {Theoretical Computer Science},
  pages        = {553-566},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reconfiguring spanning and induced subgraphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Two improved schemes in the bitprobe model. <em>TCS</em>,
<em>806</em>, 543–552. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we describe two new explicit schemes in the bitprobe model that, to the best of our knowledge, improves upon the existing schemes in the literature. One such scheme is to store three elements using O ( m 2 / 3 ) O(m2/3) amount of space and answer membership queries using two adaptive bitprobes. Previously, the maximum number of elements that could be handled using two queries and O ( m 2 / 3 ) O(m2/3) amount of space is two, which is due to Radhakrishnan et al. [1] . A corollary of this result is an explicit scheme for storing three elements using three queries in the non-adaptive model, a first such scheme in the model. The next scheme uses four bitprobes in the non-adaptive bitprobe model and uses O ( m 2 / 3 ) O(m2/3) amount of space to accommodate five elements using the block-superblock idea of Radhakrishnan et al. [1] . The previous scheme to store such a configuration was a non-explicit scheme due to Alon and Fiege [2] , and we provide an explicit scheme for the same.},
  archive      = {J_TCS},
  author       = {Mirza Galib Anwarul Husain Baig and Deepanjan Kesh},
  doi          = {10.1016/j.tcs.2019.08.033},
  journal      = {Theoretical Computer Science},
  pages        = {543-552},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Two improved schemes in the bitprobe model},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Searching for a non-adversarial, uncooperative agent on a
cycle. <em>TCS</em>, <em>806</em>, 531–542. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assume k robots are placed on a cycle–the perimeter of a unit (radius) disk–at a position of our choosing and can move on the cycle with maximum speed one. A non-adversarial, uncooperative agent, called bus , is moving with constant speed s along the perimeter of the cycle. The robots are searching for the moving bus but do not know its exact location. Moreover, during the search they can move anywhere on the perimeter of the cycle. We give algorithms which minimize the worst-case search time required for at least one of the robots to find the bus. The following results are obtained for one robot. 1) If the robot knows the speed s of the bus but does not know its direction of movement then the optimal search time is shown to be exactly 2 π / s 2π/s , if s ≥ 1 s≥1 , 4 π / ( s + 1 ) 4π/(s+1) , if 1 / 3 ≤ s ≤ 1 1/3≤s≤1 , and 2 π / ( 1 − s ) 2π/(1−s) , if s ≤ 1 / 3 s≤1/3 . 2) If the robot does not know neither the speed nor the direction of movement of the bus then the optimal search time is shown to be 2 π ( 1 + 1 s + 1 ) 2π(1+1s+1) . Moreover, for all ϵ &gt; 0 ϵ&amp;gt;0 there exists a speed s such that any algorithm knowing neither the bus speed nor its direction will need time at least 4 π − ϵ 4π−ϵ to meet the bus. These results are also generalized to k ≥ 2 k≥2 robots and analogous tight upper and lower bounds are proved depending on the knowledge the robots have about the speed and direction of movement of the bus.},
  archive      = {J_TCS},
  author       = {Jurek Czyzowicz and Stefan Dobrev and Maxime Godon and Evangelos Kranakis and Toshinori Sakai and Jorge Urrutia},
  doi          = {10.1016/j.tcs.2019.08.031},
  journal      = {Theoretical Computer Science},
  pages        = {531-542},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Searching for a non-adversarial, uncooperative agent on a cycle},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Data collection in population protocols with non-uniformly
random scheduler. <em>TCS</em>, <em>806</em>, 516–530. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrary to many previous studies on population protocols using the uniformly random scheduler, we consider a more general non-uniform case. Here, pair-wise interactions between agents (moving and communicating devices) are assumed to be drawn non-uniformly at random. While such a scheduler is known to be relevant for modeling many practical networks, it is also known to make the formal analysis more difficult. This study concerns data collection , a fundamental problem in mobile sensor networks (one of the target networks of population protocols). In this problem, pieces of information given to the agents (e.g., sensor readings) should be eventually delivered to a predefined sink node without loss or duplication. Following an idea of the known deterministic protocol TTF solving this problem, we propose an adapted version of it and perform a complete formal analysis of execution times in expectation and with high probability (w.h.p.). We further investigate the important issue of energy consumption. The goal is to improve TTF in terms of energy complexity, while still keeping good time complexities (in expectation and w.h.p.). Namely, we propose a new parameterized protocol for data collection, called lazy TTF, and present a study showing that an appropriate choice of the protocol parameters can considerably improve energy performances (compared to TTF), at a slight expense of time performance.},
  archive      = {J_TCS},
  author       = {Chuan Xu and Joffroy Beauquier and Janna Burman and Shay Kutten and Thomas Nowak},
  doi          = {10.1016/j.tcs.2019.08.029},
  journal      = {Theoretical Computer Science},
  pages        = {516-530},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Data collection in population protocols with non-uniformly random scheduler},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Improved approximation algorithms for two-stage flowshops
scheduling problem. <em>TCS</em>, <em>806</em>, 509–515. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of scheduling n two-stage jobs on m two-stage flowshops so as to minimize the makespan. By studying the relationship between the problem and the classical makespan problem, we prove that if there is an α -approximation algorithm for the makespan problem, then for the general case of the problem, we can construct a 2 α -approximation algorithm, and for two restricted cases which are of practical importance, we can construct an ( α + 1 / 2 ) (α+1/2) -approximation algorithm. As a result, by employing the polynomial-time approximation scheme for the makespan problem, we get a ( 2 + ϵ ) (2+ϵ) -approximation algorithm for the general case and a ( 1.5 + ϵ ) (1.5+ϵ) -approximation algorithm for the two restricted cases, which significantly improve the previous approximation ratios 2.6 and 11/6 respectively.},
  archive      = {J_TCS},
  author       = {Guangwei Wu and Jianer Chen and Jianxin Wang},
  doi          = {10.1016/j.tcs.2019.08.028},
  journal      = {Theoretical Computer Science},
  pages        = {509-515},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved approximation algorithms for two-stage flowshops scheduling problem},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On simple back-off in unreliable radio networks.
<em>TCS</em>, <em>806</em>, 489–508. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study local and global broadcast in the dual graph model, which describes communication in a radio network with both reliable and unreliable links. Existing work proved that efficient solutions to these problems are impossible in the dual graph model under standard assumptions. In real networks, however, simple back-off strategies tend to perform well for solving these basic communication tasks. We address this apparent paradox by introducing a new set of constraints to the dual graph model that better generalize the slow/fast fading behavior common in real networks. We prove that in the context of these new constraints, simple back-off strategies now provide efficient solutions to local and global broadcast in the dual graph model. We also precisely characterize how this efficiency degrades as the new constraints are reduced down to non-existent, and prove new lower bounds that establish this degradation as near optimal for a large class of natural algorithms. We conclude with an analysis of a more general model where we propose an enhanced back-off algorithm. These results provide theoretical foundations for the practical observation that simple back-off algorithms tend to work well even amid the complicated link dynamics of real radio networks.},
  archive      = {J_TCS},
  author       = {Seth Gilbert and Nancy Lynch and Calvin Newport and Dominik Pajak},
  doi          = {10.1016/j.tcs.2019.08.027},
  journal      = {Theoretical Computer Science},
  pages        = {489-508},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On simple back-off in unreliable radio networks},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Game theory-based optimization of distributed idle computing
resources in cloud environments. <em>TCS</em>, <em>806</em>, 468–488.
(<a href="https://doi.org/10.1016/j.tcs.2019.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid cloud technological advancement and economic growth, more and more organizations have purchased cloud resources for daily business operations besides building their own IT infrastructures. Thus, it is very important to understand the economy of cloud computing. In this paper, we mainly focus on examining the private idle computing resources owned by various organizations who are willing to form a network of ad hoc cloud provider and sell the services to cloud users. In such a case, the organizations cannot only meet their own demands, but also sell their idle computing resources in the form of ad hoc cloud. Naturally, the organizations, as provider, aim at maximizing their own profit through adjusting business costs and sale prices. Due to the uncertainty of the amount of idle computing resources, dynamic pricing is challenging. We approach the problem from the perspective of game theory and formulate it as a non-cooperative game among multiple organizations, i.e., the game player. For each player, a utility function is used to represent its profits. The players choose request strategies and sales service strategies to maximize the utility function. This paper has proved that there exists Nash equilibrium for this game problem. We proposed an iterative proximal algorithm ( IPA ) for calculating the Nash equilibrium. After analyzing the convergence of the IPA , we found that the algorithm converges to the Nash equilibrium solution when reasonable conditions are satisfied and conforms to the theoretical proof. Experimental results show that our proposed algorithm can quickly converge to a stable state, and by calculating the appropriate service (resource) request strategies and selling service strategies for all organizations, organizations&#39; profit are increased compared to without IPA algorithm.},
  archive      = {J_TCS},
  author       = {Gang Liu and Zheng Xiao and GuangHua Tan and Kenli Li and Anthony Theodore Chronopoulos},
  doi          = {10.1016/j.tcs.2019.08.019},
  journal      = {Theoretical Computer Science},
  pages        = {468-488},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Game theory-based optimization of distributed idle computing resources in cloud environments},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online facility assignment. <em>TCS</em>, <em>806</em>,
455–467. (<a href="https://doi.org/10.1016/j.tcs.2019.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the online facility assignment problem, with a set of facilities F of equal capacity l in metric space and customers arriving one by one in an online manner. We must assign customer c i ci to facility f j fj before the next customer c i + 1 ci+1 arrives. The cost of this assignment is the distance between c i ci and f j fj . The total number of customers is at most | F | l |F|l and each customer must be assigned to a facility. The objective is to minimize the sum of all assignment costs. We first consider the case where facilities are placed on a line so that the distance between adjacent facilities is the same and customers appear anywhere on the line. We describe a greedy algorithm with competitive ratio 4 | F | 4|F| and another one with competitive ratio | F | |F| . We also consider a slightly more general situation where different facilities may have different capacities. Finally, we study a variant of the online facility assignment problem in which the facilities are placed on the vertices of a graph and present two algorithms for that setting.},
  archive      = {J_TCS},
  author       = {Abu Reyan Ahmed and Md. Saidur Rahman and Stephen Kobourov},
  doi          = {10.1016/j.tcs.2019.08.011},
  journal      = {Theoretical Computer Science},
  pages        = {455-467},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Online facility assignment},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximation algorithm for the l-pseudoforest deletion
problem. <em>TCS</em>, <em>806</em>, 446–454. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An l-pseudoforest is a graph each of whose connected components is at most l edges removal being a tree. The l-Pseudoforest Deletion problem is to delete a vertex set P of minimum weight from a given vertex-weighted graph G = ( V , E ) G=(V,E) such that the remaining graph G [ V ∖ P ] G[V∖P] is an l -pseudoforest. The Feedback Vertex Set problem is a special case of the l -Pseudoforest Deletion problem with l = 0 l=0 . In this paper, we present a polynomial time 4 l -approximation algorithm for the l -Pseudoforest Deletion problem with l ≥ 1 l≥1 by using the local ratio technique. When l = 1 l=1 , we get a better approximation ratio 2 for the problem by further analyzing the local ratio, which matches the current best constant approximation factor for the Feedback Vertex Set problem.},
  archive      = {J_TCS},
  author       = {Mugang Lin and Qilong Feng and Bin Fu and Jianxin Wang},
  doi          = {10.1016/j.tcs.2019.08.009},
  journal      = {Theoretical Computer Science},
  pages        = {446-454},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An approximation algorithm for the l-pseudoforest deletion problem},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robustness: A new form of heredity motivated by dynamic
networks. <em>TCS</em>, <em>806</em>, 429–445. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a special case of hereditary property in graphs, referred to as robustness . A property (or structure) is called robust in a graph G if it is inherited by all the connected spanning subgraphs of G . We motivate this definition using two different settings of dynamic networks. The first corresponds to networks of low dynamicity, where some links may be permanently removed so long as the network remains connected. The second corresponds to highly-dynamic networks, where communication links appear and disappear arbitrarily often, subject only to the requirement that the entities are temporally connected in a recurrent fashion ( i.e. they can always reach each other through temporal paths). Each context induces a different interpretation of the notion of robustness. We start by motivating the definition and discussing the two interpretations, after what we consider the notion independently from its interpretation, taking as our focus the robustness of maximal independent sets (MIS). A graph may or may not admit a robust MIS. We characterize the set of graphs RMI S ∀ RMIS∀ in which all MISs are robust. Then, we turn our attention to the graphs that admit a robust MIS ( RMI S ∃ RMIS∃ ). This class has a more complex structure; we give a partial characterization in terms of elementary graph properties, then a complete characterization by means of a (polynomial time) decision algorithm that accepts if and only if a robust MIS exists. This algorithm can be adapted to construct such a solution if one exists.},
  archive      = {J_TCS},
  author       = {Arnaud Casteigts and Swan Dubois and Franck Petit and John M. Robson},
  doi          = {10.1016/j.tcs.2019.08.008},
  journal      = {Theoretical Computer Science},
  pages        = {429-445},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Robustness: A new form of heredity motivated by dynamic networks},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalizing the hypergraph laplacian via a diffusion
process with mediators. <em>TCS</em>, <em>806</em>, 416–428. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent breakthrough STOC 2015 paper, a continuous diffusion process was considered on hypergraphs (which has been refined in a recent JACM 2018 paper) to define a Laplacian operator , whose spectral properties satisfy the celebrated Cheeger&#39;s inequality. However, one peculiar aspect of this diffusion process is that each hyperedge directs flow only from vertices with the maximum density to those with the minimum density, while ignoring vertices having strict in-between densities. In this work, we consider a generalized diffusion process, in which vertices in a hyperedge can act as mediators to receive flow from vertices with maximum density and deliver flow to those with minimum density. We show that the resulting Laplacian operator still has a second eigenvalue satisfying the Cheeger&#39;s inequality. Our generalized diffusion model shows that there is a family of operators whose spectral properties are related to hypergraph conductance, and provides a powerful tool to enhance the development of spectral hypergraph theory. Moreover, since every vertex can participate in the new diffusion model at every instant, this can potentially have wider practical applications.},
  archive      = {J_TCS},
  author       = {T.-H. Hubert Chan and Zhibin Liang},
  doi          = {10.1016/j.tcs.2019.07.024},
  journal      = {Theoretical Computer Science},
  pages        = {416-428},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Generalizing the hypergraph laplacian via a diffusion process with mediators},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bipartite graphs of small readability. <em>TCS</em>,
<em>806</em>, 402–415. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a parameter of bipartite graphs called readability, introduced by Chikhi et al. ( Discrete Applied Mathematics , 2016) and motivated by applications of overlap graphs in bioinformatics. The behavior of the parameter is poorly understood. The complexity of computing it is open and it is not known whether the decision version of the problem is in NP. The only known upper bound on the readability of a bipartite graph (following from a work of Braga and Meidanis, LATIN 2002) is exponential in the maximum degree of the graph. Graphs that arise in bioinformatics applications have low readability. In this paper, we focus on graph families with readability o ( n ) o(n) , where n is the number of vertices. We show that the readability of n -vertex bipartite chain graphs is between Ω ( log ⁡ n ) Ω(log⁡n) and O ( n ) O(n) . We give an efficiently testable characterization of bipartite graphs of readability at most 2 and completely determine the readability of grids, showing in particular that their readability never exceeds 3. As a consequence, we obtain a polynomial time algorithm to determine the readability of induced subgraphs of grids. One of the highlights of our techniques is the appearance of Euler&#39;s totient function in the analysis of the readability of bipartite chain graphs. We also develop a new technique for proving lower bounds on readability, which is applicable to dense graphs with a large number of distinct degrees.},
  archive      = {J_TCS},
  author       = {Rayan Chikhi and Vladan Jovičić and Stefan Kratsch and Paul Medvedev and Martin Milanič and Sofya Raskhodnikova and Nithin Varma},
  doi          = {10.1016/j.tcs.2019.07.022},
  journal      = {Theoretical Computer Science},
  pages        = {402-415},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Bipartite graphs of small readability},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minsum k-sink problem on path networks. <em>TCS</em>,
<em>806</em>, 388–401. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of locating a set of k sinks on a path network with general edge capacities that minimizes the sum of the evacuation times of all evacuees. We first present an O ( k n log 4 ⁡ n ) O(knlog4⁡n) time algorithm when the edge capacities are non-uniform, where n is the number of vertices. We then present an O ( k n log 3 ⁡ n ) O(knlog3⁡n) time algorithm when the edge capacities are uniform. We also present an O ( n log ⁡ n ) O(nlog⁡n) time algorithm for the special case where k = 1 k=1 and the edge capacities are non-uniform.},
  archive      = {J_TCS},
  author       = {Robert Benkoczi and Binay Bhattacharya and Yuya Higashikawa and Tsunehiko Kameda and Naoki Katoh},
  doi          = {10.1016/j.tcs.2019.05.047},
  journal      = {Theoretical Computer Science},
  pages        = {388-401},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Minsum k-sink problem on path networks},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The cost of global broadcast in dynamic radio networks.
<em>TCS</em>, <em>806</em>, 363–387. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the time complexity of single and multi token broadcast in adversarial dynamic radio networks. Initially, k tokens (which are k pieces of information) are distributed among the n nodes of a network and all the tokens need to be disseminated to all the nodes in the network. We first consider the single-token broadcast problem (i.e., the case k = 1 k=1 ). By presenting upper and lower bounds , we show that the time complexity of single-token broadcast depends on the amount of stability and connectivity of the dynamic network topology and on the adaptiveness of the adversary providing the dynamic topology . Then, we give two generic algorithms which allow to transform generalized forms of single-token broadcast algorithms into multi-token broadcast ( k -token broadcast) algorithms. Based on these generic algorithms , we obtain k -token broadcast algorithms for a number of different dynamic network settings. For one of the modeling assumptions, our algorithm is complemented by a lower bound which shows that the upper bound is close to optimal.},
  archive      = {J_TCS},
  author       = {Mohamad Ahmadi and Abdolhamid Ghodselahi and Fabian Kuhn and Anisur Rahaman Molla},
  doi          = {10.1016/j.tcs.2019.07.013},
  journal      = {Theoretical Computer Science},
  pages        = {363-387},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The cost of global broadcast in dynamic radio networks},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The metric dimension of zn×zn×zn is ⌊3n/2⌋. <em>TCS</em>,
<em>806</em>, 344–362. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we determine the metric dimension of Z n × Z n × Z n Zn×Zn×Zn as ⌊ 3 n / 2 ⌋ ⌊3n/2⌋ for all n ≥ 2 n≥2 . We prove this result by investigating a variant of Mastermind. Mastermind is a famous two-player game that has attracted much attention in the literature in recent years. In particular we consider the static (also called non-adaptive) black-peg variant of Mastermind. The game is played by a codemaker and a codebreaker . Given c colors and p pegs, the principal rule is that the codemaker has to choose a secret by assigning colors to the pegs, i.e., the secret is a p -tuple of colors, and the codebreaker asks a number of questions all at once. Like the secret, a question is a p -tuple of colors chosen from the c available colors. The codemaker then answers all of those questions by telling the codebreaker how many pegs in each question are correctly colored. The goal is to find the minimal number of questions that allows the codebreaker to determine the secret from the received answers. We present such a strategy for this game for p = 3 p=3 pegs and an arbitrary number c ≥ 2 c≥2 of colors using ⌊ 3 c / 2 ⌋ + 1 ⌊3c/2⌋+1 questions, which we prove to be both feasible and optimal. The minimal number of questions required for p pegs and c colors is easily seen to be equal to the metric dimension of Z c p Zcp plus 1 which proves our main result.},
  archive      = {J_TCS},
  author       = {Gerold Jäger and Frank Drewes},
  doi          = {10.1016/j.tcs.2019.05.042},
  journal      = {Theoretical Computer Science},
  pages        = {344-362},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The metric dimension of Zn×Zn×Zn is ⌊3n/2⌋},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reconfiguration of satisfying assignments and subset sums:
Easy to find, hard to connect. <em>TCS</em>, <em>806</em>, 332–343. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the computational complexity of reconfiguration problems, in which one is given two combinatorial configurations satisfying some constraints, and is asked to transform one into the other using elementary operations, while satisfying the constraints at all times. Such problems appear naturally in many contexts, such as model checking, motion planning, enumeration, sampling, and recreational mathematics. We provide hardness results for problems in this family, in which the constraints and operations are particularly simple. More precisely, we prove the PSPACE -completeness of the following decision problems:},
  archive      = {J_TCS},
  author       = {Jean Cardinal and Erik D. Demaine and David Eppstein and Robert A. Hearn and Andrew Winslow},
  doi          = {10.1016/j.tcs.2019.05.028},
  journal      = {Theoretical Computer Science},
  pages        = {332-343},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reconfiguration of satisfying assignments and subset sums: Easy to find, hard to connect},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A strongly polynomial time algorithm for the maximum supply
rate problem on trees. <em>TCS</em>, <em>806</em>, 323–331. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suppose that we are given a graph whose each vertex is either a supply vertex or a demand vertex and is assigned a nonnegative integer supply or demand value. We consider partitioning G into connected components by removing edges from G so that each connected component has exactly one supply vertex and there exists a flow in each connected component satisfying the supply/demand constraints. The problem that determines the existence of such a partition is called the partition problem. Ito et al. (2005) showed that the partition problem is NP NP -complete in general and it can be solved in linear time if the given graph is a tree. When the graph does not have such a partition, we scale the demand values uniformly by scale factor r so that the obtained graph has a desired partition. The maximum supply rate problem is the problem that finds the maximum value of such r . Whereas the maximum supply rate problem is NP NP -hard in general in the same way as the partition problem, Morishita and Nishizeki (2015) gave a weakly polynomial-time algorithm for the problem on trees. In this paper, we give a first strongly polynomial-time algorithm for the maximum supply rate problem on trees. Our algorithm is based on the dynamic programming technique, in which we compute “surplus” and “deficit” of the supply in subproblems from leaves to the root. We use piecewise linear functions of r to represent them, and one of our important contributions is to bound the size of the representation of each function.},
  archive      = {J_TCS},
  author       = {Koki Takayama and Yusuke Kobayashi},
  doi          = {10.1016/j.tcs.2019.05.014},
  journal      = {Theoretical Computer Science},
  pages        = {323-331},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A strongly polynomial time algorithm for the maximum supply rate problem on trees},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Enumeration of nonisomorphic interval graphs and
nonisomorphic permutation graphs. <em>TCS</em>, <em>806</em>, 310–322.
(<a href="https://doi.org/10.1016/j.tcs.2019.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a general framework for enumerating every element in a graph class is given. The main feature of this framework is that it is designed to enumerate only nonisomorphic graphs in a graph class. Applying this framework to the classes of interval graphs and permutation graphs, we give efficient enumeration algorithms for these graph classes such that each element in the class is output in a polynomial time delay. The experimental results are also given. The catalogs of graphs in these graph classes are also provided.},
  archive      = {J_TCS},
  author       = {Kazuaki Yamazaki and Toshiki Saitoh and Masashi Kiyomi and Ryuhei Uehara},
  doi          = {10.1016/j.tcs.2019.04.017},
  journal      = {Theoretical Computer Science},
  pages        = {310-322},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Enumeration of nonisomorphic interval graphs and nonisomorphic permutation graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Calculating an upper bound of the locating-chromatic number
of trees. <em>TCS</em>, <em>806</em>, 305–309. (<a
href="https://doi.org/10.1016/j.tcs.2019.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The locating-chromatic number of a graph G ( V , E ) G(V,E) is the cardinality of a minimum resolving partition of the vertex set V ( G ) V(G) such that all vertices have distinct coordinates with respect to this partition and every two adjacent vertices not contained in the same partition class. Determining the locating-chromatic number of any tree is a difficult task. In this paper, we propose an algorithm to compute the upper bound on the locating-chromatic number of any tree. To do so, we decompose a tree into caterpillars and then compute the upper bound of the locating-chromatic number of this tree in terms of the ones for these caterpillars.},
  archive      = {J_TCS},
  author       = {Hilda Assiyatun and Dian Kastika Syofyan and Edy Tri Baskoro},
  doi          = {10.1016/j.tcs.2019.04.011},
  journal      = {Theoretical Computer Science},
  pages        = {305-309},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Calculating an upper bound of the locating-chromatic number of trees},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Parametrised second-order complexity theory with
applications to the study of interval computation. <em>TCS</em>,
<em>806</em>, 281–304. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the framework for complexity of operators in analysis devised by Kawamura and Cook (2012) to allow for the treatment of a wider class of representations. The main novelty is to endow represented spaces of interest with an additional function on names, called a parameter, which measures the complexity of a given name. This parameter generalises the size function which is usually used in second-order complexity theory and therefore also central to the framework of Kawamura and Cook. The complexity of an algorithm is measured in terms of its running time as a second-order function in the parameter, as well as in terms of how much it increases the complexity of a given name, as measured by the parameters on the input and output side. As an application we develop a rigorous computational complexity theory for interval computation. In the framework of Kawamura and Cook the representation of real numbers based on nested interval enclosures does not yield a reasonable complexity theory. In our new framework this representation is polytime equivalent to the usual Cauchy representation based on dyadic rational approximation . By contrast, the representation of continuous real functions based on interval enclosures is strictly smaller in the polytime reducibility lattice than the usual representation, which encodes a modulus of continuity. Furthermore, the function space representation based on interval enclosures is optimal in the sense that it contains the minimal amount of information amongst those representations which render evaluation polytime computable.},
  archive      = {J_TCS},
  author       = {Eike Neumann and Florian Steinberg},
  doi          = {10.1016/j.tcs.2019.05.009},
  journal      = {Theoretical Computer Science},
  pages        = {281-304},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Parametrised second-order complexity theory with applications to the study of interval computation},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for the p-hub center routing
problem in parameterized metric graphs. <em>TCS</em>, <em>806</em>,
271–280. (<a href="https://doi.org/10.1016/j.tcs.2019.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G = ( V , E , w ) G=(V,E,w) be a Δ β Δβ -metric graph with a distance function w ( ⋅ , ⋅ ) w(⋅,⋅) on V such that w ( v , v ) = 0 w(v,v)=0 , w ( u , v ) = w ( v , u ) w(u,v)=w(v,u) , and w ( u , v ) ≤ β ⋅ ( w ( u , x ) + w ( x , v ) ) w(u,v)≤β⋅(w(u,x)+w(x,v)) for all u , v , x ∈ V u,v,x∈V . Given a positive integer p , let H be a spanning subgraph of G satisfying the conditions that vertices ( hubs ) in C ⊂ V C⊂V form a clique of size at most p in H , vertices ( non-hubs ) in V ∖ C V∖C form an independent set in H , and each non-hub v ∈ V ∖ C v∈V∖C is adjacent to exactly one hub in C . Define d H ( u , v ) = w ( u , f ( u ) ) + w ( f ( u ) , f ( v ) ) + w ( v , f ( v ) ) dH(u,v)=w(u,f(u))+w(f(u),f(v))+w(v,f(v)) where f ( u ) f(u) and f ( v ) f(v) are hubs adjacent to u and v in H respectively. Notice that if u is a hub in H then w ( u , f ( u ) ) = 0 w(u,f(u))=0 . Let r ( H ) = ∑ u , v ∈ V d H ( u , v ) r(H)=∑u,v∈VdH(u,v) be the routing cost of H . The Single Allocation at most p -Hub Center Routing problem is to find a spanning subgraph H of G such that r ( H ) r(H) is minimized. In this paper, we show that the Single Allocation at most p -Hub Center Routing problem is NP-hard in Δ β Δβ -metric graphs for any β &gt; 1 / 2 β&amp;gt;1/2 . Moreover, we give 2 β -approximation algorithms running in time O ( n 2 ) O(n2) for any β &gt; 1 / 2 β&amp;gt;1/2 where n is the number of vertices in the input graph. Finally, we show that the approximation ratio of our algorithms is at least Ω ( β ) Ω(β) , and we examine the structure of any potential o ( β ) o(β) -approximation algorithm.},
  archive      = {J_TCS},
  author       = {Li-Hsuan Chen and Sun-Yuan Hsieh and Ling-Ju Hung and Ralf Klasing},
  doi          = {10.1016/j.tcs.2019.05.008},
  journal      = {Theoretical Computer Science},
  pages        = {271-280},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithms for the p-hub center routing problem in parameterized metric graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Fixed-parameter tractability for minimum tree cut/paste
distance and minimum common integer partition. <em>TCS</em>,
<em>806</em>, 256–270. (<a
href="https://doi.org/10.1016/j.tcs.2019.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational biology is mainly concerned with discovering an object from a given set of observations that are supposed to be good approximations of the real object. Two important steps here are to define a way to measure the distance between different objects and to calculate the distance between two given objects. The main problem is then to find an object that has the minimum total distance to the given observations. We study two NP-hard problems formulated in computational biology. The minimum tree cut/paste distance problem asks for the minimum number of cut/paste operations we need to transform a tree to another tree. The minimum common integer partition problem asks for a minimum-cardinality integer partition of a number that refines two given integer partitions of the same number. We give parameterized algorithms for both problems.},
  archive      = {J_TCS},
  author       = {Jie You and Feng Shi and Jianxin Wang and Qilong Feng},
  doi          = {10.1016/j.tcs.2019.04.003},
  journal      = {Theoretical Computer Science},
  pages        = {256-270},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Fixed-parameter tractability for minimum tree cut/paste distance and minimum common integer partition},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beachcombing on strips and islands. <em>TCS</em>,
<em>806</em>, 236–255. (<a
href="https://doi.org/10.1016/j.tcs.2019.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A group of mobile robots (beachcombers) have to search collectively every point of a given domain. At any given moment, each robot can be in walking mode or in searching mode . It is assumed that each robot&#39;s maximum allowed searching speed is strictly smaller than its maximum allowed walking speed. A point of the domain is searched if at least one of the robots visits it in searching mode. The Beachcombers&#39; Problem consists in developing efficient schedules (algorithms) for the robots which collectively search all the points of the given domain as fast as possible. We consider searching schedules in the following one-dimensional geometric domains : the cycle of a known circumference L , the finite straight line segment of a known length L , and the semi-infinite line [ 0 , + ∞ ) [0,+∞) . We first consider the online Beachcombers&#39; Problem (i.e. the scenario when the robots do not know in advance the length of the segment to be searched), where the robots are initially collocated at the origin of a semi-infinite line. It is sought to design a schedule A with maximum speed S , defined as S = inf ℓ ⁡ ℓ t A ( ℓ ) S=infℓ⁡ℓtA(ℓ) , where t A ( ℓ ) tA(ℓ) denotes the time when the search of the segment [ 0 , ℓ ] [0,ℓ] is completed under A . We consider a discrete and a continuous version of the problem, depending on whether the infimum is taken over ⁎ ℓ ∈ N ⁎ ℓ∈N⁎ or ℓ ≥ 1 ℓ≥1 . We prove that the LeapFrog algorithm, which was proposed in Czyzowicz et al. (2015) [12] , is in fact optimal in the discrete case. This settles in the affirmative a conjecture from that paper. We also show how to extend this result to the more general continuous online setting. For the offline version of the Beachcombers&#39; Problem (i.e. the scenario when the robots know in advance the length of the segment to be searched), we consider the t-source Beachcombers&#39; Problem (i.e. all robots start from a fixed number t ≥ 1 t≥1 of starting positions) on the cycle and on the finite segment. For the t-source Beachcombers&#39; Problem on the cycle, we show that the structure of the optimal solutions is identical to the structure of the optimal solutions to the 2 t -source Beachcombers&#39; Problem on a finite segment. In consequence, by using results from Czyzowicz et al. (2014) [13] , we prove that the 1-source Beachcombers&#39; Problem on the cycle is NP-hard, and we derive approximation algorithms for the problem. For the t-source variant of the Beachcombers&#39; Problem on the cycle and on the finite segment, we also derive efficient approximation algorithms . One important contribution of our work is that, in all variants of the offline Beachcombers&#39; Problem that we discuss, we allow the robots to change direction of movement and search points of the domain on both sides of their respective starting positions. This represents a significant generalization compared to the model considered in Czyzowicz et al. (2014) [13] , in which each robot had a fixed direction of movement that was specified as part of the solution to the problem. We manage to prove that changes of direction do not help the robots achieve optimality .},
  archive      = {J_TCS},
  author       = {Evangelos Bampas and Jurek Czyzowicz and David Ilcinkas and Ralf Klasing},
  doi          = {10.1016/j.tcs.2019.04.001},
  journal      = {Theoretical Computer Science},
  pages        = {236-255},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Beachcombing on strips and islands},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new kind of selectors and their applications to conflict
resolution in wireless multichannels networks. <em>TCS</em>,
<em>806</em>, 219–235. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the benefits of using multiple channels in wireless networks, under the full-duplex multi-packet reception model of communication. The main question we address is the following: Is a speedup linear in the number of channels available, for some interesting communication primitive? We provide a positive answer to this interrogative for the Information Exchange Problem , in which up to k arbitrary nodes have information they intend to share with the entire network. In particular, we give non-adaptive deterministic protocols for both the scenario in which the channels provide the transmitting stations with the feedback on whether their transmissions have been successful and for the scenario in which channels provide no such feedback. To this aim, we devise and exploit a new combinatorial structure that generalizes well known combinatorial tools, widely used in the area of data-exchange in multiple-access channels (i.e., strongly selective families, selectors, and related mathematical objects). For our new combinatorial structures we provide both existential results and randomized algorithms to generate them. We also prove non-existence results showing that our protocol for the model with feedback is optimal, whereas that for the no-feedback scenario uses a number of time slots that exceeds the lower bound by a log ⁡ k log⁡k factor. Leveraging on properties of error correcting codes , we show that for an infinite set of the relevant parameters n and k , one can construct our combinatorial structure for the no-feedback scenario in polynomial time and of minimum length.},
  archive      = {J_TCS},
  author       = {Annalisa De Bonis and Ugo Vaccaro},
  doi          = {10.1016/j.tcs.2019.03.034},
  journal      = {Theoretical Computer Science},
  pages        = {219-235},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A new kind of selectors and their applications to conflict resolution in wireless multichannels networks},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal graph classes: A view through temporal separators.
<em>TCS</em>, <em>806</em>, 197–218. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate for temporal graphs the computational complexity of separating two distinct vertices s and z by vertex deletion. In a temporal graph, the vertex set is fixed but the edges have (discrete) time labels. Since the corresponding Temporal ( s , z ) (s,z) -Separation problem is NP -complete, it is natural to investigate whether relevant special cases exist that are computationally tractable. To this end, we study restrictions of the underlying (static) graph—there we observe polynomial-time solvability in the case of bounded treewidth—as well as restrictions concerning the “temporal evolution” along the time steps. Systematically studying partially novel concepts in this direction, we identify sharp borders between tractable and intractable cases.},
  archive      = {J_TCS},
  author       = {Till Fluschnik and Hendrik Molter and Rolf Niedermeier and Malte Renken and Philipp Zschoche},
  doi          = {10.1016/j.tcs.2019.03.031},
  journal      = {Theoretical Computer Science},
  pages        = {197-218},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Temporal graph classes: A view through temporal separators},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal matching. <em>TCS</em>, <em>806</em>, 184–196. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A link stream is a sequence of pairs of the form (t,{u,v}) , where t∈N represents a time instant and u≠v . Given an integer γ , the γ -edge between vertices u and v , starting at time t , is the set of temporally consecutive edges defined by 〚 〛 {(t′,{u,v})|t′∈〚t,t+γ−1〛} . We introduce the notion of temporal matching of a link stream to be an independent γ -edge set belonging to the link stream. We show that the problem of computing a temporal matching of maximum size is NP-hard as soon as γ&amp;gt;1 . We depict a kernelization algorithm parameterized by the solution size for the problem. As a byproduct we also give a 2-approximation algorithm. Both our 2-approximation and kernelization algorithms are implemented and confronted to link streams collected from real world graph data. We observe that finding temporal matchings is a sensitive question when mining our data from such a perspective as: managing peer-working when any pair of peers X and Y are to collaborate over a period of one month, at an average rate of at least two email exchanges every week. We furthermore design a link stream generating process by mimicking the behavior of a random moving group of particles under natural simulation, and confront our algorithms to these generated instances of link streams. All the implementations are open source.},
  archive      = {J_TCS},
  author       = {Julien Baste and Binh-Minh Bui-Xuan and Antoine Roux},
  doi          = {10.1016/j.tcs.2019.03.026},
  journal      = {Theoretical Computer Science},
  pages        = {184-196},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Temporal matching},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the broadcast domination number of permutation graphs.
<em>TCS</em>, <em>806</em>, 171–183. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broadcast domination models the idea of covering a network of cities by transmitters of varying powers while minimizing the total cost of the transmitters used to achieve full coverage. To be exact, let G be a connected graph of order at least two with vertex set V ( G ) V(G) and edge set E ( G ) E(G) . Let d ( x , y ) d(x,y) , e ( v ) e(v) , and diam ( G ) diam(G) , respectively, denote the length of a shortest x − y x−y path in G , the eccentricity of a vertex v in G , and the diameter of G . A function f : V ( G ) → { 0 , 1 , … , diam ( G ) } f:V(G)→{0,1,…,diam(G)} is called a broadcast if f ( v ) ≤ e ( v ) f(v)≤e(v) for each v ∈ V ( G ) v∈V(G) . A broadcast f is called a dominating broadcast of G if, for each vertex u ∈ V ( G ) u∈V(G) , there exists a vertex v ∈ V ( G ) v∈V(G) such that f ( v ) &gt; 0 f(v)&amp;gt;0 and d ( u , v ) ≤ f ( v ) d(u,v)≤f(v) . The broadcast domination number , γ b ( G ) γb(G) , of G is the minimum of ∑ v ∈ V ( G ) f ( v ) ∑v∈V(G)f(v) over all dominating broadcasts f on G . Let G 1 G1 and G 2 G2 be two disjoint copies of a graph G , and let σ : V ( G 1 ) → V ( G 2 ) σ:V(G1)→V(G2) be a bijection . Then a permutation graph G σ = ( V , E ) Gσ=(V,E) has vertex set V = V ( G 1 ) ∪ V ( G 2 ) V=V(G1)∪V(G2) and edge set E = E ( G 1 ) ∪ E ( G 2 ) ∪ { u v : v = σ ( u ) } E=E(G1)∪E(G2)∪{uv:v=σ(u)} . For a connected graph G of order at least two, we prove the sharp bounds 2 ≤ γ b ( G σ ) ≤ 2 γ b ( G ) 2≤γb(Gσ)≤2γb(G) ; we give an example showing that there is no function h such that γ b ( G ) γb(G)&amp;lt;h(γb(Gσ)) for all pairs ( G , σ ) (G,σ) . We characterize G σ Gσ satisfying γ b ( G σ ) = 2 γb(Gσ)=2 , and examine γ b ( G σ ) γb(Gσ) when G is a cycle, a path, or a complete multipartite graph.},
  archive      = {J_TCS},
  author       = {Eunjeong Yi},
  doi          = {10.1016/j.tcs.2019.03.025},
  journal      = {Theoretical Computer Science},
  pages        = {171-183},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the broadcast domination number of permutation graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The solid-metric dimension. <em>TCS</em>, <em>806</em>,
156–170. (<a href="https://doi.org/10.1016/j.tcs.2019.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolving sets are designed to locate an object in a network by measuring the distances to the object. However, if there are more than one object present in the network, this can lead to wrong conclusions. To overcome this problem, we introduce the concept of solid-resolving sets. In this paper, we study the structure and constructions of solid-resolving sets. In particular, we classify the forced vertices with respect to a solid-resolving set. We also give bounds on the solid-metric dimension utilizing concepts like the Dilworth number, the boundary of a graph, and locating-dominating sets. It is also shown that deciding whether there exists a solid-resolving set with a certain number of elements is an NP-complete problem.},
  archive      = {J_TCS},
  author       = {Anni Hakanen and Ville Junnila and Tero Laihonen},
  doi          = {10.1016/j.tcs.2019.02.013},
  journal      = {Theoretical Computer Science},
  pages        = {156-170},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The solid-metric dimension},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Neighbor-locating colorings in graphs. <em>TCS</em>,
<em>806</em>, 144–155. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k-coloring of a graph G is a k -partition Π = { S 1 , … , S k } Π={S1,…,Sk} of V ( G ) V(G) into independent sets, called colors . A k -coloring is called neighbor-locating if for every pair of vertices u , v u,v belonging to the same color S i Si , the set of colors of the neighborhood of u is different from the set of colors of the neighborhood of v . The neighbor-locating chromatic number χ N L ( G ) χNL(G) is the minimum cardinality of a neighbor-locating coloring of G . We establish some tight bounds for the neighbor-locating chromatic number of a graph, in terms of its order, maximum degree and independence number. We determine all connected graphs of order n ≥ 5 n≥5 with neighbor-locating chromatic number n or n − 1 n−1 . We examine the neighbor-locating chromatic number for two graph operations: join and disjoint union, and also for two graph families: split graphs and Mycielski graphs.},
  archive      = {J_TCS},
  author       = {Liliana Alcon and Marisa Gutierrez and Carmen Hernando and Mercè Mora and Ignacio M. Pelayo},
  doi          = {10.1016/j.tcs.2019.01.039},
  journal      = {Theoretical Computer Science},
  pages        = {144-155},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Neighbor-locating colorings in graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Alternative parameterizations of metric dimension.
<em>TCS</em>, <em>806</em>, 133–143. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set of vertices W in a graph G is called resolving if for any two distinct x , y ∈ V ( G ) x,y∈V(G) , there is v ∈ W v∈W such that d G ( v , x ) ≠ d G ( v , y ) dG(v,x)≠dG(v,y) , where d G ( u , v ) dG(u,v) denotes the length of a shortest path between u and v in the graph G . The metric dimension md ( G ) md(G) of G is the minimum cardinality of a resolving set. The Metric Dimension problem, i.e. deciding whether md ( G ) ⩽ k md(G)⩽k , is NP-complete even for interval graphs (Foucaud et al., 2017). We study Metric Dimension (for arbitrary graphs) from the lens of parameterized complexity. The problem parameterized by k was proved to be W [ 2 ] W[2] -hard by Hartung and Nichterlein (2013) and we study the dual parameterization, i.e., the problem of whether md ( G ) ⩽ n − k md(G)⩽n−k , where n is the order of G . We prove that the dual parameterization admits (a) a kernel with at most 6 ( k + 1 ) 6(k+1) vertices and (b) a randomized algorithm of runtime ⁎ O ⁎ ( 4 k + o ( k ) ) O⁎(4k+o(k)) . Hartung and Nichterlein (2013) also observed that Metric Dimension is fixed-parameter tractable when parameterized by the vertex cover number v c ( G ) vc(G) of the input graph. We complement this observation by showing that it does not admit a polynomial kernel even when parameterized by v c ( G ) + k vc(G)+k , unless NP ⊆ coNP/poly. Our reduction also gives evidence for non-existence of polynomial Turing kernels. We also prove that Metric Dimension parameterized by bandwidth or cutwidth does not admit a polynomial kernel, unless NP ⊆ coNP/poly. Finally, using Eppstein&#39;s results (2015) we show that Metric Dimension parameterized by max-leaf number does admit a polynomial kernel.},
  archive      = {J_TCS},
  author       = {Gregory Gutin and M.S. Ramanujan and Felix Reidl and Magnus Wahlström},
  doi          = {10.1016/j.tcs.2019.01.028},
  journal      = {Theoretical Computer Science},
  pages        = {133-143},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Alternative parameterizations of metric dimension},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Recognizing binary shuffle squares is NP-hard. <em>TCS</em>,
<em>806</em>, 116–132. (<a
href="https://doi.org/10.1016/j.tcs.2019.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A shuffle of two words is formed by interleaving the characters into a new word, keeping the characters of each word in order. A word is a shuffle square if it is a shuffle of two identical words. Deciding whether a word is a shuffle square has been proved to be NP -complete independently by Buss and Soltys [5] and Rizzi and Vialette [20] , the former proving the result for alphabets as small as 9 letters. We prove in this paper that deciding whether a binary word is a shuffle square is NP -complete.},
  archive      = {J_TCS},
  author       = {Laurent Bulteau and Stéphane Vialette},
  doi          = {10.1016/j.tcs.2019.01.012},
  journal      = {Theoretical Computer Science},
  pages        = {116-132},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Recognizing binary shuffle squares is NP-hard},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An information-theoretic framework for the lossy compression
of link streams. <em>TCS</em>, <em>806</em>, 90–115. (<a
href="https://doi.org/10.1016/j.tcs.2018.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph compression is a data analysis technique that consists in the replacement of parts of a graph by more concise structural patterns in order to reduce its description length. It notably provides interesting exploration tools for the study of real, large-scale, and complex graphs which cannot be grasped at first glance. This article proposes a framework for the compression of temporal graphs , that is for the compression of graphs that evolve with time. This framework first builds on a simple and limited scheme, exploiting structural equivalence for the lossless compression of static graphs, then generalises it to the lossy compression of link streams, a recent formalism for the study of temporal graphs . Such generalisation builds on the natural extension of (bidimensional) relational data by the addition of a third temporal dimension. Moreover, we introduce an information-theoretic measure to quantify and to control the information that is lost during compression, as well as an algebraic characterisation of the space of possible compression patterns to enhance the expressiveness of the initial compression scheme . These contributions lead to the definition of a combinatorial optimisation problem , that is the Lossy Multistream Compression Problem , for which we provide an exact algorithm.},
  archive      = {J_TCS},
  author       = {Robin Lamarche-Perrin},
  doi          = {10.1016/j.tcs.2018.12.009},
  journal      = {Theoretical Computer Science},
  pages        = {90-115},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An information-theoretic framework for the lossy compression of link streams},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Boosting over non-deterministic ZDDs. <em>TCS</em>,
<em>806</em>, 81–89. (<a
href="https://doi.org/10.1016/j.tcs.2018.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new approach to large-scale machine learning , learning over compressed data : First compress the training data somehow and then employ various machine learning algorithms on the compressed data, with the hope that the computation time is significantly reduced when the training data is well compressed. As a first step toward this approach, we consider a variant of the Zero-Suppressed Binary Decision Diagram (ZDD) as the data structure for representing the training data, which is a generalization of the ZDD by incorporating non-determinism. For the learning algorithm to be employed, we consider a boosting algorithm called AdaBoost⁎ and its precursor AdaBoost. In this paper, we give efficient implementations of the boosting algorithms whose running times (per iteration) are linear in the size of the given ZDD.},
  archive      = {J_TCS},
  author       = {Takahiro Fujita and Kohei Hatano and Eiji Takimoto},
  doi          = {10.1016/j.tcs.2018.11.027},
  journal      = {Theoretical Computer Science},
  pages        = {81-89},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Boosting over non-deterministic ZDDs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improvement of the algorithm of hertli for the unique
3SAT problem. <em>TCS</em>, <em>806</em>, 70–80. (<a
href="https://doi.org/10.1016/j.tcs.2018.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a simple idea for improving the randomized algorithm of Hertli (2014) [2] for the Unique 3SAT problem. Using recently developed techniques (Hertli (2015) [3] and Scheder–Steinberger (2017) [7] ), we can derive from this algorithm currently the fastest randomized algorithm for the general 3SAT problem. Though the efficiency improvement is extremely small, we hope that this idea would lead to better improvements.},
  archive      = {J_TCS},
  author       = {Tong Qin and Osamu Watanabe},
  doi          = {10.1016/j.tcs.2018.11.023},
  journal      = {Theoretical Computer Science},
  pages        = {70-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An improvement of the algorithm of hertli for the unique 3SAT problem},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The connected metric dimension at a vertex of a graph.
<em>TCS</em>, <em>806</em>, 53–69. (<a
href="https://doi.org/10.1016/j.tcs.2018.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of metric dimension , dim⁡(G) , of a graph G , as well as a number of variants, is now well studied. In this paper, we begin a local analysis of this notion by introducing cdimG(v) , the connected metric dimension of G at a vertex v , which is defined as follows: a set of vertices S of G is a resolving set if, for any pair of distinct vertices x and y of G , there is a vertex z∈S such that the distance between z and x is distinct from the distance between z and y in G . We say that a resolving set S is connected if S induces a connected subgraph of G . Then, cdimG(v) is defined to be the minimum of the cardinalities of all connected resolving sets which contain the vertex v . The connected metric dimension of G , denoted by cdim(G) , is min⁡{cdimG(v):v∈V(G)} . Noting that 1≤dim⁡(G)≤cdim(G)≤cdimG(v)≤|V(G)|−1 for any vertex v of G , we show the existence of a pair (G,v) such that cdimG(v) takes all positive integer values from dim⁡(G) to |V(G)|−1 , as v varies in a fixed graph G . We characterize graphs G and their vertices v satisfying cdimG(v)∈{1,|V(G)|−1} . We show that cdim(G)=2 implies G is planar, whereas it is well known that there is a non-planar graph H with dim⁡(H)=2 . We also characterize trees and unicyclic graphs G satisfying cdim(G)=dim⁡(G) . We show that cdim(G)−dim⁡(G) can be arbitrarily large. We determine cdim(G) and cdimG(v) for some classes of graphs. We further examine the effect of vertex or edge deletion on the connected metric dimension. We conclude with some open problems.},
  archive      = {J_TCS},
  author       = {Linda Eroh and Cong X. Kang and Eunjeong Yi},
  doi          = {10.1016/j.tcs.2018.11.002},
  journal      = {Theoretical Computer Science},
  pages        = {53-69},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The connected metric dimension at a vertex of a graph},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the k-partition dimension of graphs. <em>TCS</em>,
<em>806</em>, 42–52. (<a
href="https://doi.org/10.1016/j.tcs.2018.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generalization of the concept of the partition dimension of a graph, this article introduces the notion of the k -partition dimension. Given a nontrivial connected graph G = ( V , E ) G=(V,E) , a partition Π of V is said to be a k -partition generator of G if any pair of different vertices u , v ∈ V u,v∈V is distinguished by at least k vertex sets of Π, i.e ., there exist at least k vertex sets S 1 , … , S k ∈ Π S1,…,Sk∈Π such that d ( u , S i ) ≠ d ( v , S i ) d(u,Si)≠d(v,Si) for every i ∈ { 1 , … , k } i∈{1,…,k} . A k -partition generator of G with minimum cardinality among all their k -partition generators is called a k -partition basis of G and its cardinality the k -partition dimension of G . A nontrivial connected graph G is k -partition dimensional if k is the largest integer such that G has a k -partition basis. We give a necessary and sufficient condition for a graph to be r -partition dimensional and we obtain several results on the k -partition dimension for k ∈ { 1 , … , r } k∈{1,…,r} .},
  archive      = {J_TCS},
  author       = {Alejandro Estrada-Moreno},
  doi          = {10.1016/j.tcs.2018.09.022},
  journal      = {Theoretical Computer Science},
  pages        = {42-52},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the k-partition dimension of graphs},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Embedding a θ-invariant code into a complete one.
<em>TCS</em>, <em>806</em>, 28–41. (<a
href="https://doi.org/10.1016/j.tcs.2018.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let A be an arbitrary alphabet and let θ be an (anti-)automorphism of ⁎ A ⁎ A⁎ (by definition, such a correspondence is determinated by a permutation of the alphabet). This paper deals with sets which are invariant under θ ( θ -invariant for short) that is, languages L satisfying θ ( L ) ⊆ L θ(L)⊆L . We establish an extension of the famous defect theorem. With regard to the so-called notion of completeness, we provide a series of examples of finite complete θ -invariant codes. Moreover, we establish a formula which allows to embed any non-complete θ -invariant code into a complete one. As a consequence, in the family of the so-called thin θ -invariant codes, maximality and completeness are two equivalent notions.},
  archive      = {J_TCS},
  author       = {Jean Néraud and Carla Selmi},
  doi          = {10.1016/j.tcs.2018.08.022},
  journal      = {Theoretical Computer Science},
  pages        = {28-41},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Embedding a θ-invariant code into a complete one},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). More on the dynamics of the symbolic square root map.
<em>TCS</em>, <em>806</em>, 10–27. (<a
href="https://doi.org/10.1016/j.tcs.2018.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our earlier paper [Peltomäki and Whiteland (2017) [5] ], we introduced a symbolic square root map. Every optimal squareful infinite word s contains exactly six minimal squares and can be written as a product of these squares: s = X 1 2 X 2 2 ⋯ s=X12X22⋯ . The square root s s of s is the infinite word X 1 X 2 ⋯ X1X2⋯ obtained by deleting half of each square. We proved that the square root map preserves the languages of Sturmian words (which are optimal squareful words). The dynamics of the square root map on a Sturmian subshift are well understood. In our earlier work, we introduced another type of subshift of optimal squareful words which together with the square root map form a dynamical system . In this paper, we study these dynamical systems in more detail and compare their properties to the Sturmian case. The main results are characterizations of periodic points and the limit set. The results show that while there is some similarity it is possible for the square root map to exhibit quite different behavior compared to the Sturmian case.},
  archive      = {J_TCS},
  author       = {Jarkko Peltomäki and Markus A. Whiteland},
  doi          = {10.1016/j.tcs.2018.08.019},
  journal      = {Theoretical Computer Science},
  pages        = {10-27},
  shortjournal = {Theor. Comput. Sci.},
  title        = {More on the dynamics of the symbolic square root map},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cartesian and lyndon trees. <em>TCS</em>, <em>806</em>, 1–9.
(<a href="https://doi.org/10.1016/j.tcs.2018.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article describes the structural and algorithmic relations between Cartesian trees and Lyndon trees. This leads to a uniform presentation of the Lyndon table of a word corresponding to the Next Nearest Smaller table of a sequence of numbers. It shows how to efficiently compute runs, that is, maximal periodicities occurring in a word.},
  archive      = {J_TCS},
  author       = {Maxime Crochemore and Luís M.S. Russo},
  doi          = {10.1016/j.tcs.2018.08.011},
  journal      = {Theoretical Computer Science},
  pages        = {1-9},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cartesian and lyndon trees},
  volume       = {806},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020e). Editorial. <em>TCS</em>, <em>805</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(19)30802-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(19)30802-3},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). When object production tunes the efficiency of membrane
systems. <em>TCS</em>, <em>805</em>, 218–231. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {P systems with active membranes is one of the most studied models within the field of Membrane Computing. Simulating the organization and behavior of the living cells through a tree-like structure and abstracting the mechanisms that help the cell to keep alive into rules (evolution, communication, dissolution and division rules), they have been used to solve several computationally hard problems. We are dealing with non-cooperative systems here, that is, the number of reactives in a rule is always one. Even then, it has been proven that problems from the class PSPACE can be solved, so in order to acquire a minimal model that can solve computationally hard problems, polarizations are removed. In this paper we find the relevance of the length of the right-hand side of the rule, being necessary when using separation rules and being irrelevant when division rules are used, improving some solutions previously presented, restricting the right-hand side of the rules, obtaining new frontiers of efficiency in this framework. The state of the art of these systems is presented in a graphical way.},
  archive      = {J_TCS},
  author       = {David Orellana-Martín and Miguel Á. Martínez-del-Amor and Ignacio Pérez-Hurtado and Agustín Riscos-Núñez and Luis Valencia-Cabrera and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.tcs.2018.04.013},
  journal      = {Theoretical Computer Science},
  pages        = {218-231},
  shortjournal = {Theor. Comput. Sci.},
  title        = {When object production tunes the efficiency of membrane systems},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). P systems with symport/antiport rules: When do the
surroundings matter? <em>TCS</em>, <em>805</em>, 206–217. (<a
href="https://doi.org/10.1016/j.tcs.2018.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cell-like P systems where communication between the regions are carried out by rules of type symport/antiport are considered. These systems compute by changing the places of objects with respect to the membranes, and not by changing the objects themselves. The environment plays an active role in the sense that it not only can receive objects from the system, but also send objects into it. There is an alphabet associated with the environment whose elements appear in an arbitrary large number of copies at the initial configuration . This property seems too strong from a complexity view, but it has been widely exploited in the design of efficient solutions to computationally hard problems when some mechanisms (inspired by mitosis and membrane fission) allowing to construct an exponential workspace in linear time, are considered. In this paper, complexity aspects of P systems with symport/antiport rules and membrane division are considered when the set associated with the environment is the emptyset. It is shown that the role of the environment is irrelevant for such kind of P systems, in contrast with the well known results concerning to its relevance when membrane separation is used instead of membrane division.},
  archive      = {J_TCS},
  author       = {David Orellana-Martín and Miguel Á. Martínez-del-Amor and Luis Valencia-Cabrera and Bosheng Song and Linqiang Pan and Mario J. Pérez-Jiménez},
  doi          = {10.1016/j.tcs.2018.04.052},
  journal      = {Theoretical Computer Science},
  pages        = {206-217},
  shortjournal = {Theor. Comput. Sci.},
  title        = {P systems with symport/antiport rules: When do the surroundings matter?},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Subroutines in p systems and closure properties of their
complexity classes. <em>TCS</em>, <em>805</em>, 193–205. (<a
href="https://doi.org/10.1016/j.tcs.2018.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The literature on membrane computing describes several variants of P systems whose complexity classes C are “closed under exponentiation”, that is, they satisfy the inclusion , where is the class of problems solved by polynomial-time Turing machines with oracles for problems in C . This closure automatically implies closure under many other operations, such as regular operations (union, concatenation, Kleene star), intersection, complement, and polynomial-time mappings, which are inherited from . Such results are typically proved by showing how elements of a family of P systems can be embedded into P systems simulating Turing machines , which exploit the elements of as subroutines. Here we focus on the latter construction, providing a description that, by abstracting from the technical details which depend on the specific variant of P system, describes a general strategy for proving closure under exponentiation . We also provide an example implementation using polarizationless P systems with active membranes and minimal cooperation.},
  archive      = {J_TCS},
  author       = {Alberto Leporati and Luca Manzoni and Giancarlo Mauri and Antonio E. Porreca and Claudio Zandron},
  doi          = {10.1016/j.tcs.2018.06.012},
  journal      = {Theoretical Computer Science},
  pages        = {193-205},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Subroutines in p systems and closure properties of their complexity classes},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local time membrane systems and time petri nets.
<em>TCS</em>, <em>805</em>, 175–192. (<a
href="https://doi.org/10.1016/j.tcs.2018.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the relationship between time Petri nets and various variants of membrane systems . We first show that adding the feature of “time” to Petri nets makes possible the simulation of the maximal parallel mode of rule application from membrane systems without introducing maximal parallelism to the Petri net semantics. Then we define local time membrane systems inspired by time Petri nets , together with two types of semantics; both kinds of local time membrane systems can be simulated by time Petri nets with the strong semantics . Finally we present the connections between catalytic Petri nets and catalytic membrane systems.},
  archive      = {J_TCS},
  author       = {Bogdan Aman and Péter Battyányi and Gabriel Ciobanu and György Vaszil},
  doi          = {10.1016/j.tcs.2018.06.013},
  journal      = {Theoretical Computer Science},
  pages        = {175-192},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Local time membrane systems and time petri nets},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two notes on APCol systems. <em>TCS</em>, <em>805</em>,
161–174. (<a href="https://doi.org/10.1016/j.tcs.2018.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we continue our research in the field of string processing membrane systems – APCol systems. We focus on a relation of APCol systems with PM colonies – colonies whose agents can only perform point mutation transformations of the common string, in a vicinity of the agent. The second part is devoted to a connection of APCol systems and logic circuits using AND, OR and NOT gates.},
  archive      = {J_TCS},
  author       = {Lucie Ciencialová and Luděk Cienciala},
  doi          = {10.1016/j.tcs.2018.07.006},
  journal      = {Theoretical Computer Science},
  pages        = {161-174},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Two notes on APCol systems},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). P systems with randomized right-hand sides of rules.
<em>TCS</em>, <em>805</em>, 144–160. (<a
href="https://doi.org/10.1016/j.tcs.2018.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {P systems are a model of distributed and compartmentalized multiset rewriting, complete with various signal transmission mechanisms. We introduce a novel kind of P systems in which rules are dynamically constructed in each step by non-deterministic pairing of left-hand and right-hand sides. We define three variants of right-hand side randomization and compare each of them with the power of conventional P systems. It turns out that all three variants enable non-cooperative P systems to generate exponential (and thus non-semi-linear) number languages. We also give a binary normal form for one of the variants of P systems with randomized rule right-hand sides. Finally, we also discuss extensions of the three variants to tissue P systems, i.e., P systems on an arbitrary graph structure.},
  archive      = {J_TCS},
  author       = {Artiom Alhazov and Rudolf Freund and Sergiu Ivanov},
  doi          = {10.1016/j.tcs.2018.07.016},
  journal      = {Theoretical Computer Science},
  pages        = {144-160},
  shortjournal = {Theor. Comput. Sci.},
  title        = {P systems with randomized right-hand sides of rules},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Time-freeness and clock-freeness and related concepts in p
systems. <em>TCS</em>, <em>805</em>, 127–143. (<a
href="https://doi.org/10.1016/j.tcs.2018.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the majority of models of P systems , rules are applied at the ticks of a global clock and their products are introduced into the system for the following step. In timed P systems , different integer durations are statically assigned to rules; time-free P systems are P systems yielding the same languages independently of these durations. In clock-free P systems, durations are real and are assigned to individual rule applications; thus, different applications of the same rule may last for a different amount of time. In this paper, we formalise timed, time-free, and clock-free P system within a framework for generalised parallel rewriting. We then explore the relationship between these variants of semantics. We show that clock-free P systems cannot efficiently solve intractable problems. Moreover, we consider un-timed systems where we collect the results using arbitrary timing functions as well as un-clocked P systems where we take the union over all possible per-instance rule durations. Finally, we also introduce and study mode-free P systems, whose results do not depend on the choice of a mode within a fixed family of modes, and compare mode-freeness with clock-freeness.},
  archive      = {J_TCS},
  author       = {Artiom Alhazov and Rudolf Freund and Sergiu Ivanov and Linqiang Pan and Bosheng Song},
  doi          = {10.1016/j.tcs.2018.09.009},
  journal      = {Theoretical Computer Science},
  pages        = {127-143},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Time-freeness and clock-freeness and related concepts in p systems},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020a). Synthesis of a DNF formula from a sample of strings using
ehrenfeucht–fraïssé games. <em>TCS</em>, <em>805</em>, 109–126. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to define a DNF version of first-order sentences over strings in which atomic sentences represent substring properties of strings, we use results of the Ehrenfeucht–Fraïssé game over strings. Then, given a sample of strings and the number of disjunctive clauses, we investigate the problem of finding a DNF formula that is consistent with the sample. We show that this problem is NP-complete, and we solve it by a translation into Boolean satisfiability. We also present an extension of this problem that is robust concerning noisy samples. We solve the generalized version by a codification into the maximum satisfiability problem . As first-order logic over strings defines exactly the class of locally threshold testable (LTT) languages, our results can be useful in the grammatical inference framework when the goal is to find a model of a LTT language from a sample of strings.},
  archive      = {J_TCS},
  author       = {Thiago Alves Rocha and Ana Teresa Martins and Francicleber Martins Ferreira},
  doi          = {10.1016/j.tcs.2019.08.015},
  journal      = {Theoretical Computer Science},
  pages        = {109-126},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Synthesis of a DNF formula from a sample of strings using Ehrenfeucht–Fraïssé games},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Representing planning autonomy in agent organizational
models. <em>TCS</em>, <em>805</em>, 92–108. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organizations are key elements in a multi-agent system, since they promote cooperation between agents by constraining their possible behaviors. However, constraining behavior means diminishing the agents autonomy. In human organizations, agents have different degrees of autonomy: autonomous and more adaptable agents coexist with non-autonomous agents that just follow organizational rules. This work will propose an explicit representation for planning autonomy in agents organizations, particularly using the MOISE organizational model. We propose the use of a domain specification, based on the planning formalism and on goal types. We implemented our representation using the JaCaMo framework in a proof-of-concept scenario showing how a planning autonomous agent can use the SHOP planner to achieve an organizational goal.},
  archive      = {J_TCS},
  author       = {Artur Vidal Maia and Jaime Simão Sichman},
  doi          = {10.1016/j.tcs.2019.09.001},
  journal      = {Theoretical Computer Science},
  pages        = {92-108},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Representing planning autonomy in agent organizational models},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reasoning in BDI agents using toulmin’s argumentation model.
<em>TCS</em>, <em>805</em>, 76–91. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of argumentation pervades several fields of knowledge, and it has gained significant space in multiagent systems because it provides a way for modeling reasoning over conflicting information in intelligent agents. This work proposes the development of an argumentation-based inference mechanism for BDI agents based on Toulmin&#39;s model of argumentation. The philosopher Stephen Toulmin claimed that arguments typically consist of six parts: data, warrant, claim, backing, qualifier, and rebuttal. This argumentation structure allows arguments to be described through separated components, making it easier to define and to evaluate the inference process. By presenting and discussing some case studies, this paper shows how this mechanism supports the inference of new beliefs based on available evidence within BDI agents programmed in an agent-oriented programming language .},
  archive      = {J_TCS},
  author       = {Vágner de Oliveira Gabriel and Alison R. Panisson and Rafael H. Bordini and Diana Francisca Adamatti and Cleo Zanella Billa},
  doi          = {10.1016/j.tcs.2019.10.026},
  journal      = {Theoretical Computer Science},
  pages        = {76-91},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Reasoning in BDI agents using toulmin&#39;s argumentation model},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the use of fitness landscape features in meta-learning
based algorithm selection for the quadratic assignment problem.
<em>TCS</em>, <em>805</em>, 62–75. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristics perform differently depending on the problem instance they are solving, meaning that manually choosing an algorithm is not trivial and an automatic selection is desirable. This task can be addressed using a meta-learning approach, which relates the characteristics of the problem instances to the performance of a set of solving algorithms. Therefore, the success of such approach is based on the quality of the extracted set of features. Some studies have proposed the use of features based on Fitness Landscape Analysis (FLA) to characterize optimization problems . However, extracting measures based on FLA usually requires a high computational effort. In a previous work, we have employed meta-heuristic selection on the Quadratic Assignment Problem (QAP) using some FLA measures. This research extends our study by including additional FLA meta-features, by using a less costly extraction method, and by considering more QAP instances. In total, we built five multi-label datasets, each composed of meta-features that were extracted by different sampling sizes, and then we used them to train Random Forest classifiers . Besides presenting satisfactory classification performance, and a decrease in time consumption in relation to our previous work, this selection approach was able to achieve better solution costs over the set of QAP instances if compared to running the meta-heuristics individually.},
  archive      = {J_TCS},
  author       = {Augusto Dantas and Aurora Pozo},
  doi          = {10.1016/j.tcs.2019.10.033},
  journal      = {Theoretical Computer Science},
  pages        = {62-75},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the use of fitness landscape features in meta-learning based algorithm selection for the quadratic assignment problem},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Image quality assessment using BSIF, CLBP, LCP, and LPQ
operators. <em>TCS</em>, <em>805</em>, 37–61. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pervasiveness of digital devices like mobile phones, tablets, and personal computers established the presence of image contents as an essential media in several communication applications. In this scenario, the quality of the displayed images is directly correlated with the sense of communication excellence experienced by the users of these applications. Therefore, the development of techniques for assessing the quality of images, as perceived by human observers, is crucial for current multimedia applications. These techniques can either utilize the full prior information from a reference image (full-reference metrics), partial features of the reference (reduced-reference metrics) or exclusively the test image (no-reference metrics). In this paper, an effective no-reference image quality assessment approach is proposed based on the binarized statistical image features (BSIF), the completed local binary patterns (CLBP), the local configuration patterns (LCP), and the local phase quantization (LPQ) descriptors. The statistics of these descriptors is thoroughly evaluated using three popular databases: LIVE, TID2013, and CSIQ. Experimental results evince the correlation of quality scores provided by the observer with the proposed metrics, that indicate a fine performance when compared with several state-of-the-art image quality assessment methods.},
  archive      = {J_TCS},
  author       = {Pedro Garcia Freitas and Luísa Peixoto da Eira and Samuel Soares Santos and Mylène C.Q. Farias},
  doi          = {10.1016/j.tcs.2019.10.038},
  journal      = {Theoretical Computer Science},
  pages        = {37-61},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Image quality assessment using BSIF, CLBP, LCP, and LPQ operators},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating the numerical instability in fuzzy clustering
validation of high-dimensional data. <em>TCS</em>, <em>805</em>, 19–36.
(<a href="https://doi.org/10.1016/j.tcs.2019.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy clustering validation of high-dimensional datasets is only possible using a reliable cluster validity index (CVI). A good CVI must correctly recognize a data structure and its validations must be independently of any parameter of a clustering algorithm or data property. However, some classical fuzzy CVIs as Partition Coefficient (PC), Partition Entropy (PE) and Fukuyama-Sugeno (FS) have the monotonic tendency in function of the number of clusters. Although the literature presents extensive investigations about such tendency, they were conducted for low-dimensional data, in which such data property does not affect the clustering behavior. In order to investigate how such aspects affect the fuzzy clustering results of high-dimensional data, in this work we have clustered objects of thirteen real datasets, using the Fuzzy c-Means algorithm. The fuzzy partitions were validated by PC, PE, FS and some proposed improvements of them to lead with the monotonic tendency, totaling eight fuzzy CVIs analyzed. Besides the analysis made about the number of clusters selected by the CVIs, the Mann-Kendall test was performed to verify statistically the monotonic trend of the CVIs results. From the two analysis made, the Modified Partition Coefficient and Scaled Partition Entropy indices were successful in respectively improving the PC and PE indices.},
  archive      = {J_TCS},
  author       = {Fernanda Eustáquio and Tatiane Nogueira},
  doi          = {10.1016/j.tcs.2019.10.039},
  journal      = {Theoretical Computer Science},
  pages        = {19-36},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Evaluating the numerical instability in fuzzy clustering validation of high-dimensional data},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An evolutionary algorithm for automated machine learning
focusing on classifier ensembles: An improved algorithm and extended
results. <em>TCS</em>, <em>805</em>, 1–18. (<a
href="https://doi.org/10.1016/j.tcs.2019.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large number of classification algorithms have been proposed in the machine learning literature. These algorithms have different pros and cons, and no algorithm is the best for all datasets. Hence, a challenging problem consists of choosing the best classification algorithm with its best hyper-parameter settings for a given input dataset. In the last few years, Automated Machine Learning (Auto-ML) has emerged as a promising approach for tackling this problem, by doing a heuristic search in a large space of candidate classification algorithms and their hyper-parameter settings. In this work we propose an improved version of our previous Evolutionary Algorithm (EA) – more precisely, an Estimation of Distribution Algorithm – for the Auto-ML task of automatically selecting the best classifier ensemble and its best hyper-parameter settings for an input dataset. The new version of this EA was compared against its previous version, as well as against a random forest algorithm (a strong ensemble algorithm) and a version of the well-known Auto-ML method Auto-WEKA adapted to search in the same space of classifier ensembles as the proposed EA. In general, in experiments with 21 datasets, the new EA version obtained the best results among all methods in terms of four popular predictive accuracy measures: error rate, precision, recall and F-measure.},
  archive      = {J_TCS},
  author       = {João C. Xavier-Júnior and Alex A. Freitas and Teresa B. Ludermir and Antonino Feitosa-Neto and Cephas A.S. Barreto},
  doi          = {10.1016/j.tcs.2019.12.002},
  journal      = {Theoretical Computer Science},
  pages        = {1-18},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An evolutionary algorithm for automated machine learning focusing on classifier ensembles: An improved algorithm and extended results},
  volume       = {805},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compacting ciphertext in multi-channel broadcast encryption
and attribute-based encryption. <em>TCS</em>, <em>804</em>, 219–235. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-channel broadcast encryption ( MCBE MCBE ) and Attribute-based encryption ( ABE ABE ) are important primitives used in a broad range of concrete application scenarios such as Pay-TV, e-Health, Cloud Storage , Blockchain and so on. The former allows a sender to efficiently send different messages to arbitrarily chosen sets of users (target sets) at the same time, while the latter supports more sophisticated access control by allowing both the encryption and decryption phases to be based on the user&#39;s attributes. Recently, Canard el al. at Theoretical Computer Science&#39;18 proposed a new technique for compacting header size in both MCBE MCBE and ABE ABE . However, their technique leads to schemes in secret-key setting which has limited applications in practice. In this paper, we propose a new technique also for compacting header size in both MCBE MCBE and ABE ABE , but our technique leads to schemes in public key setting which therefore can overcome the weakness mentioned above of the Canard el al.&#39;s technique. We finally implement our MCBE MCBE and ABE ABE schemes to give some concrete benchmarks.},
  archive      = {J_TCS},
  author       = {Minh Ha Le and Vinh Duc Tran and Van Anh Trinh and Viet Cuong Trinh},
  doi          = {10.1016/j.tcs.2019.11.034},
  journal      = {Theoretical Computer Science},
  pages        = {219-235},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Compacting ciphertext in multi-channel broadcast encryption and attribute-based encryption},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the parameterized complexity of [1,j]-domination
problems. <em>TCS</em>, <em>804</em>, 207–218. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a graph G , a set D ⊆ V ( G ) D⊆V(G) is called a [ 1 , j ] [1,j] -dominating set if every vertex in V ( G ) ∖ D V(G)∖D has at least one and at most j neighbors in D . A set D ⊆ V ( G ) D⊆V(G) is called a [ 1 , j ] [1,j] -total dominating set if every vertex in V ( G ) V(G) has at least one and at most j neighbors in D . In the [ 1 , j ] [1,j] -(Total) Dominating Set problem we are given a graph G and a positive integer k . The objective is to test whether there exists a [ 1 , j ] [1,j] -(total) dominating set of size at most k . The [ 1 , j ] [1,j] -Dominating Set problem is known to be NP-complete, even for restricted classes of graphs such as chordal and planar graphs , but polynomial-time solvable on split graphs. The [ 1 , 2 ] [1,2] -Total Dominating Set problem is known to be NP-complete, even for bipartite graphs . As both problems generalize the Dominating Set problem, both are W[1]-hard when parameterized by solution size. In this work, we study the aforementioned problems on various graph classes from the perspective of parameterized complexity and prove the following results:},
  archive      = {J_TCS},
  author       = {Mohsen Alambardar Meybodi and Fedor V. Fomin and Amer E. Mouawad and Fahad Panolan},
  doi          = {10.1016/j.tcs.2019.11.032},
  journal      = {Theoretical Computer Science},
  pages        = {207-218},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the parameterized complexity of [1,j]-domination problems},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing a metric basis of a 2-connected bipartite
distance-hereditary graph. <em>TCS</em>, <em>804</em>, 186–206. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A vertex x of a connected graph G resolves two distinct vertices u and v in V ( G ) V(G) if the distance between u and x differs from the distance between v and x . A subset X of V ( G ) V(G) resolves two distinct vertices u and v in G if there exists a vertex x in X that resolves u and v ; X is a metric generator of G if, for every pair of distinct vertices u and v of G , X resolves u and v and is a metric basis of G if X is a metric generator of G with minimum cardinality. The metric dimension of G is the cardinality of a metric basis of G . The problem of finding the metric dimension of an arbitrary graph is NP-hard. In this paper we show that the problem is solvable in polynomial time for the class of 2-connected bipartite distance-hereditary graphs by providing an algorithm that computes a metric basis of a 2-connected bipartite distance-hereditary graph in O ( | V ( G ) | 2 | E ( G ) | ) O(|V(G)|2|E(G)|) time.},
  archive      = {J_TCS},
  author       = {Marina Moscarini},
  doi          = {10.1016/j.tcs.2019.11.031},
  journal      = {Theoretical Computer Science},
  pages        = {186-206},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing a metric basis of a 2-connected bipartite distance-hereditary graph},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Morphic words and equidistributed sequences. <em>TCS</em>,
<em>804</em>, 171–185. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem we consider is the following: Given an infinite word w on an ordered alphabet, construct the sequence ν w = ( ν [ n ] ) n νw=(ν[n])n , equidistributed on [ 0 , 1 ] [0,1] and such that ν [ m ] ν[m]&amp;lt;ν[n] if and only if σ m ( w ) σm(w)&amp;lt;σn(w) , where σ is the shift operation, erasing the first symbol of w . The sequence ν w νw exists and is unique for every word with well-defined positive uniform frequencies of every factor, or, in dynamical terms, for every element of a uniquely ergodic subshift. In this paper we describe the construction of ν w νw for the case when the subshift of w is generated by a morphism of a special kind; then we overcome some technical difficulties to extend the result to all binary morphisms. The sequence ν w νw in this case is also constructed with a morphism . At last, we introduce a software tool which, given a binary morphism φ , computes the morphism on extended intervals and first elements of the equidistributed sequences associated with fixed points of φ .},
  archive      = {J_TCS},
  author       = {Mélodie Andrieu and Anna E. Frid},
  doi          = {10.1016/j.tcs.2019.11.030},
  journal      = {Theoretical Computer Science},
  pages        = {171-185},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Morphic words and equidistributed sequences},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Beyond level planarity: Cyclic, torus, and simultaneous
level planarity. <em>TCS</em>, <em>804</em>, 161–170. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we settle the computational complexity of two open problems related to the extension of the notion of level planarity to surfaces different from the plane. Namely, we show that the problems of testing the existence of a level embedding of a level graph on the surface of the rolling cylinder or on the surface of the torus, respectively known by the name of Cyclic Level Planarity and Torus Level Planarity , are polynomial-time solvable. Moreover, we show a complexity dichotomy for testing the Simultaneous Level Planarity of a set of level graphs, with respect to both the number of level graphs and the number of levels.},
  archive      = {J_TCS},
  author       = {Patrizio Angelini and Giordano Da Lozzo and Giuseppe Di Battista and Fabrizio Frati and Maurizio Patrignani and Ignaz Rutter},
  doi          = {10.1016/j.tcs.2019.11.024},
  journal      = {Theoretical Computer Science},
  pages        = {161-170},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Beyond level planarity: Cyclic, torus, and simultaneous level planarity},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unique decipherability in formal languages. <em>TCS</em>,
<em>804</em>, 149–160. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider several language-theoretic aspects of various notions of unique decipherability (or unique factorization) in formal languages. Given a language L at some position within the Chomsky hierarchy, we investigate the language of words UD ( L ) UD(L) in ⁎ L ⁎ L⁎ that have unique factorization over L . We also consider similar notions for weaker forms of unique decipherability, such as numerically decipherable words ND ( L ) ND(L) , multiset decipherable words MSD ( L ) MSD(L) and set decipherable words SD ( L ) SD(L) . Although these notions of unique factorization have been considered before, it appears that the languages of words having these properties have not been positioned in the Chomsky hierarchy up until now. We show that UD ( L ) , ND ( L ) , MSD ( L ) UD(L),ND(L),MSD(L) and SD ( L ) SD(L) need not be context-free if L is context-free. In fact ND ( L ) ND(L) and MSD ( L ) MSD(L) need not be context-free even if L is finite, although UD ( L ) UD(L) and SD ( L ) SD(L) are regular in this case. We show that if L is context-sensitive, then so are UD ( L ) UD(L) , ND ( L ) ND(L) , MSD ( L ) MSD(L) and SD ( L ) SD(L) . We also prove that the membership problem (resp., emptiness problem) for these classes is PSPACE-complete (resp., undecidable). We finally determine upper and lower bounds on the length of the shortest word of ⁎ L ⁎ L⁎ not having the various forms of unique decipherability into elements of L .},
  archive      = {J_TCS},
  author       = {Paul C. Bell and Daniel Reidenbach and Jeffrey O. Shallit},
  doi          = {10.1016/j.tcs.2019.11.022},
  journal      = {Theoretical Computer Science},
  pages        = {149-160},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Unique decipherability in formal languages},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the g-good-neighbor connectivity of graphs. <em>TCS</em>,
<em>804</em>, 139–148. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Connectivity and diagnosability are two important parameters for the fault tolerant of an interconnection network G . In 1996, Fàbrega and Fiol proposed the g -good-neighbor connectivity of G . In this paper, we show that 1 ≤ κ g ( G ) ≤ n − 2 g − 2 1≤κg(G)≤n−2g−2 for 0 ≤ g ≤ { Δ ( G ) , ⌊ n − 3 2 ⌋ } 0≤g≤{Δ(G),⌊n−32⌋} , and graphs with κ g ( G ) = 1 , 2 κg(G)=1,2 and trees with κ g ( T n ) = n − t κg(Tn)=n−t for 4 ≤ t ≤ n + 2 2 4≤t≤n+22 are characterized, respectively. In the end, we get the three extremal results for the g -good-neighbor connectivity.},
  archive      = {J_TCS},
  author       = {Zhao Wang and Yaping Mao and Sun-Yuan Hsieh and Jichang Wu},
  doi          = {10.1016/j.tcs.2019.11.021},
  journal      = {Theoretical Computer Science},
  pages        = {139-148},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the g-good-neighbor connectivity of graphs},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the equality of the induced matching number and the
uniquely restricted matching number for subcubic graphs. <em>TCS</em>,
<em>804</em>, 126–138. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a matching M in a graph G , let G ( M ) G(M) be the subgraph of G induced by the vertices of G that are incident with an edge in M . The matching M is induced, if G ( M ) G(M) is 1-regular, and M is uniquely restricted, if M is the unique perfect matching of G ( M ) G(M) . The induced matching number ν s ( G ) νs(G) of G is the largest size of an induced matching in G , and the uniquely restricted matching number ν u r ( G ) νur(G) of G is the largest size of a uniquely restricted matching in G . Golumbic et al. (2001) [4] posed the problem to characterize the graphs G with ν s ( G ) = ν u r ( G ) νs(G)=νur(G) . We give a complete characterization of the 2-connected subcubic graphs G of sufficiently large order with ν s ( G ) = ν u r ( G ) νs(G)=νur(G) . As a consequence, we are able to show that the subcubic graphs G with ν s ( G ) = ν u r ( G ) νs(G)=νur(G) can be recognized in polynomial time .},
  archive      = {J_TCS},
  author       = {M. Fürst and D. Rautenbach},
  doi          = {10.1016/j.tcs.2019.11.020},
  journal      = {Theoretical Computer Science},
  pages        = {126-138},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the equality of the induced matching number and the uniquely restricted matching number for subcubic graphs},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Patterns of relation triples in inversion and ascent
sequences. <em>TCS</em>, <em>804</em>, 115–125. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Martinez and Savage carried out the systematic study of inversion sequences avoiding triples of relations. They reported many nice connections with familiar combinatorial families and posed several enumeration conjectures. All of their conjectures have already been solved except those related to the OEIS sequence A098746. In this paper, we address those remaining conjectures, which completes a picture for all the suspected connections arising in their investigation. As one of the most important subsets of inversion sequences, ascent sequences were introduced by Bousquet-Mélou et al. in bijection with ( 2 + 2 ) (2+2) -free posets and their pattern avoidance properties have been extensively studied. We investigate some classical Eulerian and Stirling statistics on ascent sequences avoiding triples of relations. This leads us to find two new interpretations of the Catalan numbers and its refinements, and to interpret combinatorially a natural refinement of the binomial transformation of Catalan numbers. The latter discovery answers a challenging open problem posed by Pudwell.},
  archive      = {J_TCS},
  author       = {Zhicong Lin},
  doi          = {10.1016/j.tcs.2019.11.007},
  journal      = {Theoretical Computer Science},
  pages        = {115-125},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Patterns of relation triples in inversion and ascent sequences},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithmic aspects of upper paired-domination in graphs.
<em>TCS</em>, <em>804</em>, 98–114. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set D of vertices in a graph G is a paired-dominating set of G if every vertex of G is adjacent to a vertex in D and the subgraph induced by D contains a perfect matching (not necessarily as an induced subgraph). A paired-dominating set of G is minimal if no proper subset of it is a paired-dominating set of G . The upper paired-domination number of G , denoted by Γ pr ( G ) , is the maximum cardinality of a minimal paired-dominating set of G . In Upper-PDS , it is required to compute a minimal paired-dominating set with cardinality Γ pr ( G ) for a given graph G . In this paper, we show that Upper-PDS cannot be approximated within a factor of n 1 − ε for any ε &gt; 0 , unless P = NP and Upper-PDS is APX -complete for bipartite graphs of maximum degree 4. On the positive side, we show that Upper-PDS can be approximated within O ( Δ ) -factor for graphs with maximum degree Δ. We also show that Upper-PDS is solvable in polynomial time for threshold graphs, chain graphs , and proper interval graphs .},
  archive      = {J_TCS},
  author       = {Michael A. Henning and D. Pradhan},
  doi          = {10.1016/j.tcs.2019.10.045},
  journal      = {Theoretical Computer Science},
  pages        = {98-114},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algorithmic aspects of upper paired-domination in graphs},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Range assignment of base-stations maximizing coverage area
without interference. <em>TCS</em>, <em>804</em>, 81–97. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of assigning non-overlapping geometric objects centered at a given set of points such that the sum of area covered by them is maximized. The problem remains open since 2002, as mentioned in a lecture slide of David Eppstein. In this paper, we have performed an exhaustive study on the problem. We show that, if the points are placed in R 2 R2 then the problem is NP-hard even for simplest type of covering objects like disks or squares. In contrast, Eppstein (2017) [10] proposed a polynomial time algorithm for maximizing the sum of radii (or perimeter) of non-overlapping disks when the points are arbitrarily placed in R 2 R2 . We show that Eppstein&#39;s algorithm for maximizing sum of perimeter of the disks in R 2 R2 gives a 2-approximation solution for the sum of area maximization problem. We also propose a PTAS for the same problem. Our results can be extended in higher dimensions as well as for a class of centrally symmetric convex objects.},
  archive      = {J_TCS},
  author       = {Ankush Acharyya and Minati De and Subhas C. Nandy and Bodhayan Roy},
  doi          = {10.1016/j.tcs.2019.10.044},
  journal      = {Theoretical Computer Science},
  pages        = {81-97},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Range assignment of base-stations maximizing coverage area without interference},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). (Strong) conflict-free connectivity: Algorithm and
complexity. <em>TCS</em>, <em>804</em>, 72–80. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be an(a) edge(vertex)-colored graph. A path P of G is called a conflict-free path if there is a color that is used on exactly one of the edges(vertices) of P . The graph G is called conflict-free (vertex-)connected if any two distinct vertices of G are connected by a conflict-free path, whereas the graph G is called strongly conflict-free connected if any two distinct vertices u , v u,v of G are connected by a conflict-free path of length of a shortest path between u and v in G . For a connected graph G , the (strong) conflict-free connection number of G , denoted by ( s c f c ( G ) ) c f c ( G ) (scfc(G))cfc(G) , is defined as the smallest number of colors that are required to make G (strongly) conflict-free connected. In this paper, we first investigate the question: Given a connected graph G and a coloring c : E ( o r V ) → { 1 , 2 , ⋯ , k } c:E(orV)→{1,2,⋯,k} ( k ≥ 1 ) (k≥1) of G , determine whether or not G is, respectively, conflict-free connected, conflict-free vertex-connected, strongly conflict-free connected under the coloring c . We solve this question by providing polynomial-time algorithms. We then show that the problem of deciding whether s c f c ( G ) ≤ k scfc(G)≤k ( k ≥ 2 ) (k≥2) for a given graph G is NP-complete. Moreover, we prove that it is NP-complete to decide whether there is a k -edge-coloring ( k ≥ 2 ) (k≥2) of G such that all pairs ( u , v ) ∈ P (u,v)∈P ( P ⊂ V × V ) (P⊂V×V) are strongly conflict-free connected.},
  archive      = {J_TCS},
  author       = {Meng Ji and Xueliang Li and Xiaoyu Zhu},
  doi          = {10.1016/j.tcs.2019.10.043},
  journal      = {Theoretical Computer Science},
  pages        = {72-80},
  shortjournal = {Theor. Comput. Sci.},
  title        = {(Strong) conflict-free connectivity: Algorithm and complexity},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scalable parallel algorithms for maximum matching and
hamiltonian circuit in convex bipartite graphs. <em>TCS</em>,
<em>804</em>, 58–71. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since bipartite convex graphs emerged from industrial applications, algorithms for this class of graphs have been devised in several research areas such as scheduling, DNA analysis, and constraint programming. A bipartite graph G = ( V , W , E ) is convex if there exists an ordering of the vertices of W such that, for each v ∈ V , the neighbors of v are consecutive in W . In this work we describe a coarse grained parallel algorithm for the maximum matching problem in a convex bipartite graph. For p processors, the algorithm runs in O ( ( | V | / p ) lg ⁡ ( | V | / p ) lg ⁡ p ) time and uses O ( lg ⁡ p ) communication rounds. We also address a well-known problem in the area of combinatorial optimization, the Hamiltonian circuit problem, presenting a sequential linear-time algorithm to determine if a convex bipartite graph has a Hamiltonian circuit. We further show how to efficiently implement both algorithms in PRAM and coarse grained parallel models. Experimental tests performed on commercial machines show the algorithms are robust and scalable.},
  archive      = {J_TCS},
  author       = {Marco A. Stefanes and Diego P. Rubert and José Soares},
  doi          = {10.1016/j.tcs.2019.10.042},
  journal      = {Theoretical Computer Science},
  pages        = {58-71},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Scalable parallel algorithms for maximum matching and hamiltonian circuit in convex bipartite graphs},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the carathéodory and exchange numbers of geodetic
convexity in graphs. <em>TCS</em>, <em>804</em>, 46–57. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set of vertices S of a graph G is geodesically convex if for every pair of vertices of S , all vertices of all shortest paths joining them also lie in S . The geodetic convex hull of S , denoted by 〈 S 〉 〈S〉 , is the minimum geodesically convex set of G containing S . We say that S is Carathéodory independent if 〈 S 〉 ∖ ( ⋃ a ∈ S 〈 S ∖ { a } 〉 ) ≠ ∅ 〈S〉∖(⋃a∈S〈S∖{a}〉)≠∅ and that S is exchange independent if | S | = 1 |S|=1 or there is p ∈ S p∈S such that 〈 S ∖ { p } 〉 ∖ ⋃ a ∈ S ∖ { p } 〈 S ∖ { a } 〉 ≠ ∅ 〈S∖{p}〉∖⋃a∈S∖{p}〈S∖{a}〉≠∅ . The Carathéodory number ( exchange number ) of G is the cardinality of a maximum Carathéodory (exchange) independent set. In this paper, we show that deciding whether a given graph has exchange number at most k is an NP -complete problem. We also present characterizations of the Carathéodory and exchange numbers for some graph classes, like unit interval graphs and powers of cycles, which allow us to determine these parameters in polynomial time .},
  archive      = {J_TCS},
  author       = {Bijo S. Anand and Ullas Chandran S.V. and Manoj Changat and Mitre C. Dourado and Ferdoos Hossein Nezhad and Prasanth G. Narasimha-Shenoi},
  doi          = {10.1016/j.tcs.2019.10.041},
  journal      = {Theoretical Computer Science},
  pages        = {46-57},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the carathéodory and exchange numbers of geodetic convexity in graphs},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-stage combinatorial optimization problems under risk.
<em>TCS</em>, <em>804</em>, 29–45. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper a class of combinatorial optimization problems is discussed. It is assumed that a solution can be constructed in two stages. The current first-stage costs are precisely known, while the future second-stage costs are only known to belong to an uncertainty set, which contains a finite number of scenarios with known probability distribution. A partial solution, chosen in the first stage, can be completed by performing an optimal recourse action, after the true second-stage scenario is revealed. A solution minimizing the Conditional Value at Risk (CVaR) measure is computed. Since expectation and maximum are boundary cases of CVaR, the model generalizes the traditional stochastic and robust two-stage approaches, previously discussed in the existing literature. In this paper some new negative and positive results are provided for basic combinatorial optimization problems such as the selection or network problems.},
  archive      = {J_TCS},
  author       = {Marc Goerigk and Adam Kasperski and Paweł Zieliński},
  doi          = {10.1016/j.tcs.2019.10.035},
  journal      = {Theoretical Computer Science},
  pages        = {29-45},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Two-stage combinatorial optimization problems under risk},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Novel updatable identity-based hash proof system and its
applications. <em>TCS</em>, <em>804</em>, 1–28. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alwen et al. in Eurocrypt 2010, showed that an identity-based hash proof system (IB-HPS), where IB-HPS generalizes the notion of hash proof system (HPS) to the identity-based setting, almost immediately yields an identity-based encryption (IBE) scheme which is secure against partial leakage of the target identity&#39;s decryption key. That is, an IBE scheme with bounded leakage resilience can be naturally created from an IB-HPS. However, in the real world, the leakage is unbounded, and any adversary can break the security of cryptography shceme by performing continuous leakage attacks. To further increase the practicability, a cryptography scheme must hold the claimed security in the continuous leakage setting. Dodis et al. in FOCS 2010, showed a generic method how to create a cryptography shceme with continuous leakage resilience from the bounded leakage-resilient cryptosystem by performing an additional key update algorithm while the public parameters keep unchanged. To construct a continuous leakage-resilient cryptography scheme, a new primitive, called it updatable identity-based hash proof system (U-IB-HPS), is proposed, which is an improved IB-HPS. In particular, the improved system has an additional key update algorithm, which can push some new randomness into the private key of user (or the master secret key), the updated results are random in the adversary&#39;s view, and the leakage of previous private key of user (or the master secret key) does not work for the updated results. However, the previous instantiations of U-IB-HPS cannot achieve the claimed security. To solve the above problems, in this paper, two instantiations of U-IB-HPS with better performance are created, and the security of proposed system is proved, in the standard model, based on the classic decisional bilinear Diffie-Hellman assumption. The corresponding IBE scheme created with our U-IB-HPS allows continuous leakage of multiple keys, i.e., continuous leakage of the master secret key and the private key of user. Additionally, our U-IB-HPS can also be employed as an underlying basic tool to build the generic construction of continuous leakage-amplified public-key encryption scheme, continuous leakage-resilient identity-based authenticated key exchange protocol, and continuous leakage-resilient public-key encryption scheme with keyword search , etc.},
  archive      = {J_TCS},
  author       = {Yanwei Zhou and Bo Yang and Tao Wang and Yi Mu},
  doi          = {10.1016/j.tcs.2019.10.031},
  journal      = {Theoretical Computer Science},
  pages        = {1-28},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Novel updatable identity-based hash proof system and its applications},
  volume       = {804},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algorithms for (n,3)-MAXSAT and parameterization above the
all-true assignment. <em>TCS</em>, <em>803</em>, 222–233. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the (n,3)-MAXSAT problem. The problem is a special case of the Maximum Satisfiability problem with an additional requirement that in the input formula each variable appears at most three times. Here, we improve previous upper bounds for (n,3)-MAXSAT in terms of n (number of variables) and in terms of k (number of clauses that we are required to satisfy). Moreover, we prove that satisfying more clauses than the simple all true assignment is an NP-hard problem.},
  archive      = {J_TCS},
  author       = {Tatiana Belova and Ivan Bliznets},
  doi          = {10.1016/j.tcs.2019.11.033},
  journal      = {Theoretical Computer Science},
  pages        = {222-233},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algorithms for (n,3)-MAXSAT and parameterization above the all-true assignment},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Practical card-based implementations of yao’s millionaire
protocol. <em>TCS</em>, <em>803</em>, 207–221. (<a
href="https://doi.org/10.1016/j.tcs.2019.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Yao&#39;s millionaire protocol enables Alice and Bob to know whether or not Bob is richer than Alice by using a public-key cryptosystem without revealing the actual amounts of their properties. In this paper, we present simple and practical implementations of Yao&#39;s millionaire protocol using a physical deck of playing cards; we straightforwardly implement the idea behind Yao&#39;s millionaire protocol so that even non-experts can easily understand their correctness and secrecy. Our implementations are based partially on the previous card-based scheme proposed by Nakai, Tokushige, Misawa, Iwamoto, and Ohta; their scheme admits players&#39; private actions on a sequence of cards called Private Permutation (PP), implying that a malicious player could make an active attack (for example, he/she could exchange some of the cards stealthily when doing such a private action). By contrast, our implementations rely on a familiar shuffling operation called a random cut, and hence, they can be conducted completely publicly so as to avoid any active attack. More specifically, we present two card-based implementations of Yao&#39;s millionaire protocol; one uses a two-colored deck of cards (which consists of black and red cards), and the other uses a standard deck of playing cards. Furthermore, we also provide card-based protocols that rely on a logical circuit representing the comparison.},
  archive      = {J_TCS},
  author       = {Daiki Miyahara and Yu-ichi Hayashi and Takaaki Mizuki and Hideaki Sone},
  doi          = {10.1016/j.tcs.2019.11.005},
  journal      = {Theoretical Computer Science},
  pages        = {207-221},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Practical card-based implementations of yao&#39;s millionaire protocol},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Balanced-flow algorithm for path network planning in
hierarchical spaces. <em>TCS</em>, <em>803</em>, 196–206. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is an important and classical problem in theoretical research and practical applications. In the complex and hierarchical space scenarios, path planning faces more difficulties and challenges due to the structural particularity. Considering the directivity of paths in hierarchical spaces, it is more important to guarantee the fluency and efficiency of the paths in hierarchical spaces. In this paper, we introduce a path network planning problem from multi-source to multi-destination in hierarchical spaces, namely Balanced-Flow Path Network Planning (BF-PNP) problem, and prove its NP-completeness. To balance the flow rate among the layers in the space, we propose a batch scheduling algorithm with the objective of minimizing the scheduling time consumption. To evaluate the performance on efficiency and time complexity, we perform a series of simulations and the results indicate the advantages of the proposed algorithm.},
  archive      = {J_TCS},
  author       = {Yi Hong and Jiandong Liu and Deying Li and Chuanwen Luo and Mengjie Chang},
  doi          = {10.1016/j.tcs.2019.10.028},
  journal      = {Theoretical Computer Science},
  pages        = {196-206},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Balanced-flow algorithm for path network planning in hierarchical spaces},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An o(log⁡n) query time algorithm for reducing ϵ-NN to
(c,r)-NN. <em>TCS</em>, <em>803</em>, 178–195. (<a
href="https://doi.org/10.1016/j.tcs.2019.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of reducing ϵ -NN to ( c , r ) (c,r) -NN is very important in theoretical computer science area and has attracted many research efforts. In this paper a new algorithm for such problem is proposed, which achieves O ( log ⁡ n ) O(log⁡n) query time. Comparing with the former algorithms for the same problem, this query time is the lowest, which is the main contribution of this paper. The low query time complexity is achieved by raising the preprocessing time and space complexity. How to reduce the cost added into the two complexities is also discussed in this paper.},
  archive      = {J_TCS},
  author       = {Hengzhao Ma and Jianzhong Li},
  doi          = {10.1016/j.tcs.2019.10.004},
  journal      = {Theoretical Computer Science},
  pages        = {178-195},
  shortjournal = {Theor. Comput. Sci.},
  title        = {An o(log⁡n) query time algorithm for reducing ϵ-NN to (c,r)-NN},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Computing bounds on product graph pebbling numbers.
<em>TCS</em>, <em>803</em>, 160–177. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a distribution of pebbles to the vertices of a graph , a pebbling move removes two pebbles from a single vertex and places a single pebble on an adjacent vertex . The pebbling number π ( G ) π(G) is the smallest number such that, for any distribution of π ( G ) π(G) pebbles to the vertices of G and choice of root vertex r of G , there exists a sequence of pebbling moves that places a pebble on r . Computing π ( G ) π(G) is provably difficult, and recent methods for bounding π ( G ) π(G) have proved computationally intractable, even for moderately sized graphs. Graham conjectured that π ( G □ H ) ≤ π ( G ) π ( H ) π(G□H)≤π(G)π(H) , where G □ H G□H is the Cartesian product of G and H (1989). While the conjecture has been verified for specific families of graphs, in general it remains open. This study combines the focus of developing a computationally tractable, IP-based method for generating good bounds on π ( G □ H ) π(G□H) , with the goal of shedding light on Graham&#39;s conjecture. We provide computational results for a variety of Cartesian-product graphs, including some that are known to satisfy Graham&#39;s conjecture and some that are not. Our approach leads to a sizable improvement on the best known bound for π ( L □ L ) π(L□L) , where L is the Lemke graph, and L □ L L□L is among the smallest known potential counterexamples to Graham&#39;s conjecture.},
  archive      = {J_TCS},
  author       = {Franklin Kenter and Daphne Skipper and Dan Wilson},
  doi          = {10.1016/j.tcs.2019.09.050},
  journal      = {Theoretical Computer Science},
  pages        = {160-177},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Computing bounds on product graph pebbling numbers},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The hardness of resilience for nested aggregation query.
<em>TCS</em>, <em>803</em>, 152–159. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilience problem is defined on a database d , given a boolean query q where q ( d ) q(d) is initially t r u e true , and an integer k , it is to find the tuple set d ′ d′ of smallest size such that the query result q ( d ∖ d ′ ) q(d∖d′) becomes f a l s e false . As a potential explanation of a specified query, resilience plays a fundamental and important role in query explanation, database debugging and error tracing. Complexity results of resilience decision on relational algebraic queries have been studied previously. In this paper, we investigate the resilience decision problem on aggregation queries. New results on the hardness are provided. We show that, this problem is polynomially intractable on nested COUNT and SUM query both under data complexity and parametric complexity, and even it is NP NP - hard hard to approximate it within a constant ratio under the active domain constraint.},
  archive      = {J_TCS},
  author       = {Dongjing Miao and Jiguo Yu and Zhipeng Cai},
  doi          = {10.1016/j.tcs.2019.09.049},
  journal      = {Theoretical Computer Science},
  pages        = {152-159},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The hardness of resilience for nested aggregation query},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Open-shop scheduling for unit jobs under precedence
constraints. <em>TCS</em>, <em>803</em>, 144–151. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study open-shop scheduling for unit jobs under precedence constraints, where if one job precedes another job then it has to be finished before the other job can start to be processed. For the three-machine open-shop to minimize the makespan, we first present a simple 5/3-approximation algorithm based on a partition of the job set into agreeable layers using the natural layered representation of the precedence graph , which is directed acyclic. We then show a greedy algorithm to reduce the number of singleton-job layers, resulting in an improved partition, which leads to a 4/3-approximation algorithm. Both approximation algorithms apply to the general m -machine open-shops too.},
  archive      = {J_TCS},
  author       = {Yong Chen and Randy Goebel and Guohui Lin and Bing Su and An Zhang},
  doi          = {10.1016/j.tcs.2019.09.046},
  journal      = {Theoretical Computer Science},
  pages        = {144-151},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Open-shop scheduling for unit jobs under precedence constraints},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quality-aware online task assignment mechanisms using latent
topic model. <em>TCS</em>, <em>803</em>, 130–143. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing has been proven to be a useful tool for the tasks which are hard for computers. Unfortunately, workers with uneven expertise are likely to provide low-quality or even deliberately wrong data. A reliability model that precisely describes workers&#39; performance on the tasks can benefit the development of both task assignment mechanism and truth discovery method. However, existing methods cannot model workers&#39; fine-grained reliability levels accurately. In this paper, we consider dividing tasks into clusters ( i.e., topics ) based on workers&#39; behaviors and propose a novel latent topic model to describe the topic structure and workers&#39; topical-level expertise. Then, we develop two online task assignment mechanisms that dynamically assign each incoming worker a set of tasks where he can achieve the Maximum Expected Gain (MEG) or Maximum Expected and Potential Gain (MEPG). The experimental results demonstrate that our methods can significantly decrease the number of task assignments and achieve higher accuracy and macro-averaging F1-score than the state-of-the-art approaches.},
  archive      = {J_TCS},
  author       = {Yang Du and Yu-E Sun and He Huang and Liusheng Huang and Hongli Xu and Xiaocan Wu},
  doi          = {10.1016/j.tcs.2019.07.033},
  journal      = {Theoretical Computer Science},
  pages        = {130-143},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Quality-aware online task assignment mechanisms using latent topic model},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Community based acceptance probability maximization for
target users on social networks: Algorithms and analysis. <em>TCS</em>,
<em>803</em>, 116–129. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different from previous social influence problems such as Influence Maximization (IM), we in this paper first propose the Acceptance Probability Maximization (APM) problem, i.e., we select a seed set S with a budget b such that the acceptance probability of the target user set T is maximized. Then we employ the classical Independent Cascade (IC) model as the information diffusion model . Based on the IC model, we prove that the APM problem is NP-hard and the objective function is monotone non-decreasing and submodular. Considering community components of the social network, we convert the APM problem to the Maximum Weight Hitting Set (MWHS) problem. Next we develop a pipage rounding algorithm whose approximation ratio is ( 1 − 1 / e ) (1−1/e) . Furthermore, we also propose a basic greedy algorithm and a heuristic algorithm as comparison methods. Finally, we conduct extensive simulations on synthetic and real-life social networks to evaluate the efficacy and efficiency of our algorithms. Empirical evaluation results validate the superiority of proposed algorithms in both effectiveness and efficiency compared with a few baseline comparison methods.},
  archive      = {J_TCS},
  author       = {Ruidong Yan and Yuqing Zhu and Deying Li and Yongcai Wang},
  doi          = {10.1016/j.tcs.2019.07.032},
  journal      = {Theoretical Computer Science},
  pages        = {116-129},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Community based acceptance probability maximization for target users on social networks: Algorithms and analysis},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hardness of and approximate mechanism design for the bike
rebalancing problem. <em>TCS</em>, <em>803</em>, 105–115. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently arose in the flourishing sharing economy, the bike rebalancing problem is a new challenge that concerns how to incentivize users to park bikes at system-desired locations that better meet bike demands. It can also be generalized to other location-based vehicle or tool sharing problems such as car, truck, drone, and trolley sharing. In this paper, we address this problem using an auction model under a crowdsourcing framework, where users report their original destinations and the bike sharing platform assigns proper relocation tasks to them in order to better balance the bike supply and demand. We first prove two impossibility results: (1) finding an optimal solution to the bike rebalancing problem is NP-hard, and (2) there is no approximate mechanism with bounded approximation ratio that is both truthful and budget-feasible. To overcome this barrier, we introduce two practical constraints and design a two-stage approximate mechanism that satisfies location truthfulness, budget feasibility, individual rationality, and achieves constant approximation ratio. To the best of our knowledge, we are the first to address two dimensional location truthfulness in the regime of mechanism design. In addition, our extensive experiments based on real-world dataset demonstrate that our proposed mechanism can effectively redress the imbalance of bike distribution.},
  archive      = {J_TCS},
  author       = {Hongtao Lv and Fan Wu and Tie Luo and Xiaofeng Gao and Guihai Chen},
  doi          = {10.1016/j.tcs.2019.07.030},
  journal      = {Theoretical Computer Science},
  pages        = {105-115},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Hardness of and approximate mechanism design for the bike rebalancing problem},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pricing and allocation algorithm designs in dynamic
ridesharing system. <em>TCS</em>, <em>803</em>, 94–104. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion and car pollution are becoming serious plagues nowadays. High travel cost brings a great burden to people and society. A ridesharing system mitigates traffic congestion and car pollution by allowing passengers to share their travel costs with others. Traditional ridesharing platforms usually require passengers to submit their plans in advance and then design schedules for the drivers who would like to offer a ride. Nowadays, with the development of the smartphone technology, dynamic ridesharing systems enable passengers request a car anytime and anywhere. This paper mainly considers the problems of how to allocate passengers to drivers, how to charge the passengers and how to design feasible schedules for the driver in such online environment. The allocation problem is modeled as an online weighted matching problem with the graph changing over time. Firstly, we give a fair pricing method which is easy to be understood and accepted by the passengers. We develop a greedy algorithm called LiqMax_Gre for the purpose of maximizing liquidity and an algorithm called UtiMax for the purpose of maximizing utility. LiqMax_Gre achieves a competitive ratio of 1 λ + 1 1λ+1 , where λ is the maximal number of passengers a car can take. In general, we prove that no online algorithm can have a good guarantee for the design goal of maximizing utility. Innovatively, UtiMax considers not only the current maximal utility, but also the opportunity cost, which is the utility contributed by occupying a seat. It reflects the utility in the future and thus can be used to handle the difficulty in online design. We prove that, our algorithm has a competitive ratio of 1/3 in a special case. The schedule problem is NP-hard and we design a heuristic nearest neighbor algorithm to solve it.},
  archive      = {J_TCS},
  author       = {Chaoli Zhang and Jiapeng Xie and Fan Wu and Xiaofeng Gao and Guihai Chen},
  doi          = {10.1016/j.tcs.2019.05.045},
  journal      = {Theoretical Computer Science},
  pages        = {94-104},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Pricing and allocation algorithm designs in dynamic ridesharing system},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General rumor blocking: An efficient random algorithm with
martingale approach. <em>TCS</em>, <em>803</em>, 82–93. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumor Blocking, an important optimization problem in social network, has been extensively studied in the literature. Given social network G = ( V , E ) G=(V,E) and rumor seed set A , the goal is asking for k protector seeds that protect the largest expected number of social individuals by truth. However, the source of rumor is always uncertain, rather than being predicted or being known in advance in the real situations, while rumor spreads like wildfire on the Internet. This paper presents General Rumor Blocking with unpredicted rumor seed set (randomized A ) and various personal profits while being protected (weights of nodes in V ). We first show that the objective function of this problem is non-decreasing and submodular, and thus a ( 1 − 1 / e ) (1−1/e) approximate solution can be returned by greedy approach. We then propose an efficient random algorithm R-GRB which returns a ( 1 − 1 / e − ε 1−1/e−ε ) approximate solution with at least 1 − n − ℓ 1−n−ℓ probability . We show that it runs in O ( m ( n − r ) ( k log ⁡ ( n − r ) + ℓ log ⁡ n ) / ε 2 ) O(m(n−r)(klog⁡(n−r)+ℓlog⁡n)/ε2) expected time, where m = | E | m=|E| , n = | V | n=|V| , r = | A | r=|A| and k is the number of protector seeds. Finally, we conduct extensive experiments to evaluate the R-GRB and show that it is superior in both theory and experiment.},
  archive      = {J_TCS},
  author       = {Qizhi Fang and Xin Chen and Qingqin Nong and Zongchao Zhang and Yongchang Cao and Yan Feng and Tao Sun and Suning Gong and Dingzhu Du},
  doi          = {10.1016/j.tcs.2019.05.044},
  journal      = {Theoretical Computer Science},
  pages        = {82-93},
  shortjournal = {Theor. Comput. Sci.},
  title        = {General rumor blocking: An efficient random algorithm with martingale approach},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New LP relaxations for minimum cycle/path/tree cover
problems. <em>TCS</em>, <em>803</em>, 71–81. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected complete graph G = ( V , E ) G=(V,E) with nonnegative edge weight function obeying the triangle inequality , a set { C 1 , C 2 {C1,C2 , … , C k } …,Ck} of cycles is called a cycle cover if V ⊆ ⋃ i = 1 k V ( C i ) V⊆⋃i=1kV(Ci) , where V ( C i ) V(Ci) represents the set of vertices in C i Ci , and its cost is given by the maximum weight of the cycles. The Minimum Cycle Cover Problem (MCCP) aims to find a cycle cover of cost at most λ with the minimum number of cycles. We propose new LP relaxations for MCCP as well as its variants, called the Minimum Path Cover Problem (MPCP) and the Minimum Tree Cover Problem, where the cycles are replaced by paths or trees. Moreover, we give new LP relaxations for a special case of the rooted version of MCCP/MPCP. We show that these LP relaxations have significantly better integrality gaps than the previous relaxations.},
  archive      = {J_TCS},
  author       = {Wei Yu and Zhaohui Liu and Xiaoguang Bao},
  doi          = {10.1016/j.tcs.2019.05.041},
  journal      = {Theoretical Computer Science},
  pages        = {71-81},
  shortjournal = {Theor. Comput. Sci.},
  title        = {New LP relaxations for minimum Cycle/Path/Tree cover problems},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for the three-machine proportionate
mixed shop scheduling. <em>TCS</em>, <em>803</em>, 57–70. (<a
href="https://doi.org/10.1016/j.tcs.2019.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mixed shop is a manufacturing infrastructure designed to process a mixture of a set of flow-shop jobs and a set of open-shop jobs. Mixed shops are in general much more complex to schedule than flow-shops and open-shops, and have been studied since the 1980&#39;s. We consider the three machine proportionate mixed shop problem denoted as M 3 | p r p t | C max M3|prpt|Cmax , in which by “proportionate” each job has equal processing times on all three machines. Koulamas and Kyparisis (2015) [6] showed that the problem is solvable in polynomial time in some very special cases; for the non-solvable case, they proposed a 5/3-approximation algorithm. In this paper, we first present an improved 4/3-approximation algorithm and show that this ratio of 4/3 is asymptotically tight; when the largest job is a flow-shop job, we then present a fully polynomial-time approximation scheme (FPTAS). On the negative side, while the F 3 | p r p t | C max F3|prpt|Cmax problem is polynomial-time solvable, we show an interesting hardness result that adding one open-shop job to the job set makes the problem NP-hard if this open-shop job is larger than any flow-shop job. We are able to design an FPTAS for this special case too.},
  archive      = {J_TCS},
  author       = {Longcheng Liu and Yong Chen and Jianming Dong and Randy Goebel and Guohui Lin and Yue Luo and Guanqun Ni and Bing Su and Yao Xu and An Zhang},
  doi          = {10.1016/j.tcs.2019.05.036},
  journal      = {Theoretical Computer Science},
  pages        = {57-70},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Approximation algorithms for the three-machine proportionate mixed shop scheduling},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Distributed representation of knowledge graphs with
subgraph-aware proximity. <em>TCS</em>, <em>803</em>, 48–56. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed representation of Knowledge graphs (KGs) aims to embed the original KG into a low-dimensional embedding vector space, so as to facilitate the completion of KGs as well as the application of KGs in other AI fields. Most existing models preserve certain proximity property of KGs in the embedding space, such as the first/second-order proximity and the sequence-aware higher-order proximity. However, the ubiquitous similarity relationship between different sequences has rarely been discussed. In this paper, we propose a unified framework to preserve the subgraph-aware proximity in the embedding space, holding that the sequences within a subgraph generally imply a similar pattern. Especially, according to the composition and structure of KG sequences, we provide three methods for computing the embeddings of KG sequences: 1) Simply adding the involved relations of the KG sequences in a relation subgraph; 2) Recurrent neural network for the KG sequences in a complete subgraph; 3) Dilated recurrent neural network to match the special structure of the KG sequences in a complete subgraph. Empirically, we evaluate the proposed framework on the KG completion tasks of link prediction and entity classification. The results show that our framework outperforms the baselines by preserving the subgraph-aware proximity. Especially, exploring the special structure of KG sequences can further improve the performance.},
  archive      = {J_TCS},
  author       = {Xiao Han and Chunhong Zhang and Chenchen Guo and Yang Ji and Zheng Hu},
  doi          = {10.1016/j.tcs.2019.03.033},
  journal      = {Theoretical Computer Science},
  pages        = {48-56},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Distributed representation of knowledge graphs with subgraph-aware proximity},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A random algorithm for profit maximization in online social
networks. <em>TCS</em>, <em>803</em>, 36–47. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a social network G and a positive integer k , the influence maximization problem seeks for k nodes in G that can influence the largest number of nodes. This problem has found important applications, and a large amount of works have been devoted to identifying the few most influential users. But most of existing works only focus on the diffusion of a single idea or product in social networks. However, in reality, one company may produce multiple kinds of products and one user may also have multiple adoptions. For multiple kinds of different products with different activation costs and profits, it is crucial for the company to distribute the limited budget among multiple products in order to achieve profit maximization. The Profit Maximization with Multiple Adoptions (PM 2 A) problem aims to seek for a seed set within the budget to maximize the overall profit. In this paper, a Randomized Modified Greedy ( RMG ) algorithm based on the Reverse Influence Sampling (RIS) technique is presented for the PM 2 A problem, which could achieve a ( 1 − 1 / e − ε ) (1−1/e−ε) -approximate solution with high probability and is also the best performance ratio of the PM 2 A problem. Comprehensive experiments on three real-world social networks are conducted, and the results demonstrate that our RMG algorithm outperforms the algorithm proposed in [16] and other heuristics in terms of profit maximization, and could better allocate the budget.},
  archive      = {J_TCS},
  author       = {Tiantian Chen and Bin Liu and Wenjing Liu and Qizhi Fang and Jing Yuan and Weili Wu},
  doi          = {10.1016/j.tcs.2019.03.028},
  journal      = {Theoretical Computer Science},
  pages        = {36-47},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A random algorithm for profit maximization in online social networks},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Profit maximization problem with coupons in social networks.
<em>TCS</em>, <em>803</em>, 22–35. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Viral marketing has become one of the most effective marketing strategies. In the process of real commercialization, in order to let some seed individuals know the products, companies can provide free samples to them. However, for some companies, especially famous ones, they are more willing to offer coupons than give samples. In this paper, we consider the Profit Maximization problem with Coupons (PM-C) in our new diffusion model named the Independent Cascade Model with Coupons and Valuations (IC-CV). To solve this problem, we propose the PMCA algorithm which can return a ( 1 3 − ε ) (13−ε) -approximate solution with at least 1 − 2 n − l 1−2n−l probability , and runs in O ( log ⁡ ( n p ) ⋅ m n 3 log ⁡ n ( l log ⁡ n + n log ⁡ 2 ) / ε 3 ) O(log⁡(np)⋅mn3log⁡n(llog⁡n+nlog⁡2)/ε3) expected time. Furthermore, during the analysis we provide a method to estimate the non-monotone submodular function.},
  archive      = {J_TCS},
  author       = {Bin Liu and Xiao Li and Huijuan Wang and Qizhi Fang and Junyu Dong and Weili Wu},
  doi          = {10.1016/j.tcs.2019.03.007},
  journal      = {Theoretical Computer Science},
  pages        = {22-35},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Profit maximization problem with coupons in social networks},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Viral marketing of online game by DS decomposition in social
networks. <em>TCS</em>, <em>803</em>, 10–21. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In social networks, the spread of influence has been studied extensively, but most efforts in existing literature are made on the product used by a single person. This paper attempts to address the product which is used by many persons such as the online game. When multiple people participate in one game, interaction between users is accompanied by browsing and clicking on advertisements, and operators can also earn certain advertising revenues. All these revenues are related to information interaction between people involved in one game. We use game profit to represent all of the revenues gained from players involved in one game and model the game profit maximization problem in social networks, which finds a seed set to maximize the game profit between players who are influenced to buy the game. We prove that the problem is NP-hard and the objective function is neither submodular nor supermodular. To solve it, we decompose it into the Difference between two Submodular functions (DS decomposition) and propose four heuristic algorithms . To address the complexity of computing objective function, we design a new sampling method based on reverse reachable set technology. Experiment results on real datasets show that our approaches perform well.},
  archive      = {J_TCS},
  author       = {Chuangen Gao and Hai Du and Weili Wu and Hua Wang},
  doi          = {10.1016/j.tcs.2019.03.006},
  journal      = {Theoretical Computer Science},
  pages        = {10-21},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Viral marketing of online game by DS decomposition in social networks},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bicriteria algorithm for the minimum submodular cost
partial set multi-cover problem. <em>TCS</em>, <em>803</em>, 1–9. (<a
href="https://doi.org/10.1016/j.tcs.2019.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a bicriteria approximation algorithm for the minimum submodular cost partial set multi-cover problem (SCPSMC), the goal of which is to find a minimum cost sub-collection of sets to fully cover q percentage of total profit of all elements, where the cost on sub-collections is a submodular function, and an element e with covering requirement r e re is fully covered if it belongs to at least r e re picked sets. Assuming that the maximum covering requirement r max = max e ∈ E ⁡ r e rmax=maxe∈E⁡re is a constant and the cost function is nonnegative and submodular, we give a deterministic ( b / q ε , ( 1 − ε ) ) (b/qε,(1−ε)) -bicriteria algorithm for SCPSMC, the output of which fully covers at least ( 1 − ε ) q (1−ε)q -percentage of the total profit and the performance ratio is b / q ε b/qε , where b = max e ⁡ ( f e r e ) b=maxe⁡(fere) and f e fe is the number of sets containing element e .},
  archive      = {J_TCS},
  author       = {Yishuo Shi and Yingli Ran and Zhao Zhang and Ding-Zhu Du},
  doi          = {10.1016/j.tcs.2019.03.004},
  journal      = {Theoretical Computer Science},
  pages        = {1-9},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A bicriteria algorithm for the minimum submodular cost partial set multi-cover problem},
  volume       = {803},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Probabilistic divide &amp; congruence: Branching
bisimilarity. <em>TCS</em>, <em>802</em>, 147–196. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the seminal paper by Bloom, Fokkink and van Glabbeek, the Divide and Congruence technique allows for the derivation of compositional properties of nondeterministic processes from the SOS-based decomposition of their modal properties. In an earlier paper, we extended their technique to deal also with quantitative aspects of process behavior: we proved the (pre)congruence property for strong (bi)simulations on processes with nondeterminism and probability . In this paper we further extend our decomposition method to favor compositional reasoning with respect to probabilistic weak semantics. In detail, we consider probabilistic branching and rooted probabilistic branching bisimilarity , and we propose logical characterizations for them. These are strongly based on the modal operator 〈 ε 〉 〈ε〉 which combines quantitative information and weak semantics by introducing a sort of probabilistic lookahead on process behavior. Our enhanced method will exploit distribution specifications , an SOS-like framework defining the probabilistic behavior of processes, to decompose this particular form of lookahead. We will show how we can apply the proposed decomposition method to derive congruence formats for the considered equivalences from their logical characterizations.},
  archive      = {J_TCS},
  author       = {Valentina Castiglioni and Simone Tini},
  doi          = {10.1016/j.tcs.2019.09.037},
  journal      = {Theoretical Computer Science},
  pages        = {147-196},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Probabilistic divide &amp; congruence: Branching bisimilarity},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). One-variable logic meets presburger arithmetic.
<em>TCS</em>, <em>802</em>, 141–146. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the one-variable fragment of first-order logic extended with Presburger constraints. The logic is designed in such a way that it subsumes the previously-known fragments extended with counting, modulo counting or cardinality comparison and combines their expressive powers . We prove -completeness of the logic by presenting an optimal algorithm for solving its finite satisfiability problem .},
  archive      = {J_TCS},
  author       = {Bartosz Bednarczyk},
  doi          = {10.1016/j.tcs.2019.09.028},
  journal      = {Theoretical Computer Science},
  pages        = {141-146},
  shortjournal = {Theor. Comput. Sci.},
  title        = {One-variable logic meets presburger arithmetic},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unifying theories of reactive design contracts.
<em>TCS</em>, <em>802</em>, 105–140. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design-by-contract is an important technique for model-based design in which a composite system is specified by a collection of contracts that specify the behavioural assumptions and guarantees of each component. In this paper, we describe a unifying theory for reactive design contracts that provides the basis for modelling and verification of reactive systems. We provide a language for expression and composition of contracts that is supported by a rich calculational theory. In contrast with other semantic models in the literature, our theory of contracts allows us to specify both the evolution of state variables and the permissible interactions with the environment. Moreover, our model of interaction is abstract, and supports, for instance, discrete time , continuous time, and hybrid computational models . Being based in Unifying Theories of Programming (UTP), our theory can be composed with further computational theories to support semantics for multi-paradigm languages. Practical reasoning support is provided via our proof framework, Isabelle/UTP, including a proof tactic that reduces a conjecture about a reactive program to three predicates, symbolically characterising its assumptions and guarantees about intermediate and final observations. This allows us to verify programs with a large or infinite state space. Our work advances the state-of-the-art in semantics for reactive languages, description of their contractual specifications, and compositional verification.},
  archive      = {J_TCS},
  author       = {Simon Foster and Ana Cavalcanti and Samuel Canham and Jim Woodcock and Frank Zeyda},
  doi          = {10.1016/j.tcs.2019.09.017},
  journal      = {Theoretical Computer Science},
  pages        = {105-140},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Unifying theories of reactive design contracts},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evaluating lambda terms with traversals. <em>TCS</em>,
<em>802</em>, 77–104. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method to evaluate untyped lambda terms based on a term tree-traversing technique and judicious use of eta-expansion. The traversal method is inspired by Game Semantics. As traversals explore nodes of the term tree, they dynamically eta-expand some of the subterms to locate their non-immediate arguments. A quantity called dynamic arity determines the necessary amount of eta-expansion to perform at a given point. Traversals are finitely enumerable and characterize the paths in the tree representation of the beta-normal form when it exists. Correctness of the evaluation method follows from the fact that traversals implement leftmost linear reduction , a non-standard reduction strategy based on head linear reduction .},
  archive      = {J_TCS},
  author       = {William Blum},
  doi          = {10.1016/j.tcs.2019.08.035},
  journal      = {Theoretical Computer Science},
  pages        = {77-104},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Evaluating lambda terms with traversals},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strassen’s theorem for quantum couplings. <em>TCS</em>,
<em>802</em>, 67–76. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strassen&#39;s theorem for probabilistic couplings is a fundamental theorem in probability theory that can be used to bound the probability of an event in a distribution by the probability of an event in another distribution coupled with the first. It has been widely applied in computer science for analysis of random algorithms, machine learning and verification of security and privacy protocols. We extend the coupling techniques in probability theory to quantum systems . A quantum generalisation of the notion of lifting, a coupling under certain constraints, is introduced. Several interesting examples and basic properties of quantum couplings and liftings are presented. Finally, a quantum extension of Strassen&#39;s theorem is established.},
  archive      = {J_TCS},
  author       = {Li Zhou and Shenggang Ying and Nengkun Yu and Mingsheng Ying},
  doi          = {10.1016/j.tcs.2019.08.026},
  journal      = {Theoretical Computer Science},
  pages        = {67-76},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Strassen&#39;s theorem for quantum couplings},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A core model for choreographic programming. <em>TCS</em>,
<em>802</em>, 38–66. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choreographic Programming is a paradigm for developing concurrent programs that are deadlock-free by construction, as a result of programming communications declaratively and then synthesising process implementations automatically. Despite strong interest on choreographies, a foundational model that explains which computations can be performed with the hallmark constructs of choreographies is still missing. In this work, we introduce Core Choreographies (CC), a model that includes only the core primitives of choreographic programming. Every computable function can be implemented as a choreography in CC, from which we can synthesise a process implementation where independent computations run in parallel. We discuss the design of CC and argue that it constitutes a canonical model for choreographic programming.},
  archive      = {J_TCS},
  author       = {Luís Cruz-Filipe and Fabrizio Montesi},
  doi          = {10.1016/j.tcs.2019.07.005},
  journal      = {Theoretical Computer Science},
  pages        = {38-66},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A core model for choreographic programming},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Algebraic graph rewriting with controlled embedding.
<em>TCS</em>, <em>802</em>, 19–37. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph transformation is a specification technique suitable for a wide range of applications, specially the ones that require a sophisticated notion of state. In graph transformation, states are represented by graphs and actions are specified by rules. Most algebraic approaches to graph transformation proposed in the literature ensure that if an item is preserved by a rule, so are its connections with the graph where it is embedded. But there are applications in which it is desirable to specify different embeddings. For example when cloning an item, there may be a need to handle the original and the copy in different ways. We propose a new algebraic approach to graph transformation, AGREE: Algebraic Graph Rewriting with controllEd Embedding, where rules allow one to specify how the embedding should be carried out. We define this approach in the framework of classified categories which are categories endowed with partial map classifiers. This new approach leads to graph transformations in which effects may be non-local, e.g. a rewrite step may alter a node of the host graph which is outside the image of the left-hand side of the considered rule. We propose a syntactic condition on AGREE rules which guarantees the locality of transformations. We also compare AGREE with other algebraic approaches to graph transformation.},
  archive      = {J_TCS},
  author       = {Andrea Corradini and Dominique Duval and Rachid Echahed and Frédéric Prost and Leila Ribeiro},
  doi          = {10.1016/j.tcs.2019.06.004},
  journal      = {Theoretical Computer Science},
  pages        = {19-37},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Algebraic graph rewriting with controlled embedding},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the complexity of the correctness problem for
non-zeroness test instruction sequences. <em>TCS</em>, <em>802</em>,
1–18. (<a href="https://doi.org/10.1016/j.tcs.2019.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the question to what extent it can be efficiently determined whether an arbitrary program correctly solves a given problem. This question is investigated with programs of a very simple form, namely instruction sequences, and a very simple problem, namely the non-zeroness test on natural numbers. The instruction sequences concerned are of a kind by which, for each n &gt; 0 n&amp;gt;0 , each function from { 0 , 1 } n {0,1}n to { 0 , 1 } {0,1} can be computed. The established results include the time complexities of the problem of determining whether an arbitrary instruction sequence correctly implements the restriction to { 0 , 1 } n {0,1}n of the function from { 0 , 1 } ⁎ ⁎ {0,1}⁎ to { 0 , 1 } {0,1} that models the non-zeroness test function, for n &gt; 0 n&amp;gt;0 , under several restrictions on the arbitrary instruction sequence.},
  archive      = {J_TCS},
  author       = {J.A. Bergstra and C.A. Middelburg},
  doi          = {10.1016/j.tcs.2019.03.040},
  journal      = {Theoretical Computer Science},
  pages        = {1-18},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the complexity of the correctness problem for non-zeroness test instruction sequences},
  volume       = {802},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020f). Editorial. <em>TCS</em>, <em>801</em>, iii. (<a
href="https://doi.org/10.1016/S0304-3975(19)30736-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Lila Kari ( Editor-in-Chief )},
  doi          = {10.1016/S0304-3975(19)30736-4},
  journal      = {Theoretical Computer Science},
  pages        = {iii},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Editorial},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The graph tessellation cover number: Chromatic bounds,
efficient algorithms and hardness. <em>TCS</em>, <em>801</em>, 175–191.
(<a href="https://doi.org/10.1016/j.tcs.2019.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tessellation of a graph is a partition of its vertices into vertex disjoint cliques . A tessellation cover of a graph is a set of tessellations that covers all of its edges, and the tessellation cover number is the size of the smallest tessellation cover. These concepts are motivated by their application to quantum walk models, in special, the evolution operator of the staggered model is obtained from a graph tessellation cover. We show that the minimum between the chromatic index of the graph and the chromatic number of its clique graph, which we call chromatic upper bound, is tight with respect to the tessellation cover number for star-octahedral and windmill graphs; whereas for ( 3 , p ) (3,p) -extended wheel graphs, the tessellation cover number is 3 and the chromatic upper bound is 3 p . The t - tessellability problem aims to decide whether there is a tessellation cover of the graph with t tessellations. Using graph classes whose tessellation cover numbers achieve the chromatic upper bound, we obtain that t -tessellability is polynomial-time solvable for bipartite, {triangle, proper major}-free, threshold, and diamond-free K -perfect graphs; whereas is NP NP -complete for triangle-free for t ≥ 3 t≥3 , unichord-free for t ≥ 3 t≥3 , planar for t = 3 t=3 , biplanar for t ≥ 3 t≥3 , chordal ( 2 , 1 ) (2,1) -graphs for t ≥ 4 t≥4 , ( 1 , 2 ) (1,2) -graphs for t ≥ 4 t≥4 , and diamond-free with diameter at most five for t = 3 t=3 . We improve the complexity of 2 -tessellability problem to linear time.},
  archive      = {J_TCS},
  author       = {A. Abreu and L. Cunha and C. de Figueiredo and L. Kowada and F. Marquezino and D. Posner and R. Portugal},
  doi          = {10.1016/j.tcs.2019.09.013},
  journal      = {Theoretical Computer Science},
  pages        = {175-191},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The graph tessellation cover number: Chromatic bounds, efficient algorithms and hardness},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the covariance-hessian relation in evolution strategies.
<em>TCS</em>, <em>801</em>, 157–174. (<a
href="https://doi.org/10.1016/j.tcs.2019.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider Evolution Strategies (ESs) operating only with isotropic Gaussian mutations on positive quadratic objective functions, and investigate the covariance matrix when constructed out of selected individuals by truncation. We prove that the covariance matrix over ( 1 , λ ) (1,λ) -selected decision vectors becomes proportional to the inverse of the landscape Hessian as the population-size λ increases. This confirms a classical hypothesis that statistical learning of the landscape is an inherent characteristic of standard ESs, and that this distinguishing capability stems only from the usage of isotropic Gaussian mutations and rank-based selection. Even though the model under consideration does not precisely conform with practically encountered scenarios, it plays a role of a theoretical foundation for learning capabilities within ESs. We also provide broad numerical validation for the proven results, and present empirical evidence for its generalization to ( μ , λ ) (μ,λ) -selection.},
  archive      = {J_TCS},
  author       = {Ofer M. Shir and Amir Yehudayoff},
  doi          = {10.1016/j.tcs.2019.09.002},
  journal      = {Theoretical Computer Science},
  pages        = {157-174},
  shortjournal = {Theor. Comput. Sci.},
  title        = {On the covariance-hessian relation in evolution strategies},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Spiking neural p systems with structural plasticity and
anti-spikes. <em>TCS</em>, <em>801</em>, 143–156. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P systems (in short, SNP systems) are a class of distributed parallel computing devices, abstracted from the way neurons communicate by means of spikes. This paper discusses spiking neural P systems with structural plasticity and anti-spikes (in short, SNP-SPA systems), a new variant of SNP systems with two interesting features: structural plasticity and anti-spike. By means of plasticity rules in neurons, SNP-SPA systems can provide a dynamic directed graph structure. Turing universality of SNP-SPA systems is discussed. It is proven that SNP-SPA systems as number generating/accepting devices are Turing universal, and a small example with 56 neurons that computes a universal function is constructed. The introduction of anti-spikes allows to reduce the modules in the proof of universality.},
  archive      = {J_TCS},
  author       = {Qian Yang and Bo Li and Yue Huang and Hong Peng and Jun Wang},
  doi          = {10.1016/j.tcs.2019.08.034},
  journal      = {Theoretical Computer Science},
  pages        = {143-156},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Spiking neural p systems with structural plasticity and anti-spikes},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Working principles of binary differential evolution.
<em>TCS</em>, <em>801</em>, 110–142. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conduct a first fundamental analysis of the working principles of binary differential evolution (BDE), an optimization heuristic for binary decision variables that was derived by Gong and Tuson (2007) from the very successful classic differential evolution (DE) for continuous optimization . We show that unlike most other optimization paradigms, it is stable in the sense that neutral bit values are sampled with probability close to 1/2 for a long time. This is generally a desirable property , however, it makes it harder to find the optima for decision variables with small influence on the objective function. This can result in an optimization time exponential in the dimension when optimizing simple symmetric functions like OneMax. On the positive side, BDE quickly detects and optimizes the most important decision variables. For example, dominant bits converge to the optimal value in time logarithmic in the population size. This enables BDE to optimize the most important bits very fast. Overall, our results indicate that BDE is an interesting optimization paradigm having characteristics significantly different from classic evolutionary algorithms or estimation-of-distribution algorithms (EDAs). On the technical side, we observe that the strong stochastic dependencies in the random experiment describing a run of BDE prevent us from proving all desired results with the mathematical rigor that was successfully used in the analysis of other evolutionary algorithms . Inspired by mean-field approaches in statistical physics we propose a more independent variant of BDE, show experimentally its similarity to BDE, and prove some statements rigorously only for the independent variant. Such a semi-rigorous approach might be interesting for other problems in evolutionary computation where purely mathematical methods failed so far.},
  archive      = {J_TCS},
  author       = {Benjamin Doerr and Weijie Zheng},
  doi          = {10.1016/j.tcs.2019.08.025},
  journal      = {Theoretical Computer Science},
  pages        = {110-142},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Working principles of binary differential evolution},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Composable security against collective attacks of a modified
BB84 QKD protocol with information only in one basis. <em>TCS</em>,
<em>801</em>, 96–109. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum Cryptography uses the counter-intuitive properties of Quantum Mechanics for performing cryptographic tasks in a secure and reliable way. The Quantum Key Distribution (QKD) protocol BB84 has been proven secure against several important types of attacks: collective attacks and joint attacks. Here we analyze the security of a modified BB84 protocol, for which information is sent only in the z basis while testing is done in both the z and the x bases, against collective attacks. The proof follows the framework of a previous paper [1] , but it avoids a classical information-theoretical analysis and proves a fully composable security. We show that this modified BB84 protocol is as secure against collective attacks as the original BB84 protocol, and that it requires more bits for testing.},
  archive      = {J_TCS},
  author       = {Michel Boyer and Rotem Liss and Tal Mor},
  doi          = {10.1016/j.tcs.2019.08.014},
  journal      = {Theoretical Computer Science},
  pages        = {96-109},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Composable security against collective attacks of a modified BB84 QKD protocol with information only in one basis},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic chemical reaction networks for robustly
approximating arbitrary probability distributions. <em>TCS</em>,
<em>801</em>, 64–95. (<a
href="https://doi.org/10.1016/j.tcs.2019.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that discrete distributions on the d -dimensional non-negative integer lattice can be approximated arbitrarily well via the marginals of stationary distributions for various classes of stochastic chemical reaction networks . We begin by providing a class of detailed balanced networks and prove that they can approximate any discrete distribution to any desired accuracy. However, these detailed balanced constructions rely on the ability to initialize a system precisely, and are therefore susceptible to perturbations in the initial conditions. We therefore provide another construction based on the ability to approximate point mass distributions and prove that this construction is capable of approximating arbitrary discrete distributions for any choice of initial condition. In particular, the developed models are ergodic, so their limit distributions are robust to a finite number of perturbations over time in the counts of molecules.},
  archive      = {J_TCS},
  author       = {Daniele Cappelletti and Andrés Ortiz-Muñoz and David F. Anderson and Erik Winfree},
  doi          = {10.1016/j.tcs.2019.08.013},
  journal      = {Theoretical Computer Science},
  pages        = {64-95},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Stochastic chemical reaction networks for robustly approximating arbitrary probability distributions},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020b). Singular value decomposition assisted multicarrier
continuous-variable quantum key distribution. <em>TCS</em>,
<em>801</em>, 35–63. (<a
href="https://doi.org/10.1016/j.tcs.2019.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We define the singular value decomposition (SVD) assisted multicarrier continuous-variable quantum key distribution (CVQKD) protocol. The proposed protocol uses the singular value decomposition of the Gaussian quantum channel , which yields an additional degree of freedom for the phase space transmission. This additional degree of freedom can further be exploited in a multiple-access scenario. The SVD-assistance defines the eigenchannels of the Gaussian physical link, which can be used for the simultaneous reliable transmission of multiple user data streams. Our transmission model also includes the singular interference avoider (SIA) precoding scheme. The proposed SIA precoding scheme prevents the eigenchannel interference to reach an optimal transmission over a Gaussian link. We demonstrate the results through the adaptive multicarrier quadrature division–multiuser quadrature allocation (AMQD-MQA) CVQKD multiple-access scheme. The singular value assisted transmission provides improved simultaneous transmission rates for the users, particularly in crucial low signal-to-noise ratio regimes.},
  archive      = {J_TCS},
  author       = {Laszlo Gyongyosi},
  doi          = {10.1016/j.tcs.2019.07.029},
  journal      = {Theoretical Computer Science},
  pages        = {35-63},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Singular value decomposition assisted multicarrier continuous-variable quantum key distribution},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal parameter choices via precise black-box analysis.
<em>TCS</em>, <em>801</em>, 1–34. (<a
href="https://doi.org/10.1016/j.tcs.2019.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been observed that some working principles of evolutionary algorithms , in particular, the influence of the parameters, cannot be understood from results on the asymptotic order of the runtime, but only from more precise results. In this work, we complement the emerging topic of precise runtime analysis with a first precise complexity theoretic result. Our vision is that the interplay between algorithm analysis and complexity theory becomes a fruitful tool also for analyses more precise than asymptotic orders of magnitude. As particular result, we prove that the unary unbiased black-box complexity of the OneMax benchmark function class is n ln ⁡ ( n ) − c n ± o ( n ) nln⁡(n)−cn±o(n) for a constant c which is between 0.2539 and 0.2665. This runtime can be achieved with a simple ( 1 + 1 ) (1+1) -type algorithm using a fitness-dependent mutation strength. When translated into the fixed-budget perspective, our algorithm finds solutions which are roughly 13\% closer to the optimum than those of the best previously known algorithms. To prove our results, we formulate several new versions of the variable drift theorems, which also might be of independent interest.},
  archive      = {J_TCS},
  author       = {Benjamin Doerr and Carola Doerr and Jing Yang},
  doi          = {10.1016/j.tcs.2019.06.014},
  journal      = {Theoretical Computer Science},
  pages        = {1-34},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Optimal parameter choices via precise black-box analysis},
  volume       = {801},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
