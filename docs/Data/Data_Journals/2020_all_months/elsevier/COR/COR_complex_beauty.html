<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cor---211">COR - 211</h2>
<ul>
<li><details>
<summary>
(2020). A new constraint programming model and a linear
programming-based adaptive large neighborhood search for the vehicle
routing problem with synchronization constraints. <em>COR</em>,
<em>124</em>, 105085. (<a
href="https://doi.org/10.1016/j.cor.2020.105085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a vehicle routing problem which seeks to minimize cost subject to time window and synchronization constraints. In this problem, the fleet of vehicles is categorized into regular and special vehicles. Some customers require both vehicles’ services, whose service start times at the customer are synchronized. Despite its important real-world application, this problem has rarely been studied in the literature. To solve the problem, we propose a Constraint Programming (CP) model and an Adaptive Large Neighborhood Search (ALNS) in which the design of insertion operators is based on solving linear programming (LP) models to check the insertion feasibility. A number of acceleration techniques is also proposed to significantly reduce the computational time. The computational experiments show that our new CP model finds better solutions than an existing CP-based ALNS, when used on small instances with 25 customers and with a much shorter running time. Our LP-based ALNS dominates the CP-based ALNS, in terms of solution quality, when it provides solutions with better objective values, on average, for all instance classes. This demonstrates the advantage of using linear programming instead of constraint programming when dealing with a variant of vehicle routing problems with relatively tight constraints, which is often considered to be more favorable for CP-based methods. We also adapt our algorithm to solve a well-studied variant of the problem, and the obtained results show that the algorithm provides good solutions as state-of-the-art approaches and improves four best known solutions.},
  archive      = {J_COR},
  author       = {Minh Hoàng Hà and Tat Dat Nguyen and Thinh Nguyen Duy and Hoang Giang Pham and Thuy Do and Louis-Martin Rousseau},
  doi          = {10.1016/j.cor.2020.105085},
  journal      = {Computers &amp; Operations Research},
  pages        = {105085},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new constraint programming model and a linear programming-based adaptive large neighborhood search for the vehicle routing problem with synchronization constraints},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Compact formulations for multi-depot routing problems:
Theoretical and computational comparisons. <em>COR</em>, <em>124</em>,
105084. (<a href="https://doi.org/10.1016/j.cor.2020.105084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-depot routing problems mainly arise in distribution logistics where a fleet of vehicles are used to serve clients from a number of (potential) depots. The problem concerns deciding on the routes of each vehicle and the depots from which the vehicles depart, so as to minimize the total cost of travel. This paper reviews a number of existing compact formulations, and proposes new ones, for two types of multi-depot routing problems, one that includes the depot selection decisions, and the other where depots are pre-selected. The formulations are compared theoretically in terms of the strength of their linear programming relaxation, and computationally in terms of the running time needed to solve the instances to optimality.},
  archive      = {J_COR},
  author       = {Tolga Bektaş and Luís Gouveia and Daniel Santos},
  doi          = {10.1016/j.cor.2020.105084},
  journal      = {Computers &amp; Operations Research},
  pages        = {105084},
  shortjournal = {Comput. Oper. Res.},
  title        = {Compact formulations for multi-depot routing problems: Theoretical and computational comparisons},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on “an exact algorithm for the blocks relocation
problem with new lower bounds.” <em>COR</em>, <em>124</em>, 105082. (<a
href="https://doi.org/10.1016/j.cor.2020.105082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is a note on [Quispe, K. E. Y., Lintzmayer, C. N., &amp; Xavier, E. C. (2018). An exact algorithm for the blocks relocation problem with new lower bounds. Computers &amp; Operations Research , 99, 206–217]. Quispe et al. (2018) presented a new lower bound called LB-LIS for the blocks relocation problem. In this note, we show that the algorithm description of LB-LIS in the referred paper is incomplete. In addition, we propose a faster algorithm for computing this lower bound more efficiently. Computational experiments on a commonly used dataset reveal that the proposed algorithm uses on average 44.48\% less time than the original LB-LIS implementation for the instances tested.},
  archive      = {J_COR},
  author       = {Bo Jin},
  doi          = {10.1016/j.cor.2020.105082},
  journal      = {Computers &amp; Operations Research},
  pages        = {105082},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on “An exact algorithm for the blocks relocation problem with new lower bounds”},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic pricing and inventory management with demand
learning: A bayesian approach. <em>COR</em>, <em>124</em>, 105078. (<a
href="https://doi.org/10.1016/j.cor.2020.105078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a retail firm selling a durable product in a volatile market where the demand is price-sensitive and random but its distribution is unknown. The firm dynamically replenishes inventory and adjusts prices over time and learns about the demand distribution. Assuming that the demand model is of the multiplicative form and unmet demand is partially backlogged, we take the empirical Bayesian approach to formulate the problem as a stochastic dynamic program. We first identify a set of regularity conditions on demand models and show that the state-dependent base-stock list-price policy is optimal. We next employ the dimensionality reduction approach to separate the scale factor that captures observed demand information from the optimal profit function, which yields a normalized dynamic program that is more tractable. We also analyze the effect of demand learning on the optimal policy using the system without Bayesian update as a benchmark. We further extend our analysis to the case with unobserved lost sales and the case with additive demand.},
  archive      = {J_COR},
  author       = {Jue Liu and Zhan Pang and Linggang Qi},
  doi          = {10.1016/j.cor.2020.105078},
  journal      = {Computers &amp; Operations Research},
  pages        = {105078},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic pricing and inventory management with demand learning: A bayesian approach},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal pricing to minimize maximum regret with limited
demand information. <em>COR</em>, <em>124</em>, 105070. (<a
href="https://doi.org/10.1016/j.cor.2020.105070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a pricing problem faced by a seller that sells a given inventory of some product over a short selling horizon with limited demand information. The seller knows only that the demand is a linear function of the price, but does not know the parameters involved in the demand function. However, the seller knows that each parameter involved in the demand function belongs to a known interval. The seller’s objective is to determine the optimal price for the entire selling season to minimize the maximum regret, where the maximum regret is defined as the maximum possible loss of revenue due to not knowing the precise values of the parameters. We derive closed-form optimal solutions for the problem under all possible cases of input parameters and identify some structural properties of the solution. We conduct computational tests to compare our modeling approach with several benchmark approaches and report related insights.},
  archive      = {J_COR},
  author       = {Ming Chen and Zhi-Long Chen},
  doi          = {10.1016/j.cor.2020.105070},
  journal      = {Computers &amp; Operations Research},
  pages        = {105070},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal pricing to minimize maximum regret with limited demand information},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constraint programming model for multi-manned assembly line
balancing problem. <em>COR</em>, <em>124</em>, 105069. (<a
href="https://doi.org/10.1016/j.cor.2020.105069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the multi-manned assembly line has become popular since the large-sized products allow more than one operator working simultaneously on the same product in a workstation. This line usually occurs in large-size products such as cars, buses, trucks, and so on. The multi-manned assembly line offers several advantages, such as fewer number of workers/workstation and less cycle time to improve the performance of the system. However, it has been analyzed by a few papers in literature due to being a relatively new and complex problem. The current study aims to develop an efficient exact solution approach, constraint programming , to solve from small to large-size problems by minimizing the cycle time as a primary objective and the total number of workers as a secondary objective. First, two mixed-integer linear programming (MILP) models are proposed based on previous studies to solve the small test cases of the problem optimally. However, the models are not capable of solving the large-size test instances. Therefore, a constraint programming (CP) model is formulated to address both small and large-size data sets. The results of the CP model are compared with two MILP models and two heuristic algorithms available in the literature. The computational results indicate that the CP model discovers optimal solutions, approximately 90\% of all the instances, and small optimality gaps in the remaining instances. It is useful to highlight that the CP model is highly concise and solved by a black-box, commercial solver.},
  archive      = {J_COR},
  author       = {Zeynel Abidin Çil and Damla Kizilay},
  doi          = {10.1016/j.cor.2020.105069},
  journal      = {Computers &amp; Operations Research},
  pages        = {105069},
  shortjournal = {Comput. Oper. Res.},
  title        = {Constraint programming model for multi-manned assembly line balancing problem},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dantzig-wolfe decomposition for the facility location and
production planning problem. <em>COR</em>, <em>124</em>, 105068. (<a
href="https://doi.org/10.1016/j.cor.2020.105068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are several mathematical models proposed for the facility location and production planning problem in the literature. However, some of these models disregard what products each customer has ordered and neglect critical production-related constraints and setup decisions while some others do not well define the connection cost between customers and facilities. In this study, we propose two mathematical models to overcome the disadvantages aforementioned, along with their reformulations by item decomposition to improve lower bounds. We demonstrate that the pricing subproblems of the item decomposition are related to uncapacitated lot-sizing problems with the Wagner-Whitin property. This property is employed to enhance the performance of column generation for the item decomposition. Our computational results show that this item decomposition method can improve lower bounds over other classical lower bounding techniques, such as linear programming relaxation and model reformulation. Additionally, we implement the proposed item decomposition method to other benchmark problems in the literature and observe that our proposed method can improve the benchmark solutions with a statistical significance.},
  archive      = {J_COR},
  author       = {Tao Wu and Zhongshun Shi and Zhe Liang and Xiaoning Zhang and Canrong Zhang},
  doi          = {10.1016/j.cor.2020.105068},
  journal      = {Computers &amp; Operations Research},
  pages        = {105068},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dantzig-wolfe decomposition for the facility location and production planning problem},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A matheuristic for solving the bilevel approach of the
facility location problem with cardinality constraints and preferences.
<em>COR</em>, <em>124</em>, 105066. (<a
href="https://doi.org/10.1016/j.cor.2020.105066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a generalized version of the facility location problem with customer preferences which includes an additional constraint on the number of customers which can be allocated to each facility. The model aims to minimize the total cost due to opening facilities and allocating customers while taking into account both customer preferences for the facilities and these cardinality constraints. First, two approaches to deal with this problem are proposed, which extend the single level and bilevel formulations of the problem in which customers are free to select their most preferred open facility. After analyzing the implications of assuming any of the two approaches, in this research, we adopt the approach based on the hierarchical character of the model which leads to the formulation of a bilevel optimization problem. Then, taking advantage of the characteristics of the lower level problem, a single level reformulation of the bilevel optimization model is developed based on duality theory which does not require the inclusion of additional binary variables. Finally, we develop a simple but effective matheuristic for solving the bilevel optimization problem whose general framework follows that of an evolutionary algorithm and exploits the bilevel structure of the model. The chromosome encoding pays attention to the upper level variables and controls the facilities which are open. Then, an optimization model is solved to allocate customers in accordance with their preferences and the availability of the open facilities. A computational experiment shows the effectiveness of the matheuristic in terms of the quality of the solutions yielded and the computing time.},
  archive      = {J_COR},
  author       = {Herminia I. Calvete and Carmen Galé and José A. Iranzo and José-Fernando Camacho-Vallejo and Martha-Selene Casas-Ramírez},
  doi          = {10.1016/j.cor.2020.105066},
  journal      = {Computers &amp; Operations Research},
  pages        = {105066},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for solving the bilevel approach of the facility location problem with cardinality constraints and preferences},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A study on the pickup and delivery problem with time
windows: Matheuristics and new instances. <em>COR</em>, <em>124</em>,
105065. (<a href="https://doi.org/10.1016/j.cor.2020.105065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present work, we study the Pickup and Delivery Problem with Time Windows, which generalizes the well-known Vehicle Routing Problem and has many potential applications to transportation services. The contributions span from an improved hybrid algorithm with a mathematical programming component (matheuristic) to a new method to generate instances for routing problems based on open data . We further provide a thorough component analysis of the proposed algorithm, a comparison to state-of-the-art methods, and investigate the differences in results obtained for a standard instance set and a new testbed . Numerical experiments show the proposed matheuristic works well for the standard benchmark set, whereas results in the new set are surprisingly divergent. The possible reasons and future research directions are discussed. In addition, a number of solutions to the standard instances have been improved.},
  archive      = {J_COR},
  author       = {Carlo S. Sartori and Luciana S. Buriol},
  doi          = {10.1016/j.cor.2020.105065},
  journal      = {Computers &amp; Operations Research},
  pages        = {105065},
  shortjournal = {Comput. Oper. Res.},
  title        = {A study on the pickup and delivery problem with time windows: Matheuristics and new instances},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Balancing of two-sided disassembly lines: Problem
definition, MILP model and genetic algorithm approach. <em>COR</em>,
<em>124</em>, 105064. (<a
href="https://doi.org/10.1016/j.cor.2020.105064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recovery of end of life (EOL) products has become an important issue in terms of economic as well as social and environmental considerations. Recent rigid environmental regulations also contribute to the popularity of disassembly and product recovery topics among academicians and practitioners. Disassembly lines have been utilised to break EOL products into pieces and remove parts which can be reused in the manufacturing of new products. However, to the best of the authors’ knowledge, there is no research on the two-sided disassembly lines, which are used for disassembly of large-sized products. Therefore, this research contributes to literature by introducing the two-sided disassembly line balancing problem (TDLBP) and modelling it mathematically for the first time. The problem is depicted and the challenges are explored through extensive numerical examples. Secondly, a powerful genetic algorithm approach, called 2-GA, is developed for solving the introduced TDLBP considering complex AND/OR precedence relations. Computational tests are conducted to test the performance of the proposed 2-GA and the results are compared to those obtained from CPLEX and tabu search algorithm. From the comparison of the obtained solutions, it can be concluded that 2-GA has a superior performance in finding optimal (or at least near-optimal) solutions usually within less than one second.},
  archive      = {J_COR},
  author       = {Ibrahim Kucukkoc},
  doi          = {10.1016/j.cor.2020.105064},
  journal      = {Computers &amp; Operations Research},
  pages        = {105064},
  shortjournal = {Comput. Oper. Res.},
  title        = {Balancing of two-sided disassembly lines: Problem definition, MILP model and genetic algorithm approach},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exact dynamic programming algorithm for the
precedence-constrained class sequencing problem. <em>COR</em>,
<em>124</em>, 105063. (<a
href="https://doi.org/10.1016/j.cor.2020.105063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the precedence-constrained class sequencing problem (PCCSP). In scheduling terms, this is a single-machine problem with precedence constraints and family setups with the goal of minimizing the number of setups. From a practical perspective, PCCSP covers a wide range of applications such as, for example, scheduling problems in systems with job families where multipurpose processors need retooling to switch from a job of one family to a job of another family. Previous research has shown that PCCSP is NP-hard and that no polynomial-time algorithm with constant worst-case performance exists unless P = NP P=NP . So far, only little research has been conducted on the development of specific computational methods for PCCSP. This article bridges this gap by proposing a dynamic programming algorithm for solving PCCSP exactly. It comprises specialized lower bound computations, node merging and precedence reasoning algorithms, and heuristics that successfully exploit the problem’s structure. Based on extensive numerical experiments, we analyze the algorithm in detail and show that it outperforms mixed-integer programming and constraint programming models.},
  archive      = {J_COR},
  author       = {Reinhard Bürgy and Alain Hertz and Pierre Baptiste},
  doi          = {10.1016/j.cor.2020.105063},
  journal      = {Computers &amp; Operations Research},
  pages        = {105063},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact dynamic programming algorithm for the precedence-constrained class sequencing problem},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact approaches to the robust vehicle routing problem with
time windows and multiple deliverymen. <em>COR</em>, <em>124</em>,
105062. (<a href="https://doi.org/10.1016/j.cor.2020.105062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the vehicle routing problem with time windows and multiple deliverymen (VRPTWMD) under uncertain demand as well as uncertain travel and service times. This variant is faced by logistics companies that deliver products to retailers located in congested urban areas, where service times are relatively long compared to travel times, and depend on the number of deliverymen assigned to each route. Differently from traditional variants, these service times show high variability, requiring an appropriate way of handling the related uncertainty. We extend two mathematical formulations to represent the VRPTWMD under uncertainty, using the robust optimization paradigm with budgeted uncertainty sets, and developed effective exact solution methods for solving each of them. The first formulation is a robust vehicle flow model solved by a tailored branch-and-cut algorithm that resorts to 1- and 2-path inequalities that we show how to effectively separate. The second formulation is a set partitioning model, for which we propose a branch-price-and-cut algorithm that relies on a robust resource-constrained elementary shortest path problem. The results of computational experiments using instances from the literature and risk analysis via a Monte Carlo simulation show the importance of incorporating uncertainties in the VRPTWMD, and indicate the sensitivity of decisions as well as cost and risk to the level of uncertainty in the input data.},
  archive      = {J_COR},
  author       = {Jonathan De La Vega and Pedro Munari and Reinaldo Morabito},
  doi          = {10.1016/j.cor.2020.105062},
  journal      = {Computers &amp; Operations Research},
  pages        = {105062},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact approaches to the robust vehicle routing problem with time windows and multiple deliverymen},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey of the parallel assembly lines balancing problem.
<em>COR</em>, <em>124</em>, 105061. (<a
href="https://doi.org/10.1016/j.cor.2020.105061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assembly lines are mass production systems which are significant in the industrial production of both standard and customised products. Currently, industrial companies offer several products and it is common for an assembly system to have multiple assembly lines. Parallel assembly lines are multiple lines located in such a way as to allow improvements in the system’s efficiency through the use of common resources. In recent years several research studies have been made on parallel assembly lines. In this paper, we survey the parallel assembly lines balancing problem (PALBP) studies. Moreover, a classification scheme is provided to ease understanding. Finally, the main gaps in the literature are described and future research directions are presented.},
  archive      = {J_COR},
  author       = {Harry Aguilar and Alberto García-Villoria and Rafael Pastor},
  doi          = {10.1016/j.cor.2020.105061},
  journal      = {Computers &amp; Operations Research},
  pages        = {105061},
  shortjournal = {Comput. Oper. Res.},
  title        = {A survey of the parallel assembly lines balancing problem},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A matheuristic framework for the three-dimensional single
large object placement problem with practical constraints. <em>COR</em>,
<em>124</em>, 105058. (<a
href="https://doi.org/10.1016/j.cor.2020.105058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Three-dimensional Single Large Object Placement Problem consists of a set of weakly heterogeneous items that must be placed inside a single larger object without overlapping each other. Many constraints can be considered depending on the practical specifications of the problem being solved, such as orientation, stability, weight limit and positioning. Although this is a well-known problem which has received considerable academic attention, most of the research limits itself to considering only three basic constraints: non-overlap, orientation and stability of the placed items. Recent literature concerning the problem has indicated that there is a pressing need for solution methods which consider a more realistic number of sets of practical constraints given that it is very uncommon to find real-world situations where only a few of these constraints are considered together. Therefore, this paper introduced a well-performing matheuristic framework which considers multiple practical constraints: orientation, load balance, loading priorities, positioning, stability, stacking and weight limit. An extension of the developed method considering multiple containers is also discussed. Results are compared against the state of the art from the literature and demonstrate the robustness of the proposed matheuristic with respect to different combinations of constraints.},
  archive      = {J_COR},
  author       = {E.F. da Silva and A.A.S. Leão and F.M.B. Toledo and T. Wauters},
  doi          = {10.1016/j.cor.2020.105058},
  journal      = {Computers &amp; Operations Research},
  pages        = {105058},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic framework for the three-dimensional single large object placement problem with practical constraints},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the p-hub interdiction problem. <em>COR</em>,
<em>124</em>, 105056. (<a
href="https://doi.org/10.1016/j.cor.2020.105056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hub location models are one of the basic concepts to model design problems for communication and traffic networks. These networks are often exposed to threats such as attacks or natural disasters. However, the literature on extensions of hub location models capable of taking such threats into account is scarce. In this article, we investigate the so-called multiple allocation p -hub r -interdiction problem, where a locator has to choose p hubs, knowing in advance that r r&amp;lt;p of them will be interdicted. The objective is to minimize the total routing costs in the network after interdiction. This problem can also be interpreted as a minmax-robust p -hub location problem with an exponentially large uncertainty set containing the worst case for each choice of hubs. We present a new bi-level formulation for the problem and investigate its mathematical structure . Using these structural results, we propose the first exact solution procedure for the problem. We compute the optimal solutions for the well-known CAB-data set and compare them to heuristic results. Moreover, we investigate the complexity of the problem and show that already the interdiction problem for given hubs is NP-hard.},
  archive      = {J_COR},
  author       = {Thomas Ullmert and Stefan Ruzika and Anita Schöbel},
  doi          = {10.1016/j.cor.2020.105056},
  journal      = {Computers &amp; Operations Research},
  pages        = {105056},
  shortjournal = {Comput. Oper. Res.},
  title        = {On the p-hub interdiction problem},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An extension of the reorder point method by using advance
demand spike information. <em>COR</em>, <em>124</em>, 105055. (<a
href="https://doi.org/10.1016/j.cor.2020.105055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses a reorder point method with an extended inventory position. The inventory position is decreased by near future known demand spikes. This advance demand information helps to improve the performance of the reorder point method. The proposed extension leads to a hybrid model: make-to-stock for demand less than the spike threshold and make-to-order for demand greater than the spike threshold. Furthermore, the number of cycles is modeled more generally and takes into account that the replenishment order has lot-size Q or an integer multiple of Q. An iterative solution procedure is developed for the proposed model, and the numerical results are shown to underpin the usefulness of the approach.},
  archive      = {J_COR},
  author       = {Herbert Jodlbauer and Matthias Dehmer},
  doi          = {10.1016/j.cor.2020.105055},
  journal      = {Computers &amp; Operations Research},
  pages        = {105055},
  shortjournal = {Comput. Oper. Res.},
  title        = {An extension of the reorder point method by using advance demand spike information},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Temporal constraints and device management for the skill
VRP: Mathematical model and lower bounding techniques. <em>COR</em>,
<em>124</em>, 105054. (<a
href="https://doi.org/10.1016/j.cor.2020.105054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a generalization of the Skill VRP that incorporates time windows aspects, precedence and synchronization constraints. Specifically, we are given a logistic network where nodes correspond to customers, and where each customer requires a set of (partially ordered) operations. A set of technicians is available to perform such operations, and each technician is qualified to execute only a subset of them, depending on his skill. By referring to a specific context such as Health Care, customers are patients while technicians are caregivers. In a Field Service context, instead, customers are usually referred to as clients while technicians as field technicians. The innovative aspect is that some operations may require a special device, which must be transported at the customer site and must be present at the customer location together with a technician qualified to use it. Given technician dependent traveling costs, we address the problem of defining the tours for the technicians and for the special device, while respecting the skill compatibility between customers and technicians, and the time windows, precedence and synchronization constraints. We propose a Mixed Integer Linear Programming (MILP) model for the generalized Skill VRP, and present some lower bounding techniques based on the proposed formulation. Preliminary computational experiments show that some lower bounding techniques may rapidly produce good lower bounds, thanks to quite effective valid inequalities . The returned percentage optimality gaps, estimated also thanks to a simple matheuristic, are in fact quite small for several scenarios of medium to large size, by encouraging the use of the proposed lower bounding techniques both as building blocks for designing exact approaches, and also as valuable tools to evaluate the efficacy of more sophisticated heuristic approaches to the problem.},
  archive      = {J_COR},
  author       = {Paola Cappanera and Cristina Requejo and Maria Grazia Scutellà},
  doi          = {10.1016/j.cor.2020.105054},
  journal      = {Computers &amp; Operations Research},
  pages        = {105054},
  shortjournal = {Comput. Oper. Res.},
  title        = {Temporal constraints and device management for the skill VRP: Mathematical model and lower bounding techniques},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integration of process planning and scheduling for
distributed flexible job shops. <em>COR</em>, <em>124</em>, 105053. (<a
href="https://doi.org/10.1016/j.cor.2020.105053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a problem regarding the joint decision of process planning and scheduling in the context of a distributed flexible job shop (DFJS). The joint decision is called integrated process planning and scheduling (IPPS). Therefore, the problem is called an IPPS/DFJS problem. This research develops a genetic algorithm (called GA_X ) to solve the IPPS/DFJS problem. The GA_X algorithm is meritorious insofar as it entails the development of an incomplete modeling scheme (chromosome Φ s Φs ) to represent an IPPS/DFJS solution. In chromosome Φ s Φs , only some decisions are explicitly modeled, and the remaining decisions are implicitly determined using heuristic rules that ensure load balancing among manufacturing resources. Therefore, GA_X generates load-balanced solutions and is more likely to search effectively. We optimize the genetic parameters of GA_X by conducting a full factorial experiment. Three experiments are conducted to compare GA_X with other algorithms. Experiment I involves two light-loading IPPS/DFJS instances. Experiment II involves 15 light-loading IPPS/flexible job shop (FJS) instances (degenerated cases of IPPS/DFJS problems). Experiment III involves 17 heavy-loading IPPS/DFJS instances. GA_X outperforms benchmark algorithms, and Φ s Φs (the proposed incomplete chromosome representation) has considerable merit. This finding highlights a promising direction in developing “incomplete solution representation schemes” when solving complex space-search problems with genetic or other metaheuristic algorithms.},
  archive      = {J_COR},
  author       = {Chi-Shiuan Lin and Pei-Yi Li and Jun-Min Wei and Muh-Cherng Wu},
  doi          = {10.1016/j.cor.2020.105053},
  journal      = {Computers &amp; Operations Research},
  pages        = {105053},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integration of process planning and scheduling for distributed flexible job shops},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Integrated optimization model and algorithm for pattern
generation and selection in logical analysis of data. <em>COR</em>,
<em>124</em>, 105049. (<a
href="https://doi.org/10.1016/j.cor.2020.105049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a new integrated optimization model and a greedy algorithm for generating patterns, directly derived from original data instead of binarized data, in logical analysis of data (LAD). Pattern generation, following data discretization (binarization) and support set selection to handle non-binary data, is a building block that largely influences LAD classification. These stand-alone steps are generally considered optimization problems, which are difficult to solve and make the LAD procedure very tedious. To this end, we propose a new mixed-integer linear program, in which data discretization and support set selection are integrated into a single pattern generation optimization model, aiming to generate multiple logical patterns to cover observations maximally in the original data space. Furthermore, we develop a greedy search algorithm, in which the optimization model is reduced and solved iteratively to efficiently generate patterns. We then examine the effectiveness of the generated patterns in both one-class and large-margin LAD classifiers. The computational results for simulated and real datasets demonstrate the competitive performance in terms of classification accuracy in a relatively short runtime compared with previously developed pattern generation methods and other state-of-the-art machine learning algorithms.},
  archive      = {J_COR},
  author       = {Ruilin Ouyang and Chun-An Chou},
  doi          = {10.1016/j.cor.2020.105049},
  journal      = {Computers &amp; Operations Research},
  pages        = {105049},
  shortjournal = {Comput. Oper. Res.},
  title        = {Integrated optimization model and algorithm for pattern generation and selection in logical analysis of data},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A manufacturer-buyers integrated inventory model with
generic distribution of lead times to deliver equal and/or unequal batch
sizes. <em>COR</em>, <em>124</em>, 105047. (<a
href="https://doi.org/10.1016/j.cor.2020.105047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although lead time variation is common in practice, integrated single-manufacturer multi-buyer model considering this factor is unavailable in the extant literature. This article considers generic distribution of lead times of delivering equal and/or unequal batch (sub-lot) sizes of a lot in developing a synchronised integrated single-manufacturer multi-buyer model. The batch sizes are assumed to be in geometric series . The variables considered in the model are the smallest batch size, total number of batches and number of unequal batch sizes delivered from the manufacturer to buyers. The smallest batch sizes delivered to the buyers are bounded below by 1 and above by the capacity of the transport vehicle. The minimal total cost solution technique to the model is derived by the method of differentiation. Significant minimal total cost reductions by the synchronised flow is illustrated through solutions to some numerical example problems. Sensitivity analyses on increasing costs of transportation, shortage, inventory and increasing mean lead times upon the optimal solution have been performed.},
  archive      = {J_COR},
  author       = {M.A. Hoque and Arijit Bhattacharya},
  doi          = {10.1016/j.cor.2020.105047},
  journal      = {Computers &amp; Operations Research},
  pages        = {105047},
  shortjournal = {Comput. Oper. Res.},
  title        = {A manufacturer-buyers integrated inventory model with generic distribution of lead times to deliver equal and/or unequal batch sizes},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Efficient approximate dynamic programming based on design
and analysis of computer experiments for infinite-horizon optimization.
<em>COR</em>, <em>124</em>, 105032. (<a
href="https://doi.org/10.1016/j.cor.2020.105032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approximate dynamic programming (ADP) method based on the design and analysis of computer experiments (DACE) approach has been demonstrated as an effective method to solve multistage decision-making problems in the literature. However, this method is still not efficient for infinite-horizon optimization considering the required large volume of sampling in the state space and high-quality value function identification. Therefore, we propose a sequential sampling algorithm and embed it into a DACE-based ADP method to obtain a high-quality value function approximation. Considering the limitations of the traditional stopping criterion (Bellman error bound), we further propose a 45-degree line stopping criterion to terminate value iteration early by identifying an optimally equivalent value function. A comparison of the computational results with those of other three existing policies indicates that the proposed sampling algorithm and stopping criterion can determine a high-quality ADP policy. Finally, we discuss the extrapolation issue of the value function approximated by multivariate adaptive regression splines, the results of which further demonstrate the quality of the ADP policy generated in this study.},
  archive      = {J_COR},
  author       = {Ying Chen and Feng Liu and Jay M. Rosenberger and Victoria C.P. Chen and Asama Kulvanitchaiyanunt and Yuan Zhou},
  doi          = {10.1016/j.cor.2020.105032},
  journal      = {Computers &amp; Operations Research},
  pages        = {105032},
  shortjournal = {Comput. Oper. Res.},
  title        = {Efficient approximate dynamic programming based on design and analysis of computer experiments for infinite-horizon optimization},
  volume       = {124},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the p-median problem on regular and lattice
networks. <em>COR</em>, <em>123</em>, 105057. (<a
href="https://doi.org/10.1016/j.cor.2020.105057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The p -median problem is one of the true classic problems of location science and has been applied in many ways. It involves the location of p -facilities on a network where the objective is to minimize the weighted distance of serving all demand. This problem was originally proposed by Hakimi (1964, 1965) where the facilities were telephone switching centers and the connections represent wire stretched between each customer and their closest facility. It has since been viewed as the quintessential public facility location problem as it involves placing facilities as close to as possible on the average to each demand. This problem was originally formulated as an integer-programming problem by ReVelle and Swain (1970). Their formulation has withstood the test of time as most of the approaches to optimally solve the p -median problem involve a form of this model. There are several notable exceptions to the use of the classical formulation which take advantage of the underlying distance matrix defined by regular networks (Elloumi 2010; García et al., 2011), such as grid-defined networks. We demonstrate that inherent properties of the distance matrix defined for regular networks can be taken into account, resulting in a reduced, frugal form of the classic p -median model of ReVelle and Swain (1970). This new model called CARS is tested and compared to a form of the original model, recent computational experience presented by Daskin and Maass (2015) and to a form of the model used by García et al. (2011). This test demonstrates that this new, simple model is very competitive to other approaches in solving sizable p -median problems using off-the-shelf commercial software.},
  archive      = {J_COR},
  author       = {Richard L. Church and Shaohua Wang},
  doi          = {10.1016/j.cor.2020.105057},
  journal      = {Computers &amp; Operations Research},
  pages        = {105057},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the p-median problem on regular and lattice networks},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Impeding challenges on industry 4.0 in circular economy:
Palm oil industry in malaysia. <em>COR</em>, <em>123</em>, 105052. (<a
href="https://doi.org/10.1016/j.cor.2020.105052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study contributes to identifying valid barriers and proposes a model to understand the challenges to Industry 4.0 in circular economy to obtain social, economic and environmental benefits in practice. Industry 4.0 and circular economy have a mutual effect in practice. Hence, this study aims to investigate how to impede the challenges of Industry 4.0 in circular economy in the context of the palm oil industry. Thirty significant challenge factors in Industry 4.0 in circular economy are collected, and the fuzzy Delphi Method is applied to address the qualitative information and translate the linguistic preferences. Interpretive structural modelling is to compose and interpretive the interrelationships in the impeding change on industry 4.0 in circular economy in practical model. The main findings are the identification of 18 essential challenges in Industry 4.0 in circular economy. The most important challenges are lack of automation system virtualization, unclear economic benefit of digital investment, lack of process design, unstable connectivity among firms and employment disruptions. This study contributes to unveiling what challenges Industry 4.0 in circular economy faces and how to address those challenges as a basis for operational decision-making. The limitations and future research directions are discussed.},
  archive      = {J_COR},
  author       = {Asma-Qamaliah Abdul-Hamid and Mohd Helmi Ali and Ming-Lang Tseng and Shulin Lan and Mukesh Kumar},
  doi          = {10.1016/j.cor.2020.105052},
  journal      = {Computers &amp; Operations Research},
  pages        = {105052},
  shortjournal = {Comput. Oper. Res.},
  title        = {Impeding challenges on industry 4.0 in circular economy: Palm oil industry in malaysia},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Load-dependent speed optimization in maritime inventory
routing. <em>COR</em>, <em>123</em>, 105051. (<a
href="https://doi.org/10.1016/j.cor.2020.105051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maritime inventory routing problems involve determining optimal routes for seagoing vessels between ports while managing the inventory of each port. Normally, such problems are considered with the vessels operating at fixed sailing speeds. However, the speed of vessels can typically be adjusted within an interval, and the actual fuel consumption depends on both the load and the speed of the vessel. The fuel consumption function combines speed and load in a non-linear manner, but can be approximated through linearization. In this work, to evaluate the importance of taking into account that both speeds and load levels influence the fuel costs, the resulting solutions are contrasted with solutions from the case where speeds and travel costs are taken as constants, as well as the case where speed is a decision, but the cost considered to be independent of the load. For either of these cases, load-dependent speed optimization can be added as a post-processing step. Computational experiments show that combining speed and load do have an impact on the selection of routes in maritime inventory routing problems, and that proper modelling of the fuel consumption can reduce sailing costs significantly. On the test instances considered, taking into account speed while ignoring the load leads to cost savings of around 38\%. Considering the fuel consumption as a function of speed and load when planning leads to additional cost savings of 28\%.},
  archive      = {J_COR},
  author       = {Line Eide and Gro Cesilie Håhjem Årdal and Nataliia Evsikova and Lars Magnus Hvattum and Sebastián Urrutia},
  doi          = {10.1016/j.cor.2020.105051},
  journal      = {Computers &amp; Operations Research},
  pages        = {105051},
  shortjournal = {Comput. Oper. Res.},
  title        = {Load-dependent speed optimization in maritime inventory routing},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Selection of time instants and intervals with support vector
regression for multivariate functional data. <em>COR</em>, <em>123</em>,
105050. (<a href="https://doi.org/10.1016/j.cor.2020.105050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When continuously monitoring processes over time, data is collected along a whole period, from which only certain time instants and certain time intervals may play a crucial role in the data analysis. We develop a method that addresses the problem of selecting a finite and small set of short intervals (or instants) able to capture the information needed to predict a response variable from multivariate functional data using Support Vector Regression (SVR). In addition to improving interpretability, storage requirements, and monitoring cost, feature selection can potentially reduce overfitting by mitigating data autocorrelation. We propose a continuous optimization algorithm to fit the SVR parameters and select intervals and instants. Our approach takes advantage of the functional nature of the data by formulating a new bilevel optimization problem that integrates selection of intervals and instants, tuning of some key SVR parameters and fitting the SVR. We illustrate the usefulness of our proposal in some benchmark data sets.},
  archive      = {J_COR},
  author       = {Rafael Blanquero and Emilio Carrizosa and Asunción Jiménez-Cordero and Belén Martín-Barragán},
  doi          = {10.1016/j.cor.2020.105050},
  journal      = {Computers &amp; Operations Research},
  pages        = {105050},
  shortjournal = {Comput. Oper. Res.},
  title        = {Selection of time instants and intervals with support vector regression for multivariate functional data},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-modal competitive hub location pricing problem with
customer loyalty and elastic demand. <em>COR</em>, <em>123</em>, 105048.
(<a href="https://doi.org/10.1016/j.cor.2020.105048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a multi-modal competitive hub location pricing problem whose target is the design of a transportation system for a company that plans to enter into a market with elastic demand, in which an existing transportation company operates its hub-and-spoke network. The entrant company aims to attract customers in the market by convenient locations for its hubs and proper pricing of its transportation services, while customer loyalty is different in the nodes. Hence, mixed-integer programming based on a multi-nominal logit model is proposed. Thereafter, to solve the single allocation hub-and-spoke model, it is decomposed into a bi-level model. In the new structure, the master problem is associated with hub location and assignment decisions, and the sub-problem is associated with pricing decisions. Moreover, upper and lower bounds are calculated to determine the price of transportation routes. Finally, based on a nested approach, a scatter search algorithm is used to search the solution space of the master problem, and a matheuristic method is designed to solve the pricing problem interactively. The proposed approach is employed to solve a case study in the postal service industry of Iran.},
  archive      = {J_COR},
  author       = {Mehdi Mahmoodjanloo and Reza Tavakkoli-Moghaddam and Armand Baboli and Atefeh Jamiri},
  doi          = {10.1016/j.cor.2020.105048},
  journal      = {Computers &amp; Operations Research},
  pages        = {105048},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-modal competitive hub location pricing problem with customer loyalty and elastic demand},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic path planning approach for dense, large,
grid-based automated guided vehicle systems. <em>COR</em>, <em>123</em>,
105046. (<a href="https://doi.org/10.1016/j.cor.2020.105046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time path planning for large, dense grid-based automated guided vehicle (AGV) systems, used for example to sort parcels, is challenging. Most approaches described in the literature are not fast enough for real-time control or are not able to avoid congestion. This paper presents a dynamic approach using a graph-representation of the grid system layout with vertex weights that are updated over time. By means of an extensive discrete-event simulation, we show that the proposed path planning approach significantly increases the throughput compared to existing approaches. Furthermore, it enables the recovery from deadlock situations.},
  archive      = {J_COR},
  author       = {K.J.C. Fransen and J.A.W.M. van Eekelen and A. Pogromsky and M.A.A. Boon and I.J.B.F. Adan},
  doi          = {10.1016/j.cor.2020.105046},
  journal      = {Computers &amp; Operations Research},
  pages        = {105046},
  shortjournal = {Comput. Oper. Res.},
  title        = {A dynamic path planning approach for dense, large, grid-based automated guided vehicle systems},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pre-processing a container yard under limited available
time. <em>COR</em>, <em>123</em>, 105045. (<a
href="https://doi.org/10.1016/j.cor.2020.105045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To pick up a container from a container terminal, other containers may need to be relocated to other positions. In practice, these relocation moves are usually done when it is busy at a terminal. However, if the crane is idle for some amount of time, it may be more efficient to execute some pre-processing moves to reduce the number of future relocation moves. In this paper, we propose a model for optimal pre-processing moves if the available time is limited. We develop a heuristic to produce fast solutions for this new optimization problem. This heuristic consists out of multiple phases and for each phase, two different approaches are possible, and thus, the heuristic produces multiple solutions. Besides that, an optimal branch-and-bound algorithm is presented. Third, we propose another heuristic in which the remaining relocation moves are estimated in a sub-optimal way in the branch-and-bound method. This algorithm is not guaranteed to find the optimal solution, but its running time is faster than the optimal branch-and-bound method. Finally, we give an integer linear program that can be used to extend these solutions for a single bay of containers to a complete yard of containers.},
  archive      = {J_COR},
  author       = {Bernard G. Zweers and Sandjai Bhulai and Rob D. van der Mei},
  doi          = {10.1016/j.cor.2020.105045},
  journal      = {Computers &amp; Operations Research},
  pages        = {105045},
  shortjournal = {Comput. Oper. Res.},
  title        = {Pre-processing a container yard under limited available time},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decomposition-based hyperheuristic approaches for the
bi-objective cold chain considering environmental effects. <em>COR</em>,
<em>123</em>, 105043. (<a
href="https://doi.org/10.1016/j.cor.2020.105043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a novel approach for a practical version of the cold chain, namely location-routing problem-based low-carbon cold chain (LRPLCCC). In the proposed bi-objective model, the first objective is the total logistics cost, including the fixed costs of the opened depots and leased vehicles, as well as the cost of fuel consumption and carbon emissions, and the second is to minimize the amount of quality degradation that aims at improving clients’ satisfaction and maintain product freshness. The cargos of clients are classified into three types: general, refrigerated, and frozen cargos. Since the presented problem is NP-hard, a novel multi-objective hyperheuristic (MOHH) was proposed to obtain the Pareto solutions. In this framework, three selection strategies were developed to improve the performance of MOHH, that is, random simple, choice function, and FRR-MAB (fitness rate rank based multi-armed bandit), and three acceptance criteria using the decomposition approaches in MOEA/D were also developed, namely penalty-based boundary intersection, Tchebycheff, and modified Tchebycheff approaches. Extensive experiments were provided to verify the efficiency of the proposed algorithms and assessed the effects of algorithm parameters on the Pareto front. The results showed that the efficiency of the proposed algorithm outperforms several existing well-known multi-objective evolutionary algorithms (MOEA).},
  archive      = {J_COR},
  author       = {Longlong Leng and Jingling Zhang and Chunmiao Zhang and Yanwei Zhao and Wanliang Wang and Gongfa Li},
  doi          = {10.1016/j.cor.2020.105043},
  journal      = {Computers &amp; Operations Research},
  pages        = {105043},
  shortjournal = {Comput. Oper. Res.},
  title        = {Decomposition-based hyperheuristic approaches for the bi-objective cold chain considering environmental effects},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A mathematical programming-based heuristic for the
production routing problem with transshipments. <em>COR</em>,
<em>123</em>, 105042. (<a
href="https://doi.org/10.1016/j.cor.2020.105042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production routing problem (PRP) is a difficult optimization problem which arises in the planning of integrated supply chains. The purpose of solving the PRP is the simultaneous optimization of the production, inventory, distribution, and routing decisions, which typically appears in vendor managed inventory systems. In this study, the classical PRP is extended by considering transshipments, either from supplier to retailers or between retailers, to further reduce the total cost. A mathematical programming-based heuristic is proposed to solve the problem. The algorithm is applied to two sets of randomly generated problem instances. The computational results show that the proposed approach is effective in solving the problem. Moreover, we conduct extensive numerical experiments to analyze the impact of the transshipments on the overall system.},
  archive      = {J_COR},
  author       = {Mustafa Avci and Seyda Topaloglu Yildiz},
  doi          = {10.1016/j.cor.2020.105042},
  journal      = {Computers &amp; Operations Research},
  pages        = {105042},
  shortjournal = {Comput. Oper. Res.},
  title        = {A mathematical programming-based heuristic for the production routing problem with transshipments},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simultaneously exploiting two formulations: An exact benders
decomposition approach. <em>COR</em>, <em>123</em>, 105041. (<a
href="https://doi.org/10.1016/j.cor.2020.105041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When modelling a given problem using integer linear programming techniques several possibilities often exist, each resulting in a different mathematical formulation of the problem. Usually, advantages and disadvantages can be identified in any single formulation. In this paper we consider mixed integer linear programs and propose an approach based on Benders decomposition to exploit the advantages of two different formulations when solving a problem. We propose applying Benders decomposition to a combined formulation, comprised of two separate formulations, augmented with linking constraints to ensure consistency between the decision variables of the respective formulations. We demonstrate the applicability of the proposed methodology to situations in which one of the formulations models a relaxation of the problem and to cases where one formulation is the Dantzig-Wolfe reformulation of the other. The proposed methodology guarantees a lower bound that is as good as the tighter of the two formulations, and we show how branching can be performed on the decision variables of either formulation. Finally, we test and compare the performance of the proposed approach on publicly available instances of the Cutting Stock Problem and the Split Delivery Vehicle Routing Problem . Compared to the best approaches from the literature, the proposed method shows promising performance and appears to be an attractive alternative.},
  archive      = {J_COR},
  author       = {Richard Martin Lusby and Mette Gamst and Stefan Ropke and Simon Spoorendonk},
  doi          = {10.1016/j.cor.2020.105041},
  journal      = {Computers &amp; Operations Research},
  pages        = {105041},
  shortjournal = {Comput. Oper. Res.},
  title        = {Simultaneously exploiting two formulations: An exact benders decomposition approach},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Effective neighborhood search with optimal splitting and
adaptive memory for the team orienteering problem with time windows.
<em>COR</em>, <em>123</em>, 105039. (<a
href="https://doi.org/10.1016/j.cor.2020.105039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Team Orienteering Problem with Time Windows (TOPTW) is an extension of the well-known Orienteering Problem. Given a set of locations, each one associated with a profit, a service time and a time window, the objective of the TOPTW is to plan a set of routes, over a subset of locations, that maximizes the total collected profit while satisfying travel time limitations and time window constraints. Within this paper, we present an effective neighborhood search for the TOPTW based on (1) the alternation between two different search spaces, a giant tour search space and a route search space , using a powerful splitting algorithm, and (2) the use of a long term memory mechanism to keep high quality routes encountered in elite solutions. We conduct extensive computational experiments to investigate the contribution of these components, and measure the performance of our method on literature benchmarks. Our approach outperforms state-of-the-art algorithms in terms of overall solution quality and computational time. It finds the current best known solutions, or better ones, for 89\% 89\% of the literature instances within reasonable runtimes. Moreover, it is able to achieve better average deviation than state-of-the-art algorithms within shorter computation times. Moreover, new improvements for 57 benchmark instances were found.},
  archive      = {J_COR},
  author       = {Youcef Amarouche and Rym Nesrine Guibadj and Elhadja Chaalal and Aziz Moukrim},
  doi          = {10.1016/j.cor.2020.105039},
  journal      = {Computers &amp; Operations Research},
  pages        = {105039},
  shortjournal = {Comput. Oper. Res.},
  title        = {Effective neighborhood search with optimal splitting and adaptive memory for the team orienteering problem with time windows},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Supply chain coordination of fresh agricultural products
based on consumer behavior. <em>COR</em>, <em>123</em>, 105038. (<a
href="https://doi.org/10.1016/j.cor.2020.105038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The circulation efficiency of the fresh agricultural product supply chain is greatly influenced by the purchasing power of end consumers. In this paper, a method to coordinate a fresh agricultural product supply chain with the consideration of strategic consumer behavior is proposed. First, considering the characteristics of the fresh agricultural products supply chain, the utility function of consumers is provided. Second, under the centralized chain, this study focuses on the impact of consumer behavior on supply chain decision-making, quantifies the strategic behavior of strategic consumers as a risk aversion coefficient, and analyzes the impact of consumer risk on supply chain decision-making. Third, two coordination contracts based on revenue sharing and wholesale price are designed for the decentralized decision making in fresh agricultural product supply chain. Finally, through numerical analysis , the sensitivity analysis of some key parameters in the model is carried out.},
  archive      = {J_COR},
  author       = {Bo Yan and Xiaoxu Chen and Congyan Cai and Shiyan Guan},
  doi          = {10.1016/j.cor.2020.105038},
  journal      = {Computers &amp; Operations Research},
  pages        = {105038},
  shortjournal = {Comput. Oper. Res.},
  title        = {Supply chain coordination of fresh agricultural products based on consumer behavior},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint decision of pricing and ordering in stochastic demand
with nash bargaining fairness. <em>COR</em>, <em>123</em>, 105037. (<a
href="https://doi.org/10.1016/j.cor.2020.105037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking fairness concerns of retailer into account, we extend the classical newsvendor model to a new type with Nash bargaining preference. Depending on the demand forms, three models are proposed: one benchmark case for deterministic demand, and two stochastic demand cases for multiplicative and additive patterns, respectively. We theoretically prove the existence and uniqueness of the optimal joint decision on pricing and ordering by maximising the fairness-concerned retailer’s utility function theoretically. The optimal strategy of the supplier is acquired via one dimensional search method numerically. The results show that the optimal price is increasing in terms of the fairness-concerned parameter, Nash bargaining power and wholesale price. But the optimal ordering changes in an opposite way. Numerical examples and experiments agree well with our theoretical analysis. It is worth noting that the degree of retailer’s fairness concerns can improve the retailer’s utility and performance of the supply chain , which is different from the traditional fairness-neutral scenario.},
  archive      = {J_COR},
  author       = {Jianxin Chen and Tonghua Zhang and Yongwu Zhou and Yuanguang Zhong},
  doi          = {10.1016/j.cor.2020.105037},
  journal      = {Computers &amp; Operations Research},
  pages        = {105037},
  shortjournal = {Comput. Oper. Res.},
  title        = {Joint decision of pricing and ordering in stochastic demand with nash bargaining fairness},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Underground mine scheduling of mobile machines using
constraint programming and large neighborhood search. <em>COR</em>,
<em>123</em>, 105036. (<a
href="https://doi.org/10.1016/j.cor.2020.105036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manual short-term scheduling in underground mines is a time-consuming and error-prone activity. In this work, we present a Constraint Programming approach capable of automating the short-term scheduling process in a cut-and-fill mine. The approach extends previous work by accounting for fleet travel times, and thus captures an important aspect of the real-world machine scheduling problem. We introduce two models: one that directly solves the original interruptible scheduling problem, and one that is based on solving a related uninterruptible scheduling problem and transforming its solution back to the original domain. Large Neighborhood Search is also employed with a domain-specific neighborhood definition that helps to find high-quality schedules faster. Problem instances derived from an operational mine are used to demonstrate the efficacy of our approach.},
  archive      = {J_COR},
  author       = {Max Åstrand and Mikael Johansson and Alessandro Zanarini},
  doi          = {10.1016/j.cor.2020.105036},
  journal      = {Computers &amp; Operations Research},
  pages        = {105036},
  shortjournal = {Comput. Oper. Res.},
  title        = {Underground mine scheduling of mobile machines using constraint programming and large neighborhood search},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An adaptive tabu search algorithm embedded with iterated
local search and route elimination for the bike repositioning and
recycling problem. <em>COR</em>, <em>123</em>, 105035. (<a
href="https://doi.org/10.1016/j.cor.2020.105035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bike repositioning and recycling problem (BRRP) is significant to develop a sustainable bike-sharing system and can effectively reduce the imbalance between demand and supply. This study investigates the static repositioning and recycling problem of a bike-sharing system, which is formulated as an integer linear programming model. The BRRP is a variant of the multi-depot simultaneous pickup and delivery problem with multi-commodity demand. To solve the proposed model, an adaptive tabu search (ATS) algorithm combined with six neighborhood structures is developed. Moreover, an iterated local search (ILS) and a route elimination operator are both embedded to reduce the number of routes. The performance of the proposed ATS is evaluated by comparing it with tabu search (TS) and variable neighborhood search (VNS). The experimental results show that the proposed algorithm performs better than TS and VNS in terms of the solution quality. The proposed ATS was used to analyze the bicycle system in New York City. Finally, a free solver is developed for the bike repositioning and recycling problem, which is named the BRRP Solver .},
  archive      = {J_COR},
  author       = {Dezhi Zhang and Wei Xu and Bin Ji and Shuangyan Li and Yajie Liu},
  doi          = {10.1016/j.cor.2020.105035},
  journal      = {Computers &amp; Operations Research},
  pages        = {105035},
  shortjournal = {Comput. Oper. Res.},
  title        = {An adaptive tabu search algorithm embedded with iterated local search and route elimination for the bike repositioning and recycling problem},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid adaptive large neighborhood search heuristic for
the team orienteering problem. <em>COR</em>, <em>123</em>, 105034. (<a
href="https://doi.org/10.1016/j.cor.2020.105034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Team Orienteering Problem (TOP) is a well-known NP-Hard vehicle routing problem in which one maximizes the collected profits for visiting some nodes. In this paper, we propose a Hybrid Adaptive Large Neighborhood Search (HALNS) to solve this problem. Our algorithm combines the exploration power of ALNS with local search procedures and an optimization stage using a Set Packing Problem to further improve the solutions. Extensive computational experiments demonstrate the high performance of our HALNS outperforming all the competing algorithms in the literature on a large set of benchmark instances in terms of solution quality and/or computational time. Our HALNS identifies all the 387 Best Known Solutions (BKS) from the literature on a first dataset including small-scale benchmark instances and all the 333 BKS for large-scale benchmark instances within very short computational times. Moreover, we improve one large-scale instance solution.},
  archive      = {J_COR},
  author       = {Farouk Hammami and Monia Rekik and Leandro C. Coelho},
  doi          = {10.1016/j.cor.2020.105034},
  journal      = {Computers &amp; Operations Research},
  pages        = {105034},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid adaptive large neighborhood search heuristic for the team orienteering problem},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A biased-randomized algorithm for optimizing efficiency in
parametric earthquake (re) insurance solutions. <em>COR</em>,
<em>123</em>, 105033. (<a
href="https://doi.org/10.1016/j.cor.2020.105033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural catastrophes with their widespread damage can overwhelm the financial systems of large communities. Catastrophe insurance is a well-understood financial risk transfer mechanism, aiming to provide resilience in the face of adversity. However, catastrophe insurance has generally a low penetration, mainly due to its high cost or to distrust of the product in providing a fast financial recovery. Parametric insurance is a form of derivative insurance that pays quickly and transparently based on a few measurable features of the event, offering a promising avenue to increase catastrophe insurance coverage. In the context of seismic risk, parametric policies may use location and magnitude of an earthquake to determine whether a payment should be made. In this paper we follow a design typology referred to as ‘cat-in-a-box’, where magnitude thresholds are defined over a set of cuboids that partition Earth’s crust. The main challenge in the design of these tools consists in finding the optimal magnitude thresholds for a large set of cubes that maximize efficiency for the insured, subjected to a budgetary constraint. Additional geometric constraints aim to reduce the volatility of payments under uncertainty. The parametric design problem is a combinatorial problem, which is NP-hard and large scale. In this paper we propose a fast heuristic and a biased-randomized algorithm to solve large-sized problems in reasonably low computing times. Experimental results illustrate the computational limits and solution quality associated with the proposed approaches.},
  archive      = {J_COR},
  author       = {Christopher Bayliss and Roberto Guidotti and Alejandro Estrada-Moreno and Guillermo Franco and Angel A. Juan},
  doi          = {10.1016/j.cor.2020.105033},
  journal      = {Computers &amp; Operations Research},
  pages        = {105033},
  shortjournal = {Comput. Oper. Res.},
  title        = {A biased-randomized algorithm for optimizing efficiency in parametric earthquake (Re) insurance solutions},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time production scheduling in the industry-4.0 context:
Addressing uncertainties in job arrivals and machine breakdowns.
<em>COR</em>, <em>123</em>, 105031. (<a
href="https://doi.org/10.1016/j.cor.2020.105031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The utilization of real-time information in production scheduling decisions becomes possible with the help of new developments in Information Technology and Industrial Informatics, such as Industry 4.0 . Regardless of the beliefs that the availability of such information will enhance scheduling decisions, several questions and concerns have been reported. One such question is to what extent can the availability of real-time information enhance scheduling decisions? Another concern is how can such information be utilized to advance scheduling decisions and when should it be used? Moreover, there is a general assumption that continuous rescheduling using real-time system updates is beneficial to some extent. However, this general assumption has not been extensively investigated in complex manufacturing systems, such as flexible job shops. Therefore, in this paper, our objective is to study the above-mentioned research questions by developing real-time scheduling (RTS) models for the flexible job-shop scheduling problem (FJSP) with unexpected new job arrivals and machine random breakdowns. We investigate how real-time updates on unexpected arrivals, the availability of machines (downtimes and recovery times), and the completion times of operations can be utilized to generate new schedules (i.e., rescheduling). The performance of the developed RTS models is also investigated under different settings for shop-floor events, different rescheduling strategies, rescheduling policies, and scheduling methods. Lastly, results, conclusions, and several promising research avenues are provided.},
  archive      = {J_COR},
  author       = {Mageed Ghaleb and Hossein Zolfagharinia and Sharareh Taghipour},
  doi          = {10.1016/j.cor.2020.105031},
  journal      = {Computers &amp; Operations Research},
  pages        = {105031},
  shortjournal = {Comput. Oper. Res.},
  title        = {Real-time production scheduling in the industry-4.0 context: Addressing uncertainties in job arrivals and machine breakdowns},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The stable set problem: Clique and nodal inequalities
revisited. <em>COR</em>, <em>123</em>, 105024. (<a
href="https://doi.org/10.1016/j.cor.2020.105024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable set problem is a fundamental combinatorial optimisation problem, that is known to be very difficult in both theory and practice. Some of the solution algorithms in the literature are based on 0-1 linear programming formulations. We examine an entire family of such formulations, based on so-called clique and nodal inequalities. As well as proving some theoretical results, we conduct extensive computational experiments. This enables us to derive guidelines on how to choose the right formulation for a given instance.},
  archive      = {J_COR},
  author       = {Adam N. Letchford and Fabrizio Rossi and Stefano Smriglio},
  doi          = {10.1016/j.cor.2020.105024},
  journal      = {Computers &amp; Operations Research},
  pages        = {105024},
  shortjournal = {Comput. Oper. Res.},
  title        = {The stable set problem: Clique and nodal inequalities revisited},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mixed integer linear programming and constraint programming
models for the online printing shop scheduling problem. <em>COR</em>,
<em>123</em>, 105020. (<a
href="https://doi.org/10.1016/j.cor.2020.105020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the online printing shop scheduling problem is considered. This challenging real problem, that appears in the nowadays printing industry, can be seen as a flexible job shop scheduling problem with sequence flexibility in which precedence constraints among operations of a job are given by an arbitrary directed acyclic graph. In addition, several complicating particularities such as periods of unavailability of the machines, resumable operations, sequence-dependent setup times, partial overlapping among operations with precedence constraints, release times, and fixed operations are also present in the addressed problem. In the present work, mixed integer linear programming and constraint programming models for the minimization of the makespan are presented. Modeling the problem is twofold. On the one hand, the problem is precisely defined. On the other hand, the capabilities and limitations of a commercial software for solving the models are analyzed. Extensive numerical experiments with small-, medium-, and large-sized instances are presented. Numerical experiments show that the commercial solver is able to optimally solve only a fraction of the small-sized instances when considering the mixed integer linear programming model; while all small-sized and a fraction of the medium-sized instances are optimally solved when considering the constraint programming formulation of the problem. Moreover, the commercial solver is able to deliver feasible solutions for the large-sized instances that are of the size of the instances that appear in practice.},
  archive      = {J_COR},
  author       = {Willian T. Lunardi and Ernesto G. Birgin and Philippe Laborie and Débora P. Ronconi and Holger Voos},
  doi          = {10.1016/j.cor.2020.105020},
  journal      = {Computers &amp; Operations Research},
  pages        = {105020},
  shortjournal = {Comput. Oper. Res.},
  title        = {Mixed integer linear programming and constraint programming models for the online printing shop scheduling problem},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving a production-routing problem with price-dependent
demand using an outer approximation method. <em>COR</em>, <em>123</em>,
105019. (<a href="https://doi.org/10.1016/j.cor.2020.105019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A production-routing problem with price-dependent demand (PRP-PD) is studied in this paper. Demand follows a general convex, differentiable, continuous and strictly decreasing function in price. The problem is modeled as a mixed integer nonlinear program (MINLP). Two Outer Approximation (OA) based algorithms are developed to solve the PRP-PD. The efficiency of the proposed algorithms in comparison with commercial MINLP solvers is demonstrated. The computational results show that our basic OA algorithm outperforms the commercial solvers both in solution quality and in computational time aspects. On the other hand, our extended (two-phase) OA algorithm provides near-optimal solutions very efficiently, especially for large problem instances. These findings prevail both for linear and for nonlinear demand functions. Additional sensitivity analyses are conducted to investigate the impact of different problem parameters on the optimal solution. The results show that the manufacturer should give higher priority to the retailer who has lower price sensitivity and who is closer to the manufacturer. Another takeaway is that a larger market size and a lower price sensitivity lead to more profit.},
  archive      = {J_COR},
  author       = {Somayeh Torkaman and Mohammad Reza Akbari Jokar and Nevin Mutlu and Tom Van Woensel},
  doi          = {10.1016/j.cor.2020.105019},
  journal      = {Computers &amp; Operations Research},
  pages        = {105019},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving a production-routing problem with price-dependent demand using an outer approximation method},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling jobs with release dates on identical parallel
machines by minimizing the total weighted completion time. <em>COR</em>,
<em>123</em>, 105018. (<a
href="https://doi.org/10.1016/j.cor.2020.105018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of scheduling a set of jobs that are released over the time on a set of identical parallel machines, aiming at the minimization of the total weighted completion time. This problem, referred to as P | r j | ∑ w j C j P|rj|∑wjCj , is of great importance in practice, because it models a variety of real-life applications. Despite its importance, the P | r j | ∑ w j C j P|rj|∑wjCj has not received much attention in the recent literature. In this work, we fill this gap by proposing mixed integer linear programs and a tailored branch-and-price algorithm. Our branch-and-price relies on the decomposition of an arc-flow formulation and on the use of efficient exact and heuristic methods for solving the pricing subproblem . Computational experiments carried out on a set of randomly generated instances prove that the proposed methods can solve to the proven optimality instances with up to 200 jobs and 10 machines, and provide very low gaps for larger instances.},
  archive      = {J_COR},
  author       = {Arthur Kramer and Mauro Dell’Amico and Dominique Feillet and Manuel Iori},
  doi          = {10.1016/j.cor.2020.105018},
  journal      = {Computers &amp; Operations Research},
  pages        = {105018},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling jobs with release dates on identical parallel machines by minimizing the total weighted completion time},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The distributionally robust machine scheduling problem with
job selection and sequence-dependent setup times. <em>COR</em>,
<em>123</em>, 105017. (<a
href="https://doi.org/10.1016/j.cor.2020.105017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an interesting variant of the parallel machine scheduling problem with sequence-dependent setup times, where a subset of jobs has to be selected to guarantee a minimum profit level while the total completion time is minimized. The problem is addressed under uncertainty, considering both the setup and the processing times as random parameters. To deal with the uncertainty and to hedge against the worst-case performance, a risk-averse distributionally robust approach, based on the conditional value-at-risk measure, is adopted. The computational complexity of the problem is tackled by a hybrid large neighborhood search metaheuristic . The efficiency of the proposed method is tested via computational experiments, performed on a set of benchmark instances.},
  archive      = {J_COR},
  author       = {M.E. Bruni and S. Khodaparasti and E. Demeulemeester},
  doi          = {10.1016/j.cor.2020.105017},
  journal      = {Computers &amp; Operations Research},
  pages        = {105017},
  shortjournal = {Comput. Oper. Res.},
  title        = {The distributionally robust machine scheduling problem with job selection and sequence-dependent setup times},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Minimizing the total travel time with limited unfairness in
traffic networks. <em>COR</em>, <em>123</em>, 105016. (<a
href="https://doi.org/10.1016/j.cor.2020.105016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently developed technologies are changing mobility dramatically. Autonomous and interactive vehicles enable a coordination of the sat-nav devices of traveling vehicles aimed at assigning paths with the goal of eliminating congestion and, more in general, of reducing the total travel time in traffic networks. In this paper we tackle the problem of finding a traffic assignment that minimizes the total travel time on a network, while guaranteeing that the paths of users with the same origin and destination have similar path traversal times. While previous approaches have identified the eligible paths a priori, we propose two mixed integer nonlinear programming models, along with their mixed integer linear approximations, that identify paths that satisfy the desired level of fairness while minimizing the total travel time on the network. The two models differ for the unfairness measure adopted. Computational results show that the total travel time spent in the network is very close to the minimum possible, that is the one obtained by the system optimum solution, while guaranteeing to each user a very low level of experienced unfairness. A heuristic algorithm is also proposed which is shown to generate high quality solutions.},
  archive      = {J_COR},
  author       = {E. Angelelli and V. Morandi and M.G. Speranza},
  doi          = {10.1016/j.cor.2020.105016},
  journal      = {Computers &amp; Operations Research},
  pages        = {105016},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing the total travel time with limited unfairness in traffic networks},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing a production-inventory system under a cost
target. <em>COR</em>, <em>123</em>, 105015. (<a
href="https://doi.org/10.1016/j.cor.2020.105015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving cost targets is a major concern for business managers. In this paper, we consider two risk management criteria for a production-inventory system under a cost target: Probability of Loss and Expected Loss . We study two models with stochastic demand and production: The unit stockout cost model and the backlogging cost rate model. We analyze a limited-information setting that is an excellent approximation to a full-information setting. We discover that the optimal inventory decisions for minimizing probability of loss are identical for both models, and that the optimal inventory decisions for minimizing expected loss share a similar structure for both models. In addition, we investigate inventory decisions when minimizing the expected cost subject to a probability of loss constraint. Extension to a generally-distributed unit production time is also explored. We provide comparative statics and managerial insights of value to loss-aware managers.},
  archive      = {J_COR},
  author       = {Bo Li and Qingkai Ji and Antonio Arreola-Risa},
  doi          = {10.1016/j.cor.2020.105015},
  journal      = {Computers &amp; Operations Research},
  pages        = {105015},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing a production-inventory system under a cost target},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A tabu search algorithm with controlled randomization for
constructing feasible university course timetables. <em>COR</em>,
<em>123</em>, 105007. (<a
href="https://doi.org/10.1016/j.cor.2020.105007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {University Course Timetabling Problem (UCTP) is one of the most studied timetabling problems. In this work, the problem of finding a feasible solution for the UCTP, i.e., a solution that satisfies all hard constraints, is addressed. To cater for the algorithm design , the problem is firstly reformulated into a version where only one hard constraint needs to be considered in the minimization procedure. Then a novel Tabu search algorithm is proposed, which integrates the controlled randomization strategy and threshold mechanism into the original Tabu search framework. Experiments on a set of 60 well-known Lewis benchmark instances show that the proposed algorithm achieves competitive results compared with eight reference algorithms. In particular, when the stop condition is relaxed, the proposed algorithm can find feasible solutions for all the 60 instances, two of which are missed in previous study.},
  archive      = {J_COR},
  author       = {Mao Chen and Xiangyang Tang and Ting Song and Chao Wu and Sanya Liu and Xicheng Peng},
  doi          = {10.1016/j.cor.2020.105007},
  journal      = {Computers &amp; Operations Research},
  pages        = {105007},
  shortjournal = {Comput. Oper. Res.},
  title        = {A tabu search algorithm with controlled randomization for constructing feasible university course timetables},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An effective benders decomposition algorithm for solving the
distributed permutation flowshop scheduling problem. <em>COR</em>,
<em>123</em>, 105006. (<a
href="https://doi.org/10.1016/j.cor.2020.105006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s centralized globalized economy, large manufacturing firms operate more than one production center. Therefore, the multifactory production scheduling environment, so-called the distributed scheduling problem, is gaining more and more attention from the authors. In this context, which factory will manufacture which product is an important decision making process. The distributed permutation flowshop scheduling problem (DPFSP) provided with real life applications has attracted attention of the researchers for nearly one decade as one of the special cases of the distributed scheduling problem. In the current literature, approximation methods have been intensely used for solving the DPFSP and only one paper containing the exact solution methods has been published to solve this problem. In this paper, the best mathematical formulations available in the current literature has been further improved and traditional and hybrid Benders decomposition algorithms are presented through the proposed new mathematical model. The developed new model is a position based model intended for restricting the domains of decision variables and assigning jobs to sequential positions in the related decision variables. The proposed hybrid Benders decomposition algorithm consists of the hybridization of NEH2_en local search algorithm, a mathematical model to find the upper bound for the number of positions used in the related decision variables, the LS3 algorithm, with the Benders decomposition algorithms. The new and best exact methods available in the literature are compared with each other by using the benchmark data sets and the experimental results showed that the new exact methods developed in this paper are superior to the existing exact methods in all aspects. In this paper, 18 new best solutions are founded for the DPFSP.},
  archive      = {J_COR},
  author       = {Alper Hamzadayı},
  doi          = {10.1016/j.cor.2020.105006},
  journal      = {Computers &amp; Operations Research},
  pages        = {105006},
  shortjournal = {Comput. Oper. Res.},
  title        = {An effective benders decomposition algorithm for solving the distributed permutation flowshop scheduling problem},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A comparative study of solution representations for the
unrelated machines environment. <em>COR</em>, <em>123</em>, 105005. (<a
href="https://doi.org/10.1016/j.cor.2020.105005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling problems are quite difficult to solve since in many cases no exact algorithms exist which can obtain the optimal solution in a reasonable amount of time. Therefore, these problems are often solved by using various metaheuristic methods, like genetic algorithms. To use these methods, the first step which needs to be performed is to define an encoding scheme that will be used to represent the solutions. Until now, several encoding schemes were proposed for the unrelated machines environment, each of which comes with its own benefits and drawbacks. However, the performance of metaheuristic methods depends on the applied encoding scheme. Unfortunately, no extensive research was performed in the literature to compare different solution representations for the unrelated machines scheduling problem. Therefore, the choice of the solution representation used is mostly provisional and is usually not based on any existing knowledge of how it would perform on the considered problem. This can cause the algorithms to obtain suboptimal results, which can lead to wrong conclusions about the performance. Thus, the goal of this paper is to test seven solution representations that were used in previous studies to represent solutions for the unrelated machines scheduling problem. The selected solution representations were tested for optimising four scheduling criteria, while additionally measuring the execution time of the genetic algorithm when using each of the encodings. The obtained results demonstrate that the encoding which is based on the permutation of jobs obtains the best results, making it the superior encoding scheme for this type of scheduling problem.},
  archive      = {J_COR},
  author       = {Ivan Vlašić and Marko Đurasević and Domagoj Jakobović},
  doi          = {10.1016/j.cor.2020.105005},
  journal      = {Computers &amp; Operations Research},
  pages        = {105005},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comparative study of solution representations for the unrelated machines environment},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimization for drone and drone-truck combined operations:
A review of the state of the art and future directions. <em>COR</em>,
<em>123</em>, 105004. (<a
href="https://doi.org/10.1016/j.cor.2020.105004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper surveys the state-of-the-art optimization approaches in the civil application of drone operations (DO) and drone-truck combined operations (DTCO) including construction/infrastructure, agriculture, transportation/logistics, security/disaster management, entertainment/media, etc. In particular, this paper reviews ongoing research on various optimization issues related to DO and DTCO including mathematical models , solution methods, synchronization between a drone and a truck, and barriers in implementing DO and DTCO. First, the paper introduces DO and DTCO and their applications, and explores some previous works including survey papers. In addition, this paper surveys the state of the art of DO and DTCO studies and discusses the research gaps in the literature. Furthermore, the detailed review of DTCO models and solution methods are reviewed. Finally, future research directions are discussed.},
  archive      = {J_COR},
  author       = {Sung Hoon Chung and Bhawesh Sah and Jinkun Lee},
  doi          = {10.1016/j.cor.2020.105004},
  journal      = {Computers &amp; Operations Research},
  pages        = {105004},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimization for drone and drone-truck combined operations: A review of the state of the art and future directions},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A matheuristic for the air transportation freight forwarder
service problem. <em>COR</em>, <em>123</em>, 105002. (<a
href="https://doi.org/10.1016/j.cor.2020.105002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freight forwarding companies provide transportation services to shipping companies by organizing shipment of freights from origins to destinations. They typically handle long-haul intermodal transportation requiring synchronization among different transportation legs and modes as well as complex bureaucratic and administrative operations, like customs clearance for international transportation. Because of the complexity of these operations, shipper companies prefer to focus on their core business activities and are more and more relying on third parties to organize shipments. In this paper we focus on the freight forwarding activity where the main transportation mode is air transportation. The problem has been recently introduced in the literature and finds interesting practical applications related to the recent raise in air freight transportation due to fast delivery times requested by e-commerce customers. In this paper, we propose a matheuristic algorithm based on the construction of feasible routes from origins to destinations and on the solution of a set-partitioning formulation. Computational tests are made on instances proposed in the literature which are based on real data. The results show that the matheuristic is capable of offering good solutions for large size instances within reasonable computing times.},
  archive      = {J_COR},
  author       = {Enrico Angelelli and Claudia Archetti and Lorenzo Peirano},
  doi          = {10.1016/j.cor.2020.105002},
  journal      = {Computers &amp; Operations Research},
  pages        = {105002},
  shortjournal = {Comput. Oper. Res.},
  title        = {A matheuristic for the air transportation freight forwarder service problem},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Risk-sensitive control of markov decision processes: A
moment-based approach with target distributions. <em>COR</em>,
<em>123</em>, 104997. (<a
href="https://doi.org/10.1016/j.cor.2020.104997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many revenue management applications risk-averse decision-making is crucial. In dynamic settings, however, it is challenging to find the right balance between maximizing expected rewards and minimizing various kinds of risk. In existing approaches utility functions, chance constraints, or (conditional) value at risk considerations are used to influence the distribution of rewards in a preferred way. Nevertheless, common techniques are not flexible enough and typically numerically complex. In our model, we exploit the fact that a distribution is characterized by its mean and higher moments. We present a multi-valued dynamic programming heuristic to compute risk-sensitive feedback policies that are able to directly control the moments of future rewards. Our approach is based on recursive formulations of higher moments and does not require an extension of the state space. Finally, we propose a self-tuning algorithm, which allows to identify feedback policies that approximate predetermined (risk-sensitive) target distributions. We illustrate the effectiveness and the flexibility of our approach for different dynamic pricing scenarios.},
  archive      = {J_COR},
  author       = {Rainer Schlosser},
  doi          = {10.1016/j.cor.2020.104997},
  journal      = {Computers &amp; Operations Research},
  pages        = {104997},
  shortjournal = {Comput. Oper. Res.},
  title        = {Risk-sensitive control of markov decision processes: A moment-based approach with target distributions},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A trilevel r-interdiction selective multi-depot vehicle
routing problem with depot protection. <em>COR</em>, <em>123</em>,
104996. (<a href="https://doi.org/10.1016/j.cor.2020.104996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The determination of critical facilities in supply chain networks has been attracting the interest of the Operations Research community. Critical facilities refer to structures including bridges, railways, train/metro stations, medical facilities, roads, warehouses, and power stations among others, which are vital to the functioning of the network. In this study we address a trilevel optimization problem for the protection of depots of utmost importance in a routing network against an intelligent adversary. We formulate the problem as a defender-attacker-defender game and refer to it as the trilevel r -interdiction selective multi-depot vehicle routing problem (3LRI-SMDVRP). The defender is the decision maker in the upper level problem (ULP) who picks u depots to protect among m existing ones. In the middle level problem (MLP), the attacker destroys r depots among the ( m–u ) unprotected ones to bring about the biggest disruption. Finally, in the lower level problem (LLP), the decision maker is again the defender who optimizes the vehicle routes and thereby selects which customers to visit and serve in the wake of the attack. All three levels have an identical objective function which is comprised of three components. (i) Operating or acquisition cost of the vehicles. (ii) Traveling cost incurred by the vehicles. (iii) Outsourcing cost due to unvisited customers. The defender aspires to minimize this objective function while the attacker tries to maximize it. As a solution approach to this trilevel discrete optimization problem, we resort to a smart exhaustive enumeration in the ULP and MLP. For the LLP we design a metaheuristic algorithm that hybridizes Variable Neighborhood Descent and Tabu Search techniques adapted to the Selective MDVRP (SMDVRP). The performance of this algorithm is demonstrated on 33 MDVRP benchmark instances existing in the literature and 41 SMDVRP instances generated from them. Numerical experiments on a large number of 3LRI-SMDVRP instances attest that our comprehensive method is effective in dealing with the defender-attacker-defender game on multi-depot routing networks.},
  archive      = {J_COR},
  author       = {Mir Ehsan Hesam Sadati and Deniz Aksen and Necati Aras},
  doi          = {10.1016/j.cor.2020.104996},
  journal      = {Computers &amp; Operations Research},
  pages        = {104996},
  shortjournal = {Comput. Oper. Res.},
  title        = {A trilevel r-interdiction selective multi-depot vehicle routing problem with depot protection},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-cut-and-price algorithm for the traveling
salesperson problem with hotel selection. <em>COR</em>, <em>123</em>,
104986. (<a href="https://doi.org/10.1016/j.cor.2020.104986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesperson Problem with Hotel Selection (TSPHS) is a realistic extension of the classic Traveling Salesperson Problem recently introduced to the literature. In the TSPHS, there is a time limit that restricts the visits that can be performed in a single day. Therefore, several days may be necessary to visit all clients. The salesperson has to spend the night in one of the available hotels. Previous works focus mainly on metaheuristics and on MIP formulations. This work presents a sophisticated exact algorithm for the TSPHS, a Branch-Cut-and-Price (BCP) algorithm that includes and adapts several features found in state-of-the-art algorithms for vehicle routing. In that algorithm, columns correspond to possible salesperson day trips; subtour elimination cuts, 2-path cuts, and limited-memory subset row cuts are separated. Computational results show that many medium-sized instances, having up to 75 clients and 20 hotels, can be solved to optimality, as well as some larger instances from the literature, with up to 225 clients.},
  archive      = {J_COR},
  author       = {Luiz Henrique Barbosa and Eduardo Uchoa},
  doi          = {10.1016/j.cor.2020.104986},
  journal      = {Computers &amp; Operations Research},
  pages        = {104986},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-cut-and-price algorithm for the traveling salesperson problem with hotel selection},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-period stochastic programming models for two-tiered
emergency medical service system. <em>COR</em>, <em>123</em>, 104974.
(<a href="https://doi.org/10.1016/j.cor.2020.104974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the multi-period ambulance redeployment planning problem in a two-tiered Emergency Medical System (EMS) where two types of ambulances are used to respond to two categories of emergency calls. In order to account for the uncertainty inherent to both categories of demand, we propose a two-stage stochastic programming model that aims at finding a cost-effective ambulance redeployment. The model tries to minimize the total cost, which encompasses ambulance relocation cost, the dispatching cost, and the penalty cost incurred by the unsatisfied demand , over a multi-period planning horizon. In order to overcome the computational complexity of the proposed model, two heuristics are proposed: a Temporal Decomposition Heuristic (HDT), and a Lagrangian Relaxation based Heuristic (SBG). A simulation model is then proposed to evaluate the service level of the EMS system and ambulance utilization while accounting for more realistic features of the problem. The computational experiments are carried out using real-world data provided by the EMS system of the northern region of Tunisia. The results show the excellent performance of HDT as it provides a near-optimal solution within a reasonable computational time. The simulation also demonstrates that the service level of the EMS system is higher if HDT is used.},
  archive      = {J_COR},
  author       = {Rania Boujemaa and Aida Jebali and Sondes Hammami and Angel Ruiz},
  doi          = {10.1016/j.cor.2020.104974},
  journal      = {Computers &amp; Operations Research},
  pages        = {104974},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-period stochastic programming models for two-tiered emergency medical service system},
  volume       = {123},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generating decision rules for flexible capacity expansion
problem through gene expression programming. <em>COR</em>, <em>122</em>,
105003. (<a href="https://doi.org/10.1016/j.cor.2020.105003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel approach for generating decision rules to exercise flexibility in capacity expansion. The proposed approach differs from other decision rule generation methods by integrating gene expression programming. This approach allows parameters to be automatically selected from a database and optimally combined to form decision rules, allowing both the structure and parameters of the decision rules to evolve. The generated decision rules support capacity expansion activities by clearly providing guidance to adjust the expansion level and timing according to the changing environment. The proposed approach was applied to a waste-to-energy system, to flexibly expand capacity under uncertainty. The empirical results demonstrate that the decision rules generated by our proposed approach improved system performance in terms of expected net present value, relative to decision rules generated by a method based on differential evolution algorithm . A sensitivity analysis was also conducted to investigate the effectiveness of the proposed approach under changes to the major assumptions, and results indicated that the generated decision rule can guide capacity expansion under different situations.},
  archive      = {J_COR},
  author       = {Junfei Hu and Peng Guo and Kim-Leng Poh},
  doi          = {10.1016/j.cor.2020.105003},
  journal      = {Computers &amp; Operations Research},
  pages        = {105003},
  shortjournal = {Comput. Oper. Res.},
  title        = {Generating decision rules for flexible capacity expansion problem through gene expression programming},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal insertion of customers with waiting time targets.
<em>COR</em>, <em>122</em>, 105001. (<a
href="https://doi.org/10.1016/j.cor.2020.105001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The insertion of randomly-arriving high-priority customers (HCs) into existing queues leads to longer waiting time of regular or scheduled customers. However, given their different levels of priority, not all HCs need to be served immediately. To reduce the waiting time for regular customers without affecting the service quality for HCs, this paper addresses the optimal insertion problem of HCs by considering their waiting time targets assigned based on their levels of priority. A finite-horizon Markov decision process model is proposed to minimize the total waiting cost incurred by both regular customers and HCs. The marginal waiting penalty is constant for regular customers and non-decreasing for HCs. Several properties are observed: the optimal control policy is proved to be a state-dependent threshold policy; the marginal effect of each state variable on the optimal action is bounded by 1; and, in some meaningful cases, the threshold proves to be state-independent. Based on these properties, several heuristic policies are proposed to solve large-size problems. Numerical experiments are performed to validate the structure of the optimal control policies and compare the performances of the heuristic policies. These results imply that the optimal control policy significantly outperforms the traditional HC-first policy. The best heuristic policy, characterized by a threshold policy derived through policy iteration, performs within 0.44\% of an optimal policy for most cases, which offers insights into the near-optimal control for large-size problems.},
  archive      = {J_COR},
  author       = {Jing Wen and Na Geng and Xiaolan Xie},
  doi          = {10.1016/j.cor.2020.105001},
  journal      = {Computers &amp; Operations Research},
  pages        = {105001},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal insertion of customers with waiting time targets},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Particle swarm metaheuristics for robust optimisation with
implementation uncertainty. <em>COR</em>, <em>122</em>, 104998. (<a
href="https://doi.org/10.1016/j.cor.2020.104998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider global non-convex optimisation problems under uncertainty. In this setting, it is not possible to implement a desired solution exactly. Instead, any other solution within some distance to the intended solution may be implemented. The aim is to find a robust solution, i.e., one where the worst possible solution nearby still performs as well as possible. Problems of this type exhibit another maximisation layer to find the worst case solution within the minimisation level of finding a robust solution, which makes them harder to solve than classic global optimisation problems. So far, only few methods have been provided that can be applied to black-box problems with implementation uncertainty. We improve upon existing techniques by introducing a novel particle swarm based framework which adapts elements of previous methods, combining them with new features in order to generate a more effective approach. In computational experiments, we find that our new method outperforms state of the art comparator heuristics in almost 80\% of cases.},
  archive      = {J_COR},
  author       = {Martin Hughes and Marc Goerigk and Trivikram Dokka},
  doi          = {10.1016/j.cor.2020.104998},
  journal      = {Computers &amp; Operations Research},
  pages        = {104998},
  shortjournal = {Comput. Oper. Res.},
  title        = {Particle swarm metaheuristics for robust optimisation with implementation uncertainty},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). MineReduce: An approach based on data mining for problem
size reduction. <em>COR</em>, <em>122</em>, 104995. (<a
href="https://doi.org/10.1016/j.cor.2020.104995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid variations of metaheuristics that include data mining strategies have been utilized to solve a variety of combinatorial optimization problems , with superior and encouraging results. Previous hybrid strategies applied mined patterns to guide the construction of initial solutions, leading to more effective exploration of the solution space. Solving a combinatorial optimization problem is usually a hard task because its solution space grows exponentially with its size. Therefore, problem size reduction is also a useful strategy in this context, especially in the case of large-scale problems. In this paper, we build upon these ideas by presenting an approach named MineReduce, which uses mined patterns to perform problem size reduction. We present an application of MineReduce to improve a heuristic for the heterogeneous fleet vehicle routing problem . The results obtained in computational experiments show that this proposed heuristic demonstrates superior performance compared to the original heuristic and other state-of-the-art heuristics, achieving better solution costs with shorter run times.},
  archive      = {J_COR},
  author       = {Marcelo Rodrigues de Holanda Maia and Alexandre Plastino and Puca Huachi Vaz Penna},
  doi          = {10.1016/j.cor.2020.104995},
  journal      = {Computers &amp; Operations Research},
  pages        = {104995},
  shortjournal = {Comput. Oper. Res.},
  title        = {MineReduce: An approach based on data mining for problem size reduction},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The commodity-split multi-compartment capacitated arc
routing problem. <em>COR</em>, <em>122</em>, 104994. (<a
href="https://doi.org/10.1016/j.cor.2020.104994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to develop a data-driven matheuristic for the Commodity-Split Multi-Compartment Capacitated Arc Routing Problem (CSMC-CARP). This problem arises in curbside waste collection, where there are different recyclable waste types called fractions. The CSMC-CARP is defined on an undirected graph with a limited heterogeneous fleet of multi-compartment vehicle types based at a depot, where each compartment’s capacity can vary depending on the waste fraction assigned to it and on the compression factor of that fraction in that vehicle type. The aim is to determine a set of least-cost routes starting and ending at the depot, such that the demand of each edge for each waste fraction is collected exactly once by one vehicle, without violating the capacity of any compartment. The CSMC-CARP consists of three decision levels: selecting the number of vehicles of each type, assigning waste fractions to the compartments of each selected vehicle, and routing the vehicles. Our three-phase algorithm decomposes the problem into incomplete solution representations and heuristically solves one or more decision levels at a time. The first phase selects a subset of attractive compartment assignments from all assignments of all vehicle types. The second phase solves the CSMC-CARP with an unlimited fleet of the selected assignments. This is done by our C-split tour splitting algorithm, which can simultaneously split a giant tour of required edges into feasible routes while making decisions on the fractions that are collected by each route. The third phase selects the set of best routes servicing all fractions of all required edges without exceeding the number of vehicles available of each type. The algorithm is applied to real-life instances arising from recyclable waste collection operations in Denmark, with graph sizes up to 6,149 nodes and 3,797 required edges, the waste sorted in three to six fractions, and four to six vehicle types with one to four compartments. Computational results show that the generated solutions favor combining different fractions together in vehicles with higher numbers of compartments, and that the algorithm adapts well to the characteristics of the data, in terms of the graph, vehicle types, degree of sorting, and to skewness in demand among waste fractions.},
  archive      = {J_COR},
  author       = {Hani Zbib and Gilbert Laporte},
  doi          = {10.1016/j.cor.2020.104994},
  journal      = {Computers &amp; Operations Research},
  pages        = {104994},
  shortjournal = {Comput. Oper. Res.},
  title        = {The commodity-split multi-compartment capacitated arc routing problem},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A review of vehicle routing with simultaneous pickup and
delivery. <em>COR</em>, <em>122</em>, 104987. (<a
href="https://doi.org/10.1016/j.cor.2020.104987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the vehicle routing problem with simultaneous pickup and delivery (VRPSPD), goods have to be transported from different origins to different destinations, and each customer has both a delivery and a pickup demand to be satisfied simultaneously. The VRPSPD has been around for about 30 years, and significant progress has since been made on this problem and its variants. This paper aims to comprehensively review the existing work on the VRPSPD. It surveys mathematical formulations, algorithms, variants, case studies, and industrial applications. It also provides an overview of trends in the literature and identifies several interesting promising future research perspectives.},
  archive      = {J_COR},
  author       = {Çağrı Koç and Gilbert Laporte and İlknur Tükenmez},
  doi          = {10.1016/j.cor.2020.104987},
  journal      = {Computers &amp; Operations Research},
  pages        = {104987},
  shortjournal = {Comput. Oper. Res.},
  title        = {A review of vehicle routing with simultaneous pickup and delivery},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic lot-sizing model under perishability, substitution,
and limited storage capacity. <em>COR</em>, <em>122</em>, 104978. (<a
href="https://doi.org/10.1016/j.cor.2020.104978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various commodities including blood, pharmaceutical, and agricultural products are perishable in nature and require special storage conditions, such as controlled temperature. However, expanding the space of cold storage is expensive. Therefore, storage capacity frequently restricts the operational efficiency of enterprises in the perishable product industry. Numerous enterprises have adopted the policies of product substitution and multiple item joint procurement to achieve an efficient inventory management and reduce their operation costs. This paper considers a two-product dynamic lot-sizing problem for perishable inventory under product substitution and limited storage capacity. This study aims to identify the ordering, inventory, and substitution decisions over a planning horizon under the criteria that (i) the inventory holding costs and deterioration rates are age dependent, (ii) a one-direction product substitution and joint ordering of two products are possible, and (iii) the storage capacity has an upper bound that limits the inventory quantities. The contributions of this study are summarized in three points. First, we develop a dynamic programming algorithm by using two structural properties to solve the dynamic lot-sizing problem with perishable inventory and demand substitution under storage capacity constraints. Second, we obtain the forecast horizons for the general problem by using the marginal analysis method and for the case with constant unit ordering costs through establishing the monotonicity of the regeneration points of two products. Third, we determine the effects of storage capacity, product lifetime, joint setup, and inventory costs on the length of the forecast horizon and the total costs by using a detailed test bed of instances. The major findings are also discussed in three aspects. First, the single-period satisfaction property fails to hold under limited storage capacity and time-varying unit ordering costs. Second, the forecast horizon inconsistently increases with joint setup costs or storage capacity. Third, the total costs fail to decrease with increasing storage capacity or product lifetime.},
  archive      = {J_COR},
  author       = {Fuying Jing and Yinping Mu},
  doi          = {10.1016/j.cor.2020.104978},
  journal      = {Computers &amp; Operations Research},
  pages        = {104978},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic lot-sizing model under perishability, substitution, and limited storage capacity},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dominance conditions determination based on machine idle
times for the permutation flowshop scheduling problem. <em>COR</em>,
<em>122</em>, 104964. (<a
href="https://doi.org/10.1016/j.cor.2020.104964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the lower bound and dominance conditions of the N -job and M -machine permutation flowshop scheduling problem to minimize the makespan based on machine idle times. We have developed and validated three dominance conditions and a lower bound based on a new approach that minimizes the machine idle times in a flowshop to facilitate the efficiency of the branch and bound approach. Most importantly, we have developed a dominance condition that is independent of the preceding and subsequent partial schedules, which has been considered critical but has not previously been developed in flowshop scheduling research. Finally, the efficiency of our developed branch and bound approach based on machine idle times is compared with the efficiencies of some previous branch and bound algorithms from the literature. We show that the dominance conditions that we developed can significantly improve the efficiency of the branch and bound approach.},
  archive      = {J_COR},
  author       = {Jin-Pin Liou},
  doi          = {10.1016/j.cor.2020.104964},
  journal      = {Computers &amp; Operations Research},
  pages        = {104964},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dominance conditions determination based on machine idle times for the permutation flowshop scheduling problem},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing makespan and stability risks in job shop
scheduling. <em>COR</em>, <em>122</em>, 104963. (<a
href="https://doi.org/10.1016/j.cor.2020.104963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world manufacturing environments, the execution of a schedule often encounters uncertain events, which will bring the risks of performance deterioration and production system instability. This study addresses the optimization of risks both in performance and stability for the job shop scheduling under random machine breakdowns, in which three objectives: makespan, makespan risk and stability risk are considered at the same time. The buffering approach under the limited predictive makespan will be proposed and used to generate predictive schedules, which allows inserting additional idle time to control the risks. By utilizing the available information about the relationship between the risks and the random machine breakdowns, we have developed two kinds of operation-block based buffering strategies. In order to meet the decision makers with different risk preferences, a multi-objective predictive scheduling algorithm with the proposed buffering strategies is developed to generate a Pareto solution set. Extensive experimental results indicate that, compared with the existing methods, the proposed method can provide a better Pareto solution set in terms of both the diversity and the convergence.},
  archive      = {J_COR},
  author       = {Zigao Wu and Shudong Sun and Shaohua Yu},
  doi          = {10.1016/j.cor.2020.104963},
  journal      = {Computers &amp; Operations Research},
  pages        = {104963},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing makespan and stability risks in job shop scheduling},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Bi-objective optimization algorithms for joint production
and maintenance scheduling under a global resource constraint:
Application to the permutation flow shop problem. <em>COR</em>,
<em>122</em>, 104943. (<a
href="https://doi.org/10.1016/j.cor.2020.104943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production scheduling and maintenance planning are two of the most important tasks that managers face before implementing their decisions on the shop floor. Another issue managers have to keep in mind is the proper allocation of various resources for production. These issues create difficulties in the planning process. In this paper, we propose a bi-objective model that integrates the three aforementioned issues and determines production scheduling, maintenance planning and resource supply rate decisions in order to minimize the make span and total production costs, which include total maintenance, resource consumption and resource inventory costs. Two meta heuristic methods were employed to find approximations of the Pareto optimal front in a permutation flow shop environment: The well-known non-dominated sorting genetic algorithm (NSGA-II) and a bi-objective adaptation of the particle swarm optimization (BOPSO). Additionally, a bi-objective randomized local search (BORLS) heuristic was developed in order to generate multiple non-dominated solutions along its search path. Two sets of computational experiments were conducted. In the first set, the performances of the two meta heuristics with purely random initial populations were compared, with results showing the superiority of BOPSO over NSGA-II. In the second set, the initial populations were enhanced with heuristically generated solutions from BORLS and the performances of BOPSO, NSGA-II and BORLS used as an independent search algorithm, were compared. In this instance, the algorithms performed evenly for large problems, with the BORLS method generating better solutions when total production cost is emphasized.},
  archive      = {J_COR},
  author       = {Radhwane BOUFELLOUH and Fayçal BELKAID},
  doi          = {10.1016/j.cor.2020.104943},
  journal      = {Computers &amp; Operations Research},
  pages        = {104943},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bi-objective optimization algorithms for joint production and maintenance scheduling under a global resource constraint: Application to the permutation flow shop problem},
  volume       = {122},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Query batching optimization in database systems.
<em>COR</em>, <em>121</em>, 104983. (<a
href="https://doi.org/10.1016/j.cor.2020.104983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Techniques based on sharing data and computation among queries have been an active research topic in database systems . While work in this area developed algorithms and systems that are shown to be effective, there is a lack of rigorous modeling and theoretical study for query processing and optimization. Query batching in database systems has strong resemblance to order batching in the warehousing context. While the latter is a well-studied problem, the literature on optimization techniques for query batching problem is quite scarce/nonexistent. In this study, we develop a Mixed Binary Quadratic Program (MBQP) to optimize query-batching in a database system. This model uses the coefficients of a linear regression on the query retrieval time, trained by a large set of randomly generated query sets. We also propose two heuristics, the so-called restricted-cardinality search methods I and II, for solving the proposed MBQP. To demonstrate the effectiveness of our proposed techniques, we conduct a comprehensive computational study over randomly generated instances of three well-known database benchmarks. The computational results show that when the proposed MBQP is solved using the designed heuristics, an improvement of up to 61.8\% in retrieving time is achieved.},
  archive      = {J_COR},
  author       = {Mehrad Eslami and Vahid Mahmoodian and Iman Dayarian and Hadi Charkhgard and Yicheng Tu},
  doi          = {10.1016/j.cor.2020.104983},
  journal      = {Computers &amp; Operations Research},
  pages        = {104983},
  shortjournal = {Comput. Oper. Res.},
  title        = {Query batching optimization in database systems},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). DILS: Constrained clustering through dual iterative local
search. <em>COR</em>, <em>121</em>, 104979. (<a
href="https://doi.org/10.1016/j.cor.2020.104979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering has always been a powerful tool in knowledge discovery. Traditionally unsupervised, it has received renewed attention recently as it has shown to produce better results when provided with new types of information, thus leading to a new kind of semi-supervised learning: constrained clustering. This technique is a generalization of traditional clustering that considers additional information encoded by constraints. Constraints can be given in the form of instance-level must-link and cannot-link constraints, which is the focus of this paper. We propose a new metaheuristic algorithm , the Dual Iterative Local Search, and prove its ability to produce quality results for the constrained clustering problem. We compare the results obtained by this proposal to those obtained by the state-of-the-art algorithms on 25 datasets with incremental levels of constraint-based information, supporting our conclusions with the aid of Bayesian statistical tests.},
  archive      = {J_COR},
  author       = {Germán González-Almagro and Julián Luengo and José-Ramón Cano and Salvador García},
  doi          = {10.1016/j.cor.2020.104979},
  journal      = {Computers &amp; Operations Research},
  pages        = {104979},
  shortjournal = {Comput. Oper. Res.},
  title        = {DILS: Constrained clustering through dual iterative local search},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Two-phase algorithm for solving the preference-based
multicriteria optimal path problem with reference points. <em>COR</em>,
<em>121</em>, 104977. (<a
href="https://doi.org/10.1016/j.cor.2020.104977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shortest path problem arises in several contexts like transportation, telecommunication or data analysis. New requirements in solving practical problems (e.g., efficient content delivery for information-centric networks, urban passenger transport system or social network) impose that more than one criterion should be considered. Since the objectives are in conflict, the solution is not unique, rather a set of (efficient) paths is defined as optimal. The most satisfactory path should be selected considering additional preference information. Generally, computing the entire set of efficient solutions is time consuming. In this paper, we apply the reference point method for finding the best path. In a reference point-based approach, non-additive scalarizing function is applied. In this case, the classical optimality principle for the shortest path problem is not valid. To overcome this issue, we propose an equivalent formulation dealing with the constrained shortest path ( CSP ) problem. The idea is to define a set of constraints guaranteeing that an optimal solution to the problem at hand lies in the feasible region of the defined CSP problem. We propose a two-phase method where, in the first phase, a bound on the optimal solution is computed and used to define the constraints, whereas, in the second phase a labelling algorithm is applied to search for an optimal solution to the defined CSP problem. The method is tested on instances generated from random and grid networks, considering several scenarios. The computational results show that, on average, the proposed solution strategy is competitive with the state-of-the-art approaches and behaves the best on grid networks.},
  archive      = {J_COR},
  author       = {Luigi Di Puglia Pugliese and Janusz Granat and Francesca Guerriero},
  doi          = {10.1016/j.cor.2020.104977},
  journal      = {Computers &amp; Operations Research},
  pages        = {104977},
  shortjournal = {Comput. Oper. Res.},
  title        = {Two-phase algorithm for solving the preference-based multicriteria optimal path problem with reference points},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Going to the core of hard resource-constrained project
scheduling instances. <em>COR</em>, <em>121</em>, 104976. (<a
href="https://doi.org/10.1016/j.cor.2020.104976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The resource-constrained project scheduling problem (RCPSP) is one of the most studied problems in the project scheduling literature, and aims at constructing a project schedule with a minimum makespan that satisfies both the precedence relations of the network and the limited availability of the renewable resources. The problem has attracted attention due to its NP hardness status, and different algorithms have been proposed that solve a wide variety of RCPSP instances to optimality or near-optimality. In this paper, we analyse the hardness of this problem from an experimental point-of-view by testing different algorithms on a huge set of existing instances and detect which ones are difficult to solve. To that purpose, we propose a three-phased approach that makes use of five elementary blocks, well-performing algorithms and a huge amount of computational power to transform easy RCPSP instances into very hard ones. The purpose of this study is to create insight and understanding into what makes an RCPSP instance hard, and propose a new dataset that consists of a small set of instances that are impossible to solve with the algorithms currently existing in the literature. These instances should be as small as possible in terms of number of activities and resources, and should be as diverse as possible in terms of network structure and resource strictness. Such a dataset should enable researchers to focus their attention on the development of radically new algorithms to solve the RCPSP rather than gradually improving current algorithms that can solve the existing RCPSP instances only slightly better.},
  archive      = {J_COR},
  author       = {José Coelho and Mario Vanhoucke},
  doi          = {10.1016/j.cor.2020.104976},
  journal      = {Computers &amp; Operations Research},
  pages        = {104976},
  shortjournal = {Comput. Oper. Res.},
  title        = {Going to the core of hard resource-constrained project scheduling instances},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Relationship between common objective functions, idle time
and waiting time in permutation flow shop scheduling. <em>COR</em>,
<em>121</em>, 104965. (<a
href="https://doi.org/10.1016/j.cor.2020.104965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on two components of idle time and waiting time, namely core idle time, ∑ CIT i , and core waiting time, ∑ CWT j . Both measures are relevant indicators of the efficiency of production systems, since they are directly related to machine utilization and to the flow of jobs, and they can be used as scheduling criteria if no-idle and no-wait constraints do not have to be strictly enforced. However, they have been scarcely considered in the literature, and their relationship with other objectives in the permutation flowshop literature (makespan or C max and total completion time or ∑ C j ), has not been studied. To bridge this gap, the alignment between ∑ CIT i and ∑ CWT j , and the classical scheduling criteria is studied. First, it is shown that ∑ CWT j (∑ CIT i ) is tantamount to ∑ C j ( C max ) for some special cases. Secondly, the general case with randomly generated processing times is computationally analysed using exact methods. Results show alignment between ∑ CWT j and ∑ C j and between ∑ CIT i and C max , being the alignment stronger for the first pair of objectives. Based on the analysis, conclusions about the possibilities for the permutation flowshop problem with these new objectives are established.},
  archive      = {J_COR},
  author       = {Kathrin Maassen and Paz Perez-Gonzalez and Lisa C. Günther},
  doi          = {10.1016/j.cor.2020.104965},
  journal      = {Computers &amp; Operations Research},
  pages        = {104965},
  shortjournal = {Comput. Oper. Res.},
  title        = {Relationship between common objective functions, idle time and waiting time in permutation flow shop scheduling},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-objective temporal bin packing problem: An application
in cloud computing. <em>COR</em>, <em>121</em>, 104959. (<a
href="https://doi.org/10.1016/j.cor.2020.104959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving energy efficiency and lowering operational costs are the main challenges faced in systems with multiple servers. One prevalent objective in such systems is to minimize the number of servers required to process a given set of tasks under server capacity constraints. This objective leads to the well-known bin packing problem . In this study, we consider a generalization of this problem with a time dimension, where the tasks are to be performed with predefined start and end times. This new dimension brings about new performance considerations, one of which is the uninterrupted utilization of servers. This study is motivated by the problem of energy efficient assignment of virtual machines to physical servers in a cloud computing service . We address the virtual machine placement problem and present a binary integer programming model to develop different assignment policies. By analyzing the structural properties of the problem, we propose an efficient heuristic method based on solving smaller versions of the original problem iteratively. Moreover, we design a column generation algorithm that yields a lower bound on the objective value, which can be utilized to evaluate the performance of the heuristic algorithm . Our numerical study indicates that the proposed heuristic is capable of solving large-scale instances in a short time with small optimality gaps.},
  archive      = {J_COR},
  author       = {Nurşen Aydın and İbrahim Muter and Ş. İlker Birbil},
  doi          = {10.1016/j.cor.2020.104959},
  journal      = {Computers &amp; Operations Research},
  pages        = {104959},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective temporal bin packing problem: An application in cloud computing},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved particle swarm optimization algorithm based novel
encoding and decoding schemes for flexible job shop scheduling problem.
<em>COR</em>, <em>121</em>, 104951. (<a
href="https://doi.org/10.1016/j.cor.2020.104951">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible job shop scheduling problem (FJSP) is a typical scheduling problem in practical production and has been proven to be a NP-hard problem. The study of FJSP is important to remarkably direct actual manufacturing processes. The paper proposes an improved particle swarm optimization (PSO) algorithm for solving FJSP and obtains beneficial solutions by improvement on encoding/decoding scheme, communication mechanism between particles, and alternate rules of candidate machines of operations. The innovation of encoding/decoding scheme proposes a novel designed chain encoding scheme and a corresponding effective decoding scheme. The chain-based encoding scheme can reasonably convert FJSP to an appropriate operation linked list and the novel designed decoding scheme owns the capacity of further explorering the solution space. The improvement of traditional PSO focuses on the innovation of information communication between particles, besides the modification of algorithm architecture. The amelioration of rules on operated machine selection is carried out based on the critical path of operations research (OR). It promotes algorithm efficiency by only alternating the candidate machines of operations on the critical path. In addition, much parameters tuning work is involved in a series of experiments. The study proposes some tuning schemes of parameters with exact mathematical methods , and these schemes can effectively help find more appropriate parameters. The final experiment results prove that the improved PSO exhibits remarkable ability to solve FJSP.},
  archive      = {J_COR},
  author       = {Haojie Ding and Xingsheng Gu},
  doi          = {10.1016/j.cor.2020.104951},
  journal      = {Computers &amp; Operations Research},
  pages        = {104951},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved particle swarm optimization algorithm based novel encoding and decoding schemes for flexible job shop scheduling problem},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The two-echelon inventory-routing problem with fleet
management. <em>COR</em>, <em>121</em>, 104944. (<a
href="https://doi.org/10.1016/j.cor.2020.104944">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Two-Echelon Inventory-Routing Problem with Fleet Management. This problem arises under a two-echelon vendor-managed inventory system when a company must make vehicle routing and inventory management decisions, while renting a fleet subject to short- and mid-term agreements. Different chemical products are transported contaminating the vehicles that may require cleaning activities. Pickups of input take place in the first echelon, and the final product deliveries are performed in the second echelon. Based on a real-life case in the petrochemical industry , we introduce a formulation that takes into account vehicle rentals, cleanings, transportation, inventory management, and vehicle returns decisions. We design a branch-and-cut algorithm to solve it and also propose a matheuristic , in which vehicle routes are handled by an adaptive large neighborhood mechanism, while input pickups, product deliveries, and fleet planning are performed by solving several subproblems to optimality . Moreover, we introduce a hybrid parallel framework, combining our matheuristic and the branch-and-cut algorithm in order to solve very large instances exactly. We validate our methods by solving a set of instances of the two-echelon multi-depot inventory-routing problem from the literature, obtaining new best solutions for all instances. We have introduced a set of instances for this rich and new problem, and performed an extensive assessment of our methods. The results provide interesting data about the supply chain structure.},
  archive      = {J_COR},
  author       = {Cleder M. Schenekemberg and Cassius T. Scarpin and José E. Pécora Jr. and Thiago A. Guimarães and Leandro C. Coelho},
  doi          = {10.1016/j.cor.2020.104944},
  journal      = {Computers &amp; Operations Research},
  pages        = {104944},
  shortjournal = {Comput. Oper. Res.},
  title        = {The two-echelon inventory-routing problem with fleet management},
  volume       = {121},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Using ℓp-norms for fairness in combinatorial optimisation.
<em>COR</em>, <em>120</em>, 104975. (<a
href="https://doi.org/10.1016/j.cor.2020.104975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of fairness has received attention from researchers in many fields, including combinatorial optimisation . One way to drive the solution toward fairness is to use a modified objective function that involves so-called ℓ p -norms . If done in a naive way, this approach leads to large and symmetric mixed-integer nonlinear programs (MINLPs), that may be difficult to solve. We show that, for some problems, one can obtain alternative MINLP formulations that are much smaller, do not suffer from symmetry, and have a reasonably tight continuous relaxation. We give encouraging computational results for certain vehicle routing, facility location and network design problems .},
  archive      = {J_COR},
  author       = {Tolga Bektaş and Adam N. Letchford},
  doi          = {10.1016/j.cor.2020.104975},
  journal      = {Computers &amp; Operations Research},
  pages        = {104975},
  shortjournal = {Comput. Oper. Res.},
  title        = {Using ℓp-norms for fairness in combinatorial optimisation},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Medical waste collection considering transportation and
storage risk. <em>COR</em>, <em>120</em>, 104966. (<a
href="https://doi.org/10.1016/j.cor.2020.104966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Periodic Load-dependent Capacitated Vehicle Routing Problem (PLCVRP) encountered by healthcare centers and medical waste collection companies for the design of a weekly inventory routing schedule to transport medical wastes to treatment sites. In addition to minimization of transportation risk, occupational risk related to temporary storage of hazardous wastes at the healthcare centers is considered. The transport risk on each arc is dependent on the weight of hazardous medical waste on the vehicle when it traverses that arc. We devise a decomposition based heuristic algorithm to solve this problem. We analyze the characteristics of the PLCVRP’s solutions with respect to four different criteria: (i) transport and occupational risk, (ii) transport risk, (iii) occupational risk, and (iv) transportation cost. Solving different versions of PLCVRP reveals that minimizing both transport and occupational risk on the network can aid decision makers to develop a better routing schedule in terms of the imposed risk of hazardous medical waste. Experimental results confirm the efficiency of our heuristic. We present a case study to illustrate solution attributes obtained by our solution methodology. The case study is based on medical waste management in Dolj, Romania.},
  archive      = {J_COR},
  author       = {Masoumeh Taslimi and Rajan Batta and Changhyun Kwon},
  doi          = {10.1016/j.cor.2020.104966},
  journal      = {Computers &amp; Operations Research},
  pages        = {104966},
  shortjournal = {Comput. Oper. Res.},
  title        = {Medical waste collection considering transportation and storage risk},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Human solution strategies for the vehicle routing problem:
Experimental findings and a choice-based theory. <em>COR</em>,
<em>120</em>, 104962. (<a
href="https://doi.org/10.1016/j.cor.2020.104962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vehicle routing problem is one of the classical problems in transportation science. Many algorithms have been proposed over the last decades, but the problem is still hard to solve, even for computers. We conduct a laboratory experiment to identify human solution strategies for the vehicle routing problem . Using a newly introduced discrete choice model , we show that humans tend to follow local-to-global problem-solving strategies, which involves a distinction between a first construction and a second improvement phase. When comparing the human performance with the optimal solution and classical heuristics (nearest neighbor, savings, and sweep), we see that participants typically perform better than the worst heuristic and worse than the best heuristic. Also, the combination of clustering and routing in the vehicle routing problem complicates finding good solutions compared to the traveling salesman problem , where particularly poor clustering leads to poor solutions. Especially participants with lower cognitive reflection test scores fail to identify good clusters and tend to use clusters that make the routing problem of a cluster easier. Moreover, only participants with a high cognitive reflection test score were able to improve solutions by using feedback on the current tour length. The other group even disimproved. Lastly, using the feedback option too often leads to a decline in performance which implies an overreaction of corrections made to an existing solution.},
  archive      = {J_COR},
  author       = {Pirmin Fontaine and Florian Taube and Stefan Minner},
  doi          = {10.1016/j.cor.2020.104962},
  journal      = {Computers &amp; Operations Research},
  pages        = {104962},
  shortjournal = {Comput. Oper. Res.},
  title        = {Human solution strategies for the vehicle routing problem: Experimental findings and a choice-based theory},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Real-time personnel re-scheduling after a minor disruption
in the retail industry. <em>COR</em>, <em>120</em>, 104952. (<a
href="https://doi.org/10.1016/j.cor.2020.104952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personnel scheduling consists of determining least-cost employee work schedules to cover the demand of one or several jobs in each period of a time horizon. During the operations, several minor disruptions caused, for example, by a late employee may occur and must be addressed in real time by re-scheduling certain employees. In this paper, we develop a fast re-scheduling heuristic that can be used to solve the personnel re-scheduling problem in a context where the employees can be assigned to a wide variety of shifts such as in the retail industry . This heuristic considers five types of decision and is based on the dual values of the linear relaxation of the personnel scheduling problem. We also propose a procedure exploiting a multivariate adaptive regression splines method for updating the dual values after each disruption when several ones occur in the same week. Computational experiments conducted on a set of 1050 instances derived from real-life datasets involving up to 191 employees show the efficiency of the proposed re-scheduling heuristic: it can compute optimal solutions for more than 95\% of these instances in less than one second on average. Furthermore, the dual value updating process allows an average reduction of 73\% of the optimality gap for each disruption.},
  archive      = {J_COR},
  author       = {Rachid Hassani and Guy Desaulniers and Issmail Elhallaoui},
  doi          = {10.1016/j.cor.2020.104952},
  journal      = {Computers &amp; Operations Research},
  pages        = {104952},
  shortjournal = {Comput. Oper. Res.},
  title        = {Real-time personnel re-scheduling after a minor disruption in the retail industry},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quota travelling salesman problem with passengers,
incomplete ride and collection time optimization by ant-based
algorithms. <em>COR</em>, <em>120</em>, 104950. (<a
href="https://doi.org/10.1016/j.cor.2020.104950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quota Travelling Salesman Problem with Passengers, Incomplete Ride, and Collection Time is a new version of the Quota Travelling Salesman Problem . In this problem, the salesman uses a flexible ridesharing system to minimize travel costs while visiting some vertices to satisfy a pre-established quota. We consider operational constraints regarding vehicle capacity, travel time, passenger limitations, and penalties for rides that do not meet passenger requirements. We present a mathematical formulation and heuristics based on Ant Colony Optimization .},
  archive      = {J_COR},
  author       = {Bruno C.H. Silva and Islame F.C. Fernandes and Marco C. Goldbarg and Elizabeth F.G. Goldbarg},
  doi          = {10.1016/j.cor.2020.104950},
  journal      = {Computers &amp; Operations Research},
  pages        = {104950},
  shortjournal = {Comput. Oper. Res.},
  title        = {Quota travelling salesman problem with passengers, incomplete ride and collection time optimization by ant-based algorithms},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The exponential multi-insertion neighborhood for the vehicle
routing problem with unit demands. <em>COR</em>, <em>120</em>, 104949.
(<a href="https://doi.org/10.1016/j.cor.2020.104949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we extend, analyze and evaluate the exponential multi-insertion neighborhood for the vehicle routing problem with unit demands, originally proposed by Angel et al. (2008). In this neighborhood, a neighbor solution is obtained by the removal of a set of mobile nodes from a solution and a subsequent best reinsertion. At first, we examine theoretical properties of the neighborhood, such as its connectivity and the question how many nodes may be chosen as mobile. Furthermore, we prove that finding a best set of mobile nodes is NP-hard. Then, we present a two-stage approach in which first mobile nodes are selected heuristically and reinserted in an optimal way afterwards. Finally, this approach is embedded into a simulated annealing procedure and compared to other heuristics known for the more general vehicle routing problem with arbitrary demands.},
  archive      = {J_COR},
  author       = {Jan-Niklas Buckow and Benjamin Graf and Sigrid Knust},
  doi          = {10.1016/j.cor.2020.104949},
  journal      = {Computers &amp; Operations Research},
  pages        = {104949},
  shortjournal = {Comput. Oper. Res.},
  title        = {The exponential multi-insertion neighborhood for the vehicle routing problem with unit demands},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Heuristic methods to consecutive block minimization.
<em>COR</em>, <em>120</em>, 104948. (<a
href="https://doi.org/10.1016/j.cor.2020.104948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many combinatorial problems addressed in the literature are modeled using binary matrices. It is often of interest to verify whether these matrices hold the consecutive ones property (C1P), which implies that there exists a permutation of the columns of the matrix such that all nonzero elements can be placed contiguously, forming a unique 1-block in every row. The minimization of the number of 1-blocks is approached by a well-known problem in the literature called consecutive block minimization (CBM), an NP -hard problem. In this study, we propose a graph representation , a heuristic based on a classical algorithm in graph theory, the implementation of a metaheuristic for solving the CBM and the application of an exact method based on a reduction of the CBM to a particular version of the well-known traveling salesman problem . Computational experiments demonstrate that the proposed metaheuristic implementation is competitive, as it matches or improves the best known solution values for all benchmark instances available in the literature, except for a single instance. The proposed exact method reports, for the first time, optimal solutions for these benchmark instances. Consequently, the proposed methods outperform previous methods and become the new state-of-the-art for solving the CBM.},
  archive      = {J_COR},
  author       = {Leonardo C.R. Soares and Jordi Alves Reinsma and Luis H.L. Nascimento and Marco A.M. Carvalho},
  doi          = {10.1016/j.cor.2020.104948},
  journal      = {Computers &amp; Operations Research},
  pages        = {104948},
  shortjournal = {Comput. Oper. Res.},
  title        = {Heuristic methods to consecutive block minimization},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing single-finger keyboard layouts on smartphones.
<em>COR</em>, <em>120</em>, 104947. (<a
href="https://doi.org/10.1016/j.cor.2020.104947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the design of optimized single-finger keyboard layouts on smartphones. In the literature, the optimization problem associated with assigning characters to keys on a single-finger keyboard is denoted as single-finger keyboard layout problem (SK-QAP), which can be seen as a variant of the quadratic assignment problem (QAP), a classical combinatorial optimization problem . To solve it, we propose a simple yet effective local search-based metaheuristic which is composed of three neighborhood structures. Two of them were previously applied to solve the SK-QAP, whereas the third one consists of an adaptation of a QAP neighborhood and it was introduced in this work. In addition, two perturbation mechanisms were developed as diversification procedures and together with the latter neighborhood structure, they revealed to be highly beneficial for improving the performance of the algorithm. Computational experiments were carried out on benchmark instances for English, French, Italian and Spanish. The results obtained were extremely competitive both in terms of solution quality and CPU time, such that all best known solutions were found in a matter of seconds. Moreover, we developed and solved benchmark instances for Portuguese, which currently has more than 230 million speakers, as a first or second language, and also uses the Latin alphabet. We have also proposed and solved bilingual instances, combining English, one of the top spoken languages in the world, with each of the remaining four ones. In addition, we quantify the potential practical benefits of adopting alternative and smartphone-oriented optimized single-finger keyboards, when compared to well-known layouts, namely QWERTY and AZERTY, for the five languages and bilingual variants considered. Finally, we show the efficiency of the proposed algorithm when generating layouts based on other existing arrangements, namely Metropolis and FITALY.},
  archive      = {J_COR},
  author       = {Ana Beatriz Herthel and Anand Subramanian},
  doi          = {10.1016/j.cor.2020.104947},
  journal      = {Computers &amp; Operations Research},
  pages        = {104947},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing single-finger keyboard layouts on smartphones},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An exact algorithm for agile earth observation satellite
scheduling with time-dependent profits. <em>COR</em>, <em>120</em>,
104946. (<a href="https://doi.org/10.1016/j.cor.2020.104946">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scheduling of an Agile Earth Observation Satellite (AEOS) consists of selecting and scheduling a subset of possible targets for observation in order to maximize the collected profit related to the images while satisfying its operational constraints. In this problem, a set of candidate targets for observation is given, each with a time-dependent profit and a visible time window. The exact profit of a target depends on the start time of its observation, reaching its maximum at the midpoint of its visible time window. This time dependency stems from the fact that the image quality is determined by the look angle between the satellite and the target to be observed. We present an exact algorithm for the single-orbit scheduling for an AEOS considering the time-dependent profits. The algorithm is called Adaptive-directional Dynamic Programming with Decremental State Space Relaxation (ADP-DSSR). This algorithm is based on the dynamic programming approach for the Orienteering Problem with Time Windows (OPTW). Several algorithmic improvements are proposed to address the time-dependent profits. The proposed algorithm is evaluated based on extensive computational tests. The experimental results show that the algorithmic improvements significantly reduce the required computational time. The comparison between the proposed exact algorithm and a state-of-the-art heuristic illustrates that our algorithm can find the optimal solutions for sufficiently large instances within limited computational time. The results also show that our algorithm is capable of efficiently solving benchmark OPTW instances.},
  archive      = {J_COR},
  author       = {Guansheng Peng and Guopeng Song and Lining Xing and Aldy Gunawan and Pieter Vansteenwegen},
  doi          = {10.1016/j.cor.2020.104946},
  journal      = {Computers &amp; Operations Research},
  pages        = {104946},
  shortjournal = {Comput. Oper. Res.},
  title        = {An exact algorithm for agile earth observation satellite scheduling with time-dependent profits},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). First-order linear programming in a column generation-based
heuristic approach to the nurse rostering problem. <em>COR</em>,
<em>120</em>, 104945. (<a
href="https://doi.org/10.1016/j.cor.2020.104945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A heuristic method based on column generation is presented for the nurse rostering problem. The method differs significantly from an exact column generation approach or a branch and price algorithm because it performs an incomplete search which quickly produces good solutions but does not provide valid lower bounds. It is effective on large instances for which it has produced best known solutions on benchmark data instances. Several innovations were required to produce solutions for the largest instances within acceptable computation times. These include using a fast first-order linear programming solver based on the work of Chambolle and Pock to approximately solve the restricted master problem. A low-accuracy but fast, first-order linear programming method is shown to be an effective option for this master problem. The pricing problem is modelled as a resource constrained shortest path problem with a two-phase dynamic programming method. The model requires only two resources. This enables it to be solved efficiently. A commercial integer programming solver is also tested on the instances. The commercial solver was unable to produce solutions on the largest instances whereas the heuristic method was able to. It is also compared against the state-of-the-art, previously published methods on these instances. Analysis of the branching strategy developed is presented to provide further insights. All the source code for the algorithms presented has been made available on-line for reproducibility of results and to assist other researchers.},
  archive      = {J_COR},
  author       = {Petter Strandmark and Yi Qu and Timothy Curtois},
  doi          = {10.1016/j.cor.2020.104945},
  journal      = {Computers &amp; Operations Research},
  pages        = {104945},
  shortjournal = {Comput. Oper. Res.},
  title        = {First-order linear programming in a column generation-based heuristic approach to the nurse rostering problem},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic sampling evolutionary (SSE) method for
stochastic bilevel programming problems. <em>COR</em>, <em>120</em>,
104942. (<a href="https://doi.org/10.1016/j.cor.2020.104942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic bilevel programming is a bilevel program having some form of randomness in the problem definition. The main objective is to optimize the leader’s (upper level) stochastic programming problem, where the follower’s problem is assumed to be satisfied as part of the constraints. Due to the involvement of randomness property and the hierarchical nature of the optimization procedure, the problem is computationally expensive and challenging. In this paper, a new meta-heuristic type algorithm is proposed that can effectively solve stochastic bilevel programs. The algorithm is based on realizing the random space, systematic sampling technique to choose a representative action from the leader’s decision space and on a hybrid particle swarm optimization procedure for searching its corresponding follower’s reaction for each leader’s action until Stackelberg equilibrium is achieved. The algorithm is shown to be convergent and its performance is checked using test problems from literature. The simulation result of the algorithm is very much promising and can be used to solve complex stochastic bilevel programming problems.},
  archive      = {J_COR},
  author       = {Natnael Nigussie Goshu and Semu Mitiku Kassa},
  doi          = {10.1016/j.cor.2020.104942},
  journal      = {Computers &amp; Operations Research},
  pages        = {104942},
  shortjournal = {Comput. Oper. Res.},
  title        = {A systematic sampling evolutionary (SSE) method for stochastic bilevel programming problems},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new approach to maximize the profit/cost ratio in a
stock-dependent demand inventory model. <em>COR</em>, <em>120</em>,
104940. (<a href="https://doi.org/10.1016/j.cor.2020.104940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work analyzes an inventory system with stock-dependent demand and non-linear holding cost. It presents a new approach to maximize the return on investment , that is, the profit/cost ratio. When an inventory manager can invest in different projects and the resources are limited, it seems sensible to select those projects that provide a higher return on investment . Thus, the goal of the manager will be to find the inventory policy that gives a major return on investment. Note that the solution for the maximum profit per unit time does not necessarily match the solution of the maximum profit/cost ratio. Consequently, a new procedure to obtain the inventory policy that maximizes the return on investment should be proposed. In this paper, it is proved that maximizing the profit/cost ratio is equivalent to minimizing the inventory cost per unit of an item, instead of minimizing the inventory cost per unit time. The optimal policy can be obtained in a closed form and the replacement should be done when the stock is depleted. Thus, the inventory manager does not need to process a new order while there are items available in stock. This optimal solution is different from the other policies proposed for the problems of minimum cost or maximum profit per unit time. Finally, numerical examples are solved to illustrate the theoretical results and the solution methodology proposed in the work.},
  archive      = {J_COR},
  author       = {Valentín Pando and Luis A. San-José and Joaquín Sicilia},
  doi          = {10.1016/j.cor.2020.104940},
  journal      = {Computers &amp; Operations Research},
  pages        = {104940},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new approach to maximize the profit/cost ratio in a stock-dependent demand inventory model},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimizing production capacity and safety stocks in general
acyclic supply chains. <em>COR</em>, <em>120</em>, 104938. (<a
href="https://doi.org/10.1016/j.cor.2020.104938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the joint optimization of production capacity and safety stocks in supply chains under the guaranteed service approach (GSA). The integrated problem is formulated as a mixed integer nonlinear program (MINLP) and solution procedures are proposed in the cases of general acyclic and spanning tree networks. For general acyclic supply chains, the integrated problem is solved using a Lagrangian decomposition method which iteratively solves capacity planning and safety stock placement subproblems , and adds budget feasibility constraints to strengthen the Lagrangian decomposition lower bound. When the supply chain has a spanning tree structure , an efficient Lagrangian relaxation heuristic dualizes the budget constraint and solves the relaxed problem using a dynamic programming algorithm . Computational experiments on real-world instances show that the Lagrangian decomposition method is able to solve all instances within 0.1\% optimality , while a state-of-the-art solver is unable to provide feasible solutions for large instances. In the case of spanning tree networks, the proposed Lagrangian relaxation heuristic finds optimal or near-optimal solutions and greatly improves running time in comparison to the Lagrangian decomposition method. In addition, numerical experiments show that savings can be achieved through joint optimization of capacity and safety stocks.},
  archive      = {J_COR},
  author       = {Foad Ghadimi and Tarik Aouam and Mario Vanhoucke},
  doi          = {10.1016/j.cor.2020.104938},
  journal      = {Computers &amp; Operations Research},
  pages        = {104938},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing production capacity and safety stocks in general acyclic supply chains},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Lower and upper bounds for the non-linear generalized
assignment problem. <em>COR</em>, <em>120</em>, 104933. (<a
href="https://doi.org/10.1016/j.cor.2020.104933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a non-linear version of the Generalized Assignment Problem, a well-known strongly NP -hard combinatorial optimization problem . We assume that the variables are continuous and that objective function and constraints are defined by non-linear functions of the variables. A mathematical model is introduced and used to derive upper bounds on the optimal solution value. We present constructive heuristics, obtained from decomposition and non-linear programming tools, and a binary linear programming model that provides approximate solutions. By combining the various methods and a local search framework, we finally obtain a hybrid heuristic approach . Extensive computational experiments show that the proposed methods outperform the direct application of non-linear solvers and provide high quality solutions in a reasonable amount of time.},
  archive      = {J_COR},
  author       = {Claudia D’Ambrosio and Silvano Martello and Michele Monaci},
  doi          = {10.1016/j.cor.2020.104933},
  journal      = {Computers &amp; Operations Research},
  pages        = {104933},
  shortjournal = {Comput. Oper. Res.},
  title        = {Lower and upper bounds for the non-linear generalized assignment problem},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic study on meta-heuristic approaches for solving
the graph coloring problem. <em>COR</em>, <em>120</em>, 104850. (<a
href="https://doi.org/10.1016/j.cor.2019.104850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, Graph Coloring Problem (GCP) is one of the key features for graph stamping in graph theory. The general approach is to paint at least edges, vertices, or the surface of the graph with some colors. In the simplest case, a kind of coloring is preferable in which two vertices are not adjacent to the same color. Similarly, the two edges in the same joint should not have the same color. In addition, the same goes for the surface color of the graph. This is one of the NP-hard issues well studied in graph theory. Therefore, many different meta-heuristic techniques are presented to solve the problem and provide high performance. Seemingly, regardless of the importance of the nature-stimulated meta-heuristic methods to solve the GCP, there is not any inclusive report and detailed review about overviewing and investigating the crucial problems of the field. As a result, the present study introduces a wide-ranging reporting of nature- stimulated meta-heuristic methods, which are used throughout the graph coloring. The literature review contains a classification of significant techniques. This study mainly aims at emphasizing the optimization algorithms to handle the GCP problems. Furthermore, the advantages and disadvantages of the meta-heuristic algorithms in solving the GCP and their key issues are examined to offer more advanced meta-heuristic techniques in the future.},
  archive      = {J_COR},
  author       = {Taha Mostafaie and Farzin Modarres Khiyabani and Nima Jafari Navimipour},
  doi          = {10.1016/j.cor.2019.104850},
  journal      = {Computers &amp; Operations Research},
  pages        = {104850},
  shortjournal = {Comput. Oper. Res.},
  title        = {A systematic study on meta-heuristic approaches for solving the graph coloring problem},
  volume       = {120},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Predicting solutions of large-scale optimization problems
via machine learning: A case study in blood supply chain management.
<em>COR</em>, <em>119</em>, 104941. (<a
href="https://doi.org/10.1016/j.cor.2020.104941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical constrained optimization models are often large, and solving them in a reasonable time is a challenge in many applications. Further, many industries have limited access to professional commercial optimization solvers or computational power for use in their day-to-day operational decisions. In this paper, we propose a novel approach to deal with the issue of solving large operational stochastic optimization problems (SOPs) by using machine learning models. We assume that decision makers have access to facilities to optimally solve their large-scale optimization model for some initial and limited period and for some test instances. This might be through a collaborative project with research institutes or through short-term use of high-performance computing facilities. We propose that longer term support can be provided by utilizing the solutions (i.e., the optimal value of the actionable decision variables) of the stochastic optimization model from this initial period to train a machine learning model to learn optimal operational decisions in the future. In this study, the proposed approach is employed to make decisions on transshipment of blood units in a network of hospitals. We compare the decisions learned by several machine learning models with the optimal results obtained if the hospitals had access to commercial optimization solvers and computational power, and with the hospital network’s current empirical heuristic policy. The results show that using a trained neural network model reduces the average daily cost by about 29\% compared with current policy, while the exact optimal policy reduces the average daily cost by 37\%. Although optimization models cannot be fully replaced by machine learning, our proposed approach while not guaranteed to be optimal can improve operational decisions when optimization models are computationally expensive and infeasible for daily operational decisions in organizations such as not-for-profit and small and medium-sized enterprises.},
  archive      = {J_COR},
  author       = {Babak Abbasi and Toktam Babaei and Zahra Hosseinifard and Kate Smith-Miles and Maryam Dehghani},
  doi          = {10.1016/j.cor.2020.104941},
  journal      = {Computers &amp; Operations Research},
  pages        = {104941},
  shortjournal = {Comput. Oper. Res.},
  title        = {Predicting solutions of large-scale optimization problems via machine learning: A case study in blood supply chain management},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal inventory policies for a two-dimensional stochastic
inventory model: A numerical investigation. <em>COR</em>, <em>119</em>,
104939. (<a href="https://doi.org/10.1016/j.cor.2020.104939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper treats a discrete-time, two-item, stationary, infinite-horizon, stochastic inventory model. The system is reviewed at the beginning of each period where the inventory manager has the option of not ordering or ordering item 1 or item 2 or ordering jointly both items. If an order is made, then a set-up cost that depends on the ordered item(s) is accordingly incurred. The demand of each item in each period follows a known random distribution. In addition, the demands of the items are independent of each other and of the period. Inventory holding or backlogging costs are incurred depending on the stock level. This paper proposes and implements an exact stochastic dynamic program that determines the optimal steady state inventory policy. It exemplifies the form of the optimal policy for a number of demand distributions. This form turns out to be an extended ( s, S ) policy, where the state R 2 R2 of possible inventory levels is naturally partitioned into two non overlapping sets: a stopping set and a continuation set. The stopping set consists of three non-overlapping subsets. The first corresponds to ordering item 1, the second to ordering item 2, and the third to jointly ordering items 1 and 2. In the continuation set, no action is required. The paper further illustrates the behavior of this policy for some interesting limiting cases, and discusses its sensitivity to the problem’s parameters.},
  archive      = {J_COR},
  author       = {Rym M’Hallah and Lakdere Benkherouf and Ahmad Al-Kandari},
  doi          = {10.1016/j.cor.2020.104939},
  journal      = {Computers &amp; Operations Research},
  pages        = {104939},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal inventory policies for a two-dimensional stochastic inventory model: A numerical investigation},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A robust optimization approach for solving two-person games
under interval uncertainty. <em>COR</em>, <em>119</em>, 104937. (<a
href="https://doi.org/10.1016/j.cor.2020.104937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, robust optimization methodologies for solving incomplete-information two-person zero-sum and nonzero-sum games are developed that consider single or multiple interval inputs (i.e., interval-valued payoffs). Unlike complete-information games, where all parameters of the game such as individual players’ payoffs are assumed common knowledge, incomplete-information games deal with uncertain payoffs. In some cases, the payoffs may be estimated from imprecise data, such as interval data. In such situations, conventional methods that use deterministic payoffs are not appropriate. Also, in many cases, payoffs are available as multiple intervals. This paper proposes robust optimization models for non-cooperative, simultaneous-move, one-shot, two-person games with incomplete information. The proposed approaches are able to aggregate information from multiple sources and thereby result in more realistic outcomes. The robust optimization methods developed in this paper can be used to solve two-person games with interval-valued (single or multiple intervals) payoffs as well as with single-valued (i.e., deterministic) and aleatory (i.e., precise probabilistic information) payoffs or a combination of them. The proposed methodologies are illustrated with several example problems including an investment decision problem and a capacity expansion decision problem. The proposed decoupled approach is compared with some previously developed approaches and it is demonstrated that the proposed formulations generate conservative solutions in the presence of interval uncertainty.},
  archive      = {J_COR},
  author       = {Arup Dey and Kais Zaman},
  doi          = {10.1016/j.cor.2020.104937},
  journal      = {Computers &amp; Operations Research},
  pages        = {104937},
  shortjournal = {Comput. Oper. Res.},
  title        = {A robust optimization approach for solving two-person games under interval uncertainty},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Unmanned aerial vehicle set covering problem considering
fixed-radius coverage constraint. <em>COR</em>, <em>119</em>, 104936.
(<a href="https://doi.org/10.1016/j.cor.2020.104936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper models the problem of providing an unmanned aerial vehicle (UAV)-based wireless network in a disaster area as a set covering problem that takes into consideration the operational constraints and benefits of UAVs. The research presents a branch-and-price algorithm and two approximation models of the quadratic coverage radius constraint in a simple discretization and a linear pairwise-conflict constraint based on Jung’s theorem. In computational experiments, we found that the exact branch-and-price algorithm and two approximation models are applicable for realistic-scaled problems with up to 100 demand points and 2,000 m of coverage radius.},
  archive      = {J_COR},
  author       = {Youngsoo Park and Peter Nielsen and Ilkyeong Moon},
  doi          = {10.1016/j.cor.2020.104936},
  journal      = {Computers &amp; Operations Research},
  pages        = {104936},
  shortjournal = {Comput. Oper. Res.},
  title        = {Unmanned aerial vehicle set covering problem considering fixed-radius coverage constraint},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decomposition-based algorithms for the crew scheduling and
routing problem in road restoration. <em>COR</em>, <em>119</em>, 104935.
(<a href="https://doi.org/10.1016/j.cor.2020.104935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crew scheduling and routing problem (CSRP) consists of determining the best route and schedule for a single crew to repair damaged nodes in a network affected by extreme events. The problem also involves the design of paths to connect a depot to demand nodes that become accessible only after the damaged nodes in these paths are repaired. The objective is to minimize the total time that demand nodes remain inaccessible from the depot. The integrated scheduling and routing decisions make the problem too complicated to be effectively solved using mixed-integer programming (MIP) formulations. In this paper, we propose exact, heuristic and hybrid approaches for the CSRP. Specifically, we introduce (i) a branch-and-Benders-cut (BBC) method that enhances a previous approach by using a different variable partitioning scheme and new valid inequalities that strengthen the linear relaxation of the master problem; (ii) genetic algorithm and simulated annealing metaheuristics; and (iii) an exact hybrid BBC (HBBC) method that effectively combines the first two approaches. Computational experiments using benchmark instances show that the proposed algorithms can solve large-scale instances in comparison to other methods proposed in the literature, mainly as result of the enhanced BBC method and the hybridization scheme. The HBBC method obtained feasible solutions for the 390 tested instances, solving 30 of them to proven optimality for the first time. On average, it improved the best known lower and upper bounds by 15.21\% and 8.41\%, respectively, and reduced the computational times by more than 70\% with respect to the standalone BBC.},
  archive      = {J_COR},
  author       = {Alfredo Moreno and Pedro Munari and Douglas Alem},
  doi          = {10.1016/j.cor.2020.104935},
  journal      = {Computers &amp; Operations Research},
  pages        = {104935},
  shortjournal = {Comput. Oper. Res.},
  title        = {Decomposition-based algorithms for the crew scheduling and routing problem in road restoration},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cargo routing and scheduling problem in deep-sea
transportation: Case study from a fertilizer company. <em>COR</em>,
<em>119</em>, 104934. (<a
href="https://doi.org/10.1016/j.cor.2020.104934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a mixed-integer linear programming (MILP) model and a solution method for a maritime cargo routing and shipping problem faced by a chemical company in Brazil. This problem is associated with the operational planning of multiple raw materials, collected from European ports and delivered to Brazilian ones to supply mixing production plants. First, the problem is modeled as a pickup and delivery problem with time windows, incorporating several constraints and operational requisites of the specific problem. In order to solve large real-world instances, a matheuristic was developed, employing a modified relax-and-fix strategy, a relaxation procedure, and repair and polishing routines for MILP solutions. The matheuristic was evaluated using real-life instances provided by the company, demonstrating the efficiency and efficacy of the developed solution method.},
  archive      = {J_COR},
  author       = {Pietro Tiaraju Giavarina dos Santos and Endel Kretschmann and Denis Borenstein and Pablo Cristini Guedes},
  doi          = {10.1016/j.cor.2020.104934},
  journal      = {Computers &amp; Operations Research},
  pages        = {104934},
  shortjournal = {Comput. Oper. Res.},
  title        = {Cargo routing and scheduling problem in deep-sea transportation: Case study from a fertilizer company},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Codon optimization by 0-1 linear programming. <em>COR</em>,
<em>119</em>, 104932. (<a
href="https://doi.org/10.1016/j.cor.2020.104932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of choosing an optimal codon sequence arises when synthetic protein-coding genes are added to cloning vectors for expression within a non-native host organism: to maximize yield, the chosen codons should have a high frequency in the host genome, but particular nucleotide bases sequences (called “motifs”) should be avoided or, instead, included. Dynamic programming (DP) has successfully been used in previous approaches to this problem. However, DP has a computational limit, especially when long motifs are forbidden, and does not allow control of motif positioning and combination. We reformulate the problem as an integer linear program (IP) and show that, with the same computational resources, one can easily solve problems with much more nucleotide bases and much longer forbidden/desired motifs than with DP. Moreover, IP ( i ) offers more flexibility than DP to treat constraints/objectives of different nature, and ( ii ) can efficiently deal with newly discovered critical motifs by dynamically re-optimizing additional variables and mathematical constraints.},
  archive      = {J_COR},
  author       = {Claudio Arbib and Mustafa Ç. Pınar and Fabrizio Rossi and Alessandra Tessitore},
  doi          = {10.1016/j.cor.2020.104932},
  journal      = {Computers &amp; Operations Research},
  pages        = {104932},
  shortjournal = {Comput. Oper. Res.},
  title        = {Codon optimization by 0-1 linear programming},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Evolutionary tabu search for flexible due-date satisfaction
in fuzzy job shop scheduling. <em>COR</em>, <em>119</em>, 104931. (<a
href="https://doi.org/10.1016/j.cor.2020.104931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the job shop scheduling problem with fuzzy sets modelling uncertain durations and flexible due dates. With the goal of maximising due-date satisfaction under uncertainty, we first give a new measure of overall due-date satisfaction in this setting. Then, we define a neighbourhood structure for local search, analyse its theoretical properties and provide a neighbour-estimation procedure. Additionally, a tabu search procedure using the neighbourhood is combined with a genetic algorithm, so the resulting memetic algorithm , guided by the defined due-date satisfaction measure, is run on a set of benchmarks. The obtained results illustrate the potential of our proposal.},
  archive      = {J_COR},
  author       = {Camino R. Vela and Sezin Afsar and Juan José Palacios and Inés González-Rodríguez and Jorge Puente},
  doi          = {10.1016/j.cor.2020.104931},
  journal      = {Computers &amp; Operations Research},
  pages        = {104931},
  shortjournal = {Comput. Oper. Res.},
  title        = {Evolutionary tabu search for flexible due-date satisfaction in fuzzy job shop scheduling},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An optimal control approach to day-to-day congestion pricing
for stochastic transportation networks. <em>COR</em>, <em>119</em>,
104929. (<a href="https://doi.org/10.1016/j.cor.2020.104929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Congestion pricing has become an effective instrument for traffic demand management on road networks . This paper proposes an optimal control approach for congestion pricing for day-to-day timescale that incorporates demand uncertainty and elasticity . Travelers make the decision to travel or not based on the experienced system travel time in the previous day and traffic managers take tolling decisions in order to minimize the average system travel time over a long time horizon. We formulate the problem as a Markov decision process (MDP) and analyze the problem to see if it satisfies conditions for conducting a satisfactory solution analysis. Such an analysis of MDPs is often dependent on the type of state space as well as on the boundedness of travel time functions. We do not constrain the travel time functions to be bounded and present an analysis centered around weighted sup-norm contractions that also holds for unbounded travel time functions. We find that the formulated MDP satisfies a set of assumptions to ensure Bellman’s optimality condition. Through this result, the existence of the optimal average cost of the MDP is shown. A method based on approximate dynamic programming is proposed to resolve the implementation and computational issues of solving the control problem. Numerical results suggest that the proposed method efficiently solves the problem and produces accurate solutions.},
  archive      = {J_COR},
  author       = {Hemant Gehlot and Harsha Honnappa and Satish V. Ukkusuri},
  doi          = {10.1016/j.cor.2020.104929},
  journal      = {Computers &amp; Operations Research},
  pages        = {104929},
  shortjournal = {Comput. Oper. Res.},
  title        = {An optimal control approach to day-to-day congestion pricing for stochastic transportation networks},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-machine preventive maintenance scheduling with
imperfect interventions: A restless bandit approach. <em>COR</em>,
<em>119</em>, 104927. (<a
href="https://doi.org/10.1016/j.cor.2020.104927">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we address the problem of allocating the efforts of a collection of repairmen to a number of deteriorating machines in order to reduce operation costs and to mitigate the cost (and likelihood) of unexpected failures. Notwithstanding these preventive maintenance interventions are aimed at returning the machine to a so-called as-good-as-new state, unforeseeable factors may imply that maintenance interventions are not perfect and the machine is only returned to an earlier (uncertain) state of wear. The problem is modelled as a restless bandit problem and an index policy for the sequential allocation of maintenance tasks is proposed. A series of numerical experiments shows the strong performance of the proposed policy. Moreover, the methodology is of interest in the general context of dynamic resource allocation and restless bandit problems, as well as being useful in the particular imperfect maintenance model described.},
  archive      = {J_COR},
  author       = {Diego Ruiz-Hernández and Jesús M. Pinar-Pérez and David Delgado-Gómez},
  doi          = {10.1016/j.cor.2020.104927},
  journal      = {Computers &amp; Operations Research},
  pages        = {104927},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-machine preventive maintenance scheduling with imperfect interventions: A restless bandit approach},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A systematic literature review on machine learning
applications for sustainable agriculture supply chain performance.
<em>COR</em>, <em>119</em>, 104926. (<a
href="https://doi.org/10.1016/j.cor.2020.104926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture plays an important role in sustaining all human activities. Major challenges such as overpopulation, competition for resources poses a threat to the food security of the planet. In order to tackle the ever-increasing complex problems in agricultural production systems, advancements in smart farming and precision agriculture offers important tools to address agricultural sustainability challenges. Data analytics hold the key to ensure future food security, food safety, and ecological sustainability. Disruptive information and communication technologies such as machine learning, big data analytics, cloud computing, and blockchain can address several problems such as productivity and yield improvement, water conservation, ensuring soil and plant health, and enhance environmental stewardship. The current study presents a systematic review of machine learning (ML) applications in agricultural supply chains (ASCs). Ninety three research papers were reviewed based on the applications of different ML algorithms in different phases of the ASCs. The study highlights how ASCs can benefit from ML techniques and lead to ASC sustainability. Based on the study findings an ML applications framework for sustainable ASC is proposed. The framework identifies the role of ML algorithms in providing real-time analytic insights for pro-active data-driven decision-making in the ASCs and provides the researchers, practitioners, and policymakers with guidelines on the successful management of ASCs for improved agricultural productivity and sustainability.},
  archive      = {J_COR},
  author       = {Rohit Sharma and Sachin S. Kamble and Angappa Gunasekaran and Vikas Kumar and Anil Kumar},
  doi          = {10.1016/j.cor.2020.104926},
  journal      = {Computers &amp; Operations Research},
  pages        = {104926},
  shortjournal = {Comput. Oper. Res.},
  title        = {A systematic literature review on machine learning applications for sustainable agriculture supply chain performance},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General swap-based multiple neighborhood adaptive search for
the maximum balanced biclique problem. <em>COR</em>, <em>119</em>,
104922. (<a href="https://doi.org/10.1016/j.cor.2020.104922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximum balanced biclique problem (MBBP) is to find the largest complete bipartite subgraph induced by two equal-sized subsets of vertices in a bipartite graph . MBBP is an NP-hard problem with a number of relevant applications. In this work, we propose a general swap-based multiple neighborhood adaptive search (SBMNAS) for MBBP. This algorithm combines a general k-SWAP operator which is used in local searches for MBBP for the first time, an adaptive rule for neighborhood exploration and a frequency-based perturbation strategy to ensure a global diversification. SBMNAS is evaluated on 60 random dense instances and 25 real-life large sparse instances from the popular Koblenz Network Collection (KONECT). Computational results show that our proposed algorithm attains all but one best-known solutions, and finds improved best-known results for 19 instances (new lower bounds).},
  archive      = {J_COR},
  author       = {Mingjie Li and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.cor.2020.104922},
  journal      = {Computers &amp; Operations Research},
  pages        = {104922},
  shortjournal = {Comput. Oper. Res.},
  title        = {General swap-based multiple neighborhood adaptive search for the maximum balanced biclique problem},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling emergency response operations: A theory building
survey. <em>COR</em>, <em>119</em>, 104921. (<a
href="https://doi.org/10.1016/j.cor.2020.104921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the response phase of an emergency, decision makers manage processes that save lives, protect infrastructure and contain evolving threats. In this paper, we undertake a comprehensive survey of the emergency response operations literature. In collating and classifying our literature sample, we employ novel methodologies adapted from unsupervised learning and network analysis to reduce sampling and expectancy biases. We find that operations research supporting emergency response has been developing in discernible clusters, with each cluster of studies focused on a particular process such as evacuation or aid distribution. Our study both serves to strengthen the theoretical foundation of emergency response operations and identifies plentiful opportunities for researchers seeking to advance the state-of-the-art in this exciting frontier of operations research.},
  archive      = {J_COR},
  author       = {J.P. Minas and N.C. Simpson and Z.Y. Tacheva},
  doi          = {10.1016/j.cor.2020.104921},
  journal      = {Computers &amp; Operations Research},
  pages        = {104921},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modeling emergency response operations: A theory building survey},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Attaining flexibility in seru production system by means of
shojinka: An optimization model and solution approaches. <em>COR</em>,
<em>119</em>, 104917. (<a
href="https://doi.org/10.1016/j.cor.2020.104917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the problem of workforce scheduling in the seru production environment where operations are performed within independent serus, so-called assembly cells. Although the seru system attracts more attention in recent years, the addressed problem remains scarcely investigated in the existing literature. To analyze the problem in detail, first, a comprehensive optimization model is proposed by placing an emphasis on achieving Shojinka, which is a Japanese word. Subsequently, the structural properties, the lower and upper bounds are presented to aid the understanding of the problem. The model is solved optimally for small-sized problems; however, several algorithms with two different initial population generation procedures are developed for large-sized problems due to the complexity of the problem. The impact of achieving Shojinka along with the workers’ heterogeneity is investigated in detail through experimental design. To this end, four different scenarios are constructed and a distinct algorithm is devoted to each scenario for the comparison purpose. According to the results, allowing interseru worker transfer leads to a considerable decrease in the makespan. This study contributes to the existing academic literature by presenting several insights regarding the implementation of operational strategies on the seru production system.},
  archive      = {J_COR},
  author       = {Ömer Faruk Yılmaz},
  doi          = {10.1016/j.cor.2020.104917},
  journal      = {Computers &amp; Operations Research},
  pages        = {104917},
  shortjournal = {Comput. Oper. Res.},
  title        = {Attaining flexibility in seru production system by means of shojinka: An optimization model and solution approaches},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Matrix-analytic solutions in production lines without
buffers. <em>COR</em>, <em>119</em>, 104903. (<a
href="https://doi.org/10.1016/j.cor.2020.104903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An exact analysis of multistation production lines in which the service periods at all stations follow a matrix-based continuous phase-type (PH) distribution is proposed. The approach uses a holding period model for production lines without buffers, and it is shown that the PH distribution satisfies closure properties in this model. Accordingly, due to the production line mechanism, the model contains random variables, such as the holding, blocking, and starving/idle periods at each station, which also follow PH distributions. Utilizing these properties, an algorithm for generating the distribution functions of these random variables, instead of only calculating the mean values, is derived, and it includes the distribution function of the production cycle. Numerical results for several numbers of stations and service period distributions are presented.},
  archive      = {J_COR},
  author       = {Abdullah Alkaff and Mochamad Nur Qomarudin and Stefanus Eko Wiratno},
  doi          = {10.1016/j.cor.2020.104903},
  journal      = {Computers &amp; Operations Research},
  pages        = {104903},
  shortjournal = {Comput. Oper. Res.},
  title        = {Matrix-analytic solutions in production lines without buffers},
  volume       = {119},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multiperiod workforce scheduling and routing problem with
dependent tasks. <em>COR</em>, <em>118</em>, 104930. (<a
href="https://doi.org/10.1016/j.cor.2020.104930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a new Workforce Scheduling and Routing Problem , denoted Multiperiod Workforce Scheduling and Routing Problem with Dependent Tasks. In this problem, customers request services from a company. Each service is composed of dependent tasks, which are executed by teams of varying skills along one or more days. Tasks belonging to a service may be executed by different teams, and customers may be visited more than once a day, as long as precedences are not violated. The objective is to schedule and route teams so that the makespan is minimized, i.e., all services are completed in the minimum number of days. In order to solve this problem, we propose a Mixed-Integer Programming model, a constructive algorithm and heuristic algorithms based on the Ant Colony Optimization (ACO) metaheuristic . The presence of precedence constraints makes it difficult to develop efficient local search algorithms . This motivates the choice of the ACO metaheuristic , which is effective in guiding the construction process towards good solutions. Computational results show that the model is capable of consistently solving problems with up to about 20 customers and 60 tasks. In most cases, the best performing ACO algorithm was able to match the best solution provided by the model in a fraction of its computational time.},
  archive      = {J_COR},
  author       = {Dilson Lucas Pereira and Júlio César Alves and Mayron César de Oliveira Moreira},
  doi          = {10.1016/j.cor.2020.104930},
  journal      = {Computers &amp; Operations Research},
  pages        = {104930},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multiperiod workforce scheduling and routing problem with dependent tasks},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-stage stochastic programming for demand response
optimization. <em>COR</em>, <em>118</em>, 104928. (<a
href="https://doi.org/10.1016/j.cor.2020.104928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increase in the energy consumption puts pressure on natural resources and environment and results in a rise in the price of energy. This motivates residents to schedule their energy consumption through demand response mechanism . We propose a multi-stage stochastic programming model to schedule different kinds of electrical appliances under uncertain weather conditions and availability of renewable energy. We incorporate appliances with chargeable and dischargeable batteries to better utilize the renewable energy sources . Our aim is to minimize the electricity cost and the residents’ dissatisfaction. We use a scenario groupwise decomposition (group subproblem) approach to compute lower and upper bounds for instances with a large number of scenarios. The results of our computational experiments show that the approach is very effective in finding high quality solutions in small computation times. We provide insights about how optimization and renewable energy combined with batteries for storage result in peak demand reduction, savings in electricity cost and more pleasant schedules for residents with different levels of price sensitivity.},
  archive      = {J_COR},
  author       = {Munise Kübra Şahin and Özlem Çavuş and Hande Yaman},
  doi          = {10.1016/j.cor.2020.104928},
  journal      = {Computers &amp; Operations Research},
  pages        = {104928},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-stage stochastic programming for demand response optimization},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Classification of the existing knowledge base of OR/MS
research and practice (1990–2019) using a proposed classification
scheme. <em>COR</em>, <em>118</em>, 104920. (<a
href="https://doi.org/10.1016/j.cor.2020.104920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operations Research/Management Science (OR/MS) has traditionally been defined as the discipline that applies advanced analytical methods to help make better and more informed decisions. The purpose of this paper is to present an analysis of the existing knowledge base of OR/MS research and practice using a proposed keywords-based approach. A conceptual structure is necessary in order to place in context the findings of our keyword analysis. Towards this we first present a classification scheme that relies on keywords that appeared in articles published in important OR/MS journals from 1990–2019 (over 82,000 articles). Our classification scheme applies a methodological approach towards keyword selection and its systematic classification, wherein approximately 1300 most frequently used keywords (in terms of cumulative percentage, these keywords and their derivations account for more than 45\% of the approx. 290,000 keyword occurrences used by the authors to represent the content of their articles) were selected and organised in a classification scheme with seven top-level categories and multiple levels of sub-categories. The scheme identified the most commonly used keywords relating to OR/MS problems, modeling techniques and applications. Next, we use this proposed scheme to present an analysis of the last 30 years, in three distinct time periods, to show the changes in OR/MS literature. The contribution of the paper is thus twofold, (a) the development of a proposed discipline-based classification of keywords (like the ACM Computer Classification System and the AMS Mathematics Subject Classification), and (b) an analysis of OR/MS research and practice using the proposed classification.},
  archive      = {J_COR},
  author       = {Navonil Mustafee and Korina Katsaliaki},
  doi          = {10.1016/j.cor.2020.104920},
  journal      = {Computers &amp; Operations Research},
  pages        = {104920},
  shortjournal = {Comput. Oper. Res.},
  title        = {Classification of the existing knowledge base of OR/MS research and practice (1990–2019) using a proposed classification scheme},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The two-echelon vehicle routing problem with covering
options: City logistics with cargo bikes and parcel lockers.
<em>COR</em>, <em>118</em>, 104919. (<a
href="https://doi.org/10.1016/j.cor.2020.104919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the two-echelon vehicle routing problem with covering options (2E-VRP-CO). This problem arises in sustainable applications for e-commerce and city distribution. In the first echelon, trucks depart from a single depot and transport goods to two types of locations. At covering locations, such as parcel lockers, customers can pick up goods themselves. At satellite locations, goods are transferred to zero-emission vehicles (such as cargo bikes) that deliver to customers. If desired, customers can indicate their choice for delivery. The 2E-VRP-CO aims at finding cost-minimizing solutions by selecting locations and routes to serve all customers. We present a compact mixed integer programming formulation and an efficient and tailored adaptive large neighborhood search heuristic that provides high-quality, and often optimal, solutions to the 2E-VRP-CO. The 2E-VRP-CO has as special cases the two-echelon vehicle routing problem, and the simultaneous facility location and vehicle routing problem without duration constraints. On these special cases, for which our heuristic predominantly solves the established benchmark instances either to optimality or to the best-known solution, our heuristic finds three new best-known solutions. Moreover, we introduce a new set of benchmark instances for the 2E-VRP-CO and provide managerial insights when distribution via both satellite and covering locations is most beneficial. Our results indicate that customers in the same area are best-served either via cargo-bikes or parcel lockers (i.e., not both), and that the use of parcel lockers has a great potential to reduce driving distance.},
  archive      = {J_COR},
  author       = {David L.J.U. Enthoven and Bolor Jargalsaikhan and Kees Jan Roodbergen and Michiel A. J. uit het Broek and Albert H. Schrotenboer},
  doi          = {10.1016/j.cor.2020.104919},
  journal      = {Computers &amp; Operations Research},
  pages        = {104919},
  shortjournal = {Comput. Oper. Res.},
  title        = {The two-echelon vehicle routing problem with covering options: City logistics with cargo bikes and parcel lockers},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Identical parallel machine scheduling with assurance of
maximum waiting time for an emergency job. <em>COR</em>, <em>118</em>,
104918. (<a href="https://doi.org/10.1016/j.cor.2020.104918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, customer satisfaction is playing an increasingly vital role in both manufacturing and service industries. Assuring an acceptable waiting time to customers is considered as an effective approach to improve customer satisfaction. In this study, an identical parallel machine scheduling problem assuring the maximum waiting time for an emergency job which arrives at any time is investigated. A mixed integer programming model is formulated, based on which a variant formulation is generated. The formulations are further enhanced by various techniques, which forms two formulation-based methods. Two objectives, makespan and total completion time, are considered separately. Regarding the makespan, the worst-case approximation ratios of the classical heuristic rules are deduced. For the total completion time, efficient bounds are provided and the NP-hardness of the problem is proved. Heuristic methods based on the classical dispatch rules are developed, for both the cases. Extensive computational experiments are conducted, based on which the performances of the formulation-based methods and heuristics are compared, the relationship between the objective values and the assured maximum waiting time for an emergency job is explored, and a few observations and managerial insights are obtained.},
  archive      = {J_COR},
  author       = {Shijin Wang and Ruochen Wu and Feng Chu and Jianbo Yu},
  doi          = {10.1016/j.cor.2020.104918},
  journal      = {Computers &amp; Operations Research},
  pages        = {104918},
  shortjournal = {Comput. Oper. Res.},
  title        = {Identical parallel machine scheduling with assurance of maximum waiting time for an emergency job},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analytical and computational aspects of the infinite buffer
single server n policy queue with batch renewal input. <em>COR</em>,
<em>118</em>, 104916. (<a
href="https://doi.org/10.1016/j.cor.2020.104916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we provide a complete analysis of an infinite buffer batch arrival GI X / M /1 queue with N threshold policy. According to this policy, as soon as the system becomes empty, the server stops service and turns into an idle state. It again resumes service when the number of customers in the queue reaches N or more. Based on the supplementary variable and the difference equation method, we propose an algorithm to obtain the steady-state probability distribution of the system-size at pre-arrival and arbitrary epochs. We perform the waiting time analysis of the model and derive the mean waiting time of an arbitrary customer along with other performance measures. Finally, we validate our analytical results by some numerical examples and conduct certain numerical experiments to study the impact of parameters on the performance characteristics of the system. The work carried out in this paper provides a substantial methodological contribution in dealing with N policy queueing models, particularly with renewal arrival process.},
  archive      = {J_COR},
  author       = {F.P. Barbhuiya and U.C. Gupta},
  doi          = {10.1016/j.cor.2020.104916},
  journal      = {Computers &amp; Operations Research},
  pages        = {104916},
  shortjournal = {Comput. Oper. Res.},
  title        = {Analytical and computational aspects of the infinite buffer single server n policy queue with batch renewal input},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integrated solution approach for multi-objective,
multi-skill workforce scheduling and routing problems. <em>COR</em>,
<em>118</em>, 104908. (<a
href="https://doi.org/10.1016/j.cor.2020.104908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the multi-skill workforce scheduling and routing problem in field service operations. It is motivated by a real-life problem faced by electricity distribution companies on a daily basis. Given a set of technicians with different skills and a set of geographically dispersed tasks with different skill requirements and priorities, the aim is to form teams of technicians and to assign a sequence of tasks to each team according to their skills. There are two objectives: completing higher priority tasks earlier and minimizing total operational costs. We propose a mixed integer programming model to find Pareto optimal solutions. Because the computational effort considerably increases for real life problem instances, we propose a two-stage matheuristic to obtain a good approximation of the Pareto frontier . We demonstrate the performance of the proposed matheuristic in real life problem instances and instances from the literature.},
  archive      = {J_COR},
  author       = {Seray Çakırgil and Eda Yücel and Gültekin Kuyzu},
  doi          = {10.1016/j.cor.2020.104908},
  journal      = {Computers &amp; Operations Research},
  pages        = {104908},
  shortjournal = {Comput. Oper. Res.},
  title        = {An integrated solution approach for multi-objective, multi-skill workforce scheduling and routing problems},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A voltage drop limited decentralized electric power
distribution network. <em>COR</em>, <em>118</em>, 104907. (<a
href="https://doi.org/10.1016/j.cor.2020.104907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a decentralized electric power distribution network design problem in rural areas with no existing infrastructure. While the source facilities can be located anywhere on the continuous space, the demand points are connected to these source facilities on a tree topology . Since excessive voltage drops cause problems with the appliances at the demand points, we employ a limitation on the voltage drop as a constraint in our distribution network design. Given the locations of demand points on a plane, we formulate a mixed-integer quadratically-constrained programming model for our design problem. Since this problem can be solved for only very small instances, we propose seven alternative heuristic methods that initially decompose the set of demand points into clusters that can be served by a single source facility. Then, for each cluster, these methods tackle the problems of locating the source facility on the continuous space and designing the voltage drop-limited minimum spanning tree to serve all demand points in the cluster by a single facility. We select the solution method based on the size of each cluster; alternative methods can be employed for different sized clusters of the same problem. We use numerical examples to demonstrate the benefits of the tree topology networks obtained by each method compared to the star topology distribution networks for the same clusters.},
  archive      = {J_COR},
  author       = {Kagan Gokbayrak and Harun Avci},
  doi          = {10.1016/j.cor.2020.104907},
  journal      = {Computers &amp; Operations Research},
  pages        = {104907},
  shortjournal = {Comput. Oper. Res.},
  title        = {A voltage drop limited decentralized electric power distribution network},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A novel matheuristic approach for a two-stage transportation
problem with fixed costs associated to the routes. <em>COR</em>,
<em>118</em>, 104906. (<a
href="https://doi.org/10.1016/j.cor.2020.104906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation problems are nowadays strategic issues which aim at selecting the routes to be opened between different facilities in order to achieve an efficient distribution strategy. This paper presents a matheuristic approach for solving the two-stage transportation problem with fixed costs associated to the routes. Our heuristic algorithm is designed to fit the challenges of the investigated transportation problem and is obtained by incorporating a linear programming optimization problem within the framework of a genetic algorithm. In addition we integrated within our proposed genetic algorithm a powerful local search procedure capable of fine tuning the global search. We evaluated the performance of the proposed solution approach on two sets of benchmark instances available in the literature. The computational results that we achieved, demonstrate that the solution approach we propose is efficient in yielding solutions that are high in quality which occur during running times that are considered reasonable, besides its superiority in comparison with other existing competing methods from the literature.},
  archive      = {J_COR},
  author       = {Ovidiu Cosma and Petrică C. Pop and Daniela Dănciulescu},
  doi          = {10.1016/j.cor.2020.104906},
  journal      = {Computers &amp; Operations Research},
  pages        = {104906},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel matheuristic approach for a two-stage transportation problem with fixed costs associated to the routes},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ergonomic risk and cycle time minimization for the u-shaped
worker assignment assembly line balancing problem: A multi-objective
approach. <em>COR</em>, <em>118</em>, 104905. (<a
href="https://doi.org/10.1016/j.cor.2020.104905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workers still perform the bulk of operations in the manufacturing industry. The consideration of the assignment of workers and the reduction of ergonomic risks in U-shaped assembly lines is of paramount importance. However, the objectives of efficient task and worker assignment and a reduction in ergonomic risks are not usually correlated. Moreover, there is limited research in the existing literature into multi-objective approaches in U-shaped assembly lines. We formulate a U-shaped assembly worker assignment and balancing problem to simultaneously minimize cycle times and ergonomic risks. In addition, and due to its simplicity and successful results in flow shop scheduling problems, a Restarted Iterated Pareto Greedy algorithm is designed to optimize both objectives. In this algorithm, a problem-specific heuristic-based initialization is extended to improve the initial solution. Two precedence-based greedy and local search phases are developed to exploit the space around the current solution. Finally, a restart mechanism is proposed to help the algorithm escape from local optima. Comprehensive computational results, supported by detailed statistical analyses, suggest that the proposed multi-objective algorithm outperforms existing methods on a large number of benchmark instances.},
  archive      = {J_COR},
  author       = {Zikai Zhang and QiuHua Tang and Rubén Ruiz and Liping Zhang},
  doi          = {10.1016/j.cor.2020.104905},
  journal      = {Computers &amp; Operations Research},
  pages        = {104905},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ergonomic risk and cycle time minimization for the U-shaped worker assignment assembly line balancing problem: A multi-objective approach},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The fuel replenishment problem: A split-delivery
multi-compartment vehicle routing problem with multiple trips.
<em>COR</em>, <em>118</em>, 104904. (<a
href="https://doi.org/10.1016/j.cor.2020.104904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fuel Replenishment Problem (FRP) is a multi-compartment, multi-trip, split-delivery VRP in which tanker trucks transport different types of petrol, separated over multiple vehicle compartments, from an oil depot to petrol stations. Large customer demands often necessitate multiple deliveries. Throughout a single working day, a tanker truck returns several times to the oil depot to resupply. A solution to the FRP involves computing a delivery schedule of minimum duration, thereby determining for each vehicle (1) the allocation of oil products to vehicle compartments, (2) the delivery routes, and (3) the delivery patterns. To solve FRP efficiently, an Adaptive Large Neighborhood Search (ALNS) heuristic is constructed. The heuristic is evaluated on data from a Chinese petroleum transportation company and compared against exact results from a MILP model and lower bounds from a column generation approach. In addition, we perform sensitivity analysis on different problem features, including the number of vehicles, products, vehicle compartments and their capacities. Computational results show that the ALNS heuristic is capable of solving instances with up to 60 customers and 3 different products in less than 25 minutes with an average optimality gap of around 10\%. On smaller instances, the heuristic finds optimal solutions in significantly less time than the exact MILP formulation.},
  archive      = {J_COR},
  author       = {L. Wang and J. Kinable and T. van Woensel},
  doi          = {10.1016/j.cor.2020.104904},
  journal      = {Computers &amp; Operations Research},
  pages        = {104904},
  shortjournal = {Comput. Oper. Res.},
  title        = {The fuel replenishment problem: A split-delivery multi-compartment vehicle routing problem with multiple trips},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Cost accounting methods and periodic-review policies for
serial inventory systems. <em>COR</em>, <em>118</em>, 104902. (<a
href="https://doi.org/10.1016/j.cor.2020.104902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For reasons of mathematical tractability and historic convention, previous studies on periodic-review inventory control policies under uncertainty have typically accounted inventory related costs at the end of each review period. Inventory holding and shortage costs in reality, however, often accrue continuously in time. Given this discrepancy, it is necessary to understand the impact of end-of-period cost accounting. We address this issue for serial inventory systems adopting fixed-interval ordering in this paper. Our contribution is two-fold. First, we develop a model to evaluate and optimize a serial inventory system where inventory holding and shortage costs accrue continuously in time. This model includes discrete-time cost accounting that evaluates inventory holding and shortage costs at a single or multiple discrete points in a reorder interval as a special case. Second, we assess the effect of applying discrete-time cost accounting when inventory holding and shortage costs actually accrue continuously in time. We make three observations. First, for single-stage systems, end-of-period cost accounting generally results in very significant cost inefficiency and this cost inefficiency is bounded below by the ratio of inventory holding cost to backordering cost asymptotically as the reorder interval increases. Second, for multiple-stage systems, the cost inefficiency of end-of-period cost accounting decreases with the number of stages but is still significant for a typical serial system. Finally, extending cost accounting from the end to multiple discrete points in a reorder interval does not provide a significant modelling and computational advantage as compared to our continuous-time cost accounting model.},
  archive      = {J_COR},
  author       = {Qinan Wang and Guangyu Wan},
  doi          = {10.1016/j.cor.2020.104902},
  journal      = {Computers &amp; Operations Research},
  pages        = {104902},
  shortjournal = {Comput. Oper. Res.},
  title        = {Cost accounting methods and periodic-review policies for serial inventory systems},
  volume       = {118},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Sequencing in an appointment system with deterministic
arrivals and non-identical exponential service times. <em>COR</em>,
<em>117</em>, 104901. (<a
href="https://doi.org/10.1016/j.cor.2020.104901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an appointment system with deterministic arrival times and non-identical exponential service times with the objective of minimizing the expected costs of customer-waiting and server-idle times (WIT). For two customers, this paper shows analytically that the smallest-variance-first-rule (SV) and, equivalently, the smallest-mean-first-rule (SM) minimize WIT when the second customer arrives at either optimal or arbitrary arrival time. For three customers, this paper shows analytically that either SV or SM minimize WIT, assuming that each customer arrives at the cumulative sum of expected service times of prior customers. Based on numerical evaluation, this paper recommends that the exponential distribution parameter, which determines either SV or SM sequences, be used for a general number of customers.},
  archive      = {J_COR},
  author       = {Sangdo Choi and Wilbert E. Wilhelm},
  doi          = {10.1016/j.cor.2020.104901},
  journal      = {Computers &amp; Operations Research},
  pages        = {104901},
  shortjournal = {Comput. Oper. Res.},
  title        = {Sequencing in an appointment system with deterministic arrivals and non-identical exponential service times},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A smooth proximity measure for optimality in multi-objective
optimization using benson’s method. <em>COR</em>, <em>117</em>, 104900.
(<a href="https://doi.org/10.1016/j.cor.2020.104900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization problems give rise to a set of trade-off Pareto-optimal solutions. To evaluate a set-based multi-objective optimization algorithm , such as an evolutionary multi-objective optimization (EMO) algorithm, for its convergence and diversity attainment, more than one performance metrics are required. To measure the convergence aspect, a new Karush-Kuhn-Tucker proximity measure (KKTPM) was recently proposed based on the extent of satisfaction of KKT optimality conditions on the augmented achievement scalarization function (AASF) formulation. However, the Pareto-optimality of a point depends on a parameter needed to be used in the AASF formulation. In this paper, we use Benson’s method as a scalarized version of the multi-objective optimization problem, mainly because it is parameter-less and is a popularly used in the multi-criterion decision-making (MCDM) literature. The proposed Benson’s method based metric (B-KKTPM) is applied to optimized solutions of popular EMO algorithms on standard two to 10-objective test problems and to a few engineering design problems. B-KKTPM is able to determine relative closeness of a set of trade-off solutions from the strictly efficient solutions without any prior knowledge of them. To reduce the computational cost of solving an optimization problem to compute B-KKTPM, we also propose a direct, but approximate, method. The obtained results from our extensive study indicates that (i) the proposed optimization based and direct B-KKTPMs can be used for a termination check for any optimization algorithm , and (ii) the direct B-KKTPM method can be used as a replacement of the optimization-based version for a good trade-off between computational time and accuracy.},
  archive      = {J_COR},
  author       = {Mohamed Abouhawwash and Mohammed Jameel and Kalyanmoy Deb},
  doi          = {10.1016/j.cor.2020.104900},
  journal      = {Computers &amp; Operations Research},
  pages        = {104900},
  shortjournal = {Comput. Oper. Res.},
  title        = {A smooth proximity measure for optimality in multi-objective optimization using benson’s method},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic aircraft recovery problem - an operational decision
support framework. <em>COR</em>, <em>117</em>, 104892. (<a
href="https://doi.org/10.1016/j.cor.2020.104892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for solving the recovery of the airline schedule when disruptions have occurred. The goal is to develop an operational tool that provides the airline with a solution in less than one minute. The proposed recovery model uses a heuristic that iteratively solves selections of the airline’s fleet in order to quickly converge to a good solution. An initial solution is always presented in seconds, after which potential reductions of disruption cost are investigated. The schedule is modeled as a set of parallel time-space networks, using an integer linear programming . The model is solved dynamically; a recovery solution is found whenever a disruption occurs and subsequent disruptions are solved based on the previously found solution. Aircraft maintenance schedules and passenger itineraries are modeled, while crew concerns are indirectly taken into consideration to avoid major disruptions caused by the recovery solution. The approach presented in this paper can be applied on heterogeneous fleets and to both point-to-point and (multi) hub-and-spoke airlines. The performance of the selection heuristic is discussed using a case study on the network of an airline operating in the United States. This case study shows that the selection heuristic can find a globally optimal solution in 90\% of the disruption instances tested, within 22 s on average. This corresponds to 4\% of the time needed to compute the optimal solution using the entire fleet.},
  archive      = {J_COR},
  author       = {J. Vink and B.F. Santos and W.J.C. Verhagen and I. Medeiros and R. Filho},
  doi          = {10.1016/j.cor.2020.104892},
  journal      = {Computers &amp; Operations Research},
  pages        = {104892},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic aircraft recovery problem - an operational decision support framework},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Clustering and portfolio selection problems: A unified
framework. <em>COR</em>, <em>117</em>, 104891. (<a
href="https://doi.org/10.1016/j.cor.2020.104891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set of assets and an investment capital, the classical portfolio selection problem consists in determining the amount of capital to be invested in each asset in order to build the most profitable portfolio. The portfolio optimization problem is naturally modeled as a mean-risk bi-criteria optimization problem where the mean rate of return of the portfolio must be maximized whereas a given risk measure must be minimized. Several mathematical programming models and techniques have been presented in the literature in order to efficiently solve the portfolio problem. A relatively recent promising line of research is to exploit clustering information of an assets network in order to develop new portfolio optimization paradigms. In this paper we endow the assets network with a metric based on correlation coefficients between assets’ returns, and show how classical location problems on networks can be used for clustering assets. In particular, by adding a new criterion to the portfolio selection problem based on an objective function of a classical location problem, we are able to measure the effect of clustering on the selected assets with respect to the non-selected ones. Most papers dealing with clustering and portfolio selection models solve these problems in two distinct steps: cluster first and then selection. The innovative contribution of this paper is that we propose a Mixed-Integer Linear Programming formulation for dealing with this problem in a unified phase. The effectiveness of our approach is validated reporting some computational experiments on some real financial datasets.},
  archive      = {J_COR},
  author       = {Justo Puerto and Moisés Rodríguez-Madrena and Andrea Scozzari},
  doi          = {10.1016/j.cor.2020.104891},
  journal      = {Computers &amp; Operations Research},
  pages        = {104891},
  shortjournal = {Comput. Oper. Res.},
  title        = {Clustering and portfolio selection problems: A unified framework},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An approximate dynamic programming approach for comparing
firing policies in a networked air defense environment. <em>COR</em>,
<em>117</em>, 104890. (<a
href="https://doi.org/10.1016/j.cor.2020.104890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An objective for effective air defense is to identify the firing policy for interceptor allocation to incoming missiles that minimizes the expected total damage to defended assets over a sequence of engagements. We formulate this dynamic weapon target assignment problem as a Markov decision process and utilize a simulation-based, approximate dynamic programming (ADP) approach to solve problem instances based on a representative scenario. Least squares policy evaluation and least squares temporal differences algorithms are developed to determine approximate solutions. A designed experiment investigates problem features such as conflict duration, attacker and defender weapon sophistication, and defended asset values. An empirical comparison of the ADP policies and two baseline policies (i.e., firing either one or two interceptors at each incoming theater ballistic missile (TBM)) yields several insights: the ADP policies outperform both baseline polices when conflict duration is short and attacker weapons are sophisticated; firing one interceptor at each TBM (regardless of inventory status) outperforms the tested ADP policies when conflict duration is long and attacker weapons are less sophisticated; and firing two interceptors at each TBM (regardless of inventory status), which is the United States Army’s currently implemented policy, is never the superlative policy for the test instances investigated.},
  archive      = {J_COR},
  author       = {Daniel S. Summers and Matthew J. Robbins and Brian J. Lunday},
  doi          = {10.1016/j.cor.2020.104890},
  journal      = {Computers &amp; Operations Research},
  pages        = {104890},
  shortjournal = {Comput. Oper. Res.},
  title        = {An approximate dynamic programming approach for comparing firing policies in a networked air defense environment},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Ant colony optimization algorithm for total weighted
completion time minimization on non-identical batch machines.
<em>COR</em>, <em>117</em>, 104889. (<a
href="https://doi.org/10.1016/j.cor.2020.104889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at the problem of scheduling a set of jobs with arbitrary sizes on parallel batch processing machines with arbitrary capacities. The optimization objective is to minimize the total weighted completion time of jobs. After describing the studied problem, we analyze its complexity and present a lower bound of the problem. A heuristic is provided to solve the problem firstly. Then, with the proposed first job selection strategy based on the weights of jobs, two algorithms based on the ant system and the max-min ant system, respectively, are designed to address the problem. Through extensive experiments, the performance of the proposed algorithms is compared with several state-of-the-art algorithms. The comparative results verify effectiveness and efficiency of the proposed algorithms.},
  archive      = {J_COR},
  author       = {Han Zhang and Zhao-hong Jia and Kai Li},
  doi          = {10.1016/j.cor.2020.104889},
  journal      = {Computers &amp; Operations Research},
  pages        = {104889},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ant colony optimization algorithm for total weighted completion time minimization on non-identical batch machines},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-stage stochastic integer programming approach for
locating electric vehicle charging stations. <em>COR</em>, <em>117</em>,
104888. (<a href="https://doi.org/10.1016/j.cor.2020.104888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles (EVs) represent one of the promising solutions to face environmental and energy concerns in transportation. Due to the limited range of EVs, deploying a charging infrastructure enabling EV drivers to carry out long distance trips is a key step to foster the widespread adoption of EVs. In this paper, we study the problem of locating EV fast charging stations so as to satisfy as much recharging demand as possible within the available investment budget. We focus on incorporating two important features into the optimization problem modeling: a multi-period decision making horizon and uncertainties on the recharging demand in terms of both the number of EVs to recharge and the set of long-distance trips to cover. Our objective is to determine the charging stations to be opened at each time period so as to maximize the expected value of the satisfied recharging demand over the entire planning horizon. To model the problem, we propose a multi-stage stochastic integer programming approach based on the use of a scenario tree to represent the uncertainties on the recharging demand. To solve the resulting large-size integer linear program , we develop two solution algorithms: an exact solution method based on a Benders decomposition and a heuristic approach based on a genetic algorithm. Our numerical results show that both methods perform well as compared to a stand-alone mathematical programming solver. Moreover, we provide the results of additional simulation experiments showing the practical benefit of the proposed multi-stage stochastic programming model as compared to a simpler multi-period deterministic model .},
  archive      = {J_COR},
  author       = {Ahmed Abdelmoumene Kadri and Romain Perrouault and Mouna Kchaou Boujelben and Céline Gicquel},
  doi          = {10.1016/j.cor.2020.104888},
  journal      = {Computers &amp; Operations Research},
  pages        = {104888},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-stage stochastic integer programming approach for locating electric vehicle charging stations},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A sorting based efficient heuristic for pooled repair shop
designs. <em>COR</em>, <em>117</em>, 104887. (<a
href="https://doi.org/10.1016/j.cor.2020.104887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the assignment problem of skills to servers (e.g., repairmen) in a multi-server repair shop of a spare parts supply system. This type of assignment problems tends to be hard in general, due to the lack of analytical queuing models with skill-based item-server assignments. In this paper, we propose a joint skill-server assignment and inventory optimization heuristic based on “pooled” repair shop designs. The heuristic decomposes the repair shop problem into sub-systems based on some attributes of repairable items. Each subsystem is responsible for its group of repairable items with full cross-training of the subsystem servers. The pooled designs reduce the complexity of the problem and enable the use of queue-theoretical approximations to optimize the inventory and repair shop capacity. The conducted numerical experiments show that the pooled skill-server assignments optimized by the proposed heuristic can reduce the total costs by 4\% when compared to the skill-server assignments obtained by Genetic Algorithm and Simulated Annealing based methods. Furthermore, in terms of cost and computation speed, the proposed heuristic shows better results than a Simulation-Optimization based skill-server assignment heuristic, which considers all possible assignments.},
  archive      = {J_COR},
  author       = {Hasan Hüseyin Turan and Andrei Sleptchenko and Shaligram Pokharel and Tarek Y ElMekkawy},
  doi          = {10.1016/j.cor.2020.104887},
  journal      = {Computers &amp; Operations Research},
  pages        = {104887},
  shortjournal = {Comput. Oper. Res.},
  title        = {A sorting based efficient heuristic for pooled repair shop designs},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Analysis of variable neighborhood descent as a local search
operator for total weighted tardiness problem on unrelated parallel
machines. <em>COR</em>, <em>117</em>, 104886. (<a
href="https://doi.org/10.1016/j.cor.2020.104886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable Neighborhood Descent (VND) is a metaheuristic commonly used as a local search operator of other metaheuristics. This work analyzes the hypothesis in which the substitution of the local search operator by VND may increase the performance of three metaheuristics (Iterated Greedy Search - IGS, Artificial Bee Colony - ABC, and Genetic Algorithm - GA), proposed in the literature for the solution of minimization problems of the total weighted tardiness in Unrelated Parallel Machines environments. For the validation of this hypothesis, six neighborhood structures are proposed, considering the characteristics of the problem for reducing the search space exploitation. The analysis is carried out considering three VND variations, two neighborhood structures exploitation order, as well as exploitation by the First Improvement and Best Improvement methods. The Taguchi Robust Parameter method is used to design a specific configuration of the VND for each metaheuristic . Additionally, some experiments to analyze the contribution of each neighborhood structure for the convergence of the metaheuristics are performed. The results show that three neighborhood structures, act together, and domain the convergence influence of the local search. The results also show that the use of VND as a local search operator in place of those original local search increases the performance of all metaheuristics evaluated. Moreover, the results achieved by the metaheuristics integrated to the VND in the most evaluated scenarios have become equivalent or better, on average, than state-of-the-art approaches.},
  archive      = {J_COR},
  author       = {Rodney Oliveira Marinho Diana and Sérgio Ricardo de Souza},
  doi          = {10.1016/j.cor.2020.104886},
  journal      = {Computers &amp; Operations Research},
  pages        = {104886},
  shortjournal = {Comput. Oper. Res.},
  title        = {Analysis of variable neighborhood descent as a local search operator for total weighted tardiness problem on unrelated parallel machines},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Mitigating partial-disruption risk: A joint facility
location and inventory model considering customers’ preferences and the
role of substitute products and backorder offers. <em>COR</em>,
<em>117</em>, 104884. (<a
href="https://doi.org/10.1016/j.cor.2020.104884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a joint facility location and inventory model from the viewpoint of partial-disruption risk—i.e., when manufacturing facilities meet the demands of third-party distribution centers with a portion of their capacity, free from any disruptions—while considering substitute products as a disruption risk mitigation strategy. We considered these third-party distribution centers as the customers of the manufacturing facilities. We used a multinomial logit model to rank-order the facilities according to customers’ preferences. Then, a non-linear integer programming model was developed which attempted to assign a sequence of facilities to each customer based on their preferences while at the same time, minimizing the total supply-chain cost. We also considered customers’ decisions for backorders while developing the model. Due to the NP-hard nature of the problem, we developed a particle swarm optimization-based metaheuristic algorithm to solve the model. The efficiency of the modified particle swarm optimization (MPSO) was illustrated through computational tests and systematic comparison with the exact method, a hybrid meta-heuristic algorithm including tabu search (TS) and variable neighborhood search (VNS) from the literature, and its modified form (Modified TS-VNS). A numerical example was used to show the applicability of the model. Finally, we gained useful insight into the role of substitute products and customers’ decisions for backorders through scenario-based analysis. We found that the total supply chain cost could increase in disruption scenarios when customers were more likely to refuse backorder offers. However, the cost-saving from producing a substitute for key products could be significant.},
  archive      = {J_COR},
  author       = {Apurba Kumar Saha and Ananna Paul and Abdullahil Azeem and Sanjoy Kumar Paul},
  doi          = {10.1016/j.cor.2020.104884},
  journal      = {Computers &amp; Operations Research},
  pages        = {104884},
  shortjournal = {Comput. Oper. Res.},
  title        = {Mitigating partial-disruption risk: A joint facility location and inventory model considering customers’ preferences and the role of substitute products and backorder offers},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Modeling interdependencies in infrastructure systems using
multi-layered network flows. <em>COR</em>, <em>117</em>, 104883. (<a
href="https://doi.org/10.1016/j.cor.2019.104883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of optimizing the operations of interdependent infrastructure systems in a resource-constrained environment. In this problem, decisions consist of determining the set of components that will be operational and how services from different infrastructures will be delivered to operational components. We propose an interdependent multi-layered network flow (IMN) model to solve this problem. In this model, interdependent infrastructures are represented by networks and movement of commodities or services by flows. We seek to maximize the reward obtained from operational components minus the cost of routing flows. We show that IMN is NP-hard in the strong sense even in the case of a single-layer network. We further propose families of valid inequalities for the integer programming formulation of IMN, which are then utilized to develop a solution approach for the problem. The solution approach is tested on synthesized data sets of interdependent infrastructure systems. Our computational results demonstrate that our solution approach can obtain high-quality solutions in less computational time when compared to the mixed integer programming (MIP) formulation solved with standard software for most of the instances. We also show the capability of IMN over the previous models in the literature on interdependent infrastructures’ operations.},
  archive      = {J_COR},
  author       = {Negin Enayaty Ahangar and Kelly M. Sullivan and Sarah G. Nurre},
  doi          = {10.1016/j.cor.2019.104883},
  journal      = {Computers &amp; Operations Research},
  pages        = {104883},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modeling interdependencies in infrastructure systems using multi-layered network flows},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Equidistant representations: Connecting coverage and
uniformity in discrete biobjective optimization. <em>COR</em>,
<em>117</em>, 104872. (<a
href="https://doi.org/10.1016/j.cor.2019.104872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nondominated frontier of a multiobjective optimization problem can be overwhelming to a decision maker , as it is often either very large or infinite in size. Instead, a discrete representation of this set in the form of a small sample of points is often preferred. In this paper we consider the Discrete Representation Problem (DRP), which is itself a triobjective optimization problem . The three objectives comprise three standard quality measures for discrete representations, namely coverage, uniformity and the cardinality of the set. We introduce the notion of complete equidistant representations , and prove that such a representation provides a nondominated solution to the DRP. In addition, we show through the help of complete equidistant representations that coverage and uniformity can be seen as dual problems given a fixed cardinality, and therefore that optimality gaps for coverage and uniformity can be obtained given any representation. Moreover, even though the definition of the coverage error requires the full nondominated set, we show how the coverage error for a given representation can be calculated by generating a much smaller set. Finally, we present a new method for finding discrete representations of a desired cardinality that outperforms existing methods w.r.t. coverage and uniformity on a set of mixed-integer programming benchmark instances.},
  archive      = {J_COR},
  author       = {Martin Philip Kidd and Richard Lusby and Jesper Larsen},
  doi          = {10.1016/j.cor.2019.104872},
  journal      = {Computers &amp; Operations Research},
  pages        = {104872},
  shortjournal = {Comput. Oper. Res.},
  title        = {Equidistant representations: Connecting coverage and uniformity in discrete biobjective optimization},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A similarity-based neighbourhood search for enhancing the
balance exploration–exploitation of differential evolution.
<em>COR</em>, <em>117</em>, 104871. (<a
href="https://doi.org/10.1016/j.cor.2019.104871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of search-based optimisation algorithms depends on appropriately balancing exploration and exploitation mechanisms during the course of the search. We introduce a mechanism that can be used with Differential Evolution ( de ) algorithms to adaptively manage the balance between the diversification and intensification phases, depending on current progress. The method— Similarity-based Neighbourhood Search ( sns )—uses information derived from measuring Euclidean distances among solutions in the decision space to adaptively influence the choice of neighbours to be used in creating a new solution. sns is integrated into explorative and exploitative variants of jade , one of the most frequently used adaptive de approaches. Furthermore, shade , which is another state-of-the-art adaptive de variant, is also considered to assess the performance of the novel sns . A thorough experimental evaluation is conducted using a well-known set of large-scale continuous problems, revealing that incorporating sns allows the performance of both explorative and exploitative variants of de to be significantly improved for a wide range of the test-cases considered. The method is also shown to outperform variants of de that are hybridised with a recently proposed global search procedure, designed to speed up the convergence of that algorithm.},
  archive      = {J_COR},
  author       = {Eduardo Segredo and Eduardo Lalla-Ruiz and Emma Hart and Stefan Voß},
  doi          = {10.1016/j.cor.2019.104871},
  journal      = {Computers &amp; Operations Research},
  pages        = {104871},
  shortjournal = {Comput. Oper. Res.},
  title        = {A similarity-based neighbourhood search for enhancing the balance exploration–exploitation of differential evolution},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new iterated greedy algorithm for no-idle permutation
flowshop scheduling with the total tardiness criterion. <em>COR</em>,
<em>117</em>, 104839. (<a
href="https://doi.org/10.1016/j.cor.2019.104839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the no-idle constraint, a machine has to process a job after finishing the previous one without any interruption. The start time of the first job on each machine must thus be delayed to meet this condition. In this paper, a new Iterated Greedy Algorithm (IGA) is presented for no-idle flowshop scheduling with the objective of minimizing the total tardiness. For the initialization phase, a variant of the NEH procedure is developed. Then, we propose a new variable local search based on an insert move with two different job selection mechanisms. A tardiness-guided job selection procedure, a job-dependent parameter and an insert-swap based method are further introduced in the destruction-construction phases. While most of the related studies have used a fixed probability for accepting new or non-improving solutions, we propose a time-dependent probability that allows our algorithm to focus on exploration in early iterations and exploitation in later iterations. Comprehensive computational experiments show that the proposed IGA is superior in terms of solution quality than state-of-the-art algorithms for the problem at hand. As a result, more than 50\% of the existing best solutions for the benchmark instances tested have been updated.},
  archive      = {J_COR},
  author       = {Vahid Riahi and Raymond Chiong and Yuli Zhang},
  doi          = {10.1016/j.cor.2019.104839},
  journal      = {Computers &amp; Operations Research},
  pages        = {104839},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new iterated greedy algorithm for no-idle permutation flowshop scheduling with the total tardiness criterion},
  volume       = {117},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Robust scheduling for target tracking using wireless sensor
networks. <em>COR</em>, <em>116</em>, 104873. (<a
href="https://doi.org/10.1016/j.cor.2019.104873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wireless sensor network (WSN) is a group of sensors deployed in an area, with all of them working on a battery and with direct communications inside the network. A fairly common situation, addressed in this work, is to monitor and record data with a WSN about vehicles (planes, terrestrial vehicles, boats, etc) passing by an area with damaged infrastructures. In such a context, an activation schedule for the sensors ensuring a continuous coverage of all the targets is required. Furthermore, the collected data, in order to be treated, have to be transmitted to a base station in the area, near the sensors. In this work, the future monitoring missions of the network are also taken into account, as well as the energy consumption of the current mission. We also consider that the spatial trajectories of the targets are known, whereas the speed of the targets along their trajectories are estimated, and subject to uncertainty. Hence, the main objective is to seek solutions that can withstand earliness and tardiness from the previsions. We propose a formulation of the problem with three different objectives and a solution method with experiments and results. The objectives are treated in a lexicographic order as follows (i) maximize the robustness schedule to cope with the advances and delaqui leys of the targets, (ii) maximize the minimum of monitoring time we can guarantee in priority areas, (iii) maximize the amount of energy left in the sensor batteries. We propose new upper bounds on the robustness measure , that are exploited by the solution approach whose complexity is shown to be pseudo-polynomial. The solution approach is based on a preprocessing step called discretisation , and the resolution of a series of linear programs .},
  archive      = {J_COR},
  author       = {Florian Delavernhe and Charly Lersteau and André Rossi and Marc Sevaux},
  doi          = {10.1016/j.cor.2019.104873},
  journal      = {Computers &amp; Operations Research},
  pages        = {104873},
  shortjournal = {Comput. Oper. Res.},
  title        = {Robust scheduling for target tracking using wireless sensor networks},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exact methods for the discrete multiple allocation (r|p)
hub-centroid problem. <em>COR</em>, <em>116</em>, 104870. (<a
href="https://doi.org/10.1016/j.cor.2019.104870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the ( r | p ) hub-centroid problem (( r | p ) HCP ), two noncooperative firms, leader and follower, locate hubs sequentially in order to maximize their own total flow being transported through system. The leader locates p hubs, knowing that the follower will react by locating r hubs. After location decisions, each flow is transported by one hub or a pair of hubs placed by either leader or follower according to the lowest cost criteria. The problem consists of optimizing the leader decision. For the discrete multiple allocation version of the ( r | p ) HCP , we prove that this version is ∑ 2 p ∑2p -hard, propose for the first time two mixed integer linear programming formulations with a polynomial number of variables and present exact branch-and-cut algorithms to solve the formulations. The algorithms are compared to the best exact one found in the literature, obtaining better results for almost all instances. Furthermore, we present the optimal solution for several open instances.},
  archive      = {J_COR},
  author       = {Antonio Camargo Andrade de Araújo and Marcos Costa Roboredo and Artur Alves Pessoa and Valdecy Pereira},
  doi          = {10.1016/j.cor.2019.104870},
  journal      = {Computers &amp; Operations Research},
  pages        = {104870},
  shortjournal = {Comput. Oper. Res.},
  title        = {Exact methods for the discrete multiple allocation (r|p) hub-centroid problem},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A survey on kriging-based infill algorithms for
multiobjective simulation optimization. <em>COR</em>, <em>116</em>,
104869. (<a href="https://doi.org/10.1016/j.cor.2019.104869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article surveys the most relevant kriging-based infill algorithms for multiobjective simulation optimization. These algorithms perform a sequential search of so-called infill points , used to update the kriging metamodel at each iteration. An infill criterion helps to balance local exploitation and global exploration during this search by using the information provided by the kriging metamodels. Most research has been done on algorithms for deterministic problem settings; only very recently, algorithms for noisy simulation outputs have been proposed. Yet, none of these algorithms so far incorporates an effective way to deal with heterogeneous noise, which remains a major challenge for future research.},
  archive      = {J_COR},
  author       = {Sebastian Rojas-Gonzalez and Inneke Van Nieuwenhuyse},
  doi          = {10.1016/j.cor.2019.104869},
  journal      = {Computers &amp; Operations Research},
  pages        = {104869},
  shortjournal = {Comput. Oper. Res.},
  title        = {A survey on kriging-based infill algorithms for multiobjective simulation optimization},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online scheduling of jobs with favorite machines.
<em>COR</em>, <em>116</em>, 104868. (<a
href="https://doi.org/10.1016/j.cor.2019.104868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long distance link may cause high data latency in cloud computing systems , and thus a computing task may be processed faster by nearby servers than distant servers. To address this class of job (task) scheduling problems, we propose the favorite machine model. Specifically, we are interested in the online version where jobs arrive one by one and must be allocated irrevocably upon each arrival without knowing the future jobs. The objective is to design efficient online algorithms for allocating jobs in order to minimize the makespan . Theoretical performance guarantees are presented for the Greedy algorithm and the Assign-U algorithm, where the latter is shown to be the best-possible online algorithm for this problem. Our theoretical results generalize the results for several classical problems, e.g. the unrelated machines and the identical machines. We also study a restriction of the model, called the symmetric favorite machine model. A 2.675-competitive algorithm is developed and proved to be the best-possible algorithm for the two machines case. Moreover, computational results show that the algorithms perform quite well for random instances, and reveal some insights for choosing algorithms for practical applications.},
  archive      = {J_COR},
  author       = {Cong Chen and Paolo Penna and Yinfeng Xu},
  doi          = {10.1016/j.cor.2019.104868},
  journal      = {Computers &amp; Operations Research},
  pages        = {104868},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online scheduling of jobs with favorite machines},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Local search for diversified top-k clique search problem.
<em>COR</em>, <em>116</em>, 104867. (<a
href="https://doi.org/10.1016/j.cor.2019.104867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the diversified top- k clique (DTKC) search problem is to find k maximal cliques that cover the maximum number of vertices in a given graph. This problem is equivalent to the well-known maximum clique problem (MaxClique) when k = 1 k=1 . This paper proves the NP-hardness of the DTKC search problem and presents a local search algorithm , named TOPKLS, based on two novel strategies for the DTKC search problem. The first strategy is called enhanced configuration checking (ECC) , which is a new variant of a recent effective strategy called configuration checking (CC), for reducing cycling in the local search and improving the diversity of the DTKC search problem. The second strategy is a heuristic to estimate the quality of each maximal clique. Experiments demonstrate that TOPKLS outperforms the existing algorithms on large sparse graphs from real-world applications.},
  archive      = {J_COR},
  author       = {Jun Wu and Chu-Min Li and Lu Jiang and Junping Zhou and Minghao Yin},
  doi          = {10.1016/j.cor.2019.104867},
  journal      = {Computers &amp; Operations Research},
  pages        = {104867},
  shortjournal = {Comput. Oper. Res.},
  title        = {Local search for diversified top-k clique search problem},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Column generation based heuristic for learning
classification trees. <em>COR</em>, <em>116</em>, 104866. (<a
href="https://doi.org/10.1016/j.cor.2019.104866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the use of Column Generation (CG) techniques in constructing univariate binary decision trees for classification tasks . We propose a novel Integer Linear Programming (ILP) formulation, based on root-to-leaf paths in decision trees . The model is solved via a Column Generation based heuristic. To speed up the heuristic, we use a restricted instance data by considering a subset of decision splits, sampled from the solutions of the well-known CART algorithm. Extensive numerical experiments show that our approach is competitive with the state-of-the-art ILP-based algorithms. In particular, the proposed approach is capable of handling big data sets with tens of thousands of data rows. Moreover, for large data sets, it finds solutions competitive to CART.},
  archive      = {J_COR},
  author       = {Murat Firat and Guillaume Crognier and Adriana F. Gabor and C.A.J. Hurkens and Yingqian Zhang},
  doi          = {10.1016/j.cor.2019.104866},
  journal      = {Computers &amp; Operations Research},
  pages        = {104866},
  shortjournal = {Comput. Oper. Res.},
  title        = {Column generation based heuristic for learning classification trees},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A multi-stage stochastic integer programming approach for a
multi-echelon lot-sizing problem with returns and lost sales.
<em>COR</em>, <em>116</em>, 104865. (<a
href="https://doi.org/10.1016/j.cor.2019.104865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider an uncapacitated multi-item multi-echelon lot-sizing problem within a remanufacturing system involving three production echelons: disassembly, refurbishing and reassembly. We seek to plan the production activities on this system over a multi-period horizon. We consider a stochastic environment, in which the input data of the optimization problem are subject to uncertainty. We propose a multi-stage stochastic integer programming approach relying on scenario trees to represent the uncertain information structure and develop a branch-and-cut algorithm in order to solve the resulting mixed-integer linear program to optimality . This algorithm relies on a new set of tree inequalities obtained by combining valid inequalities previously known for each individual scenario of the scenario tree. These inequalities are used within a cutting-plane generation procedure based on a heuristic resolution of the corresponding separation problem. Computational experiments carried out on randomly generated instances show that the proposed branch-and-cut algorithm performs well as compared to the use of a stand-alone mathematical solver. Finally, rolling horizon simulations are carried out to assess the practical performance of the multi-stage stochastic planning model with respect to a deterministic model and a two-stage stochastic planning model.},
  archive      = {J_COR},
  author       = {Franco Quezada and Céline Gicquel and Safia Kedad-Sidhoum and Dong Quan Vu},
  doi          = {10.1016/j.cor.2019.104865},
  journal      = {Computers &amp; Operations Research},
  pages        = {104865},
  shortjournal = {Comput. Oper. Res.},
  title        = {A multi-stage stochastic integer programming approach for a multi-echelon lot-sizing problem with returns and lost sales},
  volume       = {116},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Editorial. <em>COR</em>, <em>115</em>, 104885. (<a
href="https://doi.org/10.1016/j.cor.2020.104885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COR},
  author       = {Mohan Krishnamoorthy and Gaurav Singh and Andreas Ernst and Graham Kendall},
  doi          = {10.1016/j.cor.2020.104885},
  journal      = {Computers &amp; Operations Research},
  pages        = {104885},
  shortjournal = {Comput. Oper. Res.},
  title        = {Editorial},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The location routing problem using electric vehicles with
constrained distance. <em>COR</em>, <em>115</em>, 104864. (<a
href="https://doi.org/10.1016/j.cor.2019.104864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of Electric Vehicles (EVs) in modern fleets facilitates a shift towards greener road transportation practices. However, the driving ranges of EVs are limited by the duration of their batteries, which raises some operational challenges. This paper discusses the Location Routing Problem with a Constrained Distance (LRPCD), which is a natural extension of the Location Routing Problem when EVs are utilized. A fast multi-start heuristic and a metaheuristic are proposed to solve the LRPCD. The former combines biased-randomization techniques with the well-known Tillman’s heuristic for the Multi-Depot Vehicle Routing Problem. The latter incorporates the biased-randomized approach into the Variable Neighborhood Search (VNS) framework. A series of computational experiments show that the multi-start heuristic is able to generate good-quality solutions in just a few seconds, while the biased-rendomized VNS metaheuristic provides higher-quality solutions by employing more computational time.},
  archive      = {J_COR},
  author       = {Abdullah Almouhanna and Carlos L. Quintero-Araujo and Javier Panadero and Angel A. Juan and Banafsheh Khosravi and Djamila Ouelhadj},
  doi          = {10.1016/j.cor.2019.104864},
  journal      = {Computers &amp; Operations Research},
  pages        = {104864},
  shortjournal = {Comput. Oper. Res.},
  title        = {The location routing problem using electric vehicles with constrained distance},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A simheuristic approach for throughput maximization of
asynchronous buffered stochastic mixed-model assembly lines.
<em>COR</em>, <em>115</em>, 104863. (<a
href="https://doi.org/10.1016/j.cor.2019.104863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-model assembly lines are large scale production layouts that often operate under uncertainties such as stochastic product sequences. Balancing such lines can be particularly challenging as throughput estimation can be difficult to determine, especially when asynchronous pace and buffers are considered. Recent works have addressed problem variants with a given target throughput, but few authors consider a variant of the throughput maximization of mixed-model assembly line balancing problem. This paper addresses the balancing optimization problem for an assembly line with a given number of workstations and buffers between them. A make-to-order environment is considered, modeled as stochastic sequence of products with known demand rates. A novel specialized cycle time simulator (CTS) is introduced, as well as a simheuristic approach (PSH) that exploits CTS to assess the cycle time of an assembly line and provide good balancing solutions. The proposed simheuristic PSH is applied to a dataset with several buffer layouts, and its solutions are then compared to those of literature benchmarks. Performance comparisons show that PSH’s solutions outperform the benchmarks’ ones, with statistically significant differences. Furthermore, the solution quality difference was greater for instances with more buffers, highlighting PSH capacity to conveniently exploit buffers in assembly lines . Lastly, analyses on the average processing times of stations, obtained for each buffer layout, partially verifies and question established results of the “bowl phenomenon” on unpaced assembly lines.},
  archive      = {J_COR},
  author       = {Thiago Cantos Lopes and Adalberto Sato Michels and Ricardo Lüders and Leandro Magatão},
  doi          = {10.1016/j.cor.2019.104863},
  journal      = {Computers &amp; Operations Research},
  pages        = {104863},
  shortjournal = {Comput. Oper. Res.},
  title        = {A simheuristic approach for throughput maximization of asynchronous buffered stochastic mixed-model assembly lines},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Joint optimization of dynamic pricing and lot-sizing
decisions with nonlinear demands: Theoretical and computational
analysis. <em>COR</em>, <em>115</em>, 104862. (<a
href="https://doi.org/10.1016/j.cor.2019.104862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a capacitated lot-sizing problem with pricing decisions. The considered problem consists of planning the production of different products during several time periods with setup costs. Unlike the classical version of the capacitated lot sizing problem, the demand for the products is not fixed but price-sensitive in this problem. The demand function is assumed to be nonlinear. The decisions consist of establishing the best strategy for production and inventory, and the best price policy. We propose an improved mathematical formulation by extending some previous works using new lower and upper bounds to reduce the solution space. We also introduce new heuristic methods to provide near-optimal solutions. These methods are tested on several instances from previous studies. The obtained results illustrate the efficiency of these methods.},
  archive      = {J_COR},
  author       = {Paulin Couzon and Yassine Ouazene and Farouk Yalaoui},
  doi          = {10.1016/j.cor.2019.104862},
  journal      = {Computers &amp; Operations Research},
  pages        = {104862},
  shortjournal = {Comput. Oper. Res.},
  title        = {Joint optimization of dynamic pricing and lot-sizing decisions with nonlinear demands: Theoretical and computational analysis},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Block-insertion-based algorithms for the linear ordering
problem. <em>COR</em>, <em>115</em>, 104861. (<a
href="https://doi.org/10.1016/j.cor.2019.104861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The linear ordering problem (LOP) is an NP-hard combinatorial optimization problem with wide applications. As the problem is computationally intractable, the only practical alternative is to develop efficient heuristics to solve it. Here we present four new properties of block insertion for the LOP, and show that changing the node order in one sub-problem does not affect the objective values of the remaining sub-problems. Based on these properties, we then propose three local search schemes for solving the LOP. Our experimental results show that the block insert with the first strategy often outperforms other local search schemes within the same computational time. To further improve the performance of this local search scheme, we incorporate it into the iterated local search and genetic algorithm frameworks, and develop the block-insertion-based iterated local search (ILS b ) and memetic algorithm (MA b ), respectively. The computational results show that both the ILS b and MA b outperform the state-of-the-art meta-heuristics. Moreover, with appropriate parameter settings, the MA b frequently outperforms the ILS b . Finally, we design a parallel computing framework, which divides the LOP problem into independent sub-problems that are solved in parallel by exact methods. This parallel framework can further improve the solutions derived by MA b or other heuristics.},
  archive      = {J_COR},
  author       = {Yanjun Qian and Jun Lin and Dehong Li and Haihua Hu},
  doi          = {10.1016/j.cor.2019.104861},
  journal      = {Computers &amp; Operations Research},
  pages        = {104861},
  shortjournal = {Comput. Oper. Res.},
  title        = {Block-insertion-based algorithms for the linear ordering problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A genetic algorithm for the picture maze generation problem.
<em>COR</em>, <em>115</em>, 104860. (<a
href="https://doi.org/10.1016/j.cor.2019.104860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A picture maze is a maze puzzle that reveals a hidden picture when the solution path is filled. The picture maze generation problem (PMGP) consists in generating a picture maze whose solution path draws the shape most similar to a given raster image. The PMGP can be formulated as the longest path problem (LPP) on grid graphs, and we propose a genetic algorithm (GA) for this problem. In our formulation, we optimize the start and exit positions simultaneously as well as the solution path. To construct an effective GA, we employ edge assembly crossover (EAX), which is known as a very effective crossover operator for the traveling salesman problem (TSP). However, because of the difference between the two problems, we adapt EAX to the PMGP in a novel manner. The proposed GA can generate satisfactory picture mazes in 17 s for complicated raster images with sizes up to 55 × 105.},
  archive      = {J_COR},
  author       = {Yuichi Nagata and Akinori Imamiya and Norihiko Ono},
  doi          = {10.1016/j.cor.2019.104860},
  journal      = {Computers &amp; Operations Research},
  pages        = {104860},
  shortjournal = {Comput. Oper. Res.},
  title        = {A genetic algorithm for the picture maze generation problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the vehicle routing problem with multi-compartment
vehicles for city logistics. <em>COR</em>, <em>115</em>, 104859. (<a
href="https://doi.org/10.1016/j.cor.2019.104859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logistics companies are under increasing pressure to overcome operational challenges and sustain profitable growth while dealing with the newest requirements of their customers. One of the remedies designed to cope with a higher number of shipments is to use multi-compartment city vans to ensure all forms of integration with deliveries. In the area of city logistics, the most common type of delivery involves storing inventory in a central warehouse and to deliver customers’ orders with multi-compartment vehicles. The problem under study is denoted as the vehicle routing problem with multi-compartment vehicles which are to operate from a single depot to visit customers within the chosen time period by minimizing major operational costs. We propose an enhanced adaptive large neighborhood search algorithm for the investigated routing problem. The computational results highlight the efficiency of the proposed algorithm in terms of both solution quality and solution time and also provide useful insights for city logistics.},
  archive      = {J_COR},
  author       = {Reza Eshtehadi and Emrah Demir and Yuan Huang},
  doi          = {10.1016/j.cor.2019.104859},
  journal      = {Computers &amp; Operations Research},
  pages        = {104859},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the vehicle routing problem with multi-compartment vehicles for city logistics},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The vehicle routing problem with simultaneous pickup and
delivery and handling costs. <em>COR</em>, <em>115</em>, 104858. (<a
href="https://doi.org/10.1016/j.cor.2019.104858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce the vehicle routing problem with simultaneous pickup and delivery and handling costs (VRPSPD-H). In the VRPSPD-H, a fleet of vehicles operates from a single depot to service all customers, which have both a delivery and a pickup demand such that all delivery items originate from and all pickup items go to the depot. The items on the vehicles are organized as a single linear stack where only the last loaded item is accessible. Handling operations are required if the delivery items are not the last loaded ones. We implement a heuristic handling policy approximating the optimal decisions for the handling sub-problem, and we propose two bounds on the optimal policy , resulting in two new myopic policies. We show that one of the myopic policies outperforms the other one in all configurations, and that it is competitive with the heuristic handling policy if many routes are required. We propose an adaptive large neighborhood search (ALNS) metaheuristic to solve our problem, in which we embed the handling policies. Computational results indicate that our metaheuristic finds optimal solutions on instances of up to 15 customers. We also compare our ALNS metaheuristic against best solutions on benchmark instances of two special cases, the vehicle routing problem with simultaneous pickup and delivery (VRPSPD) and the traveling salesman problem with pickups, deliveries and handling costs (TSPPD-H), and on two related problems, the vehicle routing problem with divisible pickup and delivery (VRPDPD) and the vehicle routing problem with mixed pickup and delivery (VRPMPD). We find or improve 39 out of 54 best known solutions (BKS) for the VRPSPD, 36 out of 54 BKS for the VRPDPD, 15 out of 21 BKS for the VRPMPD, and 69 out of 80 BKS for the TSPPD-H. Finally, we introduce and analyze solutions for the variations of the VRPDPD and VRPMPD with handling costs – the VRPDPD-H and the VRPMPD-H, respectively.},
  archive      = {J_COR},
  author       = {Richard P. Hornstra and Allyson Silva and Kees Jan Roodbergen and Leandro C. Coelho},
  doi          = {10.1016/j.cor.2019.104858},
  journal      = {Computers &amp; Operations Research},
  pages        = {104858},
  shortjournal = {Comput. Oper. Res.},
  title        = {The vehicle routing problem with simultaneous pickup and delivery and handling costs},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A fast and effective heuristic for smoothing workloads on
assembly lines: Algorithm design and experimental analysis.
<em>COR</em>, <em>115</em>, 104857. (<a
href="https://doi.org/10.1016/j.cor.2019.104857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workload smoothing on assembly lines, which aims to evenly assign tasks to stations, supports workforce planning and resource optimization. In this paper, we study smoothing assembly lines and develop a problem-specific heuristic to efficiently solve large-sized instances. To build solutions, the algorithm uses a number of well-known priority rules for task assignment in conjunction with a probabilistic decision-making procedure for closing workstations. We conduct an experimental design for selecting the best performing priority rules and for tuning the probabilistic decision-making procedure. The efficiency of our algorithm is tested and demonstrated through an extensive experimental study.},
  archive      = {J_COR},
  author       = {Öncü Hazır and Maher A.N. Agi and Jérémy Guérin},
  doi          = {10.1016/j.cor.2019.104857},
  journal      = {Computers &amp; Operations Research},
  pages        = {104857},
  shortjournal = {Comput. Oper. Res.},
  title        = {A fast and effective heuristic for smoothing workloads on assembly lines: Algorithm design and experimental analysis},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Handling fairness issues in time-relaxed tournaments with
availability constraints. <em>COR</em>, <em>115</em>, 104856. (<a
href="https://doi.org/10.1016/j.cor.2019.104856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports timetables determine who will play against whom, where, and on which time slot. In contrast to time-constrained sports timetables, time-relaxed timetables utilize (many) more time slots than there are games per team. This offers time-relaxed timetables additional flexibility to take into account venue availability constraints, stating that a team can only play at home when its venue is available, and player availability constraints stating that a team can only play when its players are available. Despite their flexibility, time-relaxed timetables have the drawback that the rest period between teams’ consecutive games can vary considerably, and the difference in the number of games played at any point in the season can become large. Besides, it can be important to timetable home and away games alternately. In this paper, we first establish the computational complexity of time-relaxed timetabling with availability constraints. Naturally, when one also incorporates fairness objectives on top of availability, the problem becomes even more challenging. We present two heuristics that can handle these fairness objectives. First, we propose an adaptive large neighborhood method that repeatedly destroys and repairs a timetable. Second, we propose a memetic algorithm that makes use of local search to schedule or reschedule all home games of a team. For numerous artificial and real-life instances, these heuristics generate high-quality timetables using considerably less computational resources compared to integer programming models solved using a state-of-the-art solver.},
  archive      = {J_COR},
  author       = {David Van Bulck and Dries Goossens},
  doi          = {10.1016/j.cor.2019.104856},
  journal      = {Computers &amp; Operations Research},
  pages        = {104856},
  shortjournal = {Comput. Oper. Res.},
  title        = {Handling fairness issues in time-relaxed tournaments with availability constraints},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). New decomposition methods for home care scheduling with
predefined visits. <em>COR</em>, <em>115</em>, 104855. (<a
href="https://doi.org/10.1016/j.cor.2019.104855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continuous aging of the population and the desire of the elderly to stay in their own homes as long as possible has led to a considerable increase in the demand for home visits. In this context, home care agencies try to serve more patients while maintaining a high level of service. They must regularly decide which patients they can accept and how the patients will be scheduled (care provider, visit days, visit times). In this paper we aim to maximize the number of new patients accepted while ensuring a single provider-to-patient assignment and a consistency of the visits times for every patient through the week. To solve this problem, we propose an extension to an existing logic-based Benders decomposition . Moreover, we present a new pattern-based logic-based Benders decomposition and a matheuristic using a large neighborhood search. The experiments demonstrate the efficiency of the proposed approaches and show that the matheuristic can solve all the benchmark instances in less than 20 s.},
  archive      = {J_COR},
  author       = {Florian Grenouilleau and Nadia Lahrichi and Louis-Martin Rousseau},
  doi          = {10.1016/j.cor.2019.104855},
  journal      = {Computers &amp; Operations Research},
  pages        = {104855},
  shortjournal = {Comput. Oper. Res.},
  title        = {New decomposition methods for home care scheduling with predefined visits},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A hybrid reactive GRASP heuristic for the risk-averse
k-traveling repairman problem with profits. <em>COR</em>, <em>115</em>,
104854. (<a href="https://doi.org/10.1016/j.cor.2019.104854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the k -traveling repairman problem with profits and uncertain travel times, a vehicle routing problem aimed at visiting a subset of customers in order to collect a revenue, which is a decreasing function of the uncertain arrival times. The introduction of the arrival time in the objective function instead of the travel time, which is common in most vehicle routing problems, poses compelling computational challenges, emphasized by the incorporation of the stochasticity in travel times. For tackling the solution of the risk-averse k -traveling repairman problem with profits, in this paper is proposed a hybrid heuristic, where a reactive greedy randomized adaptive search procedure is used as a multi-start framework, equipped with an adaptive local search algorithm . The effectiveness of the solution approach is shown through an extensive experimental phase, performed on a set of instances, generated from three sets of benchmark instances containing up to 200 nodes.},
  archive      = {J_COR},
  author       = {M.E. Bruni and P. Beraldi and S. Khodaparasti},
  doi          = {10.1016/j.cor.2019.104854},
  journal      = {Computers &amp; Operations Research},
  pages        = {104854},
  shortjournal = {Comput. Oper. Res.},
  title        = {A hybrid reactive GRASP heuristic for the risk-averse k-traveling repairman problem with profits},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A toolbox for calculating and decomposing total factor
productivity indices. <em>COR</em>, <em>115</em>, 104853. (<a
href="https://doi.org/10.1016/j.cor.2019.104853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Total Factor Productivity Toolbox is a new set of functions to calculate the main Total Factor Productivity (TFP) indices and their decompositions, based on Shephard’s distance functions, and using Data Envelopment Analysis (DEA) programming techniques. The package includes code for the standard Malmquist, Moorsteen–Bjurek, price-weighted and share-weighted TFP indices, allowing for the choice of orientation (input or output), reference period (base, comparison, geometric mean), returns to scale (variable or constant), and specific decompositions (aggregate, or identifying scale effects, as well as input and output mix effects). Classic definitions of TFP corresponding to the Laspeyres, Paasche, Fisher, or Törnqvist formulas can also be calculated as particular cases. This paper describes the methodology and implementation of the productivity functions in MATLAB . We compare the results corresponding to the different definitions by studying productivity trends in the US agriculture at the individual state level.},
  archive      = {J_COR},
  author       = {Bert M. Balk and Javier Barbero and José L. Zofío},
  doi          = {10.1016/j.cor.2019.104853},
  journal      = {Computers &amp; Operations Research},
  pages        = {104853},
  shortjournal = {Comput. Oper. Res.},
  title        = {A toolbox for calculating and decomposing total factor productivity indices},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Branch-and-cut-and-price for the cardinality-constrained
multi-cycle problem in kidney exchange. <em>COR</em>, <em>115</em>,
104852. (<a href="https://doi.org/10.1016/j.cor.2019.104852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The establishment of kidney exchange programs has dramatically improved rates for kidney transplants by matching donors to compatible patients who would otherwise fail to receive a kidney for transplant. Rather than simply swapping kidneys between two patient-donor pairs, having multiple patient-donor pairs simultaneously donate kidneys in a cyclic manner enables more patients to receive a kidney for transplant. For practicality reasons, the cycles must be limited to short lengths. Finding these cycles can be accomplished by solving the Cardinality-constrained Multi-cycle Problem, which generalizes the Prize-collecting Assignment Problem with constraints that bound the length of the subtours. This paper presents a series of additions to existing works—new constraints, some polyhedral results, new separation algorithms and a new pricing algorithm—and integrates them in the first branch-and-cut-and-price model of the problem. The model is shown to empirically outperform the state-of-the-art by solving 149 of 160 standard benchmarks, compared to 115 by the position-indexed chain-edge formulation and 114 by the position-indexed edge formulation.},
  archive      = {J_COR},
  author       = {Edward Lam and Vicky Mak-Hau},
  doi          = {10.1016/j.cor.2019.104852},
  journal      = {Computers &amp; Operations Research},
  pages        = {104852},
  shortjournal = {Comput. Oper. Res.},
  title        = {Branch-and-cut-and-price for the cardinality-constrained multi-cycle problem in kidney exchange},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bottom-up packing approach for modeling the constrained
two-dimensional guillotine placement problem. <em>COR</em>,
<em>115</em>, 104851. (<a
href="https://doi.org/10.1016/j.cor.2019.104851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the Constrained Two-dimensional Guillotine Placement Problem (C2GPP). This problem considers a rectangular large object and a set of rectangular small item types of given sizes and values. The objective is to select and cut the most valuable subset of small items from the large object using orthogonal guillotine cuts and constrained patterns. To completely model the problem, we present pseudo-polynomial and compact integer non-linear formulations. Then, we obtain an equivalent Mixed Integer Linear Programming (MILP) formulation from each non-linear model. These novel formulations are related to a bottom-up packing approach of successive horizontal and vertical builds of the small items. Additionally, we develop a set of constraints for each model which allows us to strictly consider d -staged guillotine cutting patterns, for a given positive integer d . To evaluate the MILP models and compare their performance to the state-of-the-art formulation of the C2GPP, we run computational experiments using three sets of benchmark instances, two of them from the literature. The results show that the proposed models, based on a bottom-up packing approach, lead to optimal or near-optimal solutions in reasonable processing times, even for scenarios that are intractable for the benchmark model .},
  archive      = {J_COR},
  author       = {Mateus Martin and Reinaldo Morabito and Pedro Munari},
  doi          = {10.1016/j.cor.2019.104851},
  journal      = {Computers &amp; Operations Research},
  pages        = {104851},
  shortjournal = {Comput. Oper. Res.},
  title        = {A bottom-up packing approach for modeling the constrained two-dimensional guillotine placement problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-benders-cut approach for the fault tolerant
regenerator location problem. <em>COR</em>, <em>115</em>, 104847. (<a
href="https://doi.org/10.1016/j.cor.2019.104847">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fault tolerant regenerator location problem (FTRLP) in optical networks, where any single network link (optical fiber) might fail, and an optical signal can only travel a maximum distance (called the optical reach) before its quality deteriorates, needing regenerations by installing regenerators at network nodes. The FTRLP is to find a minimal number of nodes for regenerator deployment such that each pair of nodes can communicate with each other for each single-link fault (failure) scenario. To solve the FTRLP to optimality , we propose a branch-and-Benders-cut (BBC) approach. During the exploration of the branch-and-bound search tree, the algorithm adds combinatorial Benders cuts. Computational results are provided and demonstrate effectiveness of the BBC approach.},
  archive      = {J_COR},
  author       = {Xiangyong Li and Y.P. Aneja},
  doi          = {10.1016/j.cor.2019.104847},
  journal      = {Computers &amp; Operations Research},
  pages        = {104847},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-benders-cut approach for the fault tolerant regenerator location problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic-based benders decomposition algorithm for
contamination detection problem in water networks. <em>COR</em>,
<em>115</em>, 104840. (<a
href="https://doi.org/10.1016/j.cor.2019.104840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To prevent the serious hazards caused by the intrusion of contaminants into the water distribution network, equipping the network with monitoring sensors is necessary. In this regard, the identification criterion is an important and recently addressed issue indicating that the sensors should be located so that in the case of intrusion of contamination, not only at least one sensor responds, but also it is possible to identify the source of contamination intrusion, as well. This paper addresses the sensor location problem with the identification criterion assuming that a limited budget is available for the sensor placement, and the aim is to minimize the number of vulnerable nodes having the same alarm pattern. First, the problem is formulated as a bi-objective mixed-integer linear programming model, assuming that the objective functions are ordered based on a given prioritization. Then, by utilizing the underlying problem structure, an exact logic-based Benders decomposition algorithm is presented. Computational results over moderate and large-sized instances confirm the efficiency of the proposed algorithm.},
  archive      = {J_COR},
  author       = {F. Hooshmand and F. Amerehi and S.A. MirHassani},
  doi          = {10.1016/j.cor.2019.104840},
  journal      = {Computers &amp; Operations Research},
  pages        = {104840},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition algorithm for contamination detection problem in water networks},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A queue-based aggregation approach for performance
evaluation of a production system with an AMHS. <em>COR</em>,
<em>115</em>, 104838. (<a
href="https://doi.org/10.1016/j.cor.2019.104838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Production planning optimization remains a major challenge in almost all industries , particularly in high-tech manufacturing. A critical task to support such optimization is performance evaluation, wherein an accurate estimation of the cycle time as a function of the throughput rate plays a key role. This paper develops a novel aggregation model based on a queueing network approach, so-called queue-based aggregation (QAG) model, to estimate the cycle time of a job-shop production system that consists of several processing workstations, and in which products are transferred via an Automated Material Handling System (AMHS). The proposed model aggregates both production and automated material handling systems and provides an accurate and fast estimation of the overall cycle time. The performance and superiority of the proposed model is validated by comparing its results with those of a detailed simulation model. Numerous sensitivity analyses are performed to provide valuable managerial insights on both the production and automated material handling systems.},
  archive      = {J_COR},
  author       = {Mehrdad Mohammadi and Stéphane Dauzère-pérès and Claude Yugma and Maryam Karimi-Mamaghan},
  doi          = {10.1016/j.cor.2019.104838},
  journal      = {Computers &amp; Operations Research},
  pages        = {104838},
  shortjournal = {Comput. Oper. Res.},
  title        = {A queue-based aggregation approach for performance evaluation of a production system with an AMHS},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Foreword: COR special issue on computational operations
research for drone systems. <em>COR</em>, <em>115</em>, 104837. (<a
href="https://doi.org/10.1016/j.cor.2019.104837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COR},
  author       = {Chase Murray and Alice E. Smith},
  doi          = {10.1016/j.cor.2019.104837},
  journal      = {Computers &amp; Operations Research},
  pages        = {104837},
  shortjournal = {Comput. Oper. Res.},
  title        = {Foreword: COR special issue on computational operations research for drone systems},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On dealing with strategic and tactical decision levels in
forestry planning under uncertainty. <em>COR</em>, <em>115</em>, 104836.
(<a href="https://doi.org/10.1016/j.cor.2019.104836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new scheme for dealing with the uncertainty in the scenario trees is considered in the presence of strategic and tactical stochastic parameters for a dynamic mixed 0–1 optimization model in a forest harvesting network along a time horizon under uncertainty. The strategic level of the model presented in this work is included by a several years time horizon, where the uncertainty lies in the timber production. It is represented in a multistage stochastic scenario tree, such that each stage comprises one or several years. Each node in the strategic tree has associated a multi-period scenario graph, where each period in the stages is related to a summer /winter season. The nodes in the graph represent the tactical uncertainty, whose stochastic parameters are the timber price and demand. The strategic decisions aim to the optimal design of the logistic timber harvesting and distribution network at each first period in the stages. The tactical decisions aim to timber harvesting, stocking and distribution from the stands until the markets at the periods in the stages. The model has been validated by using data from a real-life problem.},
  archive      = {J_COR},
  author       = {Antonio Alonso-Ayuso and Laureano F. Escudero and Monique Guignard and Andres Weintraub},
  doi          = {10.1016/j.cor.2019.104836},
  journal      = {Computers &amp; Operations Research},
  pages        = {104836},
  shortjournal = {Comput. Oper. Res.},
  title        = {On dealing with strategic and tactical decision levels in forestry planning under uncertainty},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The time buffer approximated buffer allocation problem: A
row–column generation approach. <em>COR</em>, <em>115</em>, 104835. (<a
href="https://doi.org/10.1016/j.cor.2019.104835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main problems in production systems is the buffer sizing. Choosing the right buffer size, at each production stage, that allows to achieve some performance measure (usually throughput or waiting time) is known as Buffer Allocation Problem (BAP), and it has been widely studied in the literature. Due to its complexity, BAP is usually approached using decomposition methods , under very strict system assumptions, or using simulation-optimization techniques. In this paper, the approximated mathematical programming formulation of the BAP simulation-optimization based on the time buffer concept is used. Using this approximation , buffers are modeled as temporal lags ( time buffers ) and this allows to use Linear Programming (LP) instead of Mixed Integer Linear Programming (MILP) models. Although LP models are easier to solve than MILPs, the huge dimension and the complex solution space topology of the time buffer approximated BAP call for ad hoc solution algorithms. To this purpose, a row-column generation algorithm is proposed, which exploits the theoretical properties of the time buffer approximation to reduce the solution time. The proposed algorithm has been compared with a standard LP solver (ILOG CPLEX) and with a state-of-the-art MILP solver and it proved to be better than the LP solver in most of the cases, and more robust than the MILP solver with respect to computation time. Moreover, the LP model (for flow lines) is able to solve the BAP also for assembly/disassembly lines.},
  archive      = {J_COR},
  author       = {Arianna Alfieri and Andrea Matta and Erica Pastore},
  doi          = {10.1016/j.cor.2019.104835},
  journal      = {Computers &amp; Operations Research},
  pages        = {104835},
  shortjournal = {Comput. Oper. Res.},
  title        = {The time buffer approximated buffer allocation problem: A row–column generation approach},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A flexible job shop scheduling approach with operators for
coal export terminals – a mature approach. <em>COR</em>, <em>115</em>,
104834. (<a href="https://doi.org/10.1016/j.cor.2019.104834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an improved scheduling approach for optimising the activities of a coal export terminal (CET) and includes for the first time, new methodology for handling blending, concurrency, de-ballasting delays, dual reclaiming and through loading. The proposed methodology can be applied to bulk materials import and export terminals and other very complex scheduling scenarios whose activities require multiple resources to be present and operating. It is also adaptable to industries with similarly complex scheduling environments with concurrency requirements and pre-emption. This scheduling problem is highly intricate and is far more challenging than traditional problems. As such it has been necessary to develop an improved meta-heuristic algorithm, with additional resource assignment chromosome and improved perturbation operators for pre-emption handling and resource assignment. A comprehensive suite of test problems is solved to demonstrate the efficacy of our approach and the capability to solve scenarios with the aforementioned features.},
  archive      = {J_COR},
  author       = {Robert L. Burdett and Paul Corry and Colin Eustace and Simon Smith},
  doi          = {10.1016/j.cor.2019.104834},
  journal      = {Computers &amp; Operations Research},
  pages        = {104834},
  shortjournal = {Comput. Oper. Res.},
  title        = {A flexible job shop scheduling approach with operators for coal export terminals – a mature approach},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic optimization in mine planning scheduling.
<em>COR</em>, <em>115</em>, 104823. (<a
href="https://doi.org/10.1016/j.cor.2019.104823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mine planning scheduling of a mineral resource exploitation aims to maximize the profit of the mining project . Frequently, there have been in use technologies of planning that, although they allow to maximize the benefits of the exploitation, do suppositions unrealistic that do not value the risk and the uncertainty for an ideal process of mining planning. In this paper an approach is made that helps solve the classic mining planning problem, since uncertainties such as geological, technical and market are taken into account, in order to obtain a robust model that minimizes risk and maximize the profits or benefits of the mining project . The present paper proposes a model that tools use of metaheuristic and simulation tools contributing to the models found in the specialized literature to solve the problem of open pit mining planning. Due to the scopes of this investigation, there will analyze the problem of the mining planning in the stochastic mining optimization, about which a model will develop for the optimal planning of an open pit mining of a polymetallic deposit identifying the fundamental variables and his uncertainties, with the goal of maximizing the awaited profits and minimizing the risks associated with the process of mining planning. Finally, in order to improve the scope and results of this proposal presented in this paper, it is recommended to include other variables typical of current mining projects, such as environmental, ecological and social variables, which help to improve the methodological proposal developed in this paper.},
  archive      = {J_COR},
  author       = {Giovanni Franco Sepúlveda and Patricia Jaramillo Álvarez and John Branch Bedoya},
  doi          = {10.1016/j.cor.2019.104823},
  journal      = {Computers &amp; Operations Research},
  pages        = {104823},
  shortjournal = {Comput. Oper. Res.},
  title        = {Stochastic optimization in mine planning scheduling},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). QUEST – a new quadratic decision model for the
multi-satellite scheduling problem. <em>COR</em>, <em>115</em>, 104822.
(<a href="https://doi.org/10.1016/j.cor.2019.104822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Demand for earth observation satellite imagery is pervasive and increasing rapidly across multiple domains, highlighting the key problem to optimally schedule satellite image acquisition/collection, subject to ground and on-board constraints. Despite the variety of reported approaches to solving the NP-hard multi-satellite scheduling problem ( m- SatSP), serious limitations still prevail, largely overlooking problem structure exploitation and/or domain knowledge. Assuming a few constraints, problem modelling—or scope—is often confined to a simple trailing satellite constellation composition perspective and tends to conveniently oversimplify footprint coverage intricacies. As a result, adequate problem task decomposition properly reflecting complex kinematic behaviour for an ad hoc satellite constellation remains elusive. Known approaches also fail to provide valuable solution optimality gap estimations to objectively qualify best computed solution and/or to control run-time execution in solving hard problem instances. In this paper, a novel approach to solving the single objective static m- SatSP is proposed. It is based on network flow optimization using mathematical programming. Unlike previous methods, QUEST (QUadratically constrainEd program Solver Technology) relies on a sound alternative approximate objective function and, the exploitation of exact problem-solving techniques. Derived from domain knowledge and problem structure considerations, QUEST generalizes problem modelling to successfully handle virtual constellation, avoiding unsuitable utilization of traditional area coverage decomposition scheme. The proposed decision model concurrently captures coverage approximation, imaging success uncertainty and quality for a variety of tasks. It also includes new and optional constraints while embracing an acceptable upper bound on collection value. A QUEST variant alternatively relying on “delayed reward” to bridge promising search regions on move selection, further shows optimality gap reduction and provides additional speedup. Computational results prove QUEST to be cost-effective and to outperform some recent baseline methods derived from best-known m- SatSP procedures. It comparatively demonstrates measurable collection and run-time gains, and provides a tight upper bound on the optimal solution of hard problems.},
  archive      = {J_COR},
  author       = {J. Berger and N. Lo and M. Barkaoui},
  doi          = {10.1016/j.cor.2019.104822},
  journal      = {Computers &amp; Operations Research},
  pages        = {104822},
  shortjournal = {Comput. Oper. Res.},
  title        = {QUEST – a new quadratic decision model for the multi-satellite scheduling problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimum ramp design in open pit mines. <em>COR</em>,
<em>115</em>, 104739. (<a
href="https://doi.org/10.1016/j.cor.2019.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem studied in this paper is that of designing the optimal open pit haulage ramp that, for a given ramp width and a maximum ramp gradient, connects two points of the mine, minimising construction and operational costs. Because in-pit ramps require the removal of a considerable amount of non-valuable material (stripping), we discuss two different problems: high stripping (or in-pit) ramp design and low stripping (or ex-pit) road design. For the first situation, we present an integer programming model; in the second case, a shortest path approach is undertaken. In both cases, the models can be solved exactly, and include gradient and curvature constraints. The proposed formulations have been tested on real mine data, showing a significant reduction in cost compared to the previous mine design.},
  archive      = {J_COR},
  author       = {Juan L. Yarmuch and Marcus Brazil and Hyam Rubinstein and Doreen A. Thomas},
  doi          = {10.1016/j.cor.2019.06.013},
  journal      = {Computers &amp; Operations Research},
  pages        = {104739},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimum ramp design in open pit mines},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Feasibility and cost minimisation for a lithium extraction
problem. <em>COR</em>, <em>115</em>, 104724. (<a
href="https://doi.org/10.1016/j.cor.2019.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we address the problem of allocating extraction pumps to wells, when exploiting lithium rich brines, as part of the production of lithium salts. The problem of choosing the location of extraction wells is defined using a transportation network structure. Based on the transportation network, the lithium rich brines are pumped out from each well and then mixed into evaporation pools. The quality of the blend will be based on the chemical concentrations of the different brines, originating from different wells. The objective of the problem is then to determine a pumping plan such that the final products have predefined concentrations, and the process is operated in the cheapest possible way. The problem is modelled as a combinatorial optimisation problem and a potential solution to it is sought using a genetic algorithm. The evaluation function of the genetic algorithm needs a method to determine feasible minimum cost flows for the proposed pumping allocation, thus requiring the formulation of a blending model in a flow network for which a new iterative non-convex local optimisation algorithm is proposed. The model was implemented and tested to measure the algorithm’s efficiency.},
  archive      = {J_COR},
  author       = {P. Bosch and J.P. Contreras and J. Munizaga-Rosas},
  doi          = {10.1016/j.cor.2019.05.029},
  journal      = {Computers &amp; Operations Research},
  pages        = {104724},
  shortjournal = {Comput. Oper. Res.},
  title        = {Feasibility and cost minimisation for a lithium extraction problem},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Production planning and scheduling in mining scenarios under
IPCC mining systems. <em>COR</em>, <em>115</em>, 104714. (<a
href="https://doi.org/10.1016/j.cor.2019.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open pit mine production scheduling problem (OPMPSP) consists of scheduling material extraction in a mineral deposit over a horizon of several time periods such that the profit of the operation is maximized and a variety of operational constraints are satisfied. These constraints vary depending on the extraction system used by the mining company for extracting material. Two extraction systems are available in the mining industry – Truck and Shovel (T&amp;S) and In-pit Crusher Conveyor (IPCC). IPCC systems offer an alternative to conventional T&amp;S systems by completely replacing trucks with conveyors. This replacement introduces a number of additional sequencing constraints that are not required in traditional T&amp;S systems. These additional constraints add further complexity to an already complex large scale OPMPSP. While OPMPSP has been extensively studied and a number of optimization techniques have been successfully applied, it is very much unresolved when IPCC systems are used; in most cases, industry still relies on the judgement or best estimate of experienced personnel. In this paper, we develop a new integer programming model of OPMPSP-IPCC and present an algorithm to address practical sized instances. The performance of the developed algorithm is also evaluated.},
  archive      = {J_COR},
  author       = {Mehran Samavati and Daryl Essam and Micah Nehring and Ruhul Sarker},
  doi          = {10.1016/j.cor.2019.05.019},
  journal      = {Computers &amp; Operations Research},
  pages        = {104714},
  shortjournal = {Comput. Oper. Res.},
  title        = {Production planning and scheduling in mining scenarios under IPCC mining systems},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling of maintenance windows in a mining supply chain
rail network. <em>COR</em>, <em>115</em>, 104670. (<a
href="https://doi.org/10.1016/j.cor.2019.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rail infrastructure forms a critical part of the mining supply chain in Australia due to the high weight to volume ratio of the product and the long distances between the mines and the ports. Across Australia, rail infrastructure has been steadily expanding to account for the growth in export volumes and the movement of mining operations further inland, and so the efficient and effective management of this critical infrastructure is vitally important. Maintenance plays a crucial role in this management as it ensures that the infrastructure assets are in a condition that allows safe, reliable, and efficient transport. In this paper we consider the annual planning of maintenance for Australia’s largest coal rail network, the Central Queensland Coal Network (CQCN), that is owned, operated, and managed, by Aurizon Holdings Pty Ltd. The current planning approach at Aurizon uses the concept of a maintenance access window (MAW) which provides a train-free time window across geographically contiguous track locations that define a maintenance zone. These train-free time windows facilitate the scheduling of specific maintenance tasks at specific track locations within zones closer to day of operation and forms the basis for a planning framework. A MIP model is introduced which facilitates the planning of different maintenance resources across this network to schedule MAWs. The model takes into account maintenance requirement forecasts as well as the availability of resources. Candidate solutions are compared using a proxy for network throughput capacity . Due to the long computation times required to solve the MIP model at the annual planning horizon a matheuristic is developed and two variants are tested. On average 80\% less computational time is required to find a good solution (average gap of 5\%) using the matheuristic compared to solving the MIP model directly (average gap of 1.5\%). The MIP model and associated matheuristic provides a suitable framework for semi-automated maintenance planning and is being integrated into the current suite of decision support tools used by Aurizon.},
  archive      = {J_COR},
  author       = {Thomas Kalinowski and Jason Matthews and Hamish Waterer},
  doi          = {10.1016/j.cor.2019.03.016},
  journal      = {Computers &amp; Operations Research},
  pages        = {104670},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling of maintenance windows in a mining supply chain rail network},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A two-step approach to incorporate cut-off grade and
stockpiling in oil sands mine planning optimization framework.
<em>COR</em>, <em>115</em>, 104659. (<a
href="https://doi.org/10.1016/j.cor.2019.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In achieving maximum benefit in oil sands mining, the time and sequence of removing ore, dyke material and waste from the final pit limit is essential to the long-term production schedule. In-pit waste management strategy requires the simultaneous construction of dykes with the advancement of mining operations. This paper seeks to determine: (1) the time and sequence for removal of ore, dyke material and waste to maximize Net Present Value (NPV); (2) the quantity of dyke material required for dyke construction to minimize construction costs; and (3) the impacts of stockpiling and stockpile reclamation with limited time duration. An Integrated Cut-Off Grade Optimization (ICOGO) model was used to generate an optimum cut-off grade policy and a schedule for mining ore and waste, as well as overburden, interburden and tailings coarse sand dyke materials in long-term production planning. Subsequently, a Mixed Integer Linear Goal Programming (MILGP) model was developed to generate a detailed production schedule for removal of ore, waste and dyke materials from the final pit limit. The cut-off grade profile and schedule generated by the ICOGO model are used as guides to define the grade constraints and production goals required by the MILGP model. The developed models feature stockpiling with limited duration for long-term production scheduling. The models were applied to an oil sands case study to maximize the NPV of the operation. In comparison, whereas the ICOGO model solved the optimization problem faster, the MILGP model results provided detailed mining-cut extraction sequencing for practical mining.},
  archive      = {J_COR},
  author       = {Navid Seyed Hosseini and Eugene Ben-Awuah and Yashar Pourrahimian},
  doi          = {10.1016/j.cor.2019.03.005},
  journal      = {Computers &amp; Operations Research},
  pages        = {104659},
  shortjournal = {Comput. Oper. Res.},
  title        = {A two-step approach to incorporate cut-off grade and stockpiling in oil sands mine planning optimization framework},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Short-term planning optimization model for underground
mines. <em>COR</em>, <em>115</em>, 104642. (<a
href="https://doi.org/10.1016/j.cor.2019.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling activities in an underground mine is a very complex task. Precedence relations, the great number of resources and the large number of work sites are some of the reasons for this complexity. This paper presents an optimization model for short-term planning that takes into consideration all parts of the development and production as well as specific limitations on equipment and workers. A preemptive mixed integer program is used in order to produce optimal planning over a short-term time horizon. Multiple tests made with various data sets and scenarios are then presented, including a comparison to a non-preemptive model and a case study.},
  archive      = {J_COR},
  author       = {Louis-Pierre Campeau and Michel Gamache},
  doi          = {10.1016/j.cor.2019.02.005},
  journal      = {Computers &amp; Operations Research},
  pages        = {104642},
  shortjournal = {Comput. Oper. Res.},
  title        = {Short-term planning optimization model for underground mines},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Practical performance of an open pit mine scheduling model
considering blending and stockpiling. <em>COR</em>, <em>115</em>,
104638. (<a href="https://doi.org/10.1016/j.cor.2019.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open pit mine production scheduling (OPMPS) is a decision problem which seeks to maximize net present value (NPV) by determining the extraction time of each block of ore and/or waste in a deposit and the destination to which this block is sent, e.g., a processing plant or waste dump. Spatial precedence constraints are imposed, as are resource capacities. Stockpiles can be used to maintain low-grade ore for future processing, to store extracted material until processing capacity is available, and/or to blend material based on single or multiple block characteristics (i.e., metal grade and/or contaminant). We adapt an existing integer-linear program to an operational polymetallic (gold and copper) open pit mine, in which the stockpile is used to blend materials based on multiple block characteristics, and call it ( P ^ l a ) (P^la) . We observe that the linear programming relaxation of our objective function is unimodal for different grade combinations (metals and contaminants) in the stockpile, which allows us to search systematically for an optimal grade combination while exploiting the linear structure of our optimization model. We compare the schedule of ( P ^ l a ) (P^la) with that produced by ( P n s ) (Pns) which does not consider stockpiling, and with ( P ˜ l a ) , (P˜la), which controls only the metal content in the stockpile and ignores the contaminant level at the mill and in the stockpile. Our proposed solution technique provides schedules for large instances in a few seconds up to a few minutes with significantly different stockpiling and material flow strategies depending on the model. We show that our model improves the NPV of the project while satisfying operational constraints.},
  archive      = {J_COR},
  author       = {Mojtaba Rezakhah and Eduardo Moreno and Alexandra Newman},
  doi          = {10.1016/j.cor.2019.02.001},
  journal      = {Computers &amp; Operations Research},
  pages        = {104638},
  shortjournal = {Comput. Oper. Res.},
  title        = {Practical performance of an open pit mine scheduling model considering blending and stockpiling},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hyper-heuristic approaches for strategic mine planning under
uncertainty. <em>COR</em>, <em>115</em>, 104590. (<a
href="https://doi.org/10.1016/j.cor.2018.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A hyper-heuristic refers to a search method or a learning mechanism for selecting or generating heuristics to solve computational search problems . Operating at a level of abstraction above that of a metaheuristic , it can be seen as an algorithm that tries to find an appropriate solution method at a given decision point rather than a solution. This paper introduces a new hyper-heuristic that combines elements from reinforcement learning and tabu search. It is applied to solve two complex stochastic scheduling problems arising in mining, namely the stochastic open-pit mine production scheduling problem with one processing stream (SMPS) and one of its generalizations, SMPS with multiple processing streams and stockpiles (SMPS+). The performance of the new hyper-heuristic is assessed by comparing it to several solution methods from the literature: problem-specific algorithms tailored for the two problems addressed in the paper and general hyper-heuristics, which use only limited problem-specific information. The computational results indicate that not only is the proposed new hyper-heuristic approach superior to the other hyper-heuristics, but it also provides results that are comparable to or improve on the results obtained by the state-of-the-art problem-specific methods.},
  archive      = {J_COR},
  author       = {Amina Lamghari and Roussos Dimitrakopoulos},
  doi          = {10.1016/j.cor.2018.11.010},
  journal      = {Computers &amp; Operations Research},
  pages        = {104590},
  shortjournal = {Comput. Oper. Res.},
  title        = {Hyper-heuristic approaches for strategic mine planning under uncertainty},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Open pit mine planning with degradation due to stockpiling.
<em>COR</em>, <em>115</em>, 104589. (<a
href="https://doi.org/10.1016/j.cor.2018.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open pit mine production scheduling with stockpiling (OPMPS+S) problem decides when to extract each notional, three-dimensional block of ore and/or waste in a deposit. In addition, this problem determines whether to send each block to a processing plant, to a stockpile, or to a waste dump. The objective function maximizes net present value, subject to constraints such as precedence, and capacities for mining and processing. Because the material within the stockpile is exposed to the environment, time-dependent changes may occur in the material’s properties, which results in increased processing costs or, equivalently, a net loss of value. We extend a linear-integer mine-planning model that considers stockpiling to account for degradation within the stockpile(s). We compare results from this model on a data set from an operational mine to more commonly used, yet less detailed, models that provide lower and upper bounds on the net present value. We show that the material degradation within a stockpile has an impact on the value that a stockpile provides. Specifically, by considering 5\% and 10\% annual degradation for our instances, we observe that the value that a stockpile provides decreases by 37\% and 69\%, respectively, relative to the computed value of a stockpile without degradation.},
  archive      = {J_COR},
  author       = {Mojtaba Rezakhah and Alexandra Newman},
  doi          = {10.1016/j.cor.2018.11.009},
  journal      = {Computers &amp; Operations Research},
  pages        = {104589},
  shortjournal = {Comput. Oper. Res.},
  title        = {Open pit mine planning with degradation due to stockpiling},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Scheduling the construction of value and discount weighted
trees for maximum net present value. <em>COR</em>, <em>115</em>, 104578.
(<a href="https://doi.org/10.1016/j.cor.2018.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a binary rooted tree in which each edge has an associated value and an associated discount factor, the problem addressed here is to determine which nodes should be visited and in what order so as to maximise the net present value calculated from the values and discount factors of the traversed edges. A process for determining which nodes to exclude is identified, some key properties of the solution are established, and an algorithm for generating an optimal sequence of nodes is presented. A key concept is the priority of a sequence of nodes, which is a certain function of the values and discount factors that determines whether the order of adjacent nodes in the sequence should be swapped. The problem was motivated by the need to determine an optimal sequence in which the network of access tunnels in an underground mine should be developed and the resources extracted when there is a limit on the equipment available.},
  archive      = {J_COR},
  author       = {P.A. Grossman and M. Brazil and J.H. Rubinstein and D.A. Thomas},
  doi          = {10.1016/j.cor.2018.10.018},
  journal      = {Computers &amp; Operations Research},
  pages        = {104578},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling the construction of value and discount weighted trees for maximum net present value},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Development of a scenario-based robust model for the optimal
truck-shovel allocation in open-pit mining. <em>COR</em>, <em>115</em>,
104539. (<a href="https://doi.org/10.1016/j.cor.2018.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a scenario-based robust optimization (SBRO) approach to solve truck–shovel allocation (TSA) problem. To this end, we formulate the TSA problem in two phases by using the concepts of the SBRO approach, network analysis and the shortest path problem, and binary integer programming under uncertainties. We consider uncertainties in shovel output and crusher capacity from the first phase and number of available trucks from the second phase based on the SBRO approach. This TSA approach is applicable in all open-pit mines where trucks with different capacities are used, and different paths exist between loading and dumping points. We exemplify the applicability of the approach based on a copper mine data. We also compare the results of the SBRO approach with the current TSA of the studied mine. Then, we update the TSA formulation based on two new strategies of increasing shovel number and shovel capacity. Compared to the traditional strategy of the mine, the output of shovels increases to 6719, 10,000, and 12,500 tons/shift by the SBRO approach based on the strategies of the available equipment, increasing the number of shovels, and increasing the capacity of shovels, respectively. In addition, operational cost decreases to $1.1825, $0.8068, and $1.1238 per ton of ore based on the strategies, respectively.},
  archive      = {J_COR},
  author       = {E. Bakhtavar and H. Mahmoudi},
  doi          = {10.1016/j.cor.2018.08.003},
  journal      = {Computers &amp; Operations Research},
  pages        = {104539},
  shortjournal = {Comput. Oper. Res.},
  title        = {Development of a scenario-based robust model for the optimal truck-shovel allocation in open-pit mining},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Valuing portfolios of interdependent real options using
influence diagrams and simulation-and-regression: A multi-stage
stochastic integer programming approach. <em>COR</em>, <em>115</em>,
104505. (<a href="https://doi.org/10.1016/j.cor.2018.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although real options generally occur within portfolios, most valuation approaches based on either option pricing or decision analysis alone focus on single well-defined options. In this paper we present a new approach for modelling and approximating the value of portfolios of interdependent real options using both influence diagrams and simulation-and-regression. The key feature of this approach is that it translates the interdependencies between real options into a set of constraints and then directly models the dynamics of all underlying uncertainties using (Markovian) stochastic processes . These are then integrated in a portfolio optimisation problem which is formulated as a multi-stage stochastic integer program . Applying a simulation and parametric regression approach to approximate the value of this optimisation problem , we present a transparent valuation algorithm that explicitly takes into account vector-valued exercise decisions and the state variable’s multidimensional resource component. The approach is therefore applicable to a wide range of complex investment projects with both inherent interdependent flexibilities and many underlying uncertainties. The approach is illustrated by evaluating a complex natural resource investment that features both a large portfolio of interdependent real options and four stochastic factors. We analyse the way in which the approximated value of the portfolio and its individual options are affected by the initial copper price as well as by the degrees of production cost and copper price uncertainty.},
  archive      = {J_COR},
  author       = {Sebastian Maier and John W. Polak and David M. Gann},
  doi          = {10.1016/j.cor.2018.06.017},
  journal      = {Computers &amp; Operations Research},
  pages        = {104505},
  shortjournal = {Comput. Oper. Res.},
  title        = {Valuing portfolios of interdependent real options using influence diagrams and simulation-and-regression: A multi-stage stochastic integer programming approach},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A 3D approximate hybrid algorithm for stope boundary
optimization. <em>COR</em>, <em>115</em>, 104475. (<a
href="https://doi.org/10.1016/j.cor.2018.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining stope boundaries is one of the critical steps to be taken when an underground mining method is selected; because of their significant impact on the profitability of the mining project , the stope boundaries have to be optimum to achieve maximum profits. This paper introduces a new hybrid algorithm that is a combination of dynamic programming and greedy algorithm . Although this proposed algorithm may fail to provide a true optimum solution, it generates better solutions than existing algorithms do. The new proposed algorithm and three existing algorithms are used to find the optimal stope boundaries on a real case ore body. The results demonstrate that the proposed algorithm can improve the profit by 117.78\%, 16.86\% and 0.42\% compared to Floating Stope, Maximum Value Neighborhood (MVN), and Greedy algorithm solutions, respectively, on a real case study at a reasonable CPU time.},
  archive      = {J_COR},
  author       = {V. Nikbin and M. Ataee-pour and K. Shahriar and Y. Pourrahimian},
  doi          = {10.1016/j.cor.2018.05.012},
  journal      = {Computers &amp; Operations Research},
  pages        = {104475},
  shortjournal = {Comput. Oper. Res.},
  title        = {A 3D approximate hybrid algorithm for stope boundary optimization},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A new model for automated pushback selection. <em>COR</em>,
<em>115</em>, 104456. (<a
href="https://doi.org/10.1016/j.cor.2018.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of pushbacks is essential to long-term open pit mine scheduling because it partitions the pit space into individual units, controlling ore and waste production. In this paper, a new model is proposed for the pushback selection procedure, which consists of characterizing the potential pushbacks based on the comprehensive family of nested pits and selecting those ones that meet a set of criteria, for instance, bounded ore and waste. An advantage of this method is the possibility to automate the pushback selection methodology, applying well-defined criteria for the selection and reducing the time employed in the planning task.},
  archive      = {J_COR},
  author       = {Enrique Jélvez and Nelson Morales and Hooman Askari-Nasab},
  doi          = {10.1016/j.cor.2018.04.015},
  journal      = {Computers &amp; Operations Research},
  pages        = {104456},
  shortjournal = {Comput. Oper. Res.},
  title        = {A new model for automated pushback selection},
  volume       = {115},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved branch-cut-and-price algorithm for the
two-echelon capacitated vehicle routing problem. <em>COR</em>,
<em>114</em>, 104833. (<a
href="https://doi.org/10.1016/j.cor.2019.104833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, we propose a branch-cut-and-price algorithm for the two-echelon capacitated vehicle routing problem in which delivery of products from a depot to customers is performed using intermediate depots called satellites. Our algorithm incorporates significant improvements recently proposed in the literature for the standard capacitated vehicle routing problem such as bucket graph based labeling algorithm for the pricing problem, automatic stabilization, limited memory rank-1 cuts, and strong branching. In addition, we make some specific problem contributions. First, we introduce a new route based formulation for the problem which does not use variables to determine product flows in satellites. Second, we introduce a new branching strategy which significantly decreases the size of the branch-and-bound tree. Third, we introduce a new family of satellite supply inequalities , and we empirically show that it improves the quality of the dual bound at the root node of the branch-and-bound tree. Finally, extensive numerical experiments reveal that our algorithm can solve to optimality all literature instances with up to 200 customers and 10 satellites for the first time and thus double the size of instances which could be solved to optimality.},
  archive      = {J_COR},
  author       = {Guillaume Marques and Ruslan Sadykov and Jean-Christophe Deschamps and Rémy Dupas},
  doi          = {10.1016/j.cor.2019.104833},
  journal      = {Computers &amp; Operations Research},
  pages        = {104833},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved branch-cut-and-price algorithm for the two-echelon capacitated vehicle routing problem},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An iterative graph expansion approach for the scheduling and
routing of airplanes. <em>COR</em>, <em>114</em>, 104832. (<a
href="https://doi.org/10.1016/j.cor.2019.104832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tourism company that offers fly-in safaris is faced with the challenge to route and schedule its fleet of airplanes in an optimal way. Over the course of a given time horizon several groups of tourists have to be picked up at airports and flown to their destinations within a certain time-window. Furthermore, the number of available seats, the consumption of fuel, the maximal takeoff weight, and restrictions on the detour of the individual groups have to be taken into account. The task of optimally scheduling the airplanes and tour groups belongs to the class of vehicle routing problems with pickup and delivery and time-windows. A flow-over-flow formulation on the time expanded graph of the airports was used in the literature in order to model this problem as a mixed integer linear program . Most of the benchmark problems, however, could not be solved within a time limit of three hours, which was overcome by what they call the time-free approach (TFA). In the TFA they formulate the problem for a simplified (time-free) graph and use an incumbent callback to check for feasibility in the original graph. While this approach led to very good results for instances, where few time-free solutions were infeasible for the original problem, some instances remained unsolved. In order to overcome this problem, we derive two new exact formulations that include time as variables. Although these formulations by themselves are not always better than the approach from the literature, they allow for an effective construction of graphs which can be interpreted as intermediate graphs between the graph of airports and the expanded graph with vertices for each visit. Using similar relaxation techniques to the TFA and constructing these graphs based on solutions of the relaxations guarantees that only critical airports are expanded. A computational study was performed in order to compare the new formulations to the methods from the literature. Within a time limit of 3 hours, the new approach was able to find proven optimal solutions for all previously unsolved benchmark instances. Furthermore, the average computation time of all benchmark instances was reduced by 90 percent.},
  archive      = {J_COR},
  author       = {Fabian Gnegel and Armin Fügenschuh},
  doi          = {10.1016/j.cor.2019.104832},
  journal      = {Computers &amp; Operations Research},
  pages        = {104832},
  shortjournal = {Comput. Oper. Res.},
  title        = {An iterative graph expansion approach for the scheduling and routing of airplanes},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A bi-level model and solution methods for partial
interdiction problem on capacitated hierarchical facilities.
<em>COR</em>, <em>114</em>, 104831. (<a
href="https://doi.org/10.1016/j.cor.2019.104831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the importance of gaining high levels of customer satisfaction in today&#39;s competitive world, making appropriate decisions in the face of malicious attacks is valued highly by many organizations. In this paper, to predict and handle the destructive effects of an intentional attack on capacitated nested hierarchical facilities, a bi-level partial interdiction problem is proposed. In this problem, there is an interdictor who can attack facilities partially in different levels. Subsequently, the system defender could respond to the customers’ demand in two different ways, namely through the remaining system facilities and the outsourcing option. The goal of the defender is to minimize the satisfaction cost of all customers’ demand under the interdictor&#39;s attacking scenario. This problem can be modeled as a bi-level programming model in which an interdictor and the system defender play the role of the leader and the follower, respectively. Due to the inherent complexity of the bi-level programming models, we develop a heuristic approach, namely “FDS”, to obtain near optimal solutions within a reasonable running time. In each iteration of the FDS, an interdiction scenario is produced heuristically and, thereupon CPLEX solver is called to solve the lower level of the model. To evaluate the effectiveness of the proposed model, a comparison between the cost of customers’ demand satisfaction in both absence and presence of the bi-level model is drawn. Computational results show that for those instances in which the optimal solutions are available, the proposed model can, on average, achieve a saving of 7.94\%.},
  archive      = {J_COR},
  author       = {Asefe Forghani and Farzad Dehghanian and Majid Salari and Yousef Ghiami},
  doi          = {10.1016/j.cor.2019.104831},
  journal      = {Computers &amp; Operations Research},
  pages        = {104831},
  shortjournal = {Comput. Oper. Res.},
  title        = {A bi-level model and solution methods for partial interdiction problem on capacitated hierarchical facilities},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Tabu search for min-max edge crossing in graphs.
<em>COR</em>, <em>114</em>, 104830. (<a
href="https://doi.org/10.1016/j.cor.2019.104830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph drawing is a key issue in the field of data analysis, given the ever-growing amount of information available today that require the use of automatic tools to represent it. Graph Drawing Problems (GDP) are hard combinatorial problems whose applications have been widely relevant in fields such as social network analysis and project management. While classically in GDPs the main aesthetic concern is related to the minimization of the total sum of crossing in the graph (min-sum), in this paper we focus on a particular variant of the problem, the Min-Max GDP, consisting in the minimization of the maximum crossing among all egdes. Recently proposed in scientific literature, the Min-Max GDP is a challenging variant of the original min-sum GDP arising in the optimization of VLSI circuits and the design of interactive graph drawing tools. We propose a heuristic algorithm based on the tabu search methodology to obtain high-quality solutions. Extensive experimentation on an established benchmark set with both previous heuristics and optimal solutions shows that our method is able to obtain excellent solutions in short computation time.},
  archive      = {J_COR},
  author       = {Tommaso Pastore and Anna Martínez-Gavara and Antonio Napoletano and Paola Festa and Rafael Martí},
  doi          = {10.1016/j.cor.2019.104830},
  journal      = {Computers &amp; Operations Research},
  pages        = {104830},
  shortjournal = {Comput. Oper. Res.},
  title        = {Tabu search for min-max edge crossing in graphs},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dispatching fire trucks under stochastic driving times.
<em>COR</em>, <em>114</em>, 104829. (<a
href="https://doi.org/10.1016/j.cor.2019.104829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accommodate a swift response to fires and other incidents, fire departments have stations spread throughout their coverage area, and typically dispatch the closest fire truck(s) available whenever a new incident arises. However, it is not obvious that the policy of always dispatching the closest truck(s) minimizes the long-run fraction of late arrivals, since it may leave gaps in the coverage for future incidents. Although the research literature on dispatching of emergency vehicles is substantial, the setting with multiple trucks has received little attention. This is despite the fact that here careful dispatching is even more important, since the potential coverage gap is much larger compared to the single-truck case. Moreover, when dispatching multiple trucks, the uncertainty in the trucks’ driving time plays an important role, in particular due to possible correlation in driving times of the trucks if their routes overlap. In this paper we discuss optimal dispatching of fire trucks, based on a particular dispatching problem that arises at the Amsterdam Fire Department, where two fire trucks are sent to the same incident location for a quick response. We formulate the dispatching problem as a Markov Decision Process , and numerically obtain the optimal dispatching decisions using policy iteration . We show that the fraction of late arrivals can be significantly reduced by deviating from current practice of dispatching the closest available trucks, with a relative improvement of on average about 20\%, and over 50\% for certain instances. We also show that driving-time correlation has a non-negligible impact on decision making, and if ignored may lead to performance decrease of over 20\% in certain cases. As the optimal policy cannot be computed for problems of realistic size due to the computational complexity of the policy iteration algorithm, we propose a dispatching heuristic based on a queueing approximation for the state of the network. We show that the performance of this heuristic is close to the optimal policy , and requires significantly less computational effort.},
  archive      = {J_COR},
  author       = {D. Usanov and P.M. van de Ven and R.D. van der Mei},
  doi          = {10.1016/j.cor.2019.104829},
  journal      = {Computers &amp; Operations Research},
  pages        = {104829},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dispatching fire trucks under stochastic driving times},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Replenishment and denomination mix of automated teller
machines with dynamic forecast demands. <em>COR</em>, <em>114</em>,
104828. (<a href="https://doi.org/10.1016/j.cor.2019.104828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the inventory management of automated teller machines (ATMs) many activities affect the total costs, such as forecasting, replenishments and the denomination mix used. The denomination mix is the combination of bills used to fulfill a customer’s demand. We investigate whether allowing the denomination mix to vary over time based on the forecast withdrawals at an ATM reduces actual operating costs of an ATM. To verify this, we propose a time-varying denomination mix strategy, which is validated by benchmarking it against the case of a bank’s denomination mix strategy. The bank’s predetermined strategy typically consists of a least note strategy or a one-smallest strategy. In all strategies we simultaneously optimize denomination mixes and replenishment decisions. We define the problem and solution strategies as mixed integer programming formulations and solve them via a rolling horizon algorithm using different frequencies of denomination mix updates, rolling horizon lengths, numbers of ATMs, cost parameters, and forecast qualities. By implementing the time-varying denomination mix, we show that the operational costs of managing an ATM can be reduced by 21\% or €153.77 per ATM per month on average, which can represent over €10 million per year in the Netherlands only.},
  archive      = {J_COR},
  author       = {Lieke M. van der Heide and Leandro C. Coelho and Iris F.A. Vis and Roel G. van Anholt},
  doi          = {10.1016/j.cor.2019.104828},
  journal      = {Computers &amp; Operations Research},
  pages        = {104828},
  shortjournal = {Comput. Oper. Res.},
  title        = {Replenishment and denomination mix of automated teller machines with dynamic forecast demands},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Anytime algorithms for the longest common palindromic
subsequence problem. <em>COR</em>, <em>114</em>, 104827. (<a
href="https://doi.org/10.1016/j.cor.2019.104827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The longest common palindromic subsequence (LCPS) problem aims at finding a longest string that appears as a subsequence in each of a set of input strings and is a palindrome at the same time. The problem is a special variant of the well known longest common subsequence problem and has applications in particular in genomics and biology, where strings correspond to DNA or protein sequences and similarities among them shall be detected or quantified. We first present a more traditional A* search that makes use of an advanced upper bound calculation for partial solutions. This exact approach works well for instances with two input strings and, as shown in experiments, outperforms several other exact methods from the literature. However, the A* search also has natural limitations when a larger number of strings shall be considered due to the problem’s complexity. To effectively deal with this case in practice, anytime A* search variants are investigated, which are able to return a reasonable heuristic solution at almost any time and are expected to find better and better solutions until reaching a proven optimum when enough time given. In particular a novel approach is proposed in which Anytime Column Search (ACS) is interleaved with traditional A* node expansions . The ACS iterations are guided by a new heuristic function that approximates the expected length of an LCPS in subproblems usually much better than the available upper bound calculation. This A*+ACS hybrid is able to solve small to medium-sized LCPS instances to proven optimality while returning good heuristic solutions together with upper bounds for large instances. In rigorous experimental evaluations we compare A*+ACS to several other anytime A* search variants and observe its superiority.},
  archive      = {J_COR},
  author       = {Marko Djukanovic and Günther R. Raidl and Christian Blum},
  doi          = {10.1016/j.cor.2019.104827},
  journal      = {Computers &amp; Operations Research},
  pages        = {104827},
  shortjournal = {Comput. Oper. Res.},
  title        = {Anytime algorithms for the longest common palindromic subsequence problem},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An integer linear programming model for efficient scheduling
of UGV tasks in precision agriculture under human supervision.
<em>COR</em>, <em>114</em>, 104826. (<a
href="https://doi.org/10.1016/j.cor.2019.104826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In precision agriculture more and more robots are being used to perform tasks that may include some farming activities , such as pruning, inspection or spraying, assigned to the robot as a result of a previous analysis activity or autonomously identified by the machine itself. In this sensitive scenario, reporting difficult situations to a decision maker , e.g., a human operator or some sophisticated software tools that cannot be integrated with the robot, could be useful to perform the correct action that the machine has to execute. Unfortunately, this key aspect is still neglected in current literature that focuses, instead, on fully automated operations by robots. Moreover, it is necessary to consider that in rural areas it often happens that successful data communication can only be achieved in certain locations in the field. In this context, we aim to address all the previous shortcomings by formulating a more comprehensive optimization problem , which also models the necessity to report to a central location and get instructions on the task to be done before proceeding to perform each action. After presenting two alternative analytical formulations of the problem, i.e. an integer linear programming model (ILP) and a mixed integer linear programming model, we propose a branch and bound algorithm that is guaranteed to find the global minimum cost solution in terms of navigation time. Simulation results show that our proposed algorithm performs about 20 to 30 times faster with respect to commercial linear programming solvers using any of the two analytical models proposed. Moreover, we also propose further improvements to reduce computational time while maintaining solution optimality . Finally, some insight into the development of future heuristics is given by analyzing the speed of convergence towards the optimal solution.},
  archive      = {J_COR},
  author       = {Lohic Fotio Tiotsop and Antonio Servetti and Enrico Masala},
  doi          = {10.1016/j.cor.2019.104826},
  journal      = {Computers &amp; Operations Research},
  pages        = {104826},
  shortjournal = {Comput. Oper. Res.},
  title        = {An integer linear programming model for efficient scheduling of UGV tasks in precision agriculture under human supervision},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A branch-and-price algorithm for the temporal bin packing
problem. <em>COR</em>, <em>114</em>, 104825. (<a
href="https://doi.org/10.1016/j.cor.2019.104825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an extension of the classical Bin Packing Problem , where each item consumes the bin capacity during a given time window that depends on the item itself. The problem asks for finding the minimum number of bins to pack all the items while respecting the bin capacity at any time instant. A polynomial-size formulation, an exponential-size formulation, and a number of lower and upper bounds are studied. A branch-and-price algorithm for solving the exponential-size formulation is introduced. An overall algorithm combining the different methods is then proposed and tested through extensive computational experiments.},
  archive      = {J_COR},
  author       = {Mauro Dell’Amico and Fabio Furini and Manuel Iori},
  doi          = {10.1016/j.cor.2019.104825},
  journal      = {Computers &amp; Operations Research},
  pages        = {104825},
  shortjournal = {Comput. Oper. Res.},
  title        = {A branch-and-price algorithm for the temporal bin packing problem},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A filtered beam search method for the m-machine permutation
flowshop scheduling problem minimizing the earliness and tardiness
penalties and the waiting time of the jobs. <em>COR</em>, <em>114</em>,
104824. (<a href="https://doi.org/10.1016/j.cor.2019.104824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the minimization of the absolute deviation of job completion times from a common due date in a flowshop scheduling problem. Besides this main objective, the minimization of the waiting time of the jobs in the production environment, that can be seen as an intermediate inventory cost , is also considered. Initially, a mixed integer programming model for this problem is proposed and, due to its complexity, heuristic approaches are developed. A list-scheduling algorithm for the approached problem is introduced. Moreover, a filtered beam search method that explores specific characteristics of the considered environment is proposed. Numerical experiments show that the presented methods can be successfully applied to this problem.},
  archive      = {J_COR},
  author       = {E.G. Birgin and J.E. Ferreira and D.P. Ronconi},
  doi          = {10.1016/j.cor.2019.104824},
  journal      = {Computers &amp; Operations Research},
  pages        = {104824},
  shortjournal = {Comput. Oper. Res.},
  title        = {A filtered beam search method for the m-machine permutation flowshop scheduling problem minimizing the earliness and tardiness penalties and the waiting time of the jobs},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An improved particle swarm optimization algorithm to solve
hybrid flowshop scheduling problems with the effect of human factors – a
case study. <em>COR</em>, <em>114</em>, 104812. (<a
href="https://doi.org/10.1016/j.cor.2019.104812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the multi-stage hybrid flowshop scheduling problem with identical parallel machines at each stage by considering the effect of human factors. The various levels of labours and the effects of their learning and forgetting are studied. The minimization of the weighted sum of the makespan and total flow time is the objective function. Since the problem is NP-hard, an improved version of the particle swarm optimization (PSO) algorithm is presented to solve the problem. A dispatching rule and a constructive heuristic are incorporated to improve the initial solutions of the PSO algorithm. The variable neighbourhood search (VNS) algorithm is also hybridized with the PSO algorithm to attain the optimal solutions consuming less computational time. An industrial scheduling problem of an automobile manufacturing unit is discussed. Moreover, several instances of the random benchmark problem are used to validate the performance of the proposed algorithm. Computational experiments have been performed and the results prove the effectiveness of the proposed approach.},
  archive      = {J_COR},
  author       = {M.K. Marichelvam and M. Geetha and Ömür Tosun},
  doi          = {10.1016/j.cor.2019.104812},
  journal      = {Computers &amp; Operations Research},
  pages        = {104812},
  shortjournal = {Comput. Oper. Res.},
  title        = {An improved particle swarm optimization algorithm to solve hybrid flowshop scheduling problems with the effect of human factors – a case study},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A flexible reference point-based multi-objective
evolutionary algorithm: An application to the UAV route planning
problem. <em>COR</em>, <em>114</em>, 104811. (<a
href="https://doi.org/10.1016/j.cor.2019.104811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the multi-objective route planning problem of an unmanned air vehicle (UAV) moving in a continuous terrain. In this problem, the UAV starts from a base, visits all targets and returns to the base in a continuous terrain that is monitored by radars. We consider two objectives: minimizing total distance and minimizing radar detection threat. This problem has infinitely many Pareto-optimal points and generating all those points is not possible. We develop a general preference-based multi-objective evolutionary algorithm to converge to preferred solutions. Preferences of a decision maker (DM) are elicited through reference point(s) and the algorithm converges to regions of the Pareto-optimal frontier close to the reference points. The algorithm allows the DM to change his/her reference point(s) whenever he/she so wishes. We devise mechanisms to prevent the algorithm from producing dominated points at the final population. We also develop mechanisms specific to the UAV route planning problem and test the algorithm on several UAV routing problems as well as other well-known problem instances. We demonstrate that our algorithm converges to preferred regions on the Pareto-optimal frontier and adapts to changes in the reference points quickly.},
  archive      = {J_COR},
  author       = {Erdi Dasdemir and Murat Köksalan and Diclehan Tezcaner Öztürk},
  doi          = {10.1016/j.cor.2019.104811},
  journal      = {Computers &amp; Operations Research},
  pages        = {104811},
  shortjournal = {Comput. Oper. Res.},
  title        = {A flexible reference point-based multi-objective evolutionary algorithm: An application to the UAV route planning problem},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Express shipment service network design with complex routes.
<em>COR</em>, <em>114</em>, 104810. (<a
href="https://doi.org/10.1016/j.cor.2019.104810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Express Shipment Service Network Design (ESSND) problem consists in defining a network of flights that enables the overnight flow of express packages from their origins to their destinations at minimum cost. This problem is normally solved considering only one-leg, multi-leg and ferry routes. Assessing the value of more complex route types is an open question of academic and practical importance. In this article, we present a mixed integer programming model that includes five types of complex routes: two-hub, transload, direct, inter-hub and early routes. We assess their economic impact by performing many experiments built from an instance provided by FedEx Express Europe. Inter-hub and early routes have the best performance, with significant average savings (from 0.5\% to 3.5\%).},
  archive      = {J_COR},
  author       = {José Miguel Quesada Pérez and Jean-Sébastien Tancrez and Jean-Charles Lange},
  doi          = {10.1016/j.cor.2019.104810},
  journal      = {Computers &amp; Operations Research},
  pages        = {104810},
  shortjournal = {Comput. Oper. Res.},
  title        = {Express shipment service network design with complex routes},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A polling system with “join the shortest - serve the
longest” policy. <em>COR</em>, <em>114</em>, 104809. (<a
href="https://doi.org/10.1016/j.cor.2019.104809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a Markovian single-server non-symmetric two-queue polling system, operating simultaneously under a combination of two well-known queueing regimes: ( i ) ‘Join the Shortest Queue’ and ( ii ) ‘Serve the Longest Queue’. The system is defined as a two-dimensional continuous-time Markov chain, and analyzed via both probability generating functions approach and matrix geometric method. Although both queues are unbounded, by applying a non-conventional representation and without resorting to involved boundary-value problem analysis, we derive the joint steady-state probability distribution of the system’s states, and consequently calculate its performance measures and derive its stability condition. Numerical results are presented, as well as a comparison with a corresponding M / G /1 queue.},
  archive      = {J_COR},
  author       = {Efrat Perel and Nir Perel and Uri Yechiali},
  doi          = {10.1016/j.cor.2019.104809},
  journal      = {Computers &amp; Operations Research},
  pages        = {104809},
  shortjournal = {Comput. Oper. Res.},
  title        = {A polling system with ‘Join the shortest - serve the longest’ policy},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Generalized affine scaling algorithms for linear programming
problems. <em>COR</em>, <em>114</em>, 104807. (<a
href="https://doi.org/10.1016/j.cor.2019.104807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interior Point Methods are widely used to solve Linear Programming problems . In this work, we present two primal Affine Scaling algorithms to achieve faster convergence in solving Linear Programming problems . In the first algorithm, we integrate Nesterov’s restarting strategy in the primal Affine Scaling method with an extra parameter, which in turn generalizes the original primal Affine Scaling method. We provide the proof of convergence for the proposed generalized algorithm considering long step size. We also provide the proof of convergence for the primal and dual sequence without the degeneracy assumption. This convergence result generalizes the original convergence result for the Affine Scaling methods and it gives us hints about the existence of a new family of methods. Then, we introduce a second algorithm to accelerate the convergence rate of the generalized algorithm by integrating a non-linear series transformation technique. Our numerical results show that the proposed algorithms outperform the original primal Affine Scaling method.},
  archive      = {J_COR},
  author       = {Md Sarowar Morshed and Md. Noor-E-Alam},
  doi          = {10.1016/j.cor.2019.104807},
  journal      = {Computers &amp; Operations Research},
  pages        = {104807},
  shortjournal = {Comput. Oper. Res.},
  title        = {Generalized affine scaling algorithms for linear programming problems},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Memetic collaborative approaches for finding balanced
incomplete block designs. <em>COR</em>, <em>114</em>, 104804. (<a
href="https://doi.org/10.1016/j.cor.2019.104804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The balanced incomplete block design (BIBD) problem is a difficult combinatorial problem with a large number of symmetries, which add complexity to its resolution. In this paper, we propose a dual (integer) problem representation that serves as an alternative to the classical binary formulation of the problem. We attack this problem incrementally: firstly, we propose basic algorithms (i.e. local search techniques and genetic algorithms) intended to work separately on the two different search spaces (i.e. binary and integer); secondly, we propose two hybrid schemes: an integrative approach (i.e. a memetic algorithm) and a collaborative model in which the previous methods work in parallel, occasionally exchanging information. Three distinct two-dimensional structures are proposed as communication topology among the algorithms involved in the collaborative model, as well as a number of migration and acceptance criteria for sending and receiving data. An empirical analysis comparing a large number of instances of our schemes (with algorithms possibly working on different search spaces and with/without symmetry breaking methods) shows that some of these algorithms can be considered the state of the art of the metaheuristic methods applied to finding BIBDs. Moreover, our cooperative proposal is a general scheme from which distinct algorithmic variants can be instantiated to handle symmetrical optimisation problems . For this reason, we have also analysed its key parameters, thereby providing general guidelines for the design of efficient/robust cooperative algorithms devised from our proposal.},
  archive      = {J_COR},
  author       = {David Rodríguez Rueda and Carlos Cotta and Antonio J. Fernández-Leiva},
  doi          = {10.1016/j.cor.2019.104804},
  journal      = {Computers &amp; Operations Research},
  pages        = {104804},
  shortjournal = {Comput. Oper. Res.},
  title        = {Memetic collaborative approaches for finding balanced incomplete block designs},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On electricity market equilibria with storage: Modeling,
uniqueness, and a distributed ADMM. <em>COR</em>, <em>114</em>, 104783.
(<a href="https://doi.org/10.1016/j.cor.2019.104783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider spot-market trading of electricity including storage operators as additional agents besides producers and consumers. Storage devices allow for shifting produced electricity from one time period to a later one. Due to this, multiple market equilibria may occur even if classical uniqueness assumptions for the case without storage systems are satisfied. For models containing storage operators, we derive sufficient conditions that ensure uniqueness of generation and demand. We also prove uniqueness of the market equilibrium for the special case of a single storage operator. Nevertheless, in case of multiple storage operators, uniqueness fails to hold in general, which we show by illustrative examples. We conclude the theoretical discussion with a general ex-post condition for proving the uniqueness of a given solution. In contrast to classical settings without storage systems, the computation of market equilibria is much more challenging since storage operations couple all trading events over time. For this reason, we propose a tailored parallel and distributed alternating direction method of multipliers (ADMM) for efficiently computing spot-market equilibria over long time horizons. We first analyze the parallel performance of the method itself. Finally, we show that the parallel ADMM clearly outperforms solving the respective problems directly and that it is capable of solving instances with more than 42 million variables in less than 13 min.},
  archive      = {J_COR},
  author       = {Julia Grübel and Thomas Kleinert and Vanessa Krebs and Galina Orlinskaya and Lars Schewe and Martin Schmidt and Johannes Thürauf},
  doi          = {10.1016/j.cor.2019.104783},
  journal      = {Computers &amp; Operations Research},
  pages        = {104783},
  shortjournal = {Comput. Oper. Res.},
  title        = {On electricity market equilibria with storage: Modeling, uniqueness, and a distributed ADMM},
  volume       = {114},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solution techniques for the inter-modal pickup and delivery
problem in two regions. <em>COR</em>, <em>113</em>, 104808. (<a
href="https://doi.org/10.1016/j.cor.2019.104808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the routing problem faced by transportation carriers and postal services that transport small parcels in large quantities. By splitting the territory into regions, these service providers can adapt a three-part network structure and solve a pickup and delivery problem with long-hauls without direct shipments between regions. That is, bilateral cross-city and cross-country requests must be met while also fulfilling capacity and time window constraints. To address this challenge, this work limits the problem to two regions and thereby can identify the correlations and synchronization between different modes. The proposed solution approach decomposes the problem into two subproblems : a long-haul assignment that can be solved exactly, and a short-haul routing problem that must be solved heuristically. The result is an efficient matheuristic , whose quality is confirmed through a comparison with findings from previous literature; it is viable in terms of solution quality and computation time. Long-haul flexibility also influences short-haul routing cost, such that improvements of up to 22\% are possible merely by increasing long-haul flexibility but not long-haul cost. Finally, realistic instances are solved based on the inter-library loan system comparing the influence of selecting train or truck on the SH routing costs.},
  archive      = {J_COR},
  author       = {A.G. Dragomir and K.F. Doerner},
  doi          = {10.1016/j.cor.2019.104808},
  journal      = {Computers &amp; Operations Research},
  pages        = {104808},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solution techniques for the inter-modal pickup and delivery problem in two regions},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Crowd-shipping with time windows and transshipment nodes.
<em>COR</em>, <em>113</em>, 104806. (<a
href="https://doi.org/10.1016/j.cor.2019.104806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd-shipping is a delivery policy in which, in addition to standard vehicle routing practices, ordinary people accept to deviate from their route to deliver items to other people, for a small compensation. In this paper we consider a variant of the problem by taking into account the presence of intermediate depots in the service network . The occasional drivers can decide to serve some customers by picking up the parcels either from the central depot or from an intermediate one. The objective is to minimize the total cost, that is, the conventional vehicle cost, plus the occasional drivers’ compensation. We formulate the problem and present a variable neighborhood search heuristic. To analyze the benefit of the crowd-shipping transportation system with intermediate depots and to assess the performance of our heuristic, we consider small- and large-size instances generated from the Solomon benchmarks. A computational analysis is carried out with the aim of gaining insights into the behavior of both conventional vehicles and occasional drivers, and of analyzing the performance of our methodology in terms of effectiveness and efficiency. Our computational results show that the proposed heuristic is highly effective and can solve large-size instances within short computational times.},
  archive      = {J_COR},
  author       = {Giusy Macrina and Luigi Di Puglia Pugliese and Francesca Guerriero and Gilbert Laporte},
  doi          = {10.1016/j.cor.2019.104806},
  journal      = {Computers &amp; Operations Research},
  pages        = {104806},
  shortjournal = {Comput. Oper. Res.},
  title        = {Crowd-shipping with time windows and transshipment nodes},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Pickup and delivery problem with incompatibility
constraints. <em>COR</em>, <em>113</em>, 104805. (<a
href="https://doi.org/10.1016/j.cor.2019.104805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to present a new version of the One-to-One Pickup and Delivery Problem in which a single vehicle must comply with requests for transportation from specific collect points to specific delivery points. The problem we consider, besides looking for a minimum cost route, adds extra constraints that forbid some requests to be in the vehicle at the same time. We first begin to formally define the problem and show how it is related to the classic graph coloring problem . Then, we introduce a comparative analysis of the computational performance of three integer programming formulations. Some polyhedral results of the most promising formulation are presented in order to strengthen the LP relaxation for increasing the computational efficacy of the model. We implement separation algorithms, a primal heuristic for finding feasible solutions and a branching strategy. All these elements were considered to the development of a Branch and Cut algorithm which is tested on a comprehensive test bed of instances. The algorithm proves to be capable of overcoming state-of-the-art mixed-integer solvers, both in number of solved instances and computational time.},
  archive      = {J_COR},
  author       = {Pablo Factorovich and Isabel Méndez-Díaz and Paula Zabala},
  doi          = {10.1016/j.cor.2019.104805},
  journal      = {Computers &amp; Operations Research},
  pages        = {104805},
  shortjournal = {Comput. Oper. Res.},
  title        = {Pickup and delivery problem with incompatibility constraints},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A note on “workload smoothing in simple assembly line
balancing.” <em>COR</em>, <em>113</em>, 104803. (<a
href="https://doi.org/10.1016/j.cor.2019.104803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workload smoothing is a variant of the well-known simple assembly line balancing problem. Given the number of (work) stations and the cycle time, the objective is to minimize the sum of squared workloads. Recently, Azizoğlu and İmat [Computers &amp; Operations Research 89 (2018) 51–57] have proposed an exact branch-and-bound algorithm to solve this problem. However, we reveal that one of the lower bounding procedures used within their algorithm is incorrect. By means of an example, we demonstrate that the wrong bound can prevent their branch-and-bound algorithm from finding optimal solutions. We correct the bounding argument and also provide a tighter formulation.},
  archive      = {J_COR},
  author       = {Rico Walter},
  doi          = {10.1016/j.cor.2019.104803},
  journal      = {Computers &amp; Operations Research},
  pages        = {104803},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on “Workload smoothing in simple assembly line balancing”},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-visit drone routing problem. <em>COR</em>,
<em>113</em>, 104802. (<a
href="https://doi.org/10.1016/j.cor.2019.104802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-Multi-visit Drone Routing Problem (k-MVDRP) considers a tandem between a truck and k drones. (When k = 1 , k=1, the problem is called the Multi-Visit Drone Routing Problem .) Each drone is capable of launching from the truck with one or more packages to deliver to customers. Each drone may return to the truck to swap/recharge batteries, pick up a new set of packages, and launch again to customer locations. Unlike many papers in the current literature, the model not only allows for a drone to carry multiple heterogeneous packages but also allows the specification of a drone energy drain function that takes into account each package weight, and it decouples the set of launch locations from the set of customer locations. This paper proposes a flexible heuristic solution . Computational experiments and sensitivity analyses are also conducted using physical parameters for drones that are consistent with recent research.},
  archive      = {J_COR},
  author       = {Stefan Poikonen and Bruce Golden},
  doi          = {10.1016/j.cor.2019.104802},
  journal      = {Computers &amp; Operations Research},
  pages        = {104802},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-visit drone routing problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Waste collection inventory routing with non-stationary
stochastic demands. <em>COR</em>, <em>113</em>, 104798. (<a
href="https://doi.org/10.1016/j.cor.2019.104798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We solve a rich routing problem inspired from practice, in which a heterogeneous fixed fleet is used for collecting recyclable waste from large containers over a finite planning horizon. Each container is equipped with a sensor that communicates its level at the start of the day. Given a history of observations, a forecasting model is used to estimate the expected demands and a forecasting error representing the level of uncertainty. The problem falls under the framework of the stochastic inventory routing problem and our main contribution is the modeling of the dynamic probability-based cost of container overflows and route failures over the planning horizon. We cast the problem as a mixed integer non-linear program and, to solve it, we develop an adaptive large neighborhood search algorithm that integrates a purpose-designed forecasting model, tested and validated on real data. We demonstrate the strength of our modeling approach on a set of rich inventory routing instances derived from real data coming from the canton of Geneva, Switzerland. Our approach significantly outperforms alternative deterministic policies in its ability to limit the occurrence of container overflows for the same routing cost. Finally, we show the benefit of a rolling horizon solution and derive lower and upper bounds on its cost.},
  archive      = {J_COR},
  author       = {Iliya Markov and Michel Bierlaire and Jean-François Cordeau and Yousef Maknoon and Sacha Varone},
  doi          = {10.1016/j.cor.2019.104798},
  journal      = {Computers &amp; Operations Research},
  pages        = {104798},
  shortjournal = {Comput. Oper. Res.},
  title        = {Waste collection inventory routing with non-stationary stochastic demands},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An enhanced lower bound for the time-dependent travelling
salesman problem. <em>COR</em>, <em>113</em>, 104795. (<a
href="https://doi.org/10.1016/j.cor.2019.104795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph whose arc traversal times vary over time, the Time-Dependent Travelling Salesman Problem amounts to find a Hamiltonian tour of least total duration. In this paper we exploit a new degree of freedom in the Cordeau et al. (2014) speed decomposition. This approach results in a parameterized family of lower bounds. The parameters are chosen by fitting the traffic data. The first model is nonlinear and difficult to solve. Hence, we devise a linearization which gives rise to a compact Mixed Integer Linear Programming model. Then, we develop an optimality condition which allows to further reduce the size of the model. Computational results show that, when embedded into a branch-and-bound procedure, this lower bounding mechanism allows to solve to optimality a larger number of instances than state-of-the-art algorithms.},
  archive      = {J_COR},
  author       = {Tommaso Adamo and Gianpaolo Ghiani and Emanuela Guerriero},
  doi          = {10.1016/j.cor.2019.104795},
  journal      = {Computers &amp; Operations Research},
  pages        = {104795},
  shortjournal = {Comput. Oper. Res.},
  title        = {An enhanced lower bound for the time-dependent travelling salesman problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Solving the general employee scheduling problem.
<em>COR</em>, <em>113</em>, 104794. (<a
href="https://doi.org/10.1016/j.cor.2019.104794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many professions the demand for work requires employees to work in different shifts to cover varying requirements including areas like health care, protection services, transportation, manufacturing or call centers. However, there are many constraints that need to be satisfied in order to create feasible schedules. The demands can be specified in various ways, different legal requirements need to be respected and employee satisfaction has to be taken into account. Therefore, automated solutions are mandatory to stay competitive. However, even then it is often hard to provide good solutions in reasonable time as many of the problems are NP-hard. While not each problem will require the whole set of available restrictions, it is cumbersome to develop a new specification format and corresponding solver for each problem. Often these can not be well applied to similar problems differing in some requirements. On the other hand it is a challenging task to provide a general formulation and solution methods that can solve large integrated problems, as even several sub-problems on their own are known to be NP-hard. Therefore a new framework is proposed for the general employee scheduling problem that allows the implementation of various heuristic algorithms and their application to a wide range of problems. This is realized by proposing a unified handling of constraints and the possibility to implement various moves that can be reused across different algorithms. Further, a new search method is developed and implemented in the framework. In order to show the applicability to a wide range of problems, we take different problems from literature that cover different types of demand and constraints, translate their instances to our formulation and apply our solver to those instances as well as our own instances with good results. For one problem class our framework could obtain better solutions for several benchmark instances.},
  archive      = {J_COR},
  author       = {Lucas Kletzander and Nysret Musliu},
  doi          = {10.1016/j.cor.2019.104794},
  journal      = {Computers &amp; Operations Research},
  pages        = {104794},
  shortjournal = {Comput. Oper. Res.},
  title        = {Solving the general employee scheduling problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A genetic algorithm for scheduling open shops with
sequence-dependent setup times. <em>COR</em>, <em>113</em>, 104793. (<a
href="https://doi.org/10.1016/j.cor.2019.104793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the open shop scheduling problem with sequence-dependent setup times, there is no established order for the processing of the jobs, which leads to a large number of possible solutions for the scheduling problem. Furthermore, there is a setup time between two consecutive operations, which depends on the job previously processed. In this work we propose a hybrid genetic algorithm for the OSSP with sequence-dependent setup times and total completion time minimization as objective function. Our proposal uses two novel constructive heuristics which are combined for the generation of the initial population. We carry out an extensive computational experience using problem instances taken from the related literature to evaluate the performance of the proposed algorithms as compared to existing heuristics for the problem. The quality of the solutions and the CPU time required are used as performance criteria. Among them, the genetic algorithm with direct decoding presents a smaller value for the average relative percentage deviation in comparison with the electromagnetic algorithm proposed by Naderi et al. (2011). The computational results prove the excellent performance of the proposed metaheuristic for the tested instances, resulting in the most efficient algorithm so-far for the problem under consideration.},
  archive      = {J_COR},
  author       = {Levi R. Abreu and Jesus O. Cunha and Bruno A. Prata and Jose M. Framinan},
  doi          = {10.1016/j.cor.2019.104793},
  journal      = {Computers &amp; Operations Research},
  pages        = {104793},
  shortjournal = {Comput. Oper. Res.},
  title        = {A genetic algorithm for scheduling open shops with sequence-dependent setup times},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strong bounds for resource constrained project scheduling:
Preprocessing and cutting planes. <em>COR</em>, <em>113</em>, 104782.
(<a href="https://doi.org/10.1016/j.cor.2019.104782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resource Constrained Project Scheduling Problems (RCPSPs) without preemption are well-known N P NP -hard combinatorial optimization problems . A feasible RCPSP solution consists of a time-ordered schedule of jobs with corresponding execution modes, respecting precedence and resources constraints. In this paper, we propose a cutting plane algorithm to separate five different cut families, as well as a new preprocessing routine to strengthen resource-related constraints. New lifted versions of the well-known precedence and cover inequalities are employed. At each iteration, a dense conflict graph is built considering feasibility and optimality conditions to separate cliques , odd-holes and strengthened Chvátal-Gomory cuts. The proposed strategies considerably improve the linear relaxation bounds, allowing a state-of-the-art mixed-integer linear programming solver to find provably optimal solutions for 754 previously open instances of different variants of the RCPSPs, which was not possible using the original linear programming formulations.},
  archive      = {J_COR},
  author       = {Janniele A.S. Araujo and Haroldo G. Santos and Bernard Gendron and Sanjay Dominik Jena and Samuel S. Brito and Danilo S. Souza},
  doi          = {10.1016/j.cor.2019.104782},
  journal      = {Computers &amp; Operations Research},
  pages        = {104782},
  shortjournal = {Comput. Oper. Res.},
  title        = {Strong bounds for resource constrained project scheduling: Preprocessing and cutting planes},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning assisted heuristic tree search for the
container pre-marshalling problem. <em>COR</em>, <em>113</em>, 104781.
(<a href="https://doi.org/10.1016/j.cor.2019.104781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The container pre-marshalling problem (CPMP) is concerned with the re-ordering of containers in container terminals during off-peak times so that containers can be quickly retrieved when the port is busy. The problem has received significant attention in the literature and is addressed by a large number of exact and heuristic methods . Existing methods for the CPMP heavily rely on problem-specific components (e.g., proven lower bounds) that need to be developed by domain experts with knowledge of optimization techniques and a deep understanding of the problem at hand. With the goal to automate the costly and time-intensive design of heuristics for the CPMP, we propose a new method called Deep Learning Heuristic Tree Search (DLTS). It uses deep neural networks to learn solution strategies and lower bounds customized to the CPMP solely through analyzing existing (near-) optimal solutions to CPMP instances. The networks are then integrated into a tree search procedure to decide which branch to choose next and to prune the search tree. DLTS produces the highest quality heuristic solutions to the CPMP to date with gaps to optimality below 2\% on real-world sized instances.},
  archive      = {J_COR},
  author       = {André Hottung and Shunji Tanaka and Kevin Tierney},
  doi          = {10.1016/j.cor.2019.104781},
  journal      = {Computers &amp; Operations Research},
  pages        = {104781},
  shortjournal = {Comput. Oper. Res.},
  title        = {Deep learning assisted heuristic tree search for the container pre-marshalling problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multi-facility green weber problem. <em>COR</em>,
<em>113</em>, 104780. (<a
href="https://doi.org/10.1016/j.cor.2019.104780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Locating facilities to satisfy the demands of customers is a strategic decision for a distribution system. In this article, we study the multi-facility green Weber problem (MF-GWP), an extension of the classical multi-facility Weber problem, that considers environmental concerns in a distribution system in the context of a planar facility location problem. In the MF-GWP, the vehicles are sent directly from the facilities to the assigned customers to satisfy their demands. Each customer has a deadline and the vehicles serving the customer must arrive at the location of the customer no later than the deadline. The MF-GWP determines the locations of p facilities on the plane, p &gt; 1, allocations of customers to the facilities, and the speeds of the distribution vehicles so as to minimize the total amount of CO 2 emission in the distribution system. We formulate this problem as a mixed integer second order cone programming (MISOCP) problem. This formulation turns out to be weak and therefore only small size instances can be solved to optimality within four hours. For larger size instances, a local search heuristic is proposed and some well-known heuristics developed for the multi-facility Weber problem, namely “location-allocation”, “transfer follow-up”, and “decomposition” are adapted for the MF-GWP. We use second order cone programming (SOCP) and the proposed MISOCP formulation as subproblems within the heuristics. We provide our computational experiments to compare the proposed solution methods in terms of solution quality and time. The results show that within a fixed computational time, even though the location-allocation heuristic is able to make more replications, the improvement heuristics considered, i.e., transfer or transfer followed by decomposition, usually find better solutions while using less number of replications. We also investigate how the total amount of CO 2 emitted by distribution vehicles changes with respect to the number of facilities located. We argue that in several real life applications from different sectors including aviation and robotics, MF-GWP and its extensions or modifications can be used to reduce the CO 2 emission or energy consumption. As an illustrative example, we show the applicability of the MF-GWP within an assembly line system, where the stations are fed by dedicated rail-guided vehicles.},
  archive      = {J_COR},
  author       = {Arsham Atashi Khoei and Haldun Süral and Mustafa Kemal Tural},
  doi          = {10.1016/j.cor.2019.104780},
  journal      = {Computers &amp; Operations Research},
  pages        = {104780},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-facility green weber problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Dynamic dispatching and preventive maintenance for parallel
machines with dispatching-dependent deterioration. <em>COR</em>,
<em>113</em>, 104779. (<a
href="https://doi.org/10.1016/j.cor.2019.104779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A dynamic decision model that coordinates dispatching and preventive maintenance decisions for failure-prone parallel machines in make-to-order (MTO) production environments is developed in this research. The primary objective is to minimize the weighted long-run average waiting costs of MTO systems. Two common but seldom studied stochastic factors, namely, the dispatching-dependent deterioration of machines and machine-health-dependent production rates, are explicitly modeled in the proposed dynamic dispatching and preventive maintenance (DDPM) model. Although the DDPM model is developed using Markov decision processes, it is equally effective in non-Markovian production environments. The performance of the DDPM model is validated in Markovian and non-Markovian production environments. Compared with several methods from the literature, simulation results show an improvement of at least 45.2\% in average job waiting times and a minimum reduction of 48.9\% in average machine downtimes. The comparison results between the optimal dynamic dispatching policies with and without coordinated preventive maintenance show that performance improvement can be mostly attributed to the coordination between preventive maintenance and dispatching decisions.},
  archive      = {J_COR},
  author       = {Cheng-Hung Wu and Yi-Chun Yao and Stéphane Dauzère-Pérès and Cheng-Juei Yu},
  doi          = {10.1016/j.cor.2019.104779},
  journal      = {Computers &amp; Operations Research},
  pages        = {104779},
  shortjournal = {Comput. Oper. Res.},
  title        = {Dynamic dispatching and preventive maintenance for parallel machines with dispatching-dependent deterioration},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Online fractional hierarchical scheduling on uniformly
related machines. <em>COR</em>, <em>113</em>, 104778. (<a
href="https://doi.org/10.1016/j.cor.2019.104778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the online fractional hierarchical scheduling problem on uniformly related machines. In the problem, the jobs and machines have several different hierarchies and a job can be processed on a machine if and only if its hierarchy is not below the hierarchy of the machine, furthermore, the jobs can be arbitrarily split between the machines. The objective is to determine the assignment scheme of the jobs so as to minimize the makespan. We present several sophisticated lower bounds and an online algorithm framework for the problem. Our bounds dominate all known bounds, and the algorithm is optimal for the problem with no more than four hierarchies. Computational tests show that our algorithm has the potential to work for all cases.},
  archive      = {J_COR},
  author       = {Zhaohui Liu and Jiyuan Zhan},
  doi          = {10.1016/j.cor.2019.104778},
  journal      = {Computers &amp; Operations Research},
  pages        = {104778},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online fractional hierarchical scheduling on uniformly related machines},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Logic-based benders decomposition for scheduling a batching
machine. <em>COR</em>, <em>113</em>, 104777. (<a
href="https://doi.org/10.1016/j.cor.2019.104777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of scheduling a set of jobs on a single batching machine to minimize the maximum lateness, where jobs may be subject to precedence constraints and incompatibilities. Single batching machine scheduling has many applications, but this study is particularly motivated by single crane scheduling in an automated storage and retrieval system (AS/RS): given a set of transport requests, which requests should be processed together in the same dual command cycle, and in what order should the cycles be processed? Since storage and retrieval requests may refer to the same physical item, precedence constraints must be observed. Moreover, the crane may not be capable of handling multiple storage or retrieval requests in the same cycle, hence the need to account for incompatibilities. We present a novel exact algorithm based on branch &amp; Benders cut, which is shown to solve even large instances with more than 100 jobs to optimality in many cases. For the special case without precedence constraints and incompatibilities, it improves on several best-known upper bounds from the literature.},
  archive      = {J_COR},
  author       = {Simon Emde and Lukas Polten and Michel Gendreau},
  doi          = {10.1016/j.cor.2019.104777},
  journal      = {Computers &amp; Operations Research},
  pages        = {104777},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition for scheduling a batching machine},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal charging facility location and capacity for electric
vehicles considering route choice and charging time equilibrium.
<em>COR</em>, <em>113</em>, 104776. (<a
href="https://doi.org/10.1016/j.cor.2019.104776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the optimal design of location and capacity of charging facilities for electric vehicles (EVs) is investigated. A bi-level mathematical model is proposed to derive optimal design considering the equilibrium of route choice and waiting time for charging. The objective is to minimize the joint cost of facility constructions and EV drivers’ travel and waiting time over the network. The upper-level model allocates the facilities and their capacity, while the lower-level model characterizes equilibrium behavior of drivers’ route and charging facility choices. In particular, we model drivers at each charging facility as the M(t)/M/n queue and approximate the average queuing time and probability of waiting time as functions of facility capacity and demand arrival rate . The bi-level model is then converted into a single-level model, and the solution algorithm is proposed for iteratively solving the relaxed problems. Comprehensive experiments are conducted on three networks to evaluate algorithm performances, assess solution robustness and understand the scalability of the solution approach on large networks.},
  archive      = {J_COR},
  author       = {Rui Chen and Xinwu Qian and Lixin Miao and Satish V. Ukkusuri},
  doi          = {10.1016/j.cor.2019.104776},
  journal      = {Computers &amp; Operations Research},
  pages        = {104776},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal charging facility location and capacity for electric vehicles considering route choice and charging time equilibrium},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Closed-form formulas for evaluating r-flip moves to the
unconstrained binary quadratic programming problem. <em>COR</em>,
<em>113</em>, 104774. (<a
href="https://doi.org/10.1016/j.cor.2019.104774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Unconstrained Binary Quadratic Programming problem ( UBQP ) belongs to the NP-hard class and has become a framework for modeling a variety of combinatorial optimization problems . The methods most commonly used to solve instances of the UBQP explore the concept of neighborhood of a solution. Given a binary vector x ∈ {0, 1} n , solution to a UBQP instance, a neighborhood of x can be defined by flip moves. Flip moves consist on selecting one or more elements (positions) of x and “flip” their values to their complementary values (i.e., from 1 to 0 or from 0 to 1). Normally, those methods compute a large number of flip moves, and so the whole process to solve an instance can be quite time consuming. In order to reduce this time, some works have proposed ways to efficiently evaluate one or two flip moves, and also extensions to higher order moves. In this paper we propose two closed-form formulas for evaluating quickly any order of flip moves. To test our theoretical findings, we executed an extensive set of computational experiments over well-known instances for the problem. Against common belief, our results show that it is possible to compute high order flip moves very fast.},
  archive      = {J_COR},
  author       = {Eduardo A.J. Anacleto and Cláudio N. Meneses and Santiago V. Ravelo},
  doi          = {10.1016/j.cor.2019.104774},
  journal      = {Computers &amp; Operations Research},
  pages        = {104774},
  shortjournal = {Comput. Oper. Res.},
  title        = {Closed-form formulas for evaluating r-flip moves to the unconstrained binary quadratic programming problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal charging and repositioning of electric vehicles in a
free-floating carsharing system. <em>COR</em>, <em>113</em>, 104771. (<a
href="https://doi.org/10.1016/j.cor.2019.104771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carsharing has received increased attention from the Operations Research community in recent years. Currently, many systems are adopting electric vehicles that require charging when battery levels fall below a given level. To do this, staff is often used to move cars to charging stations. Repositioning cars, rather than simply moving them to the closest charging station, might provide a better distribution of cars and in turn generate increased revenue and customer service while only marginally increase the operational costs. We present a mathematical model for the problem of charging and repositioning a fleet of shared electric cars. The model considers the assignment of cars to charging stations and the routing of staff and service vehicles. The complexity of the resulting mixed integer program makes it impossible to solve real world instances using a commercial solver. Therefore, we propose a new Hybrid Genetic Search with Adaptive Diversity Control algorithm. Tests based on data from a real life carsharing organization demonstrate that the proposed method can handle real size instances and that combining repositioning and charging operations can give significant benefits.},
  archive      = {J_COR},
  author       = {Carl Axel Folkestad and Nora Hansen and Kjetil Fagerholt and Henrik Andersson and Giovanni Pantuso},
  doi          = {10.1016/j.cor.2019.104771},
  journal      = {Computers &amp; Operations Research},
  pages        = {104771},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimal charging and repositioning of electric vehicles in a free-floating carsharing system},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improved flow-based formulations for the skiving stock
problem. <em>COR</em>, <em>113</em>, 104770. (<a
href="https://doi.org/10.1016/j.cor.2019.104770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thanks to the rapidly advancing development of (commercial) MILP software and hardware components, pseudo-polynomial formulations have been established as a powerful tool for solving cutting and packing problems in recent years. In this paper, we focus on the one-dimensional skiving stock problem (SSP), where a given inventory of small items has to be recomposed to obtain a maximum number of larger objects, each satisfying a minimum threshold length. In the literature, different modeling approaches for the SSP have been proposed, and the standard flow-based formulation has turned out to lead to the best trade-off between efficiency and solution time. However, especially for instances of practically meaningful sizes, the resulting models involve very large numbers of variables and constraints, so that appropriate reduction techniques are required to decrease the numerical efforts. For that reason, this paper introduces two improved flow-based formulations for the skiving stock problem that are able to cope with much larger problem sizes. By means of extensive experiments, these new models are shown to possess significantly fewer variables as well as an average better computational performance compared to the standard arcflow formulation.},
  archive      = {J_COR},
  author       = {J. Martinovic and M. Delorme and M. Iori and G. Scheithauer and N. Strasdat},
  doi          = {10.1016/j.cor.2019.104770},
  journal      = {Computers &amp; Operations Research},
  pages        = {104770},
  shortjournal = {Comput. Oper. Res.},
  title        = {Improved flow-based formulations for the skiving stock problem},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Benders decomposition for the inventory vehicle routing
problem with perishable products and environmental costs. <em>COR</em>,
<em>113</em>, 104751. (<a
href="https://doi.org/10.1016/j.cor.2019.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of inventory routing in the context of perishable products and find near-optimal replenishment scheduling and vehicle routes when the objective is to maximize the supplier’s profit and minimize the costs due to fuel consumption, inventory holding, and greenhouse gas emissions. Greenhouse gas emissions are calculated as a function of fuel consumed, and fuel consumption levels are accurately calculated as a function of vehicle speed, load and traveled distance. To solve the problem efficiently, we develop an exact method based on Benders decomposition to find high-quality solutions in reasonable time. To enhance the convergence rate of the Benders decomposition algorithm, we present several acceleration strategies, such as addition of valid inequalities to the master problem and warm-up start. The warm-up start acceleration strategy itself is a meta-heuristic based on the greedy random adaptive search procedure (GRASP) and mathematical programming formulations. We present computational results which illustrate the superior performance of the proposed solution methodology in solving large-scale instances with 60 customers and 6 planning periods with 4 vehicles using Benders decomposition. Additionally, we show that utilizing a more comprehensive model to calculate the fuel cost results in fuel savings of 2 to 11\% on the tested instances compared to traditional models that assume that the fuel cost is solely a function of the distance traveled during delivery.},
  archive      = {J_COR},
  author       = {Faisal Alkaabneh and Ali Diabat and Huaizhu Oliver Gao},
  doi          = {10.1016/j.cor.2019.07.009},
  journal      = {Computers &amp; Operations Research},
  pages        = {104751},
  shortjournal = {Comput. Oper. Res.},
  title        = {Benders decomposition for the inventory vehicle routing problem with perishable products and environmental costs},
  volume       = {113},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
