<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ICAE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="icae---29">ICAE - 29</h2>
<ul>
<li><details>
<summary>
(2020). Real-time facial expression recognition using smoothed deep
neural network ensemble. <em>ICAE</em>, <em>28</em>(1), 97–111. (<a
href="https://doi.org/10.3233/ICA-200643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial emotion recognition (FER) has been extensively researched over the past two decades due to its direct impact in the computer vision and affective robotics fields. However, the available datasets to train these models include often miss-labelled data due to the labellers bias that drives the model to learn incorrect features. In this paper, a facial emotion recognition system is proposed, addressing automatic face detection and facial expression recognition separately, the latter is performed by a set of only four deep convolutional neural network respect to an ensembling approach, while a label smoothing technique is applied to deal with the miss-labelled training data. The proposed system takes only 13.48 ms using a dedicated graphics processing unit (GPU) and 141.97 ms using a CPU to recognize facial emotions and reaches the current state-of-the-art performances regarding the challenging databases, FER2013, SFEW 2.0, and ExpW, giving recognition accuracies of 72.72%, 51.97%, and 71.82% respectively.},
  archive      = {J_ICAE},
  author       = {Benamara, Nadir Kamel and Val-Calvo, Mikel and Álvarez-Sánchez, Jose Ramón and Díaz-Morcillo, Alejandro and Ferrández-Vicente, Jose Manuel and Fernández-Jover, Eduardo and Stambouli, Tarik Boudghene},
  doi          = {10.3233/ICA-200643},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {97-111},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Real-time facial expression recognition using smoothed deep neural network ensemble},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Improving multi-class boosting-based object detection.
<em>ICAE</em>, <em>28</em>(1), 81–96. (<a
href="https://doi.org/10.3233/ICA-200636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years we have witnessed significant progress in the performance of object detection in images. This advance stems from the use of rich discriminative features produced by deep models and the adoption of new training techniques. Although these techniques have been extensively used in the m ainstream deep learning-based models, it is still an open issue to analyze their impact in alternative, and computationally more efficient, ensemble-based approaches. In this paper we evaluate the impact of the adoption of data augmentation, bounding box refinement and multi-scale processing in the context of multi-class Boosting-based object detection. In our experiments we show that use of these training advancements significantly improves the object detection performance.},
  archive      = {J_ICAE},
  author       = {Buenaposada, José Miguel and Baumela, Luis},
  doi          = {10.3233/ICA-200636},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {81-96},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Improving multi-class boosting-based object detection},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Learning ensembles of priority rules for online scheduling
by hybrid evolutionary algorithms. <em>ICAE</em>, <em>28</em>(1), 65–80.
(<a href="https://doi.org/10.3233/ICA-200634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the computation of ensembles of priority rules for the One Machine Scheduling Problem with variable capacity and total tardiness minimization. Concretely, we address the problem of building optimal ensembles of priority rules, starting from a pool of rules evolved by a Genetic Pr ogramming approach. Building on earlier work, we propose a number of new algorithms. These include an iterated greedy search method, a local search algorithm and a memetic algorithm. Experimental results show the potential of the proposed approaches.},
  archive      = {J_ICAE},
  author       = {Gil-Gala, Francisco J. and Mencía, Carlos and Sierra, María R. and Varela, Ramiro},
  doi          = {10.3233/ICA-200634},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {65-80},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Learning ensembles of priority rules for online scheduling by hybrid evolutionary algorithms},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A convolution-based distance measure for fuzzy singletons
and its application in a pattern recognition problem. <em>ICAE</em>,
<em>28</em>(1), 51–63. (<a
href="https://doi.org/10.3233/ICA-200629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new method to measure the distance between fuzzy singletons (FSNs) is presented. It first fuzzifies a crisp number to a generalized trapezoidal fuzzy number (GTFN) using the Mamdani fuzzification method. It then treats an FSN as an impulse signal and transforms the FSN into a new GTFN by convolut ing it with the original GTFN. In so doing, an existing distance measure for GTFNs can be used to measure distance between FSNs. It is shown that the new measure offers a desirable behavior over the Euclidean and weighted distance measures in the following sense: Under the new measure, the distance between two FSNs is larger when they are in different GTFNs, and smaller when they are in the same GTFN. The advantage of the new measure is demonstrated on a fuzzy forecasting trading system over two different real stock markets, which provides better predictions with larger profits than those obtained using the Euclidean distance measure for the same system.},
  archive      = {J_ICAE},
  author       = {Naranjo, Rodrigo and Santos, Matilde and Garmendia, Luis},
  doi          = {10.3233/ICA-200629},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {51-63},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A convolution-based distance measure for fuzzy singletons and its application in a pattern recognition problem},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Simplified binary cat swarm optimization. <em>ICAE</em>,
<em>28</em>(1), 35–50. (<a
href="https://doi.org/10.3233/ICA-200618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the biological behavior of domestic cats, the Cat Swarm Optimization (CSO) is a metaheuristic which has been successfully applied to solve several optimization problems. For binary problems, the Boolean Binary Cat Swarm Optimization (BBCSO) presents consistent performance and differenti ates itself from most of the other algorithms by not considering the agents as continuous vectors using transfer and discretization functions. In this paper, we present a simplified version of the BBCSO. This new version, named Simplified Binary CSO (SBCSO) which features a new position update rule for the tracing mode, demonstrates improved performance, and reduced computational cost when compared to previous CSO versions, including the BBCSO. Furthermore, the results of the experiments indicate that SBCSO can outperform other well-known algorithms such as the Improved Binary Fish School Search (IBFSS), the Binary Artificial Bee Colony (BABC), the Binary Genetic Algorithm (BGA), and the Modified Binary Particle Swarm Optimization (MBPSO) in several instances of the One Max, 0/1 Knapsack, Multiple 0/1 Knapsack, SubsetSum problem besides Feature Selection problems for eight datasets.},
  archive      = {J_ICAE},
  author       = {Siqueira, Hugo and Santana, Clodomir and Macedo, Mariana and Figueiredo, Elliackin and Gokhale, Anuradha and Bastos-Filho, Carmelo},
  doi          = {10.3233/ICA-200618},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {35-50},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Simplified binary cat swarm optimization},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An unsupervised semantic sentence ranking scheme for text
documents. <em>ICAE</em>, <em>28</em>(1), 17–33. (<a
href="https://doi.org/10.3233/ICA-200626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents Semantic SentenceRank (SSR), an unsupervised scheme for automatically ranking sentences in a single document according to their relative importance. In particular, SSR extracts essential words and phrases from a text document, and uses semantic measures to construct, respectivel y, a semantic phrase graph over phrases and words, and a semantic sentence graph over sentences. It applies two variants of article-structure-biased PageRank to score phrases and words on the first graph and sentences on the second graph. It then combines these scores to generate the final score for each sentence. Finally, SSR solves a multi-objective optimization problem for ranking sentences based on their final scores and topic diversity through semantic subtopic clustering. An implementation of SSR that runs in quadratic time is presented, and it outperforms, on the SummBank benchmarks, each individual judge’s ranking and compares favorably with the combined ranking of all judges.},
  archive      = {J_ICAE},
  author       = {Zhang, Hao and Wang, Jie},
  doi          = {10.3233/ICA-200626},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {17-33},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An unsupervised semantic sentence ranking scheme for text documents},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Write right for ICAE. <em>ICAE</em>, <em>28</em>(1), 11–14.
(<a href="https://doi.org/10.3233/ICA-200630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  doi          = {10.3233/ICA-200630},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {11-14},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Write right for ICAE},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). How to maintain the highest quality standards of a leading
journal after three decades: An extraordinary editor-in-chief leading by
example. <em>ICAE</em>, <em>28</em>(1), 7–8. (<a
href="https://doi.org/10.3233/ICA-200644">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  doi          = {10.3233/ICA-200644},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {7-8},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {How to maintain the highest quality standards of a leading journal after three decades: An extraordinary editor-in-chief leading by example},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An outstanding platform for ground-breaking
cross-disciplinary research. <em>ICAE</em>, <em>28</em>(1), 3–5. (<a
href="https://doi.org/10.3233/ICA-200642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  doi          = {10.3233/ICA-200642},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {12},
  number       = {1},
  pages        = {3-5},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {An outstanding platform for ground-breaking cross-disciplinary research},
  volume       = {28},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). 3D mesh simplification with feature preservation based on
whale optimization algorithm and differential evolution. <em>ICAE</em>,
<em>27</em>(4), 417–435. (<a
href="https://doi.org/10.3233/ICA-200641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale 3D models consume large computing and storage resources. To address this challenging problem, this paper proposes a new method to obtain the optimal simplified 3D mesh models with the minimum approximation error. First, we propose a feature-preservation edge collapse operation to mainta in the feature edges, in which the collapsing cost is calculated in a novel way by combining Gauss curvature and Quadratic Error Metrics (QEM). Second, we introduce the edge splitting operation into the mesh simplification process and propose a hybrid ‘undo/redo’ mechanism that combines the edge splitting and edge collapse operation to reduce the number of long and narrow triangles. Third, the proposed ‘undo/redo’ mechanism can also reduce the approximation error; however, it is impossible to manually choose the best operation sequence combination that can result in the minimum approximation error. To solve this problem, we formulate the proposed mesh simplification process as an optimization model, in which the solution space is composed of the possible combinations of operation sequences, and the optimization objective is the minimum of the approximation error. Finally, we propose a novel optimization algorithm, WOA-DE, by replacing the exploration phase of the original Whale Optimization Algorithm (WOA) with the mutate and crossover operations of Differential Evolution (DE) to compute the optimal simplified mesh model more efficiently. We conduct numerous experiments to test the capabilities of the proposed method, and the experimental results show that our method outperforms the previous methods in terms of the geometric feature preservation, triangle quality, and approximation error.},
  archive      = {J_ICAE},
  author       = {Liang, Yaqian and He, Fazhi and Zeng, Xiantao},
  doi          = {10.3233/ICA-200641},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {417-435},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {3D mesh simplification with feature preservation based on whale optimization algorithm and differential evolution},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Shallow buried improvised explosive device detection via
convolutional neural networks. <em>ICAE</em>, <em>27</em>(4), 403–416.
(<a href="https://doi.org/10.3233/ICA-200638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of detecting improvised explosive devices, henceforth IEDs, in rural or built-up urban environments is a persistent and serious concern for governments in the developing world. In many cases, such devices are plastic, or varied metallic objects containing rudimentary explosives, which are not visible to the naked eye and are difficult to detect autonomously. The most effective strategy for detecting land mines also happens to be the most dangerous. This paper intends to leverage the use of a Convolutional Neural Network (CNN) to aid in the discovery of such IEDs. As part of a related project, an autonomous sensor array was used to detect the devices in terrains too hazardous for a human to survey. This paper presents a CNN and its training methodology, suitable to make use of the sensor system. This convolutional neural network can accurately distinguish between a potential IED and surrounding undergrowth and natural features of the environment in real-time. The training methodology enabled the CNN to successfully recognise the IEDs with an accuracy of 98.7%, in well-lit conditions. The results are evaluated against other convolutional neural systems as well as against a deterministic algorithm, showing that the proposed CNN outperforms its competitors including the deterministic method.},
  archive      = {J_ICAE},
  author       = {Colreavy-Donnelly, Simon and Caraffini, Fabio and Kuhn, Stefan and Gongora, Mario and Florez-Lozano, Johana and Parra, Carlos},
  doi          = {10.3233/ICA-200638},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {403-416},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Shallow buried improvised explosive device detection via convolutional neural networks},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep support vector neural networks. <em>ICAE</em>,
<em>27</em>(4), 389–402. (<a
href="https://doi.org/10.3233/ICA-200635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kernel based Support Vector Machines, SVM, one of the most popular machine learning models, usually achieve top performances in two-class classification and regression problems. However, their training cost is at least quadratic on sample size, making them thus unsuitable for large sample problems. However, Deep Neural Networks (DNNs), with a cost linear on sample size, are able to solve big data problems relatively easily. In this work we propose to combine the advanced representations that DNNs can achieve in their last hidden layers with the hinge and ϵ insensitive losses that are used in two-class SVM classification and regression. We can thus have much better scalability while achieving performances comparable to those of SVMs. Moreover, we will also show that the resulting Deep SVM models are competitive with standard DNNs in two-class classification problems but have an edge in regression ones.},
  archive      = {J_ICAE},
  author       = {Díaz-Vico, David and Prada, Jesús and Omari, Adil and Dorronsoro, José},
  doi          = {10.3233/ICA-200635},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {389-402},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Deep support vector neural networks},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Deep learning-based video surveillance system managed by low
cost hardware and panoramic cameras. <em>ICAE</em>, <em>27</em>(4),
373–387. (<a href="https://doi.org/10.3233/ICA-200632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of automated video surveillance systems often involves the detection of agents which exhibit anomalous or dangerous behavior in the scene under analysis. Models aimed to enhance the video pattern recognition abilities of the system are commonly integrated in order to increase its perform ance. Deep learning neural networks are found among the most popular models employed for this purpose. Nevertheless, the large computational demands of deep networks mean that exhaustive scans of the full video frame make the system perform rather poorly in terms of execution speed when implemented on low cost devices, due to the excessive computational load generated by the examination of multiple image windows. This work presents a video surveillance system aimed to detect moving objects with abnormal behavior for a panoramic 360∘ surveillance camera. The block of the video frame to be analyzed is determined on the basis of a probabilistic mixture distribution comprised by two mixture components. The first component is a uniform distribution, which is in charge of a blind window selection, while the second component is a mixture of kernel distributions. The kernel distributions generate windows within the video frame in the vicinity of the areas where anomalies were previously found. This contributes to obtain candidate windows for analysis which are close to the most relevant regions of the video frame, according to the past recorded activity. A Raspberry Pi microcontroller based board is employed to implement the system. This enables the design and implementation of a system with a low cost, which is nevertheless capable of performing the video analysis with a high video frame processing rate.},
  archive      = {J_ICAE},
  author       = {Benito-Picazo, Jesus and Domínguez, Enrique and Palomo, Esteban J. and López-Rubio, Ezequiel},
  doi          = {10.3233/ICA-200632},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {373-387},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Deep learning-based video surveillance system managed by low cost hardware and panoramic cameras},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Motivation as a tool for designing lifelong learning robots.
<em>ICAE</em>, <em>27</em>(4), 353–372. (<a
href="https://doi.org/10.3233/ICA-200633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing robots has usually implied knowing beforehand the tasks to be carried out and in what domains. However, in the case of fully autonomous robots this is not possible. Autonomous robots need to operate in an open-ended manner, that is, deciding on the most interesting goals to achieve in domains that are not known at design time. This obviously poses a challenge from the point of view of designing the robot control structure. In particular, the main question that arises is how to endow the robot with a designer defined purpose and with means to translate that purpose into operational decisions without any knowledge of what situations the robot will find itself in. In this paper, we provide a formalization of motivation from an engineering perspective that allows for the structured design of purposeful robots. This formalization is based on a definition of the concepts of robot needs and drives, which are related through experience to the appropriate goals in specific domains. To illustrate the process, a motivational system to guide the operation of a real robot is constructed using this approach. A series of experiments carried out over it are discussed providing some insights on the design of purposeful motivated operation.},
  archive      = {J_ICAE},
  author       = {Romero, Alejandro and Bellas, Francisco and Becerra, José A. and Duro, Richard J.},
  doi          = {10.3233/ICA-200633},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {353-372},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Motivation as a tool for designing lifelong learning robots},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exploring communication protocols and centralized critics in
multi-agent deep learning. <em>ICAE</em>, <em>27</em>(4), 333–351. (<a
href="https://doi.org/10.3233/ICA-200631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tackling multi-agent environments where each agent has a local limited observation of the global state is a non-trivial task that often requires hand-tuned solutions. A team of agents coordinating in such scenarios must handle the complex underlying environment, while each agent only has partial kn owledge about the environment. Deep reinforcement learning has been shown to achieve super-human performance in single-agent environments, and has since been adapted to the multi-agent paradigm. This paper proposes A3C3, a multi-agent deep learning algorithm, where agents are evaluated by a centralized referee during the learning phase, but remain independent from each other in actual execution. This referee’s neural network is augmented with a permutation invariance architecture to increase its scalability to large teams. A3C3 also allows agents to learn communication protocols with which agents share relevant information to their team members, allowing them to overcome their limited knowledge, and achieve coordination. A3C3 and its permutation invariant augmentation is evaluated in multiple multi-agent test-beds, which include partially-observable scenarios, swarm environments, and complex 3D soccer simulations.},
  archive      = {J_ICAE},
  author       = {Simões, David and Lau, Nuno and Reis, Luís Paulo},
  doi          = {10.3233/ICA-200631},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {9},
  number       = {4},
  pages        = {333-351},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Exploring communication protocols and centralized critics in multi-agent deep learning},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Content based image retrieval by ensembles of deep learning
object classifiers. <em>ICAE</em>, <em>27</em>(3), 317–331. (<a
href="https://doi.org/10.3233/ICA-200625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning has demonstrated its efficiency in many computer vision tasks. In this paper, we address this paradigm within content based image retrieval (CBIR). We propose to build an ensemble of convolutional neural networks (CNNs), either by training the CNNs on different bags of images, or by using CNNs trained on the same dataset, but having different architectures. Each network is used to extract the class probability vectors from images to use them as representations. The final image representation is then generated by combining the extracted class probability vectors from the built ensemble. We show that the use of CNN ensembles is very efficient in generating a powerful image representation compared to individual CNNs. Moreover, we propose an Averarge Query Expansion technique for our proposal to enhance the retrieval results. Several experiments were conducted to extensively evaluate the application of ensemble learning in CBIR. Results in terms of precision, recall, and mean average precision show the outperformance of our proposal compared to the state of the art.},
  archive      = {J_ICAE},
  author       = {Hamreras, Safa and Boucheham, Bachir and Molina-Cabello, Miguel A. and Benítez-Rochel, Rafaela and López-Rubio, Ezequiel},
  doi          = {10.3233/ICA-200625},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {317-331},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Content based image retrieval by ensembles of deep learning object classifiers},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Semantic visual recognition in a cognitive architecture for
social robots. <em>ICAE</em>, <em>27</em>(3), 301–316. (<a
href="https://doi.org/10.3233/ICA-200624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive architectures allow robots to perform their operations by drawing on a process that aims to simulate human reasoning. This paper presents an integrated semantic artificial memory system in cognitive architecture based on symbolic reasoning and a connective representation of the knowledge. This memory system attempts to simulate how humans learn to distinguish instances of particular objects within their class using a convolutional network to detect the relevant elements of an image. We use a vector with the extracted features to learn to discriminate an instance of another element from the same class. A novel feature of our approach is its autonomous learning process during the operation of the robot, integrating a deep learning embedding with a statistical classifier. The usefulness and robustness of this method are demonstrated by applying it to a social robot that learns to differentiate people. Finally, experiments are carried out to validate our approach, comparing the detection results with several alternative methods.},
  archive      = {J_ICAE},
  author       = {Martin-Rico, Francisco and Gomez-Donoso, Francisco and Escalona, Felix and Garcia-Rodriguez, Jose and Cazorla, Miguel},
  doi          = {10.3233/ICA-200624},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {301-316},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Semantic visual recognition in a cognitive architecture for social robots},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Design of reliable virtual human facial expressions and
validation by healthy people. <em>ICAE</em>, <em>27</em>(3), 287–299.
(<a href="https://doi.org/10.3233/ICA-200623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The level of realism that real-time virtual humans have reached in the last years enables their use as an alternative to pictures and videos in the remediation of social cognition deficits. This paper presents the engineering principles and tools used to design facial expressions on virtual humans to play basic emotions. The proposal is based on the Facial Action Coding System that makes it possible to easily represent facial expressions. Then, the paper describes how the designed virtual human facial emotions have been assessed by healthy people. For that purpose, 204 healthy participants have taken part in an experiment in which they had to recognize the six basic emotions (each of them with two levels of intensity) depicted by the virtual humans. The overall accuracy of the emotion identification task was 88.25%, which outperforms most results obtained by other authors using virtual humans and/or pictures. The best recognized emotions were neutral, happiness and anger. Remarkably striking was the high success rate gotten for disgust, far superior to previous studies based on virtual reality. Unlike other works, no significant differences were found between women and men in the recognition of emotions, probably due to an enhanced dynamism and realism of the designed human faces. However, age-related differences were found for some emotions in favor of the younger participants. In addition, higher emotion identification rates were detected for higher intensity representations of each emotion, for more dynamic avatars and for faces shown frontally compared to lateral ones. Therefore, the results of the evaluation experiment have demonstrated that virtual humans perfectly convey emotions using facial expressions.},
  archive      = {J_ICAE},
  author       = {García, Arturo S. and Fernández-Sotos, Patricia and Vicente-Querol, Miguel A. and Lahera, Guillermo and Rodriguez-Jimenez, Roberto and Fernández-Caballero, Antonio},
  doi          = {10.3233/ICA-200623},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {287-299},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Design of reliable virtual human facial expressions and validation by healthy people},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Intelligent trajectory planner and generalised proportional
integral control for two carts equipped with a red-green-blue depth
sensor on a circular rail. <em>ICAE</em>, <em>27</em>(3), 267–285. (<a
href="https://doi.org/10.3233/ICA-200622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an intelligent trajectory generator and a generalised proportional integral (GPI) control law for the movement of two carts on a circular motorised rail. The objective is to continuously monitor a person performing physical rehabilitation exercises and moving freely inside the circle. Each cart is equipped with an red-green-blue depth (RGB-D) device so that the patient is monitored from two points of view. One RGB-D device is dedicated to track the body part being exercised, while the other focuses on the person’s face to detect his/her emotional state. The proposed feedback control scheme is based on an exact feed-forward action combined with a velocity vector structural estimation using a model-based integral state re-constructor. Furthermore, the proposed intelligent trajectory generator comprises the references required to move the carts based on the instantaneous position of the patient and the current position of both carts. It also establishes the role (master or slave) of each cart, the direction that each cart must follow, and it generates smooth trajectories that avoid collisions between the carts. Moreover, the paper introduces a description of the displacements of both carts and the positioning of the tilt and pan angles of each RGB-D sensor so as to track the patient’s face and the body from the best viewpoints. The performance of the intelligent trajectory generation and the control of the two carts were analysed with numerical simulations. A comparison was made between the developed GPI control and a standard proportional integral derivative (PID) control. The simulation results show the effectiveness of the trajectory planner, and demonstrate that the GPI control has a better dynamic response than the PID control as well as a better performance in terms of the integral squared tracking error, the integral absolute tracking error, and the integral time absolute tracking error.},
  archive      = {J_ICAE},
  author       = {Panduro, Ramón and Segura, Eva and Belmonte, Lidia M. and Fernández-Caballero, Antonio and Novais, Paulo and Benet, Jesús and Morales, Rafael},
  doi          = {10.3233/ICA-200622},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {267-285},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Intelligent trajectory planner and generalised proportional integral control for two carts equipped with a red-green-blue depth sensor on a circular rail},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Background subtraction by probabilistic modeling of patch
features learned by deep autoencoders. <em>ICAE</em>, <em>27</em>(3),
253–265. (<a href="https://doi.org/10.3233/ICA-200621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video sequence analysis systems must be able to operate for long periods of time and they must attempt that the different events that can affect the quality of the input data do not diminish the performance of the system to an excessive extent. In this work a method called Probabilistic Mixture of Deeply Autoencoded Patch Features (PMDAPF) is proposed. A Deep Autoencoder is the cornerstone of the methodology for robust background modeling and foreground detection that is presented in this document. Its purpose is to obtain a reduced set of significant features from each patch belonging to one of the several shifted tilings of the video frames. Then, a probabilistic model is responsible for determining whether the whole patch belongs to the background or not. Foreground pixel detection takes into account the information of all patches in which the pixel is included. The robustness of the proposal, as well as its suitability to the uninterrupted analysis and processing of visual information, is reflected in the experiments, in which the performance of the proposed system is affected slightly whereas those of the classic methods are degraded drastically.},
  archive      = {J_ICAE},
  author       = {García-González, Jorge and Ortiz-de-Lazcano-Lobato, Juan M. and Luque-Baena, Rafael M. and López-Rubio, Ezequiel},
  doi          = {10.3233/ICA-200621},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {253-265},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Background subtraction by probabilistic modeling of patch features learned by deep autoencoders},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiobjective optimization of deep neural networks with
combinations of lp-norm cost functions for 3D medical image
super-resolution. <em>ICAE</em>, <em>27</em>(3), 233–251. (<a
href="https://doi.org/10.3233/ICA-200620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical imaging, the lack of high-quality images is present in many areas such as magnetic resonance (MR). Due to many acquisition impediments, the generated images have not enough resolution to carry out an adequate diagnosis. Image super-resolution (SR) is an ill-posed problem that tries to in fer information from the image to enhance its resolution. Nowadays, deep learning techniques have become a powerful tool to extract features from images and infer new information. In MR, most of the recent works are based on the minimization of the errors between the input and the output images based on the Euclidean norm. This work presents a new methodology to perform three-dimensional SR based on the combination of Lp-norms in the loss layer. Two multiobjective optimization techniques are used to combine two cost functions. The proposed loss layers were trained with the SRCNN3D and DCSRN networks and tested with two MR structural T1-weighted datasets, and then compared with the traditional Euclidean loss. Experimental results show significant differences in terms of Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM) and Bhattacharyya Coefficient (BC), while the residual images show refined details.},
  archive      = {J_ICAE},
  author       = {Thurnhofer-Hemsi, Karl and López-Rubio, Ezequiel and Roé-Vellvé, Núria and Molina-Cabello, Miguel A.},
  doi          = {10.3233/ICA-200620},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {233-251},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Multiobjective optimization of deep neural networks with combinations of lp-norm cost functions for 3D medical image super-resolution},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). EvoAAA: An evolutionary methodology for automated neural
autoencoder architecture search. <em>ICAE</em>, <em>27</em>(3), 211–231.
(<a href="https://doi.org/10.3233/ICA-200619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models work better when curated features are provided to them. Feature engineering methods have been usually used as a preprocessing step to obtain or build a proper feature set. In late years, autoencoders (a specific type of symmetrical neural network) have been widely used to pe rform representation learning, proving their competitiveness against classical feature engineering algorithms. The main obstacle in the use of autoencoders is finding a good architecture, a process that most experts confront manually. An automated autoencoder symmetrical architecture search procedure, based on evolutionary methods, is proposed in this paper. The methodology is tested against nine heterogeneous data sets. The obtained results show the ability of this approach to find better architectures, able to concentrate most of the useful information in a minimized encoding, in a reduced time.},
  archive      = {J_ICAE},
  author       = {Charte, Francisco and Rivera, Antonio J. and Martínez, Francisco and del Jesus, María J.},
  doi          = {10.3233/ICA-200619},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {211-231},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {EvoAAA: An evolutionary methodology for automated neural autoencoder architecture search},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Introduction. <em>ICAE</em>, <em>27</em>(3), 209. (<a
href="https://doi.org/10.3233/ICA-200628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ICAE},
  doi          = {10.3233/ICA-200628},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {5},
  number       = {3},
  pages        = {209},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Introduction},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Depth and thermal information fusion for head tracking using
particle filter in a fall detection context. <em>ICAE</em>,
<em>27</em>(2), 195–208. (<a
href="https://doi.org/10.3233/ICA-190615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security of elderly people living alone is a major issue. A system that detects anomalies can be useful for both individual and retirement homes. In this paper, we present an adaptive human tracking method built on particle filter, using depth and thermal information based on the velocity and t he position of the head. The main contribution of this paper is the fusion of information to improve tracking. For each frame, there is a new combination of coefficients for each particle based on an adaptive weighting. Results show that the tracking method can deal with the cases of fast motion (fall), partial occultation and scale variation. To assess the impact of fusion on the tracking process, the robustness and accuracy of the method are tested on a variety of challenging scenarios with or without depth-thermal fusion.},
  archive      = {J_ICAE},
  author       = {Halima, Imen and Laferté, Jean-Marc and Cormier, Geoffroy and Fougères, Alain-Jérôme and Dillenseger, Jean-Louis},
  doi          = {10.3233/ICA-190615},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {195-208},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Depth and thermal information fusion for head tracking using particle filter in a fall detection context},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Self-adapted optimization-based video magnification for
revealing subtle changes. <em>ICAE</em>, <em>27</em>(2), 173–193. (<a
href="https://doi.org/10.3233/ICA-190614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video magnification techniques can reveal subtle temporal variations that are difficult or even impossible to see with the naked eye and display them in an indicative manner. State-of-the-art approaches rely on hand-designed filters or precise prior knowledge of the target signal and produce magnif ied outputs that are always bounded by the spatial support of the related pyramids. This paper proposes a method for adaptively magnifying subtle video changes by directly solving three key optimization problems. To efficiently model the magnification transformation, alternating direction method of multipliers is employed to solve convex variation-detection optimization problems. Following the transformation step, the perturbation problem is innovatively solved using a forward additive iterative approach to iteratively minimize the dissimilarity between the original and magnified sequences based on the enhanced correlation coefficient. The proposed method can be applied to videos overlaid with different types of temporal change to obtain motion and color magnification. Quantitative and qualitative experimental comparison of the proposed method with state-of-the-art techniques reveals that it produces magnified videos with improved visual quality and substantially fewer artifacts or blurring.},
  archive      = {J_ICAE},
  author       = {Cai, Enjian and Li, Dongsheng and Li, Hongnan and Xue, Zhilin},
  doi          = {10.3233/ICA-190614},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {173-193},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Self-adapted optimization-based video magnification for revealing subtle changes},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A domain-specific modeling approach supporting tool-chain
development with bayesian network models. <em>ICAE</em>, <em>27</em>(2),
153–171. (<a href="https://doi.org/10.3233/ICA-190612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing and evaluating a comprehensive tool-chain with commercial off-the-shelf and proprietary tools for the deployment of model-based systems engineering (MBSE) is a challenging and complex task. Specifically, the lack of early assessment during tool-chain development has led to increased re search and development costs when unexpected features are developed or poor decisions are made. In this paper, a domain-specific modeling (DSM) approach is proposed to support decision-makings during tool-chain design and to facilitate quantitative assessment of tool-chain features at early-phases. Using this approach, different views of tool-chains are first formalized under a DSM framework. Then the DSM models are transformed to Bayesian network models for supporting the quantitative assessment of related tools in order to analyze the whole tool-chains’ features. In the case study, the approach is verified by comparing two MBSE tool-chains for an auto-braking system design. The results indicate that the DSM approach enhances the understanding of tool-chain concepts, promotes the efficiency of MBSE tool-chain development, and verifies the tool-chain in early development phases using a quantitative approach.},
  archive      = {J_ICAE},
  author       = {Lu, Jinzhi and Wang, Guoxin and Tao, Xin and Wang, Jian and Törngren, Martin},
  doi          = {10.3233/ICA-190612},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {153-171},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A domain-specific modeling approach supporting tool-chain development with bayesian network models},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Routing in congested baggage handling systems using deep
reinforcement learning. <em>ICAE</em>, <em>27</em>(2), 139–152. (<a
href="https://doi.org/10.3233/ICA-190613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing number of people choosing to travel by airplane puts pressure on the baggage handling systems in airports. As the load increases, the risk of deadlocks in the systems increase as well. Therefore, it is increasingly important to find routing solutions which can handle the high loads. Currently this is achieved by using shortest path algorithms and hand engineered site-specific routing rules, based on the experience of the employees and on trial and error processes using complex emulators. This is a time-consuming and costly approach, as every airport needs its own set of routing rules. New development within machine learning, and especially reinforcement learning allows very complex control policies to be found in large environments. This could therefore potentially solve the need of manually creating site-specific routing rules. This paper proposes to use a single global deep reinforcement learning agent to route a fleet of baggage-totes to continuously pick up and deliver baggage in simple yet functionally realistic simulations of baggage handling systems. This is achieved using a Dueling DQN architecture with prioritized experience reply and a multi action approach. Training and testing are performed in three baggage handling system environments of different size and complexity. The results show that by training with a broad distribution of loads, it is possible to get a model, capable of routing in highly congested baggage handling systems. The results also show that the reinforcement learning agent can limit the number of deadlocks up until a higher load than both a static shortest path and a dynamic shortest path method, even if the dynamic shortest path method is using a naive deadlock avoidance add-on.},
  archive      = {J_ICAE},
  author       = {Sørensen, René Arendt and Nielsen, Michael and Karstoft, Henrik},
  doi          = {10.3233/ICA-190613},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {139-152},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Routing in congested baggage handling systems using deep reinforcement learning},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A membrane parallel rapidly-exploring random tree algorithm
for robotic motion planning. <em>ICAE</em>, <em>27</em>(2), 121–138. (<a
href="https://doi.org/10.3233/ICA-190616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, incremental sampling-based motion planning algorithms have been widely used to solve robot motion planning problems in high-dimensional configuration spaces. In particular, the Rapidly-exploring Random Tree (RRT) algorithm and its asymptotically-optimal counterpart called RRT* are popular algorithms used in real-life applications due to its desirable properties. Such algorithms are inherently iterative, but certain modules such as the collision-checking procedure can be parallelized providing significant speedup with respect to sequential implementations. In this paper, the RRT and RRT* algorithms have been adapted to a bioinspired computational framework called Membrane Computing whose models of computation, a.k.a. P systems, run in a non-deterministic and massively parallel way. A large number of robotic applications are currently using a variant of P systems called Enzymatic Numerical P systems (ENPS) for reactive controlling, but there is a lack of solutions for motion planning in the framework. The novel models in this work have been designed using the ENPS framework. In order to test and validate the ENPS models for RRT and RRT*, we present two ad-hoc implementations able to emulate the computation of the models using OpenMP and CUDA. Finally, we show the speedup of our solutions with respect to sequential baseline implementations. The results show a speedup up to 6x using OpenMP with 8 cores against the sequential implementation and up to 24x using CUDA against the best multi-threading configuration.},
  archive      = {J_ICAE},
  author       = {Pérez-Hurtado, Ignacio and Martínez-del-Amor, Miguel Á. and Zhang, Gexiang and Neri, Ferrante and Pérez-Jiménez, Mario J.},
  doi          = {10.3233/ICA-190616},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {121-138},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {A membrane parallel rapidly-exploring random tree algorithm for robotic motion planning},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asynchronous dual-pipeline deep learning framework for
online data stream classification. <em>ICAE</em>, <em>27</em>(2),
101–119. (<a href="https://doi.org/10.3233/ICA-200617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data streaming classification has become an essential task in many fields where real-time decisions have to be made based on incoming information. Neural networks are a particularly suitable technique for the streaming scenario due to their incremental learning nature. However, the high computation cost of deep architectures limits their applicability to high-velocity streams, hence they have not yet been fully explored in the literature. Therefore, in this work, we aim to evaluate the effectiveness of complex deep neural networks for supervised classification in the streaming context. We propose an asynchronous deep learning framework in which training and testing are performed simultaneously in two different processes. The data stream entering the system is dual fed into both layers in order to concurrently provide quick predictions and update the deep learning model. This separation reduces processing time while obtaining high accuracy on classification. Several time-series datasets from the UCR repository have been simulated as streams to evaluate our proposal, which has been compared to other methods such as Hoeffding trees, drift detectors, and ensemble models. The statistical analysis carried out verifies the improvement in performance achieved with our dual-pipeline deep learning framework, that is also competitive in terms of computation time.},
  archive      = {J_ICAE},
  author       = {Lara-Benítez, Pedro and Carranza-García, Manuel and García-Gutiérrez, Jorge and Riquelme, José C.},
  doi          = {10.3233/ICA-200617},
  journal      = {Integrated Computer-Aided Engineering},
  month        = {2},
  number       = {2},
  pages        = {101-119},
  shortjournal = {Integrated Computer-Aided Engineering},
  title        = {Asynchronous dual-pipeline deep learning framework for online data stream classification},
  volume       = {27},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
