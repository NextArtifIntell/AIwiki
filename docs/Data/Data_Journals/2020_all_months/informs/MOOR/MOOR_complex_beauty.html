<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MOOR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="moor---67">MOOR - 67</h2>
<ul>
<li><details>
<summary>
(2020). The value of insight. <em>MOOR</em>, <em>45</em>(4),
1193–1620. (<a href="https://doi.org/10.1287/moor.2019.1028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An investor may invest in a riskless bank account and in a stock that is a standard Black–Scholes asset with occasional Gaussian jumps of the log price, as proposed by Merton [Merton RC ( 1976 ) Option pricing when underlying stock returns are discontinuous. J. Financial Econom. 3(1):125–144.]. It is well known how to solve the standard running consumption problem for this investor, which we take as a benchmark for comparing the performance of two different insiders, one who knows in advance of each jump exactly when the jump will happen, and the other who has information in advance of each jump about the size of the jump but no information about the time. These considerations give rise to two novel and concrete stochastic control problems. For each problem, rigorous verification proofs for optimality are presented.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1028},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {The value of insight},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Utility maximization with proportional transaction costs
under model uncertainty. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a discrete time financial market with proportional transaction costs under model uncertainty and study a numéraire-based semistatic utility maximization problem with an exponential utility preference. The randomization techniques recently developed in Bouchard, Deng, and Tan [Bouchard B, Deng S, Tan X (2019) Super-replication with proportional transaction cost under model uncertainty. Math. Finance 29(3):837–860.], allow us to transform the original problem into a frictionless counterpart on an enlarged space. By suggesting a different dynamic programming argument than in Bartl [Bartl D (2019) Exponential utility maximization under model uncertainty for unbounded endowments. Ann. Appl. Probab. 29(1):577–612.], we are able to prove the existence of the optimal strategy and the convex duality theorem in our context with transaction costs. In the frictionless framework, this alternative dynamic programming argument also allows us to generalize the main results in Bartl [Bartl D (2019) Exponential utility maximization under model uncertainty for unbounded endowments. Ann. Appl. Probab. 29(1):577–612.] to a weaker market condition. Moreover, as an application of the duality representation, some basic features of utility indifference prices are investigated in our robust setting with transaction costs.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1029},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Utility maximization with proportional transaction costs under model uncertainty},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Acyclic gambling games. <em>MOOR</em>, <em>45</em>(4),
1193–1620. (<a href="https://doi.org/10.1287/moor.2019.1030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two-player, zero-sum stochastic games in which each player controls the player’s own state variable living in a compact metric space. The terminology comes from gambling problems in which the state of a player represents its wealth in a casino. Under standard assumptions (e.g., continuous running payoff and nonexpansive transitions), we consider for each discount factor the value v λ of the λ-discounted stochastic game and investigate its limit when λ goes to zero. We show that, under a new acyclicity condition, the limit exists and is characterized as the unique solution of a system of functional equations: the limit is the unique continuous excessive and depressive function such that each player, if the player’s opponent does not move, can reach the zone when the current payoff is at least as good as the limit value without degrading the limit value. The approach generalizes and provides a new viewpoint on the Mertens–Zamir system coming from the study of zero-sum repeated games with lack of information on both sides. A counterexample shows that under a slightly weaker notion of acyclicity, convergence of ( v λ ) may fail.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1030},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Acyclic gambling games},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reinforcement with fading memories. <em>MOOR</em>,
<em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effect of imperfect memory on decision making in the context of a stochastic sequential action-reward problem. An agent chooses a sequence of actions, which generate discrete rewards at different rates. She is allowed to make new choices at rate β , whereas past rewards disappear from her memory at rate μ . We focus on a family of decision rules where the agent makes a new choice by randomly selecting an action with a probability approximately proportional to the amount of past rewards associated with each action in her memory. We provide closed form formulas for the agent’s steady-state choice distribution in the regime where the memory span is large ( μ → 0 ) and show that the agent’s success critically depends on how quickly she updates her choices relative to the speed of memory decay. If β ≫ μ , the agent almost always chooses the best action (that is, the one with the highest reward rate). Conversely, if β ≪ μ , the agent chooses an action with a probability roughly proportional to its reward rate.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1031},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Reinforcement with fading memories},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control-stopping games for market microstructure and beyond.
<em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a family of control-stopping games that arise naturally in equilibrium-based models of market microstructure as well as in other models with strategic buyers and sellers. A distinctive feature of this family of games is the fact that the agents do not have any exogenously given fundamental value for the asset, and they deduce the value of their position from the bid and ask prices posted by other agents (i.e., they are pure speculators). As a result, in such a game, the reward function of each agent at the time of stopping depends directly on the controls of other players. The equilibrium problem leads naturally to a system of coupled control-stopping problems (or, equivalently, reflected-backward stochastic differential equations), in which the individual reward functions (or reflecting barriers) depend on the value functions (or solution components) of other agents. The resulting system, in general, presents multiple mathematical challenges because of the nonstandard form of coupling (or reflection). In the present case, this system is also complicated by the fact that the continuous controls of the agents, describing their posted bid and ask prices, are constrained to take values in a discrete grid. The latter feature reflects the presence of a positive tick size in the market, and it creates additional discontinuities in the agents’ reward functions (or reflecting barriers). Herein we prove the existence of a solution to the associated system in a special Markovian framework, provide numerical examples, and discuss the potential applications.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1033},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Control-stopping games for market microstructure and beyond},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stabilizing weighted graphs. <em>MOOR</em>, <em>45</em>(4),
1193–1620. (<a href="https://doi.org/10.1287/moor.2019.1034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An edge-weighted graph G is called stable if the value of a maximum-weight matching equals the value of a maximum-weight fractional matching. Stable graphs play an important role in network bargaining games and cooperative matching games, because they characterize instances that admit stable outcomes. We give the first polynomial-time algorithm to find a minimum cardinality subset of vertices whose removal from G yields a stable graph, for any weighted graph G . The algorithm is combinatorial and exploits new structural properties of basic fractional matchings, which are of independent interest. In contrast, we show that the problem of finding a minimum cardinality subset of edges whose removal from a weighted graph G yields a stable graph, does not admit any constant-factor approximation algorithm, unless P = NP . In this setting, we develop an O (Δ)-approximation algorithm for the problem, where Δ is the maximum degree of a node in G .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1034},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Stabilizing weighted graphs},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Surplus-invariant risk measures. <em>MOOR</em>,
<em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a systematic study of the notion of surplus invariance, which plays a natural and important role in the theory of risk measures and capital requirements. So far, this notion has been investigated in the setting of some special spaces of random variables. In this paper, we develop a theory of surplus invariance in its natural framework, namely, that of vector lattices. Besides providing a unifying perspective on the existing literature, we establish a variety of new results including dual representations and extensions of surplus-invariant risk measures and structural results for surplus-invariant acceptance sets. We illustrate the power of the lattice approach by specifying our results to model spaces with a dominating probability, including Orlicz spaces, as well as to robust model spaces without a dominating probability, where the standard topological techniques and exhaustion arguments cannot be applied.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1035},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Surplus-invariant risk measures},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Closing the gap for makespan scheduling via sparsification
techniques. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Makespan scheduling on identical machines is one of the most basic and fundamental packing problems studied in the discrete optimization literature. It asks for an assignment of n jobs to a set of m identical machines that minimizes the makespan. The problem is strongly NP-hard, and thus we do not expect a ( 1 + ε )-approximation algorithm with a running time that depends polynomially on 1 / ε . It has been recently shown that a subexponential running time on 1 / ε would imply that the Exponential Time Hypothesis (ETH) fails. A long sequence of algorithms have been developed that try to obtain low dependencies on 1 / ε , the better of which achieves a quadratic running time on the exponent. In this paper we obtain an algorithm with an almost-linear dependency on 1 / ε in the exponent, which is tight under ETH up to logarithmic factors. Our main technical contribution is a new structural result on the configuration-IP integer linear program. More precisely, we show the existence of a highly symmetric and sparse optimal solution, in which all but a constant number of machines are assigned a configuration with small support. This structure can then be exploited by integer programming techniques and enumeration. We believe that our structural result is of independent interest and should find applications to other settings. We exemplify this by applying our structural results to the minimum makespan problem on related machines and to a larger class of objective functions on parallel machines. For all these cases, we obtain an efficient PTAS with running time with an almost-linear dependency on 1 / ε and polynomial in n .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1036},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Closing the gap for makespan scheduling via sparsification techniques},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the existence of pairwise stable weighted networks.
<em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In network theory, Jackson and Wolinsky introduced a now widely used notion of stability for unweighted network formation called pairwise stability. We prove the existence of pairwise stable weighted networks under assumptions on payoffs that are similar to those in Nash&#39;s and Glicksberg’s existence theorem (continuity and quasi concavity). Then, we extend our result, allowing payoffs to depend not only on the network, but also on some game-theoretic strategies. The proof is not a standard application of tools from game theory, the difficulty coming from the fact that the pairwise stability notion has both cooperative and noncooperative features. Last, some examples are given and illustrate how our results may open new paths in the literature on network formation.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1032},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {On the existence of pairwise stable weighted networks},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Stochastic recursive inclusions in two timescales with
nonadditive iterate-dependent markov noise. <em>MOOR</em>,
<em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the asymptotic behavior of a stochastic approximation scheme on two timescales with set-valued drift functions and in the presence of nonadditive iterate-dependent Markov noise. We show that the recursion on each timescale tracks the flow of a differential inclusion obtained by averaging the set-valued drift function in the recursion with respect to a set of measures accounting for both averaging with respect to the stationary distributions of the Markov noise terms and the interdependence between the two recursions on different timescales. The framework studied in this paper builds on a recent work by Ramaswamy and Bhatnagar, by allowing for the presence of nonadditive iterate-dependent Markov noise. As an application, we consider the problem of computing the optimum in a constrained convex optimization problem, where the objective function and the constraints are averaged with respect to the stationary distribution of an underlying Markov chain. Further, the proposed scheme neither requires the differentiability of the objective function nor the knowledge of the averaging measure.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1037},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Stochastic recursive inclusions in two timescales with nonadditive iterate-dependent markov noise},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Core nonemptiness of stratified pooling games: A structured
markov decision process approach. <em>MOOR</em>, <em>45</em>(4),
1193–1620. (<a href="https://doi.org/10.1287/moor.2019.1038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study several service providers that keep spare parts in stock to protect for downtime of their high-tech machines and that face different downtime costs per stockout. Service providers can cooperate by forming a joint spare parts pool, and we study the allocation of the joint costs to the individual service providers by studying an associated cooperative game. In extant literature, the joint spare parts pool is typically controlled by a suboptimal full-pooling policy. A full-pooling policy may lead to an empty core of the associated cooperative game, and we show this result in our setting as well. We then focus on situations where service providers apply an optimal policy: a stratification that determines, depending on the real-time on-hand inventory, which service providers may take parts from the pool. We formulate the associated stratified pooling game by defining each coalitional value in terms of the minimal long-run average costs of a Markov decision process. We present a proof demonstrating that stratified pooling games always have a nonempty core. This five-step proof is of interest in itself, because it may be more generally applicable for other cooperative games where coalitional values can be defined in terms of Markov decision processes.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1038},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Core nonemptiness of stratified pooling games: A structured markov decision process approach},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Last-mile shared delivery: A discrete sequential packing
approach. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model for optimizing the last-mile delivery of n packages from a distribution center to their final recipients, using a strategy that combines the use of ride-sharing platforms (e.g., Uber or Lyft) with traditional in-house van delivery systems. The main objective is to compute the optimal reward offered to private drivers for each of the n packages such that the total expected cost of delivering all packages is minimized. Our technical approach is based on the formulation of a discrete sequential packing problem, in which bundles of packages are picked up from the warehouse at random times during the interval [ 0 , T ] . Our theoretical results include both exact and asymptotic (as n → ∞ ) expressions for the expected number of packages that are picked up by time T . They are closely related to the classical Rényi’s parking/packing problem. Our proposed framework is scalable with the number of packages.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1039},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Last-mile shared delivery: A discrete sequential packing approach},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). About the structure of the integer cone and its application
to bin packing. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the bin packing problem with d different item sizes and revisit the structure theorem given by Goemans and Rothvoß about solutions of the integer cone. We present new techniques on how solutions can be modified and give a new structure theorem that relies on the set of vertices of the underlying integer polytope. As a result of our new structure theorem, we obtain an algorithm for the bin packing problem with running time | V | 2 O ( d ) ⋅ e n c ( I ) O ( 1 ) , where V is the set of vertices of the integer knapsack polytope, and e n c ( I ) is the encoding length of the bin packing instance. The algorithm is fixed-parameter tractable, parameterized by the number of vertices of the integer knapsack polytope | V | . This shows that the bin packing problem can be solved efficiently when the underlying integer knapsack polytope has an easy structure (i.e., has a small number of vertices). Furthermore, we show that the presented bounds of the structure theorem are asymptotically tight. We give a construction of bin packing instances using new structural insights and classical number theoretical theorems which yield the desired lower bound.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1040},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {About the structure of the integer cone and its application to bin packing},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximation algorithms for d-optimal design.
<em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experimental design is a classical statistics problem, and its aim is to estimate an unknown vector from linear measurements where a Gaussian noise is introduced in each measurement. For the combinatorial experimental design problem, the goal is to pick a subset of experiments so as to make the most accurate estimate of the unknown parameters. In this paper, we will study one of the most robust measures of error estimation—the D -optimality criterion, which corresponds to minimizing the volume of the confidence ellipsoid for the estimation error. The problem gives rise to two natural variants depending on whether repetitions of experiments are allowed or not. We first propose an approximation algorithm with a 1/ e -approximation for the D -optimal design problem with and without repetitions, giving the first constant-factor approximation for the problem. We then analyze another sampling approximation algorithm and prove that it is asymptotically optimal. Finally, for D -optimal design with repetitions, we study a different algorithm proposed by the literature and show that it can improve this asymptotic approximation ratio. All the sampling algorithms studied in this paper are shown to admit polynomial-time deterministic implementations.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1041},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Approximation algorithms for D-optimal design},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Asymptotic optimality of power-of-d load balancing in
large-scale systems. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a system of N identical server pools and a single dispatcher in which tasks with unit-exponential service requirements arrive at rate λ ( N ) . In order to optimize the experienced performance, the dispatcher aims to evenly distribute the tasks across the various server pools. Specifically, when a task arrives, the dispatcher assigns it to the server pool with the minimum number of tasks among d ( N ) randomly selected server pools. We construct a stochastic coupling to bound the difference in the system occupancy processes between the join-the-shortest-queue (JSQ) policy and a scheme with an arbitrary value of d ( N ). We use the coupling to derive the fluid limit in case d ( N ) → ∞ and λ ( Ν ) / Ν → λ as N → ∞ along with the associated fixed point. The fluid limit turns out to be insensitive to the exact growth rate of d ( N ) and coincides with that for the JSQ policy. We further establish that the diffusion limit corresponds to that for the JSQ policy as well, as long as d ( N ) / N log ( N ) → ∞ , and characterize the common limiting diffusion process. These results indicate that the JSQ optimality can be preserved at the fluid and diffusion levels while reducing the overhead by nearly a factor O( N ) and O( N / log ( N ) ), respectively.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1042},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Asymptotic optimality of power-of-d load balancing in large-scale systems},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the scenario-tree optimal-value error for stochastic
programming problems. <em>MOOR</em>, <em>45</em>(4), 1193–1620. (<a
href="https://doi.org/10.1287/moor.2019.1043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic programming problems generally lead to large-scale programs if the number of random outcomes is large or if the problem has many stages. A way to tackle them is provided by scenario-tree generation methods, which construct approximate problems from a reduced subset of outcomes. However, it is well known that the number of scenarios required to keep the approximation error within a given tolerance grows rapidly with the number of random parameters and stages. For this reason, to limit the fast growth of complexity, scenario-tree generation methods tailored to problems must be developed. These will use more information about the problem than just the underlying probability distributions; namely, they will also take into account the objective function and the constraints. In this paper, we develop a general framework to build problem-driven scenario trees. We do so by studying how the optimal-value error arises as a sum of lower-level errors made at each node of the tree. We show how these small but numerous node errors depend on the specific features of the problem and how they can be controlled by designing scenario trees with appropriate branching structures and discretization points and weights. We illustrate our approach on two examples.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1043},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {On the scenario-tree optimal-value error for stochastic programming problems},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Approximate markov-nash equilibria for discrete-time
risk-sensitive mean-field games. <em>MOOR</em>, <em>45</em>(4),
1193–1620. (<a href="https://doi.org/10.1287/moor.2019.1044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a class of discrete-time mean-field games under the infinite-horizon risk-sensitive optimality criterion. Risk sensitivity is introduced for each agent (player) via an exponential utility function. In this game model, each agent is coupled with the rest of the population through the empirical distribution of the states, which affects both the agent’s individual cost and its state dynamics. Under mild assumptions, we establish the existence of a mean-field equilibrium in the infinite-population limit as the number of agents ( N ) goes to infinity, and we then show that the policy obtained from the mean-field equilibrium constitutes an approximate Nash equilibrium when N is sufficiently large.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1044},
  journal      = {Mathematics of Operations Research},
  number       = {4},
  pages        = {1193-1620},
  shortjournal = {Math. Oper. Res.},
  title        = {Approximate markov-nash equilibria for discrete-time risk-sensitive mean-field games},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Control policies approaching hierarchical greedy ideal
performance in heavy traffic for resource sharing networks.
<em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider resource sharing networks of the form introduced in work of Massoulié and Roberts as models for Internet flows. The goal is to study the open problem, formulated in Harrison et al. (2014) [Harrison JM, Mandayam C, Shah D, Yang Y (2014) Resource sharing networks: Overview and an open problem. Stochastic Systems 4(2):524–555.], of constructing simple form rate-allocation policies for broad families of resource sharing networks with associated costs converging to the hierarchical greedy ideal performance in the heavy traffic limit. We consider two types of cost criteria: an infinite horizon discounted cost and a long-time average cost per unit time. We introduce a sequence of rate-allocation control policies that are determined in terms of certain thresholds for the scaled queue-length processes and prove that, under conditions, both type of costs associated with these policies converge in the heavy traffic limit to the corresponding hierarchical greedy ideal (HGI) performance. The conditions needed for these results are satisfied by all the examples considered in the above cited paper of Harrison et al.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1007},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Control policies approaching hierarchical greedy ideal performance in heavy traffic for resource sharing networks},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A block successive upper-bound minimization method of
multipliers for linearly constrained convex optimization. <em>MOOR</em>,
<em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the problem of minimizing the sum of a smooth convex function and a separable nonsmooth convex function subject to linear coupling constraints. Problems of this form arise in many contemporary applications, including signal processing, wireless networking, and smart grid provisioning. Motivated by the huge size of these applications, we propose a new class of first-order primal–dual algorithms called the block successive upper-bound minimization method of multipliers (BSUM-M) to solve this family of problems. The BSUM-M updates the primal variable blocks successively by minimizing locally tight upper bounds of the augmented Lagrangian of the original problem, followed by a gradient-type update for the dual variable in closed form. We show that under certain regularity conditions, and when the primal block variables are updated in either a deterministic or a random fashion, the BSUM-M converges to a point in the set of optimal solutions. Moreover, in the absence of linear constraints and under similar conditions as in the previous result, we show that the randomized BSUM-M (which reduces to the randomized block successive upper-bound minimization method) converges at an asymptotically linear rate without relying on strong convexity.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1010},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {A block successive upper-bound minimization method of multipliers for linearly constrained convex optimization},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Power-of-d-choices with memory: Fluid limit and optimality.
<em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiserver distributed queueing systems, the access of stochastically arriving jobs to resources is often regulated by a dispatcher, also known as a load balancer. A fundamental problem consists in designing a load-balancing algorithm that minimizes the delays experienced by jobs. During the last two decades, the power-of- d -choice algorithm, based on the idea of dispatching each job to the least loaded server out of d servers randomly sampled at the arrival of the job itself, has emerged as a breakthrough in the foundations of this area because of its versatility and appealing asymptotic properties. In this paper, we consider the power-of- d -choice algorithm with the addition of a local memory that keeps track of the latest observations collected over time on the sampled servers. Then, each job is sent to a server with the lowest observation. We show that this algorithm is asymptotically optimal in the sense that the load balancer can always assign each job to an idle server in the large-system limit. This holds true if and only if the system load λ is less than 1 − 1 𝑑 1 − 1 d 1−1d . If this condition is not satisfied, we show that queue lengths are bounded by ⌈ − log ( 1 − 𝜆 ) log ( 𝜆𝑑 + 1 ) ⌉ ⌈ − log ( 1 − λ ) log ( λd + 1 ) ⌉ ⌈−log(1−λ)log(λd+1)⌉ . This is in contrast with the classic version of the power-of- d -choice algorithm, in which, at the fluid scale, a strictly positive proportion of servers containing 𝑖 i i jobs exists for all 𝑖 ≥ 0 i ≥ 0 i≥0 in equilibrium. Our results quantify and highlight the importance of using memory as a means to enhance performance in randomized load balancing.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1014},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Power-of-d-choices with memory: Fluid limit and optimality},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Limit equilibrium payoffs in stochastic games.
<em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the limit of equilibrium payoffs, as the discount factor goes to one, in non-zero-sum stochastic games. We first show that the set of stationary equilibrium payoffs always converges. We then provide two-player examples in which the whole set of equilibrium payoffs diverges. The construction is robust to perturbations of the payoffs and to the introduction of normal-form correlation.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1015},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Limit equilibrium payoffs in stochastic games},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Envy-free division of land. <em>MOOR</em>, <em>45</em>(3),
797–1192. (<a href="https://doi.org/10.1287/moor.2019.1016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classic cake-cutting algorithms enable people with different preferences to divide among them a heterogeneous resource (“cake”) such that the resulting division is fair according to each agent’s individual preferences. However, these algorithms either ignore the geometry of the resource altogether or assume it is one-dimensional. In practice, it is often required to divide multidimensional resources, such as land estates or advertisement spaces in print or electronic media. In such cases, the geometric shape of the allotted piece is of crucial importance. For example, when building houses or designing advertisements, in order to be useful, the allotments should be squares or rectangles with bounded aspect ratio. We, thus, introduce the problem of fair land division —fair division of a multidimensional resource wherein the allocated piece must have a prespecified geometric shape. We present constructive division algorithms that satisfy the two most prominent fairness criteria, namely envy-freeness and proportionality . In settings in which proportionality cannot be achieved because of the geometric constraints, our algorithms provide a partially proportional division, guaranteeing that the fraction allocated to each agent be at least a certain positive constant. We prove that, in many natural settings, the envy-freeness requirement is compatible with the best attainable partial-proportionality.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1016},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Envy-free division of land},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). General error estimates for the longstaff–schwartz
least-squares monte carlo algorithm. <em>MOOR</em>, <em>45</em>(3),
797–1192. (<a href="https://doi.org/10.1287/moor.2019.1017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We establish error estimates for the Longstaff–Schwartz algorithm, employing just a single set of independent Monte Carlo sample paths that is reused for all exercise time steps. We obtain, within the context of financial derivative payoff functions bounded according to the uniform norm, new bounds on the stochastic part of the error of this algorithm for an approximation architecture that may be any arbitrary set of L 2 functions of finite Vapnik–Chervonenkis (VC) dimension whenever the algorithm’s least-squares regression optimization step is solved either exactly or approximately. Moreover, we show how to extend these estimates to the case of payoff functions bounded only in L p , p a real number greater than 2 &lt; p &lt; ∞ . We also establish new overall error bounds for the Longstaff–Schwartz algorithm, including estimates on the approximation error also for unconstrained linear, finite-dimensional polynomial approximation. Our results here extend those in the literature by not imposing any uniform boundedness condition on the approximation architectures, allowing each of them to be any set of L 2 functions of finite VC dimension and by establishing error estimates as well in the case of ɛ-additive approximate least-squares optimization, ɛ greater than or equal to 0.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1017},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {General error estimates for the Longstaff–Schwartz least-squares monte carlo algorithm},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Constant approximation algorithm for nonuniform capacitated
multi-item lot sizing via strong covering inequalities. <em>MOOR</em>,
<em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the nonuniform capacitated multi-item lot-sizing problem. In this problem, there is a set of demands over a planning horizon of T discrete time periods, and all demands must be satisfied on time. We can place an order at the beginning of each period s , incurring an ordering cost K s . In this order, we can order up to C s units of products. On the other hand, carrying inventory from time to time incurs an inventory holding cost. The goal of the problem is to find a feasible solution that minimizes the sum of ordering and holding costs. Levi et al. [Levi R, Lodi A, Sviridenko M (2008) Approximation algorithms for the capacitated multi-item lot-sizing problem via flow-cover inequalities. Math. Oper. Res. 33(2):461–474.] gave a two-approximation for the problem when the capacities C s are the same. Extending the result to the case of nonuniform capacities requires new techniques as pointed out in the discussion section of their paper. In this paper, we solve the problem by giving a 10-approximation algorithm for the capacitated multi-item lot-sizing problem with general capacities. The constant approximation is achieved by adding an exponential number of new covering inequalities to the natural facility location–type linear programming (LP) relaxation for the problem. Along the way of our algorithm, we reduce the lot-sizing problem to two generalizations of the classic knapsack-covering problem. We give LP-based constant approximation algorithms for both generalizations via the iterative rounding technique.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1018},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Constant approximation algorithm for nonuniform capacitated multi-item lot sizing via strong covering inequalities},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Variance regularization in sequential bayesian optimization.
<em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential Bayesian optimization constitutes an important and broad class of problems where model parameters are not known a priori but need to be learned over time using Bayesian updating. It is known that the solution to these problems can in principle be obtained by solving the Bayesian dynamic programming (BDP) equation. Although the BDP equation can be solved in certain special cases (for example, when posteriors have low-dimensional representations), solving this equation in general is computationally intractable and remains an open problem. A second unresolved issue with the BDP equation lies in its (rather generic) interpretation. Beyond the standard narrative of balancing immediate versus future costs—an interpretation common to all dynamic programs with or without learning—the BDP equation does not provide much insight into the underlying mechanism by which sequential Bayesian optimization trades off between learning (exploration) and optimization (exploitation), the distinguishing feature of this problem class. The goal of this paper is to develop good approximations (with error bounds) to the BDP equation that help address the issues of computation and interpretation. To this end, we show how the BDP equation can be represented as a tractable single-stage optimization problem that trades off between a myopic term and a “variance regularization” term that measures the total solution variability over the remaining planning horizon. Intuitively, the myopic term can be regarded as a pure exploitation objective that ignores the impact of future learning, whereas the variance regularization term captures a pure exploration objective that only puts value on solutions that resolve statistical uncertainty. We develop quantitative error bounds for this representation and prove that the error tends to zero like o(n -1 ) almost surely in the number of stages n , which as a corollary, establishes strong consistency of the approximate solution.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1019},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Variance regularization in sequential bayesian optimization},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Characterization, robustness, and aggregation of signed
choquet integrals. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article contains various results on a class of nonmonotone, law-invariant risk functionals called the signed Choquet integrals. A functional characterization via comonotonic additivity is established along with some theoretical properties, including six equivalent conditions for a signed Choquet integral to be convex. We proceed to address two practical issues currently popular in risk management, namely robustness (continuity) issues and risk aggregation with dependence uncertainty, for signed Choquet integrals. Our results generalize in several directions those in the literature of risk functionals. From the results obtained in this paper, we see that many profound and elegant mathematical results in the theory of risk measures hold for the general class of signed Choquet integrals; thus, they do not rely on the assumption of monotonicity.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1020},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Characterization, robustness, and aggregation of signed choquet integrals},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The limit of stationary distributions of many-server queues
in the halfin–whitt regime. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the so-called GI/GI/N queue, in which a stream of jobs with independent and identically distributed service times arrive as a renewal process to a common queue that is served by N identical parallel servers in a first-come, first-served manner. We introduce a new representation for the state of the system and, under suitable conditions on the service and interarrival distributions, establish convergence of the corresponding sequence of centered and scaled stationary distributions in the so-called Halfin–Whitt asymptotic regime. In particular, this resolves an open question posed by Halfin and Whitt in 1981. We also characterize the limit as the stationary distribution of an infinite-dimensional, two-component Markov process that is the unique solution to a certain stochastic partial differential equation. Previous results were essentially restricted to exponential service distributions or service distributions with finite support, for which the corresponding limit process admits a reduced finite-dimensional Markovian representation. We develop a different approach to deal with the general case when the Markovian representation of the limit is truly infinite dimensional. This approach is more broadly applicable to a larger class of networks.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1021},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {The limit of stationary distributions of many-server queues in the Halfin–Whitt regime},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Monotonicity and weighted prenucleoli: A characterization
without consistency. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A solution on a set of transferable utility (TU) games satisfies strong aggregate monotonicity (SAM) if every player can improve when the grand coalition becomes richer. It satisfies equal surplus division (ESD) if the solution allows the players to improve equally. We show that the set of weight systems generating weighted prenucleoli that satisfy SAM is open, which implies that for weight systems close enough to any regular system, the weighted prenucleolus satisfies SAM. We also provide a necessary condition for SAM for symmetrically weighted nucleoli. Moreover, we show that the per capita nucleolus on balanced games is characterized by single-valuedness (SIVA), translation covariance (TCOV) and scale covariance (SCOV), and equal adjusted surplus division (EASD), a property that is comparable to but stronger than ESD. These properties together with ESD characterize the per capita prenucleolus on larger sets of TU games. EASD and ESD can be transformed to independence of ( adjusted ) proportional shifting , and these properties may be generalized for arbitrary weight systems p to I(A)S p . We show that the p -weighted prenucleolus on the set of balanced TU games is characterized by SIVA, TCOV, SCOV, and IAS p and on larger sets by additionally requiring IS p .},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1022},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Monotonicity and weighted prenucleoli: A characterization without consistency},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Steady-state analysis of the join-the-shortest-queue model
in the halfin–whitt regime. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the steady-state properties of the join-the-shortest-queue model in the Halfin–Whitt regime. We focus on the process tracking the number of idle servers and the number of servers with nonempty buffers. Recently, Eschenfeldt and Gamarnik proved that a scaled version of this process converges, over finite time intervals, to a two-dimensional diffusion limit as the number of servers goes to infinity. In this paper, we prove that the diffusion limit is exponentially ergodic and that the diffusion scaled sequence of the steady-state number of idle servers and nonempty buffers is tight. Combined with the process-level convergence proved by Eschenfeldt and Gamarnik, our results imply convergence of steady-state distributions. The methodology used is the generator expansion framework based on Stein’s method, also referred to as the drift-based fluid limit Lyapunov function approach in Stolyar. One technical contribution to the framework is to show how it can be used as a general tool to establish exponential ergodicity.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1023},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Steady-state analysis of the join-the-shortest-queue model in the Halfin–Whitt regime},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A stochastic analysis of queues with customer choice and
delayed information. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many service systems provide queue length information to customers, thereby allowing customers to choose among many options of service. However, queue length information is often delayed, and it is often not provided in real time. Recent work by Dong et al. [Dong J, Yom-Tov E, Yom-Tov GB (2018) The impact of delay announcements on hospital network coordination and waiting times. Management Sci. 65(5):1969–1994.] explores the impact of these delays in an empirical study in U.S. hospitals. Work by Pender et al. [Pender J, Rand RH, Wesson E (2017) Queues with choice via delay differential equations. Internat. J. Bifurcation Chaos Appl. Sci. Engrg . 27(4):1730016-1–1730016-20.] uses a two-dimensional fluid model to study the impact of delayed information and determine the exact threshold under which delayed information can cause oscillations in the dynamics of the queue length. In this work, we confirm that the fluid model analyzed by Pender et al. [Pender J, Rand RH, Wesson E (2017) Queues with choice via delay differential equations. Internat. J. Bifurcation Chaos Appl. Sci. Engrg . 27(4):1730016-1–1730016-20.] can be rigorously obtained as a functional law of large numbers limit of a stochastic queueing process, and we generalize their threshold analysis to arbitrary dimensions. Moreover, we prove a functional central limit theorem for the queue length process and show that the scaled queue length converges to a stochastic delay differential equation. Thus, our analysis sheds new insight on how delayed information can produce unexpected system dynamics.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1024},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {A stochastic analysis of queues with customer choice and delayed information},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A dynamic network model of interbank lending—systemic risk
and liquidity provisioning. <em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a dynamic model of interbank borrowing and lending activities in which banks are organized into clusters, and adjust their monetary reserve levels to meet prescribed capital requirements. Each bank has its own initial monetary reserve level and faces idiosyncratic risks characterized by an independent Brownian motion, whereas system wide, the banks form a hierarchical structure of clusters. We model the interbank transactional dynamics through a set of interacting measure-valued processes. Each individual process describes the intracluster borrowing/lending activities, and the interactions among the processes capture the intercluster financial transactions. We establish the weak limit of the interacting measure-valued processes as the number of banks in the system grows large. We then use the weak limit to develop asymptotic approximations of two proposed macromeasures (the liquidity stress index and the concentration index), both capturing the dynamics of systemic risk. We use numerical examples to illustrate the applications of the asymptotics and conduct-related sensitivity analysis with respect to various indicators of financial activity.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1025},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {A dynamic network model of interbank Lending—Systemic risk and liquidity provisioning},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Exchangeable processes: De finetti’s theorem revisited.
<em>MOOR</em>, <em>45</em>(3), 797–1192. (<a
href="https://doi.org/10.1287/moor.2019.1026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequence of random variables is exchangeable if the joint distribution of any finite subsequence is invariant to permutations. De Finetti’s representation theorem states that every exchangeable infinite sequence is a convex combination of independent and identically distributed processes. In this paper, we explore the relationship between exchangeability and frequency-dependent posteriors. We show that any stationary process is exchangeable if and only if its posteriors depend only on the empirical frequency of past events.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1026},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Exchangeable processes: De finetti’s theorem revisited},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Strong metric (sub)regularity of karush–kuhn–tucker mappings
for piecewise linear-quadratic convex-composite optimization and the
quadratic convergence of newton’s method. <em>MOOR</em>, <em>45</em>(3),
797–1192. (<a href="https://doi.org/10.1287/moor.2019.1027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work concerns the local convergence theory of Newton and quasi-Newton methods for convex-composite optimization: where one minimizes an objective that can be written as the composition of a convex function with one that is continuiously differentiable. We focus on the case in which the convex function is a potentially infinite-valued piecewise linear-quadratic function. Such problems include nonlinear programming, mini-max optimization, and estimation of nonlinear dynamics with non-Gaussian noise as well as many modern approaches to large-scale data analysis and machine learning. Our approach embeds the optimality conditions for convex-composite optimization problems into a generalized equation. We establish conditions for strong metric subregularity and strong metric regularity of the corresponding set-valued mappings. This allows us to extend classical convergence of Newton and quasi-Newton methods to the broader class of nonfinite valued piecewise linear- quadratic convex-composite optimization problems. In particular, we establish local quadratic convergence of the Newton method under conditions that parallel those in nonlinear programming.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1027},
  journal      = {Mathematics of Operations Research},
  number       = {3},
  pages        = {797-1192},
  shortjournal = {Math. Oper. Res.},
  title        = {Strong metric (Sub)regularity of Karush–Kuhn–Tucker mappings for piecewise linear-quadratic convex-composite optimization and the quadratic convergence of newton’s method},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Future expectations modeling, random coefficient
forward–backward stochastic differential equations, and stochastic
viscosity solutions. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2018.0981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study a class of infinite horizon fully coupled forward–backward stochastic differential equations (FBSDEs) with random coefficients that are stimulated by various continuous time future expectations models. Under standard Lipschitz and monotonicity conditions and by means of the contraction mapping principle, we establish existence and uniqueness of an adapted solution, and we obtain results regarding the dependence of this solution on the data of the problem. Making further the connection with finite horizon quasilinear backward stochastic partial differential equations via a generalization of the well known four-step-scheme, we are led to the notion of stochastic viscosity solutions. As an application of this framework, we also provide a stochastic maximum principle for the optimal control problem of such FBSDEs, which in the linear-quadratic Markovian case boils down to the solvability of an infinite horizon fully coupled system of forward-backward Ricatti differential equations.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0981},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Future expectations modeling, random coefficient Forward–Backward stochastic differential equations, and stochastic viscosity solutions},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Quitting games and linear complementarity problems.
<em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.0996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that every multiplayer quitting game admits a sunspot ε -equilibrium for every ε &gt;0, that is, an ε -equilibrium in an extended game in which the players observe a public signal at every stage. We also prove that, if a certain matrix that is derived from the payoffs in the game is not a Q -matrix in the sense of linear complementarity problems, then the game admits a uniform ε -equilibrium for every ε &gt;0.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0996},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Quitting games and linear complementarity problems},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Counting integral points in polytopes via numerical analysis
of contour integration. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.0997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of counting integer points in a rational polytope described by P ( y ) = { x ∈ R m : A x = y, x ≥ 0}, where A is an n × m integer matrix and y is an n -dimensional integer vector. We study the Z transformation approach initiated in works by Brion and Vergne, Beck, and Lasserre and Zeron from the numerical analysis point of view and obtain a new algorithm on this problem. If A is nonnegative, then the number of integer points in P ( y ) can be computed in O ( poly ( n , m , ‖ y ‖ ∞ ) ( ‖ y ‖ ∞ + 1 ) n ) time and O ( poly ( n , m , ‖ y ‖ ∞ ) ) space. This improves, in terms of space complexity, a naive DP algorithm with O ( ( ‖ y ‖ ∞ + 1 ) n ) -size dynamic programming table. Our result is based on the standard error analysis of the numerical contour integration for the inverse Z transform and establishes a new type of an inclusion-exclusion formula for integer points in P ( y ). We apply our result to hypergraph b -matching and obtain a O ( poly ( n , m , ‖ b ‖ ∞ ) ( ‖ b ‖ ∞ + 1 ) ( 1 − 1 / k ) n ) time algorithm for counting b -matchings in a k -partite hypergraph with n vertices and m hyperedges. This result is viewed as a b -matching generalization of the classical result by Ryser for k = 2 and its multipartite extension by Björklund and Husfeldt.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0997},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Counting integral points in polytopes via numerical analysis of contour integration},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). A verification theorem for threshold-indexability of
real-state discounted restless bandits. <em>MOOR</em>, <em>45</em>(2),
403–795. (<a href="https://doi.org/10.1287/moor.2019.0998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Whittle index, which characterizes optimal policies for controlling certain single restless bandit projects (a Markov decision process with two actions: active and passive) is the basis for a widely used heuristic index policy for the intractable restless multiarmed bandit problem. Yet two roadblocks need to be overcome to apply such a policy: the individual projects in the model at hand must be shown to be indexable, so that they possess a Whittle index; and the index must be evaluated. Such roadblocks can be especially vexing when project state spaces are real intervals, as in recent sensor scheduling applications. This paper presents sufficient conditions for indexability (relative to a generalized Whittle index) of general real-state discrete-time restless bandits under the discounted criterion, which are not based on elucidating properties of the optimal value function and do not require proving beforehand optimality of threshold policies as in prevailing approaches. The main contribution is a verification theorem establishing that, if project performance metrics under threshold policies and an explicitly defined marginal productivity (MP) index satisfy three conditions, then the project is indexable with its generalized Whittle index being given by the MP index, and threshold policies are optimal for dynamic project control.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0998},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {A verification theorem for threshold-indexability of real-state discounted restless bandits},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Greed works—online algorithms for unrelated machine
stochastic scheduling. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.0999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes performance guarantees for online algorithms that schedule stochastic, nonpreemptive jobs on unrelated machines to minimize the expected total weighted completion time. Prior work on unrelated machine scheduling with stochastic jobs was restricted to the offline case and required linear or convex programming relaxations for the assignment of jobs to machines. The algorithms introduced in this paper are purely combinatorial. The performance bounds are of the same order of magnitude as those of earlier work and depend linearly on an upper bound on the squared coefficient of variation of the jobs’ processing times. Specifically for deterministic processing times, without and with release times, the competitive ratios are 4 and 6, respectively. As to the technical contribution, this paper shows how dual fitting techniques can be used for stochastic and nonpreemptive scheduling problems.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0999},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Greed Works—Online algorithms for unrelated machine stochastic scheduling},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Randomized linear programming solves the markov decision
problem in nearly linear (sometimes sublinear) time. <em>MOOR</em>,
<em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel randomized linear programming algorithm for approximating the optimal policy of the discounted-reward and average-reward Markov decision problems. By leveraging the value–policy duality, the algorithm adaptively samples state–action–state transitions and makes exponentiated primal–dual updates. We show that it finds an ɛ -optimal policy using nearly linear runtime in the worst case for a fixed value of the discount factor. When the Markov decision process is ergodic and specified in some special data formats, for fixed values of certain ergodicity parameters, the algorithm finds an ɛ -optimal policy using sample size and time linear in the total number of state–action pairs, which is sublinear in the input size. These results provide a new venue and complexity benchmarks for solving stochastic dynamic programs.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1000},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Randomized linear programming solves the markov decision problem in nearly linear (Sometimes sublinear) time},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Synthesis and generalization of structural results in
inventory management: A generalized convexity property. <em>MOOR</em>,
<em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address a general periodic review inventory control model with the simultaneous presence of the following complications: (a) bilateral inventory adjustment options, via procurement orders and salvage sales or returns to the supplier; (b) fixed costs associated with procurement orders and downward inventory adjustments (via salvage sales or returns); and (c) capacity limits associated with upward or downward inventory adjustments. We characterize the optimal adjustment strategy, both for finite and infinite horizon periodic review models, by showing that in each period the inventory position line is to be partitioned into (maximally) five regions. Our results are obtained by identifying a novel generalized convexity property for the value functions, which we refer to as strong ( C 1 K 1 , C 2 K 2 )-convexity. To our knowledge, we recover most existing structural results for models with exogenous demands as special cases of a unified analysis.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1001},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Synthesis and generalization of structural results in inventory management: A generalized convexity property},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Budgeted prize-collecting traveling salesman and minimum
spanning tree problems. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider constrained versions of the prize-collecting traveling salesman and the prize-collecting minimum spanning tree problems. The goal is to maximize the number of vertices in the returned tour/tree subject to a bound on the tour/tree cost. Rooted variants of the problems have the additional constraint that a given vertex, the root, must be contained in the tour/tree. We present a 2-approximation algorithm for the rooted and unrooted versions of both the tree and tour variants. The algorithm is based on a parameterized primal–dual approach. It relies on first finding a threshold value for the dual variable corresponding to the budget constraint in the primal and then carefully constructing a tour/tree that is, in a precise sense, just within budget. We improve upon the best-known guarantee of 2 + ε for the rooted and unrooted tour versions and 3 + ε for the rooted and unrooted tree versions. Our analysis extends to the setting with weighted vertices, in which we want to maximize the total weight of vertices in the tour/tree. Interestingly enough, the algorithm and analysis for the rooted case and the unrooted case are almost identical.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1002},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Budgeted prize-collecting traveling salesman and minimum spanning tree problems},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Primal–dual interior-point methods for domain-driven
formulations. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study infeasible-start, primal–dual interior-point methods for convex optimization problems given in a typically natural form we denote as domain-driven formulations. Our algorithms extend many advantages of primal–dual interior-point techniques available for conic formulations, such as the current best complexity bounds, and more robust certificates of approximate optimality, unboundedness, and infeasibility, to domain-driven formulations. The complexity results are new for the infeasible-start setup used even in the case of linear programming. In addition to complexity results, our algorithms aim for expanding the applications of and software for interior-point methods to wider classes of problems beyond optimization over symmetric cones.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1003},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Primal–Dual interior-point methods for domain-driven formulations},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The pareto comparisons of a group of exponential
discounters. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agents with different discount factors disagree about some intertemporal trade-offs, but they will also agree sometimes. We seek to understand precisely the nature of their agreements and disagreements. A group of agents is identified with a set of discount factors. We characterize the comparisons that a given interval of discount factors will agree on, including what all discount factors in the interval [0, 1] will agree on. Our result is analogous to how all risk-averse and monotone agents agree on mean-preserving spreads. Motivated by a maxmin representation, we also characterize the comparisons that are consistent with some set of discount factors, when the set is not known or exogenously given. In other words, we describe the Pareto comparisons that are consistent with a society, or group, of exponentially discounting agents.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1004},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {The pareto comparisons of a group of exponential discounters},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Multiconstrained finite-horizon piecewise deterministic
markov decision processes with unbounded transition rates.
<em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a multiconstrained problem for piecewise deterministic Markov decision processes (PDMDPs) with unbounded cost and transition rates. The goal is to minimize one type of expected finite-horizon cost over history-dependent policies while keeping some other types of expected finite-horizon costs lower than some tolerable bounds. Using the Dynkin formula for the PDMDPs, we obtain an equivalent characterization of occupancy measures and express the expected finite-horizon costs in terms of occupancy measures. Under suitable assumptions, the existence of constrained-optimal policies is shown, the linear programming formulation and its dual program for the constrained problem are derived, and the strong duality between the two programs is established. An example is provided to demonstrate our results.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1005},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Multiconstrained finite-horizon piecewise deterministic markov decision processes with unbounded transition rates},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rates of convergence to stationarity for reflected brownian
motion. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide the first rate of convergence to stationarity analysis for reflected Brownian motion (RBM) as the dimension grows under some uniformity conditions. In particular, if the underlying routing matrix is uniformly contractive, uniform stability of the drift vector holds, and the variances of the underlying Brownian motion (BM) are bounded, then we show that the RBM converges exponentially fast to stationarity with a relaxation time of order O ( d 4 ( l o g ( d ) ) 3 ) as the dimension d → ∞. Our bound for the relaxation time follows as a corollary of the nonasymptotic bound we obtain for the initial transient effect, which is explicit in terms of the RBM parameters.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1006},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Rates of convergence to stationarity for reflected brownian motion},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The proximal alternating direction method of multipliers in
the nonconvex setting: Convergence analysis and rates. <em>MOOR</em>,
<em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two numerical algorithms in the fully nonconvex setting for the minimization of the sum of a smooth function and the composition of a nonsmooth function with a linear operator. The iterative schemes are formulated in the spirit of the proximal alternating direction method of multipliers and its linearized variant, respectively. The proximal terms are introduced via variable metrics, a fact that allows us to derive new proximal splitting algorithms for nonconvex structured optimization problems, as particular instances of the general schemes. Under mild conditions on the sequence of variable metrics and by assuming that a regularization of the associated augmented Lagrangian has the Kurdyka–Łojasiewicz property, we prove that the iterates converge to a Karush–Kuhn–Tucker point of the objective function. By assuming that the augmented Lagrangian has the Łojasiewicz property, we also derive convergence rates for both the augmented Lagrangian and the iterates.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1008},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {The proximal alternating direction method of multipliers in the nonconvex setting: Convergence analysis and rates},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hamiltonian cycles and subsets of discounted occupational
measures. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a certain polytope arising from embedding the Hamiltonian cycle problem in a discounted Markov decision process. The Hamiltonian cycle problem can be reduced to finding particular extreme points of a certain polytope associated with the input graph. This polytope is a subset of the space of discounted occupational measures. We characterize the feasible bases of the polytope for a general input graph G and determine the expected numbers of different types of feasible bases when the underlying graph is random. We utilize these results to demonstrate that augmenting certain additional constraints to reduce the polyhedral domain can eliminate a large number of feasible bases that do not correspond to Hamiltonian cycles. Finally, we develop a random walk algorithm on the feasible bases of the reduced polytope and present some numerical results. We conclude with a conjecture on the feasible bases of the reduced polytope.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1009},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Hamiltonian cycles and subsets of discounted occupational measures},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Rescaling algorithms for linear conic feasibility.
<em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose simple polynomial-time algorithms for two linear conic feasibility problems. For a matrix A ∈ ℝ m × n , the kernel problem requires a positive vector in the kernel of A , and the image problem requires a positive vector in the image of A T . Both algorithms iterate between simple first-order steps and rescaling steps. These rescalings improve natural geometric potentials. If Goffin’s condition measure ρ A is negative, then the kernel problem is feasible, and the worst-case complexity of the kernel algorithm is O ( ( m 3 n + m n 2 ) l o g | ρ A | − 1 ) ; if ρ A &gt; 0 , then the image problem is feasible, and the image algorithm runs in time O ( m 2 n 2 ⁡ l o g ⁡ ρ A − 1 ) . We also extend the image algorithm to the oracle setting. We address the degenerate case ρ A = 0 by extending our algorithms to find maximum support nonnegative vectors in the kernel of A and in the image of A T . In this case, the running time bounds are expressed in the bit-size model of computation: for an input matrix A with integer entries and total encoding length L , the maximum support kernel algorithm runs in time O ( ( m 3 n + m n 2 ) L ) , whereas the maximum support image algorithm runs in time O ( m 2 n 2 L ) . The standard linear programming feasibility problem can be easily reduced to either maximum support problems, yielding polynomial-time algorithms for linear programming.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1011},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Rescaling algorithms for linear conic feasibility},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Price of anarchy in networks with heterogeneous latency
functions. <em>MOOR</em>, <em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the performance of selfish network routing in multicommodity flows where the latency or delay function on edges is dependent on the flow of individual commodities, rather than on the aggregate flow. An application of this study is the analysis of a network with differentiated traffic, that is, in transportation networks where there are multiple types of traffic and in networks where traffic is prioritized according to type classification. We consider the inefficiency of equilibrium in this model and provide price of anarchy bounds for networks with k (types of) commodities, where each link is associated with heterogeneous polynomial delays, that is, commodity i on edge e faces delay specified by a multivariate polynomial dependent on the individual flow of each commodity on the edge. We consider both atomic and nonatomic flows and show bounds on the price of anarchy that depend on the relative impact of each type of traffic on the edge delay when the delay functions are polynomials of degree θ , for example, ∑ i a i f i ( e ) θ . The price of anarchy is unbounded for arbitrary polynomials. For networks with decomposable delay functions where the delay is the same for all commodities using the edge, we show improved bounds on the price of anarchy, for both nonatomic and atomic flows. The results illustrate that the inefficiency of selfish routing worsens in the case of heterogeneous delays compared with the standard delay functions that do not consider type differentiation.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1012},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Price of anarchy in networks with heterogeneous latency functions},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Epi-regularization of risk measures. <em>MOOR</em>,
<em>45</em>(2), 403–795. (<a
href="https://doi.org/10.1287/moor.2019.1013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty pervades virtually every branch of science and engineering, and in many disciplines, the underlying phenomena can be modeled by partial differential equations (PDEs) with uncertain or random inputs. This work is motivated by risk-averse stochastic programming problems constrained by PDEs. These problems are posed in infinite dimensions, which leads to a significant increase in the scale of the (discretized) problem. In order to handle the inherent nonsmoothness of, for example, coherent risk measures and to exploit existing solution techniques for smooth, PDE-constrained optimization problems, we propose a variational smoothing technique called epigraphical (epi-)regularization. We investigate the effects of epi-regularization on the axioms of coherency and prove differentiability of the smoothed risk measures. In addition, we demonstrate variational convergence of the epi-regularized risk measures and prove the consistency of minimizers and first-order stationary points for the approximate risk-averse optimization problem. We conclude with numerical experiments confirming our theoretical results.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.1013},
  journal      = {Mathematics of Operations Research},
  number       = {2},
  pages        = {403-795},
  shortjournal = {Math. Oper. Res.},
  title        = {Epi-regularization of risk measures},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The euclidean k-supplier problem. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0953">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -supplier problem is a fundamental location problem that involves opening k facilities to minimize the maximum distance of any client to an open facility. We consider the k -supplier problem in Euclidean metrics (of arbitrary dimension) and present an algorithm with approximation ratio 1 + 3 2.64 . We also present a nearly linear time algorithm for the Euclidean k -supplier in constant dimensions that achieves an approximation ratio better than three.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0953},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {The euclidean k-supplier problem},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Decompositions of semidefinite matrices and the perspective
reformulation of nonseparable quadratic programs. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of decomposing the Hessian matrix of a mixed integer convex quadratic program (MICQP) into the sum of positive semidefinite 2 × 2 matrices. Solving this problem enables the use of perspective reformulation techniques for obtaining strong lower bounds for MICQPs with semicontinuous variables but a nonseparable objective function. An explicit formula is derived for constructing 2 × 2 decompositions when the underlying matrix is weakly scaled diagonally dominant, and necessary and sufficient conditions are given for the decomposition to be unique. For matrices lying outside this class, two exact semidefinite programming approaches and an efficient heuristic are developed for finding approximate decompositions. We present preliminary results on the bound strength of a 2 × 2 perspective reformulation for the portfolio optimization problem, showing that, for some classes of instances, the use of 2 × 2 matrices can significantly improve the quality of the bound with respect to the best previously known approach, although at a possibly high computational cost.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0969},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Decompositions of semidefinite matrices and the perspective reformulation of nonseparable quadratic programs},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Polynomial time algorithms for branching markov decision
processes and probabilistic min(max) polynomial bellman equations.
<em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that one can compute the least nonnegative solution (also known as the least fixed point ) for a system of probabilistic min (max) polynomial equations, to any desired accuracy ɛ &gt; 0 in time polynomial in both the encoding size of the system and in log(1/ ɛ ). These are Bellman optimality equations for important classes of infinite-state Markov decision processes (MDPs), including branching MDPs (BMDPs), which generalize classic multitype branching stochastic processes. We thus obtain the first polynomial time algorithm for computing, to any desired precision, optimal (maximum and minimum) extinction probabilities for BMDPs. Our algorithms are based on a novel generalization of Newton’s method, which employs linear programming in each iteration. We also provide polynomial-time (P-time) algorithms for computing an ɛ -optimal policy for both maximizing and minimizing extinction probabilities in a BMDP, whereas we note a hardness result for computing an exact optimal policy. Furthermore, improving on prior results, we provide more efficient P-time algorithms for qualitative analysis of BMDPs, that is, for determining whether the maximum or minimum extinction probability is 1, and, if so, computing a policy that achieves this. We also observe some complexity consequences of our results for branching simple stochastic games, which generalize BMDPs.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0970},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Polynomial time algorithms for branching markov decision processes and probabilistic Min(Max) polynomial bellman equations},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Finding a stable allocation in polymatroid intersection.
<em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stable matching (or stable marriage) model of Gale and Shapley [Gale D, Shapley LS (1962) College admissions and the stability of marriage. Amer. Math. Monthly 69(1):9–15.] has been generalized in various directions, such as matroid kernels by Fleiner [Fleiner T (2001) A matroid generalization of the stable matching polytope. Aardal K, Gerards AMH, eds. Proc. 8th Internat. Conf. Integer Programming Combin. Optim., Lecture Notes in Computer Science, vol. 2081 (Springer-Verlag, Berlin), 105–114.] and stable allocations in bipartite networks by Baïou and Balinski [Baïou M, Balinski M (2002) Erratum: The stable allocation (or ordinal transportation) problem. Math. Oper. Res. 27(4):662–680.]. Unifying these generalizations, we introduce the concept of stable allocations in polymatroid intersection. Our framework includes both integer and real variable versions. The integer variable version corresponds to a special case of the discrete concave function model of Eguchi et al. [Eguchi A, Fujishige S, Tamura A (2003) A generalized Gale-Shapley algorithm for a discrete-concave stable-marriage model. Ibaraki T, Katoh N, Ono H, eds. Proc. 14th Internat. Sympos. Algorithms Comput ., Lecture Notes in Computer Science, vol. 2906 (Springer-Verlag, Berlin), 495–504.], who established the existence of a stable allocation by showing that a simple extension of the deferred acceptance algorithm of Gale and Shapley finds a stable allocation in pseudopolynomial time. It has been open to develop a polynomial time algorithm even for our special case. In this paper, we present the first strongly polynomial algorithm for finding a stable allocation in polymatroid intersection. To achieve this, we utilize the augmenting path technique for polymatroid intersection. In each iteration, the algorithm searches for an augmenting path by simulating a chain of proposes and rejects in the deferred acceptance algorithm. The running time of our algorithm is O ( n 3 γ), where n and γ denote the cardinality of the ground set and the time for computing the saturation and exchange capacities, respectively. Moreover, we show that the output of our algorithm is optimal for one side, where this optimality is a generalization of the man optimality in the stable marriage model.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0976},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Finding a stable allocation in polymatroid intersection},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Worst-case examples for lasserre’s measure–based hierarchy
for polynomial optimization on the hypercube. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the convergence rate of a hierarchy of upper bounds for polynomial optimization problems, proposed by Lasserre, and a related hierarchy by de Klerk, Hess, and Laurent. For polynomial optimization over the hypercube, we show a refined convergence analysis for the first hierarchy. We also show lower bounds on the convergence rate for both hierarchies on a class of examples. These lower bounds match the upper bounds and thus establish the true rate of convergence on these examples. Interestingly, these convergence rates are determined by the distribution of extremal zeroes of certain families of orthogonal polynomials.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0983},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Worst-case examples for lasserre’s Measure–Based hierarchy for polynomial optimization on the hypercube},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Discrete midpoint convexity. <em>MOOR</em>, <em>45</em>(1),
1–401. (<a href="https://doi.org/10.1287/moor.2018.0984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a function defined on the integer lattice, we consider discrete versions of midpoint convexity, which offer a unifying framework for discrete convexity of functions, including integral convexity, L ♮ -convexity, and submodularity. By considering discrete midpoint convexity for all pairs at ℓ ∞ -distance equal to 2 or not smaller than 2, we identify new classes of discrete convex functions, called locally and globally discrete midpoint convex functions . These functions enjoy nice structural properties. They are stable under scaling and addition and satisfy a family of inequalities named parallelogram inequalities . Furthermore, they admit a proximity theorem with the same small proximity bound as that for L ♮ -convex functions. These structural properties allow us to develop an algorithm for the minimization of locally and globally discrete midpoint convex functions based on the proximity-scaling approach and on a novel 2-neighborhood steepest descent algorithm.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0984},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Discrete midpoint convexity},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Reference dependence and market participation.
<em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper finds optimal portfolios for the reference-dependent preferences by Kőszegi and Rabin with piecewise linear gain–loss utility in a one-period model with a safe and a risky asset. If the return of the risky asset is highly dispersed relative to its potential gains, two personal equilibria arise, one of them including risky investments and the other one only safe holdings. In the same circumstances, the risky personal equilibrium entails market participation that decreases with loss aversion and gain–loss sensitivity, whereas the preferred personal equilibrium is sensitive to market and preference parameters. Relevant market parameters are not the expected return and standard deviation, but rather the ratio of expected gains to losses and the Gini index of the return.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0985},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Reference dependence and market participation},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On synchronous, asynchronous, and randomized best-response
schemes for stochastic nash games. <em>MOOR</em>, <em>45</em>(1), 1–401.
(<a href="https://doi.org/10.1287/moor.2018.0986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a stochastic Nash game in which each player minimizes a parameterized expectation-valued convex objective function. In deterministic regimes, proximal best-response (BR) schemes have been shown to be convergent under a suitable spectral property associated with the proximal BR map. However, a direct application of this scheme to stochastic settings requires obtaining exact solutions to stochastic optimization problems at each iteration. Instead, we propose an inexact generalization of this scheme in which an inexact solution to the BR problem is computed in an expected-value sense via a stochastic approximation (SA) scheme. On the basis of this framework, we present three inexact BR schemes: (i) First, we propose a synchronous inexact BR scheme where all players simultaneously update their strategies. (ii) Second, we extend this to a randomized setting where a subset of players is randomly chosen to update their strategies while the other players keep their strategies invariant. (iii) Third, we propose an asynchronous scheme, where each player chooses its update frequency while using outdated rival-specific data in updating its strategy. Under a suitable contractive property on the proximal BR map, we proceed to derive almost sure convergence of the iterates to the Nash equilibrium (NE) for (i) and (ii) and mean convergence for (i)–(iii). In addition, we show that for (i)–(iii), the generated iterates converge to the unique equilibrium in mean at a linear rate with a prescribed constant rather than a sublinear rate. Finally, we establish the overall iteration complexity of the scheme in terms of projected stochastic gradient (SG) steps for computing an ɛ -NE 2 (or ɛ -NE ∞ ) and note that in all settings, the iteration complexity is O ( 1 / ɛ 2 ( 1 + c ) + δ ) , where c = 0 in the context of (i), and c &gt; 0 represents the positive cost of randomization in (ii) and asynchronicity and delay in (iii). Notably, in the synchronous regime, we achieve a near-optimal rate from the standpoint of solving stochastic convex optimization problems by SA schemes. The schemes are further extended to settings where players solve two-stage stochastic Nash games with linear and quadratic recourse. Finally, preliminary numerics developed on a multiportfolio investment problem and a two-stage capacity expansion game support the rate and complexity statements.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0986},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {On synchronous, asynchronous, and randomized best-response schemes for stochastic nash games},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). The computational complexity of integer programming with
alternations. <em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2018.0988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove that integer programming with three alternating quantifiers is NP-complete, even for a fixed number of variables. This complements earlier results by Lenstra [ 16 ] [Lenstra H ( 1983 ) Integer programming with a fixed number of variables. Math. Oper. Res. 8(4):538–548.] and Kannan [ 13, 14 ] [Kannan R ( 1990 ) Test sets for integer programs, ∀ ∃ sentences. Polyhedral Combinatorics (American Mathematical Society, Providence, RI), 39–47. Kannan R ( 1992 ) Lattice translates of a polytope and the Frobenius problem. Combinatorica 12(2):161–177.], which together say that integer programming with at most two alternating quantifiers can be done in polynomial time for a fixed number of variables. As a byproduct of the proof, we show that for two polytopes P , Q ⊂ R 3 , counting the projections of integer points in Q\P is #P-complete. This contrasts the 2003 result by Barvinok and Woods [ 5 ] [Barvinok A, Woods K ( 2003 ) Short rational generating functions for lattice point problems. J. Amer. Math. Soc. 16(4):957–979.], which allows counting in polynomial time the projections of integer points in P and Q separately.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2018.0988},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {The computational complexity of integer programming with alternations},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Nonzero-sum stochastic differential games with impulse
controls: A verification theorem with applications. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a general nonzero-sum impulse game with two players. The main mathematical contribution of this paper is a verification theorem that provides, under some regularity conditions, a suitable system of quasi-variational inequalities for the payoffs and the strategies of the two players at some Nash equilibrium. As an application, we study an impulse game with a one-dimensional state variable, following a real-valued scaled Brownian motion, and two players with linear and symmetric running payoffs. We fully characterize a family of Nash equilibria and provide explicit expressions for the corresponding equilibrium strategies and payoffs. We also prove some asymptotic results with respect to the intervention costs. Finally, we consider two further nonsymmetric examples where a Nash equilibrium is found numerically.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0989},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Nonzero-sum stochastic differential games with impulse controls: A verification theorem with applications},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the efficiency of random permutation for ADMM and
coordinate descent. <em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random permutation is observed to be powerful for optimization algorithms: for multiblock ADMM (alternating direction method of multipliers), whereas the classical cyclic version diverges, the randomly permuted version converges in practice; for BCD (block coordinate descent), the randomly permuted version is typically faster than other versions. In this paper we provide strong theoretical evidence that random permutation has positive effects on ADMM and BCD, by analyzing randomly permuted ADMM (RP-ADMM) for solving linear systems of equations, and randomly permuted BCD (RP-BCD) for solving unconstrained quadratic problems. First, we prove that RP-ADMM converges in expectation for solving systems of linear equations. The key technical result is that the spectrum of the expected update matrix of RP-BCD lies in (−1/3, 1), instead of the typical range (−1, 1). Second, we establish expected convergence rates of RP-ADMM for solving linear systems and RP-BCD for solving unconstrained quadratic problems. This expected rate of RP-BCD is O ( n ) times better than the worst-case rate of cyclic BCD, thus establishing a gap of at least O ( n ) between RP-BCD and cyclic BCD. To analyze RP-BCD, we propose a conjecture of a new matrix algebraic mean-geometric mean inequality and prove a weaker version of it.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0990},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {On the efficiency of random permutation for ADMM and coordinate descent},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). On the construction of substitutes. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gross substitutability is a central concept in economics and is connected to important notions in discrete convex analysis, number theory, and the analysis of greedy algorithms in computer science. Many different characterizations are known for this class, but providing a constructive description remains a major open problem. The construction problem asks how to construct all gross substitutes from a class of simpler functions using a set of operations. Because gross substitutes are a natural generalization of matroids to real-valued functions, matroid rank functions form a desirable such class of simpler functions. Shioura proved that a rich class of gross substitutes can be expressed as sums of matroid rank functions, but it is open whether all gross substitutes can be constructed this way. Our main result is a negative answer showing that some gross substitutes cannot be expressed as positive linear combinations of matroid rank functions. En route, we provide necessary and sufficient conditions for the sum to preserve substitutability, uncover a new operation preserving substitutability, and fully describe all substitutes with at most four items.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0991},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {On the construction of substitutes},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Trimmed statistical estimation via variance reduction.
<em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we show how to transform any optimization problem that arises from fitting a machine learning model into one that (1) detects and removes contaminated data from the training set while (2) simultaneously fitting the trimmed model on the uncontaminated data that remains. To solve the resulting nonconvex optimization problem, we introduce a fast stochastic proximal-gradient algorithm that incorporates prior knowledge through nonsmooth regularization. For data sets of size n , our approach requires O ( n 2/3 / ℇ ) gradient evaluations to reach ℇ -accuracy, and when a certain error bound holds, the complexity improves to O ( κn 2/3 log(1/ ℇ )), where κ is a “condition number.” These rates are n 1/3 times better than those achieved by typical, nonstochastic methods.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0992},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Trimmed statistical estimation via variance reduction},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Hiring secretaries over time: The benefit of concurrent
employment. <em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a stochastic online problem where n applicants arrive over time, one per time step. Upon the arrival of each applicant, their cost per time step is revealed, and we have to fix the duration of employment, starting immediately. This decision is irrevocable; that is, we can neither extend a contract nor dismiss a candidate once hired. In every time step, at least one candidate needs to be under contract, and our goal is to minimize the total hiring cost, which is the sum of the applicants’ costs multiplied with their respective employment durations. We provide a competitive online algorithm for the case that the applicants’ costs are drawn independently from a known distribution. Specifically, the algorithm achieves a competitive ratio of 2.965 for the case of uniform distributions. For this case, we give an analytical lower bound of 2 and a computational lower bound of 2.148. We then adapt our algorithm to stay competitive even in settings with one or more of the following restrictions: (i) at most two applicants can be hired concurrently; (ii) the distribution of the applicants’ costs is unknown; (iii) the total number n of time steps is unknown. On the other hand, we show that concurrent employment is a necessary feature of competitive algorithms by proving that no algorithm has a competitive ratio better than Ω ( n / l o g n ) if concurrent employment is forbidden.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0993},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Hiring secretaries over time: The benefit of concurrent employment},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Random serial dictatorship: The one and only. <em>MOOR</em>,
<em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fix a Pareto-optimal, strategy-proof, and nonbossy deterministic matching mechanism and define a random matching mechanism by assigning agents to the roles in the mechanism via a uniform lottery. Given a profile of preferences, the lottery over outcomes that arises under the random matching mechanism is identical to the lottery that arises under random serial dictatorship, where the order of dictators is uniformly distributed. This result extends the celebrated equivalence between the core from random endowments and random serial dictatorship to the grand set of all Pareto-optimal, strategy-proof, and nonbossy matching mechanisms.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0987},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Random serial dictatorship: The one and only},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). An (almost) optimal solution for orthogonal point enclosure
query in ℝ3. <em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The orthogonal point enclosure query ( OPEQ ) problem is a fundamental problem in the context of data management for modeling user preferences. Formally, preprocess a set S of n axis-aligned boxes (possibly overlapping) in ℝ d into a data structure so that the boxes in S containing a given query point q can be reported efficiently. In the pointer machine model, optimal solutions for the OPEQ in ℝ 1 and ℝ 2 were discovered in the 1980s: linear-space data structures that can answer the query in O (log n + k ) query time, where k is the number of boxes reported. However, for the past three decades, an optimal solution in ℝ 3 has been elusive. In this work, we obtain the first data structure that almost optimally solves the OPEQ in ℝ 3 in the pointer machine model: an O ( n log* n )-space data structure with O (log 2 n · log log n + k ) query time. Here, log * n is the iterated logarithm of n . This almost matches the lower-bound, which states that any data structure that occupies O ( n ) space requires Ω (log 2 n + k ) time to answer an OPEQ in ℝ 3 . Finally, we also obtain the best known bounds for the OPEQ in higher dimensions ( d ≥ 4).},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0994},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {An (Almost) optimal solution for orthogonal point enclosure query in ℝ3},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
<li><details>
<summary>
(2020). Optimal redeeming strategy of stock loans under drift
uncertainty. <em>MOOR</em>, <em>45</em>(1), 1–401. (<a
href="https://doi.org/10.1287/moor.2019.0995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practice, one must recognize the inevitable incompleteness of information while making decisions. In this paper, we consider the optimal redeeming problem of stock loans under a state of incomplete information presented by the uncertainty in the (bull or bear) trends of the underlying stock. This is called drift uncertainty. Owing to the unavoidable need for the estimation of trends while making decisions, the related Hamilton–Jacobi–Bellman equation turns out to be of a degenerate parabolic type. Hence, it is very hard to obtain its regularity using the standard approach, making the problem different from the existing optimal redeeming problems without drift uncertainty. We present a thorough and delicate probabilistic and functional analysis to obtain the regularity of the value function and the optimal redeeming strategies. The optimal redeeming strategies of stock loans appear significantly different in the bull and bear trends.},
  archive      = {J_MOOR},
  doi          = {10.1287/moor.2019.0995},
  journal      = {Mathematics of Operations Research},
  number       = {1},
  pages        = {1-401},
  shortjournal = {Math. Oper. Res.},
  title        = {Optimal redeeming strategy of stock loans under drift uncertainty},
  volume       = {45},
  year         = {2020},
}
</textarea>
</details></li>
</ul>

</body>
</html>
